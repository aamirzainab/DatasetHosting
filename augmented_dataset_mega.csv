Conference,Year,Title,DOI,Link,FirstPage,LastPage,PaperType,Abstract,AuthorNames-Deduped,AuthorNames,AuthorAffiliation,InternalReferences,AuthorKeywords,AminerCitationCount,CitationCount_CrossRef,PubsCited_CrossRef,Downloads_Xplore,Award,GraphicsReplicabilityStamp,Keywords,RelevanceScore,KeywordClusters,RefinedKeywordClusters,AllClusters,DominantCluster
VAST,2006,Pixnostics: Towards Measuring the Value of Visualization,10.1109/vast.2006.261423,http://dx.doi.org/10.1109/VAST.2006.261423,199.0,206.0,C,"During the last two decades a wide variety of advanced methods for the visual exploration of large data sets have been proposed. For most of these techniques user interaction has become a crucial element, since there are many situations in which a user or an analyst has to select the right parameter settings from among many or select a subset of the available attribute space for the visualization process, in order to construct valuable visualizations that provide insight, into the data and reveal interesting patterns. The right choice of input parameters is often essential, since suboptimal parameter settings or the investigation of irrelevant data dimensions make the exploration process more time consuming and may result in wrong conclusions. In this paper we propose a novel method for automatically determining meaningful parameter- and attribute settings based on the information content of the resulting visualizations. Our technique called Pixnostics, in analogy to Scagnostics (Wilkinson et al., 2005), automatically analyses pixel images resulting from diverse parameter mappings and ranks them according to the potential value for the user. This allows a more effective and more efficient visual data analysis process, since the attribute/parameter space is reduced to meaningful selections and thus the analyst obtains faster insight into the data. Real world applications are provided to show the benefit of the proposed approach",Jörn Schneidewind;Mike Sips;Daniel A. Keim,Jorn Schneidewind;Mike Sips;Daniel A. Keim,"University of Konstanz, Germany;University of Stanford, USA;University of Konstanz, Germany",10.1109/infvis.2005.1532145;10.1109/infvis.2005.1532142;10.1109/visual.2005.1532782;10.1109/visual.2005.1532781;10.1109/infvis.2000.885092;10.1109/infvis.2005.1532145,"Visual Data Exploration, Visualization technique,Visual Analytics",63.0,35.0,24.0,684.0,,,construct valuable visualizations;parameter attribute settings;called pixnostics;select subset;2005 automatically,0.6616;0.2800;0.2359;0.1310;0.0510,"[np.int64(-1), -1, -1, -1, -1]",211;-1;-1;-1;-1,211,211
VAST,2015,Interactive semi-automatic categorization for spinel group minerals,10.1109/vast.2015.7347676,http://dx.doi.org/10.1109/VAST.2015.7347676,197.0,198.0,M,"Spinel group minerals are excellent indicators of geological environments (tectonic settings). In 2001, Barnes and Roeder defined a set of contours corresponding to compositional fields for spinel group minerals. Geologists typically use this contours to estimate the tectonic environment where a particular spinel composition could have been formed. This task is prone to errors and requires tedious manual comparison of overlapping diagrams. We introduce a semi-automatic, interactive detection of tectonic settings for an arbitrary dataset based on the Barnes and Roeder contours. The new approach integrates the mentioned contours and includes a novel interaction called contour brush. The new methodology is integrated in the Spinel Explorer system and it improves the scientist's workflow significantly.",Maria Luján Ganuza;Maria Florencia Gargiulo;Gabriela Ferracutti;Silvia Mabel Castro;Ernesto A. Bjerg;M. Eduard Gröller;Kresimir Matkovic,María Luján Ganuza;Florencia Gargiulo;Gabriela Ferracutti;Silvia Castro;Ernesto Bjerg;Eduard Gröller;Krešimir Matković,"UNS, VyGLab;INGEOSUR CONICET;INGEOSUR CONICET;UNS, VyGLab;INGEOSUR CONICET;TU Wien;VRVis",0.1109/tvcg.2014.2346754,,5.0,2.0,5.0,106.0,,,interactive detection tectonic;compositional fields spinel;settings arbitrary dataset;group;prone errors,0.6692;0.3364;0.1164;0.0436;0.0330,"[np.int64(-1), -1, -1, -1, -1]",251;-1;-1;-1;-1,251,251
Vis,1994,Visualization in medicine: VIRTUAL reality or ACTUAL reality ?,10.1109/visual.1994.346288,http://dx.doi.org/10.1109/VISUAL.1994.346288,396.0,399.0,M,Discusses and debates the role played by 3D visualization in medicine as a set of methods and techniques for displaying 3D spatial information related to the anatomy and the physiology of the human body.&lt;&lt;ETX&gt;&gt;,Christian Roux;Jean-Louis Coatrieux;Jean-Louis Dillenseger;Elliot K. Fishman;Murray H. Loew;Hans-Peter Meinzer;Justin D. Pearlman,C. Roux;J.L. Coatrieux;J.-L. Dillenseger;E.K. Fishman;M. Loew;H.-P. Meinzer;J.D. Pearlman,"Département Image et Traitement de l'Information, Ecole Nationale Supérieure des TéIécommunications, Brest, France;Labratoire Tiaitement du Signal et de l'Image, Université de Rennes 1, Rennes, France;University of Rennes I, France;Johns Hopkins School of Medicine, USA;Washington University, USA;German Cancer Center Heidelberg, Germany;Harvard Medical School, USA",,,3.0,1.0,3.0,96.0,,,3d visualization medicine;body;methods techniques displaying;lt etx;debates role,0.8177;0.2443;0.2170;0.0906;0.0320,"[np.int64(-1), -1, -1, -1, -1]",133;-1;-1;-1;-1,133,133
InfoVis,2014,Attribute Signatures: Dynamic Visual Summaries for Analyzing Multivariate Geographical Data,10.1109/tvcg.2014.2346265,http://dx.doi.org/10.1109/TVCG.2014.2346265,2033.0,2042.0,J,"The visual analysis of geographically referenced datasets with a large number of attributes is challenging due to the fact that the characteristics of the attributes are highly dependent upon the locations at which they are focussed, and the scale and time at which they are measured. Specialized interactive visual methods are required to help analysts in understanding the characteristics of the attributes when these multiple aspects are considered concurrently. Here, we develop attribute signatures-interactively crafted graphics that show the geographic variability of statistics of attributes through which the extent of dependency between the attributes and geography can be visually explored. We compute a number of statistical measures, which can also account for variations in time and scale, and use them as a basis for our visualizations. We then employ different graphical configurations to show and compare both continuous and discrete variation of location and scale. Our methods allow variation in multiple statistical summaries of multiple attributes to be considered concurrently and geographically, as evidenced by examples in which the census geography of London and the wider UK are explored.",Cagatay Turkay;Aidan Slingsby;Helwig Hauser;Jo Wood;Jason Dykes,Cagatay Turkay;Aidan Slingsby;Helwig Hauser;Jo Wood;Jason Dykes,"Dep. of Computer Science at City University London, UK;Dep. of Computer Science at City University London, UK;Department of Informatics at University of Bergen, Bergen, Norway;Dep. of Computer Science at City University London, UK;Dep. of Computer Science at City University London, UK",10.1109/tvcg.2013.173;10.1109/tvcg.2011.178;10.1109/tvcg.2013.226;10.1109/tvcg.2011.197;10.1109/tvcg.2007.70558;10.1109/tvcg.2008.149;10.1109/infvis.2004.12;10.1109/tvcg.2012.256;10.1109/tvcg.2007.70574;10.1109/vast.2008.4677350;10.1109/tvcg.2008.125;10.1109/tvcg.2013.122;10.1109/tvcg.2013.173,"Visual analytics, multi-variate data, geographic information, geovisualization, interactive data analysis",65.0,39.0,54.0,1343.0,,,visual analysis geographically;statistical measures account;referenced datasets large;concurrently develop attribute;different,0.7344;0.2434;0.2329;0.1353;0.0790,"[np.int64(-1), -1, -1, -1, -1]",154;-1;-1;-1;-1,154,154
SciVis,2020,Polyphorm: Structural Analysis of Cosmological Datasets via Interactive Physarum Polycephalum Visualization,10.1109/tvcg.2020.3030407,http://dx.doi.org/10.1109/TVCG.2020.3030407,806.0,816.0,J,"This paper introduces Polyphorm, an interactive visualization and model fitting tool that provides a novel approach for investigating cosmological datasets. Through a fast computational simulation method inspired by the behavior of Physarum polycephalum, an unicellular slime mold organism that efficiently forages for nutrients, astrophysicists are able to extrapolate from sparse datasets, such as galaxy maps archived in the Sloan Digital Sky Survey, and then use these extrapolations to inform analyses of a wide range of other data, such as spectroscopic observations captured by the Hubble Space Telescope. Researchers can interactively update the simulation by adjusting model parameters, and then investigate the resulting visual output to form hypotheses about the data. We describe details of Polyphorm's simulation model and its interaction and visualization modalities, and we evaluate Polyphorm through three scientific use cases that demonstrate the effectiveness of our approach.",Oskar Elek;Joseph N. Burchett;J. Xavier Prochaska;Angus G. Forbes,Oskar Elek;Joseph N. Burchett;J. Xavier Prochaska;Angus G. Forbes,"Dept. of Computational Media, University of California, Santa Cruz;Dept. of Astronomy and Astrophysics, University of California, Santa Cruz;Dept. of Astronomy and Astrophysics, University of California, Santa Cruz;Dept. of Computational Media, University of California, Santa Cruz",10.1109/tvcg.2019.2934259;10.1109/tvcg.2019.2934259,"Astrophysics visualization,agent-based modeling,intergalactic media,Physarum polycephalum,Cosmic Web",13.0,10.0,79.0,530.0,,,investigating cosmological datasets;polyphorm interactive visualization;mold organism efficiently;interactively update;cases,0.6864;0.4737;0.2242;0.0722;-0.0446,"[np.int64(-1), -1, -1, -1, -1]",2;-1;-1;-1;-1,2,2
VAST,2017,Clustering Trajectories by Relevant Parts for Air Traffic Analysis,10.1109/tvcg.2017.2744322,http://dx.doi.org/10.1109/TVCG.2017.2744322,34.0,44.0,J,"Clustering of trajectories of moving objects by similarity is an important technique in movement analysis. Existing distance functions assess the similarity between trajectories based on properties of the trajectory points or segments. The properties may include the spatial positions, times, and thematic attributes. There may be a need to focus the analysis on certain parts of trajectories, i.e., points and segments that have particular properties. According to the analysis focus, the analyst may need to cluster trajectories by similarity of their relevant parts only. Throughout the analysis process, the focus may change, and different parts of trajectories may become relevant. We propose an analytical workflow in which interactive filtering tools are used to attach relevance flags to elements of trajectories, clustering is done using a distance function that ignores irrelevant elements, and the resulting clusters are summarized for further analysis. We demonstrate how this workflow can be useful for different analysis tasks in three case studies with real data from the domain of air traffic. We propose a suite of generic techniques and visualization guidelines to support movement data analysis by means of relevance-aware trajectory clustering.",Gennady L. Andrienko;Natalia V. Andrienko;Georg Fuchs;Jose Manuel Cordero Garcia,Gennady Andrienko;Natalia Andrienko;Georg Fuchs;Jose Manuel Cordero Garcia,"Fraunhofer IAIS, City University, London;Fraunhofer IAIS, City University, London;Fraunhofer Institute IAIS;CRIDA (Reference Center for Research, Development and Innovation in ATM)",10.1109/vast.2009.5332584;10.1109/tvcg.2013.193;10.1109/tvcg.2011.233;10.1109/tvcg.2015.2468292;10.1109/vast.2008.4677350;10.1109/vast.2009.5332584,"Visual analytics,movement data analysis,trajectory clustering,air traffic",90.0,62.0,53.0,2561.0,,,trajectories clustering using;important technique movement;relevance flags;workflow interactive;air,0.7251;0.2497;0.1665;0.1544;0.1401,"[np.int64(-1), -1, -1, -1, -1]",279;-1;-1;-1;-1,279,279
Vis,1996,Volume Thinning for Automatic Isosurface Propagation,10.1109/visual.1996.568123,http://doi.ieeecomputersociety.org/10.1109/VISUAL.1996.568123,303.0,310.0,C,"An isosurface can be efficiently generated by visiting adjacent intersected cells in order, as if the isosurface were propagating itself. We previously proposed an extrema graph method (T. Itoh and K. Koyamada, 1995), which generates a graph connecting extremum points. The isosurface propagation starts from some of the intersected cells that are found both by visiting the cells through which arcs of the graph pass and by visiting the cells on the boundary of a volume. We propose an efficient method of searching for cells intersected by an isosurface. This method generates a volumetric skeleton. consisting of cells, like an extrema graph, by applying a thinning algorithm used in the image recognition area. Since it preserves the topological features of the volume and the connectivity of the extremum points, it necessarily intersects every isosurface. The method is more efficient than the extrema graph method, since it does not require that cells on the boundary be visited.",Takayuki Itoh;Yasushi Yamaguchi 0001;Koji Koyamada,T. Itoh;Y. Yamaguchi;K. Koyamada,"Tokyo Research Laboratory, IBM Japan;Graduate School of Arts and Sciences, The University of Tokyo;Tokyo Research Laboratory, IBM Japan",10.1109/visual.1991.175780,,73.0,22.0,0.0,28.0,,,cells order isosurface;recognition area preserves;generates graph connecting;volume;method searching,0.5701;0.4382;0.3050;0.2427;0.2146,"[np.int64(-1), -1, -1, -1, -1]",311;-1;-1;-1;-1,311,311
Vis,2008,Sinus Endoscopy - Application of Advanced GPU Volume Rendering for Virtual Endoscopy,10.1109/tvcg.2008.161,http://dx.doi.org/10.1109/TVCG.2008.161,1491.0,1498.0,J,"For difficult cases in endoscopic sinus surgery, a careful planning of the intervention is necessary. Due to the reduced field of view during the intervention, the surgeons have less information about the surrounding structures in the working area compared to open surgery. Virtual endoscopy enables the visualization of the operating field and additional information, such as risk structures (e.g., optical nerve and skull base) and target structures to be removed (e.g., mucosal swelling). The Sinus Endoscopy system provides the functional range of a virtual endoscopic system with special focus on a realistic representation. Furthermore, by using direct volume rendering, we avoid time-consuming segmentation steps for the use of individual patient datasets. However, the image quality of the endoscopic view can be adjusted in a way that a standard computer with a modern standard graphics card achieves interactive frame rates with low CPU utilization. Thereby, characteristics of the endoscopic view are systematically used for the optimization of the volume rendering speed. The system design was based on a careful analysis of the endoscopic sinus surgery and the resulting needs for computer support. As a small standalone application it can be instantly used for surgical planning and patient education. First results of a clinical evaluation with ENT surgeons were employed to fine-tune the user interface, in particular to reduce the number of controls by using appropriate default values wherever possible. The system was used for preoperative planning in 102 cases, provides useful information for intervention planning (e.g., anatomic variations of the Rec. Frontalis), and closely resembles the intraoperative situation.",Arno Krüger;Christoph Kubisch;Gero Strauß;Bernhard Preim,Arno Krueger;Christoph Kubisch;Bernhard Preim;Gero Strauss,"Department of Simulation and Graphics, Otto-von-Guericke-University of Magdeburg, Germany;Department of Simulation and Graphics, Otto-von-Guericke-University of Magdeburg, Germany;ENT Department, University Hospital of Leipzig;Department of Simulation and Graphics, Otto-von-Guericke-University of Magdeburg, Germany",10.1109/visual.2003.1250370;10.1109/visual.2003.1250384;10.1109/visual.2004.98;10.1109/visual.2003.1250370,"medical visualization, sinus surgery, operation planning, virtual endoscopy, volume rendering",57.0,35.0,22.0,593.0,,,surgery virtual endoscopy;swelling sinus;provides useful information;frame rates;using appropriate default,0.6810;0.3314;0.1187;0.0552;0.0181,"[np.int64(-1), -1, -1, -1, -1]",4;-1;-1;-1;-1,4,4
InfoVis,2006,Measuring Data Abstraction Quality in Multiresolution Visualizations,10.1109/tvcg.2006.161,http://dx.doi.org/10.1109/TVCG.2006.161,709.0,716.0,J,"Data abstraction techniques are widely used in multiresolution visualization systems to reduce visual clutter and facilitate analysis from overview to detail. However, analysts are usually unaware of how well the abstracted data represent the original dataset, which can impact the reliability of results gleaned from the abstractions. In this paper, we define two data abstraction quality measures for computing the degree to which the abstraction conveys the original dataset: the histogram difference measure and the nearest neighbor measure. They have been integrated within XmdvTool, a public-domain multiresolution visualization system for multivariate data analysis that supports sampling as well as clustering to simplify data. Several interactive operations are provided, including adjusting the data abstraction level, changing selected regions, and setting the acceptable data abstraction quality level. Conducting these operations, analysts can select an optimal data abstraction level. Also, analysts can compare different abstraction methods using the measures to see how well relative data density and outliers are maintained, and then select an abstraction method that meets the requirement of their analytic tasks",Qingguang Cui;Matthew O. Ward;Elke A. Rundensteiner;Jing Yang 0001,Qingguang Cui;Matthew Ward;Elke Rundensteiner;Jing Yang,"Worcester Polytechnic Institute, Worcester, MA, USA;Worcester Polytechnic Institute, Worcester, MA, USA;Worcester Polytechnic Institute, Worcester, MA, USA;University of North Carolina, Charlotte, Charlotte, NC, USA",10.1109/infvis.2004.19;10.1109/visual.2005.1532819;10.1109/infvis.2004.15;10.1109/visual.1995.485139;10.1109/infvis.2000.885088;10.1109/infvis.2004.19,"Metrics, Clustering, Sampling, Multiresolution Visualization",128.0,68.0,28.0,977.0,,,visualization multivariate data;nearest neighbor;unaware abstracted;impact reliability results;regions setting acceptable,0.5716;0.1777;0.1415;0.1315;0.1158,"[np.int64(-1), -1, -1, -1, -1]",184;-1;-1;-1;-1,184,184
Vis,1999,Spiraling Edge: fast surface reconstruction from partially organized sample points,10.1109/visual.1999.809903,http://dx.doi.org/10.1109/VISUAL.1999.809903,317.0,538.0,C,"Many applications produce three-dimensional points that must be further processed to generate a surface. Surface reconstruction algorithms that start with a set of unorganized points are extremely time-consuming. Sometimes however, points are generated such that there is additional information available to the reconstruction algorithm. We present Spiraling Edge, a specialized algorithm for surface reconstruction that is three orders of magnitude faster than algorithms for the general case. In addition to sample point locations, our algorithm starts with normal information and knowledge of each point's neighbors. Our algorithm produces a localized approximation to the surface by creating a star-shaped triangulation between a point and a subset of its nearest neighbors. This surface patch is extended by locally triangulating each of the points along the edge of the patch. As each edge point is triangulated, it is removed from the edge and new edge points along the patch's edge are inserted in its place. The updated edge spirals out over the surface until the edge encounters a surface boundary and stops growing in that direction, or until the edge reduces to a small hole that is filled by the final triangle.",Patricia Crossno;Edward Angel,P. Crossno;E. Angel,"Sandia National Laboratories, USA;University of New Mexico, USA",10.1109/visual.1997.663930;10.1109/visual.1998.745286;10.1109/visual.1997.663930,"Surface reconstruction, advancing front, triangulation",37.0,8.0,6.0,87.0,,,algorithm surface reconstruction;spirals;information knowledge point;patch extended locally;extremely time,0.6886;0.2777;0.1489;0.1463;-0.0510,"[np.int64(-1), -1, -1, -1, -1]",104;-1;-1;-1;-1,104,104
Vis,2021,Revisiting Dimensionality Reduction Techniques for Visual Cluster Analysis: An Empirical Study,10.1109/tvcg.2021.3114694,http://dx.doi.org/10.1109/TVCG.2021.3114694,529.0,539.0,J,"Dimensionality Reduction (DR) techniques can generate 2D projections and enable visual exploration of cluster structures of high-dimensional datasets. However, different DR techniques would yield various patterns, which significantly affect the performance of visual cluster analysis tasks. We present the results of a user study that investigates the influence of different DR techniques on visual cluster analysis. Our study focuses on the most concerned property types, namely the linearity and locality, and evaluates twelve representative DR techniques that cover the concerned properties. Four controlled experiments were conducted to evaluate how the DR techniques facilitate the tasks of 1) cluster identification, 2) membership identification, 3) distance comparison, and 4) density comparison, respectively. We also evaluated users' subjective preference of the DR techniques regarding the quality of projected clusters. The results show that: 1) Non-linear and Local techniques are preferred in cluster identification and membership identification; 2) Linear techniques perform better than non-linear techniques in density comparison; 3) UMAP (Uniform Manifold Approximation and Projection) and t-SNE (t-Distributed Stochastic Neighbor Embedding) perform the best in cluster identification and membership identification; 4) NMF (Nonnegative Matrix Factorization) has competitive performance in distance comparison; 5) t-SNLE (t-Distributed Stochastic Neighbor Linear Embedding) has competitive performance in density comparison.",Jiazhi Xia;Yuchen Zhang;Jie Song;Yang Chen;Yunhai Wang;Shixia Liu,Jiazhi Xia;Yuchen Zhang;Jie Song;Yang Chen;Yunhai Wang;Shixia Liu,"School of Computer Science and Engineering, Central South University, China;School of Computer Science and Engineering, Central South University, China;School of Computer Science and Engineering, Central South University, China;I4 data, United States;School of Computer Science and Technology, Shandong University, China;School of Software, Tsinghua University, China",10.1109/tvcg.2015.2467552;10.1109/tvcg.2011.220;10.1109/infvis.2003.1249017;10.1109/tvcg.2016.2598831;10.1109/tvcg.2017.2745258;10.1109/vast47406.2019.8986943;10.1109/tvcg.2020.3030432;10.1109/tvcg.2019.2934660;10.1109/tvcg.2018.2865020;10.1109/tvcg.2015.2467552,"Dimensionality reduction,visual cluster analysis,perception-based evaluation",17.0,39.0,61.0,1783.0,,,visual cluster analysis;linearity locality evaluates;significantly affect performance;identification nmf nonnegative;property types,0.7279;0.2847;0.0893;0.0846;0.0654,"[np.int64(-1), -1, -1, -1, -1]",167;-1;-1;-1;-1,167,167
InfoVis,2008,HiPP: A Novel Hierarchical Point Placement Strategy and its Application to the Exploration of Document Collections,10.1109/tvcg.2008.138,http://dx.doi.org/10.1109/TVCG.2008.138,1229.0,1236.0,J,"Point placement strategies aim at mapping data points represented in higher dimensions to bi-dimensional spaces and are frequently used to visualize relationships amongst data instances. They have been valuable tools for analysis and exploration of data sets of various kinds. Many conventional techniques, however, do not behave well when the number of dimensions is high, such as in the case of documents collections. Later approaches handle that shortcoming, but may cause too much clutter to allow flexible exploration to take place. In this work we present a novel hierarchical point placement technique that is capable of dealing with these problems. While good grouping and separation of data with high similarity is maintained without increasing computation cost, its hierarchical structure lends itself both to exploration in various levels of detail and to handling data in subsets, improving analysis capability and also allowing manipulation of larger data sets.",Fernando Vieira Paulovich;Rosane Minghim,Fernando V. Paulovich;Rosane Minghim,"ICMC, Instituto de Ciências Matemáticas e de Computaçãao, University of São Paulo, Sao Paulo, Brazil;ICMC, Instituto de Ciências Matemáticas e de Computaçãao, University of São Paulo, Sao Paulo, Brazil",10.1109/visual.1999.809866;10.1109/visual.1991.175815;10.1109/vast.2007.4389002;10.1109/visual.1996.567787,"Text and document visualization, hierarchical multidimensional visualization, visual knowledge discovery, high-dimensional data",118.0,62.0,24.0,836.0,,,hierarchical point placement;documents collections;bi dimensional spaces;data;increasing computation cost,0.6046;0.4158;0.3215;0.2702;0.1649,"[np.int64(-1), -1, -1, -1, -1]",53;-1;-1;-1;-1,53,53
Vis,2011,Vortex Visualization in Ultra Low Reynolds Number Insect Flight,10.1109/tvcg.2011.260,http://dx.doi.org/10.1109/TVCG.2011.260,2071.0,2079.0,J,"We present the visual analysis of a biologically inspired CFD simulation of the deformable flapping wings of a dragonfly as it takes off and begins to maneuver, using vortex detection and integration-based flow lines. The additional seed placement and perceptual challenges introduced by having multiple dynamically deforming objects in the highly unsteady 3D flow domain are addressed. A brief overview of the high speed photogrammetry setup used to capture the dragonfly takeoff, parametric surfaces used for wing reconstruction, CFD solver and underlying flapping flight theory is presented to clarify the importance of several unsteady flight mechanisms, such as the leading edge vortex, that are captured visually. A novel interactive seed placement method is used to simplify the generation of seed curves that stay in the vicinity of relevant flow phenomena as they move with the flapping wings. This method allows a user to define and evaluate the quality of a seed's trajectory over time while working with a single time step. The seed curves are then used to place particles, streamlines and generalized streak lines. The novel concept of flowing seeds is also introduced in order to add visual context about the instantaneous vector fields surrounding smoothly animate streak lines. Tests show this method to be particularly effective at visually capturing vortices that move quickly or that exist for a very brief period of time. In addition, an automatic camera animation method is used to address occlusion issues caused when animating the immersed wing boundaries alongside many geometric flow lines. Each visualization method is presented at multiple time steps during the up-stroke and down-stroke to highlight the formation, attachment and shedding of the leading edge vortices in pairs of wings. Also, the visualizations show evidence of wake capture at stroke reversal which suggests the existence of previously unknown unsteady lift generation mechanisms that are unique to quad wing insects.",Christopher Koehler;Thomas Wischgoll;Haibo Dong;Zachary Gaston,Christopher Koehler;Thomas Wischgoll;Haibo Dong;Zachary Gaston,"College of Engineering and Computer Science, Wright State University, USA;College of Engineering and Computer Science, Wright State University, USA;College of Mechanical and Materials Engineering, Wright State University, USA;College of Mechanical and Materials Engineering, Wright State University, USA",10.1109/visual.2002.1183789;10.1109/visual.2005.1532830;10.1109/tvcg.2007.70557;10.1109/visual.2005.1532831;10.1109/tvcg.2008.163;10.1109/tvcg.2010.169;10.1109/visual.2005.1532848;10.1109/visual.2005.1532850;10.1109/tvcg.2010.212;10.1109/visual.2000.885690;10.1109/tvcg.2010.198;10.1109/visual.2004.113;10.1109/visual.1998.745296;10.1109/tvcg.2007.70595;10.1109/tvcg.2009.190;10.1109/tvcg.2008.133;10.1109/tvcg.2006.199;10.1109/visual.2002.1183821;10.1109/tvcg.2007.70545;10.1109/tvcg.2010.166;10.1109/tvcg.2006.201;10.1109/visual.2002.1183789,"Flow visualization, flowing seed points, streak lines, streamlines, insect flight, vortex visualization, unsteady flow",42.0,31.0,47.0,1318.0,,,wings visualizations;reconstruction cfd solver;caused animating immersed;detection integration based;simplify generation seed,0.6005;0.3056;0.1888;0.1145;0.0880,"[np.int64(-1), -1, -1, -1, -1]",153;-1;-1;-1;-1,153,153
Vis,2021,MultiVision: Designing Analytical Dashboards with Deep Learning Based Recommendation,10.1109/tvcg.2021.3114826,http://dx.doi.org/10.1109/TVCG.2021.3114826,162.0,172.0,J,"We contribute a deep-learning-based method that assists in designing analytical dashboards for analyzing a data table. Given a data table, data workers usually need to experience a tedious and time-consuming process to select meaningful combinations of data columns for creating charts. This process is further complicated by the needs of creating dashboards composed of multiple views that unveil different perspectives of data. Existing automated approaches for recommending multiple-view visualizations mainly build on manually crafted design rules, producing sub-optimal or irrelevant suggestions. To address this gap, we present a deep learning approach for selecting data columns and recommending multiple charts. More importantly, we integrate the deep learning models into a mixed-initiative system. Our model could make recommendations given optional user-input selections of data columns. The model, in turn, learns from provenance data of authoring logs in an offline manner. We compare our deep learning model with existing methods for visualization recommendation and conduct a user study to evaluate the usefulness of the system.",Aoyu Wu;Yun Wang 0012;Mengyu Zhou;Xinyi He;Haidong Zhang;Huamin Qu;Dongmei Zhang 0001,Aoyu Wu;Yun Wang;Mengyu Zhou;Xinyi He;Haidong Zhang;Huamin Qu;Dongmei Zhang,"Hong Kong University of Science and Technology, Hong Kong and Microsoft Research Area, United States;Microsoft Research Area, United States;Microsoft Research Area, United States;Microsoft Research Area, United States;Microsoft Research Area, United States;Hong Kong University of Science and Technology, Hong Kong;Microsoft Research Area, United States",10.1109/tvcg.2020.3030338;10.1109/tvcg.2019.2934810;10.1109/tvcg.2019.2934332;10.1109/tvcg.2018.2865138;10.1109/tvcg.2013.119;10.1109/tvcg.2016.2598620;10.1109/tvcg.2017.2744019;10.1109/tvcg.2018.2865235;10.1109/tvcg.2007.70594;10.1109/tvcg.2020.3030430;10.1109/tvcg.2018.2865240;10.1109/tvcg.2020.3030387;10.1109/tvcg.2017.2744198;10.1109/tvcg.2014.2346291;10.1109/tvcg.2018.2865158;10.1109/tvcg.2018.2864903;10.1109/tvcg.2016.2599030;10.1109/tvcg.2020.3030403;10.1109/tvcg.2020.3030396;10.1109/tvcg.2018.2865145;10.1109/tvcg.2017.2744843;10.1109/tvcg.2019.2934798;10.1109/tvcg.2019.2934398;10.1109/tvcg.2015.2467191;10.1109/tvcg.2020.3030423,"Visualization Recommendation,Deep Learning,Multiple-View,Dashboard,Mixed-Initiative,Visualization Provenance",14.0,31.0,73.0,1788.0,,,dashboards analyzing data;present deep learning;select meaningful combinations;manually crafted;irrelevant,0.5685;0.3128;0.2108;0.1375;0.0307,"[np.int64(-1), -1, -1, -1, -1]",197;-1;-1;-1;-1,197,197
Vis,2001,Chromatin decondensation: case study of tracking features in confocal data,10.1109/visual.2001.964546,http://dx.doi.org/10.1109/VISUAL.2001.964546,441.0,444.0,C,"In this case study we discuss an interactive feature tracking system and its use for the analysis of chromatin decondensation. Features are described as points in a multidimensional attribute space. Distances between points are used as a measure for feature correspondence. Users can interactively experiment with the correspondence measure in order to gain insight in chromatin movement. In addition, by defining time as an attribute, tracking problems related to noisy confocal data can be circumvented.",Wim C. de Leeuw;Robert van Liere,W. de Leeuw;R. van Liere,"Center of Mathematics and Computer Science, Amsterdam, Netherlands;Center of Mathematics and Computer Science, Amsterdam, Netherlands",10.1109/visual.2000.885735,"feature tracking, multidimensional visualization, biomedical imaging",13.0,3.0,8.0,63.0,,,insight chromatin movement;measure feature correspondence;users interactively;noisy confocal;addition defining time,0.6764;0.3660;0.2113;0.1903;0.0508,"[np.int64(-1), -1, -1, -1, -1]",19;-1;-1;-1;-1,19,19
InfoVis,2017,Skeleton-Based Scagnostics,10.1109/tvcg.2017.2744339,http://dx.doi.org/10.1109/TVCG.2017.2744339,542.0,552.0,J,"Scatterplot matrices (SPLOMs) are widely used for exploring multidimensional data. Scatterplot diagnostics (scagnostics) approaches measure characteristics of scatterplots to automatically find potentially interesting plots, thereby making SPLOMs more scalable with the dimension count. While statistical measures such as regression lines can capture orientation, and graph-theoretic scagnostics measures can capture shape, there is no scatterplot characterization measure that uses both descriptors. Based on well-known results in shape analysis, we propose a scagnostics approach that captures both scatterplot shape and orientation using skeletons (or medial axes). Our representation can handle complex spatial distributions, helps discovery of principal trends in a multiscale way, scales visually well with the number of samples, is robust to noise, and is automatic and fast to compute. We define skeleton-based similarity metrics for the visual exploration and analysis of SPLOMs. We perform a user study to measure the human perception of scatterplot similarity and compare the outcome to our results as well as to graph-based scagnostics and other visual quality metrics. Our skeleton-based metrics outperform previously defined measures both in terms of closeness to perceptually-based similarity and computation time efficiency.",José Matute;Alexandru C. Telea;Lars Linsen,José Matute;Alexandru C. Telea;Lars Linsen,"Institute of Computer Science, University of Münster, Germany;Johann Bernoulli Institute for Mathematics and Computer Science, University of Groningen, Groningen, The Netherlands;Institute of Computer Science, University of Münster, Germany",10.1109/vast.2011.6102437;10.1109/tvcg.2011.233;10.1109/tvcg.2010.213;10.1109/tvcg.2011.223;10.1109/tvcg.2011.220;10.1109/vast.2008.4677367;10.1109/vast.2009.5332628;10.1109/vast.2011.6102437,"Multidimensional Data (primary keyword),High-Dimensional Data",30.0,22.0,65.0,729.0,,,perception scatterplot similarity;define skeleton;sploms widely used;representation handle complex;perform,0.6837;0.2581;0.2043;0.1282;0.0343,"[np.int64(-1), -1, -1, -1, -1]",94;-1;-1;-1;-1,94,94
Vis,1997,Two-phase perspective ray casting for interactive volume navigation,10.1109/visual.1997.663878,http://dx.doi.org/10.1109/VISUAL.1997.663878,183.0,189.0,C,"Volume navigation is the interactive exploration of volume data sets by ""flying"" the view point through the data, producing a volume rendered view at each frame. The authors present an inexpensive perspective volume navigation method designed to run on a PC platform with accelerated 3D graphics hardware. They compute perspective projections at each frame, allow trilinear interpolation of sample points, and render both gray scale and RGB volumes by volumetric compositing. The implementation handles arbitrarily large volumes, by dynamically swapping data within the local depth-limited frustum into main memory as the viewpoint moves through the volume. They describe a new ray casting algorithm that takes advantage of the coherence inherent in adjacent frames to generate a sequence of approximate animated frames much faster than they could be computed individually. They also take advantage of the 3D graphics acceleration hardware to offload much of the alpha blending and resampling from the CPU.",Martin L. Brady;Kenneth K. Jung;H. T. Nguyen;Thinh P. Q. Nguyen,M. Brady;K. Jung;H.T. Nguyen;T. Nguyen,"Microcomputer Research Laboratories, Intel Corporation, USA;Microcomputer Research Laboratories, Intel Corporation, USA;;Microcomputer Research Laboratories, Intel Corporation, USA",10.1109/visual.1994.346340;10.1109/visual.1995.485154;10.1109/visual.1996.567603;10.1109/visual.1994.346340,"Volume navigation, volume rendering, 3D medical imaging, scientific visualization, texture mapping",67.0,9.0,18.0,130.0,,,volumetric compositing implementation;animated frames;faster;limited frustum main;data local,0.6213;0.3354;0.1005;0.0993;0.0544,"[np.int64(-1), -1, -1, -1, -1]",256;-1;-1;-1;-1,256,256
Vis,2005,Particle and texture based spatiotemporal visualization of time-dependent vector fields,10.1109/visual.2005.1532852,http://dx.doi.org/10.1109/VISUAL.2005.1532852,639.0,646.0,C,"We propose a hybrid particle and texture based approach for the visualization of time-dependent vector fields. The underlying space-time framework builds a dense vector field representation in a two-step process: 1) particle-based forward integration of trajectories in spacetime for temporal coherence, and 2) texture-based convolution along another set of paths through the spacetime for spatially correlated patterns. Particle density is controlled by stochastically injecting and removing particles, taking into account the divergence of the vector field. Alternatively, a uniform density can be maintained by placing exactly one particle in each cell of a uniform grid, which leads to particle-in-cell forward advection. Moreover, we discuss strategies of previous visualization methods for unsteady flow and show how they address issues of spatiotemporal coherence and dense visual representations. We demonstrate how our framework is capable of realizing several of these strategies. Finally, we present an efficient GPU implementation that facilitates an interactive visualization of unsteady 2D flow on Shader Model 3 compliant graphics hardware.",Daniel Weiskopf;Frederik Schramm;Gordon Erlebacher;Thomas Ertl,D. Weiskopf;F. Schramm;G. Erlebacher;T. Ertl,"Institute of Visualization and Interactive Systems, University of Stuttgart, Germany and Graphics, Usability and Visualization (GrUVi) Laboratory, Simon Fraser University, Canada;Institute of Visualization and Interactive Systems, University of Stuttgart, Germany;School of Computational Science and Information Technology, Florida State University, USA;Institute of Visualization and Interactive Systems, University of Stuttgart, Germany",10.1109/visual.2003.1250377;10.1109/visual.2003.1250363;10.1109/visual.2003.1250361;10.1109/visual.2000.885689;10.1109/visual.2003.1250402;10.1109/visual.2003.1250364;10.1109/visual.2003.1250377,"Unsteady flow visualization, visualization framework, LIC, texture advection, particle systems, GPU methods",36.0,7.0,31.0,259.0,,,particle texture based;visualization unsteady;spacetime temporal coherence;gpu implementation facilitates;account divergence,0.5397;0.3726;0.3573;0.3134;0.1209,"[np.int64(-1), -1, -1, -1, -1]",-1;-1;-1;-1;-1,,-1
Vis,2023,Let the Chart Spark: Embedding Semantic Context into Chart with Text-to-Image Generative Model,10.1109/tvcg.2023.3326913,http://dx.doi.org/10.1109/TVCG.2023.3326913,284.0,294.0,J,"Pictorial visualization seamlessly integrates data and semantic context into visual representation, conveying complex information in an engaging and informative manner. Extensive studies have been devoted to developing authoring tools to simplify the creation of pictorial visualizations. However, mainstream works follow a retrieving-and-editing pipeline that heavily relies on retrieved visual elements from a dedicated corpus, which often compromise data integrity. Text-guided generation methods are emerging, but may have limited applicability due to their predefined entities. In this work, we propose ChartSpark, a novel system that embeds semantic context into chart based on text-to-image generative models. ChartSpark generates pictorial visualizations conditioned on both semantic context conveyed in textual inputs and data information embedded in plain charts. The method is generic for both foreground and background pictorial generation, satisfying the design practices identified from empirical research into existing pictorial visualizations. We further develop an interactive visual interface that integrates a text analyzer, editing module, and evaluation module to enable users to generate, modify, and assess pictorial visualizations. We experimentally demonstrate the usability of our tool, and conclude with a discussion of the potential of using text-to-image generative models combined with an interactive interface for visualization design.",Shishi Xiao;Suizi Huang;Yue Lin;Yilin Ye;Wei Zeng 0004,Shishi Xiao;Suizi Huang;Yue Lin;Yilin Ye;Wei Zeng,"Hong Kong University of Science and Technology (Guangzhou), Guangzhou, China;Hong Kong University of Science and Technology (Guangzhou), Guangzhou, China;Hong Kong University of Science and Technology (Guangzhou), Guangzhou, China;Hong Kong University of Science and Technology (Guangzhou), Guangzhou, China;Hong Kong University of Science and Technology (Guangzhou), Guangzhou, China",0.1109/tvcg.2012.197;10.1109/tvcg.2015.2467732;10.1109/tvcg.2013.234;10.1109/tvcg.2019.2934810;10.1109/tvcg.2019.2934785;10.1109/tvcg.2011.175;10.1109/tvcg.2016.2598620;10.1109/tvcg.2012.221;10.1109/tvcg.2020.3030448;10.1109/tvcg.2022.3209486;10.1109/tvcg.2022.3209357;10.1109/tvcg.2019.2934398;10.1109/tvcg.2022.3209447,"pictorial visualization,generative model,authoring tool",,5.0,61.0,1226.0,,,generates pictorial visualizations;data semantic context;editing module evaluation;dedicated corpus compromise;simplify,0.6739;0.3490;0.1645;0.1555;0.0430,"[np.int64(-1), -1, -1, -1, -1]",155;-1;-1;-1;-1,155,155
VAST,2011,How locus of control influences compatibility with visualization style,10.1109/vast.2011.6102445,http://dx.doi.org/10.1109/VAST.2011.6102445,81.0,90.0,C,"Existing research suggests that individual personality differences are correlated with a user's speed and accuracy in solving problems with different types of complex visualization systems. In this paper, we extend this research by isolating factors in personality traits as well as in the visualizations that could have contributed to the observed correlation. We focus on a personality trait known as “locus of control,” which represents a person's tendency to see themselves as controlled by or in control of external events. To isolate variables of the visualization design, we control extraneous factors such as color, interaction, and labeling, and specifically focus on the overall layout style of the visualizations. We conduct a user study with four visualizations that gradually shift from an indentation metaphor to a containment metaphor and compare the participants' speed, accuracy, and preference with their locus of control. Our findings demonstrate that there is indeed a correlation between the two: participants with an internal locus of control perform more poorly with visualizations that employ a containment metaphor, while those with an external locus of control perform well with such visualizations. We discuss a possible explanation for this relationship based in cognitive psychology and propose that these results can be used to better understand how people use visualizations and how to adapt visual analytics design to an individual user's needs.",Caroline Ziemkiewicz;R. Jordan Crouser;Ashley Rye Yauilla;Sara L. Su;William Ribarsky;Remco Chang,Caroline Ziemkiewicz;R. Jordan Crouser;Ashley Rye Yauilla;Sara L. Su;William Ribarsky;Remco Chang,"Brown University, USA;Tufts University, USA;Winthrop University, USA;Tufts University, USA;UNC-Charlotte, USA;Tufts University, USA",10.1109/vast.2010.5653587;10.1109/tvcg.2008.171;10.1109/tvcg.2008.121;10.1109/vast.2010.5653587,,70.0,40.0,31.0,509.0,HM,,user study visualizations;personality trait;indentation metaphor;speed accuracy solving;control extraneous,0.6874;0.2593;0.2516;0.1096;0.0234,"[np.int64(-1), -1, -1, -1, -1]",270;-1;-1;-1;-1,270,270
Vis,1999,Visual debugging of visualization software: a case study for particle systems,10.1109/visual.1999.809919,http://dx.doi.org/10.1109/VISUAL.1999.809919,417.0,554.0,C,"Visualization systems are complex dynamic software systems. Debugging such systems is difficult using conventional debuggers because the programmer must try to imagine the three-dimensional geometry based on a list of positions and attributes. In addition, the programmer must be able to mentally animate changes in those positions and attributes to grasp dynamic behaviors within the algorithm. We show that representing geometry, attributes, and relationships graphically permits visual pattern recognition skills to be applied to the debugging problem. The particular application is a particle system used for isosurface extraction from volumetric data. Coloring particles based on individual attributes is especially helpful when these colorings are viewed as animations over successive iterations in the program. Although we describe a particular application, the types of tools that we discuss can be applied to a variety of problems.",Patricia Crossno;Edward Angel,P. Crossno;E. Angel,"Sandia National Laboratories, USA;University of New Mexico, USA",10.1109/visual.1996.568120;10.1109/visual.1997.663930;10.1109/visual.1996.568120,,17.0,7.0,17.0,111.0,,,visualization systems;using conventional debuggers;particle used isosurface;animate changes positions;able,0.5637;0.3595;0.2617;0.1512;-0.0170,"[np.int64(-1), -1, -1, -1, -1]",276;-1;-1;-1;-1,276,276
Vis,2023,ExTreeM: Scalable Augmented Merge Tree Computation via Extremum Graphs,10.1109/tvcg.2023.3326526,http://dx.doi.org/10.1109/TVCG.2023.3326526,1085.0,1094.0,J,"Over the last decade merge trees have been proven to support a plethora of visualization and analysis tasks since they effectively abstract complex datasets. This paper describes the ExTreeM-Algorithm: A scalable algorithm for the computation of merge trees via extremum graphs. The core idea of ExTreeM is to first derive the extremum graph $\mathcal{G}$ of an input scalar field $f$ defined on a cell complex $\mathcal{K}$, and subsequently compute the unaugmented merge tree of $f$ on $\mathcal{G}$ instead of $\mathcal{K}$; which are equivalent. Any merge tree algorithm can be carried out significantly faster on $\mathcal{G}$, since $\mathcal{K}$ in general contains substantially more cells than $\mathcal{G}$. To further speed up computation, ExTreeM includes a tailored procedure to derive merge trees of extremum graphs. The computation of the fully augmented merge tree, i.e., a merge tree domain segmentation of $\mathcal{K}$, can then be performed in an optional post-processing step. All steps of ExTreeM consist of procedures with high parallel efficiency, and we provide a formal proof of its correctness. Our experiments, performed on publicly available datasets, report a speedup of up to one order of magnitude over the state-of-the-art algorithms included in the TTK and VTK-m software libraries, while also requiring significantly less memory and exhibiting excellent scaling behavior.",Jonas Lukasczyk;Michael Will;Florian Wetzels;Gunther H. Weber;Christoph Garth,Jonas Lukasczyk;Michael Will;Florian Wetzels;Gunther H. Weber;Christoph Garth,"RPTU Kaiserslautern-Landau, Germany;RPTU Kaiserslautern-Landau, Germany;RPTU Kaiserslautern-Landau, Germany;Lawrence Berkeley National Lab., USA;RPTU Kaiserslautern-Landau, Germany",0.1109/tvcg.2019.2934257;10.1109/tvcg.2017.2743938,"Scalar field topology,merge trees,persistence pairs,high performance computing",,0.0,41.0,334.0,,,computation merge trees;domain segmentation;extremum graph;contains substantially cells;scalar field,0.6246;0.3878;0.3239;0.1739;0.1321,"[np.int64(-1), -1, -1, -1, -1]",12;-1;-1;-1;-1,12,12
InfoVis,2012,PivotPaths: Strolling through Faceted Information Spaces,10.1109/tvcg.2012.252,http://dx.doi.org/10.1109/TVCG.2012.252,2709.0,2718.0,J,"We present PivotPaths, an interactive visualization for exploring faceted information resources. During both work and leisure, we increasingly interact with information spaces that contain multiple facets and relations, such as authors, keywords, and citations of academic publications, or actors and genres of movies. To navigate these interlinked resources today, one typically selects items from facet lists resulting in abrupt changes from one subset of data to another. While filtering is useful to retrieve results matching specific criteria, it can be difficult to see how facets and items relate and to comprehend the effect of filter operations. In contrast, the PivotPaths interface exposes faceted relations as visual paths in arrangements that invite the viewer to `take a stroll' through an information space. PivotPaths supports pivot operations as lightweight interaction techniques that trigger gradual transitions between views. We designed the interface to allow for casual traversal of large collections in an aesthetically pleasing manner that encourages exploration and serendipitous discoveries. This paper shares the findings from our iterative design-and-evaluation process that included semi-structured interviews and a two-week deployment of PivotPaths applied to a large database of academic publications.",Marian Dörk;Nathalie Henry Riche;Gonzalo A. Ramos;Susan T. Dumais,Marian Dörk;Nathalie Henry Riche;Gonzalo Ramos;Susan Dumais,"University of Calgary, Canada;Microsoft, USA;Microsoft, USA;Microsoft, USA",10.1109/vast.2009.5333443;10.1109/tvcg.2010.154;10.1109/vast.2006.261426;10.1109/vast.2007.4389006;10.1109/vast.2008.4677370;10.1109/tvcg.2007.70539;10.1109/tvcg.2008.175;10.1109/tvcg.2009.108;10.1109/vast.2009.5333443,"Information visualization, interactivity, node-link diagrams, animation, information seeking, exploratory search",217.0,126.0,24.0,1637.0,,,exploring faceted information;lightweight interaction techniques;pivotpaths applied large;work leisure increasingly;invite,0.6254;0.2994;0.2773;0.1799;-0.1157,"[np.int64(-1), -1, -1, -1, -1]",243;-1;-1;-1;-1,243,243
Vis,2023,Average Estimates in Line Graphs Are Biased Toward Areas of Higher Variability,10.1109/tvcg.2023.3326589,http://dx.doi.org/10.1109/TVCG.2023.3326589,306.0,315.0,J,"We investigate variability overweighting, a previously undocumented bias in line graphs, where estimates of average value are biased toward areas of higher variability in that line. We found this effect across two preregistered experiments with 140 and 420 participants. These experiments also show that the bias is reduced when using a dot encoding of the same series. We can model the bias with the average of the data series and the average of the points drawn along the line. This bias might arise because higher variability leads to stronger weighting in the average calculation, either due to the longer line segments (even though those segments contain the same number of data values) or line segments with higher variability being otherwise more visually salient. Understanding and predicting this bias is important for visualization design guidelines, recommendation systems, and tool builders, as the bias can adversely affect estimates of averages and trends.",Dominik Moritz;Lace M. K. Padilla;Francis Nguyen;Steven L. Franconeri,Dominik Moritz;Lace M. Padilla;Francis Nguyen;Steven L. Franconeri,"Carnegie Mellon University, USA;Northeastern University, USA;Northwestern University, USA;UBC, Canada",0.1109/infvis.2005.1532136;10.1109/tvcg.2018.2865077;10.1109/tvcg.2009.131;10.1109/tvcg.2021.3114783;10.1109/tvcg.2010.162;10.1109/tvcg.2021.3114684;10.1109/tvcg.2019.2934784;10.1109/tvcg.2019.2934400;10.1109/tvcg.2021.3114865,"bias,lines graph,ensemble perception,average",,2.0,34.0,440.0,HM,,bias important visualization;series average;using dot encoding;systems tool builders;longer,0.5901;0.3591;0.0936;0.0786;0.0677,"[np.int64(-1), -1, -1, -1, -1]",160;-1;-1;-1;-1,160,160
Vis,2024,Motion-Based Visual Encoding Can Improve Performance on Perceptual Tasks with Dynamic Time Series,10.1109/tvcg.2024.3456405,http://dx.doi.org/10.1109/TVCG.2024.3456405,163.0,173.0,J,"Dynamic data visualizations can convey large amounts of information over time, such as using motion to depict changes in data values for multiple entities. Such dynamic displays put a demand on our visual processing capacities, yet our perception of motion is limited. Several techniques have been shown to improve the processing of dynamic displays. Staging the animation to sequentially show steps in a transition and tracing object movement by displaying trajectory histories can improve processing by reducing the cognitive load. In this paper, We examine the effectiveness of staging and tracing in dynamic displays. We showed participants animated line charts depicting the movements of lines and asked them to identify the line with the highest mean and variance. We manipulated the animation to display the lines with or without staging, tracing and history, and compared the results to a static chart as a control. Results showed that tracing and staging are preferred by participants, and improve their performance in mean and variance tasks respectively. They also preferred display time 3 times shorter when staging is used. Also, encoding animation speed with mean and variance in congruent tasks is associated with higher accuracy. These findings help inform real-world best practices for building dynamic displays. The supplementary materials can be found at https://osf.io/8c95v/",Songwen Hu;Ouxun Jiang;Jeffrey Riedmiller;Cindy Xiong Bearfield,Songwen Hu;Ouxun Jiang;Jeffrey Riedmiller;Cindy Xiong Bearfield,"Georgia Tech., USA;Northwestern University, USA;Dolby Laboratories, USA;Georgia Tech., USA",10.1109/infvis.1999.801854;10.1109/tvcg.2019.2934397;10.1109/tvcg.2019.2934288;10.1109/tvcg.2014.2346424;10.1109/vast.2012.6400552;10.1109/tvcg.2020.3029413;10.1109/tvcg.2007.70539;10.1109/tvcg.2018.2864909;10.1109/tvcg.2013.191;10.1109/tvcg.2018.2865193;10.1109/tvcg.2008.125;10.1109/tvcg.2018.2865147;10.1109/tvcg.2020.3030418;10.1109/infvis.2001.963279;10.1109/tvcg.2022.3209369,"Animation,Dynamic Displays,,,Perception,Motion,Analytic Tasks",,0.0,56.0,130.0,,,animated line charts;processing reducing cognitive;tracing staging preferred;highest mean variance;materials https,0.6243;0.3407;0.1860;0.0798;0.0170,"[np.int64(-1), -1, -1, -1, -1]",123;-1;-1;-1;-1,123,123
Vis,2024,Defogger: A Visual Analysis Approach for Data Exploration of Sensitive Data Protected by Differential Privacy,10.1109/tvcg.2024.3456304,http://dx.doi.org/10.1109/TVCG.2024.3456304,448.0,458.0,J,"Differential privacy ensures the security of individual privacy but poses challenges to data exploration processes because the limited privacy budget incapacitates the flexibility of exploration and the noisy feedback of data requests leads to confusing uncertainty. In this study, we take the lead in describing corresponding exploration scenarios, including underlying requirements and available exploration strategies. To facilitate practical applications, we propose a visual analysis approach to the formulation of exploration strategies. Our approach applies a reinforcement learning model to provide diverse suggestions for exploration strategies according to the exploration intent of users. A novel visual design for representing uncertainty in correlation patterns is integrated into our prototype system to support the proposed approach. Finally, we implemented a user study and two case studies. The results of these studies verified that our approach can help develop strategies that satisfy the exploration intent of users.",Xumeng Wang;Shuangcheng Jiao;Chris Bryan,Xumeng Wang;Shuangcheng Jiao;Chris Bryan,"DISSec, Nankai University, China;DISSec, Nankai University, China;SCAI, Arizona State University, USA",10.1109/tvcg.2018.2865040;10.1109/tvcg.2013.124;10.1109/tvcg.2015.2467199;10.1109/tvcg.2017.2743959;10.1109/tvcg.2018.2864889;10.1109/tvcg.2023.3327195;10.1109/tvcg.2018.2865027;10.1109/tvcg.2023.3326929;10.1109/tvcg.2009.114;10.1109/vast50239.2020.00006;10.1109/tvcg.2017.2745139;10.1109/tvcg.2015.2467191;10.1109/tvcg.2020.3030369;10.1109/tvcg.2022.3209391,"Differential privacy,Visual data analysis,,,Data exploration,Visualization for uncertainty illustration",,0.0,44.0,176.0,,,data exploration;privacy budget incapacitates;representing uncertainty correlation;intent users novel;available,0.6115;0.4134;0.2617;0.2232;-0.0658,"[np.int64(-1), -1, -1, -1, -1]",259;-1;-1;-1;-1,259,259
Vis,2024,SimpleSets: Capturing Categorical Point Patterns with Simple Shapes,10.1109/tvcg.2024.3456168,http://dx.doi.org/10.1109/TVCG.2024.3456168,262.0,271.0,J,"Points of interest on a map such as restaurants, hotels, or subway stations, give rise to categorical point data: data that have a fixed location and one or more categorical attributes. Consequently, recent years have seen various set visualization approaches that visually connect points of the same category to support users in understanding the spatial distribution of categories. Existing methods use complex and often highly irregular shapes to connect points of the same category, leading to high cognitive load for the user. In this paper we introduce SimpleSets, which uses simple shapes to enclose categorical point patterns, thereby providing a clean overview of the data distribution. SimpleSets is designed to visualize sets of points with a single categorical attribute; as a result, the point patterns enclosed by SimpleSets form a partition of the data. We give formal definitions of point patterns that correspond to simple shapes and describe an algorithm that partitions categorical points into few such patterns. Our second contribution is a rendering algorithm that transforms a given partition into a clean set of shapes resulting in an aesthetically pleasing set visualization. Our algorithm pays particular attention to resolving intersections between nearby shapes in a consistent manner. We compare SimpleSets to the state-of-the-art set visualizations using standard datasets from the literature.",Steven van den Broek;Wouter Meulemans;Bettina Speckmann,Steven van den Broek;Wouter Meulemans;Bettina Speckmann,"TU Eindhoven, the Netherlands;TU Eindhoven, the Netherlands;TU Eindhoven, the Netherlands",10.1109/tvcg.2011.186;10.1109/tvcg.2009.122;10.1109/infvis.2005.1532126;10.1109/tvcg.2010.210;10.1109/tvcg.2006.122;10.1109/tvcg.2021.3114761,"Set visualization,geographic visualization,,,algorithms",,0.0,32.0,156.0,,X,pleasing set visualization;map restaurants;category support users;irregular;definitions,0.6297;0.4239;0.1491;0.1442;0.0990,"[np.int64(-1), -1, -1, -1, -1]",176;-1;-1;-1;-1,176,176
Vis,2011,Visualization of AMR Data With Multi-Level Dual-Mesh Interpolation,10.1109/tvcg.2011.252,http://dx.doi.org/10.1109/TVCG.2011.252,1862.0,1871.0,J,"We present a new technique for providing interpolation within cell-centered Adaptive Mesh Refinement (AMR) data that achieves C&lt;sup&gt;0&lt;/sup&gt; continuity throughout the 3D domain. Our technique improves on earlier work in that it does not require that adjacent patches differ by at most one refinement level. Our approach takes the dual of each mesh patch and generates ""stitching cells"" on the fly to fill the gaps between dual meshes. We demonstrate applications of our technique with data from Enzo, an AMR cosmological structure formation simulation code. We show ray-cast visualizations that include contributions from particle data (dark matter and stars, also output by Enzo) and gridded hydrodynamic data. We also show results from isosurface studies, including surfaces in regions where adjacent patches differ by more than one refinement level.",Patrick J. Moran;David A. Ellsworth,Patrick Moran;David Ellsworth,"NASA Ames Research Center, USA;Computer Sciences Corporation, NASA Ames, USA",10.1109/visual.1991.175782;10.1109/tvcg.2009.149;10.1109/visual.2002.1183820;10.1109/visual.1991.175782,"Adaptive mesh refinement, AMR, Enzo, interpolation, ray casting, isosurfaces, dual meshes, stitching cells",17.0,14.0,22.0,576.0,,,adaptive mesh refinement;amr cosmological;cast visualizations include;gaps;cell centered,0.6673;0.3243;0.2032;0.1550;0.1151,"[np.int64(-1), -1, -1, -1, -1]",111;-1;-1;-1;-1,111,111
Vis,2024,Curio: A Dataflow-Based Framework for Collaborative Urban Visual Analytics,10.1109/tvcg.2024.3456353,http://dx.doi.org/10.1109/TVCG.2024.3456353,1224.0,1234.0,J,"Over the past decade, several urban visual analytics systems and tools have been proposed to tackle a host of challenges faced by cities, in areas as diverse as transportation, weather, and real estate. Many of these tools have been designed through collaborations with urban experts, aiming to distill intricate urban analysis workflows into interactive visualizations and interfaces. However, the design, implementation, and practical use of these tools still rely on siloed approaches, resulting in bespoke systems that are difficult to reproduce and extend. At the design level, these tools undervalue rich data workflows from urban experts, typically treating them only as data providers and evaluators. At the implementation level, they lack interoperability with other technical frameworks. At the practical use level, they tend to be narrowly focused on specific fields, inadvertently creating barriers to cross-domain collaboration. To address these gaps, we present Curio, a framework for collaborative urban visual analytics. Curio uses a dataflow model with multiple abstraction levels (code, grammar, GUI elements) to facilitate collaboration across the design and implementation of visual analytics components. The framework allows experts to intertwine data preprocessing, management, and visualization stages while tracking the provenance of code and visualizations. In collaboration with urban experts, we evaluate Curio through a diverse set of usage scenarios targeting urban accessibility, urban microclimate, and sunlight access. These scenarios use different types of data and domain methodologies to illustrate Curio's flexibility in tackling pressing societal challenges. Curio is available at urbantk.org/curio.",Gustavo Moreira;Maryam Hosseini;Carolina Veiga Ferreira de Souza;Lucas Alexandre;Nicola Colaninno;Daniel de Oliveira 0001;Nivan Ferreira;Marcos Lage;Fabio Miranda 0001,Gustavo Moreira;Maryam Hosseini;Carolina Veiga;Lucas Alexandre;Nicola Colaninno;Daniel de Oliveira;Nivan Ferreira;Marcos Lage;Fabio Miranda,"University of Illinois, USA;University of California, Berkeley, and the Massachusetts Institute of Technology, USA;University of Illinois Urbana-Champaign, USA;Universidade Federal Fluminense, Brazil;Politecnico di Milano, Italy;Universidade Federal Fluminense, Brazil;Universidade Federal de Pernambuco, Brazil;Universidade Federal Fluminense, Brazil;University of Illinois, USA",10.1109/tvcg.2018.2865040;10.1109/tvcg.2017.2743990;10.1109/visual.2005.1532788;10.1109/tvcg.2019.2934670;10.1109/vast.2015.7347636;10.1109/tvcg.2013.226;10.1109/tvcg.2021.3114876;10.1109/tvcg.2016.2598585;10.1109/tvcg.2023.3326598;10.1109/tvcg.2022.3209474;10.1109/tvcg.2016.2599030;10.1109/tvcg.2017.2743938;10.1109/tvcg.2022.3209360;10.1109/tvcg.2016.2598497,"Urban analytics,urban data,,,spatial data,dataflow,provenance,visualization framework,visualization system",,0.0,75.0,171.0,,,urban visual analytics;bespoke systems difficult;microclimate sunlight;curio flexibility tackling;specific fields inadvertently,0.7834;0.1591;0.1220;0.0119;-0.0103,"[np.int64(-1), -1, -1, -1, -1]",174;-1;-1;-1;-1,174,174
Vis,2022,MosaicSets: Embedding Set Systems into Grid Graphs,10.1109/tvcg.2022.3209485,http://dx.doi.org/10.1109/TVCG.2022.3209485,875.0,885.0,J,"Visualizing sets of elements and their relations is an important research area in information visualization. In this paper, we present MosaicSets: a novel approach to create Euler-like diagrams from non-spatial set systems such that each element occupies one cell of a regular hexagonal or square grid. The main challenge is to find an assignment of the elements to the grid cells such that each set constitutes a contiguous region. As use case, we consider the research groups of a university faculty as elements, and the departments and joint research projects as sets. We aim at finding a suitable mapping between the research groups and the grid cells such that the department structure forms a base map layout. Our objectives are to optimize both the compactness of the entirety of all cells and of each set by itself. We show that computing the mapping is NP-hard. However, using integer linear programming we can solve real-world instances optimally within a few seconds. Moreover, we propose a relaxation of the contiguity requirement to visualize otherwise non-embeddable set systems. We present and discuss different rendering styles for the set overlays. Based on a case study with real-world data, our evaluation comprises quantitative measures as well as expert interviews.",Peter Rottmann;Markus Wallinger;Annika Bonerath;Sven Gedicke;Martin Nöllenburg;Jan-Henrik Haunert,Peter Rottmann;Markus Wallinger;Annika Bonerath;Sven Gedicke;Martin Nöllenburg;Jan-Henrik Haunert,"Geoinformation Group of the University of Bonn, Germany;Algorithms and Complexity Group of the Technical University of Vienna, Austria;Geoinformation Group of the University of Bonn, Germany;Geoinformation Group of the University of Bonn, Germany;Algorithms and Complexity Group of the Technical University of Vienna, Austria;Geoinformation Group of the University of Bonn, Germany",10.1109/tvcg.2011.186;10.1109/tvcg.2009.122;10.1109/tvcg.2020.3030475;10.1109/tvcg.2021.3114834;10.1109/tvcg.2014.2346248;10.1109/tvcg.2016.2598542;10.1109/tvcg.2020.3028953;10.1109/tvcg.2012.199;10.1109/tvcg.2010.210;10.1109/tvcg.2014.2346249;10.1109/tvcg.2008.165;10.1109/tvcg.2011.186,"Set Visualization,Euler Diagram,Integer Linear Programming,Hypergraph",,4.0,66.0,504.0,,,visualizing sets;layout objectives optimize;base map;groups university faculty;integer linear,0.6362;0.3083;0.2748;0.2368;0.0502,"[np.int64(-1), -1, -1, -1, -1]",176;-1;-1;-1;-1,176,176
VAST,2016,Supporting visual exploration for multiple users in large display environments,10.1109/vast.2016.7883506,http://dx.doi.org/10.1109/VAST.2016.7883506,1.0,10.0,C,"We present a design space exploration of interaction techniques for supporting multiple collaborators exploring data on a shared large display. Our proposed solution is based on users controlling individual lenses using both explicit gestures as well as proxemics: the spatial relations between people and physical artifacts such as their distance, orientation, and movement. We discuss different design considerations for implicit and explicit interactions through the lens, and evaluate the user experience to find a balance between the implicit and explicit interaction styles. Our findings indicate that users favor implicit interaction through proxemics for navigation and collaboration, but prefer using explicit mid-air gestures to perform actions that are perceived to be direct, such as terminating a lens composition. Based on these results, we propose a hybrid technique utilizing both proxemics and mid-air gestures, along with examples applying this technique to other datasets. Finally, we performed a usability evaluation of the hybrid technique and observed user performance improvements in the presence of both implicit and explicit interaction styles.",Sriram Karthik Badam;Fereshteh Amini;Niklas Elmqvist;Pourang Irani,Sriram Karthik Badam;Fereshteh Amini;Niklas Elmqvist;Pourang Irani,"University of Maryland, College Park, MD, USA;University of Manitoba, Winnipeg, MB, Canada;University of Maryland, College Park, MD, USA;University of Manitoba, Winnipeg, MB, Canada",10.1109/tvcg.2013.166;10.1109/tvcg.2009.162;10.1109/tvcg.2013.163;10.1109/tvcg.2011.185;10.1109/tvcg.2013.166,,34.0,27.0,41.0,885.0,,,interaction techniques supporting;distance orientation;terminating lens;proxemics mid air;shared large,0.6070;0.2646;0.1772;0.1621;0.1538,"[np.int64(-1), -1, -1, -1, -1]",79;-1;-1;-1;-1,79,79
Vis,2024,Visual Support for the Loop Grafting Workflow on Proteins,10.1109/tvcg.2024.3456401,http://dx.doi.org/10.1109/TVCG.2024.3456401,580.0,590.0,J,"In understanding and redesigning the function of proteins in modern biochemistry, protein engineers are increasingly focusing on exploring regions in proteins called loops. Analyzing various characteristics of these regions helps the experts design the transfer of the desired function from one protein to another. This process is denoted as loop grafting. We designed a set of interactive visualizations that provide experts with visual support through all the loop grafting pipeline steps. The workflow is divided into several phases, reflecting the steps of the pipeline. Each phase is supported by a specific set of abstracted 2D visual representations of proteins and their loops that are interactively linked with the 3D View of proteins. By sequentially passing through the individual phases, the user shapes the list of loops that are potential candidates for loop grafting. Finally, the actual in-silico insertion of the loop candidates from one protein to the other is performed, and the results are visually presented to the user. In this way, the fully computational rational design of proteins and their loops results in newly designed protein structures that can be further assembled and tested through in-vitro experiments. We showcase the contribution of our visual support design on a real case scenario changing the enantiomer selectivity of the engineered enzyme. Moreover, we provide the readers with the experts' feedback.",Filip Opálený;Pavol Ulbrich;Joan Planas-Iglesias;Jan Byska;Jan Stourac;David Bednár;Katarína Furmanová;Barbora Kozlíková,Filip Opálený;Pavol Ulbrich;Joan Planas-Iglesias;Jan Byška;Jan Štourač;David Bednář;Katarína Furmanová;Barbora Kozlíková,"Department of Visual Computing, Faculty of Informatics, Masaryk University, Brno, Czech Republic;Department of Visual Computing, Faculty of Informatics, Masaryk University, Brno, Czech Republic;Department of Experimental Biology and RECETOX, Loschmidt Laboratories, Faculty of Science, Masaryk University, Brno, Czech Republic;Department of Visual Computing, Faculty of Informatics, Masaryk University, Brno, Czech Republic;Department of Experimental Biology and RECETOX, Loschmidt Laboratories, Faculty of Science, Masaryk University, Brno, Czech Republic;Department of Experimental Biology and RECETOX, Loschmidt Laboratories, Faculty of Science, Masaryk University, Brno, Czech Republic;Department of Visual Computing, Faculty of Informatics, Masaryk University, Brno, Czech Republic;Department of Visual Computing, Faculty of Informatics, Masaryk University, Brno, Czech Republic",10.1109/tvcg.2016.2598544;10.1109/tvcg.2009.111;10.1109/tvcg.2020.3030438;10.1109/tvcg.2012.213;10.1109/tvcg.2022.3209434,"Protein visualization,protein engineering,,,loop grafting,abstract views",,0.0,59.0,127.0,HM,,design proteins loops;interactive visualizations provide;grafting;actual;divided phases reflecting,0.6395;0.4680;0.2552;0.0055;-0.0389,"[np.int64(-1), -1, -1, -1, -1]",119;-1;-1;-1;-1,119,119
Vis,1995,Interval set: a volume rendering technique generalizing isosurface extraction,10.1109/visual.1995.480789,http://dx.doi.org/10.1109/VISUAL.1995.480789,3.0,,C,"A scalar volume V={(x,f(x))|x/spl isin/R} is described by a function f(x) defined over some region R of the three dimensional space. The paper presents a simple technique for rendering interval sets of the form I/sub g/(a,b)={(x,f(x))|a/spl les/g(x)/spl les/b}, where a and b are either real numbers of infinities. We describe an algorithm for triangulating interval sets as /spl alpha/ shapes, which can be accurately and efficiently rendered as surfaces or semi transparent clouds. On the theoretical side, interval sets provide an unified approach to isosurface extraction and direct volume rendering. On the practical side, interval sets add flexibility to scalar volume visualization-we may choose to, for example, have an interactive, high quality display of the volume surrounding or ""inside"" an isosurface when such display for the entire volume is too expensive to produce.",Baining Guo,Baining Guo,"Department of Computer Science, University of Toronto, Toronto, ONT, Canada",,,57.0,8.0,22.0,100.0,,,volume visualization;infinities algorithm triangulating;approach isosurface extraction;theoretical interval sets;unified,0.6629;0.4109;0.4096;0.3593;0.0388,"[np.int64(-1), -1, -1, -1, -1]",84;-1;-1;-1;-1,84,84
Vis,2006,Feature Aligned Volume Manipulation for Illustration and Visualization,10.1109/tvcg.2006.144,http://dx.doi.org/10.1109/TVCG.2006.144,1069.0,1076.0,J,"In this paper we describe a GPU-based technique for creating illustrative visualization through interactive manipulation of volumetric models. It is partly inspired by medical illustrations, where it is common to depict cuts and deformation in order to provide a better understanding of anatomical and biological structures or surgical processes, and partly motivated by the need for a real-time solution that supports the specification and visualization of such illustrative manipulation. We propose two new feature aligned techniques, namely surface alignment and segment alignment, and compare them with the axis-aligned techniques which were reported in previous work on volume manipulation. We also present a mechanism for defining features using texture volumes, and methods for computing correct normals for the deformed volume in respect to different alignments. We describe a GPU-based implementation to achieve real-time performance of the techniques and a collection of manipulation operators including peelers, retractors, pliers and dilators which are adaptations of the metaphors and tools used in surgical procedures and medical illustrations. Our approach is directly applicable in medical and biological illustration, and we demonstrate how it works as an interactive tool for focus+context visualization, as well as a generic technique for volume graphics",Carlos D. Correa;Deborah Silver;Min Chen 0001,Carlos Correa;Deborah Silver;Min Chen,"Department of Electrical and Computer Engineering, State University of New Jersey, Rutgers, USA;Department of Electrical and Computer Engineering, State University of New Jersey, Rutgers, USA;Department of Computer Science, University of Wales, Swansea, UK",10.1109/visual.2003.1250400;10.1109/visual.2000.885694;10.1109/visual.2003.1250400,"Illustrative visualization, Illustrative manipulation, GPU computing, volume rendering, volume deformation, computerassisted medical illustration",125.0,61.0,25.0,708.0,,,interactive manipulation volumetric;paper gpu;common depict cuts;medical biological;different alignments,0.6684;0.3553;0.3234;0.1470;0.0573,"[np.int64(-1), -1, -1, -1, -1]",312;-1;-1;-1;-1,312,312
Vis,1995,On enhancing the speed of splatting with indexing,10.1109/visual.1995.480797,http://dx.doi.org/10.1109/VISUAL.1995.480797,69.0,,C,"Splatting is an object space direct volume rendering algorithm that produces images of high quality, but is computationally expensive like many other volume rendering algorithms. The paper presents a new technique that enhances the speed of splatting without trading off image quality. This new method reduces rendering time by employing a simple indexing mechanism which allows to visit and splat only the voxels of interest. It is shown that this algorithm is suitable for the dynamic situation in which viewing parameters and opacity transfer functions change interactively. We report experimental results on several test data sets of useful site and complexity, and discuss the cost/benefit trade off of our method.",Insung Ihm;Rae Kyoung Lee,Insung Ihm;Rae Kyoung Lee,"Department of Computer Science, Sogang University, Seoul, South Korea;Department of Computer Science, Sogang University, Seoul, South Korea",10.1109/visual.1990.146377;10.1109/visual.1990.146377,,40.0,3.0,13.0,48.0,,,volume rendering algorithms;splat;indexing mechanism allows;change interactively;test data sets,0.7297;0.2959;0.1286;0.0515;0.0459,"[np.int64(-1), -1, -1, -1, -1]",96;-1;-1;-1;-1,96,96
Vis,1999,Visualizing gridded datasets with large number of missing values,10.1109/visual.1999.809916,http://dx.doi.org/10.1109/VISUAL.1999.809916,405.0,551.0,C,"Much of the research in scientific visualization has focused on complete sets of gridded data. The paper presents our experience dealing with gridded data sets with a large number of missing or invalid data, and some of our experiments in addressing the shortcomings of standard off-the-shelf visualization algorithms. In particular, we discuss the options in modifying known algorithms to adjust to the specifics of sparse datasets, and provide a new technique to smooth out the side-effects of the operations. We apply our findings to data acquired from NEXRAD (NEXt generation RADars) weather radars, which usually have no more than 3 to 4 percent of all possible cell points filled.",Suzana Djurcilov;Alex Pang,S. Djurcilov;A. Pang,"Computer Science Department, University of California, Santa Cruz, USA;Computer Science Department, University of California, Santa Cruz, USA",10.1109/visual.1996.568145;10.1109/visual.1996.568145,,23.0,11.0,12.0,91.0,,,gridded data sets;nexrad generation radars;smooth effects operations;usually percent;missing invalid,0.6045;0.3215;0.0936;0.0649;0.0598,"[np.int64(-1), -1, -1, -1, -1]",144;-1;-1;-1;-1,144,144
VAST,2016,NameClarifier: A Visual Analytics System for Author Name Disambiguation,10.1109/tvcg.2016.2598465,http://dx.doi.org/10.1109/TVCG.2016.2598465,141.0,150.0,J,"In this paper, we present a novel visual analytics system called NameClarifier to interactively disambiguate author names in publications by keeping humans in the loop. Specifically, NameClarifier quantifies and visualizes the similarities between ambiguous names and those that have been confirmed in digital libraries. The similarities are calculated using three key factors, namely, co-authorships, publication venues, and temporal information. Our system estimates all possible allocations, and then provides visual cues to users to help them validate every ambiguous case. By looping users in the disambiguation process, our system can achieve more reliable results than general data mining models for highly ambiguous cases. In addition, once an ambiguous case is resolved, the result is instantly added back to our system and serves as additional cues for all the remaining unidentified names. In this way, we open up the black box in traditional disambiguation processes, and help intuitively and comprehensively explain why the corresponding classifications should hold. We conducted two use cases and an expert review to demonstrate the effectiveness of NameClarifier.",Qiaomu Shen;Tongshuang Wu;Haiyan Yang;Yanhong Wu;Huamin Qu;Weiwei Cui,Qiaomu Shen;Tongshuang Wu;Haiyan Yang;Yanhong Wu;Huamin Qu;Weiwei Cui,Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Microsoft Research,10.1109/tvcg.2012.252;10.1109/tvcg.2011.188;10.1109/vast.2006.261429;10.1109/tvcg.2012.252,Name disambiguation;analytical reasoning,47.0,26.0,41.0,1681.0,,,interactively disambiguate author;novel visual analytics;libraries similarities;cases addition;humans loop specifically,0.6837;0.3352;0.3076;0.1292;0.1121,"[np.int64(-1), -1, -1, -1, -1]",243;-1;-1;-1;-1,243,243
VAST,2011,Exploring agent-based simulations using temporal graphs,10.1109/vast.2011.6102469,http://dx.doi.org/10.1109/VAST.2011.6102469,271.0,272.0,M,"Agent-based simulation has become a key technique for modeling and simulating dynamic, complicated behaviors in social and behavioral sciences. Lacking the appropriate tools and support, it is difficult for social scientists to thoroughly analyze the results of these simulations. In this work, we capture the complex relationships between discrete simulation states by visualizing the data as a temporal graph. In collaboration with expert analysts, we identify two graph structures which capture important relationships between pivotal states in the simulation and their inevitable outcomes. Finally, we demonstrate the utility of these structures in the interactive analysis of a large-scale social science simulation of political power in present-day Thailand.",R. Jordan Crouser;Jeremy G. Freeman;Remco Chang,R. Jordan Crouser;Jeremy G. Freeman;Remco Chang,"Tufts University, USA;Tufts University, USA;Tufts University, USA",0.1109/infvis.2005.1532126,,0.0,0.0,8.0,163.0,,,simulation political power;identify graph;day thailand;thoroughly analyze results;support difficult social,0.6789;0.2714;0.1644;0.1467;0.0936,"[np.int64(-1), -1, -1, -1, -1]",1;-1;-1;-1;-1,1,1
Vis,2007,Visualization of Cosmological Particle-Based Datasets,10.1109/tvcg.2007.70526,http://dx.doi.org/10.1109/TVCG.2007.70526,1712.0,1718.0,J,"We describe our visualization process for a particle-based simulation of the formation of the first stars and their impact on cosmic history. The dataset consists of several hundred time-steps of point simulation data, with each time-step containing approximately two million point particles. For each time-step, we interpolate the point data onto a regular grid using a method taken from the radiance estimate of photon mapping [21]. We import the resulting regular grid representation into ParaView [24], with which we extract isosurfaces across multiple variables. Our images provide insights into the evolution of the early universe, tracing the cosmic transition from an initially homogeneous state to one of increasing complexity. Specifically, our visualizations capture the build-up of regions of ionized gas around the first stars, their evolution, and their complex interactions with the surrounding matter. These observations will guide the upcoming James Webb Space Telescope, the key astronomy mission of the next decade.",Paul A. Navrátil;Jarrett Johnson;Volker Bromm,Paul Navratil;Jarrett Johnson;Volker Bromm,"Texas Advanced Computing Center, University of Texas at Austin;Department of Astronomy, University of Technology, Austin, USA and Department of Astronomy, University of Texas at Austin;Department of Astronomy, University of Technology, Austin, USA and Department of Astronomy, University of Texas at Austin",10.1109/visual.2004.52;10.1109/visual.2004.29;10.1109/visual.2004.52,"Interpolation, Isosurface, Astronomy, Cosmology",51.0,23.0,41.0,403.0,,,early universe tracing;grid representation paraview;isosurfaces;james webb;homogeneous state increasing,0.6233;0.2497;0.2129;0.1076;0.0266,"[np.int64(-1), -1, -1, -1, -1]",2;-1;-1;-1;-1,2,2
InfoVis,2012,Visualizing Flow of Uncertainty through Analytical Processes,10.1109/tvcg.2012.285,http://dx.doi.org/10.1109/TVCG.2012.285,2526.0,2535.0,J,"Uncertainty can arise in any stage of a visual analytics process, especially in data-intensive applications with a sequence of data transformations. Additionally, throughout the process of multidimensional, multivariate data analysis, uncertainty due to data transformation and integration may split, merge, increase, or decrease. This dynamic characteristic along with other features of uncertainty pose a great challenge to effective uncertainty-aware visualization. This paper presents a new framework for modeling uncertainty and characterizing the evolution of the uncertainty information through analytical processes. Based on the framework, we have designed a visual metaphor called uncertainty flow to visually and intuitively summarize how uncertainty information propagates over the whole analysis pipeline. Our system allows analysts to interact with and analyze the uncertainty information at different levels of detail. Three experiments were conducted to demonstrate the effectiveness and intuitiveness of our design.",Yingcai Wu;Guo-Xun Yuan;Kwan-Liu Ma,Yingcai Wu;Guo-Xun Yuan;Kwan-Liu Ma,"University of California, Davis, USA;University of California,슠Davis, USA;University of California, Davis, USA",10.1109/tvcg.2008.137;10.1109/tvcg.2011.178;10.1109/infvis.2004.2;10.1109/infvis.2002.1173145;10.1109/visual.1993.398857;10.1109/vast.2009.5332611;10.1109/tvcg.2010.183;10.1109/tvcg.2009.114;10.1109/tvcg.2011.197;10.1109/tvcg.2010.176,"Uncertainty visualization, uncertainty quantification, uncertainty propagation, error ellipsoids, uncertainty fusion",69.0,43.0,46.0,1098.0,,,uncertainty aware visualization;analysts interact;transformations additionally process;sequence data;called,0.7671;0.3211;0.2009;0.1445;0.0247,"[np.int64(-1), -1, -1, -1, -1]",159;-1;-1;-1;-1,159,159
VAST,2019,GPGPU Linear Complexity t-SNE Optimization,10.1109/tvcg.2019.2934307,http://dx.doi.org/10.1109/TVCG.2019.2934307,1172.0,1181.0,J,"In recent years the t-distributed Stochastic Neighbor Embedding (t-SNE) algorithm has become one of the most used and insightful techniques for exploratory data analysis of high-dimensional data. It reveals clusters of high-dimensional data points at different scales while only requiring minimal tuning of its parameters. However, the computational complexity of the algorithm limits its application to relatively small datasets. To address this problem, several evolutions of t-SNE have been developed in recent years, mainly focusing on the scalability of the similarity computations between data points. However, these contributions are insufficient to achieve interactive rates when visualizing the evolution of the t-SNE embedding for large datasets. In this work, we present a novel approach to the minimization of the t-SNE objective function that heavily relies on graphics hardware and has linear computational complexity. Our technique decreases the computational cost of running t-SNE on datasets by orders of magnitude and retains or improves on the accuracy of past approximated techniques. We propose to approximate the repulsive forces between data points by splatting kernel textures for each data point. This approximation allows us to reformulate the t-SNE minimization problem as a series of tensor operations that can be efficiently executed on the graphics card. An efficient implementation of our technique is integrated and available for use in the widely used Google TensorFlow.js, and an open-source C++ library.",Nicola Pezzotti;Julian Thijssen;Alexander Mordvintsev;Thomas Höllt;Baldur van Lew;Boudewijn P. F. Lelieveldt;Elmar Eisemann;Anna Vilanova,Nicola Pezzotti;Julian Thijssen;Alexander Mordvintsev;Thomas Höllt;Baldur Van Lew;Boudewijn P.F. Lelieveldt;Elmar Eisemann;Anna Vilanova,"Google AI, Zürich, Switzerland and Delft University of Technology, Delft, The Netherlands;Delft University of Technology, Delft, The Netherlands;Google AI, Zürich, Switzerland;Delft University of Technology, Delft, The Netherlands and Leiden University Medical Center, Leiden, The Netherlands;Leiden University Medical Center, Leiden, The Netherlands;Delft University of Technology, Delft, The Netherlands and Leiden University Medical Center, Leiden, The Netherlands;Delft University of Technology, Delft, The Netherlands;Delft University of Technology, Delft, The Netherlands",10.1109/tvcg.2017.2744318;10.1109/tvcg.2017.2744718;10.1109/tvcg.2017.2745141;10.1109/tvcg.2017.2744358;10.1109/tvcg.2014.2346574,"High Dimensional Data,Dimensionality Reduction,Progressive Visual Analytics,Approximate Computation,GPGPU",59.0,45.0,45.0,1185.0,,,stochastic neighbor embedding;visualizing evolution;tensorflow js open;repulsive forces;graphics card efficient,0.6117;0.3444;0.2563;0.2062;0.1546,"[np.int64(-1), -1, -1, -1, -1]",31;-1;-1;-1;-1,31,31
VAST,2012,Visual analytics methods for categoric spatio-temporal data,10.1109/vast.2012.6400553,http://dx.doi.org/10.1109/VAST.2012.6400553,183.0,192.0,C,"We focus on visual analysis of space- and time-referenced categorical data, which describe possible states of spatial (geographical) objects or locations and their changes over time. The analysis of these data is difficult as there are only limited possibilities to analyze the three aspects (location, time and category) simultaneously. We present a new approach which interactively combines (a) visualization of categorical changes over time; (b) various spatial data displays; (c) computational techniques for task-oriented selection of time steps. They provide an expressive visualization with regard to either the overall evolution over time or unusual changes. We apply our approach on two use cases demonstrating its usefulness for a wide variety of tasks. We analyze data from movement tracking and meteorologic areas. Using our approach, expected events could be detected and new insights were gained.",Tatiana von Landesberger;Sebastian Bremm;Natalia V. Andrienko;Gennady L. Andrienko;Maria Tekusova,T. von Landesberger;Sebastian Bremm;Natalia Andrienko;Gennady Andrienko;Mária Tekušová,"TU Darmstadt, Darmstadt, Germany;TU Darmstadt, Darmstadt, Germany;Fraunhofer IAIS, Bonn, Germany;Fraunhofer IAIS, Bonn, Germany;SHMU, Bratislava, Slovakia",10.1109/tvcg.2011.174;10.1109/tvcg.2009.117;10.1109/tvcg.2009.181;10.1109/infvis.2000.885098;10.1109/tvcg.2010.138;10.1109/vast.2010.5652530;10.1109/infvis.2004.27;10.1109/infvis.2005.1532152;10.1109/infvis.2001.963281;10.1109/tvcg.2008.165;10.1109/tvcg.2009.153;10.1109/tvcg.2011.174,,100.0,43.0,43.0,1416.0,,,visualization categorical changes;task oriented selection;location time;meteorologic areas using;expected events,0.6561;0.3065;0.2926;0.2926;0.1431,"[np.int64(-1), -1, -1, -1, -1]",162;-1;-1;-1;-1,162,162
Vis,2024,DimBridge: Interactive Explanation of Visual Patterns in Dimensionality Reductions with Predicate Logic,10.1109/tvcg.2024.3456391,http://dx.doi.org/10.1109/TVCG.2024.3456391,207.0,217.0,J,"Dimensionality reduction techniques are widely used for visualizing high-dimensional data. However, support for interpreting patterns of dimension reduction results in the context of the original data space is often insufficient. Consequently, users may struggle to extract insights from the projections. In this paper, we introduce DimBridge, a visual analytics tool that allows users to interact with visual patterns in a projection and retrieve corresponding data patterns. DimBridge supports several interactions, allowing users to perform various analyses, from contrasting multiple clusters to explaining complex latent structures. Leveraging first-order predicate logic, DimBridge identifies subspaces in the original dimensions relevant to a queried pattern and provides an interface for users to visualize and interact with them. We demonstrate how DimBridge can help users overcome the challenges associated with interpreting visual patterns in projections.",Brian Montambault;Gabriel Appleby;Jen Rogers;Camelia D. Brumar;Mingwei Li;Remco Chang,Brian Montambault;Gabriel Appleby;Jen Rogers;Camelia D. Brumar;Mingwei Li;Remco Chang,"Tufts University, USA;Tufts University, USA;Tufts University, USA;Tufts University, USA;Tufts University, USA;Tufts University, USA",10.1109/tvcg.2011.229;10.1109/tvcg.2018.2864477;10.1109/vast.2012.6400489;10.1109/tvcg.2019.2934251;10.1109/tvcg.2021.3114807;10.1109/vast.2008.4677352;10.1109/infvis.2002.1173157;10.1109/tvcg.2017.2745085;10.1109/visual.1990.146386;10.1109/tvcg.2022.3209382;10.1109/visual.1995.485139;10.1109/tvcg.2018.2864812;10.1109/tvcg.2013.153;10.1109/tvcg.2021.3114870;10.1109/tvcg.2017.2744843;10.1109/tvcg.2015.2467717;10.1109/vast.2012.6400488;10.1109/tvcg.2017.2745258;10.1109/infvis.2005.1532142;10.1109/tvcg.2022.3209423;10.1109/vast.2006.261436,"Predicates,Dimensionality Reduction,,,Explainable Machine Learning",,0.0,95.0,220.0,,,visualizing high dimensional;multiple clusters explaining;logic dimbridge identifies;reduction results;support,0.6151;0.4332;0.3196;0.1879;0.1271,"[np.int64(-1), -1, -1, -1, -1]",182;-1;-1;-1;-1,182,182
Vis,2003,Interactive view-dependent rendering with conservative occlusion culling in complex environments,10.1109/visual.2003.1250368,http://dx.doi.org/10.1109/VISUAL.2003.1250368,163.0,170.0,C,"This paper presents an algorithm combining view-dependent rendering and conservative occlusion culling for interactive display of complex environments. A vertex hierarchy of the entire scene is decomposed into a cluster hierarchy through a novel clustering and partitioning algorithm. The cluster hierarchy is then used for view-frustum and occlusion culling. Using hardware accelerated occlusion queries and frame-to-frame coherence, a potentially visible set of clusters is computed. An active vertex front and face list is computed from the visible clusters and rendered using vertex arrays. The integrated algorithm has been implemented on a Pentium IV PC with a NVIDIA GeForce 4 graphics card and applied in two complex environments composed of millions of triangles. The resulting system can render these environments at interactive rates with little loss in image quality and minimal popping artifacts.",Sung-Eui Yoon;Brian Salomon;Dinesh Manocha,Sung-Eui Yoon;B. Salomon;D. Manocha,"University of North Carolina, Chapel Hill, USA;University of North Carolina, Chapel Hill, USA;University of North Carolina, Chapel Hill, USA",10.1109/visual.2002.1183760;10.1109/visual.2001.964534;10.1109/visual.2002.1183796;10.1109/visual.2002.1183760,"Interactive Display, View-Dependent Rendering, Occlusion Culling, Level of Detail, Multiresolution Hierarchies",56.0,6.0,40.0,118.0,,,hardware accelerated occlusion;display complex environments;cluster hierarchy used;scene;list computed,0.6035;0.4821;0.2570;0.1520;0.0705,"[np.int64(-1), -1, -1, -1, -1]",290;-1;-1;-1;-1,290,290
Vis,2008,Generation of Accurate Integral Surfaces in Time-Dependent Vector fields,10.1109/tvcg.2008.133,http://dx.doi.org/10.1109/TVCG.2008.133,1404.0,1411.0,J,"We present a novel approach for the direct computation of integral surfaces in time-dependent vector fields. As opposed to previous work, which we analyze in detail, our approach is based on a separation of integral surface computation into two stages: surface approximation and generation of a graphical representation. This allows us to overcome several limitations of existing techniques. We first describe an algorithm for surface integration that approximates a series of time lines using iterative refinement and computes a skeleton of the integral surface. In a second step, we generate a well-conditioned triangulation. Our approach allows a highly accurate treatment of very large time-varying vector fields in an efficient, streaming fashion. We examine the properties of the presented methods on several example datasets and perform a numerical study of its correctness and accuracy. Finally, we investigate some visualization aspects of integral surfaces.",Christoph Garth;Han Krishnan;Xavier Tricoche;Tom Tricoche;Kenneth I. Joy,Christoph Garth;Han Krishnan;Xavier Tricoche;Tom Tricoche;Kenneth I. Joy,"Institute of Data Analysis and Visualization, University of California, Davis, USA;Institute of Data Analysis and Visualization, University of California, Davis, USA;Computer Science Dept., Purdue University, USA;Geometric Algorithms Group, University of Kaiserslautern;Institute of Data Analysis and Visualization, University of California, Davis, USA",10.1109/visual.1993.398875;10.1109/visual.2001.964506;10.1109/visual.2004.28;10.1109/visual.1992.235211;10.1109/visual.1992.235226;10.1109/visual.1993.398875,"3D vector field visualization, flow visualization, time-varying and time-series visualization, surface extraction",103.0,51.0,18.0,376.0,,,integral surfaces time;triangulation;streaming fashion;fields opposed;approximates series,0.5838;0.3497;0.1337;0.1040;0.0339,"[np.int64(-1), -1, -1, -1, -1]",251;-1;-1;-1;-1,251,251
Vis,2000,Two-level volume rendering - fusing MIP and DVR,10.1109/visual.2000.885697,http://dx.doi.org/10.1109/VISUAL.2000.885697,211.0,218.0,C,"Presents a two-level approach for fusing direct volume rendering (DVR) and maximum-intensity projection (MIP) within a joint rendering method. Different structures within the data set are rendered locally by either MIP or DVR on an object-by-object basis. Globally, all the results of subsequent object renderings are combined in a merging step (usually compositing in our case). This allows us to selectively choose the most suitable technique for depicting each object within the data, while keeping the amount of information contained in the image at a reasonable level. This is especially useful when inner structures should be visualized together with semi-transparent outer parts, similar to the focus-and-context approach known from information visualization. We also present an implementation of our approach which allows us to explore volumetric data using two-level rendering at interactive frame rates.",Helwig Hauser;Lukas Mroz;Gian Italo Bischi;M. Eduard Gröller,H. Hauser;L. Mroz;G.-I. Bischi;M.E. Groller,"VRVis Center Vienna, Austria;University of Technology, Vienna, Austria;University of Urbino, Italy;University of Technology, Vienna, Austria",10.1109/visual.1998.745311;10.1109/visual.1999.809887;10.1109/visual.1996.568113;10.1109/visual.2000.885697;10.1109/visual.1998.745311,"visualization, volume rendering, dynamical systems,medical applications",81.0,12.0,20.0,173.0,,,direct volume rendering;object basis globally;explore;combined;keeping information,0.7287;0.2026;0.1436;0.1119;0.1087,"[np.int64(-1), -1, -1, -1, -1]",98;-1;-1;-1;-1,98,98
Vis,2023,VISPUR: Visual Aids for Identifying and Interpreting Spurious Associations in Data-Driven Decisions,10.1109/tvcg.2023.3326587,http://dx.doi.org/10.1109/TVCG.2023.3326587,219.0,229.0,J,"Big data and machine learning tools have jointly empowered humans in making data-driven decisions. However, many of them capture empirical associations that might be spurious due to confounding factors and subgroup heterogeneity. The famous Simpson's paradox is such a phenomenon where aggregated and subgroup-level associations contradict with each other, causing cognitive confusions and difficulty in making adequate interpretations and decisions. Existing tools provide little insights for humans to locate, reason about, and prevent pitfalls of spurious association in practice. We propose VISPUR, a visual analytic system that provides a causal analysis framework and a human-centric workflow for tackling spurious associations. These include a CONFOUNDER DASHBOARD, which can automatically identify possible confounding factors, and a SUBGROUP VIEWER, which allows for the visualization and comparison of diverse subgroup patterns that likely or potentially result in a misinterpretation of causality. Additionally, we propose a REASONING STORYBOARD, which uses a flow-based approach to illustrate paradoxical phenomena, as well as an interactive DECISION DIAGNOSIS panel that helps ensure accountable decision-making. Through an expert interview and a controlled user experiment, our qualitative and quantitative results demonstrate that the proposed “de-paradox” workflow and the designed visual analytic system are effective in helping human users to identify and understand spurious associations, as well as to make accountable causal decisions.",Xian Teng;Yongsu Ahn;Yu-Ru Lin,Xian Teng;Yongsu Ahn;Yu-Ru Lin,"University of Pittsburgh, USA;University of Pittsburgh, USA;University of Pittsburgh, USA",0.1109/tvcg.2019.2934262;10.1109/tvcg.2014.2346297;10.1109/vast.2018.8802486;10.1109/vast47406.2019.8986948;10.1109/tvcg.2020.3030342;10.1109/tvcg.2018.2865043;10.1109/tvcg.2020.3030465;10.1109/tvcg.2021.3114824;10.1109/tvcg.2017.2745085;10.1109/infvis.2005.1532152;10.1109/tvcg.2015.2467931;10.1109/vast.2017.8585647;10.1109/tvcg.2019.2934619;10.1109/tvcg.2020.3028957,"Causal Analysis,Simpson's Paradox,Spurious Associations,Machine Learning,Decision Making",,0.0,76.0,426.0,,,associations spurious confounding;visualization comparison diverse;factors subgroup;dashboard automatically;uses,0.5565;0.3643;0.1866;0.1326;0.1200,"[np.int64(-1), -1, -1, -1, -1]",85;-1;-1;-1;-1,85,85
Vis,2005,Multimodal exploration of the fourth dimension,10.1109/visual.2005.1532804,http://dx.doi.org/10.1109/VISUAL.2005.1532804,263.0,270.0,C,"We present a multimodal paradigm for exploring topological surfaces embedded in four dimensions; we exploit haptic methods in particular to overcome the intrinsic limitations of 3D graphics images and 3D physical models. The basic problem is that, just as 2D shadows of 3D curves lose structure where lines cross, 3D graphics projections of smooth 4D topological surfaces are interrupted where one surface intersects another. Furthermore, if one attempts to trace real knotted ropes or a plastic models of self-intersecting surfaces with a fingertip, one inevitably collides with parts of the physical artifact. In this work, we exploit the free motion of a computer-based haptic probe to support a continuous motion that follows the local continuity of the object being explored. For our principal test case of 4D-embedded surfaces projected to 3D, this permits us to follow the full local continuity of the surface as though in fact we were touching an actual 4D object. We exploit additional sensory cues to provide supplementary or redundant information. For example, we can use audio tags to note the relative 4D depth of illusory 3D surface intersections produced by projection from 4D, as well as providing automated refinement of the tactile exploration path to eliminate jitter and snagging, resulting in a much cleaner exploratory motion than a bare uncorrected motion. Visual enhancements provide still further improvement to the feedback: by opening a view-direction-defined cutaway into the interior of the 3D surface projection, we allow the viewer to keep the haptic probe continuously in view as it traverses any touchable part of the object. Finally, we extend the static tactile exploration framework using a dynamic mode that links each stylus motion to a change in orientation that creates at each instant a maximal-area screen projection of a neighborhood of the current point of interest. This minimizes 4D distortion and permits true metric sizes to be deduced locally at any point. All these methods combine to reveal the full richness of the complex spatial relationships of the target shapes, and to overcome many expected perceptual limitations in 4D visualization.",Andrew J. Hanson;Hui Zhang 0006,A.J. Hanson;H. Zhang,"Computer Science Department, Indiana University, USA;Computer Science Department, Indiana University, USA",10.1109/visual.1995.480804;10.1109/visual.1995.480804," multimodal, haptics, visualization",21.0,5.0,31.0,170.0,,,touching actual 4d;paradigm exploring topological;eliminate jitter snagging;attempts trace;provide supplementary redundant,0.6277;0.3054;0.0972;0.0809;-0.0137,"[np.int64(-1), -1, -1, -1, -1]",238;-1;-1;-1;-1,238,238
Vis,2001,"Semi-immersive space mission design and visualization: case study of the ""Terrestrial Planet Finder"" mission",10.1109/visual.2001.964562,http://dx.doi.org/10.1109/VISUAL.2001.964562,501.0,504.0,C,"The paper addresses visualization issues of the Terrestrial Planet Finder Mission (C.A. Beichman et al., 1999). The goal of this mission is to search for chemical signatures of life in distant solar systems using five satellites flying in formation to simulate a large telescope. To design and visually verify such a delicate mission, one has to analyze and interact with many different 3D spacecraft trajectories, which is often difficult in 2D. We employ a novel trajectory design approach using invariant manifold theory, which is best understood and utilized in an immersive setting. The visualization also addresses multi-scale issues related to the vast differences in distance, velocity, and time at different phases of the mission. Additionally, the parameterization and coordinate frames used for numerical simulations may not be suitable for direct visualization. Relative motion presents a more serious problem where the patterns of the trajectories can only be viewed in particular rotating frames. Some of these problems are greatly relieved by using interactive, animated stereo 3D visualization in a semi-immersive environment such as a Responsive Workbench. Others were solved using standard techniques such as a stratify approach with multiple windows to address the multiscale issues, re-parameterizations of trajectories and associated 2D manifolds and relative motion of the camera to ""evoke"" the desired patterns.",Ken Museth;Alan H. Barr;Martin W. Lo,K. Museth;A. Barr;M.W. Lo,"Computer Science Department, California Institute of Technology, Pasadena, CA, USA;Computer Science Department, California Institute of Technology, Pasadena, CA, USA;Jet Propulsion Laboratory and Computer Science Department, California Institute of Technology, Pasadena, CA",,,13.0,3.0,7.0,122.0,,,3d spacecraft trajectories;chemical signatures life;camera evoke desired;responsive workbench;stratify,0.6054;0.2041;0.1688;0.1521;0.0789,"[np.int64(-1), -1, -1, -1, -1]",239;-1;-1;-1;-1,239,239
InfoVis,2020,Table Scraps: An Actionable Framework for Multi-Table Data Wrangling From An Artifact Study of Computational Journalism,10.1109/tvcg.2020.3030462,http://dx.doi.org/10.1109/TVCG.2020.3030462,957.0,966.0,J,"For the many journalists who use data and computation to report the news, data wrangling is an integral part of their work. Despite an abundance of literature on data wrangling in the context of enterprise data analysis, little is known about the specific operations, processes, and pain points journalists encounter while performing this tedious, time-consuming task. To better understand the needs of this user group, we conduct a technical observation study of 50 public repositories of data and analysis code authored by 33 professional journalists at 26 news organizations. We develop two detailed and cross-cutting taxonomies of data wrangling in computational journalism, for actions and for processes. We observe the extensive use of multiple tables, a notable gap in previous wrangling analyses. We develop a concise, actionable framework for general multi-table data wrangling that includes wrangling operations documented in our taxonomy that are without clear parallels in other work. This framework, the first to incorporate tables as first-class objects, will support future interactive wrangling tools for both computational journalism and general-purpose use. We assess the generative and descriptive power of our framework through discussion of its relationship to our set of taxonomies.",Stephen Kasica;Charles Berret;Tamara Munzner,Stephen Kasica;Charles Berret;Tamara Munzner,"Department of Computer Science, University of British Columbia;University of British Columbia, School of Journalism, Writing, and Media;Department of Computer Science, University of British Columbia",10.1109/vast47406.2019.8986909;10.1109/vast.2011.6102441;10.1109/tvcg.2012.219;10.1109/tvcg.2019.2934593;10.1109/vast.2011.6102440;10.1109/tvcg.2019.2934539;10.1109/tvcg.2015.2467551;10.1109/infvis.2000.885086;10.1109/vast47406.2019.8986909,"Computational journalism,Data journalism,Data wrangling",20.0,17.0,55.0,800.0,,,journalists use data;framework incorporate tables;operations processes pain;taxonomy clear parallels;26,0.6592;0.2414;0.1863;0.0989;0.0118,"[np.int64(-1), -1, -1, -1, -1]",124;-1;-1;-1;-1,124,124
Vis,1994,Nonpolygonal isosurface rendering for large volume datasets,10.1109/visual.1994.346306,http://dx.doi.org/10.1109/VISUAL.1994.346306,293.0,,C,"Surface-based rendering techniques, particularly those that extract a polygonal approximation of an isosurface, are widely used in volume visualization. As dataset size increases though, the computational demands of these methods can overwhelm typically available computing resources. Recent work on accelerating such techniques has focused on preprocessing the volume data or postprocessing the extracted polygonization. The algorithm presented, concentrates instead on streamlining the surface extraction process itself so as to accelerate the rendering of large volumes. The technique shortens the conventional isosurface visualization pipeline by eliminating the intermediate polygonization. We compute the contribution of the isosurface within a volume cell to the resulting image directly from a simplified numerical description of the cell/surface intersection. The approach also reduces the work in the remaining stages of the visualization process. By quantizing the volume data, we exploit precomputed and cached data at key processing steps to improve rendering efficiency. The resulting implementation provides comparatively fast renderings with reasonable image quality.&lt;&lt;ETX&gt;&gt;",James W. Durkin;John F. Hughes,J.W. Durkin;J.F. Hughes,"Cornell University, Ithaca, NY, USA;Computer Science Department, Brown University, Providence, RI, USA",,,27.0,2.0,12.0,53.0,,,volume visualization;comparatively fast renderings;conventional isosurface;postprocessing extracted polygonization;exploit precomputed cached,0.6695;0.4283;0.4127;0.4008;0.0458,"[np.int64(-1), -1, -1, -1, -1]",84;-1;-1;-1;-1,84,84
Vis,2023,Interactive Design and Optics-Based Visualization of Arbitrary Non-Euclidean Kaleidoscopic Orbifolds,10.1109/tvcg.2023.3326927,http://dx.doi.org/10.1109/TVCG.2023.3326927,1292.0,1301.0,J,"Orbifolds are a modern mathematical concept that arises in the research of hyperbolic geometry with applications in computer graphics and visualization. In this paper, we make use of rooms with mirrors as the visual metaphor for orbifolds. Given any arbitrary two-dimensional kaleidoscopic orbifold, we provide an algorithm to construct a Euclidean, spherical, or hyperbolic polygon to match the orbifold. This polygon is then used to create a room for which the polygon serves as the floor and the ceiling. With our system that implements Möbius transformations, the user can interactively edit the scene and see the reflections of the edited objects. To correctly visualize non-Euclidean orbifolds, we adapt the rendering algorithms to account for the geodesics in these spaces, which light rays follow. Our interactive orbifold design system allows the user to create arbitrary two-dimensional kaleidoscopic orbifolds. In addition, our mirror-based orbifold visualization approach has the potential of helping our users gain insight on the orbifold, including its orbifold notation as well as its universal cover, which can also be the spherical space and the hyperbolic space.",Jinta Zheng;Eugene Zhang;Yue Zhang 0009,Jinta Zheng;Eugene Zhang;Yue Zhang,"Oregon State University, USA;Oregon State University, USA;Oregon State University, USA",0.1109/tvcg.2020.3030431;10.1109/tvcg.2017.2744038;10.1109/tvcg.2018.2864768,"Kaleidoscopic Orbifolds,Orbifold Visualization,Math Visualization,Orbifold Construction,Spherical Geometry,Hyperbolic Geometry",,0.0,36.0,214.0,,,based orbifold visualization;hyperbolic space;polygon serves floor;scene reflections edited;given arbitrary,0.7131;0.4431;0.3597;0.3065;0.0703,"[np.int64(-1), -1, -1, -1, -1]",252;-1;-1;-1;-1,252,252
InfoVis,1999,Evaluating a visualisation of image similarity as a tool for image browsing,10.1109/infvis.1999.801855,http://dx.doi.org/10.1109/INFVIS.1999.801855,36.0,,C,"A similarity metric based on the low-level content of images can be used to create a visualisation in which visually similar images are displayed close to each other. We are carrying out a series of experiments to evaluate the usefulness of this type of visualisation as an image browsing aid. The initial experiment, described, considered whether people would find a given photograph more quickly in a visualisation than in a randomly arranged grid of images. The results show that the subjects were faster with the visualisation, although in post-experiment interviews many of them said that they preferred the clarity and regularity of the grid. We describe an algorithm with which the best aspects of the two layout types can be combined.",Kerry Rodden;Wojciech Basalaj;David Sinclair;Kenneth R. Wood,K. Rodden;W. Basalaj;D. Sinclair;K. Wood,"Computer Laboratory, University of Cambridge, Cambridge, UK;Computer Laboratory, University of Cambridge, Cambridge, UK;AT and T Laboratories, Cambridge, UK;AT and T Laboratories, Cambridge, UK",0.1109/infvis.1999.801855,,113.0,25.0,17.0,236.0,,,visually similar images;best aspects layout;regularity grid algorithm;low level;carrying series,0.6448;0.3190;0.2895;0.0338;0.0122,"[np.int64(-1), -1, -1, -1, -1]",129;-1;-1;-1;-1,129,129
InfoVis,2008,Particle-based labeling: Fast point-feature labeling without obscuring other visual features,10.1109/tvcg.2008.152,http://dx.doi.org/10.1109/TVCG.2008.152,1237.0,1244.0,J,"In many information visualization techniques, labels are an essential part to communicate the visualized data. To preserve the expressiveness of the visual representation, a placed label should neither occlude other labels nor visual representatives (e.g., icons, lines) that communicate crucial information. Optimal, non-overlapping labeling is an NP-hard problem. Thus, only a few approaches achieve a fast non-overlapping labeling in highly interactive scenarios like information visualization. These approaches generally target the point-feature label placement (PFLP) problem, solving only label-label conflicts. This paper presents a new, fast, solid and flexible 2D labeling approach for the PFLP problem that additionally respects other visual elements and the visual extent of labeled features. The results (number of placed labels, processing time) of our particle-based method compare favorably to those of existing techniques. Although the esthetic quality of non-real-time approaches may not be achieved with our method, it complies with practical demands and thus supports the interactive exploration of information spaces. In contrast to the known adjacent techniques, the flexibility of our technique enables labeling of dense point clouds by the use of non-occluding distant labels. Our approach is independent of the underlying visualization technique, which enables us to demonstrate the application of our labeling method within different information visualization scenarios.",Martin Luboschik;Heidrun Schumann;Hilko Cords,Martin Luboschik;Heidrun Schumann;Hilko Cords,"University of Rostock, Germany;University of Rostock, Germany;University of Rostock, Germany",10.1109/tvcg.2006.136;10.1109/tvcg.2006.136;10.1109/visual.2005.1532856,"Interactive labeling, dynamic labeling, automatic label placement, occlusion-free, information visualization",88.0,50.0,23.0,786.0,,,information visualization;labeling dense point;particle;placement pflp problem;hard,0.5756;0.4783;0.2606;0.2045;0.0631,"[np.int64(-1), -1, -1, -1, -1]",207;-1;-1;-1;-1,207,207
Vis,1997,Isosurface extraction using particle systems,10.1109/visual.1997.663930,http://dx.doi.org/10.1109/VISUAL.1997.663930,495.0,498.0,C,"Presents a new approach to isosurface extraction from volume data using particle systems. Particle behavior is dynamic and can be based on laws of physics or artificial rules. For isosurface extraction, we program particles to be attracted towards a specific surface value while simultaneously repelling adjacent particles. The repulsive forces are based on the curvature of the surface at that location. A birth-death process results in a denser concentration of particles in areas of high curvature and sparser populations in areas of lower curvature. The overall level of detail is controlled through a scaling factor that increases or decreases the repulsive forces of the particles. Once particles reach equilibrium, their locations are used as vertices in generating a triangular mesh of the surface. The advantages of our approach include: vertex densities are based on surface features rather than on the sampling rate of the volume; a single scaling factor simplifies level-of-detail control; and meshing is efficient because it uses neighbor information that has already been generated during the force calculations.",Patricia Crossno;Edward Angel,P. Crossno;E. Angel,"Department of Computer Science, University of New Mexico, USA;Department of Computer Science, University of New Mexico, USA",10.1109/visual.1993.398880;10.1109/visual.1993.398880,,101.0,24.0,9.0,136.0,,,densities based surface;repulsive forces particles;extraction program;vertices generating triangular;simultaneously,0.6053;0.2874;0.2475;0.1584;-0.0444,"[np.int64(-1), -1, -1, -1, -1]",294;-1;-1;-1;-1,294,294
VAST,2015,VA2: A Visual Analytics Approach for Evaluating Visual Analytics Applications,10.1109/tvcg.2015.2467871,http://dx.doi.org/10.1109/TVCG.2015.2467871,61.0,70.0,J,"Evaluation has become a fundamental part of visualization research and researchers have employed many approaches from the field of human-computer interaction like measures of task performance, thinking aloud protocols, and analysis of interaction logs. Recently, eye tracking has also become popular to analyze visual strategies of users in this context. This has added another modality and more data, which requires special visualization techniques to analyze this data. However, only few approaches exist that aim at an integrated analysis of multiple concurrent evaluation procedures. The variety, complexity, and sheer amount of such coupled multi-source data streams require a visual analytics approach. Our approach provides a highly interactive visualization environment to display and analyze thinking aloud, interaction, and eye movement data in close relation. Automatic pattern finding algorithms allow an efficient exploratory search and support the reasoning process to derive common eye-interaction-thinking patterns between participants. In addition, our tool equips researchers with mechanisms for searching and verifying expected usage patterns. We apply our approach to a user study involving a visual analytics application and we discuss insights gained from this joint analysis. We anticipate our approach to be applicable to other combinations of evaluation techniques and a broad class of visualization applications.",Tanja Blascheck;Markus John;Kuno Kurzhals;Steffen Koch 0001;Thomas Ertl,Tanja Blascheck;Markus John;Kuno Kurzhals;Steffen Koch;Thomas Ertl,"Institute for Visualization and Interactive Systems (VIS), University of Stuttgart, Germany;Institute for Visualization and Interactive Systems (VIS), University of Stuttgart, Germany;Visualization Research Center, University of Stuttgart, Germany;Institute for Visualization and Interactive Systems (VIS), University of Stuttgart, Germany;Institute for Visualization and Interactive Systems (VIS), University of Stuttgart, Germany",10.1109/tvcg.2012.276;10.1109/tvcg.2013.124;10.1109/vast.2008.4677361;10.1109/vast.2009.5333878;10.1109/tvcg.2014.2346677;10.1109/vast.2010.5653598;10.1109/tvcg.2012.273;10.1109/visual.2005.1532837;10.1109/tvcg.2012.276,"visual analytics, qualitative evaluation, thinking aloud, interaction logs, eye tracking, time series data",,69.0,53.0,2679.0,HM,,visual analytics;thinking aloud protocols;recently eye;research researchers employed;derive common,0.6403;0.3537;0.2193;0.0892;0.0679,"[np.int64(-1), -1, -1, -1, -1]",201;-1;-1;-1;-1,201,201
VAST,2020,Diagnosing Concept Drift with Visual Analytics,10.1109/vast50239.2020.00007,http://dx.doi.org/10.1109/VAST50239.2020.00007,12.0,23.0,C,"Concept drift is a phenomenon in which the distribution of a data stream changes over time in unforeseen ways, causing prediction models built on historical data to become inaccurate. While a variety of automated methods have been developed to identify when concept drift occurs, there is limited support for analysts who need to understand and correct their models when drift is detected. In this paper, we present a visual analytics method, DriftVis, to support model builders and analysts in the identification and correction of concept drift in streaming data. DriftVis combines a distribution-based drift detection method with a streaming scatterplot to support the analysis of drift caused by the distribution changes of data streams and to explore the impact of these changes on the model’s accuracy. A quantitative experiment and two case studies on weather prediction and text classification have been conducted to demonstrate our proposed tool and illustrate how visual analytics can be used to support the detection, examination, and correction of concept drift.",Weikai Yang;Zhen Li 0044;Mengchen Liu;Yafeng Lu;Kelei Cao;Ross Maciejewski;Shixia Liu,Weikai Yang;Zhen Li;Mengchen Liu;Yafeng Lu;Kelei Cao;Ross Maciejewski;Shixia Liu,"School of Software, BNRist, Tsinghua University;School of Software, BNRist, Tsinghua University;Microsoft;Bloomberg L.P.;School of Software, BNRist, Tsinghua University;Computer Science, Arizona State University;School of Software, BNRist, Tsinghua University",10.1109/tvcg.2018.2864499;10.1109/tvcg.2017.2744878;10.1109/tvcg.2019.2934619;10.1109/vast50239.2020.00006;10.1109/tvcg.2018.2864504;10.1109/visual.2005.1532820;10.1109/tvcg.2017.2744158;10.1109/tvcg.2018.2865044;10.1109/tvcg.2018.2864838;10.1109/tvcg.2016.2598828;10.1109/tvcg.2016.2598838;10.1109/tvcg.2017.2744358;10.1109/tvcg.2019.2934267;10.1109/tvcg.2018.2864812;10.1109/vast.2017.8585721;10.1109/tvcg.2019.2934631;10.1109/tvcg.2016.2598831;10.1109/tvcg.2017.2744938;10.1109/vast.2018.8802509;10.1109/tvcg.2018.2865027;10.1109/tvcg.2018.2864500;10.1109/tvcg.2019.2934659;10.1109/tvcg.2018.2865043;10.1109/tvcg.2013.212;10.1109/tvcg.2017.2744683;10.1109/tvcg.2018.2864499,"Concept drift,streaming data,change detection,scatterplot,t-SNE.",16.0,21.0,76.0,1097.0,,,identify concept drift;weather prediction text;scatterplot support;model builders;correction,0.7139;0.3175;0.3137;0.1109;0.0434,"[np.int64(-1), -1, -1, -1, -1]",223;-1;-1;-1;-1,223,223
Vis,1996,The Design and Implementation of an Object-Oriented Toolkit for 3D Graphics and Visualization,10.1109/visual.1996.567752,http://doi.ieeecomputersociety.org/10.1109/VISUAL.1996.567752,93.0,100.0,C,"The Visualization Toolkit (vtk) is a freely available C++ class library for 3D graphics and visualization. We describe core characteristics of the toolkit. This includes a description of object oriented models for graphics and visualization; methods for synchronizing system execution; a summary of data representation schemes; the role of C++; issues in portability across PC and Unix systems; and how we automatically wrap the C++ class library with interpreted languages such as Java and Tcl. We also demonstrate the capabilities of the system for scalar, vector, tensor, and other visualization techniques.",William J. Schroeder;Ken Martin;William E. Lorensen,W.J. Schroeder;K.M. Martin;W.E. Lorensen,"GE Corp. Res. & Dev., USA;;",10.1109/visual.1993.398878;10.1109/visual.1994.346303;10.1109/visual.1992.235205;10.1109/visual.1995.480821,,402.0,95.0,0.0,150.0,TT,,3d graphics visualization;toolkit includes description;scalar;issues portability pc;methods synchronizing execution,0.6884;0.2728;0.1634;0.0733;0.0722,"[np.int64(-1), -1, -1, -1, -1]",110;-1;-1;-1;-1,110,110
Vis,2001,Wavelet representation of contour sets,10.1109/visual.2001.964525,http://dx.doi.org/10.1109/VISUAL.2001.964525,303.0,310.0,C,"We present a new wavelet compression and multiresolution modeling approach for sets of contours (level sets). In contrast to previous wavelet schemes, our algorithm creates a parametrization of a scalar field induced by its contours and compactly stores this parametrization rather than function values sampled on a regular grid. Our representation is based on hierarchical polygon meshes with subdivision connectivity whose vertices are transformed into wavelet coefficients. From this sparse set of coefficients, every set of contours can be efficiently reconstructed at multiple levels of resolution. When applying lossy compression, introducing high quantization errors, our method preserves contour topology, in contrast to compression methods applied to the corresponding field function. We provide numerical results for scalar fields defined on planar domains. Our approach generalizes to volumetric domains, time-varying contours, and level sets of vector fields.",Martin Bertram 0001;Daniel E. Laney;Mark A. Duchaineau;Charles D. Hansen;Bernd Hamann;Kenneth I. Joy,M. Bertram;D.E. Laney;M.A. Duchaineau;C.D. Hansen;B. Hamann;K.I. Joy,"Department of Computer Science, University of Kaiserslautern, Kaiserslautern, Germany and SCI Institute, University of Utah, Salt Lake, UT, USA;Center for Applied Scientific Computing CASC, Lawrence Livemore National Laboratory, Livermore, CA, USA;Center for Applied Scientific Computing CASC, Lawrence Livemore National Laboratory, Livermore, CA, USA;Center for Image Processing and Integrated Computing CIPIC Department of Computer Science, University of California, Davis, CA, USA;SCI Institute, University of Utah, Salt Lake, UT, USA;Center for Image Processing and Integrated Computing CIPIC Department of Computer Science, University of California, Davis, CA, USA",10.1109/visual.1994.346332;10.1109/visual.2000.885720;10.1109/visual.2000.885716;10.1109/visual.2000.885705;10.1109/visual.1994.346332,"Contours, Geometry Compression, Iso-surfaces, Level Sets, Multiresolution Methods, Wavelets",14.0,3.0,21.0,90.0,,,wavelet compression multiresolution;contours efficiently;fields defined planar;lossy;sets,0.5814;0.5136;0.1971;0.0804;0.0121,"[np.int64(-1), np.int64(-1), -1, -1, -1]",99;254;-1;-1;-1,99;254,99
Vis,2001,Case study: medical Web service for the automatic 3D documentation for neuroradiological diagnosis,10.1109/visual.2001.964542,http://dx.doi.org/10.1109/VISUAL.2001.964542,425.0,428.0,C,"The case study presents a medical Web service for the automatic analysis of CTA (computer tomography angiography) datasets. It aims at the detection and evaluation of intracranial aneurysms which are malformations of cerebral blood vessels. To obtain a standardized 3D visualization, digital videos are automatically generated. The time-consuming video production caused by the manual delineation of structures, software based volume rendering, and the interactive definition of an optimized camera path is considerably improved with a fully automatic strategy. Therefore, a previously suggested approach (C. Rezk-Salama, 2000) is applied which uses an optimized transfer function as a template and automatically adapts it to an individual dataset. Furthermore, we introduce hardware-accelerated morphologic filtering in order to detect the location of mid-size and giant aneurysms. The actual generation of the video is finally integrated into a hardware accelerated off-screen rendering process based on 3D texture mapping, ensuring fast visualization of high quality. Overall, clinical routine can be considerably assisted by providing a Web based service combining automatic detection and standardized visualization.",Sabine Iserhardt-Bauer;Peter Hastreiter;Thomas Ertl;K. Eberhardt;Bernd Tomandl,S. Iserhardt-Bauer;P. Hastreiter;T. Ertl;K. Eberhardt;B. Tomandl,"Visualization and Interactive Systems Group, University of Stuttgart, Germany;Neurocenter, University of Erlangen Nuremberg, Germany;Visualization and Interactive Systems Group, University of Stuttgart, Germany;Division of Neuroradiology, University of Erlangen Nuremberg, Germany;Division of Neuroradiology, University of Erlangen Nuremberg, Germany",10.1109/visual.2000.885729;10.1109/visual.2000.885729,"Medical visualization, segmentation, automatic web service, video generation",15.0,2.0,11.0,128.0,,,computer tomography angiography;based 3d texture;video production caused;based service combining;definition,0.5708;0.4086;0.1848;0.0836;0.0123,"[np.int64(-1), -1, -1, -1, -1]",133;-1;-1;-1;-1,133,133
VAST,2014,Transforming Scagnostics to Reveal Hidden Features,10.1109/tvcg.2014.2346572,http://dx.doi.org/10.1109/TVCG.2014.2346572,1624.0,1632.0,J,"Scagnostics (Scatterplot Diagnostics) were developed by Wilkinson et al. based on an idea of Paul and John Tukey, in order to discern meaningful patterns in large collections of scatterplots. The Tukeys' original idea was intended to overcome the impediments involved in examining large scatterplot matrices (multiplicity of plots and lack of detail). Wilkinson's implementation enabled for the first time scagnostics computations on many points as well as many plots. Unfortunately, scagnostics are sensitive to scale transformations. We illustrate the extent of this sensitivity and show how it is possible to pair statistical transformations with scagnostics to enable discovery of hidden structures in data that are not discernible in untransformed visualizations.",Dang Tuan Nhon;Leland Wilkinson,Tuan Nhon Dang;Leland Wilkinson,"Department of Computer Science, University of Illinois at Chicago;Department of Computer Science, University of Illinois at Chicago",10.1109/tvcg.2006.163;10.1109/infvis.2005.1532142;10.1109/tvcg.2013.187;10.1109/tvcg.2011.167;10.1109/vast.2006.261423;10.1109/tvcg.2010.184;10.1109/vast.2011.6102437;10.1109/vast.2007.4389006;10.1109/tvcg.2006.163,"Scagnostics, Scatterplot matrix, Transformation, High-Dimensional Visual Analytics",46.0,26.0,44.0,783.0,,,scatterplot diagnostics developed;sensitive scale transformations;patterns large collections;multiplicity;al,0.6910;0.4130;0.2866;0.1130;0.0049,"[np.int64(-1), -1, -1, -1, -1]",151;-1;-1;-1;-1,151,151
Vis,1995,"Defining, computing, and visualizing molecular interfaces",10.1109/visual.1995.480793,http://dx.doi.org/10.1109/VISUAL.1995.480793,36.0,,C,"A parallel, analytic approach for defining and computing the inter and intra molecular interfaces in three dimensions is described. The molecular interface surfaces are derived from approximations to the power diagrams over the participating molecular units. For a given molecular interface our approach can generate a family of interface surfaces parametrized by /spl alpha/ and /spl beta/, where /spl alpha/ is the radius of the solvent molecule (also known as the probe radius) and /spl beta/ is the interface radius that defines the size of the molecular interface. Molecular interface surfaces provide biochemists with a powerful tool to study surface complementarity and to efficiently characterize the interactions during a protein substrate docking. The complexity of our algorithm for molecular environments is O(nk log/sup 2/ k), where n is the number of atoms in the participating molecular units and k is the average number of neighboring atoms-a constant, given /spl alpha/ and /spl beta/.",Amitabh Varshney;Frederick P. Brooks Jr.;David C. Richardson;William V. Wright;Dinesh Manocha,A. Varshney;F.P. Brooks;D.C. Richardson;W.V. Wright;D. Manocha,"Department of Computer Science, State University of New York, Stony Brook, Stony Brook, NY, USA;Department of Computer Science, University of North Carolina, Chapel Hill, Chapel Hill, NC, USA;Department of Biochemistry, Duke University Medical Center, Durham, NC, USA;Department of Computer Science, University of North Carolina, Chapel Hill, Chapel Hill, NC, USA;Department of Computer Science, University of North Carolina, Chapel Hill, Chapel Hill, NC, USA",10.1109/visual.1993.398878;10.1109/visual.1993.398878,,45.0,7.0,19.0,91.0,,,molecular interface approach;docking complexity algorithm;parallel;environments nk;log sup number,0.7336;0.3866;0.0905;0.0317;-0.0299,"[np.int64(-1), -1, -1, -1, -1]",-1;-1;-1;-1;-1,,-1
Vis,1997,The multilevel finite element method for adaptive mesh optimization and visualization of volume data,10.1109/visual.1997.663907,http://dx.doi.org/10.1109/VISUAL.1997.663907,387.0,394.0,C,"Multilevel representations and mesh reduction techniques have been used for accelerating the processing and the rendering of large datasets representing scalar- or vector-valued functions defined on complex 2D or 3D meshes. We present a method based on finite element approximations which combines these two approaches in a new and unique way that is conceptually simple and theoretically sound. The main idea is to consider mesh reduction as an approximation problem in appropriate finite element spaces. Starting with a very coarse triangulation of the functional domain, a hierarchy of highly non-uniform tetrahedral (or triangular in 2D) meshes is generated adaptively by local refinement. This process is driven by controlling the local error of the piecewise linear finite element approximation of the function on each mesh element. A reliable and efficient computation of the global approximation error and a multilevel preconditioned conjugate gradient solver are the key components of the implementation. In order to analyze the properties and advantages of the adaptively generated tetrahedral meshes, we implemented two volume visualization algorithms: an iso-surface extractor and a ray-caster. Both algorithms, while conceptually simple, show significant speedups over conventional methods delivering comparable rendering quality from adaptively compressed datasets.",Roberto Grosso;Christoph Lürig;Thomas Ertl,R. Grosso;C. Lurig;T. Ertl,"Computer Graphics Group, Universität Erlangen Nürnberg, Germany;Computer Graphics Group, Universität Erlangen Nürnberg, Germany;Computer Graphics Group, Universität Erlangen Nürnberg, Germany",10.1109/visual.1996.568127;10.1109/visual.1996.568124;10.1109/visual.1995.480805;10.1109/visual.1996.568121;10.1109/visual.1993.398852;10.1109/visual.1995.480806;10.1109/visual.1996.567606;10.1109/visual.1996.568127,,133.0,38.0,32.0,281.0,,,mesh reduction techniques;multilevel representations;tetrahedral triangular 2d;scalar vector valued;approximation error,0.6374;0.3242;0.3191;0.1507;0.1277,"[np.int64(-1), -1, -1, -1, -1]",112;-1;-1;-1;-1,112,112
Vis,2009,Multimodal Vessel Visualization of Mouse Aorta PET/CT Scans,10.1109/tvcg.2009.169,http://dx.doi.org/10.1109/TVCG.2009.169,1515.0,1522.0,J,"In this paper, we present a visualization system for the visual analysis of PET/CT scans of aortic arches of mice. The system has been designed in close collaboration between researchers from the areas of visualization and molecular imaging with the objective to get deeper insights into the structural and molecular processes which take place during plaque development. Understanding the development of plaques might lead to a better and earlier diagnosis of cardiovascular diseases, which are still the main cause of death in the western world. After motivating our approach, we will briefly describe the multimodal data acquisition process before explaining the visualization techniques used. The main goal is to develop a system which supports visual comparison of the data of different species. Therefore, we have chosen a linked multi-view approach, which amongst others integrates a specialized straightened multipath curved planar reformation and a multimodal vessel flattening technique. We have applied the visualization concepts to multiple data sets, and we will present the results of this investigation.",Timo Ropinski;Sven Hermann;Rainer Reich;Michael Schäfers 0001;Klaus H. Hinrichs,Timo Ropinski;Sven Hermann;Rainer Reich;Michael Schafers;Klaus Hinrichs,"Visualization and Computer Graphics Research Group (VisCG), University of Münster, Germany;University of Münster, Germany;Visualization and Computer Graphics Research Group (VisCG), University of Münster, Germany;European Institute of Molecular Imaging, Germany;Visualization and Computer Graphics Research Group (VisCG), University of Münster, Germany",10.1109/visual.2003.1250353;10.1109/visual.1992.235203;10.1109/tvcg.2007.70576;10.1109/visual.2004.104;10.1109/visual.2003.1250384;10.1109/visual.2001.964538;10.1109/tvcg.2007.70560;10.1109/visual.2002.1183754;10.1109/visual.2003.1250396;10.1109/visual.2003.1250353,"Vessel visualization, plaque growth, multipath CPR, vessel flattening",42.0,22.0,36.0,501.0,,,multimodal vessel flattening;visual comparison data;plaques lead better;arches mice;development understanding development,0.6502;0.3413;0.2385;0.2274;0.0214,"[np.int64(-1), -1, -1, -1, -1]",225;-1;-1;-1;-1,225,225
Vis,2007,Topological Visualization of Brain Diffusion MRI Data,10.1109/tvcg.2007.70602,http://dx.doi.org/10.1109/TVCG.2007.70602,1496.0,1503.0,J,"Topological methods give concise and expressive visual representations of flow fields. The present work suggests a comparable method for the visualization of human brain diffusion MRI data. We explore existing techniques for the topological analysis of generic tensor fields, but find them inappropriate for diffusion MRI data. Thus, we propose a novel approach that considers the asymptotic behavior of a probabilistic fiber tracking method and define analogs of the basic concepts of flow topology, like critical points, basins, and faces, with interpretations in terms of brain anatomy. The resulting features are fuzzy, reflecting the uncertainty inherent in any connectivity estimate from diffusion imaging. We describe an algorithm to extract the new type of features, demonstrate its robustness under noise, and present results for two regions in a diffusion MRI dataset to illustrate that the method allows a meaningful visual analysis of probabilistic fiber tracking results.",Thomas Schultz 0001;Holger Theisel;Hans-Peter Seidel,Thomas Schultz;Holger Theisel;Hans-Peter Seidel,"MPI Informatik Saarbrücken, Saarbruecken, Germany;BieGraph Group, Bielefeld University, Germany;MPI Informatik Saarbrücken, Saarbruecken, Germany",10.1109/visual.1999.809894;10.1109/visual.2005.1532777;10.1109/visual.2005.1532841;10.1109/visual.1994.346326;10.1109/visual.2005.1532778;10.1109/visual.1994.346326;10.1109/visual.1999.809894,"Diffusion tensor, probabilistic fiber tracking, tensor topology, uncertainty visualization",64.0,42.0,32.0,477.0,,,brain diffusion mri;existing techniques topological;tensor fields;probabilistic fiber;define analogs,0.6290;0.4574;0.4072;0.3331;0.0629,"[np.int64(-1), -1, np.int64(-1), -1, -1]",43;-1;17;-1;-1,17;43,43
InfoVis,2020,Rainbows Revisited: Modeling Effective Colormap Design for Graphical Inference,10.1109/tvcg.2020.3030439,http://dx.doi.org/10.1109/TVCG.2020.3030439,1032.0,1042.0,J,"Color mapping is a foundational technique for visualizing scalar data. Prior literature offers guidelines for effective colormap design, such as emphasizing luminance variation while limiting changes in hue. However, empirical studies of color are largely focused on perceptual tasks. This narrow focus inhibits our understanding of how generalizable these guidelines are, particularly to tasks like visual inference that require synthesis and judgement across multiple percepts. Furthermore, the emphasis on traditional ramp designs (e.g., sequential or diverging) may sideline other key metrics or design strategies. We study how a cognitive metric-color name variation-impacts people's ability to make model-based judgments. In two graphical inference experiments, participants saw a series of color-coded scalar fields sampled from different models and assessed the relationships between these models. Contrary to conventional guidelines, participants were more accurate when viewing colormaps that cross a variety of uniquely nameable colors. We modeled participants' performance using this metric and found that it provides a better fit to the experimental data than do existing design principles. Our findings indicate cognitive advantages for colorful maps like rainbow, which exhibit high color categorization, despite their traditionally undesirable perceptual properties. We also found no evidence that color categorization would lead observers to infer false data features. Our results provide empirically grounded metrics for predicting a colormap's performance and suggest alternative guidelines for designing new quantitative colormaps to support inference. The data and materials for this paper are available at: https://osf.io/tck2r/",Khairi Reda;Danielle Albers Szafir,Khairi Reda;Danielle Albers Szafir,"University of Colorado, Boulder;University-Purdue University, Indianapolis",10.1109/visual.1995.480803;10.1109/tvcg.2011.192;10.1109/tvcg.2017.2743978;10.1109/tvcg.2016.2598918;10.1109/tvcg.2012.230;10.1109/tvcg.2014.2346325;10.1109/tvcg.2016.2599106;10.1109/visual.2001.964510;10.1109/tvcg.2015.2467471;10.1109/tvcg.2019.2934284;10.1109/tvcg.2017.2744359;10.1109/tvcg.2010.161;10.1109/visual.1995.480803,"Color,perception,graphical inference,scalar data",18.0,29.0,68.0,1151.0,,,cognitive metric color;variety uniquely nameable;traditional ramp designs;scalar fields sampled;series,0.6480;0.2149;0.1770;0.0889;0.0410,"[np.int64(-1), -1, -1, -1, -1]",24;-1;-1;-1;-1,24,24
Vis,1994,"Visualization and geographic information system integration: what are the needs and the requirements, if any?",10.1109/visual.1994.346284,http://dx.doi.org/10.1109/VISUAL.1994.346284,400.0,403.0,M,"Addresses the needs and requirements of integrating visualization and geographic information system technologies. There are three levels of integration methods: rudimentary, operational and functional. The rudimentary approach uses the minimum amount of data sharing and exchange between these two technologies. The operational level attempts to provide consistency of the data while removing redundancies between the two technologies. The functional form attempts to provide transparent communication between these respective software environments. At this level, the user only needs to request information and the integrated system retrieves or generates the information depending upon the request. This paper examines the role and impact of these three levels of integration. Stepping further into the future, the paper also questions the long-term survival of these separate disciplines.&lt;&lt;ETX&gt;&gt;",Theresa-Marie Rhyne;William Ivey;Loey Knapp;Peter Kochevar;Tom Mace,T.M. Rhyne;W. Ivey;L. Knapp;P. Kochevar;T. Mace,"Martin Marietta, U. S. EPA Visualization Center;SAS Institute, Inc.;IBM and University of Colorado, USA;DEC, San Diego Supercomputing Center;Scientific Computing Branch, U.S. EPA",,,29.0,2.0,3.0,112.0,,,integrating visualization geographic;technologies levels;minimum data sharing;retrieves generates;paper questions long,0.8077;0.2526;0.1851;-0.0067;-0.0702,"[np.int64(-1), -1, -1, -1, -1]",-1;-1;-1;-1;-1,,-1
InfoVis,2011,"Angular Histograms: Frequency-Based Visualizations for Large, High Dimensional Data",10.1109/tvcg.2011.166,http://dx.doi.org/10.1109/TVCG.2011.166,2572.0,2580.0,J,"Parallel coordinates is a popular and well-known multivariate data visualization technique. However, one of their inherent limitations has to do with the rendering of very large data sets. This often causes an overplotting problem and the goal of the visual information seeking mantra is hampered because of a cluttered overview and non-interactive update rates. In this paper, we propose two novel solutions, namely, angular histograms and attribute curves. These techniques are frequency-based approaches to large, high-dimensional data visualization. They are able to convey both the density of underlying polylines and their slopes. Angular histogram and attribute curves offer an intuitive way for the user to explore the clustering, linear correlations and outliers in large data sets without the over-plotting and clutter problems associated with traditional parallel coordinates. We demonstrate the results on a wide variety of data sets including real-world, high-dimensional biological data. Finally, we compare our methods with the other popular frequency-based algorithms.",Zhao Geng;Zhenmin Peng;Robert S. Laramee;Jonathan C. Roberts;Rick Walker,Zhao Geng;ZhenMin Peng;Robert S.Laramee;Jonathan C. Roberts;Rick Walker,"Visual Computing Group, Swansea University, UK;Visual Computing Group, Swansea University, UK;Swansea University, UK;Bangor University, UK;Visual Computing Group, Swansea University, UK",10.1109/infvis.2002.1173157;10.1109/infvis.2004.68;10.1109/tvcg.2006.138;10.1109/tvcg.2007.70535;10.1109/visual.1999.809866;10.1109/infvis.1996.559216;10.1109/visual.1990.146402;10.1109/tvcg.2010.184;10.1109/infvis.2005.1532138;10.1109/tvcg.2006.170;10.1109/tvcg.2008.131;10.1109/infvis.2002.1173157,"Parallel Coordinates, Angular Histogram, Attribute Curves",77.0,33.0,28.0,1702.0,,,multivariate data visualization;polylines slopes angular;frequency;causes overplotting;non interactive update,0.6891;0.3585;0.1235;0.0522;0.0134,"[np.int64(-1), -1, -1, -1, -1]",184;-1;-1;-1;-1,184,184
Vis,2010,VDVR: Verifiable Volume Visualization of Projection-Based Data,10.1109/tvcg.2010.211,http://dx.doi.org/10.1109/TVCG.2010.211,1515.0,1524.0,J,"Practical volume visualization pipelines are never without compromises and errors. A delicate and often-studied component is the interpolation of off-grid samples, where aliasing can lead to misleading artifacts and blurring, potentially hiding fine details of critical importance. The verifiable visualization framework we describe aims to account for these errors directly in the volume generation stage, and we specifically target volumetric data obtained via computed tomography (CT) reconstruction. In this case the raw data are the X-ray projections obtained from the scanner and the volume data generation process is the CT algorithm. Our framework informs the CT reconstruction process of the specific filter intended for interpolation in the subsequent visualization process, and this in turn ensures an accurate interpolation there at a set tolerance. Here, we focus on fast trilinear interpolation in conjunction with an octree-type mixed resolution volume representation without T-junctions. Efficient rendering is achieved by a space-efficient and locality-optimized representation, which can straightforwardly exploit fast fixed-function pipelines on GPUs.",Ziyi Zheng;Wei Xu 0020;Klaus Mueller 0001,Ziyi Zheng;Wei Xu;Klaus Mueller,"Center of Visual Computing, Stony Brook University, USA;Center of Visual Computing, Stony Brook University, USA;Center of Visual Computing, Stony Brook University, USA",10.1109/visual.1999.809908;10.1109/visual.1991.175805;10.1109/tvcg.2009.194;10.1109/tvcg.2006.141;10.1109/visual.1994.346331;10.1109/visual.2004.70;10.1109/tvcg.2009.149;10.1109/visual.1999.809908,"Direct volume rendering, computed tomography, filtered back-projection, verifiable visualization ",13.0,5.0,36.0,338.0,,,practical volume visualization;tomography ct reconstruction;filter intended interpolation;function pipelines gpus;exploit fast fixed,0.6427;0.4924;0.2875;0.2786;-0.0133,"[np.int64(-1), -1, -1, -1, -1]",84;-1;-1;-1;-1,84,84
Vis,1991,Designing a distributed scientific visualization tool,10.1109/visual.1991.175835,http://dx.doi.org/10.1109/VISUAL.1991.175835,383.0,386.0,C,"The benefits of using a distributed scientific visualization tool in the field of acoustic modeling are demonstrated. A user-friendly interface was developed under SunView. A Remote Procedure Call was used for transparent data transfer between a CRAY X-MP/28 and Sun 4 workstation. PV-WAVE, a high-level graphics package, was used to visualize the results.&lt;&lt;ETX&gt;&gt;",L. van der Sluis,L.V. Sluis,"Technology Applications, Inc.",,,1.0,0.0,4.0,42.0,,,acoustic modeling demonstrated;scientific visualization tool;sunview remote procedure;benefits using distributed;28 sun,0.6136;0.5654;0.2888;0.1511;-0.0143,"[np.int64(-1), np.int64(-1), -1, -1, -1]",26;149;-1;-1;-1,26;149,26
InfoVis,2004,Building Highly-Coordinated Visualizations in Improvise,10.1109/infvis.2004.12,http://dx.doi.org/10.1109/INFVIS.2004.12,159.0,166.0,C,"Improvise is a fully-implemented system in which users build and browse multiview visualizations interactively using a simple shared-object coordination mechanism coupled with a flexible, expression-based visual abstraction language. By coupling visual abstraction with coordination, users gain precise control over how navigation and selection in the visualization affects the appearance of data in individual views. As a result, it is practical to build visualizations with more views and richer coordination in Improvise than in other visualization systems. Building and browsing activities are integrated in a single, live user interface that lets users alter visualizations quickly and incrementally during data exploration",Chris E. Weaver,C. Weaver,"Computer Science Department, University of Wisconsin, Madison, USA",10.1109/infvis.2002.1173141;10.1109/infvis.2000.885086;10.1109/infvis.2002.1173141,"coordinated queries, coordination, exploratory visualization, multiple views, visual abstraction language",320.0,101.0,23.0,1026.0,,,visualizations interactively;build browse multiview;coordination mechanism coupled;expression;single live user,0.7397;0.4057;0.1154;0.0917;-0.0153,"[np.int64(-1), -1, -1, -1, -1]",194;-1;-1;-1;-1,194,194
Vis,2008,Visualizing Particle/Flow Structure Interactions in the Small Bronchial Tubes,10.1109/tvcg.2008.183,http://dx.doi.org/10.1109/TVCG.2008.183,1412.0,1427.0,J,"Particle deposition in the small bronchial tubes (generations six through twelve) is strongly influenced by the vortex-dominated secondary flows that are induced by axial curvature of the tubes. In this paper, we employ particle destination maps in conjunction with two-dimensional, finite-time Lyapunov exponent maps to illustrate how the trajectories of finite-mass particles are influenced by the presence of vortices. We consider two three-generation bronchial tube models: a planar, asymmetric geometry and a non-planar, asymmetric geometry. Our visualizations demonstrate that these techniques, coupled with judiciously seeded particle trajectories, are effective tools for studying particle/flow structure interactions.",Bela Soni;David S. Thompson;Raghu Machiraju,Bela Soni;David Thompson;Raghu Machiraju,"Graduate Research Assistant at the Computational Simulation and Design Center, Mississippi State University, USA;Department of Aerospace Engineering, Mississippi State University, USA;Department of Computer Science and Engineering, Ohio State Uinversity, USA",10.1109/tvcg.2007.70551;10.1109/tvcg.2007.70554;10.1109/tvcg.2007.70551,"FTLE, particle trajectory, visualization, bronchial tube",27.0,17.0,30.0,335.0,,,studying particle flow;generation bronchial tube;lyapunov exponent maps;geometry non planar;judiciously,0.5979;0.4257;0.2888;0.0252;0.0074,"[np.int64(-1), -1, -1, -1, -1]",38;-1;-1;-1;-1,38,38
VAST,2015,"The Role of Uncertainty, Awareness, and Trust in Visual Analytics",10.1109/tvcg.2015.2467591,http://dx.doi.org/10.1109/TVCG.2015.2467591,240.0,249.0,J,"Visual analytics supports humans in generating knowledge from large and often complex datasets. Evidence is collected, collated and cross-linked with our existing knowledge. In the process, a myriad of analytical and visualisation techniques are employed to generate a visual representation of the data. These often introduce their own uncertainties, in addition to the ones inherent in the data, and these propagated and compounded uncertainties can result in impaired decision making. The user's confidence or trust in the results depends on the extent of user's awareness of the underlying uncertainties generated on the system side. This paper unpacks the uncertainties that propagate through visual analytics systems, illustrates how human's perceptual and cognitive biases influence the user's awareness of such uncertainties, and how this affects the user's trust building. The knowledge generation model for visual analytics is used to provide a terminology and framework to discuss the consequences of these aspects in knowledge construction and though examples, machine uncertainty is compared to human trust measures with provenance. Furthermore, guidelines for the design of uncertainty-aware systems are presented that can aid the user in better decision making.",Dominik Sacha;Hansi Senaratne;Bum Chul Kwon;Geoffrey P. Ellis;Daniel A. Keim,Dominik Sacha;Hansi Senaratne;Bum Chul Kwon;Geoffrey Ellis;Daniel A. Keim,"Data Analysis and Visualisation Group, University of Konstanz;Data Analysis and Visualisation Group, University of Konstanz;Data Analysis and Visualisation Group, University of Konstanz;Data Analysis and Visualisation Group, University of Konstanz;Data Analysis and Visualisation Group, University of Konstanz",10.1109/tvcg.2014.2346575;10.1109/visual.2000.885679;10.1109/vast.2008.4677385;10.1109/vast.2009.5332611;10.1109/tvcg.2012.260;10.1109/vast.2011.6102473;10.1109/vast.2009.5333020;10.1109/vast.2011.6102435;10.1109/tvcg.2012.279;10.1109/tvcg.2014.2346481;10.1109/vast.2006.261416;10.1109/tvcg.2014.2346575,"Visual Analytics, Knowledge Generation, Uncertainty Measures and Propagation, Trust Building, Human Factors",261.0,180.0,83.0,4217.0,,,visual analytics systems;trust building knowledge;uncertainties result impaired;employed generate;terminology,0.5819;0.3769;0.3494;0.1029;0.0850,"[np.int64(-1), -1, -1, -1, -1]",201;-1;-1;-1;-1,201,201
InfoVis,2020,Responsive Matrix Cells: A Focus+Context Approach for Exploring and Editing Multivariate Graphs,10.1109/tvcg.2020.3030371,http://dx.doi.org/10.1109/TVCG.2020.3030371,1644.0,1654.0,J,"Matrix visualizations are a useful tool to provide a general overview of a graph's structure. For multivariate graphs, a remaining challenge is to cope with the attributes that are associated with nodes and edges. Addressing this challenge, we propose responsive matrix cells as a focus+context approach for embedding additional interactive views into a matrix. Responsive matrix cells are local zoomable regions of interest that provide auxiliary data exploration and editing facilities for multivariate graphs. They behave responsively by adapting their visual contents to the cell location, the available display space, and the user task. Responsive matrix cells enable users to reveal details about the graph, compare node and edge attributes, and edit data values directly in a matrix without resorting to external views or tools. We report the general design considerations for responsive matrix cells covering the visual and interactive means necessary to support a seamless data exploration and editing. Responsive matrix cells have been implemented in a web-based prototype based on which we demonstrate the utility of our approach. We describe a walk-through for the use case of analyzing a graph of soccer players and report on insights from a preliminary user feedback session.",Tom Horak;Philip Berger;Heidrun Schumann;Raimund Dachselt;Christian Tominski,Tom Horak;Philip Berger;Heidrun Schumann;Raimund Dachselt;Christian Tominski,"Interactive Media Lab, Technische Universitat Dresden;Inst. for Visual & Analytic Computing, University of Rostock;Inst. for Visual & Analytic Computing, University of Rostock;Interactive Media Lab, Technische Universitat Dresden;Inst. for Visual & Analytic Computing, University of Rostock",10.1109/tvcg.2006.120;10.1109/tvcg.2017.2743990;10.1109/tvcg.2014.2346575;10.1109/tvcg.2011.213;10.1109/tvcg.2007.70582;10.1109/infvis.2004.2;10.1109/tvcg.2008.109;10.1109/tvcg.2018.2865151;10.1109/infvis.2002.1173149;10.1109/tvcg.2009.151;10.1109/tvcg.2018.2865149;10.1109/tvcg.2014.2346279;10.1109/tvcg.2017.2745219;10.1109/tvcg.2014.2346441;10.1109/tvcg.2015.2467202;10.1109/tvcg.2006.120,"Multivariate graph visualization,matrix visualization,focus+context,embedded visualizations,responsive visualization,graph editing",7.0,14.0,83.0,1479.0,,,matrix visualizations;node edge attributes;editing responsive;soccer players report;contents cell,0.6361;0.3167;0.2746;0.1788;0.1482,"[np.int64(-1), -1, -1, -1, -1]",261;-1;-1;-1;-1,261,261
Vis,1990,Personal visualization system: applications in research and engineering,10.1109/visual.1990.146418,http://dx.doi.org/10.1109/VISUAL.1990.146418,443.0,,C,"The authors describe an innovative personal visualization system and its application to several research and engineering problems. The system bridges both hardware and software components to permit a user to graphically describe a visualization problem to the computer; thereby reducing program development time to a few hours. Low-cost visualization is achieved using PC-based software that can either be executed on a PC or drive graphic workstations for high-resolution displays. In either case, supercomputer computation rates are available for the visualization process. On PCs this is done with one or more PiP plug in cards, each of which is capable of 100 million floating point operations per second. On workstations this is done with the QUEN array processor. Applications mentioned include: ocean wave imaging; characterizing superconductors; and solar sail visualization.&lt;&lt;ETX&gt;&gt;",Quentin E. Dolecek;K. Moorjani;B. F. Kim;D. G. Tilley;Thomas S. Denney Jr.,Q.E. Dolecek;K. Moorjani;B.F. Kim;D.G. Tilley;T.S. Denney,"Applied Physics Laboratory, Johns Hopkins University, Laurel, MD, USA;Applied Physics Laboratory, Johns Hopkins University, Laurel, MD, USA;Applied Physics Laboratory, Johns Hopkins University, Laurel, MD, USA;Applied Physics Laboratory, Johns Hopkins University, Laurel, MD, USA;Applied Physics Laboratory, Johns Hopkins University, Laurel, MD, USA",,,0.0,0.0,9.0,54.0,,,solar sail visualization;resolution displays;characterizing superconductors;software executed pc;authors innovative personal,0.6115;0.2156;0.1910;0.1628;0.0885,"[np.int64(-1), -1, -1, -1, -1]",153;-1;-1;-1;-1,153,153
Vis,2000,New techniques for topologically correct surface reconstruction,10.1109/visual.2000.885718,http://dx.doi.org/10.1109/VISUAL.2000.885718,373.0,380.0,C,"We present a novel approach to surface reconstruction based on the Delaunay complex. First we give a simple and fast algorithm that picks locally a surface at each vertex. For that, we introduce the concept of /spl lambda/-intervals. It turns out that for smooth regions of the surface this method works very well and at difficult parts of the surface yields an output well-suited for postprocessing. As a postprocessing step we propose a topological clean up and a new technique based on linear programming in order to establish a topologically correct surface. These techniques should be useful also for many other reconstruction schemes.",Udo Adamy;Joachim Giesen;Matthias John 0003,U. Adamy;J. Giesen;M. John,"Institute of Theoretical Computer Science, Zurich, Switzerland;Institute of Theoretical Computer Science, Switzerland;Institute of Theoretical Computer Science, Switzerland",10.1109/visual.1998.745286;10.1109/visual.1998.745286,"surface reconstruction, gabriel graph, linear programming, topology",65.0,12.0,18.0,85.0,,,reconstruction based delaunay;topologically correct surface;complex simple;postprocessing postprocessing step;picks,0.7101;0.4721;0.1995;0.0687;0.0191,"[np.int64(-1), -1, -1, -1, -1]",102;-1;-1;-1;-1,102,102
Vis,2011,Interactive Multiscale Tensor Reconstruction for Multiresolution Volume Visualization,10.1109/tvcg.2011.214,http://dx.doi.org/10.1109/TVCG.2011.214,2135.0,2143.0,J,"Large scale and structurally complex volume datasets from high-resolution 3D imaging devices or computational simulations pose a number of technical challenges for interactive visual analysis. In this paper, we present the first integration of a multiscale volume representation based on tensor approximation within a GPU-accelerated out-of-core multiresolution rendering framework. Specific contributions include (a) a hierarchical brick-tensor decomposition approach for pre-processing large volume data, (b) a GPU accelerated tensor reconstruction implementation exploiting CUDA capabilities, and (c) an effective tensor-specific quantization strategy for reducing data transfer bandwidth and out-of-core memory footprint. Our multiscale representation allows for the extraction, analysis and display of structural features at variable spatial scales, while adaptive level-of-detail rendering methods make it possible to interactively explore large datasets within a constrained memory footprint. The quality and performance of our prototype system is evaluated on large structurally complex datasets, including gigabyte-sized micro-tomographic volumes.",Susanne K. Suter;José Antonio Iglesias Guitián;Fabio Marton;Marco Agus;Andreas Elsener;Christoph P. E. Zollikofer;Meenakshisundaram Gopi;Enrico Gobbetti;Renato Pajarola,Susanne K. Suter;Jose A. Iglesias Guitian;Fabio Marton;Marco Agus;Andreas Elsener;Christoph P.E. Zollikofer;M. Gopi;Enrico Gobbetti;Renato Pajarola,"University of Zurich, Switzerland;CRS4, Italy;CRS4, Italy;CRS4, Italy;University of Zurich, Switzerland;University of Zurich, Switzerland;University of California, Irvine, USA;CRS4, Italy;University of Zurich, Switzerland",10.1109/visual.2002.1183757;10.1109/visual.1997.663900;10.1109/tvcg.2007.70516;10.1109/visual.1998.745311;10.1109/tvcg.2006.146;10.1109/visual.2003.1250385;10.1109/visual.2002.1183757,"GPU/CUDA, multiscale, tensor reconstruction, interactive volume visualization, multiresolution rendering",63.0,39.0,28.0,838.0,,,volume data gpu;scale structurally complex;specific quantization strategy;including;prototype evaluated,0.6273;0.3216;0.1969;-0.0108;-0.0184,"[np.int64(-1), -1, -1, -1, -1]",255;-1;-1;-1;-1,255,255
InfoVis,2004,Value and Relation Display for Interactive Exploration of High Dimensional Datasets,10.1109/infvis.2004.71,http://dx.doi.org/10.1109/INFVIS.2004.71,73.0,80.0,C,"Traditional multidimensional visualization techniques, such as glyphs, parallel coordinates and scatterplot matrices, suffer from clutter at the display level and difficult user navigation among dimensions when visualizing high dimensional datasets. In this paper, we propose a new multidimensional visualization technique named a value and relation (VaR) display, together with a rich set of navigation and selection tools, for interactive exploration of datasets with up to hundreds of dimensions. By explicitly conveying the relationships among the dimensions of a high dimensional dataset, the VaR display helps users grasp the associations among dimensions. By using pixel-oriented techniques to present values of the data items in a condensed manner, the VaR display reveals data patterns in the dataset using as little screen space as possible. The navigation and selection tools enable users to interactively reduce clutter, navigate within the dimension space, and examine data value details within context effectively and efficiently. The VaR display scales well to datasets with large numbers of data items by employing sampling and texture mapping. A case study on a real dataset, as well as the VaR displays of multiple real datasets throughout the paper, reveals how our proposed approach helps users interactively explore high dimensional datasets with large numbers of data items",Jing Yang 0001;Anilkumar Patro;Shiping Huang;Nishant K. Mehta;Matthew O. Ward;Elke A. Rundensteiner,Jing Yang;A. Patro;Shiping Huang;N. Mehta;M.O. Ward;E.A. Rundensteiner,"Computer Science Department, Worcester Polytechnic Institute, Worcester, MA, USA;Computer Science Department, Worcester Polytechnic Institute, Worcester, MA, USA;Computer Science Department, Worcester Polytechnic Institute, Worcester, MA, USA;Computer Science Department, Worcester Polytechnic Institute, Worcester, MA, USA;Computer Science Department, Worcester Polytechnic Institute, Worcester, MA, USA;Computer Science Department, Worcester Polytechnic Institute, Worcester, MA, USA",10.1109/infvis.1998.729559;10.1109/infvis.2003.1249015;10.1109/visual.1994.346302;10.1109/infvis.2003.1249014;10.1109/infvis.1995.528686;10.1109/visual.1995.485140;10.1109/infvis.1998.729559,"Multi-dimensional visualization, pixel-oriented, multi-dimensional scaling, high dimensional datasets",85.0,18.0,24.0,517.0,,,traditional multidimensional visualization;display reveals data;named value relation;helps users;set,0.7105;0.3073;0.2377;0.2026;0.0241,"[np.int64(-1), -1, -1, -1, -1]",182;-1;-1;-1;-1,182,182
Vis,2002,Case study: Visualizing ocean flow vertical motions using Lagrangian-Eulerian time surfaces,10.1109/visual.2002.1183822,http://dx.doi.org/10.1109/VISUAL.2002.1183822,529.0,532.0,C,"Ocean model simulations commonly assume the ocean is hydrostatic, resulting in near zero vertical motion. The vertical motion found is typically associated with the variations of the thermocline depth over time, which are mainly a result of the development and movement of ocean fronts, eddies, and internal waves. A new technique, extended from Lagrangian-Eulerian Advection, is presented to help understand the variation of vertical motion associated with the change in thermocline depth over time. A time surface is correctly deformed in a single direction according to the flow. The evolution of the time surface is computed via a mixture of Eulerian and Lagrangian techniques. The dominant horizontal motion is textured onto the surface using texture advection, while both the horizontal and vertical motions are used to displace the surface. The resulting surface is shaded for enhanced contrast. Timings indicate that the overhead over standard 2D texture advection is no more than 12%.",Josh Grant;Gordon Erlebacher;James F. O'Brien,J. Grant;G. Erlebacher;J. O'Brien,"Center for Ocean-Atmospheric Prediction Studies, Florida State University, USA;School of Computational Science and Information Technology, Florida State University, USA;Center for Ocean-Atmospheric Prediction Studies, Florida State University, USA",10.1109/visual.1999.809895;10.1109/visual.2001.964493;10.1109/visual.2000.885688;10.1109/visual.1996.568149;10.1109/visual.1999.809895,"unsteady vector fields, time surfaces, ocean currents, vertical velocity",18.0,5.0,16.0,122.0,,,ocean model simulations;horizontal motion textured;associated change thermocline;eulerian lagrangian techniques;evolution time,0.5942;0.5057;0.3400;0.2878;0.1801,"[np.int64(-1), np.int64(-1), -1, -1, -1]",48;-1;-1;-1;-1,48,48
InfoVis,2014,Activity Sculptures: Exploring the Impact of Physical Visualizations on Running Activity,10.1109/tvcg.2014.2352953,http://dx.doi.org/10.1109/TVCG.2014.2352953,2201.0,2210.0,J,"Data sculptures are a promising type of visualizations in which data is given a physical form. In the past, they have mostly been used for artistic, communicative or educational purposes, and designers of data sculptures argue that in such situations, physical visualizations can be more enriching than pixel-based visualizations. We present the design of Activity Sculptures: data sculptures of running activity. In a three-week field study we investigated the impact of the sculptures on 14 participants' running activity, the personal and social behaviors generated by the sculptures, as well as participants' experiences when receiving these individual physical tokens generated from the specific data of their runs. The physical rewards generated curiosity and personal experimentation but also social dynamics such as discussion on runs or envy/competition. We argue that such passive (or calm) visualizations can complement nudging and other mechanisms of persuasion with a more playful and reflective look at ones' activity.",Simon Stusak;Aurélien Tabard;Franziska Sauka;Rohit Ashok Khot;Andreas Butz,Simon Stusak;Aurélien Tabard;Franziska Sauka;Rohit Ashok Khot;Andreas Butz,"University of Munich (LMU);Université de Lyon & CNRS, Université Lyon 1, LIRIS, UMR5205, France;University of Munich (LMU);Exertion Games Lab, RMIT University;University of Munich (LMU)",10.1109/tvcg.2007.70541;10.1109/infvis.2003.1249031;10.1109/tvcg.2013.134;10.1109/tvcg.2007.70541,"Physical Visualizations, Activity Sculptures, Physical Activity, Data Sculptures, Behavioral Change",122.0,67.0,41.0,1566.0,,,activity sculptures;individual physical tokens;specific data runs;argue;past used,0.6085;0.1899;0.1848;0.1780;0.1123,"[np.int64(-1), -1, -1, -1, -1]",-1;-1;-1;-1;-1,,-1
Vis,2000,Geometric compression for interactive transmission,10.1109/visual.2000.885711,http://dx.doi.org/10.1109/VISUAL.2000.885711,319.0,326.0,C,"The compression of geometric structures is a relatively new field of data compression. Since about 1995, several articles have dealt with the coding of meshes, using for most of them the following approach: the vertices of the mesh are coded in an order that partially contains the topology of the mesh. In the same time, some simple rules attempt to predict the position of each vertex from the positions of its neighbors that have been previously coded. We describe a compression algorithm whose principle is completely different: the coding order of the vertices is used to compress their coordinates, and then the topology of the mesh is reconstructed from the vertices. This algorithm achieves compression ratios that are slightly better than those of the currently available algorithms, and moreover, it allows progressive and interactive transmission of the meshes.",Olivier Devillers;Pierre-Marie Gandoin,O. Devillers;P.-M. Gandoin,"INRIA, Sophia-Antipolis, France;INRIA, Sophia-Antipolis, France",10.1109/visual.1997.663902;10.1109/visual.1999.809902;10.1109/vis.1999.10000;10.1109/visual.1997.663902,"geometry, compression, coding, interactivity, mesh, reconstruction, terrain models",187.0,76.0,18.0,339.0,,,compression geometric structures;mesh coded order;articles dealt coding;attempt predict position;completely different,0.6875;0.5249;0.1711;0.0919;-0.0491,"[np.int64(-1), np.int64(-1), -1, -1, -1]",80;253;-1;-1;-1,80;253,80
Vis,2024,Sportify: Question Answering with Embedded Visualizations and Personified Narratives for Sports Video,10.1109/tvcg.2024.3456332,http://dx.doi.org/10.1109/TVCG.2024.3456332,12.0,22.0,J,"As basketball's popularity surges, fans often find themselves confused and overwhelmed by the rapid game pace and complexity. Basketball tactics, involving a complex series of actions, require substantial knowledge to be fully understood. This complexity leads to a need for additional information and explanation, which can distract fans from the game. To tackle these challenges, we present Sportify, a Visual Question Answering system that integrates narratives and embedded visualization for demystifying basketball tactical questions, aiding fans in understanding various game aspects. We propose three novel action visualizations (i.e., Pass, Cut, and Screen) to demonstrate critical action sequences. To explain the reasoning and logic behind players' actions, we leverage a large-language model (LLM) to generate narratives. We adopt a storytelling approach for complex scenarios from both first and third-person perspectives, integrating action visualizations. We evaluated Sportify with basketball fans to investigate its impact on understanding of tactics, and how different personal perspectives of narratives impact the understanding of complex tactic with action visualizations. Our evaluation with basketball fans demonstrates Sportify's capability to deepen tactical insights and amplify the viewing experience. Furthermore, third-person narration assists people in getting in-depth game explanations while first-person narration enhances fans' game engagement.",Chunggi Lee;Tica Lin;Hanspeter Pfister;Zhu-Tian Chen,Chunggi Lee;Tica Lin;Hanspeter Pfister;Chen Zhu-Tian,"John A. Paulson School of Engineering and Applied Sciences, Harvard University, Cambridge, MA, USA;John A. Paulson School of Engineering and Applied Sciences, Harvard University, Cambridge, MA, USA;John A. Paulson School of Engineering and Applied Sciences, Harvard University, Cambridge, MA, USA;CSE department, University of Minnesota, Minneapolis, MN, USA",10.1109/tvcg.2020.3030358;10.1109/tvcg.2021.3114861;10.1109/vast.2014.7042478;10.1109/tvcg.2023.3326910;10.1109/tvcg.2023.3327161;10.1109/tvcg.2022.3209353;10.1109/tvcg.2013.192;10.1109/tvcg.2010.179;10.1109/tvcg.2023.3327197;10.1109/tvcg.2017.2745181;10.1109/tvcg.2019.2934630;10.1109/tvcg.2016.2598608;10.1109/tvcg.2022.3209373;10.1109/tvcg.2021.3114806,"Embedded Visualization,Narrative and storytelling,,,Basketball tactic,Question-answering (QA) system",,0.0,67.0,387.0,,,visualization demystifying basketball;answering integrates narratives;large language model;sportify capability;complex series actions,0.6367;0.4268;0.3013;0.1476;0.0899,"[np.int64(-1), -1, -1, -1, -1]",158;-1;-1;-1;-1,158,158
Vis,2001,Nonmanifold subdivision,10.1109/visual.2001.964528,http://dx.doi.org/10.1109/VISUAL.2001.964528,325.0,332.0,C,"Commonly-used subdivision schemes require manifold control meshes and produce manifold surfaces. However, it is often necessary to model nonmanifold surfaces, such as several surface patches meeting at a common boundary. In this paper, we describe a subdivision algorithm that makes it possible to model nonmanifold surfaces. Any triangle mesh, subject only to the restriction that no two vertices of any triangle coincide, can serve as an input to the algorithm. Resulting surfaces consist of collections of manifold patches joined along nonmanifold curves and vertices. If desired, constraints may be imposed on the tangent planes of manifold patches sharing a curve or a vertex. The algorithm is an extension of a well-known Loop subdivision scheme, and uses techniques developed for piecewise smooth surfaces.",Lexing Ying;Denis Zorin,Lexing Ying;D. Zorin,"New York University, USA;New York University, USA",10.1109/visual.1999.809870,"Subdivision surfaces, Nonmanifold surfaces, Geometric modeling",,3.0,17.0,88.0,,,manifold control meshes;subdivision scheme uses;surfaces triangle;piecewise;common,0.6513;0.4492;0.3928;0.2378;-0.0296,"[np.int64(-1), -1, -1, -1, -1]",5;-1;-1;-1;-1,5,5
VAST,2015,MobilityGraphs: Visual Analysis of Mass Mobility Dynamics via Spatio-Temporal Graphs and Clustering,10.1109/tvcg.2015.2468111,http://dx.doi.org/10.1109/TVCG.2015.2468111,11.0,20.0,J,"Learning more about people mobility is an important task for official decision makers and urban planners. Mobility data sets characterize the variation of the presence of people in different places over time as well as movements (or flows) of people between the places. The analysis of mobility data is challenging due to the need to analyze and compare spatial situations (i.e., presence and flows of people at certain time moments) and to gain an understanding of the spatio-temporal changes (variations of situations over time). Traditional flow visualizations usually fail due to massive clutter. Modern approaches offer limited support for investigating the complex variation of the movements over longer time periods. We propose a visual analytics methodology that solves these issues by combined spatial and temporal simplifications. We have developed a graph-based method, called MobilityGraphs, which reveals movement patterns that were occluded in flow maps. Our method enables the visual representation of the spatio-temporal variation of movements for long time series of spatial situations originally containing a large number of intersecting flows. The interactive system supports data exploration from various perspectives and at various levels of detail by interactive setting of clustering parameters. The feasibility our approach was tested on aggregated mobility data derived from a set of geolocated Twitter posts within the Greater London city area and mobile phone call data records in Abidjan, Ivory Coast. We could show that MobilityGraphs support the identification of regular daily and weekly movement patterns of resident population.",Tatiana von Landesberger;Felix Brodkorb;Philipp Roskosch;Natalia V. Andrienko;Gennady L. Andrienko;Andreas Kerren,Tatiana von Landesberger;Felix Brodkorb;Philipp Roskosch;Natalia Andrienko;Gennady Andrienko;Andreas Kerren,"Technical University of Darmstadt, Germany;Technical University of Darmstadt, Germany;Technical University of Darmstadt, Germany;Fraunhofer IAIS, City University, London, UK;Fraunhofer IAIS, City University, London, UK;Fraunhofer IAIS, City University, London, UK",10.1109/tvcg.2011.202;10.1109/tvcg.2011.226;10.1109/tvcg.2011.233;10.1109/infvis.2004.18;10.1109/tvcg.2009.143;10.1109/tvcg.2014.2346271;10.1109/tvcg.2008.125;10.1109/tvcg.2014.2346441;10.1109/infvis.1999.801851;10.1109/vast.2012.6400553;10.1109/vast.2009.5333893;10.1109/infvis.2005.1532150;10.1109/tvcg.2011.202,"Visual analytics, movement data, networks, graphs, temporal aggregation, spatial aggregation, flows, clustering",211.0,159.0,56.0,4670.0,,,analysis mobility data;traditional flow visualizations;simplifications;method enables visual;different,0.6385;0.4922;0.1218;0.0676;0.0297,"[np.int64(-1), -1, -1, -1, -1]",67;-1;-1;-1;-1,67,67
InfoVis,2001,"2D vs 3D, implications on spatial memory",10.1109/infvis.2001.963291,http://dx.doi.org/10.1109/INFVIS.2001.963291,139.0,145.0,C,"Since the introduction of graphical user interfaces (GUI) and two-dimensional (2D) displays, the concept of space has entered the information technology (IT) domain. Interactions with computers were re-encoded in terms of fidelity to the interactions with real environment and consequently in terms of fitness to cognitive and spatial abilities. A further step in this direction was the creation of three-dimensional (3D) displays which have amplified the fidelity of digital representations. However, there are no systematic results evaluating the extent to which 3D displays better support cognitive spatial abilities. The aim of this research is to empirically investigate spatial memory performance across different instances of 2D and 3D displays. Two experiments were performed. The displays used in the experimental situation represented hierarchical information structures. The results of the test show that the 3D display does improve performances in the designed spatial memory task.",Monica Tavanti;Mats Lind,M. Tavanti;M. Lind,"Department of Information Science, University of Uppsala, Sweden;Department of Information Science, University of Uppsala, Sweden",,,203.0,64.0,11.0,1036.0,,,support cognitive spatial;3d displays experiments;information technology domain;performance different;consequently terms,0.6517;0.5365;0.2360;0.1848;0.0253,"[np.int64(-1), np.int64(-1), -1, -1, -1]",305;238;-1;-1;-1,238;305,305
VAST,2009,Combining automated analysis and visualization techniques for effective exploration of high-dimensional data,10.1109/vast.2009.5332628,http://dx.doi.org/10.1109/VAST.2009.5332628,59.0,66.0,C,"Visual exploration of multivariate data typically requires projection onto lower-dimensional representations. The number of possible representations grows rapidly with the number of dimensions, and manual exploration quickly becomes ineffective or even unfeasible. This paper proposes automatic analysis methods to extract potentially relevant visual structures from a set of candidate visualizations. Based on features, the visualizations are ranked in accordance with a specified user task. The user is provided with a manageable number of potentially useful candidate visualizations, which can be used as a starting point for interactive data analysis. This can effectively ease the task of finding truly useful visualizations and potentially speed up the data exploration task. In this paper, we present ranking measures for class-based as well as non class-based Scatterplots and Parallel Coordinates visualizations. The proposed analysis methods are evaluated on different datasets.",Andrada Tatu;Georgia Albuquerque;Martin Eisemann;Jörn Schneidewind;Holger Theisel;Marcus A. Magnor;Daniel A. Keim,Andrada Tatu;Georgia Albuquerque;Martin Eisemann;Jorn Schneidewind;Holger Theisel;Marcus Magnork;Daniel Keim,"University of Konstanz, Germany;TU Braunschweig, Germany;TU Braunschweig, Germany;Telefonica o2 Business Intelligence Center, Germany;University of Magdeburg, Germany;Technische Universitat Braunschweig, Braunschweig, Niedersachsen, DE;University of Konstanz, Germany",10.1109/infvis.2005.1532142;10.1109/infvis.1998.729559;10.1109/infvis.2003.1249017;10.1109/visual.1994.346302;10.1109/vast.2006.261423;10.1109/infvis.2005.1532142,,119.0,98.0,25.0,1325.0,,,visual exploration multivariate;class based;number dimensions manual;lower;ineffective unfeasible paper,0.7083;0.1922;0.1920;0.0384;0.0343,"[np.int64(-1), -1, -1, -1, -1]",257;-1;-1;-1;-1,257,257
VAST,2014,Visual Analytics for Complex Engineering Systems: Hybrid Visual Steering of Simulation Ensembles,10.1109/tvcg.2014.2346744,http://dx.doi.org/10.1109/TVCG.2014.2346744,1803.0,1812.0,J,"In this paper we propose a novel approach to hybrid visual steering of simulation ensembles. A simulation ensemble is a collection of simulation runs of the same simulation model using different sets of control parameters. Complex engineering systems have very large parameter spaces so a naïve sampling can result in prohibitively large simulation ensembles. Interactive steering of simulation ensembles provides the means to select relevant points in a multi-dimensional parameter space (design of experiment). Interactive steering efficiently reduces the number of simulation runs needed by coupling simulation and visualization and allowing a user to request new simulations on the fly. As system complexity grows, a pure interactive solution is not always sufficient. The new approach of hybrid steering combines interactive visual steering with automatic optimization. Hybrid steering allows a domain expert to interactively (in a visualization) select data points in an iterative manner, approximate the values in a continuous region of the simulation space (by regression) and automatically find the “best” points in this continuous region based on the specified constraints and objectives (by optimization). We argue that with the full spectrum of optimization options, the steering process can be improved substantially. We describe an integrated system consisting of a simulation, a visualization, and an optimization component. We also describe typical tasks and propose an interactive analysis workflow for complex engineering systems. We demonstrate our approach on a case study from automotive industry, the optimization of a hydraulic circuit in a high pressure common rail Diesel injection system.",Kresimir Matkovic;Denis Gracanin;Rainer Splechtna;Mario Jelovic;Benedikt Stehno;Helwig Hauser;Werner Purgathofer,Kreŝimir Matković;Denis Gračanin;Rainer Splechtna;Mario Jelović;Benedikt Stehno;Helwig Hauser;Werner Purgathofer,"VRVis Research Center, Vienna, Austria;Virginia Tech, Blacksburg, VA, USA;VRVis Research Center, Vienna, Austria;AVL-AST Zagreb, Croatia;VRVis Research Center, Vienna, Austria;University of Bergen, Norway;Vienna University of Technology, Austria",10.1109/tvcg.2010.223;10.1109/tvcg.2012.280;10.1109/tvcg.2008.145;10.1109/tvcg.2009.110;10.1109/tvcg.2010.171;10.1109/vast.2009.5333081;10.1109/vast.2010.5651694;10.1109/tvcg.2010.223,"Interactive Visual Analysis, Integrated Design Environment, Simulation, Visual Steering, Automatic Optimization",31.0,25.0,42.0,946.0,,,simulation visualization optimization;steering automatic;domain expert;pressure common rail;argue spectrum,0.6506;0.2198;0.1953;0.1457;-0.0060,"[np.int64(-1), -1, -1, -1, -1]",-1;-1;-1;-1;-1,,-1
Vis,2023,A Local Iterative Approach for the Extraction of 2D Manifolds from Strongly Curved and Folded Thin-Layer Structures,10.1109/tvcg.2023.3327403,http://dx.doi.org/10.1109/TVCG.2023.3327403,1260.0,1270.0,J,"Ridge surfaces represent important features for the analysis of 3-dimensional (3D) datasets in diverse applications and are often derived from varying underlying data including flow fields, geological fault data, and point data, but they can also be present in the original scalar images acquired using a plethora of imaging techniques. Our work is motivated by the analysis of image data acquired using micro-computed tomography ($\mu\text{CT}$) of ancient, rolled and folded thin-layer structures such as papyrus, parchment, and paper as well as silver and lead sheets. From these documents we know that they are 2-dimensional (2D) in nature. Hence, we are particularly interested in reconstructing 2D manifolds that approximate the document's structure. The image data from which we want to reconstruct the 2D manifolds are often very noisy and represent folded, densely-layered structures with many artifacts, such as ruptures or layer splitting and merging. Previous ridge-surface extraction methods fail to extract the desired 2D manifold for such challenging data. We have therefore developed a novel method to extract 2D manifolds. The proposed method uses a local fast marching scheme in combination with a separation of the region covered by fast marching into two sub-regions. The 2D manifold of interest is then extracted as the surface separating the two sub-regions. The local scheme can be applied for both automatic propagation as well as interactive analysis. We demonstrate the applicability and robustness of our method on both artificial data as well as real-world data including folded silver and papyrus sheets.",Nicolas Klenert;Verena Lepper;Daniel Baum,Nicolas Klenert;Verena Lepper;Daniel Baum,"Zuse Institute Berlin, Germany;Agyptisches Museum und Papyrussammlung, Germany;Zuse Institute Berlin, Germany",0.1109/tvcg.2009.177;10.1109/tvcg.2007.70554,"Ridge surface,crease surface,2D manifold extraction,fast marching,virtual unfolding,historical documents",,0.0,42.0,226.0,,,ridge surface extraction;ruptures layer;fast marching sub;ancient;sheets documents,0.6400;0.2615;0.1886;0.1355;0.1352,"[np.int64(-1), -1, -1, -1, -1]",91;-1;-1;-1;-1,91,91
Vis,2002,Computing singularities of 3D vector fields with geometric algebra,10.1109/visual.2002.1183786,http://dx.doi.org/10.1109/VISUAL.2002.1183786,283.0,289.0,C,"Critical points of a vector field are key to their characterization. Their positions as well as their indexes are crucial for understanding vector fields. Considerable work exists in 2D, but less is available for 3D or higher dimensions. Geometric algebra is a derivative of Clifford algebra that not only enables a succinct definition of the index of a critical point in higher dimension; it also provides insight and computational pathways for calculating the index. We describe the problems in terms of geometric algebra and present an octree based solution using the algebra for finding critical points and their index in a 3D vector field.",Stephen Mann;Alyn P. Rockwood,S. Mann;A. Rockwood,"School of Computer Science, University of Waterloo, Waterloo, ONT, Canada;Department of Math and Computer Science, Colorado Schml of Mines, Golden, CO, USA",10.1109/visual.1997.663858;10.1109/visual.1997.663871,"Geometric Algebra, 3D Vector Fields, Singularities",59.0,18.0,20.0,232.0,,,vector fields;algebra present octree;definition index critical;clifford;insight computational pathways,0.5804;0.4378;0.2139;0.1653;0.1156,"[np.int64(-1), -1, -1, -1, -1]",40;-1;-1;-1;-1,40,40
VAST,2010,Interactive visual analysis of multiobjective optimizations,10.1109/vast.2010.5651694,http://dx.doi.org/10.1109/VAST.2010.5651694,215.0,216.0,M,"Optimization problems are typically addressed by purely automatic approaches. For multi-objective problems, however, a single best solution often does not exist. In this case, it is necessary to analyze trade-offs between many conflicting goals within a given application context. This poster describes an approach that tightly integrates automatic algorithms for multi-objective optimization and interactive multivariate visualizations. Ad-hoc selections support a flexible definition of input data for subsequent algorithms. These algorithms in turn represent their result as derived data attributes that can be assigned to visualizations or be used as a basis for further selections (e.g., to constrain the result set). This enables a guided search that still involves the knowledge of domain experts. We describe our approach in the context of multi-run simulation data from the application domain of car engine design.",Wolfgang Berger;Harald Piringer,Wolfgang Berger;Harald Piringer,"VRVis Research Center, Vienna, Austria;VRVis Research Center, Vienna, Austria",0.1109/vast.2009.5333081;10.1109/tvcg.2009.110,,8.0,9.0,7.0,309.0,,,objective optimization interactive;multivariate visualizations;car engine;offs conflicting;represent,0.5803;0.4629;0.2608;0.0555;0.0079,"[np.int64(-1), -1, -1, -1, -1]",218;-1;-1;-1;-1,218,218
Vis,1999,Time-critical Multiresolution Scene Rendering,10.1109/visual.1999.809876,http://doi.ieeecomputersociety.org/10.1109/VISUAL.1999.809876,123.0,130.0,C,"We describe a framework for time-critical rendering of graphics scenes composed of a large number of objects having complex geometric descriptions. Our technique relies upon a scene description in which objects are represented as multiresolution meshes. We perform a constrained optimization at each frame to choose the resolution of each potentially visible object that generates the best quality image while meeting timing constraints. The technique provides smooth level-of-detail control and aims at guaranteeing a uniform, bounded frame rate even for widely changing viewing conditions. The optimization algorithm is independent from the particular data structure used to represent multiresolution meshes. The only requirements are the ability to represent a mesh with an arbitrary number of triangles and to traverse a mesh structure at an arbitrary resolution in a short predictable time. A data structure satisfying these criteria is described and experimental results are discussed.",Enrico Gobbetti;Eric Bouvier,E. Gobbetti;E. Bouvier,"Center for Adv. Studies, Cagliari, Italy;Center for Adv. Studies, Cagliari, Italy",10.1109/visual.1996.568126;10.1109/visual.1998.745282,"multiresolution modeling,level of detail,adaptive rendering, time-critical graphics",77.0,15.0,0.0,26.0,,,represented multiresolution meshes;meeting timing constraints;visible object generates;traverse;large number,0.6247;0.2184;0.2034;0.1737;0.1172,"[np.int64(-1), -1, -1, -1, -1]",313;-1;-1;-1;-1,313,313
VAST,2006,Visual Analysis of Conflicting Opinions,10.1109/vast.2006.261431,http://dx.doi.org/10.1109/VAST.2006.261431,59.0,66.0,C,"Understanding the nature and dynamics of conflicting opinions is a profound and challenging issue. In this paper we address several aspects of the issue through a study of more than 3,000 Amazon customer reviews of the controversial bestseller The Da Vinci Code, including 1,738 positive and 918 negative reviews. The study is motivated by critical questions such as: what are the differences between positive and negative reviews? What is the origin of a particular opinion? How do these opinions change over time? To what extent can differentiating features be identified from unstructured text? How accurately can these features predict the category of a review? We first analyze terminology variations in these reviews in terms of syntactic, semantic, and statistic associations identified by TermWatch and use term variation patterns to depict underlying topics. We then select the most predictive terms based on log likelihood tests and demonstrate that this small set of terms classifies over 70% of the conflicting reviews correctly. This feature selection process reduces the dimensionality of the feature space from more than 20,000 dimensions to a couple of hundreds. We utilize automatically generated decision trees to facilitate the understanding of conflicting opinions in terms of these highly predictive terms. This study also uses a number of visualization and modeling tools to identify not only what positive and negative reviews have in common, but also they differ and evolve over time",Chaomei Chen;Fidelia Ibekwe-Sanjuan;Eric SanJuan;Chris E. Weaver,Chaomei Chen;Fidelia Ibekwe-SanJuan;Eric SanJuan;Chris Weaver,"Drexel University, USA;Universite de Lyon, France;Universite d''Avignon, France;Pennsylvania State University, USA",10.1109/infvis.2002.1173155,"Visual Analytics, Intelligence analysis, Problemsolving environments, Visual Knowledge Discovery",105.0,53.0,21.0,732.0,,,customer reviews controversial;associations identified termwatch;vinci code including;number visualization;change time,0.5519;0.3176;0.2654;0.1870;0.0368,"[np.int64(-1), -1, -1, -1, -1]",114;-1;-1;-1;-1,114,114
VAST,2018,ForVizor: Visualizing Spatio-Temporal Team Formations in Soccer,10.1109/tvcg.2018.2865041,http://dx.doi.org/10.1109/TVCG.2018.2865041,65.0,75.0,J,"Regarded as a high-level tactic in soccer, a team formation assigns players different tasks and indicates their active regions on the pitch, thereby influencing the team performance significantly. Analysis of formations in soccer has become particularly indispensable for soccer analysts. However, formations of a team are intrinsically time-varying and contain inherent spatial information. The spatio-temporal nature of formations and other characteristics of soccer data, such as multivariate features, make analysis of formations in soccer a challenging problem. In this study, we closely worked with domain experts to characterize domain problems of formation analysis in soccer and formulated several design goals. We design a novel spatio-temporal visual representation of changes in team formation, allowing analysts to visually analyze the evolution of formations and track the spatial flow of players within formations over time. Based on the new design, we further design and develop ForVizor, a visual analytics system, which empowers users to track the spatio-temporal changes in formation and understand how and why such changes occur. With ForVizor, domain experts conduct formation analysis of two games. Analysis results with insights and useful feedback are summarized in two case studies.",Yingcai Wu;Xiao Xie;Jiachen Wang;Dazhen Deng;Hongye Liang;Hui Zhang 0051;Shoubin Cheng;Wei Chen 0001,Yingcai Wu;Xiao Xie;Jiachen Wang;Dazhen Deng;Hongye Liang;Hui Zhang;Shoubin Cheng;Wei Chen,"State Key Lab of CAD&CG, Zhejiang University;State Key Lab of CAD&CG, Zhejiang University;State Key Lab of CAD&CG, Zhejiang University;State Key Lab of CAD&CG, Zhejiang University;State Key Lab of CAD&CG, Zhejiang University;Department of Sport Science, Zhejiang University;Department of Sport Science, Zhejiang University;State Key Lab of CAD&CG, Zhejiang University",10.1109/vast.2008.4677356;10.1109/tvcg.2011.239;10.1109/tvcg.2014.2346433;10.1109/vast.2014.7042477;10.1109/tvcg.2018.2865018;10.1109/tvcg.2016.2598831;10.1109/tvcg.2013.192;10.1109/tvcg.2014.2346445;10.1109/tvcg.2017.2745181;10.1109/tvcg.2017.2744218;10.1109/vast.2008.4677356,"Soccer data,formation analysis,spatio-temporal visualization",79.0,82.0,48.0,2778.0,,,formation analysis soccer;temporal visual representation;analytics empowers users;forvizor domain;regions pitch influencing,0.6550;0.3629;0.3330;0.1266;0.1250,"[np.int64(-1), -1, -1, -1, -1]",75;-1;-1;-1;-1,75,75
VAST,2016,Visualizing Dimension Coverage to Support Exploratory Analysis,10.1109/tvcg.2016.2598466,http://dx.doi.org/10.1109/TVCG.2016.2598466,21.0,30.0,J,"Data analysis involves constantly formulating and testing new hypotheses and questions about data. When dealing with a new dataset, especially one with many dimensions, it can be cumbersome for the analyst to clearly remember which aspects of the data have been investigated (i.e., visually examined for patterns, trends, outliers etc.) and which combinations have not. Yet this information is critical to help the analyst formulate new questions that they have not already answered. We observe that for tabular data, questions are typically comprised of varying combinations of data dimensions (e.g., what are the trends of Sales and Profit for different Regions?). We propose representing analysis history from the angle of dimension coverage (i.e., which data dimensions have been investigated and in which combinations). We use scented widgets to incorporate dimension coverage of the analysts' past work into interaction widgets of a visualization tool. We demonstrate how this approach can assist analysts with the question formation process. Our approach extends the concept of scented widgets to reveal aspects of one's own analysis history, and offers a different perspective on one's past work than typical visualization history tools. Results of our empirical study showed that participants with access to embedded dimension coverage information relied on this information when formulating questions, asked more questions about the data, generated more top-level findings, and showed greater breadth of their analysis without sacrificing depth.",Ali Sarvghad;Melanie Tory;Narges Mahyar,Ali Sarvghad;Melanie Tory;Narges Mahyar,University of Victoria;Tableau Research;University of British Columbia,10.1109/tvcg.2015.2467191;10.1109/tvcg.2006.120;10.1109/infvis.1999.801862;10.1109/infvis.2000.885086;10.1109/visual.2005.1532788;10.1109/tvcg.2014.2346452;10.1109/vast.2009.5333020;10.1109/infvis.2001.963289;10.1109/tvcg.2008.137;10.1109/tvcg.2015.2467611;10.1109/visual.1993.398857;10.1109/tvcg.2007.70589;10.1109/tvcg.2013.167;10.1109/tvcg.2008.109;10.1109/tvcg.2015.2467191,Dimension coverage;Tabular data;History;Empirical laboratory study;Exploratory data analysis;Scented widgets,35.0,27.0,33.0,1201.0,,,visualization history tools;dimension coverage analysts;formulating questions asked;extends concept scented;typical,0.5611;0.3797;0.3108;0.2549;0.0647,"[np.int64(-1), -1, -1, -1, -1]",315;-1;-1;-1;-1,315,315
SciVis,2018,Dynamic Volume Lines: Visual Comparison of 3D Volumes through Space-filling Curves,10.1109/tvcg.2018.2864510,http://dx.doi.org/10.1109/TVCG.2018.2864510,1040.0,1049.0,J,"The comparison of many members of an ensemble is difficult, tedious, and error-prone, which is aggravated by often just subtle differences. In this paper, we introduce Dynamic Volume Lines for the interactive visual analysis and comparison of sets of 3D volumes. Each volume is linearized along a Hilbert space-filling curve into a 1D Hilbert line plot, which depicts the intensities over the Hilbert indices. We present a nonlinear scaling of these 1D Hilbert line plots based on the intensity variations in the ensemble of 3D volumes, which enables a more effective use of the available screen space. The nonlinear scaling builds the basis for our interactive visualization techniques. An interactive histogram heatmap of the intensity frequencies serves as overview visualization. When zooming in, the frequencies are replaced by detailed 1D Hilbert line plots and optional functional boxplots. To focus on important regions of the volume ensemble, nonlinear scaling is incorporated into the plots. An interactive scaling widget depicts the local ensemble variations. Our brushing and linking interface reveals, for example, regions with a high ensemble variation by showing the affected voxels in a 3D spatial view. We show the applicability of our concepts using two case studies on ensembles of 3D volumes resulting from tomographic reconstruction. In the first case study, we evaluate an artificial specimen from simulated industrial 3D X-ray computed tomography (XCT). In the second case study, a real-world XCT foam specimen is investigated. Our results show that Dynamic Volume Lines can identify regions with high local intensity variations, allowing the user to draw conclusions, for example, about the choice of reconstruction parameters. Furthermore, it is possible to detect ring artifacts in reconstructions volumes.",Johannes Weissenbock;Bernhard Fröhler;M. Eduard Gröller;Johann Kastner;Christoph Heinzl,Johannes Weissenböck;Bernhard Fröhler;Eduard Gröller;Johann Kastner;Christoph Heinzl,"University of Applied Sciences Upper Austria, Wels, Austria;University of Applied Sciences Upper Austria, Wels, Austria;Technische Universitat Wien, Wien, Wien, AT;University of Applied Sciences Upper Austria, Wels, Austria;University of Applied Sciences Upper Austria, Wels, Austria",10.1109/tvcg.2014.2346448;10.1109/vast.2015.7347634;10.1109/tvcg.2009.155;10.1109/tvcg.2014.2346455;10.1109/visual.2005.1532847;10.1109/tvcg.2013.213;10.1109/vast.2014.7042491;10.1109/tvcg.2014.2346321;10.1109/vast.2016.7883516;10.1109/tvcg.2013.143;10.1109/tvcg.2014.2346448,"Ensemble data,comparative visualization,visual analysis,Hilbert curve,nonlinear scaling,X-ray computed tomography",29.0,20.0,43.0,955.0,,,volume lines interactive;linearized hilbert space;scaling builds;just subtle differences;choice reconstruction,0.6298;0.1895;0.1475;0.0962;0.0952,"[np.int64(-1), -1, -1, -1, -1]",293;-1;-1;-1;-1,293,293
VAST,2013,Visual Analysis of Topic Competition on Social Media,10.1109/tvcg.2013.221,http://dx.doi.org/10.1109/TVCG.2013.221,2012.0,2021.0,J,"How do various topics compete for public attention when they are spreading on social media? What roles do opinion leaders play in the rise and fall of competitiveness of various topics? In this study, we propose an expanded topic competition model to characterize the competition for public attention on multiple topics promoted by various opinion leaders on social media. To allow an intuitive understanding of the estimated measures, we present a timeline visualization through a metaphoric interpretation of the results. The visual design features both topical and social aspects of the information diffusion process by compositing ThemeRiver with storyline style visualization. ThemeRiver shows the increase and decrease of competitiveness of each topic. Opinion leaders are drawn as threads that converge or diverge with regard to their roles in influencing the public agenda change over time. To validate the effectiveness of the visual analysis techniques, we report the insights gained on two collections of Tweets: the 2012 United States presidential election and the Occupy Wall Street movement.",Panpan Xu;Yingcai Wu;Enxun Wei;Tai-Quan Peng;Shixia Liu;Jonathan J. H. Zhu;Huamin Qu,Panpan Xu;Yingcai Wu;Enxun Wei;Tai-Quan Peng;Shixia Liu;Jonathan J.H. Zhu;Huamin Qu,"Hong Kong University of Science and Technology, Hong Kong, China;Microsoft Research, Asia, Russia;Shanghai Jiao Tong University, China;Nanyang Technological University, Singapore;Microsoft Research, Asia, Russia;City University of Hong Kong, Hong Kong, China;Hong Kong University of Science and Technology, Hong Kong, China",10.1109/tvcg.2008.166;10.1109/tvcg.2011.239;10.1109/tvcg.2012.253;10.1109/tvcg.2012.225;10.1109/vast.2009.5333437;10.1109/tvcg.2010.194;10.1109/tvcg.2012.291;10.1109/vast.2010.5652931;10.1109/tvcg.2013.196;10.1109/infvis.2001.963273;10.1109/tvcg.2012.212;10.1109/vast.2010.5652922;10.1109/tvcg.2010.129;10.1109/infvis.1999.801851;10.1109/tvcg.2008.166,"Social media visuaization, topic competition, information diffusion, information propagation, agenda-setting",153.0,90.0,50.0,4604.0,,,topic competition model;visualization metaphoric interpretation;wall street movement;drawn threads converge;united states presidential,0.5876;0.3672;0.3335;0.2520;0.1711,"[np.int64(-1), -1, -1, -1, -1]",45;-1;-1;-1;-1,45,45
Vis,1997,Building and traversing a surface at variable resolution,10.1109/visual.1997.663865,http://dx.doi.org/10.1109/VISUAL.1997.663865,103.0,110.0,C,"The authors consider the multi-triangulation, a general model for representing surfaces at variable resolution based on triangle meshes. They analyse characteristics of the model that make it effective for supporting basic operations such as extraction of a surface approximation, and point location. An interruptible algorithm for extracting a representation at a resolution variable over the surface is presented. Different heuristics for building the model are considered and compared. Results on both the construction and the extraction algorithm are presented.",Leila De Floriani;Paola Magillo;Enrico Puppo,L. De Fioriani;P. Magillo;E. Puppo,"Dipt. di Inf. e Sci. dell'Inf., Genoa Univ., Italy;Dipartimento di Informatica e Scienze dellInformazione, Universita di Genova, Genoa, Italy;Consiglio Nazionale delle Ricerche, Istituto per la Matematica Applicata del CNR, Genoa, Italy",,,163.0,26.0,21.0,79.0,,,based triangle meshes;representation resolution variable;location interruptible;building;compared,0.6977;0.2590;0.1870;0.0971;0.0333,"[np.int64(-1), -1, -1, -1, -1]",108;-1;-1;-1;-1,108,108
SciVis,2015,Real-time Uncertainty Visualization for B-Mode Ultrasound,10.1109/scivis.2015.7429489,http://dx.doi.org/10.1109/SciVis.2015.7429489,33.0,40.0,C,"B-mode ultrasound is a very well established imaging modality and is widely used in many of today's clinical routines. However, acquiring good images and interpreting them correctly is a challenging task due to the complex ultrasound image formation process depending on a large number of parameters. To facilitate ultrasound acquisitions, we introduce a novel framework for real-time uncertainty visualization in B-mode images. We compute real-time per-pixel ultrasound Confidence Maps, which we fuse with the original ultrasound image in order to provide the user with an interactive feedback on the quality and credibility of the image. In addition to a standard color overlay mode, primarily intended for educational purposes, we propose two perceptional visualization schemes to be used in clinical practice. Our mapping of uncertainty to chroma uses the perceptionally uniform L*a*b* color space to ensure that the perceived brightness of B-mode ultrasound remains the same. The alternative mapping of uncertainty to fuzziness keeps the B-mode image in its original grayscale domain and locally blurs or sharpens the image based on the uncertainty distribution. An elaborate evaluation of our system and user studies on both medical students and expert sonographers demonstrate the usefulness of our proposed technique. In particular for ultrasound novices, such as medical students, our technique yields powerful visual cues to evaluate the image quality and thereby learn the ultrasound image formation process. Furthermore, seeing the distribution of uncertainty adjust to the transducer positioning in real-time, provides also expert clinicians with a strong visual feedback on their actions. This helps them to optimize the acoustic window and can improve the general clinical value of ultrasound.",Christian Schulte zu Berge;Denis Declara;Christoph Hennersperger;Maximilian Baust;Nassir Navab,Christian Schulte Zu Berge;Denis Declara;Christoph Hennersperger;Maximilian Baust;Nassir Navab,;;;;,10.1109/visual.2001.964550;10.1109/tvcg.2006.134;10.1109/tvcg.2007.70518;10.1109/tvcg.2012.279;10.1109/tvcg.2009.114;10.1109/visual.2001.964550,"Ultrasound, Uncertainty Visualization, Confidence Maps, Real-time",2.0,3.0,23.0,436.0,,,ultrasound confidence maps;color overlay mode;blurs sharpens image;improve general clinical;task,0.6866;0.3184;0.2482;0.1806;0.0559,"[np.int64(-1), -1, -1, -1, -1]",304;-1;-1;-1;-1,304,304
InfoVis,2013,Selecting the Aspect Ratio of a Scatter Plot Based on Its Delaunay Triangulation,10.1109/tvcg.2013.187,http://dx.doi.org/10.1109/TVCG.2013.187,2326.0,2335.0,J,"Scatter plots are diagrams that visualize two-dimensional data as sets of points in the plane. They allow users to detect correlations and clusters in the data. Whether or not a user can accomplish these tasks highly depends on the aspect ratio selected for the plot, i.e., the ratio between the horizontal and the vertical extent of the diagram. We argue that an aspect ratio is good if the Delaunay triangulation of the scatter plot at this aspect ratio has some nice geometric property, e.g., a large minimum angle or a small total edge length. More precisely, we consider the following optimization problem. Given a set Q of points in the plane, find a scale factor s such that scaling the x-coordinates of the points in Q by s and the y-coordinates by 1=s yields a point set P(s) that optimizes a property of the Delaunay triangulation of P(s), over all choices of s. We present an algorithm that solves this problem efficiently and demonstrate its usefulness on real-world instances. Moreover, we discuss an empirical test in which we asked 64 participants to choose the aspect ratios of 18 scatter plots. We tested six different quality measures that our algorithm can optimize. In conclusion, minimizing the total edge length and minimizing what we call the 'uncompactness' of the triangles of the Delaunay triangulation yielded the aspect ratios that were most similar to those chosen by the participants in the test.",Martin Fink 0001;Jan-Henrik Haunert;Joachim Spoerhase;Alexander Wolff 0001,Martin Fink;Jan-Henrik Haunert;Joachim Spoerhase;Alexander Wolff,"Lehrstuhl I, Institut für Informatik, Universität Würzburg, Germany;Lehrstuhl I, Institut für Informatik, Universität Würzburg, Germany;Lehrstuhl I, Institut für Informatik, Universität Würzburg, Germany;Lehrstuhl I, Institut für Informatik, Universität Würzburg, Germany",10.1109/tvcg.2006.163;10.1109/tvcg.2012.196;10.1109/tvcg.2011.167;10.1109/tvcg.2006.163,"Scatter plot, aspect ratio, Delaunay triangulation",35.0,24.0,28.0,727.0,,,delaunay triangulation scatter;choose aspect ratios;clusters data;efficiently demonstrate usefulness;allow,0.6072;0.3702;0.3686;0.1983;-0.0029,"[np.int64(-1), -1, -1, -1, -1]",286;-1;-1;-1;-1,286,286
VAST,2012,The spatiotemporal multivariate hypercube for discovery of patterns in event data,10.1109/vast.2012.6400536,http://dx.doi.org/10.1109/VAST.2012.6400536,235.0,236.0,M,"Event data can hold valuable decision making information, yet detecting interesting patterns in this type of data is not an easy task because the data is usually rich and contains spatial, temporal as well as multivariate dimensions. Research into visual analytics tools to support the discovery of patterns in event data often focuses on the spatiotemporal or spatiomultivariate dimension of the data only. Few research efforts focus on all three dimensions in one framework. An integral view on all three dimensions is, however, required to unlock the full potential of event datasets. In this poster, we present an event visualization, transition, and interaction framework that enables an integral view on all dimensions of spatiotemporal multivariate event data. The framework is built around the notion that the event data space can be considered a spatiotemporal multivariate hypercube. Results of a case study we performed suggest that a visual analytics tool based on the proposed framework is indeed capable to support users in the discovery of multidimensional spatiotemporal multivariate patterns in event data.",Fred Olislagers;Marcel Worring,Fred Olislagers;Marcel Worring,"Intelligent Systems Lab Amsterdam, University of Amsterdam, The Netherlands;Intelligent Systems Lab Amsterdam, University of Amsterdam, The Netherlands",,,3.0,1.0,3.0,206.0,,,event visualization;spatiomultivariate dimension data;framework built notion;study performed suggest;unlock,0.7077;0.4763;0.0467;0.0456;-0.0202,"[np.int64(-1), -1, -1, -1, -1]",156;-1;-1;-1;-1,156,156
InfoVis,2010,Declarative Language Design for Interactive Visualization,10.1109/tvcg.2010.144,http://dx.doi.org/10.1109/TVCG.2010.144,1149.0,1156.0,J,"We investigate the design of declarative, domain-specific languages for constructing interactive visualizations. By separating specification from execution, declarative languages can simplify development, enable unobtrusive optimization, and support retargeting across platforms. We describe the design of the Protovis specification language and its implementation within an object-oriented, statically-typed programming language (Java). We demonstrate how to support rich visualizations without requiring a toolkit-specific data model and extend Protovis to enable declarative specification of animated transitions. To support cross-platform deployment, we introduce rendering and event-handling infrastructures decoupled from the runtime platform, letting designers retarget visualization specifications (e.g., from desktop to mobile phone) with reduced effort. We also explore optimizations such as runtime compilation of visualization specifications, parallelized execution, and hardware-accelerated rendering. We present benchmark studies measuring the performance gains provided by these optimizations and compare performance to existing Java-based visualization tools, demonstrating scalability improvements exceeding an order of magnitude.",Jeffrey Heer;Michael Bostock,Jeffrey Heer;Michael Bostock,"Computer Science Department, University of Stanford, Stanford, CA, USA;Computer Science Department, University of Stanford, Stanford, CA, USA",10.1109/tvcg.2009.174;10.1109/tvcg.2006.178;10.1109/infvis.2004.12;10.1109/tvcg.2007.70577;10.1109/tvcg.2009.128;10.1109/visual.1992.235219;10.1109/tvcg.2009.191;10.1109/tvcg.2009.110;10.1109/tvcg.2007.70539;10.1109/infvis.2004.64;10.1109/infvis.2000.885086;10.1109/tvcg.2009.174,"Information visualization, user interfaces, toolkits, domain specific languages, declarative languages, optimization",151.0,82.0,25.0,1485.0,HM,,visualization specifications;animated transitions;languages simplify development;decoupled runtime;retarget,0.6372;0.4034;0.3889;0.2261;0.0498,"[np.int64(-1), -1, -1, -1, -1]",275;-1;-1;-1;-1,275,275
Vis,2009,Interactive Visual Analysis of Complex Scientific Data as Families of Data Surfaces,10.1109/tvcg.2009.155,http://dx.doi.org/10.1109/TVCG.2009.155,1351.0,1358.0,J,"The widespread use of computational simulation in science and engineering provides challenging research opportunities. Multiple independent variables are considered and large and complex data are computed, especially in the case of multi-run simulation. Classical visualization techniques deal well with 2D or 3D data and also with time-dependent data. Additional independent dimensions, however, provide interesting new challenges. We present an advanced visual analysis approach that enables a thorough investigation of families of data surfaces, i.e., datasets, with respect to pairs of independent dimensions. While it is almost trivial to visualize one such data surface, the visual exploration and analysis of many such data surfaces is a grand challenge, stressing the users' perception and cognition. We propose an approach that integrates projections and aggregations of the data surfaces at different levels (one scalar aggregate per surface, a 1D profile per surface, or the surface as such). We demonstrate the necessity for a flexible visual analysis system that integrates many different (linked) views for making sense of this highly complex data. To demonstrate its usefulness, we exemplify our approach in the context of a meteorological multi-run simulation data case and in the context of the engineering domain, where our collaborators are working with the simulation of elastohydrodynamic (EHD) lubrication bearing in the automotive industry.",Kresimir Matkovic;Denis Gracanin;Borislav Klarin;Helwig Hauser,Kresimir Matkovic;Denis Gracanin;Borislav Klarin;Helwig Hauser,"VRVis Research Center Vienna, Austria;Virginia Technology, USA;AVL AST, Zagreb, Croatia;University of Bergen, Norway",10.1109/visual.1997.663867;10.1109/tvcg.2008.145;10.1109/infvis.2001.963273;10.1109/tvcg.2006.170;10.1109/visual.1997.663867,"Interactive visual analysis, family of surfaces, coordinated multiple views, multidimensional multivariate data",60.0,34.0,23.0,784.0,,,visualize data surface;lubrication bearing automotive;multi run simulation;engineering provides challenging;especially,0.6697;0.2883;0.2655;0.2253;0.0169,"[np.int64(-1), -1, -1, -1, -1]",261;-1;-1;-1;-1,261,261
InfoVis,2008,Effectiveness of Animation in Trend Visualization,10.1109/tvcg.2008.125,http://dx.doi.org/10.1109/TVCG.2008.125,1325.0,1332.0,J,"Animation has been used to show trends in multi-dimensional data. This technique has recently gained new prominence for presentations, most notably with Gapminder Trendalyzer. In Trendalyzer, animation together with interesting data and an engaging presenter helps the audience understand the results of an analysis of the data. It is less clear whether trend animation is effective for analysis. This paper proposes two alternative trend visualizations that use static depictions of trends: one which shows traces of all trends overlaid simultaneously in one display and a second that uses a small multiples display to show the trend traces side-by-side. The paper evaluates the three visualizations for both analysis and presentation. Results indicate that trend animation can be challenging to use even for presentations; while it is the fastest technique for presentation and participants find it enjoyable and exciting, it does lead to many participant errors. Animation is the least effective form for analysis; both static depictions of trends are significantly faster than animation, and the small multiples display is more accurate.",George G. Robertson;Roland Fernandez;Danyel Fisher;Bongshin Lee;John T. Stasko,George Robertson;Roland Fernandez;Danyel Fisher;Bongshin Lee;John Stasko,Microsoft Research;Microsoft Research;Microsoft Research;Microsoft Research;Georgia Institute of Technology,10.1109/infvis.1999.801854;10.1109/tvcg.2007.70539,"Information visualization, animation, trends, design, experiment",480.0,259.0,21.0,4273.0,TT,,trend visualizations;faster animation small;overlaid simultaneously display;presenter helps audience;paper proposes alternative,0.7835;0.3073;0.2422;0.1804;0.0312,"[np.int64(-1), -1, -1, -1, -1]",162;-1;-1;-1;-1,162,162
Vis,2005,Understanding visualization through spatial ability differences,10.1109/visual.2005.1532836,http://dx.doi.org/10.1109/VISUAL.2005.1532836,511.0,518.0,C,"Little is known about the cognitive abilities which influence the comprehension of scientific and information visualizations and what properties of the visualization affect comprehension. Our goal in this paper is to understand what makes visualizations difficult. We address this goal by examining the spatial ability differences in a diverse population selected for spatial ability variance. For example, how is, spatial ability related to visualization comprehension? What makes a particular visualization difficult or time intensive for specific groups of subjects? In this paper, we present the results of an experiment designed to answer these questions. Fifty-six subjects were tested on a basic visualization task and given standard paper tests of spatial abilities. An equal number of males and females were recruited in this study in order to increase spatial ability variance. Our results show that high spatial ability is correlated with accuracy on our three-dimensional visualization test, but not with time. High spatial ability subjects also had less difficulty with object complexity and the hidden properties of an object.",Maria C. Velez;Deborah Silver;Marilyn Tremaine,M.C. Velez;D. Silver;M. Tremaine,"Center for Advanced Information Processing Rutgers, State University of New Jersey, USA;Center for Advanced Information Processing Rutgers, State University of New Jersey, USA;Center for Advanced Information Processing Rutgers, State University of New Jersey, USA",10.1109/infvis.2003.1249022;10.1109/visual.2003.1250396,"Gender differences, orthogonal projections, spatial ability, standardized testing",199.0,21.0,36.0,1041.0,,,visualization comprehension makes;ability correlated accuracy;population selected spatial;standard paper tests;difficult time,0.6827;0.2801;0.2793;0.1748;0.0938,"[np.int64(-1), -1, -1, -1, -1]",271;-1;-1;-1;-1,271,271
SciVis,2017,Multiscale Visualization and Scale-Adaptive Modification of DNA Nanostructures,10.1109/tvcg.2017.2743981,http://dx.doi.org/10.1109/TVCG.2017.2743981,1014.0,1024.0,J,"We present an approach to represent DNA nanostructures in varying forms of semantic abstraction, describe ways to smoothly transition between them, and thus create a continuous multiscale visualization and interaction space for applications in DNA nanotechnology. This new way of observing, interacting with, and creating DNA nanostructures enables domain experts to approach their work in any of the semantic abstraction levels, supporting both low-level manipulations and high-level visualization and modifications. Our approach allows them to deal with the increasingly complex DNA objects that they are designing, to improve their features, and to add novel functions in a way that no existing single-scale approach offers today. For this purpose we collaborated with DNA nanotechnology experts to design a set of ten semantic scales. These scales take the DNA's chemical and structural behavior into account and depict it from atoms to the targeted architecture with increasing levels of abstraction. To create coherence between the discrete scales, we seamlessly transition between them in a well-defined manner. We use special encodings to allow experts to estimate the nanoscale object's stability. We also add scale-adaptive interactions that facilitate the intuitive modification of complex structures at multiple scales. We demonstrate the applicability of our approach on an experimental use case. Moreover, feedback from our collaborating domain experts confirmed an increased time efficiency and certainty for analysis and modification tasks on complex DNA structures. Our method thus offers exciting new opportunities with promising applications in medicine and biotechnology.",Haichao Miao;Elisa De Llano;Johannes Sorger;Yasaman Ahmadi;Tadija Kekic;Tobias Isenberg 0001;M. Eduard Gröller;Ivan Barisic;Ivan Viola,Haichao Miao;Elisa De Llano;Johannes Sorger;Yasaman Ahmadi;Tadija Kekic;Tobias Isenberg;M. Eduard Gröller;Ivan Barišić;Ivan Viola,"Austrian Institute of Technology and TU Wien, Austria;Austrian Institute of Technology;TU Wien, Austria;Austrian Institute of Technology;Austrian Institute of Technology;Université Paris-Saclay, France;VRVis Research Center, Austria and TU Wien, Austria;Austrian Institute of Technology;Austrian Institute of Technology and TU Wien, Austria",10.1109/visual.2004.103;10.1109/tvcg.2007.70578;10.1109/tvcg.2009.168;10.1109/tvcg.2013.126;10.1109/tvcg.2009.111,"Nano,nanotechnology,assembly,multiscale,abstraction,DNA,origami,scale-adaptive modification",23.0,21.0,54.0,1015.0,,,represent dna nanostructures;work semantic abstraction;scales seamlessly transition;experimental use;single,0.7316;0.2776;0.2300;0.0832;-0.0213,"[np.int64(-1), -1, -1, -1, -1]",120;-1;-1;-1;-1,120,120
Vis,2002,A radial focus+context visualization for multi-dimensional functions,10.1109/visual.2002.1183806,http://dx.doi.org/10.1109/VISUAL.2002.1183806,443.0,450.0,C,"The analysis of multidimensional functions is important in many engineering disciplines, and poses a major problem as the number of dimensions increases. Previous visualization approaches focus on representing three or fewer dimensions at a time. This paper presents a new focus+context visualization that provides an integrated overview of an entire multidimensional function space, with uniform treatment of all dimensions. The overview is displayed with respect to a user-controlled polar focal point in the function's parameter space. Function value patterns are viewed along rays that emanate from the focal point in all directions in the parameter space, and represented radially around the focal point in the visualization. Data near the focal point receives proportionally more screen space than distant data. This approach scales smoothly from two dimensions to 10-20, with a 1000 pixel range on each dimension.",Sanjini Jayaraman;Chris North 0001,S. Jayaraman;C. North,"Center for Human Computer Interaction, Department of Computer Science, Virginia Polytechnic Institute and State University, Blacksburg, VA, USA;Center for Human Computer Interaction, Department of Computer Science, Virginia Polytechnic Institute and State University, Blacksburg, VA, USA",10.1109/infvis.1997.636793;10.1109/infvis.1995.528688;10.1109/visual.1993.398859;10.1109/infvis.1998.729558;10.1109/infvis.1997.636793,"visualization, multidimensional functions",27.0,8.0,11.0,146.0,,,focus context visualization;entire multidimensional function;user controlled polar;proportionally;10 20 1000,0.6944;0.3623;0.2096;0.1233;0.0720,"[np.int64(-1), -1, -1, -1, -1]",-1;-1;-1;-1;-1,,-1
VAST,2017,Supporting Handoff in Asynchronous Collaborative Sensemaking Using Knowledge-Transfer Graphs,10.1109/tvcg.2017.2745279,http://dx.doi.org/10.1109/TVCG.2017.2745279,340.0,350.0,J,"During asynchronous collaborative analysis, handoff of partial findings is challenging because externalizations produced by analysts may not adequately communicate their investigative process. To address this challenge, we developed techniques to automatically capture and help encode tacit aspects of the investigative process based on an analyst's interactions, and streamline explicit authoring of handoff annotations. We designed our techniques to mediate awareness of analysis coverage, support explicit communication of progress and uncertainty with annotation, and implicit communication through playback of investigation histories. To evaluate our techniques, we developed an interactive visual analysis system, KTGraph, that supports an asynchronous investigative document analysis task. We conducted a two-phase user study to characterize a set of handoff strategies and to compare investigative performance with and without our techniques. The results suggest that our techniques promote the use of more effective handoff strategies, help increase an awareness of prior investigative process and insights, as well as improve final investigative outcomes.",Jian Zhao 0010;Michael Glueck;Petra Isenberg;Fanny Chevalier;Azam Khan,Jian Zhao;Michael Glueck;Petra Isenberg;Fanny Chevalier;Azam Khan,FX Palo Alto Laboratory;Autodesk Research;Inria;Inria;Autodesk Research,10.1109/vast.2007.4389009;10.1109/vast.2011.6102447;10.1109/vast.2010.5652932;10.1109/vast.2006.261420;10.1109/vast.2007.4389011;10.1109/tvcg.2008.137;10.1109/tvcg.2007.70568;10.1109/vast.2009.5333020;10.1109/vast.2009.5333878;10.1109/vast.2011.6102438;10.1109/vast.2006.261415;10.1109/tvcg.2014.2346573;10.1109/tvcg.2015.2467551;10.1109/vast.2008.4677358;10.1109/tvcg.2016.2598466;10.1109/vast.2007.4389006;10.1109/tvcg.2007.70577;10.1109/tvcg.2007.70589;10.1109/tvcg.2016.2598543;10.1109/vast.2007.4389009,"Collaboration,sensemaking,handoff,handover,structured externalizations,interactive visual analysis",63.0,41.0,55.0,1372.0,HM,,asynchronous collaborative analysis;investigative process address;handoff strategies help;visual;capture help encode,0.6236;0.4040;0.2333;0.2283;0.1042,"[np.int64(-1), -1, -1, -1, -1]",72;-1;-1;-1;-1,72,72
Vis,2002,Evaluation of a multimodal interface for 3D terrain visualization,10.1109/visual.2002.1183802,http://dx.doi.org/10.1109/VISUAL.2002.1183802,411.0,418.0,C,"Novel speech and/or gesture interfaces are candidates for use in future mobile or ubiquitous applications. This paper describes an evaluation of various interfaces for visual navigation of a whole Earth 3D terrain model. A mouse driven interface, a speech interface, a gesture interface, and a multimodal speech and gesture interface were used to navigate to targets placed at various points on the Earth. This study measured each participant's recall of target identity, order, and location as a measure of cognitive load. Timing information as well as a variety of subjective measures including discomfort and user preference were taken. While the familiar and mature mouse interface scored best by most measures, the speech interface also performed well. The gesture and multimodal interface suffered from weaknesses in the gesture modality. Weaknesses in the speech and multimodal modalities are identified and areas for improvement are discussed.",David M. Krum;Olugbenga Omoteso;William Ribarsky;Thad Starner;Larry F. Hodges,D.M. Krum;O. Omoteso;W. Ribarsky;T. Starner;L.F. Hodges,"College of Computing, Georgia Institute of Technology, GVU Center, Atlanta, GA, USA;College of Computing, Georgia Institute of Technology, GVU Center, Atlanta, GA, USA;College of Computing, Georgia Institute of Technology, GVU Center, Atlanta, GA, USA;College of Computing, Georgia Institute of Technology, GVU Center, Atlanta, GA, USA;College of Computing, Georgia Institute of Technology, GVU Center, Atlanta, GA, USA",,"multimodal interaction, evaluation, navigation, speech recognition, gesture recognition, virtual reality, mobile visualization, GIS",32.0,5.0,15.0,175.0,,,gesture interfaces;used navigate;earth 3d terrain;participant recall target;load timing,0.5964;0.3681;0.3312;0.1355;0.0647,"[np.int64(-1), -1, -1, -1, -1]",79;-1;-1;-1;-1,79,79
InfoVis,2018,Looks Good To Me: Visualizations As Sanity Checks,10.1109/tvcg.2018.2864907,http://dx.doi.org/10.1109/TVCG.2018.2864907,830.0,839.0,J,"Famous examples such as Anscombe's Quartet highlight that one of the core benefits of visualizations is allowing people to discover visual patterns that might otherwise be hidden by summary statistics. This visual inspection is particularly important in exploratory data analysis, where analysts can use visualizations such as histograms and dot plots to identify data quality issues. Yet, these visualizations are driven by parameters such as histogram bin size or mark opacity that have a great deal of impact on the final visual appearance of the chart, but are rarely optimized to make important features visible. In this paper, we show that data flaws have varying impact on the visual features of visualizations, and that the adversarial or merely uncritical setting of design parameters of visualizations can obscure the visual signatures of these flaws. Drawing on the framework of Algebraic Visualization Design, we present the results of a crowdsourced study showing that common visualization types can appear to reasonably summarize distributional data while hiding large and important flaws such as missing data and extraneous modes. We make use of these results to propose additional best practices for visualizations of distributions for data quality tasks.",Michael Correll;Mingwei Li;Gordon L. Kindlmann;Carlos Scheidegger,Michael Correll;Mingwei Li;Gordon Kindlmann;Carlos Scheidegger,Tableau Research;University of Arizona;University of Chicago;University of Arizona,10.1109/tvcg.2016.2598862;10.1109/tvcg.2011.185;10.1109/tvcg.2014.2346298;10.1109/vast.2016.7883519;10.1109/tvcg.2016.2598618;10.1109/tvcg.2014.2346978;10.1109/tvcg.2014.2346979;10.1109/tvcg.2012.230;10.1109/tvcg.2014.2346325;10.1109/tvcg.2016.2599030;10.1109/tvcg.2017.2744359;10.1109/tvcg.2015.2469125;10.1109/tvcg.2010.161;10.1109/tvcg.2015.2467191;10.1109/tvcg.2016.2598862,"Graphical perception,data quality,univariate visualizations",52.0,47.0,51.0,1426.0,,,quality issues visualizations;adversarial merely uncritical;histogram bin;make use results;deal,0.6983;0.2991;0.2753;0.0362;-0.0260,"[np.int64(-1), -1, -1, -1, -1]",186;-1;-1;-1;-1,186,186
VAST,2014,DIA2: Web-based Cyberinfrastructure for Visual Analysis of Funding Portfolios,10.1109/tvcg.2014.2346747,http://dx.doi.org/10.1109/TVCG.2014.2346747,1823.0,1832.0,J,"We present a design study of the Deep Insights Anywhere, Anytime (DIA2) platform, a web-based visual analytics system that allows program managers and academic staff at the U.S. National Science Foundation to search, view, and analyze their research funding portfolio. The goal of this system is to facilitate users' understanding of both past and currently active research awards in order to make more informed decisions of their future funding. This user group is characterized by high domain expertise yet not necessarily high literacy in visualization and visual analytics-they are essentially casual experts-and thus require careful visual and information design, including adhering to user experience standards, providing a self-instructive interface, and progressively refining visualizations to minimize complexity. We discuss the challenges of designing a system for casual experts and highlight how we addressed this issue by modeling the organizational structure and workflows of the NSF within our system. We discuss each stage of the design process, starting with formative interviews, prototypes, and finally live deployments and evaluation with stakeholders.",Krishna P. C. Madhavan;Niklas Elmqvist;Mihaela Vorvoreanu;Xin Chen;Yuet Ling Wong;Hanjun Xian;Zhihua Dong;Aditya Johri,Krishna Madhavan;Niklas Elmqvist;Mihaela Vorvoreanu;Xin Chen;Yuetling Wong;Hanjun Xian;Zhihua Dong;Aditya Johri,Purdue University;Purdue University;Purdue University;Purdue University;Purdue University;Microsoft Corporation;Microsoft Corporation;George Mason University,10.1109/tvcg.2007.70541;10.1109/tvcg.2011.174;10.1109/tvcg.2010.177;10.1109/tvcg.2012.255;10.1109/tvcg.2009.123;10.1109/tvcg.2013.223;10.1109/infvis.2001.963283;10.1109/tvcg.2012.213;10.1109/vast.2008.4677361;10.1109/tvcg.2007.70541,"visual analytics, portfolio mining, web-based visualization, casual visualization, design study",30.0,16.0,40.0,1540.0,,,visualization visual analytics;research funding portfolio;expertise necessarily high;workflows nsf discuss;national,0.5746;0.3450;0.3208;0.2833;0.0544,"[np.int64(-1), -1, -1, -1, -1]",201;-1;-1;-1;-1,201,201
Vis,2021,Augmenting Sports Videos with VisCommentator,10.1109/tvcg.2021.3114806,http://dx.doi.org/10.1109/TVCG.2021.3114806,824.0,834.0,J,"Visualizing data in sports videos is gaining traction in sports analytics, given its ability to communicate insights and explicate player strategies engagingly. However, augmenting sports videos with such data visualizations is challenging, especially for sports analysts, as it requires considerable expertise in video editing. To ease the creation process, we present a design space that characterizes augmented sports videos at an element-level <i>(what the constituents are)</i> and clip-level <i>(how those constituents are organized)</i>. We do so by systematically reviewing 233 examples of augmented sports videos collected from TV channels, teams, and leagues. The design space guides selection of data insights and visualizations for various purposes. Informed by the design space and close collaboration with domain experts, we design VisCommentator, a fast prototyping tool, to eases the creation of augmented table tennis videos by leveraging machine learning-based data extractors and design space-based visualization recommendations. With VisCommentator, sports analysts can create an augmented video by <i>selecting the data</i> to visualize instead of manually <i>drawing the graphical marks</i>. Our system can be generalized to other racket sports <i>(e.g</i>., tennis, badminton) once the underlying datasets and models are available. A user study with seven domain experts shows high satisfaction with our system, confirms that the participants can reproduce augmented sports videos in a short period, and provides insightful implications into future improvements and opportunities.",Zhutian Chen;Shuainan Ye;Xiangtong Chu;Haijun Xia;Hui Zhang 0051;Huamin Qu;Yingcai Wu,Zhutian Chen;Shuainan Ye;Xiangtong Chu;Haijun Xia;Hui Zhang;Huamin Qu;Yingcai Wu,"Department of Cognitive Science and Design Lab, State Key Lab of CAD & CG, Zhejiang University and Hong Kong University of Science and Technology, University of California, San Diego, United States;State Key Lab of CAD & CG, Zhejiang University, China;State Key Lab of CAD & CG, Zhejiang University, China;Department of Cognitive Science and Design Lab, University of California, San Diego, United States;Department of Sport Science, Zhejiang University, China;Hong Kong University of Science and Technology, Hong Kong;State Key Lab of CAD & CG, Zhejiang University, China",10.1109/tvcg.2016.2598647;10.1109/tvcg.2019.2934810;10.1109/tvcg.2014.2346250;10.1109/tvcg.2018.2865240;10.1109/tvcg.2010.179;10.1109/tvcg.2020.3030403;10.1109/tvcg.2017.2745181;10.1109/tvcg.2019.2934398;10.1109/tvcg.2015.2467191;10.1109/tvcg.2017.2744218;10.1109/tvcg.2020.3028957;10.1109/tvcg.2020.3030359;10.1109/tvcg.2020.3030392;10.1109/tvcg.2019.2934656;10.1109/tvcg.2020.3030458,"Augmented Sports Videos,Video-based Visualization,Sports visualization,Intelligent Design Tool,Storytelling",19.0,42.0,62.0,2151.0,HM,,visualizing data sports;video editing ease;insightful implications future;element;design space close,0.7605;0.3853;0.1952;0.1452;0.1355,"[np.int64(-1), -1, -1, -1, -1]",158;-1;-1;-1;-1,158,158
Vis,1998,Visualizing diffusion tensor images of the mouse spinal cord,10.1109/visual.1998.745294,http://dx.doi.org/10.1109/VISUAL.1998.745294,127.0,134.0,C,"Within biological systems, water molecules undergo continuous stochastic Brownian motion. The diffusion rate can give clues to the structure of the underlying tissues. In some tissues, the rate is anisotropic. Diffusion-rate images can be calculated from diffusion-weighted MRI. A 2D diffusion tensor image (DTI) and an associated anatomical scalar field define seven values at each spatial location. We present two new methods for visually representing DTIs. The first method displays an array of ellipsoids, where the shape of each ellipsoid represents one tensor value. The ellipsoids are all normalized to approximately the same size so that they can be displayed simultaneously in context. The second method uses concepts from oil painting to represent the seven-valued data with multiple layers of varying brush strokes. Both methods successfully display most or all of the information in DTIs and provide exploratory methods for understanding them. The ellipsoid method has a simpler interpretation and explanation than the painting-motivated method; the painting-motivated method displays more of the information and is easier to read quantatively. We demonstrate the methods on images of the mouse spinal cord. The visualizations show significant differences between spinal cords from mice suffering from experimental allergic encephalomyelitis and spinal cords from wild-type mice. The differences are consistent with differences shown histologically and suggest that our new non-invasive imaging methodology and visualization of the results could have early diagnostic value for neurodegenerative diseases.",David H. Laidlaw;Eric T. Ahrens;David Kremers;Matthew J. Avalos;Russell E. Jacobs;Carol Readhead,D.H. Laidlaw;E.T. Ahrens;D. Kremers;M.J. Avalos;R.E. Jacobs;C. Readhead,"California Institute of Technology, Pasadena, CA, USA;California Institute of Technology, Pasadena, CA, USA;California Institute of Technology, Pasadena, CA, USA;California Institute of Technology, Pasadena, CA, USA;California Institute of Technology, Pasadena, CA, USA;Cedars Sinai Medical Center, Los Angeles, CA, USA",10.1109/visual.1992.235201;10.1109/visual.1992.235201,"multi-valued visualization, tensor field visualization,oil painting",223.0,63.0,26.0,287.0,,,diffusion tensor image;histologically suggest new;ellipsoids shape;simpler interpretation explanation;cords mice suffering,0.6835;0.2179;0.2178;0.1688;0.1257,"[np.int64(-1), -1, -1, -1, -1]",43;-1;-1;-1;-1,43,43
Vis,2004,Surface reconstruction of noisy and defective data sets,10.1109/visual.2004.101,http://dx.doi.org/10.1109/VISUAL.2004.101,259.0,266.0,C,"We present a novel surface reconstruction algorithm that can recover high-quality surfaces from noisy and defective data sets without any normal or orientation information. A set of new techniques is introduced to afford extra noise tolerability, robust orientation alignment, reliable outlier removal, and satisfactory feature recovery. In our algorithm, sample points are first organized by an octree. The points are then clustered into a set of monolithically singly-oriented groups. The inside/outside orientation of each group is determined through a robust voting algorithm. We locally fit an implicit quadric surface in each octree cell. The locally fitted implicit surfaces are then blended to produce a signed distance field using the modified Shepard's method. We develop sophisticated iterative fitting algorithms to afford improved noise tolerance both in topology recognition and geometry accuracy. Furthermore, this iterative fitting algorithm, coupled with a local model selection scheme, provides a reliable sharp feature recovery mechanism even in the presence of bad input.",Hui Xie 0001;Kevin T. McDonnell;Hong Qin 0001,H. Xie;K.T. McDonnell;H. Qin,"Computer Science Department, State University of New York at Stony Brook, NY;Computer Science Department, State University of New York at Stony Brook, Stony Brook, NY, USA;Computer Science Department, State University of New York at Stony Brook, Stony Brook, NY, USA",10.1109/visual.2003.1250359;10.1109/visual.2003.1250359,"Computer Graphics, Surface Reconstruction, Surface Representation, MPU implicits, Modified Shepard's Method",106.0,39.0,27.0,475.0,,,surface reconstruction;octree cell locally;alignment reliable;outlier;using modified shepard,0.6800;0.2833;0.2343;0.2067;0.1219,"[np.int64(-1), -1, -1, -1, -1]",104;-1;-1;-1;-1,104,104
SciVis,2016,Topological Analysis of Inertial Dynamics,10.1109/tvcg.2016.2599018,http://dx.doi.org/10.1109/TVCG.2016.2599018,950.0,959.0,J,"Traditional vector field visualization has a close focus on velocity, and is typically constrained to the dynamics of massless particles. In this paper, we present a novel approach to the analysis of the force-induced dynamics of inertial particles. These forces can arise from acceleration fields such as gravitation, but also be dependent on the particle dynamics itself, as in the case of magnetism. Compared to massless particles, the velocity of an inertial particle is not determined solely by its position and time in a vector field. In contrast, its initial velocity can be arbitrary and impacts the dynamics over its entire lifetime. This leads to a four-dimensional problem for 2D setups, and a six-dimensional problem for the 3D case. Our approach avoids this increase in dimensionality and tackles the visualization by an integrated topological analysis approach. We demonstrate the utility of our approach using a synthetic time-dependent acceleration field, a system of magnetic dipoles, and N-body systems both in 2D and 3D.",Antoni Sagristà;Stefan Jordan;Andreas Just;Fabio Dias 0001;Luis Gustavo Nonato;Filip Sadlo,Antoni Sagristà;Stefan Jordan;Andreas Just;Fabio Dias;Luis Gustavo Nonato;Filip Sadlo,"Heidelberg University, Germany;Heidelberg University, Germany;ZAH, Heidelberg University, Germany;Universidade de Såo Paulo, Såo Carlos, Brazil;Universidade de Såo Paulo, Såo Carlos, Brazil;Heidelberg University, Germany",10.1109/visual.1993.398859;10.1109/tvcg.2014.2346415;10.1109/visual.1990.146386;10.1109/visual.1993.398859,Visualization of inertial dynamics;N-body systems;magnetism;acceleration,15.0,12.0,30.0,448.0,,,vector field visualization;induced dynamics inertial;massless particles;topological;entire lifetime,0.6084;0.4318;0.3073;0.2460;0.0203,"[np.int64(-1), -1, -1, -1, -1]",140;-1;-1;-1;-1,140,140
InfoVis,2019,Why Authors Don't Visualize Uncertainty,10.1109/tvcg.2019.2934287,http://dx.doi.org/10.1109/TVCG.2019.2934287,130.0,139.0,J,"Clear presentation of uncertainty is an exception rather than rule in media articles, data-driven reports, and consumer applications, despite proposed techniques for communicating sources of uncertainty in data. This work considers, Why do so many visualization authors choose not to visualize uncertainty? I contribute a detailed characterization of practices, associations, and attitudes related to uncertainty communication among visualization authors, derived from the results of surveying 90 authors who regularly create visualizations for others as part of their work, and interviewing thirteen influential visualization designers. My results highlight challenges that authors face and expose assumptions and inconsistencies in beliefs about the role of uncertainty in visualization. In particular, a clear contradiction arises between authors' acknowledgment of the value of depicting uncertainty and the norm of omitting direct depiction of uncertainty. To help explain this contradiction, I present a rhetorical model of uncertainty omission in visualization-based communication. I also adapt a formal statistical model of how viewers judge the strength of a signal in a visualization to visualization-based communication, to argue that uncertainty communication necessarily reduces degrees of freedom in viewers' statistical inferences. I conclude with recommendations for how visualization research on uncertainty communication could better serve practitioners' current needs and values while deepening understanding of assumptions that reinforce uncertainty omission.",Jessica Hullman,Jessica Hullman,Northwestern University,10.1109/tvcg.2016.2598862;10.1109/tvcg.2011.255;10.1109/tvcg.2018.2864889;10.1109/tvcg.2018.2864909;10.1109/tvcg.2010.161;10.1109/tvcg.2014.2346298;10.1109/tvcg.2016.2598862,"Uncertainty visualization,graphical statistical inference,visualization rhetoric",97.0,87.0,55.0,2598.0,,,visualization research uncertainty;rule media articles;better;serve practitioners;necessarily reduces degrees,0.7483;0.1476;0.1162;0.0599;0.0291,"[np.int64(-1), -1, -1, -1, -1]",-1;-1;-1;-1;-1,,-1
InfoVis,2010,Pargnostics: Screen-Space Metrics for Parallel Coordinates,10.1109/tvcg.2010.184,http://dx.doi.org/10.1109/TVCG.2010.184,1017.0,1026.0,J,"Interactive visualization requires the translation of data into a screen space of limited resolution. While currently ignored by most visualization models, this translation entails a loss of information and the introduction of a number of artifacts that can be useful, (e.g., aggregation, structures) or distracting (e.g., over-plotting, clutter) for the analysis. This phenomenon is observed in parallel coordinates, where overlapping lines between adjacent axes form distinct patterns, representing the relation between variables they connect. However, even for a small number of dimensions, the challenge is to effectively convey the relationships for all combinations of dimensions. The size of the dataset and a large number of dimensions only add to the complexity of this problem. To address these issues, we propose Pargnostics, parallel coordinates diagnostics, a model based on screen-space metrics that quantify the different visual structures. Pargnostics metrics are calculated for pairs of axes and take into account the resolution of the display as well as potential axis inversions. Metrics include the number of line crossings, crossing angles, convergence, overplotting, etc. To construct a visualization view, the user can pick from a ranked display showing pairs of coordinate axes and the structures between them, or examine all possible combinations of axes at once in a matrix display. Picking the best axes layout is an NP-complete problem in general, but we provide a way of automatically optimizing the display according to the user's preferences based on our metrics and model.",Aritra Dasgupta;Robert Kosara,Aritra Dasgupta;Robert Kosara,"UNC-Charlotte, USA;UNC-Charlotte, USA",10.1109/infvis.2005.1532142;10.1109/tvcg.2006.138;10.1109/visual.1990.146402;10.1109/vast.2006.261423;10.1109/vast.2009.5332628;10.1109/infvis.2005.1532136;10.1109/infvis.1998.729559;10.1109/infvis.1997.636793;10.1109/infvis.2005.1532142,"Parallel coordinates, metrics, display optimization, visualization models",163.0,102.0,32.0,1207.0,,,interactive visualization requires;axes matrix;overlapping lines;inversions metrics;resolution currently ignored,0.6396;0.3388;0.3335;0.1644;0.1606,"[np.int64(-1), -1, -1, -1, -1]",194;-1;-1;-1;-1,194,194
VAST,2017,Analyzing the Training Processes of Deep Generative Models,10.1109/tvcg.2017.2744938,http://dx.doi.org/10.1109/TVCG.2017.2744938,77.0,87.0,J,"Among the many types of deep models, deep generative models (DGMs) provide a solution to the important problem of unsupervised and semi-supervised learning. However, training DGMs requires more skill, experience, and know-how because their training is more complex than other types of deep models such as convolutional neural networks (CNNs). We develop a visual analytics approach for better understanding and diagnosing the training process of a DGM. To help experts understand the overall training process, we first extract a large amount of time series data that represents training dynamics (e.g., activation changes over time). A blue-noise polyline sampling scheme is then introduced to select time series samples, which can both preserve outliers and reduce visual clutter. To further investigate the root cause of a failed training process, we propose a credit assignment algorithm that indicates how other neurons contribute to the output of the neuron causing the training failure. Two case studies are conducted with machine learning experts to demonstrate how our approach helps understand and diagnose the training processes of DGMs. We also show how our approach can be directly used to analyze other types of deep models, such as CNNs.",Mengchen Liu;Jiaxin Shi;Kelei Cao;Jun Zhu 0001;Shixia Liu,Mengchen Liu;Jiaxin Shi;Kelei Cao;Jun Zhu;Shixia Liu,"Tsinghua University, National Engineering Lab for Big Data Software;Tsinghua University;Tsinghua University, National Engineering Lab for Big Data Software;Tsinghua University;Tsinghua University, National Engineering Lab for Big Data Software",10.1109/tvcg.2016.2598496;10.1109/tvcg.2014.2346594;10.1109/tvcg.2010.131;10.1109/tvcg.2011.239;10.1109/tvcg.2016.2598831;10.1109/tvcg.2016.2598797;10.1109/tvcg.2016.2598838;10.1109/tvcg.2016.2598829;10.1109/visual.2005.1532820;10.1109/vast.2016.7883511;10.1109/tvcg.2016.2598664;10.1109/tvcg.2010.132;10.1109/tvcg.2016.2598496,"deep learning,deep generative models,blue noise sampling,credit assignment",134.0,116.0,55.0,3126.0,,,deep generative;visual analytics;large time series;understanding diagnosing;blue noise polyline,0.6353;0.3519;0.2768;0.2458;0.2218,"[np.int64(-1), np.int64(-1), -1, -1, -1]",50;201;-1;-1;-1,50;201,50
VAST,2014,The Spinel Explorer - Interactive Visual Analysis of Spinel Group Minerals,10.1109/tvcg.2014.2346754,http://dx.doi.org/10.1109/TVCG.2014.2346754,1913.0,1922.0,J,"Geologists usually deal with rocks that are up to several thousand million years old. They try to reconstruct the tectonic settings where these rocks were formed and the history of events that affected them through the geological time. The spinel group minerals provide useful information regarding the geological environment in which the host rocks were formed. They constitute excellent indicators of geological environments (tectonic settings) and are of invaluable help in the search for mineral deposits of economic interest. The current workflow requires the scientists to work with different applications to analyze spine data. They do use specific diagrams, but these are usually not interactive. The current workflow hinders domain experts to fully exploit the potentials of tediously and expensively collected data. In this paper, we introduce the Spinel Explorer-an interactive visual analysis application for spinel group minerals. The design of the Spinel Explorer and of the newly introduced interactions is a result of a careful study of geologists' tasks. The Spinel Explorer includes most of the diagrams commonly used for analyzing spinel group minerals, including 2D binary plots, ternary plots, and 3D Spinel prism plots. Besides specific plots, conventional information visualization views are also integrated in the Spinel Explorer. All views are interactive and linked. The Spinel Explorer supports conventional statistics commonly used in spinel minerals exploration. The statistics views and different data derivation techniques are fully integrated in the system. Besides the Spinel Explorer as newly proposed interactive exploration system, we also describe the identified analysis tasks, and propose a new workflow. We evaluate the Spinel Explorer using real-life data from two locations in Argentina: the Frontal Cordillera in Central Andes and Patagonia. We describe the new findings of the geologists which would have been much more difficult to achieve using the current workflow only. Very positive feedback from geologists confirms the usefulness of the Spinel Explorer.",Maria Luján Ganuza;Gabriela Ferracutti;Maria Florencia Gargiulo;Silvia Mabel Castro;Ernesto A. Bjerg;M. Eduard Gröller;Kresimir Matkovic,María Luján Ganuza;Gabriela Ferracutti;María Florencia Gargiulo;Silvia Mabel Castro;Ernesto Bjerg;Eduard Gröller;Krešimir Matković,"VyGLab Research Laboratory at the Universidad Nacional del Sur, Bahía Blanca, Argentina;Departamento de Geología, Universidad Nacional del Sur, Bahía Blanca, Argentina;Departamento de Geología, Universidad Nacional del Sur, Bahía Blanca, Argentina;VyGLab Research Laboratory at the Universidad Nacional del Sur, Bahía Blanca, Argentina;Departamento de Geología, Universidad Nacional del Sur, Bahía Blanca, Argentina;Vienna University of Technology, Austria;VRVis Research Center, Vienna, Austria",10.1109/infvis.2000.885086;10.1109/tvcg.2009.155;10.1109/visual.1995.485139,"Interactive visual analysis, visualization in earth/space/ and environmental sciences, coordinated and multiple views, design studies",21.0,12.0,29.0,664.0,,,spinel minerals exploration;explorer supports;interactive current workflow;statistics views different;hinders domain,0.6622;0.1978;0.1891;0.1877;-0.0340,"[np.int64(-1), -1, -1, -1, -1]",278;-1;-1;-1;-1,278,278
InfoVis,2007,NodeTrix: a Hybrid Visualization of Social Networks,10.1109/tvcg.2007.70582,http://dx.doi.org/10.1109/TVCG.2007.70582,1302.0,1309.0,J,"The need to visualize large social networks is growing as hardware capabilities make analyzing large networks feasible and many new data sets become available. Unfortunately, the visualizations in existing systems do not satisfactorily resolve the basic dilemma of being readable both for the global structure of the network and also for detailed analysis of local communities. To address this problem, we present NodeTrix, a hybrid representation for networks that combines the advantages of two traditional representations: node-link diagrams are used to show the global structure of a network, while arbitrary portions of the network can be shown as adjacency matrices to better support the analysis of communities. A key contribution is a set of interaction techniques. These allow analysts to create a NodeTrix visualization by dragging selections to and from node-link and matrix forms, and to flexibly manipulate the NodeTrix representation to explore the dataset and create meaningful summary visualizations of their findings. Finally, we present a case study applying NodeTrix to the analysis of the InfoVis 2004 coauthorship dataset to illustrate the capabilities of NodeTrix as both an exploration tool and an effective means of communicating results.",Nathalie Henry;Jean-Daniel Fekete;Michael J. McGuffin,Nathalie Henry;Jean-Daniel Fekete;Michael J. McGuffin,"University of Sydney, Australia and INRIA Futurs, University of Paris-Sud 11, France;INRIA Futurs and Laboratory RI UMR CNRS 5800, France;Ontario Cancer Institute, University of Toronto, Canada",10.1109/tvcg.2006.160;10.1109/vast.2006.261426;10.1109/infvis.2005.1532126;10.1109/infvis.2004.46;10.1109/tvcg.2006.193;10.1109/infvis.2005.1532129;10.1109/tvcg.2006.166;10.1109/tvcg.2006.147;10.1109/infvis.2004.64;10.1109/infvis.2003.1249011;10.1109/tvcg.2006.160,"Network visualization, Matrix visualization, Hybrid visualization, Aggregation, Interaction",675.0,383.0,35.0,4341.0,,,visualize large social;capabilities nodetrix;matrix forms;unfortunately;dragging selections,0.6996;0.2556;0.1249;0.0841;0.0737,"[np.int64(-1), -1, -1, -1, -1]",169;-1;-1;-1;-1,169,169
InfoVis,2016,Gaussian Cubes: Real-Time Modeling for Visual Exploration of Large Multidimensional Datasets,10.1109/tvcg.2016.2598694,http://dx.doi.org/10.1109/TVCG.2016.2598694,681.0,690.0,J,"Recently proposed techniques have finally made it possible for analysts to interactively explore very large datasets in real time. However powerful, the class of analyses these systems enable is somewhat limited: specifically, one can only quickly obtain plots such as histograms and heatmaps. In this paper, we contribute Gaussian Cubes, which significantly improves on state-of-the-art systems by providing interactive modeling capabilities, which include but are not limited to linear least squares and principal components analysis (PCA). The fundamental insight in Gaussian Cubes is that instead of precomputing counts of many data subsets (as state-of-the-art systems do), Gaussian Cubes precomputes the best multivariate Gaussian for the respective data subsets. As an example, Gaussian Cubes can fit hundreds of models over millions of data points in well under a second, enabling novel types of visual exploration of such large datasets. We present three case studies that highlight the visualization and analysis capabilities in Gaussian Cubes, using earthquake safety simulations, astronomical catalogs, and transportation statistics. The dataset sizes range around one hundred million elements and 5 to 10 dimensions. We present extensive performance results, a discussion of the limitations in Gaussian Cubes, and future research directions.",Zhe Wang;Nivan Ferreira;Youhao Wei;Aarthy Sankari Bhaskar;Carlos Scheidegger,Zhe Wang;Nivan Ferreira;Youhao Wei;Aarthy Sankari Bhaskar;Carlos Scheidegger,University of Arizona;Universidade Federal de Pernambuco;University of Arizona;University of Arizona;University of Arizona,10.1109/vast.2008.4677357;10.1109/infvis.2000.885086;10.1109/tvcg.2013.179;10.1109/tvcg.2014.2346452;10.1109/tvcg.2009.129;10.1109/tvcg.2013.141;10.1109/tvcg.2014.2346325;10.1109/vast.2012.6400490,data cubes;Data modeling;dimensionality reduction;interactive visualization,61.0,37.0,45.0,1167.0,,,gaussian cubes precomputes;studies highlight visualization;astronomical catalogs transportation;earthquake;enable somewhat limited,0.5705;0.3616;0.2544;0.1783;-0.0009,"[np.int64(-1), -1, -1, -1, -1]",286;-1;-1;-1;-1,286,286
InfoVis,2010,The FlowVizMenu and Parallel Scatterplot Matrix: Hybrid Multidimensional Visualizations for Network Exploration,10.1109/tvcg.2010.205,http://dx.doi.org/10.1109/TVCG.2010.205,1100.0,1108.0,J,"A standard approach for visualizing multivariate networks is to use one or more multidimensional views (for example, scatterplots) for selecting nodes by various metrics, possibly coordinated with a node-link view of the network. In this paper, we present three novel approaches for achieving a tighter integration of these views through hybrid techniques for multidimensional visualization, graph selection and layout. First, we present the FlowVizMenu, a radial menu containing a scatterplot that can be popped up transiently and manipulated with rapid, fluid gestures to select and modify the axes of its scatterplot. Second, the FlowVizMenu can be used to steer an attribute-driven layout of the network, causing certain nodes of a node-link diagram to move toward their corresponding positions in a scatterplot while others can be positioned manually or by force-directed layout. Third, we describe a novel hybrid approach that combines a scatterplot matrix (SPLOM) and parallel coordinates called the Parallel Scatterplot Matrix (P-SPLOM), which can be used to visualize and select features within the network. We also describe a novel arrangement of scatterplots called the Scatterplot Staircase (SPLOS) that requires less space than a traditional scatterplot matrix. Initial user feedback is reported.",Christophe Viau;Michael J. McGuffin;Yves Chiricota;Igor Jurisica,Christophe Viau;Michael J. McGuffin;Yves Chiricota;Igor Jurisica,"École de technologie supérieure, Montreal, Canada;École de technologie supérieure, Montreal, Canada;Université du Quàbec à Chicoutimi, Chicoutimi, Canada;Ontario Cancer Institute, PMH UHN, Toronto, Canada",10.1109/tvcg.2009.151;10.1109/infvis.2005.1532142;10.1109/tvcg.2007.70523;10.1109/tvcg.2009.179;10.1109/vast.2009.5332586;10.1109/infvis.2005.1532141;10.1109/tvcg.2006.187;10.1109/infvis.2004.47;10.1109/tvcg.2007.70521;10.1109/infvis.2003.1249011;10.1109/tvcg.2008.153;10.1109/tvcg.2009.151,"Interactive graph drawing, network layout, attribute-driven layout, parallel coordinates, scatterplot matrix, radial menu",104.0,67.0,39.0,1480.0,,,visualizing multivariate networks;driven layout;gestures select modify;certain nodes node;standard,0.7594;0.2834;0.2561;0.2016;-0.0079,"[np.int64(-1), -1, -1, -1, -1]",169;-1;-1;-1;-1,169,169
VAST,2020,A Visual Analytics Approach for Ecosystem Dynamics based on Empirical Dynamic Modeling,10.1109/tvcg.2020.3028956,http://dx.doi.org/10.1109/TVCG.2020.3028956,506.0,516.0,J,"An important approach for scientific inquiry across many disciplines involves using observational time series data to understand the relationships between key variables to gain mechanistic insights into the underlying rules that govern the given system. In real systems, such as those found in ecology, the relationships between time series variables are generally not static; instead, these relationships are dynamical and change in a nonlinear or state-dependent manner. To further understand such systems, we investigate integrating methods that appropriately characterize these dynamics (i.e., methods that measure interactions as they change with time-varying system states) with visualization techniques that can help analyze the behavior of the system. Here, we focus on empirical dynamic modeling (EDM) as a state-of-the-art method that specifically identifies causal variables and measures changing state-dependent relationships between time series variables. Instead of using approaches centered on parametric equations, EDM is an equation-free approach that studies systems based on their dynamic attractors. We propose a visual analytics system to support the identification and mechanistic interpretation of system states using an EDM-constructed dynamic graph. This work, as detailed in four analysis tasks and demonstrated with a GUI, provides a novel synthesis of EDM and visualization techniques such as brush-link visualization and visual summarization to interpret dynamic graphs representing ecosystem dynamics. We applied our proposed system to ecological simulation data and real data from a marine mesocosm study as two key use cases. Our case studies show that our visual analytics tools support the identification and interpretation of the system state by the user, and enable us to discover both confirmatory and new findings in ecosystem dynamics. Overall, we demonstrated that our system can facilitate an understanding of how systems function beyond the intuitive analysis of high-dimensional information based on specific domain knowledge.",Hiroaki Natsukawa;Ethan R. Deyle;Gerald M. Pao;Koji Koyamada;George Sugihara,Hiroaki Natsukawa;Ethan R. Deyle;Gerald M. Pao;Koji Koyamada;George Sugihara,"Kyoto University;Boston University and Scripps Institution of Oceanography, University of California, San Diego;Salk Institution for Biological Sciences;Kyoto University;Scripps Institution of Oceanography, University of California, San Diego",10.1109/tvcg.2009.181;10.1109/tvcg.2019.2934251;10.1109/tvcg.2013.198;10.1109/tvcg.2006.192;10.1109/tvcg.2015.2468078;10.1109/tvcg.2017.2745258;10.1109/tvcg.2009.181,"Visual analytics,empirical dynamic modeling,dynamic network,exploratory data analysis",4.0,7.0,58.0,1153.0,,,representing ecosystem dynamics;mechanistic insights underlying;techniques brush;enable discover confirmatory;case,0.6974;0.3436;0.1183;0.0408;-0.0517,"[np.int64(-1), -1, -1, -1, -1]",215;-1;-1;-1;-1,215,215
Vis,1996,Case Study: Visual access for landscape event based temporal data,10.1109/visual.1996.568148,http://dx.doi.org/10.1109/VISUAL.1996.568148,425.0,428.0,C,As ecological awareness increases there has been a shift towards more integrated forest management. Accurate modeling of future states of forested landscapes will allow better planning for safeguarding our forest resource for future generations. We present an initial exploration into providing visual access to information generated by SELES (Spatially Explicit Landscape Event Simulator). We explore the application of our visual access distortion technique to a block of temporal data created from a sequence of landscape event based information. This type of access extends the possibilities of visual exploration for temporal and spatial interrelations in a data set.,M. Sheelagh T. Carpendale;Andrew Fall;David J. Cowperthwaite;Joseph Fall;F. David Fracchia,M. Sheelagh T. Carpendale;A. Fall;D.J. Cowperthwaite;J. Fall;F.D. Fracchia,"Simon Fraser University, Burnaby, BC, CA;Simon Fraser University, Burnaby, BC, CA;Simon Fraser University, Burnaby, BC, CA;Simon Fraser University, Burnaby, BC, CA;Simon Fraser University, Burnaby, BC, CA",,"distortion viewing, 3D interaction, information visualization, temporal data",12.0,4.0,4.0,90.0,,,landscape event simulator;safeguarding forest resource;interrelations data;access extends possibilities;seles,0.5539;0.3467;0.2581;0.2084;0.0528,"[np.int64(-1), -1, -1, -1, -1]",215;-1;-1;-1;-1,215,215
VAST,2007,VAST 2007 Contest - Blue Iguanodon,10.1109/vast.2007.4389032,http://dx.doi.org/10.1109/VAST.2007.4389032,231.0,232.0,M,Visual analytics experts realize that one effective way to push the field forward and to develop metrics for measuring the performance of various visual analytics components is to hold an annual competition. The second visual analytics science and technology (VAST) contest was held in conjunction with the 2007 IEEE VAST symposium. In this contest participants were to use visual analytic tools to explore a large heterogeneous data collection to construct a scenario and find evidence buried in the data of illegal and terrorist activities that were occurring. A synthetic data set was made available as well as tasks. In this paper we describe some of the advances we have made from the first competition held in 2006.,Georges G. Grinstein;Catherine Plaisant;Sharon J. Laskowski;Theresa A. O'Connell;Jean Scholtz;Mark A. Whiting,Georges Grinstein;Catherine Plaisant;Sharon Laskowski;Theresa O'Connell;Jean Scholtz;Mark Whiting,"University of Massachusetts, Lowell, USA;National Institute for Standards and Technology, USA;National Institute for Standards and Technology, USA;Pacific Northwest National Laboratory, USA;Pacific Northwest National Laboratory, USA;University of Maryland, USA",,,17.0,10.0,6.0,121.0,,,visual analytics science;scenario evidence buried;illegal terrorist;hold annual competition;set available tasks,0.7134;0.2577;0.2463;0.1454;-0.0093,"[np.int64(-1), -1, -1, -1, -1]",201;-1;-1;-1;-1,201,201
SciVis,2020,ChemVA: Interactive Visual Analysis of Chemical Compound Similarity in Virtual Screening,10.1109/tvcg.2020.3030438,http://dx.doi.org/10.1109/TVCG.2020.3030438,891.0,901.0,J,"In the modern drug discovery process, medicinal chemists deal with the complexity of analysis of large ensembles of candidate molecules. Computational tools, such as dimensionality reduction (DR) and classification, are commonly used to efficiently process the multidimensional space of features. These underlying calculations often hinder interpretability of results and prevent experts from assessing the impact of individual molecular features on the resulting representations. To provide a solution for scrutinizing such complex data, we introduce ChemVA, an interactive application for the visual exploration of large molecular ensembles and their features. Our tool consists of multiple coordinated views: Hexagonal view, Detail view, 3D view, Table view, and a newly proposed Difference view designed for the comparison of DR projections. These views display DR projections combined with biological activity, selected molecular features, and confidence scores for each of these projections. This conjunction of views allows the user to drill down through the dataset and to efficiently select candidate compounds. Our approach was evaluated on two case studies of finding structurally similar ligands with similar binding affinity to a target protein, as well as on an external qualitative evaluation. The results suggest that our system allows effective visual inspection and comparison of different high-dimensional molecular representations. Furthermore, ChemVA assists in the identification of candidate compounds while providing information on the certainty behind different molecular representations.",María Virginia Sabando;Pavol Ulbrich;Matias Nicolás Selzer;Jan Byska;Jan Mican;Ignacio Ponzoni;Axel J. Soto;Maria Luján Ganuza;Barbora Kozlíková,María Virginia Sabando;Pavol Ulbrich;Matías Selzer;Jan Byška;Jan Mičan;Ignacio Ponzoni;Axel J. Soto;María Luján Ganuza;Barbora Kozlíková,"Department of Computer Science and Engineering, Universidad Nacional del Sur, Institute for Computer Science and Engineering (UNS-CONICET), Bahía, Blanca, Argentina and Department of Computer Science and Engineering, Universidad Nacional del Sur, VyGLab Research Laboratory (UNS-CICPBA), Institute for Computer Science and Engineering (UNS-CONICET), Bahía, Blanca, Argentina;Faculty of Informatics, Masaryk University, Brno, Czech Republic;Department of Computer Science and Engineering, Universidad Nacional del Sur, Institute for Computer Science and Engineering (UNS-CONICET), Bahía, Blanca, Argentina and Department of Computer Science and Engineering, Universidad Nacional del Sur, VyGLab Research Laboratory (UNS-CICPBA), Institute for Computer Science and Engineering (UNS-CONICET), Bahía, Blanca, Argentina;Faculty of Informatics, Masaryk University, Brno, Czech Republic;Department of Experimental Biology and RECETOX, Loschmidt Laboratories, Faculty of Medicine Masaryk University, Brno, Czech Republic;Department of Computer Science and Engineering, Universidad Nacional del Sur, Institute for Computer Science and Engineering (UNS-CONICET), Bahía, Blanca, Argentina and Department of Computer Science and Engineering, Universidad Nacional del Sur, VyGLab Research Laboratory (UNS-CICPBA), Institute for Computer Science and Engineering (UNS-CONICET), Bahía, Blanca, Argentina;Department of Computer Science and Engineering, Universidad Nacional del Sur, Institute for Computer Science and Engineering (UNS-CONICET), Bahía, Blanca, Argentina and Department of Computer Science and Engineering, Universidad Nacional del Sur, VyGLab Research Laboratory (UNS-CICPBA), Institute for Computer Science and Engineering (UNS-CONICET), Bahía, Blanca, Argentina;Department of Computer Science and Engineering, Universidad Nacional del Sur, Institute for Computer Science and Engineering (UNS-CONICET), Bahía, Blanca, Argentina and Department of Computer Science and Engineering, Universidad Nacional del Sur, VyGLab Research Laboratory (UNS-CICPBA), Institute for Computer Science and Engineering (UNS-CONICET), Bahía, Blanca, Argentina;Faculty of Informatics, Masaryk University, Brno, Czech Republic",10.1109/tvcg.2019.2934209;10.1109/tvcg.2011.185;10.1109/tvcg.2013.173;10.1109/tvcg.2016.2598495;10.1109/tvcg.2013.153;10.1109/tvcg.2019.2934209,"Virtual screening,visual analysis,dimensionality reduction,coordinated views,cheminformatics",4.0,9.0,79.0,665.0,,,candidate molecules computational;hinder interpretability results;projections views display;user drill dataset;qualitative,0.5921;0.2879;0.2414;0.1289;0.1061,"[np.int64(-1), -1, -1, -1, -1]",119;-1;-1;-1;-1,119,119
Vis,2008,Interactive Visualization and Analysis of Transitional Flow,10.1109/tvcg.2008.146,http://dx.doi.org/10.1109/TVCG.2008.146,1420.0,1427.0,J,"A stand-alone visualization application has been developed by a multi-disciplinary, collaborative team with the sole purpose of creating an interactive exploration environment allowing turbulent flow researchers to experiment and validate hypotheses using visualization. This system has specific optimizations made in data management, caching computations, and visualization allowing for the interactive exploration of datasets on the order of 1TB in size. Using this application, the user (co-author Calo) is able to interactively visualize and analyze all regions of a transitional flow volume, including the laminar, transitional and fully turbulent regions. The underlying goal of the visualizations produced from these transitional flow simulations is to localize turbulent spots in the laminar region of the boundary layer, determine under which conditions they form, and follow their evolution. The initiation of turbulent spots, which ultimately lead to full turbulence, was located via a proposed feature detection condition and verified by experimental results. The conditions under which these turbulent spots form and coalesce are validated and presented.",Gregory P. Johnson;Victor M. Calo;Kelly P. Gaither,"Gregory P. Johnson,;Victor M. Calo;Kelly P. Gaither","Texas Advanced Computing Center, The University of Texas, Austin;Texas Advanced Computing Center, University of Technology, Austin, USA and Institute for Computational and Engineering Sciences, The University of Texas, Austin;Texas Advanced Computing Center, University of Technology, Austin, USA and Texas Advanced Computing Center, The University of Texas, Austin",10.1109/visual.2005.1532792;10.1109/visual.1993.398850;10.1109/visual.2005.1532794;10.1109/visual.1991.175818;10.1109/visual.2004.55;10.1109/visual.2004.54,"Applications of Visualization, Flow Visualization, Transitional Flow, Turbulence",11.0,8.0,31.0,323.0,,,turbulent flow researchers;interactively visualize;laminar region boundary;follow evolution initiation;localize,0.7199;0.2904;0.2775;0.0792;-0.1823,"[np.int64(-1), -1, -1, -1, -1]",66;-1;-1;-1;-1,66,66
Vis,2007,Querying and Creating Visualizations by Analogy,10.1109/tvcg.2007.70584,http://dx.doi.org/10.1109/TVCG.2007.70584,1560.0,1567.0,J,"While there have been advances in visualization systems, particularly in multi-view visualizations and visual exploration, the process of building visualizations remains a major bottleneck in data exploration. We show that provenance metadata collected during the creation of pipelines can be reused to suggest similar content in related visualizations and guide semi-automated changes. We introduce the idea of query-by-example in the context of an ensemble of visualizations, and the use of analogies as first-class operations in a system to guide scalable interactions. We describe an implementation of these techniques in VisTrails, a publicly-available, open-source system.",Carlos Eduardo Scheidegger;Huy T. Vo;David Koop;Juliana Freire;Cláudio T. Silva,Carlos Scheidegger;Huy Vo;David Koop;Juliana Freire;Claudio Silva,"Scientific Computing and Imaging (SCI) Institute, University of Utah, USA;Scientific Computing and Imaging (SCI) Institute, University of Utah, USA;Scientific Computing and Imaging (SCI) Institute, University of Utah, USA;School of Computing, University of Utah, USA;Scientific Computing and Imaging (SCI) Institute, University of Utah, USA",10.1109/visual.2005.1532781;10.1109/infvis.2004.2;10.1109/visual.2004.112;10.1109/visual.2005.1532788;10.1109/visual.2005.1532795;10.1109/visual.2005.1532781,"visualization systems, query-by-example, analogy",160.0,70.0,31.0,594.0,BP,,building visualizations;provenance metadata;pipelines reused;suggest similar content;particularly,0.6312;0.4755;0.2436;0.2272;0.0794,"[np.int64(-1), -1, -1, -1, -1]",210;-1;-1;-1;-1,210,210
VAST,2016,VisFlow - Web-based Visualization Framework for Tabular Data with a Subset Flow Model,10.1109/tvcg.2016.2598497,http://dx.doi.org/10.1109/TVCG.2016.2598497,251.0,260.0,J,"Data flow systems allow the user to design a flow diagram that specifies the relations between system components which process, filter or visually present the data. Visualization systems may benefit from user-defined data flows as an analysis typically consists of rendering multiple plots on demand and performing different types of interactive queries across coordinated views. In this paper, we propose VisFlow, a web-based visualization framework for tabular data that employs a specific type of data flow model called the subset flow model. VisFlow focuses on interactive queries within the data flow, overcoming the limitation of interactivity from past computational data flow systems. In particular, VisFlow applies embedded visualizations and supports interactive selections, brushing and linking within a visualization-oriented data flow. The model requires all data transmitted by the flow to be a data item subset (i.e. groups of table rows) of some original input table, so that rendering properties can be assigned to the subset unambiguously for tracking and comparison. VisFlow features the analysis flexibility of a flow diagram, and at the same time reduces the diagram complexity and improves usability. We demonstrate the capability of VisFlow on two case studies with domain experts on real-world datasets showing that VisFlow is capable of accomplishing a considerable set of visualization and analysis tasks. The VisFlow system is available as open source on GitHub.",Bowen Yu 0004;Cláudio T. Silva,Bowen Yu;Cláudio T. Silva,New York University;New York University,10.1109/tvcg.2009.195;10.1109/infvis.2004.12;10.1109/vast.2011.6102440;10.1109/infvis.1998.729560;10.1109/tvcg.2014.2346260;10.1109/infvis.2005.1532136;10.1109/tvcg.2011.225;10.1109/infvis.2003.1249013;10.1109/visual.2005.1532788;10.1109/tvcg.2014.2346753;10.1109/tvcg.2011.185;10.1109/tvcg.2014.2346291;10.1109/tvcg.2009.195,Visualization framework;data flow;subset flow model;tabular data,45.0,43.0,47.0,2370.0,,,data visualization;framework tabular;model visflow focuses;subset groups;limitation interactivity past,0.6549;0.2790;0.2140;0.1909;0.1538,"[np.int64(-1), -1, -1, -1, -1]",203;-1;-1;-1;-1,203,203
Vis,2002,NASA's great zooms: a case study,10.1109/visual.2002.1183825,http://dx.doi.org/10.1109/VISUAL.2002.1183825,541.0,544.0,C,"This paper examines a series of NASA outreach visualizations created using several layers of remote sensing satellite data ranging from 4-kilometers per pixel to I-meter per pixel. The viewer is taken on a seamless, cloud free journey from a global view of the Earth down to ground level where buildings, streets, and cars are visible. The visualizations were produced using a procedural shader that takes advantage of accurate georegistration and color matching between images. The shader accurately and efficiently maps the data sets to geometry allowing for animations with few perceptual transitions among data sets. We developed a pipeline to facilitate the production of over twenty zoom visualizations. Millions of people have seen these visualizations through national and international media coverage.",Gregory W. Shirah;Horace Mitchell,G.W. Shirah;H.G. Mitchell,"Scientific Visualization Studio, NASA Goddard Space Flight Center, USA;Scientific Visualization Studio, NASA Goddard Space Flight Center, USA",,"visualization, remote sensing, renderman, shader, georegistration, color matching",0.0,0.0,11.0,120.0,,,nasa outreach visualizations;animations perceptual transitions;images shader accurately;level buildings streets;takes advantage,0.6192;0.3521;0.3128;0.1819;0.0875,"[np.int64(-1), -1, -1, -1, -1]",322;-1;-1;-1;-1,322,322
InfoVis,2006,Visualization of Barrier Tree Sequences,10.1109/tvcg.2006.196,http://dx.doi.org/10.1109/TVCG.2006.196,781.0,788.0,J,"Dynamical models that explain the formation of spatial structures of RNA molecules have reached a complexity that requires novel visualization methods that help to analyze the validity of these models. We focus on the visualization of so-called folding landscapes of a growing RNA molecule. Folding landscapes describe the energy of a molecule as a function of its spatial configuration; thus they are huge and high dimensional. Their most salient features, however, are encapsulated by their so-called barrier tree that reflects the local minima and their connecting saddle points. For each length of the growing RNA chain there exists a folding landscape. We visualize the sequence of folding landscapes by an animation of the corresponding barrier trees. To generate the animation, we adapt the foresight layout with tolerance algorithm for general dynamic graph layout problems. Since it is very general, we give a detailed description of each phase: constructing a supergraph for the trees, layout of that supergraph using a modified DOT algorithm, and presentation techniques for the final animation",Christian Heine 0002;Gerik Scheuermann;Christoph Flamm;Ivo L. Hofacker;Peter F. Stadler,Christian Heine;Gerik Scheuermann;Christoph Flamm;Ivo L. Hofacker;Peter F. Stadler,"Image and Signal Processing Group, Department of Computer Science, University of Leipzig, Germany;Image and Signal Processing Group, Department of Computer Science, University of Leipzig, Germany;Bioinformatics Group, Department of Computer Science, University of Leipzig, Germany;Department of Theoretical Chemistry and Structural Biology, University of Vienna, Germany;Bioinformatics Group, Department of Computer Science, University of Leipzig, Germany",10.1109/infvis.2004.18;10.1109/infvis.2004.18,"Graph drawing, dynamic graph, RNA folding, energy landscape, fitness landscape, barrier tree",22.0,13.0,25.0,347.0,,,visualize sequence folding;spatial configuration huge;energy molecule function;tolerance algorithm general;tree,0.6288;0.3042;0.2203;0.1596;0.1468,"[np.int64(-1), -1, -1, -1, -1]",301;-1;-1;-1;-1,301,301
InfoVis,2020,A Bayesian cognition approach for belief updating of correlation judgement through uncertainty visualizations,10.1109/tvcg.2020.3029412,http://dx.doi.org/10.1109/TVCG.2020.3029412,978.0,988.0,J,"Understanding correlation judgement is important to designing effective visualizations of bivariate data. Prior work on correlation perception has not considered how factors including prior beliefs and uncertainty representation impact such judgements. The present work focuses on the impact of uncertainty communication when judging bivariate visualizations. Specifically, we model how users update their beliefs about variable relationships after seeing a scatterplot with and without uncertainty representation. To model and evaluate the belief updating, we present three studies. Study 1 focuses on a proposed “Line + Cone” visual elicitation method for capturing users' beliefs in an accurate and intuitive fashion. The findings reveal that our proposed method of belief solicitation reduces complexity and accurately captures the users' uncertainty about a range of bivariate relationships. Study 2 leverages the “Line + Cone” elicitation method to measure belief updating on the relationship between different sets of variables when seeing correlation visualization with and without uncertainty representation. We compare changes in users beliefs to the predictions of Bayesian cognitive models which provide normative benchmarks for how users should update their prior beliefs about a relationship in light of observed data. The findings from Study 2 revealed that one of the visualization conditions with uncertainty communication led to users being slightly more confident about their judgement compared to visualization without uncertainty information. Study 3 builds on findings from Study 2 and explores differences in belief update when the bivariate visualization is congruent or incongruent with users' prior belief. Our results highlight the effects of incorporating uncertainty representation, and the potential of measuring belief updating on correlation judgement with Bayesian cognitive models.",Alireza Karduni;Douglas Markant;Ryan Wesslen;Wenwen Dou,Alireza Karduni;Douglas Markant;Ryan Wesslen;Wenwen Dou,"University of North Carolina, Charlotte;University of North Carolina, Charlotte;University of North Carolina, Charlotte;University of North Carolina, Charlotte",10.1109/tvcg.2014.2346979;10.1109/tvcg.2019.2934287;10.1109/tvcg.2017.2743898;10.1109/tvcg.2018.2864889;10.1109/tvcg.2018.2864909;10.1109/tvcg.2015.2467671;10.1109/tvcg.2017.2745240;10.1109/tvcg.2010.177;10.1109/tvcg.2012.279;10.1109/tvcg.2012.199;10.1109/tvcg.2015.2467758;10.1109/tvcg.2013.153;10.1109/tvcg.2014.2346979,"Information visualization,Bayesian modeling,uncertainty visualizations,correlations,belief elicitation",22.0,14.0,59.0,911.0,,,correlation visualization uncertainty;models provide normative;different sets variables;incongruent;users update,0.6619;0.2804;0.1482;0.1320;0.0604,"[np.int64(-1), -1, -1, -1, -1]",159;-1;-1;-1;-1,159,159
InfoVis,2007,VisLink: Revealing Relationships Amongst Visualizations,10.1109/tvcg.2007.70521,http://dx.doi.org/10.1109/TVCG.2007.70521,1192.0,1199.0,J,"We present VisLink, a method by which visualizations and the relationships between them can be interactively explored. VisLink readily generalizes to support multiple visualizations, empowers inter-representational queries, and enables the reuse of the spatial variables, thus supporting efficient information encoding and providing for powerful visualization bridging. Our approach uses multiple 2D layouts, drawing each one in its own plane. These planes can then be placed and re-positioned in 3D space: side by side, in parallel, or in chosen placements that provide favoured views. Relationships, connections, and patterns between visualizations can be revealed and explored using a variety of interaction techniques including spreading activation and search filters.",Christopher Collins 0001;Sheelagh Carpendale,Christopher Collins;Sheelagh Carpendale,"Computer Science Department, Univeristy of Toronto, Canada;Computer Science Department, University of Calgary, Canada",10.1109/visual.2003.1250400;10.1109/visual.1990.146402;10.1109/tvcg.2006.166;10.1109/visual.1991.175815;10.1109/infvis.2003.1249008;10.1109/infvis.2001.963279;10.1109/tvcg.2006.147;10.1109/visual.2003.1250400,"Graph visualization, node-link diagrams, structural comparison, hierarchies, 3D visualization, edge aggregation",275.0,139.0,22.0,1646.0,,,multiple visualizations empowers;vislink;positioned 3d space;search;including,0.7315;0.3305;0.2779;0.1259;0.0999,"[np.int64(-1), -1, -1, -1, -1]",187;-1;-1;-1;-1,187,187
VAST,2006,Exploring Large-Scale Video News via Interactive Visualization,10.1109/vast.2006.261433,http://dx.doi.org/10.1109/VAST.2006.261433,75.0,82.0,C,"In this paper, we have developed a novel visualization framework to enable more effective visual analysis of large-scale news videos, where keyframes and keywords are automatically extracted from news video clips and visually represented according to their interestingness measurement to help audiences rind news stories of interest at first glance. A computational approach is also developed to quantify the interestingness measurement of video clips. Our experimental results have shown that our techniques for intelligent news video analysis have the capacity to enable more effective visualization of large-scale news videos. Our news video visualization system is very useful for security applications and for general audiences to quickly find news topics of interest from among many channels",Hangzai Luo;Jianping Fan 0001;Jing Yang 0001;William Ribarsky;Shin'ichi Satoh 0001,Hangzai Luo;Jianping Fan;Jing Yang;William Ribarsky;Shin'ichi Satoh,"Department of Computer Science, UNC-Charlotte, Charlotte, NC, USA;Department of Computer Science, UNC-Charlotte, Charlotte, NC, USA;Department of Computer Science, UNC-Charlotte, Charlotte, NC, USA;Department of Computer Science, UNC-Charlotte, Charlotte, NC, USA;National Institute of Informatics (NII), Tokyo, Japan",10.1109/infvis.1998.729570;10.1109/infvis.2003.1249019;10.1109/visual.1991.175815;10.1109/infvis.1998.729570,"News Visualization, Semantic Video Classification",36.0,23.0,25.0,390.0,,,news video visualization;according interestingness;keywords automatically extracted;computational approach developed;capacity enable,0.7307;0.3640;0.2743;0.1352;-0.0199,"[np.int64(-1), -1, -1, -1, -1]",258;-1;-1;-1;-1,258,258
VAST,2015,Evolution inspector: Interactive visual analysis for evolutionary molecular design,10.1109/vast.2015.7347687,http://dx.doi.org/10.1109/VAST.2015.7347687,219.0,220.0,M,"De novo design is a computational-chemistry method, where a computer program utilizes an optimization method, in our case an evolutionary algorithm, to design compounds with desired chemical properties. The optimization is performed with respect to a quantity called fitness, defined by the chemists. We present a tool that connects interactive visual analysis and evolutionary algorithm-based molecular design. We employ linked views to communicate different aspects of the data: the statistical distribution of molecule fitness, connections between individual molecules during the evolution and 3D molecular structure. The application is already used by chemists to explore and analyze the results of their evolution experiments and has proved to be highly useful.",Veronika Soltészová;Marco Foscato;Sondre H. Eliasson;Vidar R. Jensen,Veronika Solteszova;Marco Foscato;Sondre H. Eliasson;Vidar R. Jensen,"Christian Michelsen Research, Bergen, Norway;Department of Chemistry, University of Bergen, Norway;Department of Chemistry, University of Bergen, Norway;Department of Chemistry, University of Bergen, Norway",0.1109/tvcg.2007.70535,,0.0,1.0,10.0,137.0,,,molecular design;evolution 3d;interactive visual analysis;called fitness defined;linked,0.6966;0.2911;0.2575;0.1502;0.0422,"[np.int64(-1), -1, np.int64(-1), -1, -1]",119;-1;318;-1;-1,119;318,119
VAST,2014,Vismate: Interactive Visual Analysis of Station-Based Observation Data on Climate Changes,10.1109/vast.2014.7042489,http://dx.doi.org/10.1109/VAST.2014.7042489,133.0,142.0,C,"We present a new approach to visualizing the climate data of multi-dimensional, time-series, and geo-related characteristics. Our approach integrates three new highly interrelated visualization techniques, and uses the same input data types as in the traditional model-based analysis methods. As the main visualization view, Global Radial Map is used to identify the overall state of climate changes and provide users with a compact and intuitive view for analyzing spatial and temporal patterns at the same time. Other two visualization techniques, providing complementary views, are specialized in analysing time trend and detecting abnormal cases, which are two important analysis tasks in any climate change study. Case studies and expert reviews have been conducted, through which the effectiveness and scalability of the proposed approach has been confirmed.",Jie Li 0006;Kang Zhang 0001;Zhao-Peng Meng,Jie Li;Kang Zhang;Zhao-Peng Meng,"School of Computer Science and Technology, National Ocean Technology Center, Tianjin, China;Department of Computer Science, The University of Texas, Dallas, USA;School of Computer Software, Tianjin University, China",10.1109/vast.2012.6400491;10.1109/tvcg.2010.194;10.1109/infvis.2000.885098;10.1109/tvcg.2007.70523;10.1109/tvcg.2009.199;10.1109/tvcg.2010.183;10.1109/vast.2012.6400553;10.1109/tvcg.2010.180;10.1109/tvcg.2009.197;10.1109/tvcg.2008.187;10.1109/tvcg.2012.284;10.1109/vast.2012.6400491,"climate changes, spatiotemporal visualization, station-based observation data, radial layout, visual analytics",44.0,18.0,54.0,760.0,,,visualizing climate data;radial;compact intuitive;abnormal cases important;proposed approach confirmed,0.8036;0.1524;0.0719;0.0440;0.0041,"[np.int64(-1), -1, -1, -1, -1]",77;-1;-1;-1;-1,77,77
Vis,2023,Adaptive Assessment of Visualization Literacy,10.1109/tvcg.2023.3327165,http://dx.doi.org/10.1109/TVCG.2023.3327165,628.0,637.0,J,"Visualization literacy is an essential skill for accurately interpreting data to inform critical decisions. Consequently, it is vital to understand the evolution of this ability and devise targeted interventions to enhance it, requiring concise and repeatable assessments of visualization literacy for individuals. However, current assessments, such as the Visualization Literacy Assessment Test (vlat), are time-consuming due to their fixed, lengthy format. To address this limitation, we develop two streamlined computerized adaptive tests (cats) for visualization literacy, a-vlat and a-calvi, which measure the same set of skills as their original versions in half the number of questions. Specifically, we (1) employ item response theory (IRT) and non-psychometric constraints to construct adaptive versions of the assessments, (2) finalize the configurations of adaptation through simulation, (3) refine the composition of test items of a-calvi via a qualitative study, and (4) demonstrate the test-retest reliability (ICC: 0.98 and 0.98) and convergent validity (correlation: 0.81 and 0.66) of both CATS via four online studies. We discuss practical recommendations for using our CATS and opportunities for further customization to leverage the full potential of adaptive assessments. All supplemental materials are available at https://osf.io/a6258/.",Yuan Cui;Lily W. Ge;Yiren Ding;Fumeng Yang;Lane Harrison;Matthew Kay 0001,Yuan Cui;Lily W. Ge;Yiren Ding;Fumeng Yang;Lane Harrison;Matthew Kay,"Northwestern University, USA;Northwestern University, USA;Worcester Polytechnic Institute, USA;Northwestern University, USA;Worcester Polytechnic Institute, USA;Northwestern University, USA",0.1109/tvcg.2014.2346984;10.1109/tvcg.2016.2598920,"Visualization literacy,computerized adaptive testing,item response theory",,1.0,33.0,521.0,,,assessments visualization literacy;leverage potential adaptive;irt non;convergent validity;lengthy format address,0.7585;0.1419;0.1090;0.0266;-0.0747,"[np.int64(-1), -1, -1, -1, -1]",211;-1;-1;-1;-1,211,211
InfoVis,2020,Implicit Multidimensional Projection of Local Subspaces,10.1109/tvcg.2020.3030368,http://dx.doi.org/10.1109/TVCG.2020.3030368,1558.0,1568.0,J,"We propose a visualization method to understand the effect of multidimensional projection on local subspaces, using implicit function differentiation. Here, we understand the local subspace as the multidimensional local neighborhood of data points. Existing methods focus on the projection of multidimensional data points, and the neighborhood information is ignored. Our method is able to analyze the shape and directional information of the local subspace to gain more insights into the global structure of the data through the perception of local structures. Local subspaces are fitted by multidimensional ellipses that are spanned by basis vectors. An accurate and efficient vector transformation method is proposed based on analytical differentiation of multidimensional projections formulated as implicit functions. The results are visualized as glyphs and analyzed using a full set of specifically-designed interactions supported in our efficient web-based visualization tool. The usefulness of our method is demonstrated using various multi- and high-dimensional benchmark datasets. Our implicit differentiation vector transformation is evaluated through numerical comparisons; the overall method is evaluated through exploration examples and use cases.",Rongzheng Bian;Yumeng Xue;Liang Zhou 0001;Jian Zhang 0070;Baoquan Chen;Daniel Weiskopf;Yunhai Wang,Rongzheng Bian;Yumeng Xue;Liang Zhou;Jian Zhang;Baoquan Chen;Daniel Weiskopf;Yunhai Wang,"Shandong University, Qingdao;Shandong University, Qingdao;University of Utah;CNIC, CAS;Peking University;University of Stuttgart;Shandong University, Qingdao",10.1109/vast.2012.6400488;10.1109/tvcg.2015.2467717;10.1109/tvcg.2013.153;10.1109/tvcg.2016.2598495;10.1109/tvcg.2019.2934811;10.1109/tvcg.2011.220;10.1109/tvcg.2018.2865194;10.1109/tvcg.2007.70535;10.1109/vast.2010.5652460;10.1109/vast.2012.6400488,"High-dimensional data visualization,dimensionality reduction,local linear subspaces,user interaction",7.0,4.0,51.0,830.0,,,differentiation multidimensional projections;visualization tool usefulness;ellipses;understand local;ignored method able,0.6228;0.3539;0.2404;0.2315;-0.0581,"[np.int64(-1), -1, -1, -1, -1]",37;-1;-1;-1;-1,37,37
Vis,1999,DELTA's Virtual Physics Laboratory: a comprehensive learning platform on physics and astronomy,10.1109/visual.1999.809920,http://dx.doi.org/10.1109/VISUAL.1999.809920,421.0,423.0,C,"Perhaps the most effective instrument to simplify and to clarify the comprehension of any complex mathematical or scientific theory is through visualisation. Moreover using interactivity and 3D real time representations, one can easily explore and hence learn quickly in the virtual environments. The concept of virtual and safe laboratories has vast potentials in education. With the aid of computer simulations and 3D visualisations, many dangerous or cumbersome experiments may be implemented in the virtual environments, with rather small effort. Nonetheless visualisation alone is of little use if the respective simulation is not scientifically accurate. Hence a rigorous combination of precise computation as well as sophisticated visualisation, presented through some intuitive user interface is required to realise a virtual laboratory for education. We introduce Delta's Virtual Physics Laboratory, comprising a wide range of applications in the field of physics and astronomy, which can be implemented and used as an interactive learning tool on the World Wide Web.",Sepideh Chakaveh;Udo Zlender;Detlef Skaley;Konstantinos Fostiropoulos;Dieter Breitschwerdt,S. Chakaveh;U. Zlender;D. Skaley;K. Fostiropoulos;D. Breitschwerdt,"GMD Forschungszentrum Informationtechnik GmBH, German National Research Centre for Information Technology, IMK-DELTA, Saint Augustine, USA;GMD Forschungszentrum Informationtechnik GmBH, German National Research Centre for Information Technology, IMK-DELTA, Saint Augustine, USA;GMD Forschungszentrum Informationtechnik GmBH, German National Research Centre for Information Technology, IMK-DELTA, Saint Augustine, USA;;Max Planck Institut für Extraterrestrische Physik, Munich, Germany and Department of Physics & Astronomy, University of Heidelberg, Germany",,,,4.0,6.0,104.0,,,virtual physics laboratory;visualisation presented intuitive;astronomy;combination precise computation;nonetheless,0.7756;0.3729;0.3248;0.0794;0.0102,"[np.int64(-1), -1, -1, -1, -1]",36;-1;-1;-1;-1,36,36
Vis,2024,DiffFit: Visually-Guided Differentiable Fitting of Molecule Structures to a Cryo-EM Map,10.1109/tvcg.2024.3456404,http://dx.doi.org/10.1109/TVCG.2024.3456404,558.0,568.0,J,"We introduce DiffFit, a differentiable algorithm for fitting protein atomistic structures into an experimental reconstructed Cryo-Electron Microscopy (cryo-EM) volume map. In structural biology, this process is necessary to semi-automatically composite large mesoscale models of complex protein assemblies and complete cellular structures that are based on measured cryo-EM data. The current approaches require manual fitting in three dimensions to start, resulting in approximately aligned structures followed by an automated fine-tuning of the alignment. The DiffFit approach enables domain scientists to fit new structures automatically and visualize the results for inspection and interactive revision. The fitting begins with differentiable three-dimensional (3D) rigid transformations of the protein atom coordinates followed by sampling the density values at the atom coordinates from the target cryo-EM volume. To ensure a meaningful correlation between the sampled densities and the protein structure, we proposed a novel loss function based on a multi-resolution volume-array approach and the exploitation of the negative space. This loss function serves as a critical metric for assessing the fitting quality, ensuring the fitting accuracy and an improved visualization of the results. We assessed the placement quality of DiffFit with several large, realistic datasets and found it to be superior to that of previous methods. We further evaluated our method in two use cases: automating the integration of known composite structures into larger protein complexes and facilitating the fitting of predicted protein domains into volume densities to aid researchers in identifying unknown proteins. We implemented our algorithm as an open-source plugin (github.com/nanovis/DiffFit) in ChimeraX, a leading visualization software in the field. All supplemental materials are available at osf. io/5tx4q.",Deng Luo;Zainab Alsuwaykit;Dawar Khan;Ondrej Strnad;Tobias Isenberg 0001;Ivan Viola,Deng Luo;Zainab Alsuwaykit;Dawar Khan;Ondřej Strnad;Tobias Isenberg;Ivan Viola,"Visual Computing Center at King Abdullah University of Science and Technology (KAUST), Saudi Arabia;Visual Computing Center at King Abdullah University of Science and Technology (KAUST), Saudi Arabia;Visual Computing Center at King Abdullah University of Science and Technology (KAUST), Saudi Arabia;Visual Computing Center at King Abdullah University of Science and Technology (KAUST), Saudi Arabia;Université Paris-Saclay, CNRS, Inria, LISN, France;Visual Computing Center at King Abdullah University of Science and Technology (KAUST), Saudi Arabia",10.1109/tvcg.2018.2864851;10.1109/tvcg.2020.3030415;10.1109/vast.2014.7042491;10.1109/tvcg.2015.2467293;10.1109/tvcg.2022.3209411,"Scalar field data,algorithms,genomics,cryo-EM,application-motivated visualization,process/workflow design,life sciences,health,medicine,biology,structural biology,bioinformatics",,0.0,52.0,308.0,,X,fitting protein atomistic;reconstructed cryo;leading visualization;necessary;differentiable dimensional,0.6115;0.3870;0.2166;0.0255;0.0219,"[np.int64(-1), -1, -1, -1, -1]",119;-1;-1;-1;-1,119,119
Vis,2002,Efficient simplification of point-sampled surfaces,10.1109/visual.2002.1183771,http://dx.doi.org/10.1109/VISUAL.2002.1183771,163.0,170.0,C,"We introduce, analyze and quantitatively compare a number of surface simplification methods for point-sampled geometry. We have implemented incremental and hierarchical clustering, iterative simplification, and particle simulation algorithms to create approximations of point-based models with lower sampling density. All these methods work directly on the point cloud, requiring no intermediate tesselation. We show how local variation estimation and quadric error metrics can be employed to diminish the approximation error and concentrate more samples in regions of high curvature. To compare the quality of the simplified surfaces, we have designed a new method for computing numerical and visual error estimates for point-sampled surfaces. Our algorithms are fast, easy to implement, and create high-quality surface approximations, clearly demonstrating the effectiveness of point-based surface simplification.",Mark Pauly;Markus H. Gross;Leif Kobbelt,M. Pauly;M. Gross;L.P. Kobbelt,"ETH Zurich, Switzerland;ETH Zurich, Switzerland;RWTH Aachen, Germany",10.1109/visual.2001.964503;10.1109/visual.1999.809896;10.1109/visual.2001.964502;10.1109/visual.2001.964489;10.1109/visual.2000.885722;10.1109/visual.2001.964503,,1370.0,340.0,32.0,4117.0,,,based surface simplification;particle simulation;error concentrate samples;point;local,0.6769;0.3500;0.1362;0.1139;0.0937,"[np.int64(-1), -1, -1, -1, -1]",105;-1;-1;-1;-1,105,105
Vis,1990,Applying space subdivision techniques to volume rendering,10.1109/visual.1990.146377,http://dx.doi.org/10.1109/VISUAL.1990.146377,150.0,,C,"The authors present a ray-tracing algorithm for volume rendering designed to work efficiently when the data of interest is distributed sparsely through the volume. A simple preprocessing step identifies the voxels representing features of interest. Frequently this set of voxels, arbitrarily distributed in three-dimensional space, is a small fraction of the original voxel grid. A median-cut space partitioning scheme, combined with bounding volumes to prune void spaces in the resulting search structure, is used to store the voxels of interest in a k-d tree. The k-d tree is used as a data structure. The tree is then efficiently ray-traced to render the voxel data. The k-d tree is view independent, and can be used for animation sequences involving changes in positions of the viewer or positions of lights. This search structure has been applied to render voxel data from MRI, CAT scan, and electron density distributions.&lt;&lt;ETX&gt;&gt;",Kalpathi R. Subramanian;Donald S. Fussell,K.R. Subramanian;D.S. Fussell,"Department of Computer Sciences, University of Texas, Austin, Austin, TX, USA;Department of Computer Sciences, University of Texas, Austin, Austin, TX, USA",,,139.0,20.0,21.0,163.0,,,volume rendering designed;tree used data;scan electron;independent used animation;authors,0.6821;0.2581;0.1895;0.1199;0.0323,"[np.int64(-1), -1, -1, -1, -1]",97;-1;-1;-1;-1,97,97
SciVis,2017,Instant Construction and Visualization of Crowded Biological Environments,10.1109/tvcg.2017.2744258,http://dx.doi.org/10.1109/TVCG.2017.2744258,862.0,872.0,J,"We present the first approach to integrative structural modeling of the biological mesoscale within an interactive visual environment. These complex models can comprise up to millions of molecules with defined atomic structures, locations, and interactions. Their construction has previously been attempted only within a non-visual and non-interactive environment. Our solution unites the modeling and visualization aspect, enabling interactive construction of atomic resolution mesoscale models of large portions of a cell. We present a novel set of GPU algorithms that build the basis for the rapid construction of complex biological structures. These structures consist of multiple membrane-enclosed compartments including both soluble molecules and fibrous structures. The compartments are defined using volume voxelization of triangulated meshes. For membranes, we present an extension of the Wang Tile concept that populates the bilayer with individual lipids. Soluble molecules are populated within compartments distributed according to a Halton sequence. Fibrous structures, such as RNA or actin filaments, are created by self-avoiding random walks. Resulting overlaps of molecules are resolved by a forced-based system. Our approach opens new possibilities to the world of interactive construction of cellular compartments. We demonstrate its effectiveness by showcasing scenes of different scale and complexity that comprise blood plasma, mycoplasma, and HIV.",Tobias Klein;Ludovic Autin;Barbora Kozlíková;David S. Goodsell;Arthur J. Olson;M. Eduard Gröller;Ivan Viola,Tobias Klein;Ludovic Autin;Barbora Kozlíková;David S. Goodsell;Arthur Olson;M. Eduard Gröller;Ivan Viola,"TU Wien, Austria;The Scripps Research Institute, California, USA;Masaryk University, Brno, Czech Republic;The Scripps Research Institute, California, USA;The Scripps Research Institute, California, USA;TU Wien, VRVis Research Center, Austria;TU Wien, Austria",,"Interactive modeling,population,biological data,interactive visualization",37.0,35.0,49.0,1043.0,HM,,biological mesoscale interactive;gpu algorithms;plasma mycoplasma hiv;effectiveness showcasing scenes;build,0.6177;0.4216;0.1083;0.1040;0.0590,"[np.int64(-1), -1, -1, -1, -1]",214;-1;-1;-1;-1,214,214
InfoVis,2020,Modeling the Influence of Visual Density on Cluster Perception in Scatterplots Using Topology,10.1109/tvcg.2020.3030365,http://dx.doi.org/10.1109/TVCG.2020.3030365,1829.0,1839.0,J,"Scatterplots are used for a variety of visual analytics tasks, including cluster identification, and the visual encodings used on a scatterplot play a deciding role on the level of visual separation of clusters. For visualization designers, optimizing the visual encodings is crucial to maximizing the clarity of data. This requires accurately modeling human perception of cluster separation, which remains challenging. We present a multi-stage user study focusing on four factors-distribution size of clusters, number of points, size of points, and opacity of points-that influence cluster identification in scatterplots. From these parameters, we have constructed two models, a distance-based model, and a density-based model, using the merge tree data structure from Topological Data Analysis. Our analysis demonstrates that these factors play an important role in the number of clusters perceived, and it verifies that the distance-based and density-based models can reasonably estimate the number of clusters a user observes. Finally, we demonstrate how these models can be used to optimize visual encodings on real-world data.",Ghulam Jilani Quadri;Paul Rosen 0001,Ghulam Jilani Quadri;Paul Rosen,University of South Florida;University of South Florida,10.1109/vast.2014.7042493;10.1109/infvis.2005.1532136;10.1109/tvcg.2014.2346594;10.1109/tvcg.2019.2934541;10.1109/tvcg.2018.2864907;10.1109/tvcg.2014.2346572;10.1109/tvcg.2007.70535;10.1109/tvcg.2013.183;10.1109/tvcg.2014.2346983;10.1109/tvcg.2014.2346979;10.1109/tvcg.2019.2934799;10.1109/tvcg.2017.2744339;10.1109/tvcg.2017.2744184;10.1109/tvcg.2017.2744359;10.1109/infvis.2005.1532142;10.1109/vast.2014.7042493,"Scatterplot,clustering,perception,empirical evaluation,visual encoding,crowdsourcing,topological data analysis",5.0,16.0,88.0,737.0,,,clusters visualization;opacity points influence;encodings;models reasonably estimate;play important,0.7490;0.1676;0.1076;0.0878;0.0398,"[np.int64(-1), -1, -1, -1, -1]",167;-1;-1;-1;-1,167,167
Vis,1990,A procedural interface for volume rendering,10.1109/visual.1990.146362,http://dx.doi.org/10.1109/VISUAL.1990.146362,36.0,,C,"The author presents a simple, procedural interface for volume rendering. The interface is built on three types of objects: volumes, which contain the data to be visualized, environments, which set up viewing and lighting, and image objects, which convert results to a user-definable format. A volume is rendered against a particular environment with the results sent to an image object for conversion. By defining volume qualities such as color, opacity, and gradient in terms of user-definable transfer functions, the rendering process is made independent of the data set's underlying representation.&lt;&lt;ETX&gt;&gt;",James L. Montine,J.L. Montine,"Alliant Computer Systems Corporation, Littleton, MA, USA",,,18.0,3.0,9.0,71.0,,,volume rendering interface;lighting image objects;procedural;defining;convert results user,0.8052;0.3039;0.2655;0.0681;0.0542,"[np.int64(-1), -1, -1, -1, -1]",256;-1;-1;-1;-1,256,256
Vis,2022,FlowNL: Asking the Flow Data in Natural Languages,10.1109/tvcg.2022.3209453,http://dx.doi.org/10.1109/TVCG.2022.3209453,1200.0,1210.0,J,"Flow visualization is essentially a tool to answer domain experts' questions about flow fields using rendered images. Static flow visualization approaches require domain experts to raise their questions to visualization experts, who develop specific techniques to extract and visualize the flow structures of interest. Interactive visualization approaches allow domain experts to ask the system directly through the visual analytic interface, which provides flexibility to support various tasks. However, in practice, the visual analytic interface may require extra learning effort, which often discourages domain experts and limits its usage in real-world scenarios. In this paper, we propose FlowNL, a novel interactive system with a natural language interface. FlowNL allows users to manipulate the flow visualization system using plain English, which greatly reduces the learning effort. We develop a natural language parser to interpret user intention and translate textual input into a declarative language. We design the declarative language as an intermediate layer between the natural language and the programming language specifically for flow visualization. The declarative language provides selection and composition rules to derive relatively complicated flow structures from primitive objects that encode various kinds of information about scalar fields, flow patterns, regions of interest, connectivities, etc. We demonstrate the effectiveness of FlowNL using multiple usage scenarios and an empirical evaluation.",Jieying Huang;Yang Xi;Junnan Hu;Jun Tao 0002,Jieying Huang;Yang Xi;Junnan Hu;Jun Tao,"School of Computer Science and Engineering, Sun Yat-sen University, China;School of Computer Science and Engineering, Sun Yat-sen University, China;School of Computer Science and Engineering, Sun Yat-sen University, China;Southern Marine Science and Engineering Guangdong Laboratory (Zhuhai), School of Computer Science and Engineering, Sun Yat-sen University, National Supercomputer Center in Guangzhou, China",10.1109/tvcg.2019.2934310;10.1109/tvcg.2011.185;10.1109/visual.2005.1532856;10.1109/tvcg.2014.2346322;10.1109/tvcg.2019.2934785;10.1109/tvcg.2017.2744684;10.1109/tvcg.2013.121;10.1109/tvcg.2018.2864806;10.1109/tvcg.2013.189;10.1109/tvcg.2019.2934537;10.1109/tvcg.2020.3030453;10.1109/tvcg.2021.3114848;10.1109/tvcg.2020.3030378;10.1109/tvcg.2020.3030378;10.1109/tvcg.2019.2934367;10.1109/tvcg.2014.2346318;10.1109/visual.2004.128;10.1109/tvcg.2016.2599030;10.1109/tvcg.2015.2467091;10.1109/tvcg.2017.2745219;10.1109/visual.2003.1250376;10.1109/vast47406.2019.8986918;10.1109/tvcg.2018.2864841;10.1109/tvcg.2010.131;10.1109/visual.2005.1532831;10.1109/tvcg.2019.2934668;10.1109/tvcg.2019.2934310,"Flow visualization,natural language interface,interactive exploration,declarative grammar",,7.0,59.0,956.0,,,flow visualization declarative;translate textual input;using rendered images;experts raise;require domain,0.7705;0.2371;0.1520;0.1073;0.0361,"[np.int64(-1), -1, -1, -1, -1]",138;-1;-1;-1;-1,138,138
Vis,2008,AD-Frustum: Adaptive Frustum Tracing for Interactive Sound Propagation,10.1109/tvcg.2008.111,http://dx.doi.org/10.1109/TVCG.2008.111,1707.0,1722.0,J,"We present an interactive algorithm to compute sound propagation paths for transmission, specular reflection and edge diffraction in complex scenes. Our formulation uses an adaptive frustum representation that is automatically sub-divided to accurately compute intersections with the scene primitives. We describe a simple and fast algorithm to approximate the visible surface for each frustum and generate new frusta based on specular reflection and edge diffraction. Our approach is applicable to all triangulated models and we demonstrate its performance on architectural and outdoor models with tens or hundreds of thousands of triangles and moving objects. In practice, our algorithm can perform geometric sound propagation in complex scenes at 4-20 frames per second on a multi-core PC.",Anish Chandak;Christian Lauterbach;Micah T. Taylor;Zhimin Ren;Dinesh Manocha,Anish Chandak;Christian Lauterbach;Micah Taylor;Zhimin Ren;Dinesh Manocha,"University of North Carolina at Chapel Hill, Chapel Hill, NC, US;University of North Carolina at Chapel Hill, Chapel Hill, NC, US;University of North Carolina at Chapel Hill, Chapel Hill, NC, US;University of North Carolina at Chapel Hill, Chapel Hill, NC, US;University of North Carolina at Chapel Hill, Chapel Hill, NC, US",10.1109/tvcg.2007.70575;10.1109/tvcg.2006.125;10.1109/visual.2005.1532790;10.1109/tvcg.2008.111;10.1109/tvcg.2007.70567;10.1109/tvcg.2007.70575,"Sound propagation, interactive system, auralization",122.0,58.0,43.0,465.0,,,geometric sound propagation;intersections scene primitives;demonstrate performance architectural;frusta;tens hundreds thousands,0.6170;0.3631;0.2319;0.2022;0.0274,"[np.int64(-1), -1, -1, -1, -1]",26;-1;-1;-1;-1,26,26
Vis,2023,Perception of Line Attributes for Visualization,10.1109/tvcg.2023.3326523,http://dx.doi.org/10.1109/TVCG.2023.3326523,1041.0,1051.0,J,"Line attributes such as width and dashing are commonly used to encode information. However, many questions on the perception of line attributes remain, such as how many levels of attribute variation can be distinguished or which line attributes are the preferred choices for which tasks. We conducted three studies to develop guidelines for using stylized lines to encode scalar data. In our first study, participants drew stylized lines to encode uncertainty information. Uncertainty is usually visualized alongside other data. Therefore, alternative visual channels are important for the visualization of uncertainty. Additionally, uncertainty—e.g., in weather forecasts—is a familiar topic to most people. Thus, we picked it for our visualization scenarios in study 1. We used the results of our study to determine the most common line attributes for drawing uncertainty: Dashing, luminance, wave amplitude, and width. While those line attributes were especially common for drawing uncertainty, they are also commonly used in other areas. In studies 2 and 3, we investigated the discriminability of the line attributes determined in study 1. Studies 2 and 3 did not require specific application areas; thus, their results apply to visualizing any scalar data in line attributes. We evaluated the just-noticeable differences (JND) and derived recommendations for perceptually distinct line levels. We found that participants could discriminate considerably more levels for the line attribute width than for wave amplitude, dashing, or luminance.",Anna Sterzik;Nils Lichtenberg;Jana Wilms;Michael Krone;Douglas W. Cunningham;Kai Lawonn,Anna Sterzik;Nils Lichtenberg;Jana Wilms;Michael Krone;Douglas W. Cunningham;Kai Lawonn,"University of Jena, Germany;University of Tübingen, Germany;University of Jena, Germany;University of Tübingen, Germany;Brandenburg University of Technology, Germany;University of Jena, Germany",0.1109/tvcg.2012.220;10.1109/tvcg.2017.2743959;10.1109/tvcg.2015.2467671;10.1109/tvcg.2012.279;10.1109/tvcg.2015.2467591;10.1109/tvcg.2016.2598826;10.1109/tvcg.2023.3326574,"Line Drawings,Line Stylization,Perceptual Evaluation,Uncertainty Visualization",,1.0,48.0,326.0,,,lines encode uncertainty;visualization scenarios study;drew stylized;attributes preferred choices;require specific application,0.6815;0.4231;0.3610;0.2596;-0.0785,"[np.int64(-1), -1, -1, -1, -1]",14;-1;-1;-1;-1,14,14
InfoVis,2000,A scalable framework for information visualization,10.1109/infvis.2000.885088,http://dx.doi.org/10.1109/INFVIS.2000.885088,27.0,36.0,C,"The paper describes major concepts of a scalable information visualization framework. We assume that the exploration of heterogeneous information spaces at arbitrary levels of detail requires a suitable preprocessing of information quantities, the combination of different graphical interfaces and the illustration of the frame of reference of given information sets. The innovative features of our system include: dynamic hierarchy computation and user controlled refinement of those hierarchies for preprocessing unstructured information spaces; a new Focus+Context technique for visualizing complex hierarchy graphs; a new paradigm for visualizing information structures within their frame of reference; and a new graphical interface that utilizes textual similarities to arrange objects of high dimensional information space in 3-dimensional visualization space.",Matthias Kreuseler;Norma López;Heidrun Schumann,M. Kreuseler;N. Lopez;H. Schumann,"Department of Computer Science, University of Rostock, Rostock, Germany;Department of Computer Science, University of Rostock, Rostock, Germany;Department of Computer Science, University of Rostock, Rostock, Germany",10.1109/visual.1990.146402;10.1109/infvis.1997.636759;10.1109/visual.1996.567745;10.1109/visual.1997.663916;10.1109/infvis.1995.528686;10.1109/infvis.1995.528691;10.1109/infvis.1998.729555;10.1109/visual.1991.175815;10.1109/infvis.1998.729559,,114.0,23.0,25.0,534.0,,,visualizing information structures;new focus context;user controlled;suitable preprocessing information;assume,0.7851;0.2440;0.1524;0.1400;-0.0171,"[np.int64(-1), -1, -1, -1, -1]",316;-1;-1;-1;-1,316,316
Vis,2001,User-centric viewpoint computation for haptic exploration and manipulation,10.1109/visual.2001.964526,http://dx.doi.org/10.1109/VISUAL.2001.964526,311.0,318.0,C,"We present several techniques for user-centric viewing of the virtual objects or datasets under haptic exploration and manipulation. Depending on the type of tasks performed by the user, our algorithms compute automatic placement of the user viewpoint to navigate through the scene, to display the near-optimal views, and to reposition the viewpoint for haptic visualization. This is accomplished by conjecturing the user's intent based on the user's actions, the object geometry, and intra- and inter-object occlusion relationships. These algorithms have been implemented and interfaced with both a 3-DOF and a 6-DOF PHANToM arms. We demonstrate their application on haptic exploration and visualization of a complex structure, as well as multiresolution modeling and 3D painting with a haptic interface.",Miguel A. Otaduy;Ming C. Lin,M.A. Otaduy;M.C. Lin,"Department of Computer Science, University of North Carolina, Chapel Hill, USA;Department of Computer Science, University of North Carolina, Chapel Hill, USA",10.1109/visual.2000.885686;10.1109/visual.1996.568108;10.1109/visual.2000.885686,,22.0,10.0,33.0,102.0,,,viewpoint haptic visualization;user actions object;dof dof phantom;multiresolution;algorithms compute automatic,0.7477;0.2361;0.1876;0.1765;0.1116,"[np.int64(-1), -1, -1, -1, -1]",239;-1;-1;-1;-1,239,239
Vis,2021,STNet: An End-to-End Generative Framework for Synthesizing Spatiotemporal Super-Resolution Volumes,10.1109/tvcg.2021.3114815,http://dx.doi.org/10.1109/TVCG.2021.3114815,270.0,280.0,J,"We present STNet, an end-to-end generative framework that synthesizes spatiotemporal super-resolution volumes with high fidelity for time-varying data. STNet includes two modules: a generator and a spatiotemporal discriminator. The input to the generator is two low-resolution volumes at both ends, and the output is the intermediate and the two-ending spatiotemporal super-resolution volumes. The spatiotemporal discriminator, leveraging convolutional long short-term memory, accepts a spatiotemporal super-resolution sequence as input and predicts a conditional score for each volume based on its spatial (the volume itself) and temporal (the previous volumes) information. We propose an unsupervised pre-training stage using cycle loss to improve the generalization of STNet. Once trained, STNet can generate spatiotemporal super-resolution volumes from low-resolution ones, offering scientists an option to save data storage (i.e., sparsely sampling the simulation output in both spatial and temporal dimensions). We compare STNet with the baseline bicubic+linear interpolation, two deep learning solutions (<inline-formula><tex-math notation=""LaTeX"">$\mathsf{SSR}+\mathsf{TSF}$</tex-math><alternatives><graphic orientation=""portrait"" position=""float"" xlink:href=""28tvcg01-han-3114815-eqinline-1-small.tif"" xmlns:xlink=""http://www.w3.org/1999/xlink""/></alternatives></inline-formula>, STD), and a state-of-the-art tensor compression solution (TTHRESH) to show the effectiveness of STNet.",Jun Han 0010;Hao Zheng 0006;Danny Z. Chen;Chaoli Wang 0001,Jun Han;Hao Zheng;Danny Z. Chen;Chaoli Wang,"Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, USA;Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, USA;Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, USA;Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, USA",10.1109/tvcg.2019.2934332;10.1109/tvcg.2020.3030344;10.1109/tvcg.2019.2934255;10.1109/tvcg.2020.3030346;10.1109/tvcg.2019.2934312;10.1109/tvcg.2006.143;10.1109/tvcg.2019.2934375;10.1109/tvcg.2019.2934332,"Time-varying data,generative adversarial network,spatiotemporal super-resolution",15.0,30.0,65.0,1183.0,,,spatiotemporal super resolution;stnet generate;volumes information;cycle loss;input predicts conditional,0.5764;0.2813;0.2548;0.2193;0.1659,"[np.int64(-1), -1, -1, -1, -1]",309;-1;-1;-1;-1,309,309
VAST,2013,Interactive Exploration of Implicit and Explicit Relations in Faceted Datasets,10.1109/tvcg.2013.167,http://dx.doi.org/10.1109/TVCG.2013.167,2080.0,2089.0,J,"Many datasets, such as scientific literature collections, contain multiple heterogeneous facets which derive implicit relations, as well as explicit relational references between data items. The exploration of this data is challenging not only because of large data scales but also the complexity of resource structures and semantics. In this paper, we present PivotSlice, an interactive visualization technique which provides efficient faceted browsing as well as flexible capabilities to discover data relationships. With the metaphor of direct manipulation, PivotSlice allows the user to visually and logically construct a series of dynamic queries over the data, based on a multi-focus and multi-scale tabular view that subdivides the entire dataset into several meaningful parts with customized semantics. PivotSlice further facilitates the visual exploration and sensemaking process through features including live search and integration of online data, graphical interaction histories and smoothly animated visual state transitions. We evaluated PivotSlice through a qualitative lab study with university researchers and report the findings from our observations and interviews. We also demonstrate the effectiveness of PivotSlice using a scenario of exploring a repository of information visualization literature.",Jian Zhao 0010;Christopher Collins 0001;Fanny Chevalier;Ravin Balakrishnan,Jian Zhao;Christopher Collins;Fanny Chevalier;Ravin Balakrishnan,"University of Toronto, Canada;Institute of Technology, University of Ontario, Canada;University of Toronto, Toronto, ON, CA;University of Toronto, Canada",10.1109/tvcg.2008.137;10.1109/vast.2011.6102440;10.1109/tvcg.2011.213;10.1109/tvcg.2010.154;10.1109/vast.2006.261426;10.1109/infvis.2005.1532136;10.1109/tvcg.2010.205;10.1109/tvcg.2012.252;10.1109/tvcg.2006.166;10.1109/infvis.2000.885086;10.1109/tvcg.2009.108;10.1109/infvis.2004.64;10.1109/tvcg.2008.137,"Faceted browsing, network exploration, dynamic query, interaction, information visualization, visual analytics",120.0,76.0,39.0,1487.0,,,information visualization literature;evaluated pivotslice;implicit relations;study university;allows,0.6158;0.2549;0.2241;0.1012;0.0227,"[np.int64(-1), -1, -1, -1, -1]",207;-1;-1;-1;-1,207,207
InfoVis,2004,Information Visualization Research: Citation and Co-Citation Highlights,10.1109/infvis.2004.38,http://dx.doi.org/10.1109/INFVIS.2004.38,,,M,An overview of the entry is given. The techniques used to prepare the InfoVis contest entry are outlined. The strengths and weaknesses are briefly discussed.,Chaomei Chen,Chaomei Chen,"Drexel University, USA",,,5.0,0.0,4.0,146.0,,,prepare infovis contest;entry outlined;overview;weaknesses briefly discussed;used,0.8292;0.3665;0.2941;0.2512;0.1218,"[np.int64(-1), -1, -1, -1, -1]",88;-1;-1;-1;-1,88,88
Vis,2002,Geometric verification of swirling features in flow fields,10.1109/visual.2002.1183789,http://dx.doi.org/10.1109/VISUAL.2002.1183789,307.0,314.0,C,"In this paper, we present a verification algorithm for swirling features in flow fields, based on the geometry of streamlines. The features of interest in this case are vortices. Without a formal definition, existing detection algorithms lack the ability to accurately identify these features, and the current method for verifying the accuracy of their results is by human visual inspection. Our verification algorithm addresses this issue by automating the visual inspection process. It is based on identifying the swirling streamlines that surround the candidate vortex cores. We apply our algorithm to both numerically simulated and procedurally generated datasets to illustrate the efficacy of our approach.",Ming Jiang 0005;Raghu Machiraju;David S. Thompson,Ming Jiang;R. Machiraju;D. Thompson,"Ohio State Uinversity, USA;Ohio State Uinversity, USA;Mississippi State University, USA",10.1109/visual.1999.809896;10.1109/visual.1998.745333;10.1109/visual.1998.745296;10.1109/visual.1993.398877;10.1109/visual.1999.809896,"feature verification, vortex detection, flow field visualization",76.0,22.0,19.0,190.0,,,based identifying swirling;inspection verification;features case;definition;addresses issue automating,0.6849;0.3272;0.0763;0.0204;-0.0038,"[np.int64(-1), -1, -1, -1, -1]",224;-1;-1;-1;-1,224,224
VAST,2007,Visual Analysis of Dynamic Networks with Geological Clustering,10.1109/vast.2007.4389027,http://dx.doi.org/10.1109/VAST.2007.4389027,221.0,222.0,M,"Many dynamic networks have associated geological information. Here we present two complementing visual analysis methods for such networks. The first one provides an overview with summerized information while the second one presents a more detailed view. The geological information is encoded in the network layout, which is designed to help maintain user's mental map. We also combined visualization with social network analysis to facilitate knowledge discovery, especially to understand network changes in the context overall evolution. Both methods are applied to the ""History of the FIFA World Cup Competition"" data set.",Adel Ahmed;Xiaoyan Fu;Seok-Hee Hong 0001;Quan Hoang Nguyen 0001;Kai Xu 0003,Adel Ahmed;Xiaoyan Fu;Seok-Hee Hong;Quan Hoang Nguyen;Kai Xu,"School of Information Technologies, University of Sydney, Australia and NICTA, Australia;NICTA, Australia;School of Information Technologies, University of Sydney, Australia;School of Computer Sciences and Engineering, University of New South Wales, Australia;NICTA, Australia",0.1109/tvcg.2006.166;10.1109/tvcg.2006.122,,3.0,1.0,7.0,194.0,,,visualization social network;geological information;fifa;evolution methods applied;changes context overall,0.6821;0.4418;0.1423;0.1017;0.0929,"[np.int64(-1), -1, -1, -1, -1]",169;-1;-1;-1;-1,169,169
InfoVis,2011,DICON: Interactive Visual Analysis of Multidimensional Clusters,10.1109/tvcg.2011.188,http://dx.doi.org/10.1109/TVCG.2011.188,2581.0,2590.0,J,"Clustering as a fundamental data analysis technique has been widely used in many analytic applications. However, it is often difficult for users to understand and evaluate multidimensional clustering results, especially the quality of clusters and their semantics. For large and complex data, high-level statistical information about the clusters is often needed for users to evaluate cluster quality while a detailed display of multidimensional attributes of the data is necessary to understand the meaning of clusters. In this paper, we introduce DICON, an icon-based cluster visualization that embeds statistical information into a multi-attribute display to facilitate cluster interpretation, evaluation, and comparison. We design a treemap-like icon to represent a multidimensional cluster, and the quality of the cluster can be conveniently evaluated with the embedded statistical information. We further develop a novel layout algorithm which can generate similar icons for similar clusters, making comparisons of clusters easier. User interaction and clutter reduction are integrated into the system to help users more effectively analyze and refine clustering results for large datasets. We demonstrate the power of DICON through a user study and a case study in the healthcare domain. Our evaluation shows the benefits of the technique, especially in support of complex multidimensional cluster analysis.",Nan Cao 0001;David Gotz;Jimeng Sun 0001;Huamin Qu,Nan Cao;David Gotz;Jimeng Sun;Huamin Qu,"Department of Computer Science and Engineering, Hong Kong University of Science and Technology, Hong Kong, China;IBM Thomas J. Watson Research Center, USA;IBM Thomas J. Watson Research Center, USA;Department of Computer Science and Engineering, Hong Kong University of Science and Technology, Hong Kong, China",10.1109/infvis.2005.1532128;10.1109/tvcg.2006.147;10.1109/tvcg.2009.179;10.1109/visual.1995.485141;10.1109/tvcg.2007.70582;10.1109/visual.1990.146402;10.1109/vast.2009.5332628;10.1109/infvis.2001.963283;10.1109/infvis.1998.729559;10.1109/tvcg.2010.216;10.1109/visual.1999.809866;10.1109/tvcg.2008.153;10.1109/tvcg.2008.165;10.1109/tvcg.2009.153;10.1109/infvis.2005.1532128,"Visual Analysis, Clustering, Information Visualization",155.0,93.0,40.0,2696.0,,,cluster visualization;introduce dicon icon;applications difficult users;conveniently evaluated embedded;healthcare domain,0.7219;0.2777;0.1504;0.1362;0.1267,"[np.int64(-1), -1, -1, -1, -1]",167;-1;-1;-1;-1,167,167
SciVis,2020,A Fluid Flow Data Set for Machine Learning and its Application to Neural Flow Map Interpolation,10.1109/tvcg.2020.3028947,http://dx.doi.org/10.1109/TVCG.2020.3028947,1279.0,1289.0,J,"In recent years, deep learning has opened countless research opportunities across many different disciplines. At present, visualization is mainly applied to explore and explain neural networks. Its counterpart-the application of deep learning to visualization problems-requires us to share data more openly in order to enable more scientists to engage in data-driven research. In this paper, we construct a large fluid flow data set and apply it to a deep learning problem in scientific visualization. Parameterized by the Reynolds number, the data set contains a wide spectrum of laminar and turbulent fluid flow regimes. The full data set was simulated on a high-performance compute cluster and contains 8000 time-dependent 2D vector fields, accumulating to more than 16 TB in size. Using our public fluid data set, we trained deep convolutional neural networks in order to set a benchmark for an improved post-hoc Lagrangian fluid flow analysis. In in-situ settings, flow maps are exported and interpolated in order to assess the transport characteristics of time-dependent fluids. Using deep learning, we improve the accuracy of flow map interpolations, allowing a more precise flow analysis at a reduced memory IO footprint.",Jakob Jakob;Markus Gross 0001;Tobias Günther,Jakob Jakob;Markus Gross;Tobias Günther,"ETH Zurich, Switzerland;ETH Zurich, Switzerland;ETH Zurich, Switzerland",10.1109/tvcg.2013.128;10.1109/tvcg.2019.2934332;10.1109/tvcg.2007.70551;10.1109/tvcg.2019.2934255;10.1109/tvcg.2019.2934312;10.1109/tvcg.2019.2934335;10.1109/tvcg.2007.70554;10.1109/tvcg.2013.128,"Scientific visualization,deep learning,flow maps",24.0,24.0,73.0,1932.0,,,deep learning visualization;fluid flow regimes;8000 time dependent;public;set contains,0.5911;0.4421;0.1663;0.0506;-0.0378,"[np.int64(-1), -1, -1, -1, -1]",135;-1;-1;-1;-1,135,135
Vis,2002,Probabilistic surfaces: point based primitives to show surface uncertainty,10.1109/visual.2002.1183769,http://dx.doi.org/10.1109/VISUAL.2002.1183769,147.0,153.0,C,"Efficient and informative visualization of surfaces with uncertainties is an important topic with many applications in science and engineering. Examples include environmental pollution borderline identification, identification of the limits of an oil basin, or discrimination between contaminated and healthy tissue in medicine. This paper presents an approach for such visualization using points as display primitives. The approach is to render each polygon as a collection of points and to displace each point from the surface in the direction of the surface normal by an amount proportional to some random number multiplied by the uncertainty level at that point. This approach can be used in combination with other techniques such as pseudo-coloring and shading to give rise to efficient and revealing visualizations. The method is used to visualize real and simulated tumor formations with uncertainty of tumor boundaries.",Gevorg Grigoryan;Penny Rheingans,G. Grigoryan;P. Rheingans,"University of Maryland, Baltimore, USA;University of Maryland, Baltimore, USA",10.1109/visual.1996.568105;10.1109/visual.2000.885679;10.1109/visual.2001.964492;10.1109/visual.1995.480802;10.1109/visual.1995.480798;10.1109/visual.1996.568105,"uncertainty, visualizing surface uncertainty, points as display primitives",65.0,17.0,18.0,197.0,,,visualization surfaces uncertainties;techniques pseudo coloring;polygon collection;tumor;important topic applications,0.6172;0.3416;0.3234;0.2040;0.0817,"[np.int64(-1), -1, -1, -1, -1]",304;-1;-1;-1;-1,304,304
VAST,2016,GazeDx: Interactive Visual Analytics Framework for Comparative Gaze Analysis with Volumetric Medical Images,10.1109/tvcg.2016.2598796,http://dx.doi.org/10.1109/TVCG.2016.2598796,311.0,320.0,J,"We present an interactive visual analytics framework, GazeDx (abbr. of GazeDiagnosis), for the comparative analysis of gaze data from multiple readers examining volumetric images while integrating important contextual information with the gaze data. Gaze pattern comparison is essential to understanding how radiologists examine medical images, and to identifying factors influencing the examination. Most prior work depended upon comparisons with manually juxtaposed static images of gaze tracking results. Comparative gaze analysis with volumetric images is more challenging due to the additional cognitive load on 3D perception. A recent study proposed a visualization design based on direct volume rendering (DVR) for visualizing gaze patterns in volumetric images; however, effective and comprehensive gaze pattern comparison is still challenging due to a lack of interactive visualization tools for comparative gaze analysis. We take the challenge with GazeDx while integrating crucial contextual information such as pupil size and windowing into the analysis process for more in-depth and ecologically valid findings. Among the interactive visualization components in GazeDx, a context-embedded interactive scatterplot is especially designed to help users examine abstract gaze data in diverse contexts by embedding medical imaging representations well known to radiologists in it. We present the results from two case studies with two experienced radiologists, where they compared the gaze patterns of 14 radiologists reading two patients' volumetric CT images.",Hyunjoo Song;Jeongjin Lee;Tae Jung Kim;Kyoung Ho Lee;Bo Hyoung Kim;Jinwook Seo,Hyunjoo Song;Jeongjin Lee;Tae Jung Kim;Kyoung Ho Lee;Bohyoung Kim;Jinwook Seo,"Seoul National University;Soongsil University;Samsung Medical Center;Bundang Hospital, Seoul National University;Hankuk University of Foreign Studies;Seoul National University",10.1109/vast.2011.6102435;10.1109/tvcg.2010.149;10.1109/vast.2011.6102435,Eye tracking;gaze visualization;gaze pattern comparison;volumetric medical images;context-embedded interactive scatterplot;interactive temporal chart,17.0,21.0,32.0,1122.0,,,visualizing gaze patterns;patients volumetric ct;context embedded interactive;compared;ecologically valid,0.7186;0.4710;0.2223;0.1715;0.0198,"[np.int64(-1), -1, -1, -1, -1]",-1;-1;-1;-1;-1,,-1
InfoVis,2016,Iterating between Tools to Create and Edit Visualizations,10.1109/tvcg.2016.2598609,http://dx.doi.org/10.1109/TVCG.2016.2598609,481.0,490.0,J,"A common workflow for visualization designers begins with a generative tool, like D3 or Processing, to create the initial visualization; and proceeds to a drawing tool, like Adobe Illustrator or Inkscape, for editing and cleaning. Unfortunately, this is typically a one-way process: once a visualization is exported from the generative tool into a drawing tool, it is difficult to make further, data-driven changes. In this paper, we propose a bridge model to allow designers to bring their work back from the drawing tool to re-edit in the generative tool. Our key insight is to recast this iteration challenge as a merge problem - similar to when two people are editing a document and changes between them need to reconciled. We also present a specific instantiation of this model, a tool called Hanpuku, which bridges between D3 scripts and Illustrator. We show several examples of visualizations that are iteratively created using Hanpuku in order to illustrate the flexibility of the approach. We further describe several hypothetical tools that bridge between other visualization tools to emphasize the generality of the model.",Alex Bigelow;Steven Mark Drucker;Danyel Fisher;Miriah D. Meyer,Alex Bigelow;Steven Drucker;Danyel Fisher;Miriah Meyer,University of Utah;Microsoft Research;Microsoft Research;University of Utah,10.1109/tvcg.2014.2346292;10.1109/tvcg.2015.2467191;10.1109/tvcg.2014.2346291;10.1109/tvcg.2015.2467091;10.1109/infvis.2004.12;10.1109/tvcg.2011.209;10.1109/tvcg.2007.70584;10.1109/tvcg.2011.185;10.1109/tvcg.2014.2346292,illustration;Visualization;iteration,49.0,39.0,32.0,1225.0,,,visualization designers;bridges d3 scripts;merge;editing document changes;using hanpuku order,0.6331;0.2923;0.2921;0.2049;0.1487,"[np.int64(-1), -1, -1, -1, -1]",204;-1;-1;-1;-1,204,204
VAST,2009,Interactive visual clustering of large collections of trajectories,10.1109/vast.2009.5332584,http://dx.doi.org/10.1109/VAST.2009.5332584,3.0,10.0,C,"One of the most common operations in exploration and analysis of various kinds of data is clustering, i.e. discovery and interpretation of groups of objects having similar properties and/or behaviors. In clustering, objects are often treated as points in multi-dimensional space of properties. However, structurally complex objects, such as trajectories of moving entities and other kinds of spatio-temporal data, cannot be adequately represented in this manner. Such data require sophisticated and computationally intensive clustering algorithms, which are very hard to scale effectively to large datasets not fitting in the computer main memory. We propose an approach to extracting meaningful clusters from large databases by combining clustering and classification, which are driven by a human analyst through an interactive visual interface.",Gennady L. Andrienko;Natalia V. Andrienko;Salvatore Rinzivillo;Mirco Nanni;Dino Pedreschi;Fosca Giannotti,Gennady Andrienko;Natalia Andrienko;Salvatore Rinzivillo;Mirco Nanni;Dino Pedreschi;Fosca Giannotti,"Fraunhofer Institute of Intelligent Analysis and Information Systems (IAIS), Sankt Augustin, Germany;Fraunhofer Institute of Intelligent Analysis and Information Systems (IAIS), Sankt Augustin, Germany;KDD Lab-ISTI-CNR, Pisa, Italy;KDD Lab-ISTI-CNR, Pisa, Italy;University of Pisa, Pisa, Italy;KDD Lab-ISTI-CNR, Pisa, Italy",10.1109/vast.2008.4677356;10.1109/vast.2007.4388999;10.1109/vast.2008.4677356,"Spatio-temporal data, movement data, trajectories, clustering, classification, scalable visualization, geovisualization",291.0,144.0,26.0,1630.0,,,extracting meaningful clusters;objects trajectories moving;analyst interactive visual;memory propose approach;human,0.6338;0.3544;0.3121;0.1695;0.1557,"[np.int64(-1), -1, -1, -1, -1]",137;-1;-1;-1;-1,137,137
SciVis,2013,MObjects--A Novel Method for the Visualization and Interactive Exploration of Defects in Industrial XCT Data,10.1109/tvcg.2013.177,http://dx.doi.org/10.1109/TVCG.2013.177,2906.0,2915.0,J,"This paper describes an advanced visualization method for the analysis of defects in industrial 3D X-Ray Computed Tomography (XCT) data. We present a novel way to explore a high number of individual objects in a dataset, e.g., pores, inclusions, particles, fibers, and cracks demonstrated on the special application area of pore extraction in carbon fiber reinforced polymers (CFRP). After calculating the individual object properties volume, dimensions and shape factors, all objects are clustered into a mean object (MObject). The resulting MObject parameter space can be explored interactively. To do so, we introduce the visualization of mean object sets (MObject Sets) in a radial and a parallel arrangement. Each MObject may be split up into sub-classes by selecting a specific property, e.g., volume or shape factor, and the desired number of classes. Applying this interactive selection iteratively leads to the intended classifications and visualizations of MObjects along the selected analysis path. Hereby the given different scaling factors of the MObjects down the analysis path are visualized through a visual linking approach. Furthermore the representative MObjects are exported as volumetric datasets to serve as input for successive calculations and simulations. In the field of porosity determination in CFRP non-destructive testing practitioners use representative MObjects to improve ultrasonic calibration curves. Representative pores also serve as input for heat conduction simulations in active thermography. For a fast overview of the pore properties in a dataset we propose a local MObjects visualization in combination with a color-coded homogeneity visualization of cells. The advantages of our novel approach are demonstrated using real world CFRP specimens. The results were evaluated through a questionnaire in order to determine the practicality of the MObjects visualization as a supportive tool for domain specialists.",Andreas Reh;Christian Gusenbauer;Johann Kastner;M. Eduard Gröller;Christoph Heinzl,Andreas Reh;Christian Gusenbauer;Johann Kastner;M. Eduard Gröller;Christoph Heinzl,"University of Applied Sciences Upper Austria, Austria;University of Applied Sciences Upper Austria, Austria;University of Applied Sciences Upper Austria, Austria;Institute of Computer Graphics and Algorithms, Vienna University of Technology, Austria;University of Applied Sciences Upper Austria, Austria",10.1109/tvcg.2012.231;10.1109/visual.1999.809871;10.1109/tvcg.2009.121;10.1109/tvcg.2012.227;10.1109/tvcg.2011.248;10.1109/visual.2005.1532807;10.1109/tvcg.2010.190;10.1109/tvcg.2010.214;10.1109/visual.1993.398859;10.1109/visual.1997.663875,"3D X-ray computed tomography, carbon fiber reinforced polymers, porosity, parameter space analysis, MObjects",37.0,21.0,29.0,834.0,,,advanced visualization;computed tomography xct;pores inclusions;reinforced polymers cfrp;representative mobjects exported,0.5185;0.4427;0.3050;0.2771;0.1662,"[np.int64(-1), -1, -1, -1, -1]",274;-1;-1;-1;-1,274,274
Vis,1998,Efficient warping for architectural walkthroughs using layered depth images,10.1109/visual.1998.745305,http://dx.doi.org/10.1109/VISUAL.1998.745305,211.0,215.0,C,"This paper presents efficient image-based rendering techniques used in the context of an architectural walkthrough system. Portals (doors and windows) are rendered by warping layered depth images (LDIs). In a preprocessing phase, for every portal, a number of pre-rendered images are combined into an LDI. The resulting LDI stores, exactly once, all surfaces visible in at least one of the images used in the construction, so most of the exposure errors are efficiently eliminated. The LDI can be warped in the McMillan occlusion compatible ordering. A substantial increase in performance is obtained by warping in parallel. Our parallelization scheme achieves good load balancing, scales with the number of processors, and preserves the occlusion compatible ordering. A fast, conservative reference-image-space clipping algorithm also reduces the warping effort.",Voicu Popescu;Anselmo Lastra;Daniel G. Aliaga;Manuel Menezes de Oliveira Neto,V. Popescu;A. Lastra;D. Aliaga;M. de Oliveira Neto,"University of North Carolina, Chapel Hill, USA;University of North Carolina, Chapel Hill, USA;University of North Carolina, Chapel Hill, USA;University of North Carolina, Chapel Hill, USA",10.1109/visual.1997.663903,"image-based rendering, parallel warping, occlusion compatible ordering for discrete images, portal, cell, exposure error, layered depth image, clipping, architectural walkthrough",69.0,16.0,8.0,75.0,,,layered depth images;windows rendered warping;context architectural walkthrough;achieves good load;number pre,0.6225;0.2458;0.2125;0.1130;0.0853,"[np.int64(-1), -1, -1, -1, -1]",290;-1;-1;-1;-1,290,290
InfoVis,1995,Case study: 3D displays of Internet traffic,10.1109/infvis.1995.528697,http://dx.doi.org/10.1109/INFVIS.1995.528697,129.0,131.0,C,"The explosive growth in world-wide communications, especially the Internet, has highlighted the need for techniques to visualize network traffic. The traditional node and link network displays work well for small datasets but become visually cluttered and uninterpretable for large datasets. A natural 3D metaphor for displaying world-wide network data is to position the nodes on a globe and draw arcs between them coding the traffic. This technique has several advantages of over the traditional 2D displays, it naturally reduces line crossing clutter, provides an intuitive model for navigation and indication of time, and retains the geographic context. Coupling these strengths with some novel interaction techniques involving the globe surface translucency and arc heights illustrates the usefulness for this class of displays.",Kenneth C. Cox;Stephen G. Eick,K.C. Cox;S.G. Eick,"AT and T Bell Laboratories, USA;AT and T Bell Laboratories, Naperville, IL, USA",10.1109/visual.1993.398870;10.1109/visual.1993.398870,,52.0,14.0,8.0,201.0,,,visualize network traffic;globe draw arcs;advantages traditional 2d;retains geographic context;especially,0.6573;0.5260;0.2500;0.2269;0.1046,"[np.int64(-1), np.int64(-1), -1, -1, -1]",166;285;-1;-1;-1,166;285,166
Vis,2022,Uncertainty-Aware Multidimensional Scaling,10.1109/tvcg.2022.3209420,http://dx.doi.org/10.1109/TVCG.2022.3209420,23.0,32.0,J,"We present an extension of multidimensional scaling (MDS) to uncertain data, facilitating uncertainty visualization of multidimensional data. Our approach uses local projection operators that map high-dimensional random vectors to low-dimensional space to formulate a generalized stress. In this way, our generic model supports arbitrary distributions and various stress types. We use our uncertainty-aware multidimensional scaling (UAMDS) concept to derive a formulation for the case of normally distributed random vectors and a squared stress. The resulting minimization problem is numerically solved via gradient descent. We complement UAMDS by additional visualization techniques that address the sensitivity and trustworthiness of dimensionality reduction under uncertainty. With several examples, we demonstrate the usefulness of our approach and the importance of uncertainty-aware techniques.",David Hägele;Tim Krake;Daniel Weiskopf,David Hägele;Tim Krake;Daniel Weiskopf,"University of Stuttgart, Germany;University of Stuttgart, Germany;University of Stuttgart, Germany",10.1109/infvis.1998.729560;10.1109/vast.2009.5332611;10.1109/tvcg.2019.2934812;10.1109/tvcg.2018.2864889;10.1109/tvcg.2016.2599106;10.1109/tvcg.2015.2467591;10.1109/tvcg.2016.2598919;10.1109/infvis.1998.729560,"Uncertainty visualization,dimensionality reduction,multidimensional scaling,non-linear projection",,2.0,37.0,2801.0,BP,X,uncertainty visualization multidimensional;generalized stress way;scaling uamds;local projection;normally,0.7401;0.4089;0.2399;0.2091;0.0181,"[np.int64(-1), -1, -1, -1, -1]",159;-1;-1;-1;-1,159,159
VAST,2011,Visual sentiment analysis on twitter data streams,10.1109/vast.2011.6102472,http://dx.doi.org/10.1109/VAST.2011.6102472,277.0,278.0,M,"Twitter currently receives about 190 million tweets (small text-based Web posts) a day, in which people share their comments regarding a wide range of topics. A large number of tweets include opinions about products and services. However, with Twitter being a relatively new phenomenon, these tweets are underutilized as a source for evaluating customer sentiment. To explore high-volume twitter data, we introduce three novel time-based visual sentiment analysis techniques: (1) topic-based sentiment analysis that extracts, maps, and measures customer opinions; (2) stream analysis that identifies interesting tweets based on their density, negativity, and influence characteristics; and (3) pixel cell-based sentiment calendars and high density geo maps that visualize large volumes of data in a single view. We applied these techniques to a variety of twitter data, (e.g., movies, amusement parks, and hotels) to show their distribution and patterns, and to identify influential opinions.",Ming C. Hao;Christian Rohrdantz;Halldor Janetzko;Umeshwar Dayal;Daniel A. Keim;Lars-Erik Haug;Meichun Hsu,Ming Hao;Christian Rohrdantz;Halldór Janetzko;Umeshwar Dayal;Daniel A. Keim;Lars-Erik Haug;Mei-Chun Hsu,"Hewlett Packard Laboratory, USA;Hewlett-Packard Laboratories, University of Konstanz, Germany;Hewlett-Packard Laboratories, University of Konstanz, Germany;Hewlett Packard Laboratory, USA;Hewlett-Packard Laboratories, University of Konstanz, Germany;Hewlett Packard Laboratory, USA;Hewlett Packard Laboratory, USA",0.1109/vast.2009.5333919,,94.0,38.0,3.0,3669.0,,,visual sentiment analysis;190 million tweets;hotels distribution patterns;geo;introduce novel time,0.6370;0.4394;0.1451;0.1425;0.1135,"[np.int64(-1), -1, -1, -1, -1]",148;-1;-1;-1;-1,148,148
InfoVis,2008,"The Word Tree, an Interactive Visual Concordance",10.1109/tvcg.2008.172,http://dx.doi.org/10.1109/TVCG.2008.172,1221.0,1228.0,J,"We introduce the Word Tree, a new visualization and information-retrieval technique aimed at text documents. A Word Tree is a graphical version of the traditional ""keyword-in-context"" method, and enables rapid querying and exploration of bodies of text. In this paper we describe the design of the technique, along with some of the technical issues that arise in its implementation. In addition, we discuss the results of several months of public deployment of word trees on Many Eyes, which provides a window onto the ways in which users obtain value from the visualization.",Martin Wattenberg;Fernanda B. Viégas,Martin Wattenberg;Fernanda B. Viégas,IBM Research;IBM Research,10.1109/infvis.2002.1173155;10.1109/vast.2007.4389006;10.1109/tvcg.2007.70577;10.1109/infvis.2002.1173148,"Text visualization, document visualization, Many Eyes, case study, concordance, information retrieval, search",449.0,206.0,15.0,3020.0,,,word tree graphical;rapid querying;bodies text paper;users obtain value;months public deployment,0.6574;0.3934;0.1986;0.1609;0.0528,"[np.int64(-1), -1, -1, -1, -1]",316;-1;-1;-1;-1,316,316
InfoVis,2013,"Interactive Visualizations on Large and Small Displays: The Interrelation of Display Size, Information Space, and Scale",10.1109/tvcg.2013.170,http://dx.doi.org/10.1109/TVCG.2013.170,2336.0,2345.0,J,"In controlled experiments on the relation of display size (i.e., the number of pixels) and the usability of visualizations, the size of the information space can either be kept constant or varied relative to display size. Both experimental approaches have limitations. If the information space is kept constant then the scale ratio between an overview of the entire information space and the lowest zoom level varies, which can impact performance; if the information space is varied then the scale ratio is kept constant, but performance cannot be directly compared. In other words, display size, information space, and scale ratio are interrelated variables. We investigate this relation in two experiments with interfaces that implement classic information visualization techniques-focus+context, overview+detail, and zooming-for multi-scale navigation in maps. Display size varied between 0.17, 1.5, and 13.8 megapixels. Information space varied relative to display size in one experiment and was constant in the other. Results suggest that for tasks where users navigate targets that are visible at all map scales the interfaces do not benefit from a large display: With a constant map size, a larger display does not improve performance with the interfaces; with map size varied relative to display size, participants found interfaces harder to use with a larger display and task completion times decrease only when they are normalized to compensate for the increase in map size. The two experimental approaches show different interaction effects between display size and interface. In particular, focus+context performs relatively worse at a large display size with variable map size, and relatively worse at a small display size with a fixed map size. Based on a theoretical analysis of the interaction with the visualization techniques, we examine individual task actions empirically so as to understand the relative impact of display size and scale ratio on the visualization techniques' performance and to discuss differences between the two experimental approaches.",Mikkel R. Jakobsen;Kasper Hornbæk,Mikkel R. Jakobsen;Kasper Hornbæk,"University of Copenhagen, Denmark;University of Copenhagen, Denmark",10.1109/tvcg.2006.184;10.1109/tvcg.2006.187;10.1109/tvcg.2006.184,"Information visualization, multi-scale navigation, interaction techniques, experimental method, user studies",42.0,25.0,32.0,1625.0,,,usability visualizations size;users navigate;focus context performs;interrelated variables;directly,0.6446;0.3474;0.2870;0.1075;-0.0122,"[np.int64(-1), -1, -1, -1, -1]",186;-1;-1;-1;-1,186,186
InfoVis,2006,Visualization of Geo-spatial Point Sets via Global Shape Transformation and Local Pixel Placement,10.1109/tvcg.2006.198,http://dx.doi.org/10.1109/TVCG.2006.198,749.0,756.0,J,"In many applications, data is collected and indexed by geo-spatial location. Discovering interesting patterns through visualization is an important way of gaining insight about such data. A previously proposed approach is to apply local placement functions such as PixelMaps that transform the input data set into a solution set that preserves certain constraints while making interesting patterns more obvious and avoid data loss from overplotting. In experience, this family of spatial transformations can reveal fine structures in large point sets, but it is sometimes difficult to relate those structures to basic geographic features such as cities and regional boundaries. Recent information visualization research has addressed other types of transformation functions that make spatially-transformed maps with recognizable shapes. These types of spatial-transformation are called global shape functions. In particular, cartogram-based map distortion has been studied. On the other hand, cartogram-based distortion does not handle point sets readily. In this study, we present a framework that allows the user to specify a global shape function and a local placement function. We combine cartogram-based layout (global shape) with PixelMaps (local placement), obtaining some of the benefits of each toward improved exploration of dense geo-spatial data sets",Christian Panse;Mike Sips;Daniel A. Keim;Stephen C. North,Christian Panse;Mike Sips;Daniel Keim;Stephen North,"University ETH Zurich, Switzerland;Max Planck Center for Visual Computing and Communication, University of Stanford, USA;University of Konstanz, Germany;AT and T Research Laboratories, NJ, USA",10.1109/visual.1998.745303;10.1109/infvis.2004.57;10.1109/visual.2003.1250410;10.1109/visual.1998.745303,"Geo-spatial Data, Shape Transformation, Cartogram, Pixel Visualization",48.0,22.0,12.0,508.0,,,cartogram based map;interesting patterns;apply local placement;transformations reveal fine;avoid,0.6521;0.2843;0.2154;0.1282;0.0954,"[np.int64(-1), -1, -1, -1, -1]",128;-1;-1;-1;-1,128,128
Vis,2004,Interactive terascale particle visualization,10.1109/visual.2004.55,http://dx.doi.org/10.1109/VISUAL.2004.55,353.0,360.0,C,"This work describes the methods used to produce an interactive visualization of a 2 TB computational fluid dynamics (CFD) data set using particle tracing (streaklines). We use the method introduced by Bruckschen el al. (2001) that precomputes a large number of particles, stores them on disk using a space-filling curve ordering that minimizes seeks, then retrieves and displays the particles according to the user's command. We describe how the particle computation can be performed using a PC cluster, how the algorithm can be adapted to work with a multiblock curvilinear mesh, how scalars can be extracted and used to color the particles, and how the out-of-core visualization can be scaled to 293 billion particles while still achieving interactive performance on PC hardware. Compared to the earlier work, our data set size and total number of particles are an order of magnitude larger. We also describe a new compression technique that losslessly reduces the amount of particle storage by 41% and speeds the particle retrieval by about 20%.",David A. Ellsworth;Bryan Green;Patrick J. Moran,D. Ellsworth;B. Green;P. Moran,"Advanced Management Technology Incorporataed, NASA Ames Research Center, USA;Advanced Management Technology Incorporataed, NASA Ames Research Center, USA;NASA Ames Research Center, USA",10.1109/visual.2003.1250375;10.1109/visual.1998.745299;10.1109/visual.1997.663888;10.1109/visual.2003.1250420;10.1109/visual.1994.346311;10.1109/visual.1998.745343;10.1109/visual.1995.480821;10.1109/visual.2003.1250375,"visualization, particle tracing, large data, out-of-core, PC hardware, clusters, computational fluid dynamics",56.0,19.0,14.0,171.0,,,using particle tracing;storage 41 speeds;ordering minimizes;core;retrieves displays,0.6219;0.1596;0.0700;0.0332;0.0240,"[np.int64(-1), -1, -1, -1, -1]",38;-1;-1;-1;-1,38,38
SciVis,2016,Physics-Based Visual Characterization of Molecular Interaction Forces,10.1109/tvcg.2016.2598825,http://dx.doi.org/10.1109/TVCG.2016.2598825,731.0,740.0,J,"Molecular simulations are used in many areas of biotechnology, such as drug design and enzyme engineering. Despite the development of automatic computational protocols, analysis of molecular interactions is still a major aspect where human comprehension and intuition are key to accelerate, analyze, and propose modifications to the molecule of interest. Most visualization algorithms help the users by providing an accurate depiction of the spatial arrangement: the atoms involved in inter-molecular contacts. There are few tools that provide visual information on the forces governing molecular docking. However, these tools, commonly restricted to close interaction between atoms, do not consider whole simulation paths, long-range distances and, importantly, do not provide visual cues for a quick and intuitive comprehension of the energy functions (modeling intermolecular interactions) involved. In this paper, we propose visualizations designed to enable the characterization of interaction forces by taking into account several relevant variables such as molecule-ligand distance and the energy function, which is essential to understand binding affinities. We put emphasis on mapping molecular docking paths obtained from Molecular Dynamics or Monte Carlo simulations, and provide time-dependent visualizations for different energy components and particle resolutions: atoms, groups or residues. The presented visualizations have the potential to support domain experts in a more efficient drug or enzyme design process.",Pedro Hermosilla;Jorge Estrada;Victor Guallar;Timo Ropinski;Àlvar Vinacua;Pere-Pau Vázquez,Pedro Hermosilla;Jorge Estrada;Victor Guallar;Timo Ropinski;Àlvar Vinacua;Pere-Pau Vázquez,"ViRVIG Group, Barcelona Supercomputing Center;Barcelona Supercomputing Center;Barcelona Supercomputing Center;Visual Computing Group, Ulm University;ViRVIG Group, UPC, Barcelona;ViRVIG Group, UPC, Barcelona",10.1109/tvcg.2009.168;10.1109/tvcg.2012.282;10.1109/tvcg.2015.2467293;10.1109/tvcg.2007.70578;10.1109/tvcg.2006.115;10.1109/tvcg.2007.70517;10.1109/tvcg.2014.2346403;10.1109/tvcg.2009.157;10.1109/tvcg.2009.168,Molecular visualization;binding analysis,21.0,17.0,52.0,708.0,,,molecule visualization;efficient drug enzyme;simulations used;docking tools commonly;taking account relevant,0.6606;0.3545;0.2855;0.2583;0.0086,"[np.int64(-1), -1, -1, -1, -1]",118;-1;-1;-1;-1,118,118
Vis,1992,Visualization for the document space,10.1109/visual.1992.235198,http://dx.doi.org/10.1109/VISUAL.1992.235198,274.0,281.0,C,"An information retrieval frame work that promotes graphical displays, and that will make documents in the computer visualizable to the searcher, is described. As examples of such graphical displays, two simulation results of using a Kohonen feature map to generate map displays for information retrieval are presented and discussed. The map displays are a mapping from a high-dimensional document space to a two-dimensional space. They show document relationships by various visual cues, such as dots, links, clusters, and areas, as well as their measurement and spatial arrangement. Using the map displays as an interface for document retrieval systems, the user is provided with richer visual information to support browsing and searching.&lt;&lt;ETX&gt;&gt;",X. Lin,X. Lin,"Center for Computerized Legal Research, Pace University, White Plains, NY, USA",,,110.0,16.0,17.0,186.0,,,displays information retrieval;using kohonen;dimensional space;map generate map;discussed,0.6679;0.3023;0.2868;0.2539;0.0188,"[np.int64(-1), -1, -1, -1, -1]",230;-1;-1;-1;-1,230,230
InfoVis,2020,ShuttleSpace: Exploring and Analyzing Movement Trajectory in Immersive Visualization,10.1109/tvcg.2020.3030392,http://dx.doi.org/10.1109/TVCG.2020.3030392,860.0,869.0,J,"We present ShuttleSpace, an immersive analytics system to assist experts in analyzing trajectory data in badminton. Trajectories in sports, such as the movement of players and balls, contain rich information on player behavior and thus have been widely analyzed by coaches and analysts to improve the players' performance. However, existing visual analytics systems often present the trajectories in court diagrams that are abstractions of reality, thereby causing difficulty for the experts to imagine the situation on the court and understand why the player acted in a certain way. With recent developments in immersive technologies, such as virtual reality (VR), experts gradually have the opportunity to see, feel, explore, and understand these 3D trajectories from the player's perspective. Yet, few research has studied how to support immersive analysis of sports data from such a perspective. Specific challenges are rooted in data presentation (e.g., how to seamlessly combine 2D and 3D visualizations) and interaction (e.g., how to naturally interact with data without keyboard and mouse) in VR. To address these challenges, we have worked closely with domain experts who have worked for a top national badminton team to design ShuttleSpace. Our system leverages 1) the peripheral vision to combine the 2D and 3D visualizations and 2) the VR controller to support natural interactions via a stroke metaphor. We demonstrate the effectiveness of ShuttleSpace through three case studies conducted by the experts with useful insights. We further conduct interviews with the experts whose feedback confirms that our first-person immersive analytics system is suitable and useful for analyzing badminton data.",Shuainan Ye;Zhutian Chen;Xiangtong Chu;Yifan Wang;Siwei Fu;Lejun Shen;Kun Zhou 0001;Yingcai Wu,Shuainan Ye;Zhutian Chen;Xiangtong Chu;Yifan Wang;Siwei Fu;Lejun Shen;Kun Zhou;Yingcai Wu,"State Key Lab of CAD CG, Zhejiang University;Hong Kong University of Science and Technology;State Key Lab of CAD CG, Zhejiang University;State Key Lab of CAD CG, Zhejiang University;Zhejiang Lab;Chengdu Sports University;State Key Lab of CAD CG, Zhejiang University;State Key Lab of CAD CG, Zhejiang University",10.1109/tvcg.2019.2934332;10.1109/vast.2014.7042478;10.1109/tvcg.2018.2865191;10.1109/tvcg.2016.2598831;10.1109/tvcg.2013.192;10.1109/visual.2001.964496;10.1109/tvcg.2019.2934243;10.1109/tvcg.2014.2346445;10.1109/vast.2014.7042477;10.1109/tvcg.2017.2745181;10.1109/tvcg.2017.2744218;10.1109/tvcg.2018.2865041;10.1109/tvcg.2018.2865192,"Movement trajectory,badminton analytics,virtual reality",43.0,61.0,49.0,2444.0,,,immersive analysis sports;stroke metaphor;data keyboard mouse;court understand;design shuttlespace leverages,0.7198;0.2911;0.2708;0.2008;0.1371,"[np.int64(-1), -1, -1, -1, -1]",297;-1;-1;-1;-1,297,297
InfoVis,2009,Constructing Overview + Detail Dendrogram-Matrix Views,10.1109/tvcg.2009.130,http://dx.doi.org/10.1109/TVCG.2009.130,889.0,896.0,J,"A dendrogram that visualizes a clustering hierarchy is often integrated with a re-orderable matrix for pattern identification. The method is widely used in many research fields including biology, geography, statistics, and data mining. However, most dendrograms do not scale up well, particularly with respect to problems of graphical and cognitive information overload. This research proposes a strategy that links an overview dendrogram and a detail-view dendrogram, each integrated with a re-orderable matrix. The overview displays only a user-controlled, limited number of nodes that represent the ldquoskeletonrdquo of a hierarchy. The detail view displays the sub-tree represented by a selected meta-node in the overview. The research presented here focuses on constructing a concise overview dendrogram and its coordination with a detail view. The proposed method has the following benefits: dramatic alleviation of information overload, enhanced scalability and data abstraction quality on the dendrogram, and the support of data exploration at arbitrary levels of detail. The contribution of the paper includes a new metric to measure the ldquoimportancerdquo of nodes in a dendrogram; the method to construct the concise overview dendrogram from the dynamically-identified, important nodes; and measure for evaluating the data abstraction quality for dendrograms. We evaluate and compare the proposed method to some related existing methods, and demonstrating how the proposed method can help users find interesting patterns through a case study on county-level U.S. cervical cancer mortality and demographic data.",Jin Chen;Alan M. MacEachren;Donna J. Peuquet,Jin Chen;Alan M. MacEachren;Donna J. Peuquet,"GeoVISTA Center, Department of Geography, Pennsylvania State University, USA;GeoVISTA Center, Department of Geography, Pennsylvania State University, USA;GeoVISTA Center, Department of Geography, Pennsylvania State University, USA",10.1109/tvcg.2006.161;10.1109/tvcg.2007.70535;10.1109/infvis.2004.46;10.1109/tvcg.2006.161,"Dendrogram, reorderable matrix, compound graphs, data abstraction quality metrics, hierarchical clusters",40.0,14.0,28.0,632.0,,,dendrogram visualizes clustering;evaluating data abstraction;orderable matrix pattern;cervical cancer mortality;user controlled limited,0.7383;0.3068;0.2252;0.1697;0.0281,"[np.int64(-1), -1, -1, -1, -1]",167;-1;-1;-1;-1,167,167
Vis,2023,ARGUS: Visualization of AI-Assisted Task Guidance in AR,10.1109/tvcg.2023.3327396,http://dx.doi.org/10.1109/TVCG.2023.3327396,1313.0,1323.0,J,"The concept of augmented reality (AR) assistants has captured the human imagination for decades, becoming a staple of modern science fiction. To pursue this goal, it is necessary to develop artificial intelligence (AI)-based methods that simultaneously perceive the 3D environment, reason about physical tasks, and model the performer, all in real-time. Within this framework, a wide variety of sensors are needed to generate data across different modalities, such as audio, video, depth, speech, and time-of-flight. The required sensors are typically part of the AR headset, providing performer sensing and interaction through visual, audio, and haptic feedback. AI assistants not only record the performer as they perform activities, but also require machine learning (ML) models to understand and assist the performer as they interact with the physical world. Therefore, developing such assistants is a challenging task. We propose ARGUS, a visual analytics system to support the development of intelligent AR assistants. Our system was designed as part of a multi-year-long collaboration between visualization researchers and ML and AR experts. This co-design process has led to advances in the visualization of ML in AR. Our system allows for online visualization of object, action, and step detection as well as offline analysis of previously recorded AR sessions. It visualizes not only the multimodal sensor data streams but also the output of the ML models. This allows developers to gain insights into the performer activities as well as the ML models, helping them troubleshoot, improve, and fine-tune the components of the AR assistant.",Sonia Castelo;João Rulff;Erin McGowan;Bea Steers;Guande Wu;Shaoyu Chen;Irán R. Román;Roque Lopez;Ethan Brewer;Chen Zhao;Jing Qian;Kyunghyun Cho;He He 0001;Qi Sun 0003;Huy T. Vo;Juan Pablo Bello;Michael Krone;Cláudio T. Silva,Sonia Castelo;Joao Rulff;Erin McGowan;Bea Steers;Guande Wu;Shaoyu Chen;Iran Roman;Roque Lopez;Ethan Brewer;Chen Zhao;Jing Qian;Kyunghyun Cho;He He;Qi Sun;Huy Vo;Juan Bello;Michael Krone;Claudio Silva,"New York University, New York;New York University, New York;New York University, New York;New York University, New York;New York University, New York;New York University, New York;New York University, New York;New York University, New York;New York University, New York;New York University, New York;New York University, New York;New York University, New York;New York University, New York;New York University, New York;New York University, New York;New York University, New York;New York University, New York;New York University, New York",0.1109/tvcg.2017.2746018;10.1109/tvcg.2018.2865152;10.1109/tvcg.2018.2864499,"Data Models,Image and Video Data,Temporal Data,Application Motivated Visualization,AR/VR/Immersive",,10.0,58.0,1124.0,HM,,reality ar assistants;performer perform activities;data streams output;modern science;necessary,0.6510;0.2641;0.1268;0.1133;0.0723,"[np.int64(-1), -1, -1, -1, -1]",78;-1;-1;-1;-1,78,78
InfoVis,2002,Case study: visualizing sets of evolutionary trees,10.1109/infvis.2002.1173150,http://dx.doi.org/10.1109/INFVIS.2002.1173150,71.0,74.0,C,"We describe a visualization tool which allows a biologist to explore a large set of hypothetical evolutionary trees. Interacting with such a dataset allows the biologist to identify distinct hypotheses about how different species or organisms evolved, which would not have been clear from traditional analyses. Our system integrates a point-set visualization of the distribution of hypothetical trees with detail views of an individual tree, or of a consensus tree summarizing a subset of trees. Efficient algorithms were required for the key tasks of computing distances between trees, finding consensus trees, and laying out the point-set visualization.",Nina Amenta;Jeff Klingner,N. Amenta;J. Klingner,"University of Texas, Austin, Austin, TX, USA;Computer Sciences Department, University of Texas, Austin, Austin, TX, USA",10.1109/visual.1996.567787;10.1109/visual.1993.398870;10.1109/visual.1996.567787,,119.0,27.0,15.0,395.0,,,evolutionary trees;point set visualization;finding consensus;traditional analyses integrates;different,0.6739;0.4496;0.2237;0.0359;0.0049,"[np.int64(-1), -1, -1, -1, -1]",12;-1;-1;-1;-1,12,12
Vis,2004,Light weight space leaping using ray coherence,10.1109/visual.2004.63,http://dx.doi.org/10.1109/VISUAL.2004.63,19.0,26.0,C,"We present a space leaping technique for accelerating volume rendering with very low space and run-time complexity. Our technique exploits the ray coherence during ray casting by using the distance a ray traverses in empty space to leap its neighboring rays. Our technique works with parallel as well as perspective volume rendering, does not require any preprocessing or 3D data structures, and is independent of the transfer function. Being an image-space technique, it is independent of the complexity of the data being rendered. It can be used to accelerate both time-coherent and noncoherent animation sequences.",Sarang Lakare;Arie E. Kaufman,S. Lakare;A. Kaufman,"Center for Visual Computing (CVC) and Department of Computer Science, Stony Brook University, Stony Brook, NY, USA;Center for Visual Computing (CVC) and Department of Computer Science, Stony Brook University, Stony Brook, NY, USA",10.1109/visual.1993.398852;10.1109/visual.1999.809914;10.1109/visual.1990.146377;10.1109/visual.1998.745713;10.1109/visual.2002.1183775;10.1109/visual.1993.398852,"Direct Volume Rendering, Space Leaping, Empty Space Skipping, Ray Coherence, Volume Rendering Acceleration",34.0,6.0,13.0,114.0,,,accelerating volume rendering;space leap neighboring;casting using;does require preprocessing;coherent noncoherent,0.6881;0.3528;0.1305;0.1218;0.0724,"[np.int64(-1), -1, -1, -1, -1]",93;-1;-1;-1;-1,93,93
Vis,1990,A problem-oriented classification of visualization techniques,10.1109/visual.1990.146375,http://dx.doi.org/10.1109/VISUAL.1990.146375,139.0,,C,"Progress in scientific visualization could be accelerated if workers could more readily find visualization techniques relevant to a given problem. The authors describe an approach to this problem, based on a classification of visualization techniques, that is independent of particular application domains. A user breaks up a problem into subproblems, describes these subproblems in terms of the objects to be represented and the operations to be supported by a representation, locates applicable visualization techniques in a catalog, and combines these representations into a composite representation for the original problem. The catalog and its underlying classification provide a way for workers in different application disciplines to share methods.&lt;&lt;ETX&gt;&gt;",Stephen Wehrend;Clayton Lewis,S. Wehrend;C. Lewis,"Center for Advanced Decision Support in Water and Environmental, Systems and Department of Computer Science, University of Colorado, Boulder, CO, USA;Center for Advanced Decision Support in Water and Environmental, Systems and Department of Computer Science, University of Colorado, Boulder, CO, USA",,,483.0,112.0,6.0,1214.0,,,scientific visualization;representations composite representation;particular application domains;readily;user breaks problem,0.7366;0.1735;0.1011;0.0638;0.0245,"[np.int64(-1), -1, -1, -1, -1]",150;-1;-1;-1;-1,150,150
SciVis,2016,Progressive Direct Volume-to-Volume Transformation,10.1109/tvcg.2016.2599042,http://dx.doi.org/10.1109/TVCG.2016.2599042,921.0,930.0,J,"We present a novel technique to generate transformations between arbitrary volumes, providing both expressive distances and smooth interpolates. In contrast to conventional morphing or warping approaches, our technique requires no user guidance, intermediate representations (like extracted features), or blending, and imposes no restrictions regarding shape or structure. Our technique operates directly on the volumetric data representation, and while linear programming approaches could solve the underlying problem optimally, their polynomial complexity makes them infeasible for high-resolution volumes. We therefore propose a progressive refinement approach designed for parallel execution that is able to quickly deliver approximate results that are iteratively improved toward the optimum. On this basis, we further present a new approach for the streaming selection of time steps in temporal data that allows for the reconstruction of the full sequence with a user-specified error bound. We finally demonstrate the utility of our technique for different applications, compare our approach against alternatives, and evaluate its characteristics with a variety of different data sets.",Steffen Frey;Thomas Ertl,Steffen Frey;Thomas Ertl,University of Stuttgart;University of Stuttgart,10.1109/tvcg.2008.140;10.1109/tvcg.2012.284;10.1109/visual.1994.346333;10.1109/tvcg.2008.143;10.1109/tvcg.2009.200;10.1109/visual.2002.1183809;10.1109/tvcg.2008.140,Volume transformation;Volume visualization;progressive;automatic;parallel;time-varying data;streaming data,14.0,12.0,47.0,679.0,,,morphing warping approaches;steps temporal data;arbitrary volumes providing;smooth;specified error,0.5367;0.3656;0.2639;0.2014;-0.0761,"[np.int64(-1), -1, -1, -1, -1]",290;-1;-1;-1;-1,290,290
Vis,2009,Visual Exploration of Nasal Airflow,10.1109/tvcg.2009.198,http://dx.doi.org/10.1109/TVCG.2009.198,1407.0,1414.0,J,"Rhinologists are often faced with the challenge of assessing nasal breathing from a functional point of view to derive effective therapeutic interventions. While the complex nasal anatomy can be revealed by visual inspection and medical imaging, only vague information is available regarding the nasal airflow itself: Rhinomanometry delivers rather unspecific integral information on the pressure gradient as well as on total flow and nasal flow resistance. In this article we demonstrate how the understanding of physiological nasal breathing can be improved by simulating and visually analyzing nasal airflow, based on an anatomically correct model of the upper human respiratory tract. In particular we demonstrate how various information visualization (InfoVis) techniques, such as a highly scalable implementation of parallel coordinates, time series visualizations, as well as unstructured grid multi-volume rendering, all integrated within a multiple linked views framework, can be utilized to gain a deeper understanding of nasal breathing. Evaluation is accomplished by visual exploration of spatio-temporal airflow characteristics that include not only information on flow features but also on accompanying quantities such as temperature and humidity. To our knowledge, this is the first in-depth visual exploration of the physiological function of the nose over several simulated breathing cycles under consideration of a complete model of the nasal airways, realistic boundary conditions, and all physically relevant time-varying quantities.",Stefan Zachow;Philipp Muigg;Thomas Hildebrandt;Helmut Doleisch;Hans-Christian Hege,Stefan Zachow;Philipp Muigg;Thomas Hildebrandt;Helmut Doleisch;Hans-Christian Hege,"Zuse Institute Berlin, Germany;Institute of Computer Graphics and Algorithms, University of Technology, Vienna, Austria;Section Brain Surgery, Asklepios Clinic Birkenwerder, Germany;SimVis GmbH, Austria;Zuse Institute Berlin, Germany",10.1109/tvcg.2008.139;10.1109/tvcg.2007.70588;10.1109/visual.2003.1250390;10.1109/visual.2000.885739;10.1109/visual.1990.146402;10.1109/visual.2005.1532788;10.1109/tvcg.2006.170;10.1109/tvcg.2008.139,"Flow visualization, exploratory data analysis, interactive visual analysis of scientific data, time-dependent data",55.0,31.0,44.0,730.0,,,nasal airflow rhinomanometry;visualization infovis techniques;simulating;physically relevant time;deeper,0.6935;0.3798;0.1797;0.0991;0.0838,"[np.int64(-1), -1, -1, -1, -1]",221;-1;-1;-1;-1,221,221
Vis,2010,An Information-theoretic Framework for Visualization,10.1109/tvcg.2010.132,http://dx.doi.org/10.1109/TVCG.2010.132,1206.0,1215.0,J,"In this paper, we examine whether or not information theory can be one of the theoretic frameworks for visualization. We formulate concepts and measurements for qualifying visual information. We illustrate these concepts with examples that manifest the intrinsic and implicit use of information theory in many existing visualization techniques. We outline the broad correlation between visualization and the major applications of information theory, while pointing out the difference in emphasis and some technical gaps. Our study provides compelling evidence that information theory can explain a significant number of phenomena or events in visualization, while no example has been found which is fundamentally in conflict with information theory. We also notice that the emphasis of some traditional applications of information theory, such as data compression or data communication, may not always suit visualization, as the former typically focuses on the efficient throughput of a communication channel, whilst the latter focuses on the effectiveness in aiding the perceptual and cognitive process for data understanding and knowledge discovery. These findings suggest that further theoretic developments are necessary for adopting and adapting information theory for visualization.",Min Chen 0001;Heike Jänicke,Min Chen;Heike Jaenicke,"Swansea University, UK;Ruprecht-Karls-University Heidelberg",10.1109/tvcg.2007.70615;10.1109/visual.2005.1532781;10.1109/tvcg.2006.152;10.1109/infvis.1996.559213;10.1109/visual.2005.1532834;10.1109/infvis.2000.885096;10.1109/tvcg.2007.70515;10.1109/tvcg.2006.159;10.1109/infvis.2004.59;10.1109/tvcg.2007.70535;10.1109/tvcg.2008.140;10.1109/tvcg.2008.121;10.1109/infvis.1997.636792;10.1109/visual.2005.1532833;10.1109/infvis.2000.885092;10.1109/visual.1990.146375;10.1109/visual.2002.1183785,"Information theory, theory of visualization, quantitative evaluation",192.0,108.0,56.0,2654.0,TT,,information theory visualization;findings suggest theoretic;explain;manifest intrinsic implicit;necessary adopting,0.7910;0.2025;0.1634;0.0004;-0.0284,"[np.int64(-1), -1, -1, -1, -1]",316;-1;-1;-1;-1,316,316
InfoVis,2017,MyBrush: Brushing and Linking with Personal Agency,10.1109/tvcg.2017.2743859,http://dx.doi.org/10.1109/TVCG.2017.2743859,605.0,615.0,J,"We extend the popular brushing and linking technique by incorporating personal agency in the interaction. We map existing research related to brushing and linking into a design space that deconstructs the interaction technique into three components: source (what is being brushed), link (the expression of relationship between source and target), and target (what is revealed as related to the source). Using this design space, we created MyBrush, a unified interface that offers personal agency over brushing and linking by giving people the flexibility to configure the source, link, and target of multiple brushes. The results of three focus groups demonstrate that people with different backgrounds leveraged personal agency in different ways, including performing complex tasks and showing links explicitly. We reflect on these results, paving the way for future research on the role of personal agency in information visualization.",Philipp Koytek;Charles Perin;Jo Vermeulen;Elisabeth André;Sheelagh Carpendale,Philipp Koytek;Charles Perin;Jo Vermeulen;Elisabeth André;Sheelagh Carpendale,"University of Calgary, Augsburg University;City, University of London, University of Calgary;University of Calgary;Augsburg University;University of Calgary",10.1109/tvcg.2011.185;10.1109/visual.1991.175794;10.1109/infvis.2003.1249024;10.1109/tvcg.2011.201;10.1109/tvcg.2007.70521;10.1109/vast.2009.5333443;10.1109/tvcg.2008.153;10.1109/infvis.2004.64;10.1109/infvis.1999.801858;10.1109/tvcg.2014.2346260;10.1109/visual.2000.885739;10.1109/infvis.2002.1173157;10.1109/vast.2007.4389011;10.1109/tvcg.2006.147;10.1109/tvcg.2008.116;10.1109/tvcg.2013.154;10.1109/tvcg.2010.138;10.1109/visual.1995.485139;10.1109/tvcg.2011.183;10.1109/tvcg.2009.162;10.1109/visual.1994.346302;10.1109/infvis.2004.12;10.1109/visual.1996.567800;10.1109/tvcg.2014.2346279;10.1109/infvis.1996.559216;10.1109/tvcg.2011.185,"Brushing,linking,personal agency,coordinated multiple views,interaction,design space,information visualization",36.0,27.0,82.0,1037.0,,,personal agency interaction;information visualization;popular brushing linking;source target target;different,0.5412;0.4387;0.4358;0.1131;0.0435,"[np.int64(-1), np.int64(-1), -1, -1, -1]",79;207;-1;-1;-1,79;207,79
VAST,2012,Visualizing flows of images in social media,10.1109/vast.2012.6400539,http://dx.doi.org/10.1109/VAST.2012.6400539,229.0,230.0,M,"Mass and social media provide flows of images for real world events. It is sometimes difficult to represent realities and impressions of events using only text. However, even a single photo might remind us complex events. Along with events in the real world, there are representative images, such as design of products and commercial pictures. We can therefore recognize changes in trends of people's ideas, experiences, and interests through observing the flows of such representative images. This paper presents a novel 3D visualization system to explore temporal changes in trends using images associating with different topics, called Image Bricks. We show case studies using images extracted from our six-year blog archive. We first extract clusters of images as topics related to given keywords. We then visualize them on multiple timelines in a 3D space. Users can visually read stories of topics through exploring visualized images.",Masahiko Itoh;Masashi Toyoda;Tetsuya Kamijo;Masaru Kitsuregawa,Masahiko Itoh;Masashi Toyoda;Tetsuya Kamijo;Masaru Kitsuregawa,"Institute of Industrial Science, University of Tokyo;Institute of Industrial Science, University of Tokyo;Rakuten, Inc.;Institute of Industrial Science, University of Tokyo",,,1.0,2.0,6.0,345.0,,,trends using images;multiple timelines 3d;blog archive extract;read stories;bricks case,0.6963;0.3811;0.2628;0.2496;0.2086,"[np.int64(-1), -1, -1, -1, -1]",310;-1;-1;-1;-1,310,310
Vis,1997,Constrained 3D navigation with 2D controllers,10.1109/visual.1997.663876,http://dx.doi.org/10.1109/VISUAL.1997.663876,175.0,182.0,C,"Navigation through 3D spaces is required in many interactive graphics and virtual reality applications. The authors consider the subclass of situations in which a 2D device such as a mouse controls smooth movements among viewpoints for a ""through the screen"" display of a 3D world. Frequently, there is a poor match between the goal of such a navigation activity, the control device, and the skills of the average user. They propose a unified mathematical framework for incorporating context-dependent constraints into the generalized viewpoint generation problem. These designer-supplied constraint modes provide a middle ground between the triviality of a single camera animation path and the confusing excess freedom of common unconstrained control paradigms. They illustrate the approach with a variety of examples, including terrain models, interior architectural spaces, and complex molecules.",Andrew J. Hanson;Eric A. Wernert,A.J. Hanson;E.A. Wernert,"Computer Science Department, Indiana University, Bloomington, IN, USA;Computer Science Department, Indiana University, Bloomington, IN, USA",10.1109/visual.1995.480804;10.1109/visual.1995.480804,"Navigation, Constrained Navigation, Viewing Control, Camera Control",189.0,32.0,25.0,250.0,,,navigation 3d spaces;framework incorporating context;screen display;common unconstrained;authors,0.6532;0.2401;0.2057;0.1998;0.0396,"[np.int64(-1), -1, -1, -1, -1]",239;-1;-1;-1;-1,239,239
Vis,1994,Piecewise-linear surface approximation from noisy scattered samples,10.1109/visual.1994.346336,http://dx.doi.org/10.1109/VISUAL.1994.346336,61.0,68.0,C,"We consider the problem of approximating a smooth surface f(x, y), based on n scattered samples {(x/sub i/, y/sub i/, z/sub i/)/sub i=1//sup n/} where the sample values {z/sub i/} are contaminated with noise: z/sub i/=f(x/sub i/, y/sub i/)=/spl epsiv//sub i/. We present an algorithm that generates a PLS (piecewise linear surface) f', defined on a triangulation of the sample locations V={(x/sub i/, y/sub i/)/sub i=1//sup n/}, approximating f well. Constructing the PLS involves specifying both the triangulation of V and the values of f' at the points of V. We demonstrate that even when the sampling process is not noisy, a better approximation for f is obtained using our algorithm, compared to existing methods. This algorithm is useful for DTM (digital terrain map) manipulation by polygon-based graphics engines for visualization applications.&lt;&lt;ETX&gt;&gt;",Michael Margaliot;Craig Gotsman,M. Margaliot;C. Gotsman,"Department of Electrical Engineering, Technion-Israel Institute of Technology, Haifa, Israel;Department of Computer Science, Technion-Israel Institute of Technology, Haifa, Israel",,,19.0,3.0,16.0,72.0,,,approximating smooth surface;defined triangulation;visualization applications lt;generates pls piecewise;contaminated,0.6507;0.4176;0.3435;0.2145;0.0497,"[np.int64(-1), -1, -1, -1, -1]",105;-1;-1;-1;-1,105,105
InfoVis,2005,Low-level components of analytic activity in information visualization,10.1109/infvis.2005.1532136,http://dx.doi.org/10.1109/INFVIS.2005.1532136,111.0,117.0,C,"Existing system level taxonomies of visualization tasks are geared more towards the design of particular representations than the facilitation of user analytic activity. We present a set of ten low level analysis tasks that largely capture people's activities while employing information visualization tools for understanding data. To help develop these tasks, we collected nearly 200 sample questions from students about how they would analyze five particular data sets from different domains. The questions, while not being totally comprehensive, illustrated the sheer variety of analytic questions typically posed by users when employing information visualization systems. We hope that the presented set of tasks is useful for information visualization system designers as a kind of common substrate to discuss the relative analytic capabilities of the systems. Further, the tasks may provide a form of checklist for system designers.",Robert A. Amar;James Eagan;John T. Stasko,R. Amar;J. Eagan;J. Stasko,"Georgia Institute of Technology,College of Computing, GVU Center;Georgia Institute of Technology,College of Computing, GVU Center;Georgia Institute of Technology,College of Computing, GVU Center",10.1109/visual.1990.146375;10.1109/infvis.1998.729560;10.1109/infvis.2000.885092;10.1109/infvis.2004.5;10.1109/infvis.2001.963289;10.1109/visual.1990.146375,"Analytic activity, taxonomy, knowledge discovery, design, evaluation",844.0,205.0,15.0,4315.0,,,information visualization designers;analytic questions typically;tasks collected nearly;kind common substrate;set low,0.7335;0.4007;0.1592;0.0402;-0.0959,"[np.int64(-1), -1, -1, -1, -1]",204;-1;-1;-1;-1,204,204
Vis,1998,Rear-projecting virtual data onto physical terrain: an exercise in two senses being better than one,10.1109/visual.1998.745341,http://dx.doi.org/10.1109/VISUAL.1998.745341,451.0,454.0,C,"This paper describes a project that combined physical model fabrication and virtual computer-based data display to create a unique visualization presentation. USGS terrain information on Prince of Wales Island, Alaska was used to create a physical prototype in SDSC's TeleManufacturing Facility. This model was then used as a mold to create a translucent plate of the terrain. Finally, deforestation data from the island was color mapped and rear-projected onto the translucent plate within a light box. The result is a very compelling display in which both the senses of sight and touch are used to make relationships between terrain features and the data more readily apparent.",Dru Clark;Richard Marciano;Rosemarie McKeon;Michael J. Bailey,D. Clark;R. Marciano;R. McKeon;M. Bailey,"San Diego Supercomputer Center, University of California, San Diego, USA;San Diego Supercomputer Center, University of California, San Diego, USA;San Diego Supercomputer Center, University of California, San Diego, USA;San Diego Supercomputer Center, University of California, San Diego, San Diego, CA, USA",10.1109/visual.1997.663862;10.1109/visual.1997.663862,,3.0,1.0,5.0,42.0,,,visualization presentation usgs;virtual computer based;used mold create;senses sight touch;island alaska used,0.6176;0.3057;0.2409;0.2146;0.1847,"[np.int64(-1), -1, -1, -1, -1]",322;-1;-1;-1;-1,322,322
VAST,2012,Enterprise Data Analysis and Visualization: An Interview Study,10.1109/tvcg.2012.219,http://dx.doi.org/10.1109/TVCG.2012.219,2917.0,2926.0,J,"Organizations rely on data analysts to model customer engagement, streamline operations, improve production, inform business decisions, and combat fraud. Though numerous analysis and visualization tools have been built to improve the scale and efficiency at which analysts can work, there has been little research on how analysis takes place within the social and organizational context of companies. To better understand the enterprise analysts' ecosystem, we conducted semi-structured interviews with 35 data analysts from 25 organizations across a variety of sectors, including healthcare, retail, marketing and finance. Based on our interview data, we characterize the process of industrial data analysis and document how organizational features of an enterprise impact it. We describe recurring pain points, outstanding challenges, and barriers to adoption for visual analytic tools. Finally, we discuss design implications and opportunities for visual analysis research.",Sean Kandel;Andreas Paepcke;Joseph M. Hellerstein;Jeffrey Heer,Sean Kandel;Andreas Paepcke;Joseph M. Hellerstein;Jeffrey Heer,"University of Stanford, USA;University of Stanford, USA;University of California, Berkeley, USA;University of Stanford, USA",10.1109/tvcg.2008.137;10.1109/vast.2008.4677365;10.1109/vast.2011.6102438;10.1109/infvis.2005.1532136;10.1109/vast.2010.5652880;10.1109/vast.2009.5333878;10.1109/vast.2007.4389011;10.1109/vast.2011.6102435;10.1109/tvcg.2008.137,"Data, analysis, visualization, enterprise",500.0,274.0,37.0,7112.0,HM,,visual analytic tools;companies better understand;35 data;takes place social;impact recurring pain,0.6462;0.3684;0.1937;0.1162;0.0162,"[np.int64(-1), -1, -1, -1, -1]",200;-1;-1;-1;-1,200,200
Vis,2010,Direct Interval Volume Visualization,10.1109/tvcg.2010.145,http://dx.doi.org/10.1109/TVCG.2010.145,1505.0,1514.0,J,"We extend direct volume rendering with a unified model for generalized isosurfaces, also called interval volumes, allowing a wider spectrum of visual classification. We generalize the concept of scale-invariant opacity-typical for isosurface rendering-to semi-transparent interval volumes. Scale-invariant rendering is independent of physical space dimensions and therefore directly facilitates the analysis of data characteristics. Our model represents sharp isosurfaces as limits of interval volumes and combines them with features of direct volume rendering. Our objective is accurate rendering, guaranteeing that all isosurfaces and interval volumes are visualized in a crack-free way with correct spatial ordering. We achieve simultaneous direct and interval volume rendering by extending preintegration and explicit peak finding with data-driven splitting of ray integration and hybrid computation in physical and data domains. Our algorithm is suitable for efficient parallel processing for interactive applications as demonstrated by our CUDA implementation.",Marco Ament;Daniel Weiskopf;Hamish A. Carr,Marco Ament;Daniel Weiskopf;Hamish Carr,"VISUS Visualization Research Center, Universität Stuttgart, Stuttgart, Germany;VISUS Visualization Research Center, Universität Stuttgart, Stuttgart, Germany;School of Computing, University of Leeds, Leeds, UK",10.1109/visual.1998.745713;10.1109/visual.1997.663886;10.1109/visual.2004.85;10.1109/visual.1995.480789;10.1109/visual.2002.1183762;10.1109/tvcg.2009.149;10.1109/tvcg.2006.113;10.1109/tvcg.2008.186;10.1109/visual.2000.885683;10.1109/visual.2005.1532808;10.1109/tvcg.2008.160;10.1109/visual.2003.1250384;10.1109/tvcg.2009.204;10.1109/visual.1995.480807;10.1109/visual.1998.745713,"Direct volume rendering, interval volume, isosurface, ray casting, preintegration, scale-invariant opacity",28.0,16.0,41.0,654.0,,,direct volume rendering;peak finding data;called interval;crack free way;unified model generalized,0.6920;0.2725;0.1662;0.1025;0.0943,"[np.int64(-1), -1, -1, -1, -1]",98;-1;-1;-1;-1,98,98
InfoVis,2014,Combing the Communication Hairball: Visualizing Parallel Execution Traces using Logical Time,10.1109/tvcg.2014.2346456,http://dx.doi.org/10.1109/TVCG.2014.2346456,2349.0,2358.0,J,"With the continuous rise in complexity of modern supercomputers, optimizing the performance of large-scale parallel programs is becoming increasingly challenging. Simultaneously, the growth in scale magnifies the impact of even minor inefficiencies - potentially millions of compute hours and megawatts in power consumption can be wasted on avoidable mistakes or sub-optimal algorithms. This makes performance analysis and optimization critical elements in the software development process. One of the most common forms of performance analysis is to study execution traces, which record a history of per-process events and interprocess messages in a parallel application. Trace visualizations allow users to browse this event history and search for insights into the observed performance behavior. However, current visualizations are difficult to understand even for small process counts and do not scale gracefully beyond a few hundred processes. Organizing events in time leads to a virtually unintelligible conglomerate of interleaved events and moderately high process counts overtax even the largest display. As an alternative, we present a new trace visualization approach based on transforming the event history into logical time inferred directly from happened-before relationships. This emphasizes the code's structural behavior, which is much more familiar to the application developer. The original timing data, or other information, is then encoded through color, leading to a more intuitive visualization. Furthermore, we use the discrete nature of logical timelines to cluster processes according to their local behavior leading to a scalable visualization of even long traces on large process counts. We demonstrate our system using two case studies on large-scale parallel codes.",Katherine E. Isaacs;Peer-Timo Bremer;Ilir Jusufi;Todd Gamblin;Abhinav Bhatele;Martin Schulz 0001;Bernd Hamann,Katherine E. Isaacs;Peer-Timo Bremer;Ilir Jusufi;Todd Gamblin;Abhinav Bhatele;Martin Schulz;Bernd Hamann,"University of California, Davis;Lawrence Livermore National Laboratory;University of California, Davis;Lawrence Livermore National Laboratory;Lawrence Livermore National Laboratory;Lawrence Livermore National Laboratory;University of California, Davis",10.1109/tvcg.2012.286;10.1109/tvcg.2009.196;10.1109/tvcg.2011.199;10.1109/tvcg.2013.200;10.1109/tvcg.2012.286,"Information visualization, software visualization, timelines, traces, performance analysis",64.0,35.0,44.0,853.0,,,application trace visualizations;parallel codes;time leads;power consumption;moderately,0.6666;0.3318;0.2515;0.1157;0.0285,"[np.int64(-1), -1, -1, -1, -1]",260;-1;-1;-1;-1,260,260
SciVis,2018,Tensor Field Visualization using Fiber Surfaces of Invariant Space,10.1109/tvcg.2018.2864846,http://dx.doi.org/10.1109/TVCG.2018.2864846,1122.0,1131.0,J,"Scientific visualization developed successful methods for scalar and vector fields. For tensor fields, however, effective, interactive visualizations are still missing despite progress over the last decades. We present a general approach for the generation of separating surfaces in symmetric, second-order, three-dimensional tensor fields. These surfaces are defined as fiber surfaces of the invariant space, i.e. as pre-images of surfaces in the range of a complete set of invariants. This approach leads to a generalization of the fiber surface algorithm by Klacansky et al. [16] to three dimensions in the range. This is due to the fact that the invariant space is three-dimensional for symmetric second-order tensors over a spatial domain. We present an algorithm for surface construction for simplicial grids in the domain and simplicial surfaces in the invariant space. We demonstrate our approach by applying it to stress fields from component design in mechanical engineering.",Felix Raith;Christian Blecha;Thomas Nagel;Francesco Parisio;Olaf Kolditz;Fabian Günther;Markus Stommel;Gerik Scheuermann,Felix Raith;Christian Blecha;Thomas Nagel;Francesco Parisio;Olaf Kolditz;Fabian Günther;Markus Stommel;Gerik Scheuermann,"Institute of Computer Science, Leipzig University, Leipzig, Germany;Institute of Computer Science, Leipzig University, Leipzig, Germany;Department of Environmental Informatics, Helmholtz Center for Environmental Research, Leipzig, Germany;Department of Environmental Informatics, Helmholtz Center for Environmental Research, Leipzig, Germany;Department of Environmental Informatics, Helmholtz Center for Environmental Research, Leipzig, Germany;Faculty for Mechanical Engineering, TU Dortmund University, Dortmund;Faculty for Mechanical Engineering, TU Dortmund University, Dortmund;Institute of Computer Science, Leipzig University, Leipzig, Germany",10.1109/visual.1994.346326;10.1109/visual.2003.1250379;10.1109/visual.1994.346326,"visualization,tensor field,invariants,fiber surface,interaction",18.0,21.0,36.0,622.0,,,tensor fields surfaces;interactive visualizations;grids domain simplicial;approach applying stress;range fact invariant,0.6828;0.3660;0.3006;0.2202;-0.0187,"[np.int64(-1), -1, -1, -1, -1]",17;-1;-1;-1;-1,17,17
InfoVis,2014,Revisiting Bertin Matrices: New Interactions for Crafting Tabular Visualizations,10.1109/tvcg.2014.2346279,http://dx.doi.org/10.1109/TVCG.2014.2346279,2082.0,2091.0,J,"We present Bertifier, a web app for rapidly creating tabular visualizations from spreadsheets. Bertifier draws from Jacques Bertin's matrix analysis method, whose goal was to “simplify without destroying” by encoding cell values visually and grouping similar rows and columns. Although there were several attempts to bring this method to computers, no implementation exists today that is both exhaustive and accessible to a large audience. Bertifier remains faithful to Bertin's method while leveraging the power of today's interactive computers. Tables are formatted and manipulated through crossets, a new interaction technique for rapidly applying operations on rows and columns. We also introduce visual reordering, a semi-interactive reordering approach that lets users apply and tune automatic reordering algorithms in a WYSIWYG manner. Sessions with eight users from different backgrounds suggest that Bertifier has the potential to bring Bertin's method to a wider audience of both technical and non-technical users, and empower them with data analysis and communication tools that were so far only accessible to a handful of specialists.COMPUTER",Charles Perin;Pierre Dragicevic;Jean-Daniel Fekete,Charles Perin;Pierre Dragicevic;Jean-Daniel Fekete,"INRIA, CNRS-LIMSI;INRIA;INRIA",10.1109/tvcg.2006.160;10.1109/tvcg.2014.2346292;10.1109/tvcg.2014.2346426;10.1109/tvcg.2006.160,"Visualization, Interaction, Tabular Data, Bertin, Crossing, Crossets",105.0,61.0,60.0,1031.0,,,tabular visualizations;reordering algorithms;web app rapidly;leveraging power today;bertifier remains faithful,0.6844;0.2624;0.2355;0.1610;0.1270,"[np.int64(-1), -1, -1, -1, -1]",261;-1;-1;-1;-1,261,261
Vis,1990,Case study in scientific visualization: factors inducing periodic breathing in humans with blunted hypoxic sensitivity,10.1109/visual.1990.146415,http://dx.doi.org/10.1109/VISUAL.1990.146415,430.0,434.0,C,"The problem of presenting and gaining deeper understanding of a multidimensional system, a mathematical model Predicting 20-90 s oscillations in breathing, is presented. The authors utilized custom software for interactive analysis of a three-dimensional model, plus Wavefront software to render translucent images of the 3D surfaces. The results show that under conditions of no peripheral chemosensor sensitivity, periodic breathing is predicted to occur with (1) an increase in circulatory transit time between the lungs and brain, (2) the presence of marked steady state hypoventilation, and/or (3) an increase in brain blood flow rate. It is concluded that the peripheral chemosensors (carotid bodies) are not essential for the development of periodic breathing.&lt;&lt;ETX&gt;&gt;",Wayne E. Fordyce;Jeffrey Ventrella,W.E. Fordyce;J.J. Ventrella,"Research Computing Services, Syracuse University, Syracuse, NY, USA;Research Computing Services, Syracuse University, Syracuse, NY, USA",0.1109/visual.1990.146415,,1.0,1.0,10.0,46.0,,,periodic breathing predicted;peripheral chemosensors;software interactive analysis;images 3d surfaces;state,0.7084;0.3371;0.0867;0.0782;-0.0205,"[np.int64(-1), -1, -1, -1, -1]",7;-1;-1;-1;-1,7,7
InfoVis,2016,Colorgorical: Creating discriminable and preferable color palettes for information visualization,10.1109/tvcg.2016.2598918,http://dx.doi.org/10.1109/TVCG.2016.2598918,521.0,530.0,J,"We present an evaluation of Colorgorical, a web-based tool for creating discriminable and aesthetically preferable categorical color palettes. Colorgorical uses iterative semi-random sampling to pick colors from CIELAB space based on user-defined discriminability and preference importances. Colors are selected by assigning each a weighted sum score that applies the user-defined importances to Perceptual Distance, Name Difference, Name Uniqueness, and Pair Preference scoring functions, which compare a potential sample to already-picked palette colors. After, a color is added to the palette by randomly sampling from the highest scoring palettes. Users can also specify hue ranges or build off their own starting palettes. This procedure differs from previous approaches that do not allow customization (e.g., pre-made ColorBrewer palettes) or do not consider visualization design constraints (e.g., Adobe Color and ACE). In a Palette Score Evaluation, we verified that each scoring function measured different color information. Experiment 1 demonstrated that slider manipulation generates palettes that are consistent with the expected balance of discriminability and aesthetic preference for 3-, 5-, and 8-color palettes, and also shows that the number of colors may change the effectiveness of pair-based discriminability and preference scores. For instance, if the Pair Preference slider were upweighted, users would judge the palettes as more preferable on average. Experiment 2 compared Colorgorical palettes to benchmark palettes (ColorBrewer, Microsoft, Tableau, Random). Colorgorical palettes are as discriminable and are at least as preferable or more preferable than the alternative palette sets. In sum, Colorgorical allows users to make customized color palettes that are, on average, as effective as current industry standards by balancing the importance of discriminability and aesthetic preference.",Connor Gramazio;David H. Laidlaw;Karen B. Schloss,Connor C. Gramazio;David H. Laidlaw;Karen B. Schloss,"Dept. of Computer Science at Brown University;Dept. of Computer Science at Brown University;Dept. of Cognitive, Linguistic, and Psychological Sciences at Brown University",10.1109/visual.1996.568118;10.1109/tvcg.2014.2346978;10.1109/tvcg.2015.2467471;10.1109/tvcg.2014.2346983;10.1109/tvcg.2012.233;10.1109/visual.1996.568118,Aesthetics in Visualization;Color Perception;Metrics & Benchmarks;Visual Design;Visualization,119.0,101.0,37.0,3136.0,,,preference color palettes;balancing importance discriminability;demonstrated slider manipulation;generates;function measured different,0.7348;0.2763;0.1581;0.0475;-0.0502,"[np.int64(-1), -1, -1, -1, -1]",219;-1;-1;-1;-1,219,219
Vis,1997,exVis: developing a wind tunnel data visualization tool,10.1109/visual.1997.663911,http://dx.doi.org/10.1109/VISUAL.1997.663911,417.0,420.0,C,"Software has been developed to apply visualization techniques to aeronautics data collected during wind tunnel experiments. Interaction between the software developers and the aeroscientists has been crucial in making the software. The interaction has also been important in building the scientists' confidence in the use of interactive, computer-mediated analysis tools.",Samuel P. Uselton,S.P. Uselton,"Ames Research Center, NASA, Moffett Field, CA, USA",,,22.0,6.0,0.0,95.0,,,wind tunnel experiments;software developers aeroscientists;apply visualization;use interactive computer;scientists confidence use,0.6379;0.4952;0.4543;0.2616;0.2133,"[np.int64(-1), -1, -1, -1, -1]",66;-1;-1;-1;-1,66,66
Vis,2008,Visualization of Cellular and Microvascular Relationships,10.1109/tvcg.2008.179,http://dx.doi.org/10.1109/TVCG.2008.179,1611.0,1618.0,J,"Understanding the structure of microvasculature structures and their relationship to cells in biological tissue is an important and complex problem. Brain microvasculature in particular is known to play an important role in chronic diseases. However, these networks are only visible at the microscopic level and can span large volumes of tissue. Due to recent advances in microscopy, large volumes of data can be imaged at the resolution necessary to reconstruct these structures. Due to the dense and complex nature of microscopy data sets, it is important to limit the amount of information displayed. In this paper, we describe methods for encoding the unique structure of microvascular data, allowing researchers to selectively explore microvascular anatomy. We also identify the queries most useful to researchers studying microvascular and cellular relationships. By associating cellular structures with our microvascular framework, we allow researchers to explore interesting anatomical relationships in dense and complex data sets.",David Mayerich;Louise C. Abbott;John Keyser,David Mayerich;Louise Abbott;John Keyser,"Department of Computer Science, Texas A and M University, USA;Department of Veterinary Integrative Biosciences, Texas A and M University, USA;Department of Computer Science, Texas A and M University, USA",10.1109/visual.2005.1532859;10.1109/visual.1997.663917;10.1109/tvcg.2006.197;10.1109/tvcg.2007.70532;10.1109/visual.2004.16;10.1109/visual.2005.1532859,"microscopy, biomedical, medical, blood vessels, cells",26.0,14.0,35.0,370.0,,,structure microvascular data;problem brain;limit information displayed;methods encoding unique;advances,0.7228;0.2447;0.1752;0.1447;0.0935,"[np.int64(-1), -1, -1, -1, -1]",225;-1;-1;-1;-1,225,225
InfoVis,2020,MobileVisFixer: Tailoring Web Visualizations for Mobile Phones Leveraging an Explainable Reinforcement Learning Framework,10.1109/tvcg.2020.3030423,http://dx.doi.org/10.1109/TVCG.2020.3030423,464.0,474.0,J,"We contribute MobileVisFixer, a new method to make visualizations more mobile-friendly. Although mobile devices have become the primary means of accessing information on the web, many existing visualizations are not optimized for small screens and can lead to a frustrating user experience. Currently, practitioners and researchers have to engage in a tedious and time-consuming process to ensure that their designs scale to screens of different sizes, and existing toolkits and libraries provide little support in diagnosing and repairing issues. To address this challenge, MobileVisFixer automates a mobile-friendly visualization re-design process with a novel reinforcement learning framework. To inform the design of MobileVisFixer, we first collected and analyzed SVG-based visualizations on the web, and identified five common mobile-friendly issues. MobileVisFixer addresses four of these issues on single-view Cartesian visualizations with linear or discrete scales by a Markov Decision Process model that is both generalizable across various visualizations and fully explainable. MobileVisFixer deconstructs charts into declarative formats, and uses a greedy heuristic based on Policy Gradient methods to find solutions to this difficult, multi-criteria optimization problem in reasonable time. In addition, MobileVisFixer can be easily extended with the incorporation of optimization algorithms for data visualizations. Quantitative evaluation on two real-world datasets demonstrates the effectiveness and generalizability of our method.",Aoyu Wu;Wai Tong;Tim Dwyer;Bongshin Lee;Petra Isenberg;Huamin Qu,Aoyu Wu;Wai Tong;Tim Dwyer;Bongshin Lee;Petra Isenberg;Huamin Qu,Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Monash University;Microsoft Research;Inria;Hong Kong University of Science and Technology,10.1109/tvcg.2018.2865234;10.1109/tvcg.2019.2934397;10.1109/tvcg.2018.2865138;10.1109/tvcg.2019.2934431;10.1109/vast.2007.4388994;10.1109/tvcg.2007.70594;10.1109/tvcg.2018.2865240;10.1109/tvcg.2017.2744320;10.1109/tvcg.2018.2865158;10.1109/tvcg.2016.2599030;10.1109/tvcg.2015.2467091;10.1109/tvcg.2012.196;10.1109/tvcg.2019.2934538;10.1109/tvcg.2018.2865234,"Mobile visualization,Responsive visualization,Machine learning for visualizations,Reinforcement learning",30.0,27.0,78.0,1404.0,,,visualizations mobile friendly;heuristic based policy;different sizes;screens lead frustrating;contribute,0.6404;0.2778;0.1615;0.1557;0.0637,"[np.int64(-1), -1, -1, -1, -1]",262;-1;-1;-1;-1,262,262
InfoVis,2002,InterRing: an interactive tool for visually navigating and manipulating hierarchical structures,10.1109/infvis.2002.1173151,http://dx.doi.org/10.1109/INFVIS.2002.1173151,77.0,84.0,C,"Radial, space-filling (RSF) techniques for hierarchy visualization have several advantages over traditional node-link diagrams, including the ability to efficiently use the display space while effectively conveying the hierarchy structure. Several RSF systems and tools have been developed to date, each with varying degrees of support for interactive operations such as selection and navigation. We describe what we believe to be a complete set of desirable operations on hierarchical structures. We then present InterRing, an RSF hierarchy visualization system that supports a significantly more extensive set of these operations than prior systems. In particular, InterRing supports multi-focus distortions, interactive hierarchy reconfiguration, and both semi-automated and manual selection. We show the power and utility of these and other operations, and describe our on-going efforts to evaluate their effectiveness and usability.",Jing Yang 0001;Matthew O. Ward;Elke A. Rundensteiner,Jing Yang;M.O. Ward;E.A. Rundensteiner,"Computer Science Department, Worcester Polytechnic Institute, Worcester, MA, USA;Computer Science Department, Worcester Polytechnic Institute, Worcester, MA, USA;Computer Science Department, Worcester Polytechnic Institute, Worcester, MA, USA",10.1109/infvis.2001.963290;10.1109/infvis.2001.963285;10.1109/infvis.1997.636718;10.1109/infvis.1999.801858;10.1109/infvis.1995.528689;10.1109/infvis.2001.963283;10.1109/visual.1991.175815;10.1109/infvis.2000.885091;10.1109/infvis.1999.801860;10.1109/infvis.2001.963284;10.1109/visual.1999.809866;10.1109/infvis.2001.963281;10.1109/infvis.1998.729557;10.1109/infvis.2001.963290,"radial space-filling hierarchy visualizations, multi-focus distortion, structure-based brushing",192.0,21.0,32.0,1028.0,,,hierarchy visualization supports;space filling rsf;reconfiguration semi automated;focus;date varying,0.7759;0.2713;0.1349;0.0963;-0.0968,"[np.int64(-1), -1, -1, -1, -1]",147;-1;-1;-1;-1,147,147
Vis,2021,A Critical Reflection on Visualization Research: Where Do Decision Making Tasks Hide?,10.1109/tvcg.2021.3114813,http://dx.doi.org/10.1109/TVCG.2021.3114813,1128.0,1138.0,J,"It has been widely suggested that a key goal of visualization systems is to assist decision making, but is this true? We conduct a critical investigation on whether the activity of decision making is indeed central to the visualization domain. By approaching decision making as a user <i>task</i>, we explore the degree to which decision tasks are evident in visualization research and user studies. Our analysis suggests that decision tasks are not commonly found in current visualization task taxonomies and that the visualization field has yet to leverage guidance from decision theory domains on how to study such tasks. We further found that the majority of visualizations addressing decision making were not evaluated based on their ability to assist decision tasks. Finally, to help expand the impact of visual analytics in organizational as well as casual decision making activities, we initiate a research agenda on how decision making assistance could be elevated throughout visualization research.",Evanthia Dimara;John T. Stasko,Evanthia Dimara;John Stasko,"Utrecht University, Netherlands and University of Konstanz, Germany;Georgia Tech, US",10.1109/vast.2011.6102457;10.1109/tvcg.2019.2934262;10.1109/infvis.2005.1532136;10.1109/infvis.2004.10;10.1109/vast.2007.4388995;10.1109/tvcg.2020.3028891;10.1109/tvcg.2016.2598869;10.1109/tvcg.2020.3030455;10.1109/tvcg.2013.186;10.1109/tvcg.2013.124;10.1109/tvcg.2013.146;10.1109/vast.2006.261431;10.1109/tvcg.2020.3030342;10.1109/infvis.1998.729560;10.1109/vast.2017.8585665;10.1109/infvis.1996.559213;10.1109/tvcg.2016.2598544;10.1109/tvcg.2018.2865233;10.1109/tvcg.2016.2598594;10.1109/tvcg.2017.2745138;10.1109/tvcg.2019.2934283;10.1109/tvcg.2020.3030469;10.1109/vast.2015.7347636;10.1109/tvcg.2013.226;10.1109/tvcg.2013.138;10.1109/vast.2008.4677365;10.1109/tvcg.2013.173;10.1109/vast.2010.5650815;10.1109/tvcg.2016.2598588;10.1109/tvcg.2019.2934659;10.1109/tvcg.2011.255;10.1109/tvcg.2018.2864889;10.1109/infvis.1997.636793;10.1109/tvcg.2020.3030335;10.1109/tvcg.2018.2864909;10.1109/tvcg.2012.215;10.1109/vast.2007.4388994;10.1109/tvcg.2014.2346930;10.1109/tvcg.2017.2744299;10.1109/tvcg.2018.2865159;10.1109/tvcg.2020.3028985;10.1109/tvcg.2010.177;10.1109/tvcg.2014.2346926;10.1109/tvcg.2012.278;10.1109/vast.2011.6102451;10.1109/tvcg.2016.2599106;10.1109/tvcg.2016.2598589;10.1109/vast.2006.261434;10.1109/tvcg.2015.2467754;10.1109/tvcg.2012.261;10.1109/tvcg.2011.196;10.1109/tvcg.2013.130;10.1109/vast.2009.5333920;10.1109/tvcg.2015.2467591;10.1109/tvcg.2014.2346481;10.1109/vast.2008.4677363;10.1109/tvcg.2013.120;10.1109/tvcg.2012.213;10.1109/tvcg.2015.2468011;10.1109/visual.1992.235203;10.1109/vast.2011.6102453;10.1109/visual.2005.1532781;10.1109/tvcg.2015.2468111;10.1109/tvcg.2017.2745078;10.1109/visual.1990.146375;10.1109/tvcg.2018.2865126;10.1109/infvis.1995.528682;10.1109/tvcg.2020.3028957;10.1109/tvcg.2016.2598664;10.1109/tvcg.2007.70515;10.1109/tvcg.2014.2346898;10.1109/tvcg.2018.2865076;10.1109/tvcg.2017.2744738;10.1109/tvcg.2020.3030458;10.1109/tvcg.2010.223;10.1109/tvcg.2014.2346922;10.1109/infvis.1995.528694;10.1109/vast.2011.6102457,"decision making,data,visualization,visual analytics,taxonomies,task",13.0,23.0,190.0,1955.0,,,visualizations addressing decision;making user task;study;theory domains;elevated,0.7813;0.1540;0.1104;0.0515;0.0102,"[np.int64(-1), -1, -1, -1, -1]",270;-1;-1;-1;-1,270,270
VAST,2017,SOMFlow: Guided Exploratory Cluster Analysis with Self-Organizing Maps and Analytic Provenance,10.1109/tvcg.2017.2744805,http://dx.doi.org/10.1109/TVCG.2017.2744805,120.0,130.0,J,"Clustering is a core building block for data analysis, aiming to extract otherwise hidden structures and relations from raw datasets, such as particular groups that can be effectively related, compared, and interpreted. A plethora of visual-interactive cluster analysis techniques has been proposed to date, however, arriving at useful clusterings often requires several rounds of user interactions to fine-tune the data preprocessing and algorithms. We present a multi-stage Visual Analytics (VA) approach for iterative cluster refinement together with an implementation (SOMFlow) that uses Self-Organizing Maps (SOM) to analyze time series data. It supports exploration by offering the analyst a visual platform to analyze intermediate results, adapt the underlying computations, iteratively partition the data, and to reflect previous analytical activities. The history of previous decisions is explicitly visualized within a flow graph, allowing to compare earlier cluster refinements and to explore relations. We further leverage quality and interestingness measures to guide the analyst in the discovery of useful patterns, relations, and data partitions. We conducted two pair analytics experiments together with a subject matter expert in speech intonation research to demonstrate that the approach is effective for interactive data analysis, supporting enhanced understanding of clustering results as well as the interactive process itself.",Dominik Sacha;Matthias Kraus 0002;Jürgen Bernard;Michael Behrisch 0001;Tobias Schreck;Yuki Asano 0003;Daniel A. Keim,Dominik Sacha;Matthias Kraus;Jürgen Bernard;Michael Behrisch;Tobias Schreck;Yuki Asano;Daniel A. Keim,"University of Konstanz, Germany;University of Konstanz, Germany;TU Darmstadt, Germany;University of Konstanz, Germany;Graz University of Technology;University of Tübingen;University of Konstanz, Germany",10.1109/vast.2009.5332584;10.1109/vast.2014.7042480;10.1109/tvcg.2013.178;10.1109/tvcg.2011.229;10.1109/tvcg.2011.188;10.1109/tvcg.2016.2598468;10.1109/vast.2010.5652443;10.1109/vast.2015.7347625;10.1109/vast.2007.4389013;10.1109/tvcg.2014.2346260;10.1109/tvcg.2007.70582;10.1109/vast.2007.4388999;10.1109/tvcg.2014.2346481;10.1109/tvcg.2016.2598495;10.1109/vast.2011.6102453;10.1109/vast.2009.5332584,"Visual Analytics,Interaction,Visual Cluster Analysis,Quality Metrics,Guidance,Self-Organizing Maps,Time Series",72.0,57.0,58.0,1887.0,,,interactive cluster analysis;data reflect previous;somflow uses self;intonation research;time,0.7032;0.2200;0.1985;0.1765;0.0697,"[np.int64(-1), -1, -1, -1, -1]",306;-1;-1;-1;-1,306,306
InfoVis,2015,Off the Radar: Comparative Evaluation of Radial Visualization Solutions for Composite Indicators,10.1109/tvcg.2015.2467322,http://dx.doi.org/10.1109/TVCG.2015.2467322,569.0,578.0,J,"A composite indicator (CI) is a measuring and benchmark tool used to capture multi-dimensional concepts, such as Information and Communication Technology (ICT) usage. Individual indicators are selected and combined to reflect a phenomena being measured. Visualization of a composite indicator is recommended as a tool to enable interested stakeholders, as well as the public audience, to better understand the indicator components and evolution overtime. However, existing CI visualizations introduce a variety of solutions and there is a lack in CI's visualization guidelines. Radial visualizations are popular among these solutions because of CI's inherent multi-dimensionality. Although in dispute, Radar-charts are often used for CI presentation. However, no empirical evidence on Radar's effectiveness and efficiency for common CI tasks is available. In this paper, we aim to fill this gap by reporting on a controlled experiment that compares the Radar chart technique with two other radial visualization methods: Flowercharts as used in the well-known OECD Betterlife index, and Circle-charts which could be adopted for this purpose. Examples of these charts in the current context are shown in Figure 1. We evaluated these charts, showing the same data with each of the mentioned techniques applying small multiple views for different dimensions of the data. We compared users' performance and preference empirically under a formal task-taxonomy. Results indicate that the Radar chart was the least effective and least liked, while performance of the two other options were mixed and dependent on the task. Results also showed strong preference of participants toward the Flower chart. Summarizing our results, we provide specific design guidelines for composite indicator visualization.",Yael Albo;Joel Lanir;Peter Bak;Sheizaf Rafaeli,Yael Albo;Joel Lanir;Peter Bak;Sheizaf Rafaeli,"University of Haifa, Israel;University of Haifa, Israel;IBM Research Haifa Lab, Haifa, Israel;Sheizaf Rafaeli is with University of Haifa, Israel",10.1109/tvcg.2010.209;10.1109/tvcg.2008.125;10.1109/tvcg.2010.209,"Visualization evaluation, radial layout design, composite indicator visualization, experiment",60.0,46.0,35.0,1415.0,,,composite indicator visualization;communication technology ict;compared users;radar effectiveness efficiency;adopted purpose,0.6964;0.2733;0.2726;0.1764;-0.0205,"[np.int64(-1), -1, -1, -1, -1]",177;-1;-1;-1;-1,177,177
VAST,2009,Multiple step social structure analysis with Cytoscape,10.1109/vast.2009.5333961,http://dx.doi.org/10.1109/VAST.2009.5333961,,,M,Cytoscape is a popular open source tool for biologists to visualize interaction networks. We find that it offers most of the desired functionality for visual analytics on graph data to guide us in the identification of the underlying social structure. We demonstrate its utility in the identification of the social structure in the VAST 2009 Flitter Mini Challenge.,Hao Zhou;Anna A. Shaverdian;H. V. Jagadish;George Michailidis,Hao Zhou;Anna A. Shaverdian;H.V. Jagadish;George Michailidis,"Department of Statistics, University of Michigan, USA;Department of EECS, University of Michigan, USA;Department of EECS, University of Michigan, USA;Department of Statistics, University of Michigan, USA",,,5.0,2.0,3.0,267.0,,,visualize interaction networks;cytoscape;flitter;data guide identification;2009,0.6566;0.5268;0.2608;0.1251;0.0354,"[np.int64(-1), np.int64(-1), -1, -1, -1]",169;19;-1;-1;-1,19;169,169
Vis,2024,2D Embeddings of Multi-Dimensional Partitionings,10.1109/tvcg.2024.3456394,http://dx.doi.org/10.1109/TVCG.2024.3456394,218.0,228.0,J,"Partitionings (or segmentations) divide a given domain into disjoint connected regions whose union forms again the entire domain. Multi-dimensional partitionings occur, for example, when analyzing parameter spaces of simulation models, where each segment of the partitioning represents a region of similar model behavior. Having computed a partitioning, one is commonly interested in understanding how large the segments are and which segments lie next to each other. While visual representations of 2D domain partitionings that reveal sizes and neighborhoods are straightforward, this is no longer the case when considering multi-dimensional domains of three or more dimensions. We propose an algorithm for computing 2D embeddings of multi-dimensional partitionings. The embedding shall have the following properties: It shall maintain the topology of the partitioning and optimize the area sizes and joint boundary lengths of the embedded segments to match the respective sizes and lengths in the multi-dimensional domain. We demonstrate the effectiveness of our approach by applying it to different use cases, including the visual exploration of 3D spatial domain segmentations and multi-dimensional parameter space partitionings of simulation ensembles. We numerically evaluate our algorithm with respect to how well sizes and lengths are preserved depending on the dimensionality of the domain and the number of segments.",Marina Evers;Lars Linsen,Marina Evers;Lars Linsen,"University of Münster, Germany;University of Münster, Germany",10.1109/tvcg.2011.186;10.1109/scivis.2015.7429487;10.1109/tvcg.2010.190;10.1109/tvcg.2009.122;10.1109/tvcg.2018.2865051;10.1109/tvcg.2014.2346321;10.1109/infvis.1999.801860;10.1109/tvcg.2016.2598830,"Multi-dimensional partitionings,segmentations,,,dimensionality reduction,parameter space visualization",,0.0,56.0,122.0,,,2d domain partitionings;simulation ensembles;including visual exploration;embeddings multi;demonstrate effectiveness,0.6854;0.4373;0.3511;0.2597;0.0041,"[np.int64(-1), -1, -1, -1, -1]",253;-1;-1;-1;-1,253,253
SciVis,2012,Derived Metric Tensors for Flow Surface Visualization,10.1109/tvcg.2012.211,http://dx.doi.org/10.1109/TVCG.2012.211,2149.0,2158.0,J,"Integral flow surfaces constitute a widely used flow visualization tool due to their capability to convey important flow information such as fluid transport, mixing, and domain segmentation. Current flow surface rendering techniques limit their expressiveness, however, by focusing virtually exclusively on displacement visualization, visually neglecting the more complex notion of deformation such as shearing and stretching that is central to the field of continuum mechanics. To incorporate this information into the flow surface visualization and analysis process, we derive a metric tensor field that encodes local surface deformations as induced by the velocity gradient of the underlying flow field. We demonstrate how properties of the resulting metric tensor field are capable of enhancing present surface visualization and generation methods and develop novel surface querying, sampling, and visualization techniques. The provided results show how this step towards unifying classic flow visualization and more advanced concepts from continuum mechanics enables more detailed and improved flow analysis.",Harald Obermaier;Kenneth I. Joy,Harald Obermaier;Kenneth I. Joy,"Institute for Data Analysis and Visualization (IDAV), University of California, Davis, USA;Institute for Data Analysis and Visualization (IDAV), University of California, Davis, USA",10.1109/tvcg.2008.163;10.1109/tvcg.2010.173;10.1109/tvcg.2011.170;10.1109/tvcg.2006.134;10.1109/tvcg.2008.133;10.1109/visual.1992.235211;10.1109/tvcg.2007.70551;10.1109/visual.2004.80;10.1109/tvcg.2009.190;10.1109/tvcg.2010.166;10.1109/tvcg.2009.154;10.1109/tvcg.2007.70554;10.1109/tvcg.2008.163,"Vector field, integral surfaces, metric tensor, deformation, velocity gradient, continuum mechanics",14.0,9.0,29.0,511.0,,,flow surface visualization;notion deformation shearing;derive metric tensor;exclusively;field encodes local,0.7172;0.3776;0.2800;-0.0091;-0.0181,"[np.int64(-1), -1, -1, -1, -1]",145;-1;-1;-1;-1,145,145
Vis,2022,Erato: Cooperative Data Story Editing via Fact Interpolation,10.1109/tvcg.2022.3209428,http://dx.doi.org/10.1109/TVCG.2022.3209428,983.0,993.0,J,"As an effective form of narrative visualization, visual data stories are widely used in data-driven storytelling to communicate complex insights and support data understanding. Although important, they are difficult to create, as a variety of interdisciplinary skills, such as data analysis and design, are required. In this work, we introduce Erato, a human-machine cooperative data story editing system, which allows users to generate insightful and fluent data stories together with the computer. Specifically, Erato only requires a number of keyframes provided by the user to briefly describe the topic and structure of a data story. Meanwhile, our system leverages a novel interpolation algorithm to help users insert intermediate frames between the keyframes to smooth the transition. We evaluated the effectiveness and usefulness of the Erato system via a series of evaluations including a Turing test, a controlled user study, a performance validation, and interviews with three expert users. The evaluation results showed that the proposed interpolation technique was able to generate coherent story content and help users create data stories more efficiently.",Mengdi Sun;Ligan Cai;Weiwei Cui;Yanqiu Wu 0001;Yang Shi 0007;Nan Cao 0001,Mengdi Sun;Ligan Cai;Weiwei Cui;Yanqiu Wu;Yang Shi;Nan Cao,"Intelligent Big Data Visualization Lab, Tongji University, China;Intelligent Big Data Visualization Lab, Tongji University, China;Microsoft Research Asia, China;Intelligent Big Data Visualization Lab, Tongji University, China;Intelligent Big Data Visualization Lab, Tongji University, China;Intelligent Big Data Visualization Lab, Tongji University, China",10.1109/tvcg.2016.2598647;10.1109/tvcg.2015.2467732;10.1109/tvcg.2016.2598876;10.1109/tvcg.2021.3114804;10.1109/tvcg.2019.2934785;10.1109/tvcg.2015.2467531;10.1109/tvcg.2013.119;10.1109/tvcg.2020.3030360;10.1109/tvcg.2021.3114775;10.1109/tvcg.2007.70594;10.1109/tvcg.2018.2865240;10.1109/tvcg.2012.249;10.1109/tvcg.2010.179;10.1109/tvcg.2020.3030403;10.1109/visual.2005.1532849;10.1109/tvcg.2018.2865232;10.1109/tvcg.2019.2934398;10.1109/visual.1995.480798;10.1109/tvcg.2015.2467191;10.1109/tvcg.2021.3114774;10.1109/tvcg.2016.2598647,"Interpolation,visual storytelling,human-machine cooperation",,6.0,61.0,987.0,,,narrative visualization;keyframes smooth transition;turing test controlled;erato requires number;including,0.7136;0.2261;0.1531;0.0820;0.0134,"[np.int64(-1), -1, -1, -1, -1]",156;-1;-1;-1;-1,156,156
Vis,2004,"Anisotropic volume rendering for extremely dense, thin line data",10.1109/visual.2004.5,http://dx.doi.org/10.1109/VISUAL.2004.5,107.0,114.0,C,"Many large scale physics-based simulations which take place on PC clusters or supercomputers produce huge amounts of data including vector fields. While these vector data such as electromagnetic fields, fluid flow fields, or particle paths can be represented by lines, the sheer number of the lines overwhelms the memory and computation capability of a high-end PC used for visualization. Further, very dense or intertwined lines, rendered with traditional visualization techniques, can produce unintelligible results with unclear depth relationships between the lines and no sense of global structure. Our approach is to apply a lighting model to the lines and sample them into an anisotropic voxel representation based on spherical harmonics as a preprocessing step. Then we evaluate and render these voxels for a given view using traditional volume rendering. For extremely large line based datasets, conversion to anisotropic voxels reduces the overall storage and rendering for O(n) lines to O(1) with a large constant that is still small enough to allow meaningful visualization of the entire dataset at nearly interactive rates on a single commodity PC.",Gregory L. Schussman;Kwan-Liu Ma,G. Schussman;K.-L. Ma,"Stanford Linear Accelerator Center, USA;University of California Davis, USA",,"anisotropic lighting, line data, scientific visualization, vector field, volume rendering",34.0,16.0,17.0,236.0,,,traditional volume rendering;intertwined lines;fields particle;pc clusters supercomputers;entire dataset,0.5938;0.2691;0.2355;0.2194;0.1071,"[np.int64(-1), -1, -1, -1, -1]",97;-1;-1;-1;-1,97,97
InfoVis,1997,Domesticating Bead: adapting an information visualization system to a financial institution,10.1109/infvis.1997.636789,http://dx.doi.org/10.1109/INFVIS.1997.636789,73.0,80.0,C,"The Bead visualization system employs a fast algorithm for laying out high-dimensional data in a low-dimensional space, and a number of features added to 3D visualizations to improve imageability. We describe recent work on both aspects of the system, in particular a generalization of the data types laid out and the implementation of imageability features in a 2D visualization tool. The variety of data analyzed in a financial institution such as UBS, and the ubiquity of spreadsheets as a medium for analysis, led us to extend our layout tools to handle data in a generic spreadsheet format. We describe the metrics of similarity used for this data type, and give examples of layouts of sets of records of financial trades. Conservatism and scepticism with regard to 3D visualization, along with the lack of functionality of widely available 3D web browsers, led to the development of a 2D visualization tool with refinements of a number of our imageability features.",Dominique Brodbeck;Matthew Chalmers;Aran Lunzer;Pamela Cotture,D. Brodbeck;M. Chalmers;A. Lunzer;P. Cotture,"UbiLaboratory, Union Bank of Switzerland, Zurich, Switzerland;UbiLaboratory, Union Bank of Switzerland, Zurich, Switzerland;UbiLaboratory, Union Bank of Switzerland, Zurich, Switzerland;UbiLaboratory, Union Bank of Switzerland, Zurich, Switzerland",10.1109/visual.1990.146402;10.1109/infvis.1995.528686;10.1109/visual.1996.568118;10.1109/infvis.1995.528688;10.1109/visual.1994.346302;10.1109/visual.1991.175794;10.1109/visual.1996.567787;10.1109/infvis.1996.559223;10.1109/visual.1990.146402,,59.0,16.0,23.0,199.0,,,bead visualization employs;3d web browsers;metrics similarity;generic spreadsheet;data low,0.6199;0.3715;0.3500;0.3421;0.1214,"[np.int64(-1), -1, -1, -1, -1]",323;-1;-1;-1;-1,323,323
InfoVis,2011,MoleView: An Attribute and Structure-Based Semantic Lens for Large Element-Based Plots,10.1109/tvcg.2011.223,http://dx.doi.org/10.1109/TVCG.2011.223,2600.0,2609.0,J,"We present MoleView, a novel technique for interactive exploration of multivariate relational data. Given a spatial embedding of the data, in terms of a scatter plot or graph layout, we propose a semantic lens which selects a specific spatial and attribute-related data range. The lens keeps the selected data in focus unchanged and continuously deforms the data out of the selection range in order to maintain the context around the focus. Specific deformations include distance-based repulsion of scatter plot points, deforming straight-line node-link graph drawings, and as varying the simplification degree of bundled edge graph layouts. Using a brushing-based technique, we further show the applicability of our semantic lens for scenarios requiring a complex selection of the zones of interest. Our technique is simple to implement and provides real-time performance on large datasets. We demonstrate our technique with actual data from air and road traffic control, medical imaging, and software comprehension applications.",Christophe Hurter;Alexandru C. Telea;Ozan Ersoy,Christophe Hurter;Alexandru Telea;Ozan Ersoy,"DGAC/DTI Research and Development, ENAC, University of Toulouse, France;University of Groningen, Netherlands;University of Groningen, Netherlands",10.1109/tvcg.2011.233;10.1109/tvcg.2008.135;10.1109/tvcg.2006.147;10.1109/infvis.2005.1532150;10.1109/infvis.2004.66;10.1109/infvis.2003.1249008;10.1109/tvcg.2011.233,"Semantic lenses, magic lenses, graph bundling, attribute filtering",98.0,49.0,35.0,858.0,,,interactive exploration multivariate;edge graph layouts;semantic;air road traffic;deforming straight,0.5465;0.3906;0.2541;0.1793;0.1345,"[np.int64(-1), -1, -1, -1, -1]",257;-1;-1;-1;-1,257,257
Vis,2010,Interactive Visual Analysis of Multiple Simulation Runs Using the Simulation Model View: Understanding and Tuning of an Electronic Unit Injector,10.1109/tvcg.2010.171,http://dx.doi.org/10.1109/TVCG.2010.171,1449.0,1457.0,J,"Multiple simulation runs using the same simulation model with different values of control parameters generate a large data set that captures the behavior of the modeled phenomenon. However, there is a conceptual and visual gap between the simulation model behavior and the data set that makes data analysis more difficult. We propose a simulation model view that helps to bridge that gap by visually combining the simulation model description and the generated data. The simulation model view provides a visual outline of the simulation process and the corresponding simulation model. The view is integrated in a Coordinated Multiple Views; (CMV) system. As the simulation model view provides a limited display space, we use three levels of details. We explored the use of the simulation model view, in close collaboration with a domain expert, to understand and tune an electronic unit injector (EUI). We also developed analysis procedures based on the view. The EUI is mostly used in heavy duty Diesel engines. We were mainly interested in understanding the model and how to tune it for three different operation modes: low emission, low consumption, and high power. Very positive feedback from the domain expert shows that the use of the simulation model view and the corresponding ;analysis procedures within a CMV system represents an effective technique for interactive visual analysis of multiple simulation runs.",Kresimir Matkovic;Denis Gracanin;Mario Jelovic;Andreas Ammer;Alan Lez;Helwig Hauser,Kresimir Matkovic;Denis Gracanin;Mario Jelovic;Andreas Ammer;Alan Lez;Helwig Hauser,"VRVis Research Center Vienna, Austria;Virginia Technology, USA;AVL AST d.o.o., Zagreb, Croatia;VRVis Research Center Vienna, Austria;VRVis Research Center Vienna, Austria;University of Bergen, Norway",10.1109/tvcg.2009.155;10.1109/infvis.2002.1173149;10.1109/infvis.1995.528685;10.1109/infvis.2002.1173157;10.1109/tvcg.2009.155,"Visualization in physical sciences and engineering, time series data, coordinated multiple views",45.0,29.0,20.0,788.0,,,simulation model view;duty diesel engines;tune electronic unit;gap visually combining;set captures behavior,0.6296;0.3067;0.2505;0.1200;0.0232,"[np.int64(-1), -1, -1, -1, -1]",0;-1;-1;-1;-1,0,0
Vis,1994,Mix&Match: a construction kit for visualization,10.1109/visual.1994.346305,http://dx.doi.org/10.1109/VISUAL.1994.346305,302.0,,C,"We present an environment in which users can interactively create different visualization methods. This modular and extensible environment encapsulates most of the existing visualization algorithms. Users can easily construct new visualization methods by combining simple, fine grain building blocks. These components operate on a local subset of the data and generally either look for target features or produce visual objects. Intermediate compositions may also be used to build more complex visualizations. This environment provides a foundation for building and exploring novel visualization methods.&lt;&lt;ETX&gt;&gt;",Alex Pang;Naim Alper,A. Pang;N. Alper,"Computer Engineering & Information Sciences, University of California, Santa Cruz, CA, USA;Computer Engineering & Information Sciences, University of California, Santa Cruz, CA, USA",10.1109/visual.1993.398860;10.1109/visual.1990.146373;10.1109/visual.1991.175804;10.1109/visual.1992.235207;10.1109/visual.1992.235219;10.1109/visual.1993.398880;10.1109/visual.1993.398879;10.1109/visual.1993.398860,,27.0,7.0,18.0,60.0,,,visualization methods modular;subset data;simple fine grain;environment provides foundation;target,0.7148;0.1699;0.1089;0.0743;0.0140,"[np.int64(-1), -1, -1, -1, -1]",275;-1;-1;-1;-1,275,275
InfoVis,2004,Uncovering Clusters in Crowded Parallel Coordinates Visualizations,10.1109/infvis.2004.68,http://dx.doi.org/10.1109/INFVIS.2004.68,81.0,88.0,C,"The one-to-one strategy of mapping each single data item into a graphical marker adopted in many visualization techniques has limited usefulness when the number of records and/or the dimensionality of the data set are very high. In this situation, the strong overlapping of graphical markers severely hampers the user's ability to identify patterns in the data from its visual representation. We tackle this problem here with a strategy that computes frequency or density information from the data set, and uses such information in parallel coordinates visualizations to filter out the information to be presented to the user, thus reducing visual clutter and allowing the analyst to observe relevant patterns in the data. The algorithms to construct such visualizations, and the interaction mechanisms supported, inspired by traditional image processing techniques such as grayscale manipulation and thresholding are also presented. We also illustrate how such algorithms can assist users to effectively identify clusters in very noisy large data sets",Almir Olivette Artero;Maria Cristina Ferreira de Oliveira;Haim Levkowitz,A.O. Artero;M.C.F. de Oliveira;H. Levkowitz,"Department of Computer Science, University of São Paulo, Brazil;Department of Computer Science, University of São Paulo;Department of Computer Science, University of Massachusetts, USA",10.1109/visual.1994.346302;10.1109/visual.1994.346302,"information visualization, visual clustering, density-based visualization, visual data mining",238.0,75.0,17.0,931.0,,,data visual representation;clusters noisy large;grayscale manipulation thresholding;computes frequency density;marker adopted,0.6583;0.3963;0.3641;0.1732;0.0663,"[np.int64(-1), -1, -1, -1, -1]",261;-1;-1;-1;-1,261,261
Vis,1993,Dichromatic color representations for complex display systems,10.1109/visual.1993.398871,http://dx.doi.org/10.1109/VISUAL.1993.398871,212.0,219.0,C,"New display technologies have begun to provide more innovative and potentially powerful methods to present information to a viewer. However, many of these techniques struggle to deliver accurate full color. In this paper, we address this difficulty by employing the dichromatic theory of color reflection, which implies that many objects can be rendered accurately using only two primaries. Complex display systems with two primaries can be produced with significantly less work than is required for the traditional three primaries. We discuss methods for selecting objects that can be rendered accurately on two-color displays, and we present our experiments with a two-color display using monochromatic primaries.&lt;&lt;ETX&gt;&gt;",Mark S. Peercy;Lambertus Hesselink,M.S. Peercy;L. Hesselink,"Department of Applied Physics, University of Stanford, Stanford, CA, USA;Department of Electrical Engineering, Department of Aeronautics and Astronautics, University of Stanford, Stanford, CA, USA",,,7.0,0.0,22.0,51.0,,,color displays;primaries complex;reflection implies objects;powerful methods;lt lt,0.6975;0.3143;0.2249;0.1374;0.0350,"[np.int64(-1), -1, -1, -1, -1]",25;-1;-1;-1;-1,25,25
Vis,2004,Force-Feedback-Enhanced Navigation for Interactive Visualization of Coronary Vessels,10.1109/visual.2004.33,http://dx.doi.org/10.1109/VISUAL.2004.33,32.0,32.0,M,"Coronary heart disease (CHD) is the number one killer in the United States. Although it is well known that CHD mainly occurs due to blocked arteries, there are contradictory results from studies designed to identify basic causes for this common disease is. To find out more about the true reason for CHD, virtual models can be employed to better understand the way the heart functions. With such a model, scientists and surgeons are able to analyze the effects of different treatment options, and ultimately find more suited ways to prevent coronary heart diseases. To investigate a given model, appropriate navigation methods are required, including suitable input devices. For the visualization, graphics cards originally designed for gaming applications are used; so, it is a just natural transition to adapt gaming input devices to a visualization system for controlling of the navigation. These devices are usually well designed with respect to ergonomics and durability, yielding more degrees of freedom in steering than two-dimensional input devices, such as desktop mice. This poster describes a visualization system that provides the user with advanced control devices for navigation enabling interactive exploration of the model. Force-feedback and sound effects provide additional cues.",Thomas Wischgoll;Elke Moritz;Jörg Meyer 0002,T. Wischgoll;E. Moritz;J. Meyer,"University of California, Irvine, USA;University of California, Irvine, USA;University of California, Irvine, USA",,,5.0,1.0,5.0,68.0,,,visualization controlling navigation;gaming input devices;heart disease chd;model force;results studies designed,0.5673;0.5008;0.2698;0.2626;0.1373,"[np.int64(-1), np.int64(-1), -1, -1, -1]",121;79;-1;-1;-1,79;121,121
VAST,2020,Visual Abstraction of Geographical Point Data with Spatial Autocorrelations,10.1109/vast50239.2020.00011,http://dx.doi.org/10.1109/VAST50239.2020.00011,60.0,71.0,C,"Scatterplots are always employed to visualize geographical point datasets, which often suffer from an overdraw problem due to the increase of data sizes. A variety of sampling strategies have been proposed to reduce overdraw and visual clutter with the spatial densities of points taken into account. However, informative attributes associated with the points also play significant roles in the exploration of geographical datasets. In this paper, we propose an attribute-based abstraction method to simplify the cluttered visualization of large-scale geographical points. Spatial autocorrelations are utilized to measure the attribute relationships of points in local areas, and a novel attribute-based sampling model is designed to generate a subset of points to preserve both density and attribute characteristics of original geographical points. A set of visual designs and user-friendly interactions are implemented, enabling users to capture the spatial distribution of geographical points and get deeper insights into the attribute features across local areas. Case studies and quantitative comparisons based on the real-world datasets further demonstrate the effectiveness of our method in the abstraction and exploration of large-scale geographical point datasets.",Zhiguang Zhou;Xinlong Zhang;Zhendong Yang;Yuanyuan Chen;Yuhua Liu;Jin Wen;Binjie Chen;Ying Zhao 0001;Wei Chen 0001,Zhiguang Zhou;Xinlong Zhang;Zhendong Yang;Yuanyuan Chen;Yuhua Liu;Jin Wen;Binjie Chen;Ying Zhao;Wei Chen,"School of Information, Zhejiang University of Finance and Economics and State Key Lab of CAD & CG, Zhejiang University;School of Information, Zhejiang University of Finance and Economics;School of Information, Zhejiang University of Finance and Economics;School of Information, Zhejiang University of Finance and Economics;School of Information, Zhejiang University of Finance and Economics;School of Information, Zhejiang University of Finance and Economics;School of Information, Zhejiang University of Finance and Economics;School of Computer Sciences and Engineering, Central South University;State Key Lab of CAD & CG, Zhejiang University",10.1109/tvcg.2008.119;10.1109/tvcg.2016.2598862;10.1109/tvcg.2014.2346594;10.1109/tvcg.2019.2934541;10.1109/tvcg.2006.161;10.1109/tvcg.2019.2934670;10.1109/tvcg.2008.175;10.1109/tvcg.2007.70535;10.1109/tvcg.2010.176;10.1109/tvcg.2019.2934799;10.1109/tvcg.2016.2598432;10.1109/tvcg.2016.2598831;10.1109/tvcg.2006.170;10.1109/tvcg.2010.180;10.1109/tvcg.2014.2346265;10.1109/tvcg.2014.2346746;10.1109/tvcg.2019.2934208;10.1109/tvcg.2017.2744098;10.1109/vast47406.2019.8986943;10.1109/tvcg.2018.2865020;10.1109/tvcg.2018.2864503;10.1109/tvcg.2008.119,"Visual Abstraction,Spatial Autocorrelation,Sampling,Geospatial Analysis",6.0,9.0,61.0,692.0,,,visualize geographical;point datasets suffer;attribute based abstraction;increase;autocorrelations utilized measure,0.6627;0.4242;0.3709;0.1019;0.0780,"[np.int64(-1), -1, -1, -1, -1]",154;-1;-1;-1;-1,154,154
Vis,2003,Video visualization,10.1109/visual.2003.1250401,http://dx.doi.org/10.1109/VISUAL.2003.1250401,409.0,416.0,C,"Video data, generated by the entertainment industry, security and traffic cameras, video conferencing systems, video emails, and so on, is perhaps most time-consuming to process by human beings. In this paper, we present a novel methodology for ""summarizing"" video sequences using volume visualization techniques. We outline a system pipeline for capturing videos, extracting features, volume rendering video and feature data, and creating video visualization. We discuss a collection of image comparison metrics, including the linear dependence detector, for constructing ""relative"" and ""absolute"" difference volumes that represent the magnitude of variation between video frames. We describe the use of a few volume visualization techniques, including volume scene graphs and spatial transfer functions, for creating video visualization. In particular, we present a stream-based technique for processing and directly rendering video data in real time. With the aid of several examples, we demonstrate the effectiveness of using video visualization to convey meaningful information contained in video sequences.",Gareth Daniel;Min Chen 0001,G. Daniel;Min Chen,"University of Wales, UK;University of Wales, UK",10.1109/visual.2002.1183790;10.1109/visual.2002.1183790," Video visualization, volume rendering, video surveillance, change detection, image-swept volume",137.0,59.0,25.0,536.0,,,video visualization;extracting features volume;industry security traffic;difference;including,0.7539;0.3731;0.1966;0.0778;0.0663,"[np.int64(-1), -1, -1, -1, -1]",258;-1;-1;-1;-1,258,258
VAST,2008,Crystal structures classifier for an evolutionary algorithm structure predictor,10.1109/vast.2008.4677351,http://dx.doi.org/10.1109/VAST.2008.4677351,11.0,18.0,C,"USPEX is a crystal structure predictor based on an evolutionary algorithm. Every USPEX run produces hundreds or thousands of crystal structures, some of which may be identical. To ease the extraction of unique and potentially interesting structures we applied usual high-dimensional classification concepts to the unusual field of crystallography. We experimented with various crystal structure descriptors, distinct distance measures and tried different clustering methods to identify groups of similar structures. These methods are already applied in combinatorial chemistry to organic molecules for a different goal and in somewhat different forms, but are not widely used for crystal structures classification. We adopted a visual design and validation method in the development of a library (CrystalFp) and an end-user application to select and validate method choices, to gain userspsila acceptance and to tap into their domain expertise. The use of the classifier has already accelerated the analysis of USPEX output by at least one order of magnitude, promoting some new crystallographic insight and discovery. Furthermore the visual display of key algorithm indicators has led to diverse, unexpected discoveries that will improve the USPEX algorithms.",Mario Valle;Artem R. Oganov,Mario Valle;Artem R. Oganov,"Data Analysis and Visualization Services, Swiss National Supercomputing Centre, Switzerland;Laboratory of Crystallography, Department of Materials, ETH Zürich",,,16.0,6.0,31.0,544.0,,,crystal structure predictor;improve uspex;adopted visual;application select validate;thousands,0.6913;0.2876;0.1762;0.0217;-0.0400,"[np.int64(-1), -1, -1, -1, -1]",119;-1;-1;-1;-1,119,119
SciVis,2015,Streamline Variability Plots for Characterizing the Uncertainty in Vector Field Ensembles,10.1109/tvcg.2015.2467204,http://dx.doi.org/10.1109/TVCG.2015.2467204,767.0,776.0,J,"We present a new method to visualize from an ensemble of flow fields the statistical properties of streamlines passing through a selected location. We use principal component analysis to transform the set of streamlines into a low-dimensional Euclidean space. In this space the streamlines are clustered into major trends, and each cluster is in turn approximated by a multivariate Gaussian distribution. This yields a probabilistic mixture model for the streamline distribution, from which confidence regions can be derived in which the streamlines are most likely to reside. This is achieved by transforming the Gaussian random distributions from the low-dimensional Euclidean space into a streamline distribution that follows the statistical model, and by visualizing confidence regions in this distribution via iso-contours. We further make use of the principal component representation to introduce a new concept of streamline-median, based on existing median concepts in multidimensional Euclidean spaces. We demonstrate the potential of our method in a number of real-world examples, and we compare our results to alternative clustering approaches for particle trajectories as well as curve boxplots.",Florian Ferstl;Kai Bürger;Rüdiger Westermann,Florian Ferstl;Kai Bürger;Rüdiger Westermann,"Computer Graphics and Visualization Group, Technische Universität München;Computer Graphics and Visualization Group, Technische Universität München;Computer Graphics and Visualization Group, Technische Universität München",10.1109/tvcg.2007.70595;10.1109/visual.2000.885715;10.1109/visual.1999.809863;10.1109/tvcg.2013.141;10.1109/tvcg.2007.70518;10.1109/tvcg.2014.2346455;10.1109/visual.2005.1532779;10.1109/tvcg.2010.181;10.1109/visual.1999.809865;10.1109/tvcg.2013.143;10.1109/tvcg.2007.70595,"Ensemble visualization, uncertainty visualization, flow visualization, streamlines, statistical modeling",109.0,83.0,50.0,1788.0,,,flow fields statistical;alternative clustering approaches;based existing median;euclidean spaces demonstrate;component,0.6407;0.3505;0.2823;0.1298;0.1010,"[np.int64(-1), -1, -1, -1, -1]",38;-1;-1;-1;-1,38,38
Vis,1999,Progressive compression and transmission of arbitrary triangular meshes,10.1109/visual.1999.809902,http://dx.doi.org/10.1109/VISUAL.1999.809902,307.0,537.0,C,"The recent growth in the size and availability of large triangular surface models has generated interest in compact multi-resolution progressive representation and data transmission. An ongoing challenge is to design an efficient data structure that encompasses both compactness of geometric representations and visual quality of progressive representations. We introduce a topological layering based data structure and an encoding scheme to build a compact progressive representation of an arbitrary triangular mesh (a 2D simplicial complex in 3D) with attached attribute data. This compact representation is composed of multiple levels of detail that can be progressively transmitted and displayed. The global topology, which is the number of holes and connected components, can be flexibly changed among successive levels while still achieving guaranteed size of the coarsest level mesh for very complex models. The flexibility in our encoding scheme also allows topology preserving progressivity.",Chandrajit L. Bajaj;Valerio Pascucci;Guozhong Zhuang,C.L. Bajaj;V. Pascucci;G. Zhuang,"Department of Computer Sciences, University of Technology, Austin, TX, USA;Department of Computer Sciences, University of Technology, Austin, TX, USA;Department of Computer Sciences, University of Technology, Austin, TX, USA",10.1109/visual.1998.745283;10.1109/visual.1997.663883;10.1109/visual.1998.745283,,133.0,36.0,26.0,93.0,,,mesh 2d simplicial;quality progressive representations;structure encompasses compactness;attached attribute data;size coarsest level,0.6051;0.3744;0.2548;0.1722;0.1069,"[np.int64(-1), -1, -1, -1, -1]",112;-1;-1;-1;-1,112,112
InfoVis,2020,Data Visceralization: Enabling Deeper Understanding of Data Using Virtual Reality,10.1109/tvcg.2020.3030435,http://dx.doi.org/10.1109/TVCG.2020.3030435,1095.0,1105.0,J,"A fundamental part of data visualization is transforming data to map abstract information onto visual attributes. While this abstraction is a powerful basis for data visualization, the connection between the representation and the original underlying data (i.e., what the quantities and measurements actually correspond with in reality) can be lost. On the other hand, virtual reality (VR) is being increasingly used to represent real and abstract models as natural experiences to users. In this work, we explore the potential of using VR to help restore the basic understanding of units and measures that are often abstracted away in data visualization in an approach we call data visceralization. By building VR prototypes as design probes, we identify key themes and factors for data visceralization. We do this first through a critical reflection by the authors, then by involving external participants. We find that data visceralization is an engaging way of understanding the qualitative aspects of physical measures and their real-life form, which complements analytical and quantitative understanding commonly gained from data visualization. However, data visceralization is most effective when there is a one-to-one mapping between data and representation, with transformations such as scaling affecting this understanding. We conclude with a discussion of future directions for data visceralization.",Benjamin Lee;Dave Brown;Bongshin Lee;Christophe Hurter;Steven Mark Drucker;Tim Dwyer,Benjamin Lee;Dave Brown;Bongshin Lee;Christophe Hurter;Steven Drucker;Tim Dwyer,"Monash University;Microsoft Research;Microsoft Research;ENAC, French Civil Aviation University;Microsoft Research;Monash University",10.1109/tvcg.2013.210;10.1109/infvis.1998.729560;10.1109/tvcg.2018.2865237;10.1109/tvcg.2010.179;10.1109/tvcg.2016.2598498;10.1109/visual.2001.964545;10.1109/tvcg.2013.210,"Data visceralization,virtual reality,exploratory study",28.0,40.0,59.0,2240.0,HM,,visualization data visceralization;reality vr increasingly;basic understanding units;critical reflection;restore basic,0.6203;0.4338;0.2924;0.2043;-0.0133,"[np.int64(-1), -1, -1, -1, -1]",317;-1;-1;-1;-1,317,317
Vis,2000,An integrated visualization and design toolkit for flexible prosthetic heart valves,10.1109/visual.2000.885730,http://dx.doi.org/10.1109/VISUAL.2000.885730,453.0,456.0,C,"We describe a toolkit for the design and visualization of flexible artificial heart valves. The toolkit consists of interlinked modules with a visual programming interface. The user of the toolkit can set the initial geometry and material properties of the valve leaflet, solve for the flexing of the leaflet and the flow of blood around it, and display the results using the visualization capabilities of the toolkit. The interactive nature of our environment is highlighted by the fact that changes in leaflet properties are immediately reflected in the flow field and response of the leaflet. Hence the user may, in a single session, investigate a broad range of designs, each one of which provides important information about the blood flow and motion of the valve during the cardiac cycle.",A. J. Fenlon;Tim David;J. P. R. B. Walton,A.J. Fenlon;T. David;J.P.R.B. Walton,"Numerical Algorithms Group (NAG) Limited, Oxford, UK;School of Mechanical Engineering, University of Leeds, Leeds, UK;School of Mechanical Engineering, University of Leeds, Leeds, UK",,"Computational fluid dynamics, interactive design, prosthetic heart valves, visualization systems",10.0,0.0,20.0,59.0,,,flexible artificial heart;toolkit design visualization;important information blood;leaflet properties immediately;single,0.7274;0.3565;0.1912;0.1353;-0.0607,"[np.int64(-1), -1, -1, -1, -1]",33;-1;-1;-1;-1,33,33
Vis,2003,Interactive protein manipulation,10.1109/visual.2003.1250423,http://dx.doi.org/10.1109/VISUAL.2003.1250423,581.0,588.0,C,"We describe an interactive visualization and modeling program for the creation of protein structures ""from scratch."" The input to our program is an amino acid sequence - decoded from a gene - and a sequence of predicted secondary structure types for each amino acid - provided by external structure prediction programs. Our program can be used in the set-up phase of a protein structure prediction process; the structures created with it serve as input for a subsequent global internal energy minimization, or another method of protein structure prediction. Our program supports basic visualization methods for protein structures, interactive manipulation based on inverse kinematics, and visualization guides to aid a user in creating ""good"" initial structures.",Oliver Kreylos;Nelson L. Max;Bernd Hamann;Silvia N. Crivelli;E. Wes Bethel,O. Kreylos;N.L. Max;B. Hamann;S.N. Crivelli;E. Wes Bethel,"Center for Image Processing and Integrated Computing, Department of Computer Science, University of California, Davis, CA, USA;Lawrence Berkeley National Laboratory, Berkeley, CA, USA and Center for Image Processing and Integrated Computing, Department of Computer Science, University of California, Davis, CA, USA;Lawrence Berkeley National Laboratory, Berkeley, CA, USA and Center for Image Processing and Integrated Computing, Department of Computer Science, University of California, Davis, CA, USA;Lawrence Berkeley National Laboratory, Berkeley, CA, USA;Lawrence Berkeley National Laboratory, Berkeley, CA, USA",,"Protein Structure Prediction, Protein Manipulation, Inverse Kinematics, Molecular Modeling, Molecular Visualization, Interactive Visualization, Computational Science",31.0,7.0,14.0,101.0,BA,,protein structures interactive;based inverse kinematics;prediction process;global internal energy;supports basic,0.7505;0.1914;0.1754;0.0791;0.0458,"[np.int64(-1), -1, -1, -1, -1]",118;-1;-1;-1;-1,118,118
InfoVis,1996,Visage: a user interface environment for exploring information,10.1109/infvis.1996.559210,http://dx.doi.org/10.1109/INFVIS.1996.559210,3.0,,C,"Visage is a prototype user interface environment for exploring and analyzing information. It represents an approach to coordinating multiple visualizations, analysis and presentation tools in data-intensive domains. Visage is based on an information-centric approach to user interface design which strives to eliminate impediments to direct user access to information objects across applications and visualizations. Visage consists of a set of data manipulation operations, an intelligent system for generating a wide variety of data visualizations (SAGE) and a briefing tool that supports the conversion of visual displays used during exploration into interactive presentation slides. This paper presents the user interface components and styles of interaction that are central to Visage's information-centric approach.",Steven F. Roth;Peter Lucas 0002;Jeffrey Senn;Cristina C. Gomberg;Michael B. Burks;Philip J. Stroffolino;John A. Kolojechick;Carolyn Dunmire,S.F. Roth;P. Lucas;J.A. Senn;C.C. Gomberg;M.B. Burks;P.J. Stroffolino;A.J. Kolojechick;C. Dunmire,"School of Computer Science, Carnegie Mellon University, Pittsburgh, PA, USA and Aberdeen Proving Ground, Army Research Laboratory, MD, USA;School of Computer Science, Carnegie Mellon University, Pittsburgh, PA, USA and Aberdeen Proving Ground, Army Research Laboratory, MD, USA;School of Computer Science, Carnegie Mellon University, Pittsburgh, PA, USA and Aberdeen Proving Ground, Army Research Laboratory, MD, USA;School of Computer Science, Carnegie Mellon University, Pittsburgh, PA, USA and Aberdeen Proving Ground, Army Research Laboratory, MD, USA;School of Computer Science, Carnegie Mellon University, Pittsburgh, PA, USA and Aberdeen Proving Ground, Army Research Laboratory, MD, USA;School of Computer Science, Carnegie Mellon University, Pittsburgh, PA, USA and Aberdeen Proving Ground, Army Research Laboratory, MD, USA;;School of Computer Science, Carnegie Mellon University, Pittsburgh, PA, USA and Aberdeen Proving Ground, Army Research Laboratory, MD, USA",10.1109/visual.1993.398870;10.1109/visual.1991.175815;10.1109/visual.1993.398870,"Visualization, exploratory data analysis, graphics, user interface environment, human-computer interaction",213.0,43.0,13.0,345.0,TT,,data visualizations;components styles interaction;paper presents user;domains visage based;eliminate impediments direct,0.6749;0.2315;0.1811;0.1766;0.0805,"[np.int64(-1), -1, -1, -1, -1]",203;-1;-1;-1;-1,203,203
Vis,2009,Structuring Feature Space: A Non-Parametric Method for Volumetric Transfer Function Generation,10.1109/tvcg.2009.185,http://dx.doi.org/10.1109/TVCG.2009.185,1473.0,1480.0,J,"The use of multi-dimensional transfer functions for direct volume rendering has been shown to be an effective means of extracting materials and their boundaries for both scalar and multivariate data. The most common multi-dimensional transfer function consists of a two-dimensional (2D) histogram with axes representing a subset of the feature space (e.g., value vs. value gradient magnitude), with each entry in the 2D histogram being the number of voxels at a given feature space pair. Users then assign color and opacity to the voxel distributions within the given feature space through the use of interactive widgets (e.g., box, circular, triangular selection). Unfortunately, such tools lead users through a trial-and-error approach as they assess which data values within the feature space map to a given area of interest within the volumetric space. In this work, we propose the addition of non-parametric clustering within the transfer function feature space in order to extract patterns and guide transfer function generation. We apply a non-parametric kernel density estimation to group voxels of similar features within the 2D histogram. These groups are then binned and colored based on their estimated density, and the user may interactively grow and shrink the binned regions to explore feature boundaries and extract regions of interest. We also extend this scheme to temporal volumetric data in which time steps of 2D histograms are composited into a histogram volume. A three-dimensional (3D) density estimation is then applied, and users can explore regions within the feature space across time without adjusting the transfer function at each time step. Our work enables users to effectively explore the structures found within a feature space of the volume and provide a context in which the user can understand how these structures relate to their volumetric data. We provide tools for enhanced exploration and manipulation of the transfer function, and we show that the initial transfer function generation serves as a reasonable base for volumetric rendering, reducing the trial-and-error overhead typically found in transfer function design.",Ross Maciejewski;Insoo Woo;Wei Chen 0001;David S. Ebert,Ross Maciejewski;Insoo Woo;Wei Chen;David Ebert,"Rendering and Perceptualization Laboratory, Purdue University, USA;Rendering and Perceptualization Laboratory, Purdue University, USA;State Key Laboratory of CAD&CG, University of Zhejiang, China;Rendering and Perceptualization Laboratory, Purdue University, USA",10.1109/tvcg.2008.119;10.1109/visual.1998.745319;10.1109/visual.2003.1250414;10.1109/visual.2003.1250371;10.1109/visual.2005.1532807;10.1109/tvcg.2008.162;10.1109/visual.2001.964519;10.1109/visual.2003.1250413;10.1109/visual.2005.1532858;10.1109/tvcg.2006.148;10.1109/tvcg.2008.119,"Volume rendering, kernel density estimation, transfer function design, temporal volume rendering",132.0,77.0,29.0,955.0,,,volumetric rendering;histograms composited histogram;extract patterns guide;users assign color;function time,0.6278;0.2444;0.2374;0.1828;0.0540,"[np.int64(-1), -1, -1, -1, -1]",256;-1;-1;-1;-1,256,256
InfoVis,2017,Stable Treemaps via Local Moves,10.1109/tvcg.2017.2745140,http://dx.doi.org/10.1109/TVCG.2017.2745140,729.0,738.0,J,"Treemaps are a popular tool to visualize hierarchical data: items are represented by nested rectangles and the area of each rectangle corresponds to the data being visualized for this item. The visual quality of a treemap is commonly measured via the aspect ratio of the rectangles. If the data changes, then a second important quality criterion is the stability of the treemap: how much does the treemap change as the data changes. We present a novel stable treemapping algorithm that has very high visual quality. Whereas existing treemapping algorithms generally recompute the treemap every time the input changes, our algorithm changes the layout of the treemap using only local modifications. This approach not only gives us direct control over stability, but it also allows us to use a larger set of possible layouts, thus provably resulting in treemaps of higher visual quality compared to existing algorithms. We further prove that we can reach all possible treemap layouts using only our local modifications. Furthermore, we introduce a new measure for stability that better captures the relative positions of rectangles. We finally show via experiments on real-world data that our algorithm outperforms existing treemapping algorithms also in practice on either visual quality and/or stability. Our algorithm scores high on stability regardless of whether we use an existing stability measure or our new measure.",Max Sondag;Bettina Speckmann;Kevin Verbeek,Max Sondag;Bettina Speckmann;Kevin Verbeek,TU Eindhoven;TU Eindhoven;TU Eindhoven,10.1109/infvis.2001.963283;10.1109/tvcg.2007.70529;10.1109/infvis.2005.1532145;10.1109/infvis.2001.963283,"Treemap,Stability,Local Moves",45.0,28.0,20.0,1269.0,,,treemaps;change data;aspect ratio;commonly;direct control stability,0.7471;0.1225;0.1108;0.0801;0.0080,"[np.int64(-1), -1, -1, -1, -1]",54;-1;-1;-1;-1,54,54
Vis,2022,Unifying Effects of Direct and Relational Associations for Visual Communication,10.1109/tvcg.2022.3209443,http://dx.doi.org/10.1109/TVCG.2022.3209443,385.0,395.0,J,"People have expectations about how colors map to concepts in visualizations, and they are better at interpreting visualizations that match their expectations. Traditionally, studies on these expectations (inferred mappings) distinguished distinct factors relevant for visualizations of categorical vs. continuous information. Studies on categorical information focused on direct associations (e.g., mangos are associated with yellows) whereas studies on continuous information focused on relational associations (e.g., darker colors map to larger quantities; dark-is-more bias). We unite these two areas within a single framework of assignment inference. Assignment inference is the process by which people infer mappings between perceptual features and concepts represented in encoding systems. Observers infer globally optimal assignments by maximizing the “merit,” or “goodness,” of each possible assignment. Previous work on assignment inference focused on visualizations of categorical information. We extend this approach to visualizations of continuous data by (a) broadening the notion of merit to include relational associations and (b) developing a method for combining multiple (sometimes conflicting) sources of merit to predict people's inferred mappings. We developed and tested our model on data from experiments in which participants interpreted colormap data visualizations, representing fictitious data about environmental concepts (sunshine, shade, wild fire, ocean water, glacial ice). We found both direct and relational associations contribute independently to inferred mappings. These results can be used to optimize visualization design to facilitate visual communication.",Melissa A. Schoenlein;Johnny Campos;Kevin J. Lande;Laurent Lessard;Karen B. Schloss,Melissa A. Schoenlein;Johnny Campos;Kevin J. Lande;Laurent Lessard;Karen B. Schloss,"Psychology and Wisconsin Institute for Discovery, University of Wisconsin-Madison, USA;Cognitive Science, University of California, Merced, USA;Philosophy, Centre for Vision Research, York University, USA;Mechanical and Industrial Engineering, Northeastern University, USA;Psychology, Wisconsin Institute for Discovery, University of Wisconsin-Madison, USA",10.1109/tvcg.2017.2743978;10.1109/tvcg.2016.2598918;10.1109/visual.2002.1183788;10.1109/tvcg.2021.3114780;10.1109/tvcg.2016.2599106;10.1109/tvcg.2019.2934536;10.1109/tvcg.2018.2865147;10.1109/tvcg.2020.3030434;10.1109/tvcg.2015.2467471;10.1109/tvcg.2019.2934284;10.1109/tvcg.2017.2744359;10.1109/tvcg.2017.2743978,"Visual reasoning,information visualization,colormap data visualizations,visual encoding,color cognition",,7.0,53.0,486.0,,,participants interpreted colormap;mangos associated;merit goodness possible;glacial ice direct;single framework,0.6353;0.1751;0.1550;0.0666;-0.0661,"[np.int64(-1), -1, -1, -1, -1]",24;-1;-1;-1;-1,24,24
InfoVis,2012,Interaction Support for Visual Comparison Inspired by Natural Behavior,10.1109/tvcg.2012.237,http://dx.doi.org/10.1109/TVCG.2012.237,2719.0,2728.0,J,"Visual comparison is an intrinsic part of interactive data exploration and analysis. The literature provides a large body of existing solutions that help users accomplish comparison tasks. These solutions are mostly of visual nature and custom-made for specific data. We ask the question if a more general support is possible by focusing on the interaction aspect of comparison tasks. As an answer to this question, we propose a novel interaction concept that is inspired by real-world behavior of people comparing information printed on paper. In line with real-world interaction, our approach supports users (1) in interactively specifying pieces of graphical information to be compared, (2) in flexibly arranging these pieces on the screen, and (3) in performing the actual comparison of side-by-side and overlapping arrangements of the graphical information. Complementary visual cues and add-ons further assist users in carrying out comparison tasks. Our concept and the integrated interaction techniques are generally applicable and can be coupled with different visualization techniques. We implemented an interactive prototype and conducted a qualitative user study to assess the concept's usefulness in the context of three different visualization techniques. The obtained feedback indicates that our interaction techniques mimic the natural behavior quite well, can be learned quickly, and are easy to apply to visual comparison tasks.",Christian Tominski;Camilla Forsell;Jimmy Johansson 0001,Christian Tominski;Camilla Forsell;Jimmy Johansson,"University of Rostock, Germany;Linköping University, Sweden;Linköping University, Sweden",10.1109/tvcg.2008.109;10.1109/tvcg.2007.70568;10.1109/tvcg.2011.201;10.1109/tvcg.2007.70515;10.1109/tvcg.2007.70623;10.1109/tvcg.2009.151;10.1109/infvis.2002.1173157;10.1109/tvcg.2011.223;10.1109/tvcg.2007.70582;10.1109/tvcg.2008.153;10.1109/tvcg.2008.109,"Interaction techniques, visual comparison, visualization, human-computer interaction, natural interaction",68.0,46.0,51.0,1235.0,,,graphical information compared;qualitative user study;add ons assist;printed paper;propose,0.7270;0.2900;0.1780;0.1388;0.0453,"[np.int64(-1), -1, -1, -1, -1]",188;-1;-1;-1;-1,188,188
InfoVis,2011,Evaluation of Artery Visualizations for Heart Disease Diagnosis,10.1109/tvcg.2011.192,http://dx.doi.org/10.1109/TVCG.2011.192,2479.0,2488.0,J,"Heart disease is the number one killer in the United States, and finding indicators of the disease at an early stage is critical for treatment and prevention. In this paper we evaluate visualization techniques that enable the diagnosis of coronary artery disease. A key physical quantity of medical interest is endothelial shear stress (ESS). Low ESS has been associated with sites of lesion formation and rapid progression of disease in the coronary arteries. Having effective visualizations of a patient's ESS data is vital for the quick and thorough non-invasive evaluation by a cardiologist. We present a task taxonomy for hemodynamics based on a formative user study with domain experts. Based on the results of this study we developed HemoVis, an interactive visualization application for heart disease diagnosis that uses a novel 2D tree diagram representation of coronary artery trees. We present the results of a formal quantitative user study with domain experts that evaluates the effect of 2D versus 3D artery representations and of color maps on identifying regions of low ESS. We show statistically significant results demonstrating that our 2D visualizations are more accurate and efficient than 3D representations, and that a perceptually appropriate color map leads to fewer diagnostic mistakes than a rainbow color map.",Michelle Borkin;Krzysztof Gajos;Amanda Peters Randles;Dimitrios Mitsouras;Simone Melchionna;Frank J. Rybicki;Charles L. Feldman;Hanspeter Pfister,Michelle Borkin;Krzysztof Gajos;Amanda Peters;Dimitrios Mitsouras;Simone Melchionna;Frank Rybicki;Charles Feldman;Hanspeter Pfister,"School of Engineering & Applied Sciences, Harvard University, USA;School of Engineering & Applied Sciences, Harvard University, USA;School of Engineering & Applied Sciences, Harvard University, USA;Applied Imaging Science Laboratory, USA;IPCF-CNR, Consiglio Nazionale delle Ricerche, Italy;Applied Imaging Science Laboratory, USA;Vascular Profiling Laboratory, Brigham and Women's Hospital and Harvard Medical School, USA;School of Engineering & Applied Sciences, Harvard University, USA",10.1109/tvcg.2009.169;10.1109/visual.2002.1183788;10.1109/visual.2002.1183754;10.1109/visual.2001.964510;10.1109/visual.2004.104;10.1109/tvcg.2006.172;10.1109/infvis.2005.1532136;10.1109/tvcg.2009.126;10.1109/visual.2001.964538;10.1109/tvcg.2009.126;10.1109/visual.1992.235201;10.1109/visual.1996.568118;10.1109/visual.2000.885731;10.1109/tvcg.2007.70550;10.1109/tvcg.2007.70596;10.1109/tvcg.2009.169,"Quantitative evaluation, qualitative evaluation, biomedical and medical visualization",192.0,124.0,52.0,2888.0,,,3d artery representations;user study;shear stress;rapid progression disease;mistakes rainbow,0.5945;0.2594;0.2162;0.1385;0.1040,"[np.int64(-1), -1, -1, -1, -1]",133;-1;-1;-1;-1,133,133
InfoVis,1996,Towards rich information landscapes for visualising structured Web spaces,10.1109/infvis.1996.559218,http://dx.doi.org/10.1109/INFVIS.1996.559218,62.0,,M,"The Harmony browser for the Hyper-G Web server utilises Hyper-G's rich data model to provide a number of tightly-coupled, two- and three-dimensional visualisation and navigational facilities. In particular the Harmony Information Landscape visualises the hierarchical structure of Hyper-G spaces upon a plane in three-dimensional space. The Harmony Information Landscape has now been extended to display a combined structure and link map by selectively superimposing hyperlink relationships in the vertical dimension above and below the hierarchy map. In addition, documents returned by search queries may be selectively ""plotted"" in the landscape, indicating their whereabouts in a broader context, and several sets of 3D icons are available for representing the various document types.",Keith Andrews;Michael Pichler;Peter Wolf,K. Andrews;M. Pichler;P. Wolf,"Institute for Information Processing and Computer Supported New Media, Graz University of Technology, Graz, Austria;Institute for Information Processing and Computer Supported New Media, Graz University of Technology, Graz, Austria;Institute for Information Processing and Computer Supported New Media, Graz University of Technology, Graz, Austria",0.1109/infvis.1995.528692,,32.0,6.0,6.0,102.0,,,harmony information landscape;sets 3d icons;superimposing hyperlink;web server utilises;selectively plotted,0.6017;0.2642;0.2466;0.1735;0.0681,"[np.int64(-1), -1, -1, -1, -1]",11;-1;-1;-1;-1,11,11
InfoVis,2003,Edgelens: an interactive method for managing edge congestion in graphs,10.1109/infvis.2003.1249008,http://dx.doi.org/10.1109/INFVIS.2003.1249008,51.0,58.0,C,"An increasing number of tasks require people to explore, navigate and search extremely complex data sets visualized as graphs. Examples include electrical and telecommunication networks, Web structures, and airline routes. The problem is that graphs of these real world data sets have many interconnected nodes, ultimately leading to edge congestion: the density of edges is so great that they obscure nodes, individual edges, and even the visual information beneath the graph. To address this problem we developed an interactive technique called EdgeLens. An EdgeLens interactively curves graph edges away for a person's focus attention without changing the node positions. This opens up sufficient space to disambiguate node and edge relationships and to see underlying information while still preserving node layout. Initially two methods of creating this interaction were developed and compared in a user study. The results of this study were used in the selection of a basic approach and the subsequent development of the EdgeLens. We then improved the EdgeLens through use of transparency and colour and by allowing multiple lenses to appear on the graph.",Nelson Wong;Sheelagh Carpendale;Saul Greenberg,N. Wong;S. Carpendale;S. Greenberg,"Department of Computer Science, University of Calgary, Canada;Department of Computer Science, University of Calgary, Canada;Department of Computer Science, University of Calgary, Canada",10.1109/infvis.1997.636786;10.1109/infvis.1996.559214," Navigation, graph layout, distortion lens, information visualization, edge congestion, interactive visualization",205.0,56.0,22.0,955.0,,,visualized graphs;edgelens use transparency;navigate search extremely;subsequent development;individual,0.6426;0.2891;0.2781;0.0900;-0.0046,"[np.int64(-1), -1, -1, -1, -1]",165;-1;-1;-1;-1,165,165
InfoVis,2010,Untangling Euler Diagrams,10.1109/tvcg.2010.210,http://dx.doi.org/10.1109/TVCG.2010.210,1090.0,1099.0,J,"In many common data analysis scenarios the data elements are logically grouped into sets. Venn and Euler style diagrams are a common visual representation of such set membership where the data elements are represented by labels or glyphs and sets are indicated by boundaries surrounding their members. Generating such diagrams automatically such that set regions do not intersect unless the corresponding sets have a non-empty intersection is a difficult problem. Further, it may be impossible in some cases if regions are required to be continuous and convex. Several approaches exist to draw such set regions using more complex shapes, however, the resulting diagrams can be difficult to interpret. In this paper we present two novel approaches for simplifying a complex collection of intersecting sets into a strict hierarchy that can be more easily automatically arranged and drawn (Figure 1). In the first approach, we use compact rectangular shapes for drawing each set, attempting to improve the readability of the set intersections. In the second approach, we avoid drawing intersecting set regions by duplicating elements belonging to multiple sets. We compared both of our techniques to the traditional non-convex region technique using five readability tasks. Our results show that the compact rectangular shapes technique was often preferred by experimental subjects even though the use of duplications dramatically improves the accuracy and performance time for most of our tasks. In addition to general set representation our techniques are also applicable to visualization of networks with intersecting clusters of nodes.",Nathalie Henry Riche;Tim Dwyer,Nathalie Henry Riche;Tim Dwyer,"Microsoft Research Limited, USA;Microsoft Corporation, USA",10.1109/tvcg.2008.144;10.1109/tvcg.2007.70582;10.1109/infvis.2005.1532126;10.1109/tvcg.2008.141;10.1109/tvcg.2009.122;10.1109/tvcg.2006.156;10.1109/tvcg.2006.120;10.1109/tvcg.2008.130;10.1109/tvcg.2006.166;10.1109/visual.1993.398863;10.1109/tvcg.2008.153;10.1109/tvcg.2008.144,"Information Visualization, Euler diagrams, Set Visualization, Graph Visualization",182.0,106.0,33.0,1414.0,,,readability set intersections;generating diagrams automatically;clusters nodes;compared techniques traditional;required continuous convex,0.6017;0.4569;0.2949;0.1548;-0.0412,"[np.int64(-1), -1, -1, -1, -1]",314;-1;-1;-1;-1,314,314
InfoVis,2012,Sketchy Rendering for Information Visualization,10.1109/tvcg.2012.262,http://dx.doi.org/10.1109/TVCG.2012.262,2749.0,2758.0,J,"We present and evaluate a framework for constructing sketchy style information visualizations that mimic data graphics drawn by hand. We provide an alternative renderer for the Processing graphics environment that redefines core drawing primitives including line, polygon and ellipse rendering. These primitives allow higher-level graphical features such as bar charts, line charts, treemaps and node-link diagrams to be drawn in a sketchy style with a specified degree of sketchiness. The framework is designed to be easily integrated into existing visualization implementations with minimal programming modification or design effort. We show examples of use for statistical graphics, conveying spatial imprecision and for enhancing aesthetic and narrative qualities of visualization. We evaluate user perception of sketchiness of areal features through a series of stimulus-response tests in order to assess users' ability to place sketchiness on a ratio scale, and to estimate area. Results suggest relative area judgment is compromised by sketchy rendering and that its influence is dependent on the shape being rendered. They show that degree of sketchiness may be judged on an ordinal scale but that its judgement varies strongly between individuals. We evaluate higher-level impacts of sketchiness through user testing of scenarios that encourage user engagement with data visualization and willingness to critique visualization design. Results suggest that where a visualization is clearly sketchy, engagement may be increased and that attitudes to participating in visualization annotation are more positive. The results of our work have implications for effective information visualization design that go beyond the traditional role of sketching as a tool for prototyping or its use for an indication of general uncertainty.",Jo Wood;Petra Isenberg;Tobias Isenberg 0001;Jason Dykes;Nadia Boukhelifa;Aidan Slingsby,Jo Wood;Petra Isenberg;Tobias Isenberg;Jason Dykes;Nadia Boukhelifa;Aidan Slingsby,"GiCentre, City University of London, UK;INRIA, Paris, France;University of Groningen, Netherlands;GiCentre, City University of London, UK;INRIA, Paris, France;GiCentre, City University of London, UK",10.1109/tvcg.2010.186;10.1109/tvcg.2011.175;10.1109/tvcg.2012.220;10.1109/tvcg.2011.251;10.1109/tvcg.2011.209;10.1109/tvcg.2011.255;10.1109/tvcg.2010.186,"NPR, non-photorealistic rendering, sketch, hand-drawn, uncertainty, visualization",101.0,58.0,47.0,1698.0,,,information visualizations;graphics environment redefines;judgement varies strongly;including line polygon;sketchy engagement,0.7036;0.1944;0.1750;0.1295;0.0762,"[np.int64(-1), -1, -1, -1, -1]",207;-1;-1;-1;-1,207,207
InfoVis,2008,Stacked Graphs - Geometry & Aesthetics,10.1109/tvcg.2008.166,http://dx.doi.org/10.1109/TVCG.2008.166,1245.0,1252.0,J,"In February 2008, the New York Times published an unusual chart of box office revenues for 7500 movies over 21 years. The chart was based on a similar visualization, developed by the first author, that displayed trends in music listening. This paper describes the design decisions and algorithms behind these graphics, and discusses the reaction on the Web. We suggest that this type of complex layered graph is effective for displaying large data sets to a mass audience. We provide a mathematical analysis of how this layered graph relates to traditional stacked graphs and to techniques such as ThemeRiver, showing how each method is optimizing a different ldquoenergy functionrdquo. Finally, we discuss techniques for coloring and ordering the layers of such graphs. Throughout the paper, we emphasize the interplay between considerations of aesthetics and legibility.",Lee Byron;Martin Wattenberg,Lee Byron;Martin Wattenberg,The New York Times;Visual Communication Laboratory at IBM,10.1109/tvcg.2006.163;10.1109/infvis.2005.1532122;10.1109/tvcg.2007.70577;10.1109/infvis.2000.885098;10.1109/tvcg.2006.163,"Streamgraph, ThemeRiver, listening history, lastfm, aesthetics, communication-minded visualization, time series",557.0,257.0,19.0,3104.0,HM,,graphs techniques themeriver;revenues;type complex layered;listening paper describes;2008 new york,0.6172;0.2489;0.1845;0.1652;0.1416,"[np.int64(-1), -1, -1, -1, -1]",249;-1;-1;-1;-1,249,249
Vis,2002,Direct surface extraction from 3D freehand ultrasound images,10.1109/visual.2002.1183755,http://dx.doi.org/10.1109/VISUAL.2002.1183755,45.0,52.0,C,"This paper presents a new technique for the extraction of surfaces from 3D ultrasound data. Surface extraction from ultrasound data is challenging for a number of reasons including noise and artifacts in the images and nonuniform data sampling. A method is proposed to fit an approximating radial basis function to the group of data samples. An explicit surface is then obtained by iso-surfacing the function. In most previous 3D ultrasound research, a pre-processing step is taken to interpolate the data into a regular voxel array and a corresponding loss of resolution. We are the first to represent the set of semi-structured ultrasound pixel data as a single function. From this we are able to extract surfaces without first reconstructing the irregularly spaced pixels into a regular 3D voxel array.",Youwei Zhang;Robert Rohling;Dinesh K. Pai,Youwei Zhang;R. Rohling;D.K. Pai,"Department of Computer Science, University of British Columbia, Vancouver, BC, Canada;Department of Electrical and Computer Engineering, University of British Columbia, Vancouver, BC, Canada;Department of Computer Science, University of British Columbia, Vancouver, BC, Canada",10.1109/visual.1991.175782;10.1109/visual.1994.346295;10.1109/visual.1991.175782,"Radial Basis Functions, Ultrasound, Isosurface, 3D Freehand Ultrasound, Direct Surface Extraction, Unstructured data",49.0,5.0,27.0,292.0,,,surfaces 3d ultrasound;irregularly spaced pixels;function able extract;represent;number reasons,0.7567;0.2330;0.1726;0.0380;-0.0031,"[np.int64(-1), -1, -1, -1, -1]",133;-1;-1;-1;-1,133,133
VAST,2020,PassVizor: Toward Better Understanding of the Dynamics of Soccer Passes,10.1109/tvcg.2020.3030359,http://dx.doi.org/10.1109/TVCG.2020.3030359,1322.0,1331.0,J,"In soccer, passing is the most frequent interaction between players and plays a significant role in creating scoring chances. Experts are interested in analyzing players' passing behavior to learn passing tactics, i.e., how players build up an attack with passing. Various approaches have been proposed to facilitate the analysis of passing tactics. However, the dynamic changes of a team's employed tactics over a match have not been comprehensively investigated. To address the problem, we closely collaborate with domain experts and characterize requirements to analyze the dynamic changes of a team's passing tactics. To characterize the passing tactic employed for each attack, we propose a topic-based approach that provides a high-level abstraction of complex passing behaviors. Based on the model, we propose a glyph-based design to reveal the multi-variate information of passing tactics within different phases of attacks, including player identity, spatial context, and formation. We further design and develop PassVizor, a visual analytics system, to support the comprehensive analysis of passing dynamics. With the system, users can detect the changing patterns of passing tactics and examine the detailed passing process for evaluating passing tactics. We invite experts to conduct analysis with PassVizor and demonstrate the usability of the system through an expert interview.",Xiao Xie;Jiachen Wang;Hongye Liang;Dazhen Deng;Shoubin Cheng;Hui Zhang 0051;Wei Chen 0001;Yingcai Wu,Xiao Xie;Jiachen Wang;Hongye Liang;Dazhen Deng;Shoubin Cheng;Hui Zhang;Wei Chen;Yingcai Wu,"State Key Lab of CAD&CG, Zhejiang University;State Key Lab of CAD&CG, Zhejiang University;State Key Lab of CAD&CG, Zhejiang University;State Key Lab of CAD&CG, Zhejiang University;Department of Sport Science, Zhejiang University;Department of Sport Science, Zhejiang University;State Key Lab of CAD&CG, Zhejiang University;State Key Lab of CAD&CG, Zhejiang University",10.1109/vast.2014.7042477;10.1109/tvcg.2013.192;10.1109/tvcg.2019.2934243;10.1109/tvcg.2014.2346445;10.1109/tvcg.2017.2745181;10.1109/tvcg.2019.2934630;10.1109/vast50239.2020.00009;10.1109/tvcg.2017.2744218;10.1109/tvcg.2018.2865041;10.1109/tvcg.2020.3030392;10.1109/vast.2014.7042477,"Soccer Analysis,Passing Analysis",34.0,41.0,44.0,1262.0,,,analyzing players passing;visual analytics support;changing patterns;information;propose glyph,0.6269;0.3600;0.2901;0.2736;0.2279,"[np.int64(-1), -1, -1, -1, -1]",75;-1;-1;-1;-1,75,75
Vis,2000,Constructing material interfaces from data sets with volume-fraction information,10.1109/visual.2000.885717,http://dx.doi.org/10.1109/VISUAL.2000.885717,367.0,372.0,C,"We present a new algorithm for material boundary interface reconstruction from data sets containing volume fractions. We transform the reconstruction problem to a problem that analyzes the dual data set, where each vertex in the dual mesh has an associated barycentric coordinate tuple that represents the fraction of each material present. After constructing the dual tetrahedral mesh from the original mesh, we construct material boundaries by mapping a tetrahedron into barycentric space and calculating the intersections with Voronoi cells in barycentric space. These intersections are mapped back to the original physical space and triangulated to form the boundary surface approximation. This algorithm can be applied to any grid structure and can treat any number of materials per element/vertex.",Kathleen S. Bonnell;Kenneth I. Joy;Bernd Hamann;Daniel Schikore;Mark A. Duchaineau,K.S. Bonnell;D.R. Schikore;K.I. Joy;M. Duchaineau;B. Hamann,"Department of Computer Science, University of California, Davis, CA, USA;Computational Engineering International, NC, USA;Department of Computer Science, University of California, Davis, CA, USA;Department of Computer Science, University of California, Davis, CA, USA;Center for Advanced Scientific Computing, Lawrence Livemore National Laboratory, Livermore, CA, USA",10.1109/visual.1991.175782;10.1109/visual.1997.663887;10.1109/visual.1997.663869;10.1109/visual.1991.175782,"Eulerian flow, material boundary surface, barycentric coordinates, volume fraction, Voronoi diagram",43.0,9.0,11.0,75.0,,,boundary interface reconstruction;voronoi cells;dual tetrahedral;materials element;fractions,0.5517;0.3992;0.3204;0.2054;0.0598,"[np.int64(-1), -1, -1, -1, -1]",247;-1;-1;-1;-1,247,247
Vis,2004,Context-Adaptive Mobile Visualization and Information Management,10.1109/visual.2004.19,http://dx.doi.org/10.1109/VISUAL.2004.19,8.0,8.0,M,"This poster abstract presents a scalable information visualization system for mobile devices and desktop systems. It is designed to support the operation and the workflow of wastewater systems. The regarded information data includes general information about buildings and units, process data, occupational safety regulations, work directions and first aid instructions in case of an accident. Technically, the presented framework combines visualization with agent technology in order to automatically scale various visualization types to fit on different platforms like PDAs (Personal Digital Assistants) or Tablet PCs. The implementation is based on but not limited to SQL, JSP, HTML and VRML.",Jochen Ehret;Achim Ebert;Lars Schuchardt;Heidrun Steinmetz;Hans Hagen,J. Ehret;A. Ebert;L. Schuchardt;H. Steinmetz;H. Hagen,"Intelligent Visualization and Simulation, German Research Center for Artificial Intelligence, Kaiserslautern, Germany;Intelligent Visualization and Simulation, German Research Center for Artificial Intelligence, Kaiserslautern, Germany;Institute of Environmental Engineering, Technical University of Kaiserslautern, Germany;Center for Innovative WasteWater Technology (tectraa), Technical University of Kaiserslautern, Germany;Intelligent Visualization and Simulation, German Research Center for Artificial Intelligence, Kaiserslautern, Germany",,,11.0,2.0,4.0,172.0,,,visualization agent technology;wastewater systems regarded;sql jsp html;tablet pcs;case accident technically,0.6038;0.5093;0.2256;0.1957;-0.0120,"[np.int64(-1), np.int64(-1), -1, -1, -1]",191;71;-1;-1;-1,71;191,191
VAST,2009,A visual analytics system for radio frequency fingerprinting-based localization,10.1109/vast.2009.5332596,http://dx.doi.org/10.1109/VAST.2009.5332596,35.0,42.0,C,"Radio frequency (RF) fingerprinting-based techniques for localization are a promising approach for ubiquitous positioning systems, particularly indoors. By finding unique fingerprints of RF signals received at different locations within a predefined area beforehand, whenever a similar fingerprint is subsequently seen again, the localization system will be able to infer a user's current location. However, developers of these systems face the problem of finding reliable RF fingerprints that are unique enough and adequately stable over time. We present a visual analytics system that enables developers of these localization systems to visually gain insight on whether their collected datasets and chosen fingerprint features have the necessary properties to enable a reliable RF fingerprinting-based localization system. The system was evaluated by testing and debugging an existing localization system.",Yi Han 0005;Erich P. Stuntebeck;John T. Stasko;Gregory D. Abowd,Yi Han;Erich P. Stuntebeck;John T. Stasko;Gregory D. Abowd,"School of Interactive Computing & GVU Center, Georgia Institute of Technology, USA;School of Interactive Computing & GVU Center, Georgia Institute of Technology, USA;School of Interactive Computing & GVU Center, Georgia Institute of Technology, USA;School of Interactive Computing & GVU Center, Georgia Institute of Technology, USA",10.1109/infvis.1997.636793;10.1109/infvis.1997.636793,,18.0,6.0,15.0,412.0,,,fingerprinting based localization;visual analytics enables;radio;testing debugging;adequately stable time,0.6238;0.2818;0.2446;0.1058;-0.0063,"[np.int64(-1), -1, -1, -1, -1]",234;-1;-1;-1;-1,234,234
VAST,2010,iVisClassifier: An interactive visual analytics system for classification based on supervised dimension reduction,10.1109/vast.2010.5652443,http://dx.doi.org/10.1109/VAST.2010.5652443,27.0,34.0,C,"We present an interactive visual analytics system for classification, iVisClassifier, based on a supervised dimension reduction method, linear discriminant analysis (LDA). Given high-dimensional data and associated cluster labels, LDA gives their reduced dimensional representation, which provides a good overview about the cluster structure. Instead of a single two- or three-dimensional scatter plot, iVisClassifier fully interacts with all the reduced dimensions obtained by LDA through parallel coordinates and a scatter plot. Furthermore, it significantly improves the interactivity and interpretability of LDA. LDA enables users to understand each of the reduced dimensions and how they influence the data by reconstructing the basis vector into the original data domain. By using heat maps, iVisClassifier gives an overview about the cluster relationship in terms of pairwise distances between cluster centroids both in the original space and in the reduced dimensional space. Equipped with these functionalities, iVisClassifier supports users' classification tasks in an efficient way. Using several facial image data, we show how the above analysis is performed.",Jaegul Choo;Hanseung Lee;Jaeyeon Kihm;Haesun Park,Jaegul Choo;Hanseung Lee;Jaeyeon Kihm;Haesun Park,"School of Computational Science and Engineering, Georgia Institute of Technology, USA;Science and Engineering and Computer Engineering, Georgia Institute of Technology, USA;School of Interactive Computing, Georgia Institute of Technology, USA;School of Computational Science and Engineering, Georgia Institute of Technology, USA",10.1109/vast.2009.5332629;10.1109/infvis.2003.1249015;10.1109/infvis.2004.60;10.1109/tvcg.2009.153;10.1109/vast.2009.5332629,,164.0,91.0,29.0,1727.0,TT,,visual analytics classification;method linear discriminant;lda lda enables;using heat;original space reduced,0.5754;0.3958;0.1576;0.1467;0.1348,"[np.int64(-1), -1, -1, -1, -1]",263;-1;-1;-1;-1,263,263
Vis,2002,Interactive rendering of large volume data sets,10.1109/visual.2002.1183757,http://dx.doi.org/10.1109/VISUAL.2002.1183757,53.0,60.0,C,"We present a new algorithm for rendering very large volume data sets at interactive frame rates on standard PC hardware. The algorithm accepts scalar data sampled on a regular grid as input. The input data is converted into a compressed hierarchical wavelet representation in a preprocessing step. During rendering, the wavelet representation is decompressed on-the-fly and rendered using hardware texture mapping. The level of detail used for rendering is adapted to the local frequency spectrum of the data and its position relative to the viewer. Using a prototype implementation of the algorithm we were able to perform an interactive walkthrough of large data sets such as the visible human on a single off-the-shelf PC.",Stefan Guthe;Michael Wand 0001;Julius Gonser;Wolfgang Straßer,S. Guthe;M. Wand;J. Gonser;W. Strasser,"WSI/GRIS, University of Tübingen, Germany and WSI/GRIS, University of Tiibingen;WSI/GRIS, University of Tübingen, Germany and WSI/GRIS, University of Tiibingen;WSI/GRIS, University of Tübingen, Germany and WSI/GRIS, University of Tiibingen and Eberhard Karls Universitat Tubingen, Tubingen, Baden-WÃ¼rttemberg, DE;WSI/GRIS, Tubingen Univ., Germany",10.1109/visual.2001.964531;10.1109/visual.1999.809908;10.1109/visual.1999.809889;10.1109/visual.1993.398845;10.1109/visual.2001.964519;10.1109/visual.2001.964531,"Compression Algorithms, Level of Detail Algorithms, Scientific Visualization, Volume Rendering, Wavelets",338.0,81.0,36.0,601.0,,,rendering wavelet representation;interactive frame rates;walkthrough large data;pc hardware;human single shelf,0.6178;0.4300;0.3484;0.2849;0.0469,"[np.int64(-1), -1, -1, -1, -1]",-1;-1;-1;-1;-1,,-1
Vis,2009,Depth-Dependent Halos: Illustrative Rendering of Dense Line Data,10.1109/tvcg.2009.138,http://dx.doi.org/10.1109/TVCG.2009.138,1299.0,1306.0,J,"We present a technique for the illustrative rendering of 3D line data at interactive frame rates. We create depth-dependent halos around lines to emphasize tight line bundles while less structured lines are de-emphasized. Moreover, the depth-dependent halos combined with depth cueing via line width attenuation increase depth perception, extending techniques from sparse line rendering to the illustrative visualization of dense line data. We demonstrate how the technique can be used, in particular, for illustrating DTI fiber tracts but also show examples from gas and fluid flow simulations and mathematics as well as describe how the technique extends to point data. We report on an informal evaluation of the illustrative DTI fiber tract visualizations with domain experts in neurosurgery and tractography who commented positively about the results and suggested a number of directions for future work.",Maarten H. Everts;Henk Bekker;Jos B. T. M. Roerdink;Tobias Isenberg 0001,Maarten H. Everts;Henk Bekker;Jos B.T.M. Roerdink;Tobias Isenberg,"University of Groningam, Netherlands;University of Groningam, Netherlands;University of Groningam, Netherlands;University of Groningam, Netherlands",10.1109/visual.2000.885694;10.1109/tvcg.2007.70532;10.1109/tvcg.2006.172;10.1109/visual.2000.885696;10.1109/visual.2005.1532778;10.1109/tvcg.2006.115;10.1109/visual.2005.1532859;10.1109/tvcg.2006.197;10.1109/visual.2005.1532858;10.1109/tvcg.2007.70555;10.1109/visual.1996.567777;10.1109/visual.2004.48;10.1109/visual.2000.885694,"Illustrative rendering and visualization, NPR, dense line data, DTI, black-and-white rendering, GPU technique",180.0,86.0,44.0,1131.0,TT;BP,,line rendering illustrative;dti fiber tract;halos combined depth;examples gas fluid;number,0.6279;0.4309;0.3251;0.1409;-0.0003,"[np.int64(-1), -1, -1, -1, -1]",57;-1;-1;-1;-1,57,57
Vis,2024,Towards Dataset-Scale and Feature-Oriented Evaluation of Text Summarization in Large Language Model Prompts,10.1109/tvcg.2024.3456398,http://dx.doi.org/10.1109/TVCG.2024.3456398,481.0,491.0,J,"Recent advancements in Large Language Models (LLMs) and Prompt Engineering have made chatbot customization more accessible, significantly reducing barriers to tasks that previously required programming skills. However, prompt evaluation, especially at the dataset scale, remains complex due to the need to assess prompts across thousands of test instances within a dataset. Our study, based on a comprehensive literature review and pilot study, summarized five critical challenges in prompt evaluation. In response, we introduce a feature-oriented workflow for systematic prompt evaluation. In the context of text summarization, our workflow advocates evaluation with summary characteristics (feature metrics) such as complexity, formality, or naturalness, instead of using traditional quality metrics like ROUGE. This design choice enables a more user-friendly evaluation of prompts, as it guides users in sorting through the ambiguity inherent in natural language. To support this workflow, we introduce Awesum, a visual analytics system that facilitates identifying optimal prompt refinements for text summarization through interactive visualizations, featuring a novel Prompt Comparator design that employs a BubbleSet-inspired design enhanced by dimensionality reduction techniques. We evaluate the effectiveness and general applicability of the system with practitioners from various domains and found that (1) our design helps overcome the learning curve for non-technical people to conduct a systematic evaluation of summarization prompts, and (2) our feature-oriented workflow has the potential to generalize to other NLG and image-generation tasks. For future works, we advocate moving towards feature-oriented evaluation of LLM prompts and discuss unsolved challenges in terms of human-agent interaction.",Sam Yu-Te Lee;Aryaman Bahukhandi;Dongyu Liu;Kwan-Liu Ma,Sam Yu-Te Lee;Aryaman Bahukhandi;Dongyu Liu;Kwan-Liu Ma,"University of California, USA;University of California, USA;University of California, USA;University of California, USA",10.1109/tvcg.2017.2743858;10.1109/tvcg.2017.2744938;10.1109/tvcg.2017.2744358;10.1109/tvcg.2015.2467112;10.1109/tvcg.2017.2744158;10.1109/tvcg.2023.3326585;10.1109/tvcg.2017.2744878,"Visual analytics,prompt engineering,,,text summarization,human-computer interaction,dimensionality reduction",,1.0,65.0,386.0,,,prompt engineering chatbot;evaluation summarization;nlg image;dataset scale remains;advocate moving,0.5657;0.4179;0.2673;0.0883;0.0219,"[np.int64(-1), -1, -1, -1, -1]",231;-1;-1;-1;-1,231,231
Vis,1998,Visualization for multiparameter aircraft designs,10.1109/visual.1998.745351,http://dx.doi.org/10.1109/VISUAL.1998.745351,491.0,494.0,C,"We describe an aircraft design problem in high dimensional space, with D typically being 10 to 30. In some respects this is a classic optimization problem, where the goal is to find the point that minimizes an objective function while satisfying a set of constraints. However, evaluating an individual point is expensive, and the high dimensionality makes many approaches to solving the problem infeasible. The difficulty of the problem means that aircraft designers would benefit from any insights that can be provided. We discuss how simple visualizations have already proved beneficial, and then describe how visualization might be of further help in the future.",Clifford A. Shaffer;Duane L. Knill;Layne T. Watson,C.A. Shaffer;D.L. Knill;L.T. Watson,"Computer Science, Virginia Technology, Blacksburg, VA, USA;Aeronautics and Astronautics, University of Washington, Seattle, WA, USA;Computer Science and Mathematics, Virginia Polytechnic Institute and State University, Blacksburg, VA, USA",10.1109/visual.1997.663866;10.1109/visual.1997.663868;10.1109/visual.1990.146402,,14.0,6.0,13.0,75.0,,,aircraft design;high dimensionality makes;point minimizes objective;infeasible;typically 10,0.6983;0.3459;0.3161;0.0598;0.0151,"[np.int64(-1), -1, -1, -1, -1]",13;-1;-1;-1;-1,13,13
VAST,2016,SocialBrands: Visual analysis of public perceptions of brands on social media,10.1109/vast.2016.7883513,http://dx.doi.org/10.1109/VAST.2016.7883513,71.0,80.0,C,"Public perceptions of a brand is critical to its performance. While social media has demonstrated a huge potential to shape public perceptions of brands, existing tools are not intuitive and explanatory for domain users to use as they fail to provide a comprehensive analysis framework for perceptions of brands. In this paper, we present SocialBrands, a novel visual analysis tool for brand managers to understand public perceptions of brands on social media. Social-Brands leverages brand personality framework in marketing literature and social computing approaches to compute the personality of brands from three driving factors (user imagery, employee imagery, and official announcement) on social media, and construct an evidence network explaining the association between brand personality and driving factors. These computational results are then integrated with new interactive visualizations to help brand managers understand personality traits and their driving factors. We demonstrate the usefulness and effectiveness of SocialBrands through a series of user studies with brand managers in an enterprise context. Design lessons are also derived from our studies.",Xiaotong Liu;Anbang Xu;Liang Gou;Haibin Liu;Rama Akkiraju;Han-Wei Shen,Xiaotong Liu;Anbang Xu;Liang Gou;Haibin Liu;Rama Akkiraju;Han-Wei Shen,Visa Research;IBM Research;Ohio State University;IBM Research;IBM Research;Visa Research,10.1109/tvcg.2014.2346922;10.1109/vast.2014.7042496;10.1109/tvcg.2013.227;10.1109/tvcg.2012.291;10.1109/tvcg.2010.129;10.1109/tvcg.2013.221;10.1109/infvis.2000.885091;10.1109/tvcg.2011.183;10.1109/tvcg.2014.2346922,,22.0,11.0,42.0,1471.0,,,socialbrands novel visual;understand personality traits;domain users use;computational results integrated;use fail provide,0.6660;0.3245;0.2148;0.0947;-0.0753,"[np.int64(-1), -1, -1, -1, -1]",313;-1;-1;-1;-1,313,313
SciVis,2014,Characterizing Molecular Interactions in Chemical Systems,10.1109/tvcg.2014.2346403,http://dx.doi.org/10.1109/TVCG.2014.2346403,2476.0,2485.0,J,"Interactions between atoms have a major influence on the chemical properties of molecular systems. While covalent interactions impose the structural integrity of molecules, noncovalent interactions govern more subtle phenomena such as protein folding, bonding or self assembly. The understanding of these types of interactions is necessary for the interpretation of many biological processes and chemical design tasks. While traditionally the electron density is analyzed to interpret the quantum chemistry of a molecular system, noncovalent interactions are characterized by low electron densities and only slight variations of them - challenging their extraction and characterization. Recently, the signed electron density and the reduced gradient, two scalar fields derived from the electron density, have drawn much attention in quantum chemistry since they enable a qualitative visualization of these interactions even in complex molecular systems and experimental measurements. In this work, we present the first combinatorial algorithm for the automated extraction and characterization of covalent and noncovalent interactions in molecular systems. The proposed algorithm is based on a joint topological analysis of the signed electron density and the reduced gradient. Combining the connectivity information of the critical points of these two scalar fields enables to visualize, enumerate, classify and investigate molecular interactions in a robust manner. Experiments on a variety of molecular systems, from simple dimers to proteins or DNA, demonstrate the ability of our technique to robustly extract these interactions and to reveal their structural relations to the atoms and bonds forming the molecules. For simple systems, our analysis corroborates the observations made by the chemists while it provides new visual and quantitative insights on chemical interactions for larger molecular systems.",David Günther;Roberto Álvarez Boto;Julia Contreras-García;Jean-Philip Piquemal;Julien Tierny,David Günther;Roberto A. Boto;Juila Contreras-Garcia;Jean-Philip Piquemal;Julien Tierny,"Institut-Mines-Télécom, Télécom Paris'Iech, CNRS LTCI, Paris, France;Sorbonne Universités, UMR 7616, Laboratoire de Chimie Théorique, Paris, France;Sorbonne Universités, UMR 7616, LCT, Paris, France;Sorbonne Universités, UMR 7616, LCT, Paris, France;CNRS LIP6, UPMC, Télécom Paris'Iech, Paris, France",10.1109/tvcg.2009.163;10.1109/visual.2004.96;10.1109/visual.2003.1250376;10.1109/tvcg.2008.110;10.1109/tvcg.2009.157;10.1109/tvcg.2011.259;10.1109/tvcg.2007.70578;10.1109/tvcg.2013.158;10.1109/tvcg.2009.163,"Molecular Chemistry, Topological Data Analysis, Morse-Smale Complex, Join Tree",93.0,64.0,58.0,772.0,,,interactions reveal structural;signed electron density;topological analysis;combinatorial algorithm automated;points scalar fields,0.5968;0.3150;0.3091;0.2063;0.1333,"[np.int64(-1), -1, -1, -1, -1]",21;-1;-1;-1;-1,21,21
SciVis,2014,A Robust Parity Test for Extracting Parallel Vectors in 3D,10.1109/tvcg.2014.2346412,http://dx.doi.org/10.1109/TVCG.2014.2346412,2526.0,2534.0,J,"Parallel vectors (PV), the loci where two vector fields are parallel, are commonly used to represent curvilinear features in 3D for data visualization. Methods for extracting PV usually operate on a 3D grid and start with detecting seed points on a cell face. We propose, to the best of our knowledge, the first provably correct test that determines the parity of the number of PV points on a cell face. The test only needs to sample along the face boundary and works for any choice of the two vector fields. A discretization of the test is described, validated, and compared with existing tests that are also based on boundary sampling. The test can guide PV-extraction algorithms to ensure closed curves wherever the input fields are continuous, which we exemplify in extracting ridges and valleys of scalar functions.",Tao Ju;Minxin Cheng;Xu Wang;Ye Duan,Tao Ju;Minxin Cheng;Xu Wang;Ye Duan,Washington University in St. Louis;University of Missouri at Columbia;University of Missouri at Columbia;University of Missouri at Columbia,10.1109/visual.2002.1183786;10.1109/visual.2005.1532851;10.1109/visual.1999.809896;10.1109/visual.2002.1183786,"Parallel vectors, feature curve extraction, ridges and valleys, parity test",7.0,6.0,17.0,385.0,HM,,extracting ridges valleys;vector fields parallel;operate 3d grid;test determines parity;commonly used represent,0.5567;0.4629;0.3792;0.2629;0.0494,"[np.int64(-1), -1, -1, -1, -1]",87;-1;-1;-1;-1,87,87
Vis,2022,On-Tube Attribute Visualization for Multivariate Trajectory Data,10.1109/tvcg.2022.3209400,http://dx.doi.org/10.1109/TVCG.2022.3209400,1288.0,1298.0,J,"Stylized tubes are an established visualization primitive for line data as encountered in many scientific fields, ranging from characteristic lines in flow fields, fiber tracks reconstructed from diffusion tensor imaging, to trajectories of moving objects as they arise from cyber-physical systems in many engineering disciplines. Typical challenges include large data set sizes demanding for efficient rendering techniques as well as a large number of attributes that cannot be mapped simultaneously to the basic visual attributes provided by a tube-based visualization. In this work, we tackle both challenges with a new on-tube visualization approach. We improve recent work on high-quality GPU ray casting of Hermite spline tubes supporting ambient occlusion and extend it by a new layered procedural texturing technique. In the proposed framework, a large number of data set attributes can be mapped simultaneously to a variety of glyphs and plots that are embedded in texture space and organized in layers. Efficient rendering with minimal data transfer is achieved by generating the glyphs procedurally and drawing them in a deferred shading pass. We integrated these techniques in a prototype visualization tool that facilitates flexible mapping of data set attributes to visual tube and glyph attributes. We studied our approach on a variety of example data from different fields and found it to provide a highly adaptable and extensible toolbox to quickly craft tailor-made tube-based trajectory visualizations.",Benjamin Russig;David Groß;Raimund Dachselt;Stefan Gumhold,Benjamin Russig;David Groß;Raimund Dachselt;Stefan Gumhold,"Chair of Computer Graphics and Visualization, TU Dresden, Germany;Chair of Computer Graphics and Visualization, TU Dresden, Germany;Interactive Media Lab, TU Dresden, Germany;Chair of Computer Graphics and Visualization, TU Dresden, Germany",10.1109/tvcg.2016.2598416;10.1109/tvcg.2018.2864811;10.1109/tvcg.2009.138;10.1109/tvcg.2020.3028954;10.1109/tvcg.2006.151;10.1109/tvcg.2007.70532;10.1109/visual.2005.1532859;10.1109/tvcg.2012.265;10.1109/tvcg.2006.172;10.1109/tvcg.2016.2598416,"Visualization,Rendering,Line Data,Trajectories,Multivariate Data",,2.0,47.0,754.0,,,tube based visualization;generating glyphs procedurally;cyber physical;data different fields;casting hermite,0.7110;0.3385;0.1380;0.0854;0.0835,"[np.int64(-1), -1, -1, -1, -1]",252;-1;-1;-1;-1,252,252
Vis,1999,Detecting null alleles with vasarely charts,10.1109/visual.1999.809931,http://dx.doi.org/10.1109/VISUAL.1999.809931,463.0,466.0,C,Microsatellite genotypes can have problems that are difficult to detect with existing tools. One such problem is null alleles. This paper presents a new visualization tool that helps to find and characterize these errors. The paper explains how the tool is used to analyze groups of genotypes and proposes other possible uses.,Carl Manaster;Elizabeth Nanthakumar;Phillip A. Morin,C.J. Manaster;E. Nanthakumar;P.A. Morin,"Axys Pharmaceuticals, USA;Axys Pharmaceuticals, USA;Axys Pharmaceuticals, USA",,,3.0,0.0,20.0,43.0,,,microsatellite genotypes;characterize errors;new visualization;tools problem null;difficult,0.7563;0.2549;0.2244;0.2020;0.0932,"[np.int64(-1), -1, -1, -1, -1]",16;-1;-1;-1;-1,16,16
Vis,2000,Combining local and remote visualization techniques for interactive volume rendering in medical applications,10.1109/visual.2000.885729,http://dx.doi.org/10.1109/VISUAL.2000.885729,449.0,452.0,C,"For a comprehensive understanding of tomographic image data in medicine, interactive and high-quality direct volume rendering is an essential prerequisite. This is provided by visualization using 3D texture mapping which is still limited to high-end graphics hardware. In order to make it available in a clinical environment, we present a system which uniquely combines local desktop computers and remote high-end graphics hardware. In this context, we exploit the standard visualization capabilities to a maximum which are available in the clinical environment. For 3D representations of high resolution and quality we access the remote specialized hardware. Various tools for 2D and 3D visualization are provided which meet the requirements of a medical diagnosis. This is demonstrated with examples from the field of neuroradiology which show the value of our strategy in practice.",Klaus Engel;Thomas Ertl;Peter Hastreiter;Bernd Tomandl;K. Eberhardt,K. Engel;P. Hastreiter;B. Tomandl;K. Eberhardt;T. Ertl,"Division of Neuroradiology, University of Erlangen Nuremberg, Germany;Visualization and Interactive Systems Group, University of Stuttgart, Germany;Neurocenter, University of Erlangen Nuremberg, Germany;Visualization and Interactive Systems Group, University of Stuttgart, Germany;Division of Neuroradiology, University of Erlangen Nuremberg, Germany",10.1109/visual.1996.568134;10.1109/visual.1996.568134,"medical data visualization, volume visualization, distributed systems, PC graphics hardware, remote rendering",112.0,21.0,14.0,245.0,,,3d visualization;image data medicine;texture mapping limited;computers remote high;diagnosis demonstrated,0.5988;0.5094;0.3115;0.2133;0.1533,"[np.int64(-1), np.int64(-1), -1, -1, -1]",110;63;-1;-1;-1,63;110,110
VAST,2011,Jigsaw to save vastopolis,10.1109/vast.2011.6102496,http://dx.doi.org/10.1109/VAST.2011.6102496,325.0,326.0,M,"This article describes our analytic process and experience of using the Jigsaw system in working on the VAST 2011 Mini Challenge 3. We describe how we extracted and worked with entities from the documents, and how Jigsaw's computational analysis capabilities and visualizations scaffolded the investigation. Based on our experiences, we discuss desirable features that would enhance the analytic power of Jigsaw.",Elizabeth Braunstein;Carsten Görg;Zhicheng Liu 0001;John T. Stasko,Elizabeth Braunstein;Carsten Görg;Zhicheng Liu;John Stasko,"Mercyhurst College, USA;University of Colorado Denver, USA;Georgia Tech, USA;Georgia Tech, USA",,,1.0,0.0,3.0,180.0,,,documents jigsaw computational;entities;enhance analytic power;2011 mini;extracted worked,0.6912;0.3238;0.1490;0.1088;0.0974,"[np.int64(-1), -1, -1, -1, -1]",303;-1;-1;-1;-1,303,303
Vis,2023,Visual Analysis of Displacement Processes in Porous Media using Spatio-Temporal Flow Graphs,10.1109/tvcg.2023.3326931,http://dx.doi.org/10.1109/TVCG.2023.3326931,759.0,769.0,J,"We developed a new approach comprised of different visualizations for the comparative spatio-temporal analysis of displacement processes in porous media. We aim to analyze and compare ensemble datasets from experiments to gain insight into the influence of different parameters on fluid flow. To capture the displacement of a defending fluid by an invading fluid, we first condense an input image series to a single time map. From this map, we generate a spatio-temporal flow graph covering the whole process. This graph is further simplified to only reflect topological changes in the movement of the invading fluid. Our interactive tools allow the visual analysis of these processes by visualizing the graph structure and the context of the experimental setup, as well as by providing charts for multiple metrics. We apply our approach to analyze and compare ensemble datasets jointly with domain experts, where we vary either fluid properties or the solid structure of the porous medium. We finally report the generated insights from the domain experts and discuss our contribution's advantages, generality, and limitations.",Alexander Straub;Nikolaos Karadimitriou;Guido Reina;Steffen Frey;Holger Steeb;Thomas Ertl,Alexander Straub;Nikolaos Karadimitriou;Guido Reina;Steffen Frey;Holger Steeb;Thomas Ertl,"University of Stuttgart, Germany;University of Stuttgart, Germany;University of Stuttgart, Germany;University of Groningen, The Netherlands;University of Stuttgart, Germany;University of Stuttgart, Germany",0.1109/tvcg.2010.190;10.1109/tvcg.2015.2468093;10.1109/tvcg.2013.141;10.1109/tvcg.2018.2864901;10.1109/tvcg.2018.2864849;10.1109/tvcg.2010.181;10.1109/tvcg.2014.2346321;10.1109/tvcg.2012.200;10.1109/tvcg.2010.223;10.1109/tvcg.2018.2864506,"Comparative visualization,ensemble,graph,porous media",,0.0,61.0,403.0,,X,flow graph;porous media;capture displacement defending;ensemble datasets jointly;different,0.5111;0.4639;0.2238;0.2215;0.0438,"[np.int64(-1), -1, -1, -1, -1]",277;-1;-1;-1;-1,277,277
VAST,2012,An Affordance-Based Framework for Human Computation and Human-Computer Collaboration,10.1109/tvcg.2012.195,http://dx.doi.org/10.1109/TVCG.2012.195,2859.0,2868.0,J,"Visual Analytics is “the science of analytical reasoning facilitated by visual interactive interfaces” [70]. The goal of this field is to develop tools and methodologies for approaching problems whose size and complexity render them intractable without the close coupling of both human and machine analysis. Researchers have explored this coupling in many venues: VAST, Vis, InfoVis, CHI, KDD, IUI, and more. While there have been myriad promising examples of human-computer collaboration, there exists no common language for comparing systems or describing the benefits afforded by designing for such collaboration. We argue that this area would benefit significantly from consensus about the design attributes that define and distinguish existing techniques. In this work, we have reviewed 1,271 papers from many of the top-ranking conferences in visual analytics, human-computer interaction, and visualization. From these, we have identified 49 papers that are representative of the study of human-computer collaborative problem-solving, and provide a thorough overview of the current state-of-the-art. Our analysis has uncovered key patterns of design hinging on humanand machine-intelligence affordances, and also indicates unexplored avenues in the study of this area. The results of this analysis provide a common framework for understanding these seemingly disparate branches of inquiry, which we hope will motivate future work in the field.",R. Jordan Crouser;Remco Chang,R. Jordon Crouser;Remco Chang,"Department of Computer Science, Tufts University, USA;Department of Computer Science, Tufts University, USA",10.1109/vast.2010.5652398;10.1109/vast.2011.6102461;10.1109/tvcg.2009.199;10.1109/vast.2010.5652910;10.1109/vast.2010.5652484;10.1109/vast.2009.5332584;10.1109/vast.2010.5652885;10.1109/vast.2009.5333564;10.1109/vast.2010.5652392;10.1109/vast.2009.5332586;10.1109/vast.2011.6102451;10.1109/vast.2009.5333023;10.1109/vast.2009.5333020;10.1109/vast.2009.5332628;10.1109/tvcg.2011.173;10.1109/tvcg.2011.218;10.1109/tvcg.2011.231;10.1109/vast.2010.5652443;10.1109/vast.2010.5653598;10.1109/vast.2011.6102447;10.1109/vast.2011.6102465;10.1109/vast.2011.6102467;10.1109/vast.2010.5652398,"Human computation, human complexity, theory, framework",58.0,36.0,83.0,1736.0,,,visual analytics human;patterns design hinging;papers ranking conferences;kdd;intractable close coupling,0.7109;0.1590;0.1081;0.0532;-0.0043,"[np.int64(-1), -1, -1, -1, -1]",263;-1;-1;-1;-1,263,263
InfoVis,2020,A Generic Framework and Library for Exploration of Small Multiples through Interactive Piling,10.1109/tvcg.2020.3028948,http://dx.doi.org/10.1109/TVCG.2020.3028948,358.0,368.0,J,"Small multiples are miniature representations of visual information used generically across many domains. Handling large numbers of small multiples imposes challenges on many analytic tasks like inspection, comparison, navigation, or annotation. To address these challenges, we developed a framework and implemented a library called PILlNG.JS for designing interactive piling interfaces. Based on the piling metaphor, such interfaces afford flexible organization, exploration, and comparison of large numbers of small multiples by interactively aggregating visual objects into piles. Based on a systematic analysis of previous work, we present a structured design space to guide the design of visual piling interfaces. To enable designers to efficiently build their own visual piling interfaces, PILlNG.JS provides a declarative interface to avoid having to write low-level code and implements common aspects of the design space. An accompanying GUI additionally supports the dynamic configuration of the piling interface. We demonstrate the expressiveness of PILlNG.JS with examples from machine learning, immunofluorescence microscopy, genomics, and public health.",Fritz Lekschas;Xinyi Zhou 0005;Wei Chen 0001;Nils Gehlenborg;Benjamin Bach;Hanspeter Pfister,Fritz Lekschas;Xinyi Zhou;Wei Chen;Nils Gehlenborg;Benjamin Bach;Hanspeter Pfister,"Cambridge, Harvard School of Engineering and Applied Sciences, MA, USA;State Key Lab of CAD&CG, Zhejiang University, Hangzhou, China;State Key Lab of CAD&CG, Zhejiang University, Hangzhou, China;Harvard Medical School, Boston, MA, USA;University of Edinburgh, Edinburgh, UK;Cambridge, Harvard School of Engineering and Applied Sciences, MA, USA",10.1109/tvcg.2015.2467851;10.1109/visual.2005.1532788;10.1109/tvcg.2011.185;10.1109/tvcg.2007.70535;10.1109/tvcg.2017.2745978;10.1109/tvcg.2008.125;10.1109/tvcg.2014.2346249;10.1109/tvcg.2012.237;10.1109/tvcg.2019.2934555;10.1109/tvcg.2015.2467851,"Information visualization,small multiples,interactive piling,visual aggregation,spatial organization",14.0,18.0,52.0,690.0,HM,,visual piling interfaces;js provides declarative;numbers small multiples;genomics public health;domains handling,0.7312;0.2694;0.1824;0.1756;-0.0120,"[np.int64(-1), -1, -1, -1, -1]",319;-1;-1;-1;-1,319,319
Vis,1991,NetV: an experimental network-based volume visualization system,10.1109/visual.1991.175807,http://dx.doi.org/10.1109/VISUAL.1991.175807,239.0,245.0,C,"An experimental volume visualization system, NetV, that distributes volume imaging tasks to appropriate network resources is described. NetV gives offsite scientists easy access to high-end volume imaging software and hardware. The system allows a user to submit volume imaging jobs to an imaging spooler on a visualization-server. Remote high-power compute engines process rendering tasks, while local workstations run the user-interface. The time required to submit a job, render the job on a mini-supercomputer-class machine, and return the volume imaging to the offsite scientist is far less than the time it would take to create a similar image on a local workstation-class machine.&lt;&lt;ETX&gt;&gt;",T. Todd Elvins;David R. Nadeau,T.T. Elvins;D.R. Nadeau,"San Diego Supercomputer Center, Advanced Scientific Visualization Laboratory;San Diego Supercomputer Center, Advanced Scientific Visualization Laboratory",10.1109/visual.1990.146362;10.1109/visual.1990.146397;10.1109/visual.1990.146382;10.1109/visual.1991.175814;10.1109/visual.1990.146362,,20.0,9.0,16.0,45.0,,,experimental volume visualization;offsite scientists;supercomputer class;netv;rendering tasks local,0.7142;0.3415;0.2963;0.2434;0.2199,"[np.int64(-1), -1, -1, -1, -1]",84;-1;-1;-1;-1,84,84
Vis,2003,Hardware-based nonlinear filtering and segmentation using high-level shading languages,10.1109/visual.2003.1250387,http://dx.doi.org/10.1109/VISUAL.2003.1250387,309.0,316.0,C,"Non-linear filtering is an important task for volume analysis. This paper presents hardware-based implementations of various non-linear filters for volume smoothing with edge preservation. The Cg high-level shading language is used in combination with latest PC consumer graphics hardware. Filtering is divided into pervertex and per-fragment stages. In both stages we propose techniques to increase the filtering performance. The vertex program pre-computes texture coordinates in order to address all contributing input samples of the operator mask. Thus additional computations are avoided in the fragment program. The presented fragment programs preserve cache coherence, exploit 4D vector arithmetic, and internal fixed point arithmetic to increase performance. We show the applicability of non-linear filters as part of a GPU-based segmentation pipeline. The resulting binary mask is compressed and decompressed in the graphics memory on-the-fly.",Ivan Viola;Armin Kanitsar;M. Eduard Gröller,I. Viola;A. Kanitsar;M.E. Groller,"Institute of Computer Graphics and Algorithms, University of Technology, Vienna, Austria;Institute of Computer Graphics and Algorithms, University of Technology, Vienna, Austria;Institute of Computer Graphics and Algorithms, University of Technology, Vienna, Austria",10.1109/visual.2002.1183766;10.1109/visual.2002.1183762;10.1109/visual.1999.809934;10.1109/visual.2002.1183757;10.1109/visual.2002.1183766," Non-linear Filtering, Segmentation, Hardware Acceleration",122.0,13.0,23.0,139.0,,,linear filters gpu;shading language used;task volume;pervertex fragment;preserve cache,0.6133;0.2420;0.2007;0.1162;0.0778,"[np.int64(-1), -1, -1, -1, -1]",250;-1;-1;-1;-1,250,250
Vis,1999,Anisotropic nonlinear diffusion in flow visualization,10.1109/visual.1999.809904,http://dx.doi.org/10.1109/VISUAL.1999.809904,325.0,539.0,C,"Vector field visualization is an important topic in scientific visualization. Its aim is to graphically represent field data in an intuitively understandable and precise way. Here a new approach based on anisotropic nonlinear diffusion is introduced. It enables an easy perception of flow data and serves as an appropriate scale space method for the visualization of complicated flow patterns. The approach is closely related to nonlinear diffusion methods in image analysis where images are smoothed while still retaining and enhancing edges. An initial noisy image is smoothed along streamlines, whereas the image is sharpened in the orthogonal direction. The method is based on a continuous model and requires the solution of a parabolic PDE problem. It is discretized only in the final implementational step. Therefore, many important qualitative aspects can already be discussed on a continuous level. Applications are shown in 2D and 3D and the provisions for flow segmentation are outlined.",Tobias Preußer;Martin Rumpf,T. Preusser;M. Rumpf,"Rheinische Friedrich-Wilhelms-Universitat Bonn, Bonn, Nordrhein-Westfalen, DE;Institut für Angewandte Mathematik, Universität Bonn, Bonn, Germany",10.1109/visual.1993.398875;10.1109/visual.1995.480817;10.1109/visual.1994.346312;10.1109/visual.1997.663912;10.1109/visual.1996.567784;10.1109/visual.1997.663898;10.1109/visual.1993.398875,"flow visualization, multiscale, nonlinear diffusion, segmentation",77.0,13.0,21.0,108.0,,,vector field visualization;anisotropic nonlinear diffusion;image sharpened;implementational step important;closely related,0.6783;0.6297;0.1529;0.0163;-0.0164,"[np.int64(-1), np.int64(-1), -1, -1, -1]",140;41;-1;-1;-1,41;140,140
SciVis,2019,Dynamic Nested Tracking Graphs,10.1109/tvcg.2019.2934368,http://dx.doi.org/10.1109/TVCG.2019.2934368,249.0,258.0,J,"This work describes an approach for the interactive visual analysis of large-scale simulations, where numerous superlevel set components and their evolution are of primary interest. The approach first derives, at simulation runtime, a specialized Cinema database that consists of images of component groups, and topological abstractions. This database is processed by a novel graph operation-based nested tracking graph algorithm (GO-NTG) that dynamically computes NTGs for component groups based on size, overlap, persistence, and level thresholds. The resulting NTGs are in turn used in a feature-centered visual analytics framework to query specific database elements and update feature parameters, facilitating flexible post hoc analysis.",Jonas Lukasczyk;Christoph Garth;Gunther H. Weber;Tim Biedert;Ross Maciejewski;Heike Leitte,Jonas Lukasczyk;Christoph Garth;Gunther H. Weber;Tim Biedert;Ross Maciejewski;Heike Leitte,"Technische Universität Kaiserslautern;Technische Universität Kaiserslautern;Lawrence Berkeley National Laboratory, University of California, Davis;NVIDIA Corporation;Arizona State University;Technische Universität Kaiserslautern",10.1109/tvcg.2018.2865265;10.1109/visual.1998.745288;10.1109/tvcg.2012.228;10.1109/tvcg.2018.2865265,"Topological Data Analysis,Nested Tracking Graphs,Image Databases,Feature Tracking,Post Hoc Visual Analytics",16.0,18.0,35.0,701.0,,,large scale simulations;nested tracking graph;superlevel set;images component;update feature parameters,0.5336;0.4386;0.2979;0.1182;0.0810,"[np.int64(-1), -1, -1, -1, -1]",15;-1;-1;-1;-1,15,15
InfoVis,1998,Similarity clustering of dimensions for an enhanced visualization of multidimensional data,10.1109/infvis.1998.729559,http://dx.doi.org/10.1109/INFVIS.1998.729559,52.0,,C,"The order and arrangement of dimensions (variates) is crucial for the effectiveness of a large number of visualization techniques such as parallel coordinates, scatterplots, recursive pattern, and many others. We describe a systematic approach to arrange the dimensions according to their similarity. The basic idea is to rearrange the data dimensions such that dimensions showing a similar behavior are positioned next to each other. For the similarity clustering of dimensions, we need to define similarity measures which determine the partial or global similarity of dimensions. We then consider the problem of finding an optimal one- or two-dimensional arrangement of the dimensions based on their similarity. Theoretical considerations show that both, the one- and the two-dimensional arrangement problem are surprisingly hard problems, i.e. they are NP complete. Our solution of the problem is therefore based on heuristic algorithms. An empirical evaluation using a number of different visualization techniques shows the high impact of our similarity clustering of dimensions on the visualization results.",Mihael Ankerst;Stefan Berchtold;Daniel A. Keim,M. Ankerst;S. Berchtold;D.A. Keim,"University of Munich (LMU), Munich, Germany;AT and T Bell Laboratories, Inc., Florham Park, NJ, USA;Martin Luther University of Halle-Wittenberg, Halle, Germany",10.1109/visual.1990.146402;10.1109/visual.1994.346302;10.1109/visual.1995.485140;10.1109/visual.1990.146402,,351.0,132.0,30.0,996.0,,,clustering dimensions visualization;idea rearrange data;define similarity;techniques parallel;recursive pattern,0.6824;0.3456;0.3410;0.2664;0.1200,"[np.int64(-1), -1, -1, -1, -1]",167;-1;-1;-1;-1,167,167
VAST,2020,Auditing the Sensitivity of Graph-based Ranking with Visual Analytics,10.1109/tvcg.2020.3028958,http://dx.doi.org/10.1109/TVCG.2020.3028958,1459.0,1469.0,J,"Graph mining plays a pivotal role across a number of disciplines, and a variety of algorithms have been developed to answer who/what type questions. For example, what items shall we recommend to a given user on an e-commerce platform? The answers to such questions are typically returned in the form of a ranked list, and graph-based ranking methods are widely used in industrial information retrieval settings. However, these ranking algorithms have a variety of sensitivities, and even small changes in rank can lead to vast reductions in product sales and page hits. As such, there is a need for tools and methods that can help model developers and analysts explore the sensitivities of graph ranking algorithms with respect to perturbations within the graph structure. In this paper, we present a visual analytics framework for explaining and exploring the sensitivity of any graph-based ranking algorithm by performing perturbation-based what-if analysis. We demonstrate our framework through three case studies inspecting the sensitivity of two classic graph-based ranking algorithms (PageRank and HITS) as applied to rankings in political news media and social networks.",Tiankai Xie;Yuxin Ma;Hanghang Tong;My T. Thai;Ross Maciejewski,Tiankai Xie;Yuxin Ma;Hanghang Tong;My T. Thai;Ross Maciejewski,Arizona State University;Arizona State University;University of Illinois at Urbana-Champaign;University of Florida;Arizona State University,10.1109/tvcg.2019.2934300;10.1109/tvcg.2018.2864477;10.1109/tvcg.2013.173;10.1109/tvcg.2017.2745085;10.1109/tvcg.2017.2743858;10.1109/tvcg.2019.2934396;10.1109/tvcg.2012.253;10.1109/tvcg.2017.2745078;10.1109/tvcg.2019.2934798;10.1109/tvcg.2019.2934805;10.1109/tvcg.2018.2865126;10.1109/tvcg.2019.2934619;10.1109/tvcg.2019.2934300,"Graph-based ranking,sensitivity analysis,visual analytics",8.0,3.0,51.0,638.0,,,graph based ranking;political news;product sales page;sensitivities small changes;demonstrate framework,0.6874;0.2556;0.1876;0.0875;-0.0303,"[np.int64(-1), -1, -1, -1, -1]",139;-1;-1;-1;-1,139,139
InfoVis,2018,Vistrates: A Component Model for Ubiquitous Analytics,10.1109/tvcg.2018.2865144,http://dx.doi.org/10.1109/TVCG.2018.2865144,586.0,596.0,J,"Visualization tools are often specialized for specific tasks, which turns the user's analytical workflow into a fragmented process performed across many tools. In this paper, we present a component model design for data visualization to promote modular designs of visualization tools that enhance their analytical scope. Rather than fragmenting tasks across tools, the component model supports unification, where components-the building blocks of this model-can be assembled to support a wide range of tasks. Furthermore, the model also provides additional key properties, such as support for collaboration, sharing across multiple devices, and adaptive usage depending on expertise, from creating visualizations using dropdown menus, through instantiating components, to actually modifying components or creating entirely new ones from scratch using JavaScript or Python source code. To realize our model, we introduce Vistrates, a literate computing platform for developing, assembling, and sharing visualization components. From a visualization perspective, Vistrates features cross-cutting components for visual representations, interaction, collaboration, and device responsiveness maintained in a component repository. From a development perspective, Vistrates offers a collaborative programming environment where novices and experts alike can compose component pipelines for specific analytical activities. Finally, we present several Vistrates use cases that span the full range of the classic “anytime” and “anywhere” motto for ubiquitous analysis: from mobile and on-the-go usage, through office settings, to collaborative smart environments covering a variety of tasks and devices..",Sriram Karthik Badam;Andreas Mathisen;Roman Rädle;Clemens Nylandsted Klokmose;Niklas Elmqvist,Sriram Karthik Badam;Andreas Mathisen;Roman Rädle;Clemens N. Klokmose;Niklas Elmqvist,"University of Maryland at College Park, College Park, MD, US;Aarhus Universitet, Aarhus, DK;Aarhus Universitet, Aarhus, DK;Aarhus Universitet, Aarhus, DK;University of Maryland at College Park, College Park, MD, US",10.1109/tvcg.2016.2598647;10.1109/tvcg.2017.2743990;10.1109/tvcg.2009.174;10.1109/tvcg.2011.185;10.1109/tvcg.2017.2745278;10.1109/infvis.2000.885092;10.1109/tvcg.2013.197;10.1109/vast.2007.4389011;10.1109/tvcg.2008.137;10.1109/tvcg.2017.2744019;10.1109/tvcg.2012.204;10.1109/tvcg.2013.191;10.1109/tvcg.2014.2346573;10.1109/tvcg.2013.200;10.1109/tvcg.2014.2346291;10.1109/tvcg.2016.2599030;10.1109/tvcg.2014.2346574;10.1109/infvis.2000.885086;10.1109/tvcg.2009.162;10.1109/tvcg.2007.70577;10.1109/tvcg.2007.70589;10.1109/tvcg.2016.2598647,"Components,literate computing,development,exploration,dissemination,collaboration,heterogeneous devices",43.0,33.0,80.0,903.0,,,creating visualizations;devices adaptive usage;component pipelines specific;anytime motto ubiquitous;provides additional key,0.6631;0.3311;0.2051;0.0697;0.0419,"[np.int64(-1), -1, -1, -1, -1]",210;-1;-1;-1;-1,210,210
Vis,2005,Illuminated lines revisited,10.1109/visual.2005.1532772,http://dx.doi.org/10.1109/VISUAL.2005.1532772,19.0,26.0,C,"For the rendering of vector and tensor fields, several texture-based volumetric rendering methods were presented in recent years. While they have indisputable merits, the classical vertex-based rendering of integral curves has the advantage of better zooming capabilities as it is not bound to a fixed resolution. It has been shown that lighting can improve spatial perception of lines significantly, especially if lines appear in bundles. Although OpenGL does not directly support lighting of lines, fast rendering of illuminated lines can be achieved by using basic texture mapping. This existing technique is based on a maximum principle which gives a good approximation of specular reflection. Diffuse reflection however is essentially limited to bidirectional lights at infinity. We show how the realism can be further increased by improving diffuse reflection. We present simplified expressions for the Phong/Blinn lighting of infinitesimally thin cylindrical tubes. Based on these, we propose a fast rendering technique with diffuse and specular reflection for orthographic and perspective views and for multiple local and infinite lights. The method requires commonly available programmable vertex and fragment shaders and only two-dimensional lookup textures.",Ovidio Mallo;Ronald Peikert;Christian Sigg;Filip Sadlo,O. Mallo;R. Peikert;C. Sigg;F. Sadlo,"ETH Zürich, Switzerland;ETH Zürich, Switzerland;ETH Zürich, Switzerland;ETH Zürich, Switzerland",10.1109/visual.2004.5;10.1109/visual.2003.1250378;10.1109/visual.2002.1183797;10.1109/visual.1996.567777;10.1109/visual.1997.663912;10.1109/visual.2004.5,"Field lines, illumination, vector field visualization,texture mapping, graphics hardware",101.0,31.0,17.0,567.0,,,rendering illuminated lines;tensor fields;infinitesimally cylindrical;zooming capabilities;blinn,0.6575;0.3327;0.2188;0.1292;0.1020,"[np.int64(-1), np.int64(-1), -1, -1, -1]",57;17;-1;-1;-1,17;57,57
VAST,2019,Tac-Simur: Tactic-based Simulative Visual Analytics of Table Tennis,10.1109/tvcg.2019.2934630,http://dx.doi.org/10.1109/TVCG.2019.2934630,407.0,417.0,J,"Simulative analysis in competitive sports can provide prospective insights, which can help improve the performance of players in future matches. However, adequately simulating the complex competition process and effectively explaining the simulation result to domain experts are typically challenging. This work presents a design study to address these challenges in table tennis. We propose a well-established hybrid second-order Markov chain model to characterize and simulate the competition process in table tennis. Compared with existing methods, our approach is the first to support the effective simulation of tactics, which represent high-level competition strategies in table tennis. Furthermore, we introduce a visual analytics system called Tac-Simur based on the proposed model for simulative visual analytics. Tac-Simur enables users to easily navigate different players and their tactics based on their respective performance in matches to identify the player and the tactics of interest for further analysis. Then, users can utilize the system to interactively explore diverse simulation tasks and visually explain the simulation results. The effectiveness and usefulness of this work are demonstrated by two case studies, in which domain experts utilize Tac-Simur to find interesting and valuable insights. The domain experts also provide positive feedback on the usability of Tac-Simur. Our work can be extended to other similar sports such as tennis and badminton.",Jiachen Wang;Kejian Zhao;Dazhen Deng;Anqi Cao;Xiao Xie;Zheng Zhou;Hui Zhang 0051;Yingcai Wu,Jiachen Wang;Kejian Zhao;Dazhen Deng;Anqi Cao;Xiao Xie;Zheng Zhou;Hui Zhang;Yingcai Wu,"State Key Lab of CAD&CG, Zhejiang University;State Key Lab of CAD&CG, Zhejiang University;State Key Lab of CAD&CG, Zhejiang University;State Key Lab of CAD&CG, Zhejiang University;State Key Lab of CAD&CG, Zhejiang University;Department of Sport Science, Zhejiang University;Department of Sport Science, Zhejiang University;State Key Lab of CAD&CG, Zhejiang University",10.1109/vast.2014.7042478;10.1109/tvcg.2016.2598432;10.1109/tvcg.2013.192;10.1109/tvcg.2012.263;10.1109/tvcg.2014.2346445;10.1109/tvcg.2018.2865126;10.1109/tvcg.2017.2744218;10.1109/tvcg.2018.2865041;10.1109/vast.2014.7042478,"Simulative Visual Analytics,Table Tennis,Design Study",45.0,55.0,48.0,1478.0,,,simulative visual analytics;sports tennis;navigate different players;order markov chain;utilize tac,0.5968;0.4178;0.3298;0.2238;0.1164,"[np.int64(-1), -1, -1, -1, -1]",-1;-1;-1;-1;-1,,-1
Vis,1994,Visualizing flow over curvilinear grid surfaces using line integral convolution,10.1109/visual.1994.346313,http://dx.doi.org/10.1109/VISUAL.1994.346313,240.0,,C,"Line integral convolution (LIC), introduced by B. Cabral and C. Leedom (1993), is a powerful technique for imaging and animating vector fields. We extend the LIC paradigm in three ways: the existing technique is limited to vector fields over a regular Cartesian grid and we extend it to vector fields over parametric surfaces, specifically those found in curvilinear grids, used in computational fluid dynamics simulations; periodic motion filters can be used to animate the flow visualization, but when the flow lies on a parametric surface, the motion appears misleading, and we explain why this problem arises and show how to adjust the LIC algorithm to handle it; we introduce a technique to visualize vector magnitude as well as vector direction, which is based on varying the frequency of the filter function and we develop a different technique based on kernel phase shifts which we have found to show substantially better results. Implementation of these algorithms utilizes texture-mapping hardware to run in real time, which allows them to be included in interactive applications.&lt;&lt;ETX&gt;&gt;",Lisa K. Forssell,L.K. Forssell,"Computer Sciences Corporation, NASA Ames Research Center, University of Stanford, USA",10.1109/visual.1992.235227;10.1109/visual.1990.146360;10.1109/visual.1991.175771;10.1109/visual.1992.235210;10.1109/visual.1990.146359;10.1109/visual.1993.398846;10.1109/visual.1993.398850;10.1109/visual.1991.175773;10.1109/visual.1992.235226;10.1109/visual.1992.235227,,148.0,35.0,17.0,131.0,BP,,animating vector fields;powerful technique imaging;integral convolution lic;cartesian grid;hardware run,0.6512;0.2833;0.2238;0.1712;0.0471,"[np.int64(-1), -1, -1, -1, -1]",40;-1;-1;-1;-1,40,40
VAST,2007,Visual Analytics with Jigsaw,10.1109/vast.2007.4389017,http://dx.doi.org/10.1109/VAST.2007.4389017,201.0,202.0,M,This article briefly introduces the Jigsaw system and describes how we used it in analysis activities for the VAST '07 Contest. Jigsaw is a visual analytic system that provides multiple coordinated views to show connections between entities that are extracted from a collection of documents.,Carsten Görg;Zhicheng Liu 0001;Neel Parekh;Kanupriya Singhal;John T. Stasko,Carsten Gorg;Zhicheng Liu;Neel Parekh;Kanupriya Singhal;John Stasko,"School of Interactive Computing, Georgia Institute of Technology;School of Interactive Computing, Georgia Institute of Technology, USA;School of Interactive Computing, Georgia Institute of Technology, USA;School of Interactive Computing, Georgia Institute of Technology, USA;School of Interactive Computing, Georgia Institute of Technology, USA",0.1109/vast.2007.4389006;10.1109/vast.2007.4389034,,21.0,4.0,3.0,236.0,,,jigsaw visual analytic;entities extracted collection;briefly introduces;multiple coordinated;contest,0.6344;0.2442;0.2408;0.1934;0.1899,"[np.int64(-1), -1, -1, -1, -1]",318;-1;-1;-1;-1,318,318
VAST,2006,Accelerating Network Traffic Analytics Using Query-Driven Visualization,10.1109/vast.2006.261437,http://dx.doi.org/10.1109/VAST.2006.261437,115.0,122.0,C,"Realizing operational analytics solutions where large and complex data must be analyzed in a time-critical fashion entails integrating many different types of technology. This paper focuses on an interdisciplinary combination of scientific data management and visualization/analysis technologies targeted at reducing the time required for data filtering, querying, hypothesis testing and knowledge discovery in the domain of network connection data analysis. We show that use of compressed bitmap indexing can quickly answer queries in an interactive visual data analysis application, and compare its performance with two alternatives for serial and parallel filtering/querying on 2.5 billion records' worth of network connection data collected over a period of 42 weeks. Our approach to visual network connection data exploration centers on two primary factors: interactive ad-hoc and multiresolution query formulation and execution over n dimensions and visual display of the n-dimensional histogram results. This combination is applied in a case study to detect a distributed network scan and to then identify the set of remote hosts participating in the attack. Our approach is sufficiently general to be applied to a diverse set of data understanding problems as well as used in conjunction with a diverse set of analysis and visualization tools",E. Wes Bethel;Scott Campbell;Eli Dart;Kurt Stockinger;Kesheng Wu,E. Wes Bethel;Scott Campbell;Eli Dart;Kurt Stockinger;Kesheng Wu,"Computational Research Division and Lawrence Berkeley National Laboratory, University of California, Berkeley, CA;National Energy Research Scientific Computing Center Division and Lawrence Berkeley National Laboratory, University of California, Berkeley, CA, USA;Energy Sciences Network and Lawrence Berkeley National Laboratory, University of California, Berkeley, CA, USA;Computational Research Division and Lawrence Berkeley National Laboratory, University of California, Berkeley, CA, USA;Computational Research Division and Lawrence Berkeley National Laboratory, University of California, Berkeley, CA, USA",10.1109/visual.1999.809930;10.1109/visual.2005.1532792;10.1109/visual.1999.809930,"query-driven visualization, network security, data mining, visual analytics",63.0,21.0,44.0,351.0,,,visualization analysis technologies;data filtering querying;hosts participating attack;indexing quickly answer;operational,0.6179;0.3509;0.2390;0.1778;0.1408,"[np.int64(-1), -1, -1, -1, -1]",276;-1;-1;-1;-1,276,276
Vis,1994,Volume rendering methods for computational fluid dynamics visualization,10.1109/visual.1994.346314,http://dx.doi.org/10.1109/VISUAL.1994.346314,232.0,,C,"The paper describes three alternative volume rendering approaches to visualizing computational fluid dynamics (CFD) data. One new approach uses realistic volumetric gas rendering techniques to produce photo-realistic images and animations from scalar CFD data. The second uses ray casting that is based an a sampler illumination model and is mainly centered around a versatile new tool for the design of transfer functions. The third method employs a simple illumination model and rapid rendering mechanisms to provide efficient preview capabilities. These tools provide a large range of volume rendering capabilities to be used by the CFD explorer to render rapidly for navigation through the data, to emphasize data features (e.g., shock waves) with a specific transfer function, or to present a realistic rendition of the model.&lt;&lt;ETX&gt;&gt;",David S. Ebert;Roni Yagel;James N. Scott;Yair Kurzion,D.S. Ebert;R. Yagel;J. Scott;Y. Kurzion,"Computer Science Department, University of Maryland Baltimore County, Baltimore, MD, USA;Department of Computer and Information Science, Ohio State Uinversity, Columbus, OH, USA;Department of Aeronautical and Astronautical Engineering, Ohio State Uinversity, Columbus, OH, USA;Department of Computer and Information Science, Ohio State Uinversity, Columbus, OH, USA",,,46.0,6.0,18.0,161.0,,,volumetric gas rendering;approaches visualizing computational;dynamics cfd data;tool design transfer;rapid,0.6700;0.4799;0.4447;0.1402;0.0868,"[np.int64(-1), -1, -1, -1, -1]",256;-1;-1;-1;-1,256,256
Vis,2021,Joint t-SNE for Comparable Projections of Multiple High-Dimensional Datasets,10.1109/tvcg.2021.3114765,http://dx.doi.org/10.1109/TVCG.2021.3114765,623.0,632.0,J,"We present Joint t-Stochastic Neighbor Embedding (Joint t-SNE), a technique to generate comparable projections of multiple high-dimensional datasets. Although t-SNE has been widely employed to visualize high-dimensional datasets from various domains, it is limited to projecting a single dataset. When a series of high-dimensional datasets, such as datasets changing over time, is projected independently using t-SNE, misaligned layouts are obtained. Even items with identical features across datasets are projected to different locations, making the technique unsuitable for comparison tasks. To tackle this problem, we introduce edge similarity, which captures the similarities between two adjacent time frames based on the Graphlet Frequency Distribution (GFD). We then integrate a novel loss term into the t-SNE loss function, which we call vector constraints, to preserve the vectors between projected points across the projections, allowing these points to serve as visual landmarks for direct comparisons between projections. Using synthetic datasets whose ground-truth structures are known, we show that Joint t-SNE outperforms existing techniques, including Dynamic t-SNE, in terms of local coherence error, Kullback-Leibler divergence, and neighborhood preservation. We also showcase a real-world use case to visualize and compare the activation of different layers of a neural network.",Yinqiao Wang;Lu Chen;Jaemin Jo;Yunhai Wang,Yinqiao Wang;Lu Chen;Jaemin Jo;Yunhai Wang,"Shandong University, CN, China;Shandong University, CN, China;Sungkyunkwan University, KR, South Korea;Shandong University, CN, China",10.1109/tvcg.2019.2934433;10.1109/tvcg.2015.2467553;10.1109/tvcg.2017.2743858;10.1109/tvcg.2017.2745919;10.1109/tvcg.2018.2864911;10.1109/tvcg.2019.2934433,"High-dimensional data,projection,embedding,t-stochastic neighbor embedding",3.0,14.0,44.0,1108.0,,,stochastic neighbor embedding;visualize compare activation;changing time projected;real world use;misaligned layouts obtained,0.6066;0.3668;0.1352;0.0930;0.0730,"[np.int64(-1), -1, -1, -1, -1]",31;-1;-1;-1;-1,31,31
Vis,2022,DendroMap: Visual Exploration of Large-Scale Image Datasets for Machine Learning with Treemaps,10.1109/tvcg.2022.3209425,http://dx.doi.org/10.1109/TVCG.2022.3209425,320.0,330.0,J,"In this paper, we present DendroMap, a novel approach to interactively exploring large-scale image datasets for machine learning (ML). ML practitioners often explore image datasets by generating a grid of images or projecting high-dimensional representations of images into 2-D using dimensionality reduction techniques (e.g., t-SNE). However, neither approach effectively scales to large datasets because images are ineffectively organized and interactions are insufficiently supported. To address these challenges, we develop DendroMap by adapting Treemaps, a well-known visualization technique. DendroMap effectively organizes images by extracting hierarchical cluster structures from high-dimensional representations of images. It enables users to make sense of the overall distributions of datasets and interactively zoom into specific areas of interests at multiple levels of abstraction. Our case studies with widely-used image datasets for deep learning demonstrate that users can discover insights about datasets and trained models by examining the diversity of images, identifying underperforming subgroups, and analyzing classification errors. We conducted a user study that evaluates the effectiveness of DendroMap in grouping and searching tasks by comparing it with a gridified version of t-SNE and found that participants preferred DendroMap. DendroMap is available at https://div-lab.github.io/dendromap/.",Donald Bertucci;Md Montaser Hamid;Yashwanthi Anand;Anita Ruangrotsakun;Delyar Tabatabai;Melissa Perez;Minsuk Kahng,Donald Bertucci;Md Montaser Hamid;Yashwanthi Anand;Anita Ruangrotsakun;Delyar Tabatabai;Melissa Perez;Minsuk Kahng,"Oregon State University, USA;Oregon State University, USA;Oregon State University, USA;Oregon State University, USA;Oregon State University, USA;Oregon State University, USA;Oregon State University, USA",10.1109/infvis.2005.1532136;10.1109/vast47406.2019.8986948;10.1109/tvcg.2020.3030342;10.1109/tvcg.2013.212;10.1109/tvcg.2013.162;10.1109/tvcg.2014.2346276;10.1109/tvcg.2021.3114855;10.1109/tvcg.2019.2934659;10.1109/tvcg.2017.2744718;10.1109/tvcg.2016.2598445;10.1109/tvcg.2016.2598838;10.1109/tvcg.2016.2598828;10.1109/tvcg.2019.2934619;10.1109/vast47406.2019.8986943;10.1109/tvcg.2007.70515;10.1109/vast.2014.7042476;10.1109/tvcg.2020.3030383;10.1109/tvcg.2021.3114837;10.1109/infvis.2005.1532136,"Visualization for machine learning,image data,treemaps,visual analytics,data-centric AI,error analysis",,12.0,71.0,1004.0,,,explore image datasets;dendromap grouping;high dimensional representations;version sne;ineffectively organized,0.5755;0.3940;0.3516;0.1454;0.1249,"[np.int64(-1), -1, -1, -1, -1]",56;-1;-1;-1;-1,56,56
VAST,2020,Integrating Prior Knowledge in Mixed-Initiative Social Network Clustering,10.1109/tvcg.2020.3030347,http://dx.doi.org/10.1109/TVCG.2020.3030347,1775.0,1785.0,J,"We propose a new approach-called PK-clustering-to help social scientists create meaningful clusters in social networks. Many clustering algorithms exist but most social scientists find them difficult to understand, and tools do not provide any guidance to choose algorithms, or to evaluate results taking into account the prior knowledge of the scientists. Our work introduces a new clustering approach and a visual analytics user interface that address this issue. It is based on a process that 1) captures the prior knowledge of the scientists as a set of incomplete clusters, 2) runs multiple clustering algorithms (similarly to clustering ensemble methods), 3) visualizes the results of all the algorithms ranked and summarized by how well each algorithm matches the prior knowledge, 4) evaluates the consensus between user-selected algorithms and 5) allows users to review details and iteratively update the acquired knowledge. We describe our approach using an initial functional prototype, then provide two examples of use and early feedback from social scientists. We believe our clustering approach offers a novel constructive method to iteratively build knowledge while avoiding being overly influenced by the results of often randomly selected black-box clustering algorithms.",Alexis Pister;Paolo Buono;Jean-Daniel Fekete;Catherine Plaisant;Paola Valdivia,Alexis Pister;Paolo Buono;Jean-Daniel Fekete;Catherine Plaisant;Paola Valdivia,"Université Paris-Saclay, CNRS, Inria, LRI, France;University of Bari, Italy;Université Paris-Saclay, CNRS, Inria, LRI, France;Université Paris-Saclay, CNRS, Inria, LRI, France and University of Maryland, USA;Université Paris-Saclay, CNRS, Inria, LRI, France",10.1109/tvcg.2018.2864477;10.1109/vast.2015.7347625;10.1109/tvcg.2014.2346260;10.1109/tvcg.2006.147;10.1109/tvcg.2017.2745178;10.1109/tvcg.2014.2346248;10.1109/tvcg.2014.2346321;10.1109/tvcg.2017.2745078;10.1109/tvcg.2018.2864477,"Social network analysis,network visualization,clustering,mixed-initiative,prior knowledge,user interface",13.0,17.0,58.0,754.0,,,meaningful clusters social;allows users review;method iteratively build;selected black box;overly,0.6658;0.1736;0.0789;0.0668;0.0332,"[np.int64(-1), -1, -1, -1, -1]",220;-1;-1;-1;-1,220,220
Vis,1999,Interactive lens visualization techniques,10.1109/visual.1999.809882,http://dx.doi.org/10.1109/VISUAL.1999.809882,155.0,521.0,C,"The paper describes new techniques for minimally immersive visualization of 3D scalar and vector fields, and visualization of document corpora. In our glyph based visualization system, the user interacts with the 3D volume of glyphs using a pair of button-enhanced 3D position and orientation trackers. The user may also examine the volume using an interactive lens, which is a rectangle that slices through the 3D volume and displays scalar information on its surface. A lens allows the display of scalar data in the 3D volume using a contour diagram, and a texture based volume rendering.",Christopher D. Shaw;James A. Hall;David S. Ebert;D. Aaron Roberts,C.D. Shaw;J.A. Hall;D.S. Ebert;D.A. Roberts,"Department of Computer Science, University of Regina, Regina, SAS, Canada;Department of Computer Science, University of Regina, Regina, SAS, Canada;Computer Science and Electrical Engineering Department, University of Maryland, Baltimore, MD, USA;NASA Goddard Space Flight Center, Greenbelt, MD, USA",10.1109/visual.1995.485141;10.1109/visual.1996.568109;10.1109/visual.1995.485141,"Volumetric Data, Glyphs, Two-Handed Interfaces, Interactive Volume Rendering, Contour Diagrams, Stereoscopic Field Analyzer SFA, Seed Fill, Over Blending",25.0,7.0,19.0,116.0,,,glyph based visualization;3d scalar vector;fields;user interacts;volume using contour,0.6906;0.3271;0.2116;0.2109;0.2059,"[np.int64(-1), -1, -1, -1, -1]",262;-1;-1;-1;-1,262,262
VAST,2008,Visual analysis for mutual fund performance,10.1109/vast.2008.4677376,http://dx.doi.org/10.1109/VAST.2008.4677376,181.0,182.0,M,"Mutual funds are one of the most important investment instruments available. However, choosing among mutual funds is not an easy task because they vary in many different dimensions, such as asset size, turnover and fee structure, and these characteristics may affect fund returns. It is thus important to understand the relation between fund performance and these properties. In this work, we use a new visual analytical tool, the density-based distribution map, to assist in this task. By visualizing various important fund characteristics from a real-world database of the US stock funds, our new visual representations greatly help understand the relation between fund characteristics and returns.",Ye Zhao 0003;Jamal Alsakran;Xinlei Zhao,Ye Zhao;Jamal Alsakran;Xinlei Zhao,"Kent University, USA;Kent University, USA;Kent University, USA",,,4.0,0.0,4.0,230.0,,,fund characteristics;visual analytical tool;world database stock;map assist;understand,0.5791;0.4143;0.1960;0.1890;0.1364,"[np.int64(-1), -1, -1, -1, -1]",232;-1;-1;-1;-1,232,232
Vis,1994,Restorer: a visualization technique for handling missing data,10.1109/visual.1994.346317,http://dx.doi.org/10.1109/VISUAL.1994.346317,212.0,,C,"Pseudocoloring is a frequently used technique in scientific visualization for mapping a color to a data value. When using pseudocolor and animation to visualize data that contain missing regions displayed as black or transparent, the missing regions popping in and out can distract the viewer from the more relevant information. Filling these gaps with interpolated data could lead to a misinterpretation of the data. The paper presents a method for combining pseudocoloring and grayscale in the same colormap. Valid data are mapped to colors in the colormap. The luminance values of the colors bounding areas of missing data are used in interpolating over these regions. The missing data are mapped to the grayscale portion of the colormap. This approach has the advantages of eliminating distracting gaps caused by missing data and distinguishing between those areas that represent valid data and those areas that do not. This approach was inspired by a technique used in the restoration of paintings.&lt;&lt;ETX&gt;&gt;",Ray Twiddy;John Cavallo;Shahram M. Shiri,R. Twiddy;J. Cavallo;S.M. Shiri,"NASA Goddard Space Flight Center, Scientific Visualization Studio, Hughes STX Corporation, Greenbelt, MD, USA;NASA Goddard Space Flight Center, Scientific Visualization Studio, Hughes STX Corporation, Greenbelt, MD, USA;NASA Goddard Space Flight Center, Scientific Visualization Studio, Hughes STX Corporation, Greenbelt, MD, USA",,,39.0,10.0,17.0,214.0,,,pseudocolor animation visualize;luminance values;missing data mapped;bounding areas;frequently used technique,0.6588;0.3134;0.3050;0.1379;0.1353,"[np.int64(-1), -1, -1, -1, -1]",308;-1;-1;-1;-1,308,308
InfoVis,2012,Assessing the Effect of Visualizations on Bayesian Reasoning through Crowdsourcing,10.1109/tvcg.2012.199,http://dx.doi.org/10.1109/TVCG.2012.199,2536.0,2545.0,J,"People have difficulty understanding statistical information and are unaware of their wrong judgments, particularly in Bayesian reasoning. Psychology studies suggest that the way Bayesian problems are represented can impact comprehension, but few visual designs have been evaluated and only populations with a specific background have been involved. In this study, a textual and six visual representations for three classic problems were compared using a diverse subject pool through crowdsourcing. Visualizations included area-proportional Euler diagrams, glyph representations, and hybrid diagrams combining both. Our study failed to replicate previous findings in that subjects' accuracy was remarkably lower and visualizations exhibited no measurable benefit. A second experiment confirmed that simply adding a visualization to a textual Bayesian problem is of little help, even when the text refers to the visualization, but suggests that visualizations are more effective when the text is given without numerical values. We discuss our findings and the need for more such experiments to be carried out on heterogeneous populations of non-experts.",Luana Micallef;Pierre Dragicevic;Jean-Daniel Fekete,Luana Micallef;Pierre Dragicevic;Jean-Daniel Fekete,"INRIA and School of Computing, University of Kent, UK;INRIA, France;INRIA, France",10.1109/tvcg.2010.210;10.1109/tvcg.2009.122;10.1109/tvcg.2010.210,"Bayesian reasoning, base rate fallacy, probabilistic judgment, Euler diagrams, glyphs, crowdsourcing",181.0,120.0,58.0,1647.0,HM,,visualization textual bayesian;psychology studies suggest;classic problems compared;area proportional euler;failed replicate,0.6686;0.3116;0.3053;0.1870;-0.0040,"[np.int64(-1), -1, -1, -1, -1]",303;-1;-1;-1;-1,303,303
InfoVis,2019,Decoding a Complex Visualization in a Science Museum – An Empirical Study,10.1109/tvcg.2019.2934401,http://dx.doi.org/10.1109/TVCG.2019.2934401,472.0,481.0,J,"This study describes a detailed analysis of museum visitors' decoding process as they used a visualization designed to support exploration of a large, complex dataset. Quantitative and qualitative analyses revealed that it took, on average, 43 seconds for visitors to decode enough of the visualization to see patterns and relationships in the underlying data represented, and 54 seconds to arrive at their first correct data interpretation. Furthermore, visitors decoded throughout and not only upon initial use of the visualization. The study analyzed think-aloud data to identify issues visitors had mapping the visual representations to their intended referents, examine why they occurred, and consider if and how these decoding issues were resolved. The paper also describes how multiple visual encodings both helped and hindered decoding and concludes with implications on the design and adaptation of visualizations for informal science learning venues.",Joyce Ma;Kwan-Liu Ma;Jennifer Frazier,Joyce Ma;Kwan-Liu Ma;Jennifer Frazier,"Exploratorium, San Francisco;University of California, Davis;Exploratorium, San Francisco",10.1109/tvcg.2012.244;10.1109/tvcg.2008.127;10.1109/tvcg.2015.2467195;10.1109/tvcg.2012.244,"Museums,informal science learning,interactive exhibit,public data visualization,decoding,visual encoding",12.0,5.0,35.0,886.0,,,visualizations informal science;museum visitors decoding;hindered decoding;referents examine occurred;average 43 seconds,0.6521;0.6208;0.2663;0.1247;0.0218,"[np.int64(-1), np.int64(-1), -1, -1, -1]",150;230;-1;-1;-1,150;230,150
Vis,2022,Quick Clusters: A GPU-Parallel Partitioning for Efficient Path Tracing of Unstructured Volumetric Grids,10.1109/tvcg.2022.3209418,http://dx.doi.org/10.1109/TVCG.2022.3209418,537.0,547.0,J,"We propose a simple yet effective method for clustering finite elements to improve preprocessing times and rendering performance of unstructured volumetric grids without requiring auxiliary connectivity data. Rather than building bounding volume hierarchies (BVHs) over individual elements, we sort elements along with a Hilbert curve and aggregate neighboring elements together, improving BVH memory consumption by over an order of magnitude. Then to further reduce memory consumption, we cluster the mesh on the fly into sub-meshes with smaller indices using a series of efficient parallel mesh re-indexing operations. These clusters are then passed to a highly optimized ray tracing API for point containment queries and ray-cluster intersection testing. Each cluster is assigned a maximum extinction value for adaptive sampling, which we rasterize into non-overlapping view-aligned bins allocated along the ray. These maximum extinction bins are then used to guide the placement of samples along the ray during visualization, reducing the number of samples required by multiple orders of magnitude (depending on the dataset), thereby improving overall visualization interactivity. Using our approach, we improve rendering performance over a competitive baseline on the NASA Mars Lander dataset from 6× (1 frame per second (fps) and 1.0 M rays per second (rps) up to now 6 fps and 12.4 M rps, now including volumetric shadows) while simultaneously reducing memory consumption by 3×(33 GB down to 11 GB) and avoiding any offline preprocessing steps, enabling high-quality interactive visualization on consumer graphics cards. Then by utilizing the full 48 GB of an RTX 8000, we improve the performance of Lander by 17 × (1 fps up to 17 fps, 1.0 M rps up to 35.6 M rps).",Nate Morrical;Alper Sahistan;Ugur Güdükbay;Ingo Wald;Valerio Pascucci,Nate Morrical;Alper Sahistan;Uğur Güdükbay;Ingo Wald;Valerio Pascucci,"SCI Institute, University of Utah, USA;Bilkent University, Turkey;Bilkent University, Turkey;NVIDIA, USA;SCI Institute, University of Utah, USA",10.1109/tvcg.2014.2346333;10.1109/tvcg.2011.252;10.1109/tvcg.2011.216;10.1109/tvcg.2021.3114869;10.1109/tvcg.2020.3030470;10.1109/tvcg.2014.2346333,"Ray Tracing,Path Tracing,Volume Rendering,Scientific Visualization,Delta Tracking",,3.0,53.0,897.0,HM,,unstructured volumetric grids;mars lander;cluster intersection;8000 improve performance;finite,0.6338;0.2774;0.2119;0.1304;0.0652,"[np.int64(-1), -1, -1, -1, -1]",109;-1;-1;-1;-1,109,109
InfoVis,2010,PedVis: A Structured; Space-Efficient Technique for Pedigree Visualization,10.1109/tvcg.2010.185,http://dx.doi.org/10.1109/TVCG.2010.185,1063.0,1072.0,J,"Public genealogical databases are becoming increasingly populated with historical data and records of the current population's ancestors. As this increasing amount of available information is used to link individuals to their ancestors, the resulting trees become deeper and more dense, which justifies the need for using organized, space-efficient layouts to display the data. Existing layouts are often only able to show a small subset of the data at a time. As a result, it is easy to become lost when navigating through the data or to lose sight of the overall tree structure. On the contrary, leaving space for unknown ancestors allows one to better understand the tree's structure, but leaving this space becomes expensive and allows fewer generations to be displayed at a time. In this work, we propose that the H-tree based layout be used in genealogical software to display ancestral trees. We will show that this layout presents an increase in the number of displayable generations, provides a nicely arranged, symmetrical, intuitive and organized fractal structure, increases the user's ability to understand and navigate through the data, and accounts for the visualization requirements necessary for displaying such trees. Finally, user-study results indicate potential for user acceptance of the new layout.",Claurissa Tuttle;Luis Gustavo Nonato;Cláudio T. Silva,Claurissa Tuttle;Luis Gustavo Nonato;Claudio Silva,"University of Utah, USA;Universidade de Sáo Paulo, Brazil;University of Utah, USA",10.1109/tvcg.2008.158;10.1109/tvcg.2008.141;10.1109/infvis.2005.1532124;10.1109/infvis.2003.1249004;10.1109/visual.1991.175815;10.1109/infvis.2002.1173152;10.1109/infvis.2002.1173148;10.1109/infvis.1997.636718;10.1109/tvcg.2008.158,"Genealogy, Pedigree, H-tree",40.0,25.0,35.0,697.0,,,genealogical software display;resulting trees deeper;fractal structure;contrary leaving space;used link,0.7177;0.3849;0.3431;0.0623;0.0186,"[np.int64(-1), -1, -1, -1, -1]",-1;-1;-1;-1;-1,,-1
InfoVis,2017,Active Reading of Visualizations,10.1109/tvcg.2017.2745958,http://dx.doi.org/10.1109/TVCG.2017.2745958,770.0,780.0,J,"We investigate whether the notion of active reading for text might be usefully applied to visualizations. Through a qualitative study we explored whether people apply observable active reading techniques when reading paper-based node-link visualizations. Participants used a range of physical actions while reading, and from these we synthesized an initial set of active reading techniques for visualizations. To learn more about the potential impact such techniques may have on visualization reading, we implemented support for one type of physical action from our observations (making freeform marks) in an interactive node-link visualization. Results from our quantitative study of this implementation show that interactive support for active reading techniques can improve the accuracy of performing low-level visualization tasks. Together, our studies suggest that the active reading space is ripe for research exploration within visualization and can lead to new interactions that make for a more flexible and effective visualization reading experience.",Jagoda Walny;Samuel Huron;Charles Perin;Tiffany Wun;Richard Pusch;Sheelagh Carpendale,Jagoda Walny;Samuel Huron;Charles Perin;Tiffany Wun;Richard Pusch;Sheelagh Carpendale,University of Calgary;University of Calgary and Telecom ParisTech;University of London and University of Calgary;University of Calgary;University of Calgary;University of Calgary,10.1109/infvis.2005.1532136;10.1109/tvcg.2011.185;10.1109/tvcg.2015.2467201;10.1109/tvcg.2014.2346984;10.1109/tvcg.2016.2598594;10.1109/infvis.2004.1;10.1109/tvcg.2014.2346435;10.1109/tvcg.2010.164;10.1109/tvcg.2008.141;10.1109/tvcg.2015.2467452;10.1109/tvcg.2015.2467671;10.1109/tvcg.2015.2467195;10.1109/tvcg.2014.2346573;10.1109/tvcg.2015.2467811;10.1109/tvcg.2014.2346422;10.1109/tvcg.2010.179;10.1109/tvcg.2013.164;10.1109/tvcg.2012.189;10.1109/tvcg.2014.2346292;10.1109/tvcg.2014.2346279,"active reading of visualizations,active reading,information visualization,spectrum of physical engagement",35.0,24.0,74.0,1887.0,,,visualization reading experience;type physical action;usefully;based node link;accuracy performing low,0.7349;0.2779;0.1783;0.1560;0.0426,"[np.int64(-1), -1, -1, -1, -1]",266;-1;-1;-1;-1,266,266
Vis,1991,Interactive data visualization using focusing and linking,10.1109/visual.1991.175794,http://dx.doi.org/10.1109/VISUAL.1991.175794,156.0,,C,"Two basic principles for interactive visualization of high-dimensional data-focusing and linking-are discussed. Focusing techniques may involve selecting subsets, dimension reduction, or some more general manipulation of the layout information on the page or screen. A consequent of focusing is that each view only conveys partial information about the data and needs to be linked so that the information contained in individual views can be integrated into a coherent image of the data as a whole. Examples are given of how graphical data analysis methods based on focusing and linking are used in applications including linguistics, geographic information systems, time series analysis, and the analysis of multi-channel images arising in radiology and remote sensing.&lt;&lt;ETX&gt;&gt;",Andreas Buja;John Alan McDonald;J. Michalak;Werner Stuetzle,A. Buja;J.A. McDonald;J. Michalak;W. Stuetzle,"Bellcore, Morristown, NJ, USA;Department of Statistics, University of Washington, Seattle, WA, USA;Department of Statistics, University of Washington, Seattle, WA, USA;Department of Statistics, University of Washington, Seattle, WA, USA",,,2.0,111.0,34.0,1274.0,,,graphical data analysis;focusing linking used;radiology remote sensing;including linguistics;high,0.6799;0.3517;0.2385;0.1981;-0.0036,"[np.int64(-1), -1, -1, -1, -1]",272;-1;-1;-1;-1,272,272
Vis,1990,Parallel coordinates: a tool for visualizing multi-dimensional geometry,10.1109/visual.1990.146402,http://dx.doi.org/10.1109/VISUAL.1990.146402,361.0,378.0,C,"A methodology for visualizing analytic and synthetic geometry in R/sup N/ is presented. It is based on a system of parallel coordinates which induces a nonprojective mapping between N-dimensional and two-dimensional sets. Hypersurfaces are represented by their planar images which have some geometrical properties analogous to the properties of the hypersurface that they represent. A point from to line duality when N=2 generalizes to lines and hyperplanes enabling the representation of polyhedra in R/sup N/. The representation of a class of convex and non-convex hypersurfaces is discussed, together with an algorithm for constructing and displaying any interior point. The display shows some local properties of the hypersurface and provides information on the point's proximity to the boundary. Applications are discussed.&lt;&lt;ETX&gt;&gt;",Alfred Inselberg;Bernard Dimsdale,A. Inselberg;B. Dimsdale,"IBM Scientific Center, Los Angeles, CA, USA and Department of Computer Sciences, University of Southern California, Los Angeles, CA, USA;IBM Scientific Center, Los Angeles, CA, USA",,,1746.0,407.0,47.0,1296.0,,,hypersurfaces represented;geometry sup;algorithm constructing displaying;analytic;interior point,0.6400;0.4024;0.2327;0.2313;0.1934,"[np.int64(-1), -1, -1, -1, -1]",17;-1;-1;-1;-1,17,17
Vis,2006,Distributed Shared Memory for Roaming Large Volumes,10.1109/tvcg.2006.135,http://dx.doi.org/10.1109/TVCG.2006.135,1299.0,1306.0,J,"We present a cluster-based volume rendering system for roaming very large volumes. This system allows to move a gigabyte-sized probe inside a total volume of several tens or hundreds of gigabytes in real-time. While the size of the probe is limited by the total amount of texture memory on the cluster, the size of the total data set has no theoretical limit. The cluster is used as a distributed graphics processing unit that both aggregates graphics power and graphics memory. A hardware-accelerated volume renderer runs in parallel on the cluster nodes and the final image compositing is implemented using a pipelined sort-last rendering algorithm. Meanwhile, volume bricking and volume paging allow efficient data caching. On each rendering node, a distributed hierarchical cache system implements a global software-based distributed shared memory on the cluster. In case of a cache miss, this system first checks page residency on the other cluster nodes instead of directly accessing local disks. Using two gigabit Ethernet network interfaces per node, we accelerate data fetching by a factor of 4 compared to directly accessing local disks. The system also implements asynchronous disk access and texture loading, which makes it possible to overlap data loading, volume slicing and rendering for optimal volume roaming",Laurent Castanie;Christophe Mion;Xavier Cavin;Bruno Lévy 0001,Laurent Castanie;Christophe Mion;Xavier Cavin;Bruno Levy,"ALICE Group, INRIA, Lorraine, Nancy, France;ALICE Group, INRIA, Lorraine, Nancy, France;ALICE Group, INRIA, Lorraine, Nancy, France;ALICE Group, INRIA, Lorraine, Nancy, France",10.1109/visual.2005.1532794;10.1109/visual.1997.663888;10.1109/visual.2005.1532785;10.1109/visual.2005.1532802;10.1109/visual.2005.1532794,"Large volumes, volume roaming, out-of-core, hierarchical caching, distributed shared memory, hardware-accelerated volume visualization, graphics hardware, parallel rendering, graphics cluster",23.0,12.0,38.0,365.0,,,distributed graphics processing;disk access texture;cluster size total;paging;bricking volume,0.5999;0.3929;0.2883;0.2304;0.1940,"[np.int64(-1), -1, -1, -1, -1]",59;-1;-1;-1;-1,59,59
InfoVis,2002,"Internet traffic: visualization, discovery, and very large displays",10.1109/infvis.2002.1173140,http://dx.doi.org/10.1109/INFVIS.2002.1173140,3.0,4.0,M,"For a decade, the ruling common wisdom for Internet traffic held that it was everywhere bursty: over periods lasting tens of milliseconds to hundreds, the traffic was either much below its average rate or much above. In other words, the traffic was not smooth, not staying at all times close to its average. It was bursty on the cable running down a street, carrying the merged traffic of a small number of cable modem users in one section of a town. It was bursty on the core fiber of an Internet service provider, carrying the merged traffic of thousands of users from all over the country. The Internet was designed to accommodate the bursty traffic. The routers and switches that forward traffic from one place to the next were designed for burstiness, and Internet service providers allocated traffic loads on the devices based on an assumption of burstiness. Recently, it was discovered that the old common wisdom is not true. Visualization played a fundamental role in the discovery. The old wisdom held up for links with a small numbers of users. But as the number of users increases, the burstiness dissipates, and the traffic becomes smooth. Design of the high-load part of the Internet needs to be rethought. The old wisdom had persisted for high-load links because the databases of traffic measurements from them are immense, and the traffic measurements had not been studied in their fullest detail, which is necessary to see the smoothing. Visualization tools allowed the detail to be seen, and allowed the verification of a mathematical theory that predicts the smoothing. To see the detail, individual visual displays were created that take up an amount of virtual screen real estate measured in hundreds of pages. It is a simple idea: if you have a lot of data, and you want to see it in detail, you need a lot of space. What is needed now is a rich set of ideas and methods for navigating such very large displays.",William S. Cleveland,W.S. Cleveland,"Statistics Research Bell Laboratories, USA",,,1.0,0.0,0.0,179.0,,,designed burstiness internet;visualization tools;measured hundreds;fundamental role;discovered old common,0.7266;0.2822;0.1915;0.0709;0.0657,"[np.int64(-1), -1, -1, -1, -1]",20;-1;-1;-1;-1,20,20
Vis,2007,Efficient Surface Reconstruction using Generalized Coulomb Potentials,10.1109/tvcg.2007.70553,http://dx.doi.org/10.1109/TVCG.2007.70553,1512.0,1519.0,J,"We propose a novel, geometrically adaptive method for surface reconstruction from noisy and sparse point clouds, without orientation information. The method employs a fast convection algorithm to attract the evolving surface towards the data points. The force field in which the surface is convected is based on generalized Coulomb potentials evaluated on an adaptive grid (i.e., an octree) using a fast, hierarchical algorithm. Formulating reconstruction as a convection problem in a velocity field generated by Coulomb potentials offers a number of advantages. Unlike methods which compute the distance from the data set to the implicit surface, which are sensitive to noise due to the very reliance on the distance transform, our method is highly resilient to shot noise since global, generalized Coulomb potentials can be used to disregard the presence of outliers due to noise. Coulomb potentials represent long-range interactions that consider all data points at once, and thus they convey global information which is crucial in the fitting process. Both the spatial and temporal complexities of our spatially-adaptive method are proportional to the size of the reconstructed object, which makes our method compare favorably with respect to previous approaches in terms of speed and flexibility. Experiments with sparse as well as noisy data sets show that the method is capable of delivering crisp and detailed yet smooth surfaces.",Andrei C. Jalba;Jos B. T. M. Roerdink,Andrei C. Jalba;Jos B.T.M. Roerdink,"Institute for Mathematics and Computing Science, University of Groningam, Netherlands;Institute for Mathematics and Computing Science, University of Groningam, Netherlands",,"Surface reconstruction, Implicit surfaces, Octrees, Generalized Coulomb potentials, Polygonization",30.0,14.0,31.0,252.0,,,surface reconstruction;points force field;noise coulomb potentials;convection problem velocity;method highly resilient,0.5867;0.2872;0.2815;0.1798;0.0915,"[np.int64(-1), -1, -1, -1, -1]",104;-1;-1;-1;-1,104,104
Vis,2002,Visibility-guided simplification,10.1109/visual.2002.1183784,http://dx.doi.org/10.1109/VISUAL.2002.1183784,267.0,274.0,C,"For some graphics applications, object interiors and hard-to-see regions contribute little to the final images and need not be processed. In this paper, we define a view-independent visibility measure on mesh surfaces based on the visibility function between the surfaces and a surrounding sphere of cameras. We demonstrate the usefulness of this measure with a visibility-guided simplification algorithm. Mesh simplification reduces the polygon counts of 3D models and speeds up the rendering process. Many mesh simplification algorithms are based on sequences of edge collapses that minimize geometric and attribute errors. By combining the surface visibility measure with a geometric error measure, we obtain simplified models with improvement proportional to the number of low visibility regions in the original models.",Eugene Zhang;Greg Turk,E. Zhang;G. Turk,"College of Computing, Georgia Institute of Technology, GVU Center, USA;College of Computing, Georgia Institute of Technology, GVU Center, USA",10.1109/visual.1999.809869;10.1109/visual.2000.885723;10.1109/visual.1999.809869,"Visualization, Visibility, Mesh Simplification, Rendering",72.0,14.0,28.0,179.0,,,mesh simplification algorithms;surface visibility;define view independent;processed paper define;counts,0.6766;0.5100;0.1760;0.0761;0.0399,"[np.int64(-1), np.int64(-1), -1, -1, -1]",112;3;-1;-1;-1,3;112,112
VAST,2015,Supporting Iterative Cohort Construction with Visual Temporal Queries,10.1109/tvcg.2015.2467622,http://dx.doi.org/10.1109/TVCG.2015.2467622,91.0,100.0,J,"Many researchers across diverse disciplines aim to analyze the behavior of cohorts whose behaviors are recorded in large event databases. However, extracting cohorts from databases is a difficult yet important step, often overlooked in many analytical solutions. This is especially true when researchers wish to restrict their cohorts to exhibit a particular temporal pattern of interest. In order to fill this gap, we designed COQUITO, a visual interface that assists users defining cohorts with temporal constraints. COQUITO was designed to be comprehensible to domain experts with no preknowledge of database queries and also to encourage exploration. We then demonstrate the utility of COQUITO via two case studies, involving medical and social media researchers.",Josua Krause;Adam Perer;Harry Stavropoulos,Josua Krause;Adam Perer;Harry Stavropoulos,NYU;IBM T.J. Watson Research Center;IBM T.J. Watson Research Center,10.1109/tvcg.2011.185;10.1109/vast.2007.4389013;10.1109/vast.2006.261421;10.1109/tvcg.2014.2346682;10.1109/vast.2010.5652890;10.1109/tvcg.2014.2346482;10.1109/tvcg.2013.200;10.1109/tvcg.2013.206;10.1109/tvcg.2009.117;10.1109/infvis.2001.963273;10.1109/tvcg.2012.225;10.1109/tvcg.2013.167;10.1109/tvcg.2011.185,"Visual temporal queries, cohort definition, electronic medical records, information visualization",91.0,66.0,44.0,1021.0,,,users defining cohorts;event databases extracting;encourage exploration demonstrate;coquito visual;wish,0.6543;0.3514;0.3139;0.2251;0.0739,"[np.int64(-1), -1, -1, -1, -1]",70;-1;-1;-1;-1,70,70
Vis,2021,Communicating Visualizations without Visuals: Investigation of Visualization Alternative Text for People with Visual Impairments,10.1109/tvcg.2021.3114846,http://dx.doi.org/10.1109/TVCG.2021.3114846,1095.0,1105.0,J,"Alternative text is critical in communicating graphics to people who are blind or have low vision. Especially for graphics that contain rich information, such as visualizations, poorly written or an absence of alternative texts can worsen the information access inequality for people with visual impairments. In this work, we consolidate existing guidelines and survey current practices to inspect to what extent current practices and recommendations are aligned. Then, to gain more insight into what people want in visualization alternative texts, we interviewed 22 people with visual impairments regarding their experience with visualizations and their information needs in alternative texts. The study findings suggest that participants actively try to construct an image of visualizations in their head while listening to alternative texts and wish to carry out visualization tasks (e.g., retrieve specific values) as sighted viewers would. The study also provides ample support for the need to reference the underlying data instead of visual elements to reduce users' cognitive burden. Informed by the study, we provide a set of recommendations to compose an informative alternative text.",Crescentia Jung;Shubham Mehta;Atharva Kulkarni;Yuhang Zhao 0001;Yea-Seul Kim,Crescentia Jung;Shubham Mehta;Atharva Kulkarni;Yuhang Zhao;Yea-Seul Kim,"University of Wisconsin-Madison, United States;University of Wisconsin-Madison, United States;University of Wisconsin-Madison, United States;University of Wisconsin-Madison, United States;University of Wisconsin-Madison, United States",10.1109/tvcg.2020.3030378;10.1109/tvcg.2018.2865237;10.1109/tvcg.2020.3030378,"accessible visualization,assistive technologies,alternative text for graphics",19.0,36.0,91.0,1903.0,HM,,graphics people blind;informative alternative text;construct;22;tasks retrieve specific,0.6940;0.4303;0.1038;-0.0115;-0.0821,"[np.int64(-1), -1, -1, -1, -1]",314;-1;-1;-1;-1,314,314
Vis,2024,DG Comics: Semi-Automatically Authoring Graph Comics for Dynamic Graphs,10.1109/tvcg.2024.3456340,http://dx.doi.org/10.1109/TVCG.2024.3456340,973.0,983.0,J,"Comics are an effective method for sequential data-driven storytelling, especially for dynamic graphs—graphs whose vertices and edges change over time. However, manually creating such comics is currently time-consuming, complex, and error-prone. In this paper, we propose DG COMICS, a novel comic authoring tool for dynamic graphs that allows users to semi-automatically build and annotate comics. The tool uses a newly developed hierarchical clustering algorithm to segment consecutive snapshots of dynamic graphs while preserving their chronological order. It also presents rich information on both individuals and communities extracted from dynamic graphs in multiple views, where users can explore dynamic graphs and choose what to tell in comics. For evaluation, we provide an example and report the results of a user study and an expert review.",Joohee Kim;Hyunwook Lee;Duc M. Nguyen;Minjeong Shin;Bum Chul Kwon;Sungahn Ko;Niklas Elmqvist,Joohee Kim;Hyunwook Lee;Duc M. Nguyen;Minjeong Shin;Bum Chul Kwon;Sungahn Ko;Niklas Elmqvist,"UNIST (Ulsan National Institute of Science and Technology), Korea;UNIST (Ulsan National Institute of Science and Technology), Korea;UNIST (Ulsan National Institute of Science and Technology), Korea;UNIST (Ulsan National Institute of Science and Technology), Korea;IBM Research, USA;UNIST (Ulsan National Institute of Science and Technology), Korea;Aarhus University, Denmark",10.1109/tvcg.2010.159;10.1109/tvcg.2011.185;10.1109/tvcg.2020.3030398;10.1109/tvcg.2009.122;10.1109/tvcg.2013.198;10.1109/tvcg.2006.160;10.1109/tvcg.2007.70582;10.1109/tvcg.2022.3209384;10.1109/tvcg.2013.119;10.1109/infvis.2002.1173148;10.1109/tvcg.2010.179;10.1109/tvcg.2015.2468078;10.1109/tvcg.2018.2865232;10.1109/tvcg.2020.3030433;10.1109/tvcg.2021.3114849,"Data-driven storytelling,narrative visualization,,,dynamic graphs,graph comics",,0.0,86.0,185.0,,,data driven storytelling;manually creating comics;hierarchical clustering algorithm;edges change time;complex error,0.5969;0.4829;0.3695;0.1960;-0.0348,"[np.int64(-1), -1, -1, -1, -1]",124;-1;-1;-1;-1,124,124
VAST,2019,explAIner: A Visual Analytics Framework for Interactive and Explainable Machine Learning,10.1109/tvcg.2019.2934629,http://dx.doi.org/10.1109/TVCG.2019.2934629,1064.0,1074.0,J,"We propose a framework for interactive and explainable machine learning that enables users to (1) understand machine learning models; (2) diagnose model limitations using different explainable AI methods; as well as (3) refine and optimize the models. Our framework combines an iterative XAI pipeline with eight global monitoring and steering mechanisms, including quality monitoring, provenance tracking, model comparison, and trust building. To operationalize the framework, we present explAIner, a visual analytics system for interactive and explainable machine learning that instantiates all phases of the suggested pipeline within the commonly used TensorBoard environment. We performed a user-study with nine participants across different expertise levels to examine their perception of our workflow and to collect suggestions to fill the gap between our system and framework. The evaluation confirms that our tightly integrated system leads to an informed machine learning process while disclosing opportunities for further extensions.",Thilo Spinner;Udo Schlegel;Hanna Schäfer;Mennatallah El-Assady,Thilo Spinner;Udo Schlegel;Hanna Schäfer;Mennatallah El-Assady,University of Konstanz;University of Konstanz;University of Konstanz;University of Konstanz,10.1109/tvcg.2017.2744683;10.1109/tvcg.2019.2934654;10.1109/tvcg.2017.2745080;10.1109/tvcg.2018.2864769;10.1109/tvcg.2017.2744718;10.1109/vast.2017.8585720;10.1109/vast.2018.8802509;10.1109/tvcg.2017.2744938;10.1109/tvcg.2016.2598831;10.1109/tvcg.2018.2864812;10.1109/tvcg.2017.2744358;10.1109/tvcg.2016.2598838;10.1109/tvcg.2014.2346481;10.1109/tvcg.2018.2864838;10.1109/tvcg.2018.2865044;10.1109/tvcg.2017.2744158;10.1109/tvcg.2018.2864504;10.1109/tvcg.2017.2744878;10.1109/tvcg.2018.2864499;10.1109/tvcg.2018.2864475;10.1109/vast.2017.8585721;10.1109/tvcg.2017.2744683,"Explainable AI,Interactive Machine Learning,Deep Learning,Visual Analytics,Interpretability,Explainability",143.0,96.0,86.0,7075.0,,,explainable machine learning;commonly used tensorboard;framework evaluation confirms;workflow collect;different,0.7307;0.2816;0.2352;0.1021;0.0171,"[np.int64(-1), -1, -1, -1, -1]",81;-1;-1;-1;-1,81,81
InfoVis,2017,Modeling Color Difference for Visualization Design,10.1109/tvcg.2017.2744359,http://dx.doi.org/10.1109/TVCG.2017.2744359,392.0,401.0,J,"Color is frequently used to encode values in visualizations. For color encodings to be effective, the mapping between colors and values must preserve important differences in the data. However, most guidelines for effective color choice in visualization are based on either color perceptions measured using large, uniform fields in optimal viewing environments or on qualitative intuitions. These limitations may cause data misinterpretation in visualizations, which frequently use small, elongated marks. Our goal is to develop quantitative metrics to help people use color more effectively in visualizations. We present a series of crowdsourced studies measuring color difference perceptions for three common mark types: points, bars, and lines. Our results indicate that peoples' abilities to perceive color differences varies significantly across mark types. Probabilistic models constructed from the resulting data can provide objective guidance for designers, allowing them to anticipate viewer perceptions in order to inform effective encoding design.",Danielle Albers Szafir,Danielle Albers Szafir,University of Colorado,10.1109/visual.1995.480803;10.1109/tvcg.2011.185;10.1109/tvcg.2010.154;10.1109/tvcg.2014.2346978;10.1109/tvcg.2016.2598918;10.1109/visual.1996.568118;10.1109/tvcg.2011.194;10.1109/tvcg.2012.279;10.1109/tvcg.2016.2599106;10.1109/tvcg.2016.2599030;10.1109/tvcg.2008.118;10.1109/visual.1995.480803,"Color Perception,Graphical Perception,Color Models,Crowdsourcing",133.0,117.0,55.0,3773.0,BP,,color effectively visualizations;crowdsourced studies measuring;bars lines results;used encode values;types points,0.6930;0.4336;0.2647;0.2129;0.2076,"[np.int64(-1), -1, -1, -1, -1]",131;-1;-1;-1;-1,131,131
SciVis,2015,PathlinesExplorer ??? Image-based exploration of large-scale pathline fields,10.1109/scivis.2015.7429512,http://dx.doi.org/10.1109/SciVis.2015.7429512,159.0,160.0,M,"PathlinesExplorer is a novel image-based tool, which has been designed to visualize large scale pathline fields on a single computer [7]. PathlinesExplorer integrates explorable images (EI) technique [4] with order-independent transparency (OIT) method [2]. What makes this method different is that it allows users to handle large data on a single workstation. Although it is a view-dependent method, PathlinesExplorer combines both exploration and modification of visual aspects without re-accessing the original huge data. Our approach is based on constructing a per-pixel linked list data structure in which each pixel contains a list of pathline segments. With this view-dependent method, it is possible to filter, color-code, and explore large-scale flow data in real-time. In addition, optimization techniques such as early-ray termination and deferred shading are applied, which further improves the performance and scalability of our approach.",Omniah H. Nagoor;Markus Hadwiger;Madhusudhanan Srinivasan,Omniah H. Nagoor;Markus Hadwiger;Madhusudhanan Srinivasan,KAUST;KAUST;KAUST,,,0.0,0.0,7.0,113.0,,,large scale pathline;exploration modification visual;transparency oit;list data;technique order,0.5781;0.3914;0.2812;0.1481;0.1146,"[np.int64(-1), -1, -1, -1, -1]",302;-1;-1;-1;-1,302,302
InfoVis,2014,PanoramicData: Data Analysis through Pen & Touch,10.1109/tvcg.2014.2346293,http://dx.doi.org/10.1109/TVCG.2014.2346293,2112.0,2121.0,J,"Interactively exploring multidimensional datasets requires frequent switching among a range of distinct but inter-related tasks (e.g., producing different visuals based on different column sets, calculating new variables, and observing the interactions between sets of data). Existing approaches either target specific different problem domains (e.g., data-transformation or data-presentation) or expose only limited aspects of the general exploratory process; in either case, users are forced to adopt coping strategies (e.g., arranging windows or using undo as a mechanism for comparison instead of using side-by-side displays) to compensate for the lack of an integrated suite of exploratory tools. PanoramicData (PD) addresses these problems by unifying a comprehensive set of tools for visual data exploration into a hybrid pen and touch system designed to exploit the visualization advantages of large interactive displays. PD goes beyond just familiar visualizations by including direct UI support for data transformation and aggregation, filtering and brushing. Leveraging an unbounded whiteboard metaphor, users can combine these tools like building blocks to create detailed interactive visual display networks in which each visualization can act as a filter for others. Further, by operating directly on relational-databases, PD provides an approachable visual language that exposes a broad set of the expressive power of SQL including functionally complete logic filtering, computation of aggregates and natural table joins. To understand the implications of this novel approach, we conducted a formative user study with both data and visualization experts. The results indicated that the system provided a fluid and natural user experience for probing multi-dimensional data and was able to cover the full range of queries that the users wanted to pose.",Emanuel Zgraggen;Robert C. Zeleznik;Steven Mark Drucker,Emanuel Zgraggen;Robert Zeleznik;Steven M. Drucker,Brown University;Brown University;Microsoft Research,10.1109/infvis.2000.885086;10.1109/tvcg.2009.162;10.1109/tvcg.2010.164;10.1109/tvcg.2011.251;10.1109/tvcg.2013.191;10.1109/tvcg.2012.275;10.1109/vast.2007.4389013;10.1109/tvcg.2013.150;10.1109/tvcg.2007.70521;10.1109/tvcg.2008.137;10.1109/infvis.2005.1532136;10.1109/tvcg.2007.70594;10.1109/tvcg.2012.204,"Visual analytics, pen and touch, user interfaces, interaction design, coordinated and multiple views",50.0,34.0,38.0,977.0,,,data visualization experts;hybrid pen touch;sql including functionally;unbounded;adopt coping strategies,0.6776;0.2287;0.1924;0.0391;-0.0052,"[np.int64(-1), -1, -1, -1, -1]",203;-1;-1;-1;-1,203,203
Vis,1999,Hue-balls and lit-tensors for direct volume rendering of diffusion tensor fields,10.1109/visual.1999.809886,http://dx.doi.org/10.1109/VISUAL.1999.809886,183.0,524.0,C,"With the development of magnetic resonance imaging techniques for acquiring diffusion tensor data from biological tissue, visualization of tensor data has become a new research focus. The diffusion tensor describes the directional dependence of water molecules' diffusion and can be represented by a three-by-three symmetric matrix. Visualization of second-order tensor fields is difficult because the data values have many degrees of freedom. Existing visualization techniques are best at portraying the tensor's properties over a two-dimensional field, or over a small subset of locations within a three-dimensional field. A means of visualizing the global structure in measured diffusion tensor data is needed. We propose the use of direct volume rendering, with novel approaches for the tensors' coloring, lighting, and opacity assignment. Hue-balls use a two-dimensional colormap on the unit sphere to illustrate the tensor's action as a linear operator. Lit-tensors provide a lighting model for tensors which includes as special cases both lit-lines (from streamline vector visualization) and standard Phong surface lighting. Together with an opacity assignment based on a novel two-dimensional barycentric space of anisotropy, these methods are shown to produce informative renderings of measured diffusion tensor data from the human brain.",Gordon L. Kindlmann;David M. Weinstein,G. Kindlmann;D. Weinstein,"Scientific Computing and Imaging, Department of Computer Science, University of Utah, USA;Scientific Computing and Imaging, Department of Computer Science, University of Utah, USA",10.1109/visual.1990.146373;10.1109/visual.1992.235193;10.1109/visual.1996.567777;10.1109/visual.1998.745294;10.1109/visual.1990.146373,,143.0,48.0,22.0,115.0,BP,,tissue visualization tensor;coloring lighting opacity;dependence water molecules;linear operator lit;cases,0.6826;0.2823;0.1955;0.0931;0.0021,"[np.int64(-1), -1, -1, -1, -1]",245;-1;-1;-1;-1,245,245
Vis,2002,Case study: Visual debugging of finite element codes,10.1109/visual.2002.1183819,http://dx.doi.org/10.1109/VISUAL.2002.1183819,517.0,520.0,C,"We present an innovative application developed at Sandia National Laboratories for visual debugging of unstructured finite element physics codes. Our tool automatically locates anomalous regions, such as inverted elements or nodes whose variable values lie outside a prescribed range, then extracts mesh subsets around these features for detailed examination. The subsets are viewed using color coding of variable values superimposed on the mesh structure. This allows the values and their relative spatial locations within the mesh to be correlated at a glance. Both topological irregularities and hot spots within the data stand out visually, allowing the user to explore the exact numeric values of the grid at surrounding points over time. We demonstrate the utility of this approach by debugging a cell inversion in a simulation of an exploding wire.",Patricia Crossno;David H. Rogers 0001;Christopher J. Garasi,P. Crossno;D.H. Rogers;C.J. Garasi,"Sandia National Laboratories, Albuquerque, NM, USA;Sandia National Laboratories, Albuquerque, NM, USA;Sandia National Laboratories, Albuquerque, NM, USA",10.1109/visual.1999.809919;10.1109/visual.2001.964543;10.1109/visual.1999.809919,"visual debugging, parallel finite element codes and simulations",10.0,5.0,9.0,86.0,,,visual debugging unstructured;element physics codes;mesh correlated;exploding wire;points time,0.6117;0.4480;0.3673;0.3283;-0.0530,"[np.int64(-1), -1, -1, -1, -1]",-1;-1;-1;-1;-1,,-1
Vis,1996,Generation of Transfer Functions with Stochastic Search Technique,10.1109/visual.1996.568113,http://dx.doi.org/10.1109/VISUAL.1996.568113,227.0,234.0,C,"This paper presents a novel approach to assist the user in exploring appropriate transfer functions for the visualization of volumetric datasets. The search for a transfer function is treated as a parameter optimization problem and addressed with stochastic search techniques. Starting from an initial population of (random or pre-defined) transfer functions, the evolution of the stochastic algorithms is controlled by either direct user selection of intermediate images or automatic fitness evaluation using user-specified objective functions. This approach essentially shields the user from the complex and tedious ""trial and error"" approach, and demonstrates effective and convenient generation of transfer functions.",Taosong He;Lichan Hong;Arie E. Kaufman;Hanspeter Pfister,Taosong He;Lichan Hong;A. Kaufman;H. Pfister,"Department of Computer Science
State University of New York at Stony Brook, Stony Brook, NY;State University of New York at Stony Brook, Stony Brook, NY;State University of New York at Stony Brook, Stony Brook, NY;State University of New York at Stony Brook, Stony Brook, NY",,,342.0,7.0,0.0,200.0,,,visualization volumetric datasets;transfer functions evolution;search techniques starting;images automatic;user specified,0.5504;0.3922;0.2734;0.2519;0.1449,"[np.int64(-1), -1, -1, -1, -1]",84;-1;-1;-1;-1,84,84
Vis,2002,Interactive visualization of complex plant ecosystems,10.1109/visual.2002.1183778,http://dx.doi.org/10.1109/VISUAL.2002.1183778,219.0,226.0,C,"We present a method for interactive rendering of large outdoor scenes. Complex polygonal plant models and whole plant populations are represented by relatively small sets of point and line primitives. This enables us to show landscapes faithfully using only a limited percentage of primitives. In addition, a hierarchical data structure allows us to smoothly reduce the geometrical representation to any desired number of primitives. The scene is hierarchically divided into local portions of geometry to achieve large reduction factors for distant regions. Additionally, the data reduction is adapted to the visual importance of geometric objects. This allows us to maintain the visual fidelity of the representation while reducing most of the geometry drastically. With our system, we are able to interactively render very complex landscapes with good visual quality.",Oliver Deussen;Carsten Colditz;Marc Stamminger;George Drettakis,O. Deussen;C. Colditz;M. Stamminger;G. Drettakis,"Faculty of Computer Science, Dresden University of Technology, Germany;Faculty of Computer Science, Dresden University of Technology, Germany;Bauhaus Universitat Weimar, Germany;Sophia Antipolis, REVES/INRIA, France",10.1109/visual.1997.663860;10.1109/visual.2001.964491;10.1109/visual.2001.964492;10.1109/visual.1997.663860,"Synthetic Plants, Ecosystems, Point-based rendering, Level-of-detail Algorithms",261.0,33.0,24.0,313.0,,,render complex landscapes;data reduction;number primitives;drastically;sets point line,0.6706;0.2678;0.1492;0.1162;0.0363,"[np.int64(-1), -1, -1, -1, -1]",58;-1;-1;-1;-1,58,58
Vis,2005,The magic volume lens: an interactive focus+context technique for volume rendering,10.1109/visual.2005.1532818,http://dx.doi.org/10.1109/VISUAL.2005.1532818,367.0,374.0,C,"The size and resolution of volume datasets in science and medicine are increasing at a rate much greater than the resolution of the screens used to view them. This limits the amount of data that can be viewed simultaneously, potentially leading to a loss of overall context of the data when the user views or zooms into a particular area of interest. We propose a focus+context framework that uses various standard and advanced magnification lens rendering techniques to magnify the features of interest, while compressing the remaining volume regions without clipping them away completely. Some of these lenses can be interactively configured by the user to specify the desired magnification patterns, while others are feature-adaptive. All our lenses are accelerated on the GPU. They allow the user to interactively manage the available screen area, dedicating more area to the more resolution-important features.",Lujin Wang;Ye Zhao 0004;Klaus Mueller 0001;Arie E. Kaufman,L. Wang;Y. Zhao;K. Mueller;A. Kaufman,"Center for Visual Computing, Computer Science, Stony Brook University, USA;Center for Visual Computing, Computer Science, Stony Brook University, USA;Center for Visual Computing, Computer Science, Stony Brook University, USA;Center for Visual Computing, Computer Science, Stony Brook University, USA",10.1109/infvis.1997.636786;10.1109/infvis.1996.559215;10.1109/infvis.1996.559214;10.1109/visual.2001.964552;10.1109/visual.2003.1250386;10.1109/visual.2003.1250384;10.1109/visual.2004.48;10.1109/visual.2003.1250400;10.1109/visual.2000.885697;10.1109/infvis.1997.636786,"Focus+Context Techniques,Lens,Volume Rendering, Hardware-assisted Volume Rendering",186.0,28.0,25.0,636.0,,,rendering techniques magnify;remaining volume regions;science medicine;gpu allow;context data user,0.6037;0.3386;0.2320;0.2275;0.1354,"[np.int64(-1), -1, -1, -1, -1]",52;-1;-1;-1;-1,52,52
SciVis,2015,Adaptive Multilinear Tensor Product Wavelets,10.1109/tvcg.2015.2467412,http://dx.doi.org/10.1109/TVCG.2015.2467412,985.0,994.0,J,"Many foundational visualization techniques including isosurfacing, direct volume rendering and texture mapping rely on piecewise multilinear interpolation over the cells of a mesh. However, there has not been much focus within the visualization community on techniques that efficiently generate and encode globally continuous functions defined by the union of multilinear cells. Wavelets provide a rich context for analyzing and processing complicated datasets. In this paper, we exploit adaptive regular refinement as a means of representing and evaluating functions described by a subset of their nonzero wavelet coefficients. We analyze the dependencies involved in the wavelet transform and describe how to generate and represent the coarsest adaptive mesh with nodal function values such that the inverse wavelet transform is exactly reproduced via simple interpolation (subdivision) over the mesh elements. This allows for an adaptive, sparse representation of the function with on-demand evaluation at any point in the domain. We focus on the popular wavelets formed by tensor products of linear B-splines, resulting in an adaptive, nonconforming but crack-free quadtree (2D) or octree (3D) mesh that allows reproducing globally continuous functions via multilinear interpolation over its cells.",Kenneth Weiss 0001;Peter Lindstrom 0001,Kenneth Weiss;Peter Lindstrom,Lawrence Livermore National Laboratory;Lawrence Livermore National Laboratory,10.1109/tvcg.2010.145;10.1109/visual.1997.663860;10.1109/visual.2002.1183810;10.1109/tvcg.2011.252;10.1109/visual.1996.568127;10.1109/tvcg.2009.186;10.1109/tvcg.2010.145,"Multilinear interpolation, adaptive wavelets, multiresolution models, octrees, continuous reconstruction",6.0,5.0,51.0,591.0,,,interpolation subdivision mesh;popular wavelets formed;rendering texture;continuous functions multilinear;rich context,0.5703;0.3614;0.2497;0.2214;0.0683,"[np.int64(-1), -1, -1, -1, -1]",111;-1;-1;-1;-1,111,111
Vis,1991,Realistic volume imaging,10.1109/visual.1991.175805,http://dx.doi.org/10.1109/VISUAL.1991.175805,226.0,,C,"A set of volume visualization tools that are based on the use of recursive ray tracing as the primary vehicle for realistic volume imaging is presented. The tools include shadows, mirrors, specularity, and constructive solid geometry. The underlying representation for the ray tracer is a 3-D raster of voxels that holds the discrete form of the scene. Unlike traditional volume rendering techniques, the discrete recursive ray tracer models many illumination phenomena by traversing discrete rays in voxel space. The approach provides true ray tracing of sampled or computed datasets, as well as ray tracing of hybrid scenes where sampled or computed data are intermixed with geometric models and enhances the understanding of complex biomedical datasets.&lt;&lt;ETX&gt;&gt;",Roni Yagel;Arie E. Kaufman;Qiang Zhang,R. Yagel;A. Kaufman;Q. Zhang,"Department of Computer Science, State University of New York, Stony Brook, Stony Brook, NY, USA;Department of Computer Science, State University of New York, Stony Brook, Stony Brook, NY, USA;Department of Computer Science, State University of New York, Stony Brook, Stony Brook, NY, USA",,,52.0,11.0,24.0,74.0,,,volume visualization;biomedical datasets;ray;shadows mirrors specularity;discrete recursive,0.6870;0.3172;0.2952;0.2622;0.1259,"[np.int64(-1), -1, -1, -1, -1]",84;-1;-1;-1;-1,84,84
InfoVis,2017,Data Through Others' Eyes: The Impact of Visualizing Others' Expectations on Visualization Interpretation,10.1109/tvcg.2017.2745240,http://dx.doi.org/10.1109/TVCG.2017.2745240,760.0,769.0,J,"In addition to visualizing input data, interactive visualizations have the potential to be social artifacts that reveal other people's perspectives on the data. However, how such social information embedded in a visualization impacts a viewer's interpretation of the data remains unknown. Inspired by recent interactive visualizations that display people's expectations of data against the data, we conducted a controlled experiment to evaluate the effect of showing social information in the form of other people's expectations on people's ability to recall the data, the degree to which they adjust their expectations to align with the data, and their trust in the accuracy of the data. We found that social information that exhibits a high degree of consensus lead participants to recall the data more accurately relative to participants who were exposed to the data alone. Additionally, participants trusted the accuracy of the data less and were more likely to maintain their initial expectations when other people's expectations aligned with their own initial expectations but not with the data. We conclude by characterizing the design space for visualizing others' expectations alongside data.",Yea-Seul Kim;Katharina Reinecke;Jessica Hullman,Yea-Seul Kim;Katharina Reinecke;Jessica Hullman,University of Washington;University of Washington;University of Washington,10.1109/vast.2007.4389011;10.1109/infvis.2005.1532126;10.1109/tvcg.2011.255;10.1109/tvcg.2014.2346419;10.1109/tvcg.2007.70577;10.1109/infvis.2005.1532122;10.1109/tvcg.2007.70589;10.1109/tvcg.2010.177,"Social influence,Social visualization,Data interpretation",50.0,30.0,40.0,1285.0,,,visualizations potential social;trusted accuracy;maintain initial expectations;data remains;high,0.5739;0.3549;0.3505;0.2460;-0.0411,"[np.int64(-1), -1, -1, -1, -1]",168;-1;-1;-1;-1,168,168
Vis,1999,Geo-spatial visualization for situational awareness,10.1109/visual.1999.809925,http://dx.doi.org/10.1109/VISUAL.1999.809925,441.0,559.0,C,"Situational awareness applications require a highly detailed geospatial visualization covering a large geographic area. Conventional polygon based terrain modeling would exceed the capacity of current computer rendering. Terrain visualization techniques for a situational awareness application are described in this case study. Visualizing large amounts of terrain data has been achieved using very large texture maps. Sun shading is applied to the terrain texture map to enhance perception of relief features. Perception of submarine positions has been enhanced using a translucent, textured water surface.",Eliot Feibush;Nikhil Gagvani;Daniel Williams,E. Feibush;N. Gagvani;D. Williams,"Sarnoff Corporation, Princeton, NJ, USA;Sarnoff Corporation, Princeton, NJ, USA;Systems and Scientific Software, Elkins Park, PA, USA",,,6.0,0.0,12.0,153.0,,,terrain visualization;situational awareness;sun shading applied;water;exceed capacity current,0.7224;0.3185;0.2811;0.1036;0.0171,"[np.int64(-1), -1, -1, -1, -1]",77;-1;-1;-1;-1,77,77
Vis,2024,SpreadLine: Visualizing Egocentric Dynamic Influence,10.1109/tvcg.2024.3456373,http://dx.doi.org/10.1109/TVCG.2024.3456373,1050.0,1060.0,J,"Egocentric networks, often visualized as node-link diagrams, portray the complex relationship (link) dynamics between an entity (node) and others. However, common analytics tasks are multifaceted, encompassing interactions among four key aspects: strength, function, structure, and content. Current node-link visualization designs may fall short, focusing narrowly on certain aspects and neglecting the holistic, dynamic nature of egocentric networks. To bridge this gap, we introduce SpreadLine, a novel visualization framework designed to enable the visual exploration of egocentric networks from these four aspects at the microscopic level. Leveraging the intuitive appeal of storyline visualizations, SpreadLine adopts a storyline-based design to represent entities and their evolving relationships. We further encode essential topological information in the layout and condense the contextual information in a metro map metaphor, allowing for a more engaging and effective way to explore temporal and attribute-based information. To guide our work, with a thorough review of pertinent literature, we have distilled a task taxonomy that addresses the analytical needs specific to egocentric network exploration. Acknowledging the diverse analytical requirements of users, SpreadLine offers customizable encodings to enable users to tailor the framework for their tasks. We demonstrate the efficacy and general applicability of SpreadLine through three diverse real-world case studies (disease surveillance, social media trends, and academic career evolution) and a usability study.",Yun-Hsin Kuo;Dongyu Liu;Kwan-Liu Ma,Yun-Hsin Kuo;Dongyu Liu;Kwan-Liu Ma,"University of California, USA;University of California, USA;University of California, USA",10.1109/vast.2017.8585487;10.1109/tvcg.2020.3030437;10.1109/vast.2016.7883510;10.1109/tvcg.2023.3326578;10.1109/tvcg.2022.3209480;10.1109/vast.2018.8802415;10.1109/vast.2015.7347632;10.1109/tvcg.2013.196;10.1109/tvcg.2020.3030403;10.1109/tvcg.2012.212;10.1109/tvcg.2020.3030467;10.1109/tvcg.2018.2864899;10.1109/tvcg.2015.2468151,"Egocentric network,network analysis,,,design study,storyline visualization,visual exploration,metaphor",,0.0,75.0,201.0,,,networks visualized node;metaphor allowing engaging;condense;tailor framework tasks;encodings enable users,0.6865;0.2660;0.0837;0.0714;-0.0838,"[np.int64(-1), -1, -1, -1, -1]",169;-1;-1;-1;-1,169,169
Vis,2021,Explanatory Journeys: Visualising to Understand and Explain Administrative Justice Paths of Redress,10.1109/tvcg.2021.3114818,http://dx.doi.org/10.1109/TVCG.2021.3114818,518.0,528.0,J,"Administrative justice concerns the relationships between individuals and the state. It includes redress and complaints on decisions of a child's education, social care, licensing, planning, environment, housing and homelessness. However, if someone has a complaint or an issue, it is challenging for people to understand different possible redress paths and explore what path is suitable for their situation. Explanatory visualisation has the potential to display these paths of redress in a clear way, such that people can see, understand and explore their options. The visualisation challenge is further complicated because information is spread across many documents, laws, guidance and policies and requires judicial interpretation. Consequently, there is not a single database of paths of redress. In this work we present how we have co-designed a system to visualise administrative justice paths of redress. Simultaneously, we classify, collate and organise the underpinning data, from expert workshops, heuristic evaluation and expert critical reflection. We make four contributions: (i) an application design study of the explanatory visualisation tool (Artemus), (ii) coordinated and co-design approach to aggregating the data, (iii) two in-depth case studies in housing and education demonstrating explanatory paths of redress in administrative law, and (iv) reflections on the expert co-design process and expert data gathering and explanatory visualisation for administrative justice and law.",Jonathan C. Roberts;Peter W. S. Butcher;Ann Sherlock;Sarah Nason,Jonathan C. Roberts;Peter Butcher;Ann Sherlock;Sarah Nason,"Bangor University, United Kingdom;Bangor University, United Kingdom;Bangor University, United Kingdom;Bangor University, United Kingdom",10.1109/tvcg.2020.3030375;10.1109/visual.2005.1532788;10.1109/tvcg.2011.185;10.1109/tvcg.2011.255;10.1109/tvcg.2013.119;10.1109/tvcg.2014.2346331;10.1109/tvcg.2015.2467271;10.1109/tvcg.2017.2745878;10.1109/tvcg.2012.213;10.1109/tvcg.2010.179;10.1109/vast.2007.4389006;10.1109/tvcg.2009.139;10.1109/infvis.2004.12;10.1109/infvis.2005.1532143;10.1109/tvcg.2009.111;10.1109/tvcg.2020.3030375,"Explanatory Visualisation,Administrative Justice,Law,Law Visualisation",8.0,4.0,70.0,615.0,HM,,visualisation administrative justice;workshops heuristic evaluation;database paths redress;environment housing;single,0.7400;0.2229;0.2009;0.1595;-0.0604,"[np.int64(-1), -1, -1, -1, -1]",270;-1;-1;-1;-1,270,270
Vis,2023,Perceptually Uniform Construction of Illustrative Textures,10.1109/tvcg.2023.3326574,http://dx.doi.org/10.1109/TVCG.2023.3326574,1052.0,1062.0,J,"Illustrative textures, such as stippling or hatching, were predominantly used as an alternative to conventional Phong rendering. Recently, the potential of encoding information on surfaces or maps using different densities has also been recognized. This has the significant advantage that additional color can be used as another visual channel and the illustrative textures can then be overlaid. Effectively, it is thus possible to display multiple information, such as two different scalar fields on surfaces simultaneously. In previous work, these textures were manually generated and the choice of density was unempirically determined. Here, we first want to determine and understand the perceptual space of illustrative textures. We chose a succession of simplices with increasing dimensions as primitives for our textures: Dots, lines, and triangles. Thus, we explore the texture types of stippling, hatching, and triangles. We create a range of textures by sampling the density space uniformly. Then, we conduct three perceptual studies in which the participants performed pairwise comparisons for each texture type. We use multidimensional scaling (MDS) to analyze the perceptual spaces per category. The perception of stippling and triangles seems relatively similar. Both are adequately described by a 1D manifold in 2D space. The perceptual space of hatching consists of two main clusters: Crosshatched textures, and textures with only one hatching direction. However, the perception of hatching textures with only one hatching direction is similar to the perception of stippling and triangles. Based on our findings, we construct perceptually uniform illustrative textures. Afterwards, we provide concrete application examples for the constructed textures.",Anna Sterzik;Monique Meuschke;Douglas W. Cunningham;Kai Lawonn,Anna Sterzik;Monique Meuschke;Douglas W. Cunningham;Kai Lawonn,"University of Jena, Germany;University of Magdeburg, Germany;Brandenburg University of Technology, Germany;University of Jena, Germany",0.1109/tvcg.2006.180;10.1109/visual.1996.568110;10.1109/tvcg.2016.2598795;10.1109/tvcg.2023.3326523,"Illustrative Visualization,Perceptual Evaluation,Hatching,Stippling",,0.0,55.0,225.0,,,illustrative textures;space hatching;scaling mds analyze;alternative conventional phong;studies participants performed,0.6983;0.2614;0.1362;0.1202;0.0108,"[np.int64(-1), -1, -1, -1, -1]",55;-1;-1;-1;-1,55,55
Vis,2008,Visualization of Myocardial Perfusion Derived from Coronary Anatomy,10.1109/tvcg.2008.180,http://dx.doi.org/10.1109/TVCG.2008.180,1595.0,1602.0,J,"Visually assessing the effect of the coronary artery anatomy on the perfusion of the heart muscle in patients with coronary artery disease remains a challenging task. We explore the feasibility of visualizing this effect on perfusion using a numerical approach. We perform a computational simulation of the way blood is perfused throughout the myocardium purely based on information from a three-dimensional anatomical tomographic scan. The results are subsequently visualized using both three-dimensional visualizations and bullpsilas eye plots, partially inspired by approaches currently common in medical practice. Our approach results in a comprehensive visualization of the coronary anatomy that compares well to visualizations commonly used for other scanning technologies. We demonstrate techniques giving detailed insight in blood supply, coronary territories and feeding coronary arteries of a selected region. We demonstrate the advantages of our approach through visualizations that show information which commonly cannot be directly observed in scanning data, such as a separate visualization of the supply from each coronary artery. We thus show that the results of a computational simulation can be effectively visualized and facilitate visually correlating these results to for example perfusion data.",Maurice Termeer;Javier Oliván Bescós;Marcel Breeuwer;Anna Vilanova;Frans A. Gerritsen;M. Eduard Gröller;Eike Nagel,Maurice Termeer;Javier Oliván Bescós;Marcel Breeuwer;Anna Vilanova;Frans Gerritsen;M. Eduard Gröller;Eike Nagel,"Vienna University of Technology, Austria;Philips Healthcare;Philips Healthcare;Eindhoven University of Technology, Netherlands;Philips Healthcare;Vienna University of Technology, Austria;King's College London, London, UK",10.1109/tvcg.2007.70550;10.1109/visual.2002.1183754;10.1109/tvcg.2007.70550,"Cardiac visualization, coronary artery territories, myocardial perfusion",34.0,15.0,21.0,469.0,,,visualization coronary anatomy;effect perfusion using;bullpsilas eye;numerical approach perform;purely based information,0.7640;0.3856;0.1727;0.1369;0.0573,"[np.int64(-1), -1, -1, -1, -1]",133;-1;-1;-1;-1,133,133
Vis,2003,Piecewise C¹ continuous surface reconstruction of noisy point clouds via local implicit quadric regression,10.1109/visual.2003.1250359,http://dx.doi.org/10.1109/VISUAL.2003.1250359,91.0,98.0,C,"This paper addresses the problem of surface reconstruction of highly noisy point clouds. The surfaces to be reconstructed are assumed to be 2-manifolds of piecewise C/sup 1/ continuity, with isolated small irregular regions of high curvature, sophisticated local topology or abrupt burst of noise. At each sample point, a quadric field is locally fitted via a modified moving least squares method. These locally fitted quadric fields are then blended together to produce a pseudo-signed distance field using Shepard's method. We introduce a prioritized front growing scheme in the process of local quadrics fitting. Flatter surface areas tend to grow faster. The already fitted regions will subsequently guide the fitting of those irregular regions in their neighborhood.",Hui Xie 0001;Jianning Wang;Jing Hua 0001;Hong Qin 0001;Arie E. Kaufman,Hui Xie;Jianning Wang;Jing Hua;Hong Qin;A. Kaufman,"Center for Visual Computing (CVC) and Department of Computer Science, Stony Brook University, Stony Brook, NY, USA;Center for Visual Computing (CVC) and Department of Computer Science, Stony Brook University, Stony Brook, NY, USA;Center for Visual Computing (CVC) and Department of Computer Science, Stony Brook University, Stony Brook, NY, USA;Center for Visual Computing (CVC) and Department of Computer Science, Stony Brook University, Stony Brook, NY, USA;Center for Visual Computing (CVC) and Department of Computer Science, Stony Brook University, Stony Brook, NY, USA",10.1109/visual.2001.964489;10.1109/visual.2001.964489,"Computer Graphics, Surface Reconstruction, Point Cloud, Surface Representation, Solid Modeling, Moving Least Squares, Shepard's Method",1.0,20.0,21.0,192.0,,,noisy point clouds;quadric field locally;shepard method introduce;grow faster;piecewise sup continuity,0.6265;0.2609;0.1359;0.0461;0.0262,"[np.int64(-1), -1, -1, -1, -1]",286;-1;-1;-1;-1,286,286
Vis,2024,DataGarden: Formalizing Personal Sketches into Structured Visualization Templates,10.1109/tvcg.2024.3456336,http://dx.doi.org/10.1109/TVCG.2024.3456336,1268.0,1278.0,J,"Sketching is a common practice among visualization designers and serves an approachable entry to data visualization for non-experts. However, moving from a sketch to a full fledged data visualization often requires throwing away the original sketch and recreating it from scratch. Our goal is to formalize these sketches, enabling them to support iteration and systematic data mapping through a visual-first templating workflow. In this workflow, authors sketch a representative visualization and structure it into an expressive template for an envisioned or partial dataset, capturing implicit style as well as explicit data mappings. To demonstrate our proposed workflow, we implement DataGarden and evaluate it through a reproduction and a freeform study. We investigate how DataGarden supports personal expression and delve into the variety of visualizations that authors can produce with it, identifying cases that demonstrate the limitations of our approach and discussing avenues for future work.",Anna Offenwanger;Theophanis Tsandilas;Fanny Chevalier,Anna Offenwanger;Theophanis Tsandilas;Fanny Chevalier,"Université Paris Saclay, CRNS, Inria, LISN, France;Université Paris Saclay, CRNS, Inria, LISN, France;Departments of Computer Science and Statistical Sciences, University of Toronto, Canada",10.1109/tvcg.2010.164;10.1109/tvcg.2014.2346292;10.1109/tvcg.2016.2598620;10.1109/tvcg.2013.191;10.1109/tvcg.2022.3209451;10.1109/tvcg.2018.2865240;10.1109/tvcg.2023.3326520;10.1109/tvcg.2018.2865158;10.1109/tvcg.2016.2598839;10.1109/tvcg.2019.2934281;10.1109/tvcg.2015.2467153;10.1109/tvcg.2020.3030476;10.1109/tvcg.2012.262;10.1109/tvcg.2020.3030367,"Personal visualization,Visualization template,,,Sketch input,Sketch-based visualization,Visualization by-example",,0.0,69.0,162.0,,,visualization designers;datagarden supports personal;dataset capturing implicit;common practice;recreating scratch goal,0.6655;0.3367;0.2758;0.1336;0.0858,"[np.int64(-1), -1, -1, -1, -1]",204;-1;-1;-1;-1,204,204
InfoVis,2020,SafetyLens: Visual Data Analysis of Functional Safety of Vehicles,10.1109/tvcg.2020.3030382,http://dx.doi.org/10.1109/TVCG.2020.3030382,1688.0,1697.0,J,"Modern automobiles have evolved from just being mechanical machines to having full-fledged electronics systems that enhance vehicle dynamics and driver experience. However, these complex hardware and software systems, if not properly designed, can experience failures that can compromise the safety of the vehicle, its occupants, and the surrounding environment. For example, a system to activate the brakes to avoid a collision saves lives when it functions properly, but could lead to tragic outcomes if the brakes were applied in a way that's inconsistent with the design. Broadly speaking, the analysis performed to minimize such risks falls into a systems engineering domain called Functional Safety. In this paper, we present SafetyLens, a visual data analysis tool to assist engineers and analysts in analyzing automotive Functional Safety datasets. SafetyLens combines techniques including network exploration and visual comparison to help analysts perform domain-specific tasks. This paper presents the design study with domain experts that resulted in the design guidelines, the tool, and user feedback.",Arpit Narechania;Ahsan Qamar;Alex Endert,Arpit Narechania;Ahsan Qamar;Alex Endert,Georgia Institute of Technology;Ford Motor Company;Georgia Institute of Technology,10.1109/vast.2006.261426;10.1109/tvcg.2014.2346248;10.1109/tvcg.2011.185;10.1109/tvcg.2014.2346249;10.1109/tvcg.2012.255;10.1109/tvcg.2006.166;10.1109/tvcg.2009.108,"Visual data analysis,Design study,Network visualization,Functional safety,Automotive engineering",2.0,1.0,57.0,644.0,,,automotive functional safety;network exploration visual;inconsistent design;collision saves;called,0.6729;0.3637;0.2181;0.1558;0.0783,"[np.int64(-1), -1, -1, -1, -1]",300;-1;-1;-1;-1,300,300
Vis,1993,Computer visualization of long genomic sequences,10.1109/visual.1993.398883,http://dx.doi.org/10.1109/VISUAL.1993.398883,308.0,315.0,C,"Human beings find it difficult to analyze local and global oligonucleotide patterns in the linear primary sequences of a genome. In this paper, we present a family of iterated function systems (IFS) that can be used to generate a set of visual models of a DNA sequence. A new visualization function, the W-curve, that is derived from this IFS family is introduced. Using W-curves, a user can readily compare subsequences within a long genomic sequence - or between genomic sequences - and can visually evaluate the effect of local variations (mutations) upon the global genomic information content.&lt;&lt;ETX&gt;&gt;",Dachywan Wu;James Robergé;Douglas J. Cork;Bao Gia Nguyen;Thom Grace,D. Wu;J. Roberge;D.J. Cork;B.G. Nguyen;T. Grace,"Department of Computer Science, Illinois Institute of Technology, Chicago, IL, USA;Department of Computer Science, Illinois Institute of Technology, Chicago, IL, USA;Department of Biology, Illinois Institute of Technology, Chicago, IL, USA;Department of Mathematics, Illinois Institute of Technology, Chicago, IL, USA;Department of Computer Science, Illinois Institute of Technology, Chicago, IL, USA",,,42.0,8.0,14.0,100.0,,,genomic sequences visually;function systems ifs;using curves user;human beings difficult;local,0.7186;0.2938;0.2160;0.0756;-0.0131,"[np.int64(-1), -1, -1, -1, -1]",117;-1;-1;-1;-1,117,117
InfoVis,2002,"SpaceTree: supporting exploration in large node link tree, design evolution and empirical evaluation",10.1109/infvis.2002.1173148,http://dx.doi.org/10.1109/INFVIS.2002.1173148,57.0,64.0,C,"We present a novel tree browser that builds on the conventional node link tree diagrams. It adds dynamic rescaling of branches of the tree to best fit the available screen space, optimized camera movement, and the use of preview icons summarizing the topology of the branches that cannot be expanded. In addition, it includes integrated search and filter functions. This paper reflects on the evolution of the design and highlights the principles that emerged from it. A controlled experiment showed benefits for navigation to already previously visited nodes and estimation of overall tree topology.",Catherine Plaisant;Jesse Grosjean;Benjamin B. Bederson,C. Plaisant;J. Grosjean;B.B. Bederson,"Human-Computer Interaction Laboratory, University of Maryland, USA;Human-Computer Interaction Laboratory, University of Maryland, USA;Human-Computer Interaction Laboratory, University of Maryland, USA",10.1109/visual.1996.567745;10.1109/visual.1996.567745,,519.0,71.0,23.0,2216.0,,,novel tree browser;rescaling;search filter functions;visited;includes,0.8092;0.1605;0.1582;0.1424;0.0502,"[np.int64(-1), -1, -1, -1, -1]",287;-1;-1;-1;-1,287,287
Vis,1998,Selective visualization of vortices in hydrodynamic flows,10.1109/visual.1998.745333,http://dx.doi.org/10.1109/VISUAL.1998.745333,419.0,422.0,C,"Vortices are important features in many research and engineering fields. Visualization is an important step in gaining more understanding and control of vortices. Vortex detection criteria fall into two categories: point based scalar quantities, calculated at single points, and curve based geometric criteria, calculated for, e.g., streamlines. The first category is easy to compute, but does not work in all cases. The second category is more intuitive and should work in all cases, but currently only works in 2D (or 3D projected) flows. We show applications of both approaches in hydrodynamic flows.",I. Ari Sadarjoen;Frits H. Post;Bing Ma;David C. Banks;Hans-Georg Pagendarm,I.A. Sadarjoen;F.H. Post;Bing Ma;D.C. Banks;H.-G. Pagendarm,"Department of Computer Science, Delft University of Technnology, Delft, Netherlands;Department of Computer Science, Delft University of Technnology, Delft, Netherlands;Laboratory for Aero and Hydrodynamics,Delft University of Technology, Tsinghua University, Beijing, China;Department of Computer Science, Mississippi State University, USA;DLR: Deutsches Zentrum für Luft-und Raumfahrt, German Aerospace Center, Germany",10.1109/visual.1995.485158;10.1109/visual.1997.663910;10.1109/visual.1994.346327;10.1109/visual.1996.568137;10.1109/visual.1995.485158,,111.0,28.0,12.0,251.0,,,vortices vortex detection;single points curve;2d 3d projected;research engineering fields;important,0.7879;0.2638;0.1855;0.0769;0.0082,"[np.int64(-1), -1, -1, -1, -1]",141;-1;-1;-1;-1,141,141
Vis,2021,Rapid Labels: Point-Feature Labeling on GPU,10.1109/tvcg.2021.3114854,http://dx.doi.org/10.1109/TVCG.2021.3114854,604.0,613.0,J,"Labels, short textual annotations are an important component of data visualizations, illustrations, infographics, and geographical maps. In interactive applications, the labeling method responsible for positioning the labels should not take the resources from the application itself. In other words, the labeling method should provide the result as fast as possible. In this work, we propose a greedy point-feature labeling method running on GPU. In contrast to existing methods that position the labels sequentially, the proposed method positions several labels in parallel. Yet, we guarantee that the positioned labels will not overlap, nor will they overlap important visual features. When the proposed method is searching for the label position of a point-feature, the available label candidates are evaluated with respect to overlaps with important visual features, conflicts with label candidates of other point-features, and their ambiguity. The evaluation of each label candidate is done in constant time independently from the number of point-features, the number of important visual features, and the resolution of the created image. Our measurements indicate that the proposed method is able to position more labels than existing greedy methods that do not evaluate conflicts between the label candidates. At the same time, the proposed method achieves a significant increase in performance. The increase in performance is mainly due to the parallelization and the efficient evaluation of label candidates.",Vaclav Pavlovec;Ladislav Cmolík,Vaclav Pavlovec;Ladislav Cmolik,"Faculty of Electrical Engineering, Czech Technical University in Prague, Czech Republic;Faculty of Electrical Engineering, Czech Technical University in Prague, Czech Republic",10.1109/tvcg.2006.136;10.1109/tvcg.2008.152;10.1109/tvcg.2006.136,"Label placement,Point-feature labeling,GPU",1.0,3.0,33.0,496.0,,,point feature labeling;maps interactive applications;method running gpu;textual;overlap,0.5078;0.4351;0.2059;0.1986;0.1978,"[np.int64(-1), -1, -1, -1, -1]",242;-1;-1;-1;-1,242,242
VAST,2009,Visual analysis of graphs with multiple connected components,10.1109/vast.2009.5333893,http://dx.doi.org/10.1109/VAST.2009.5333893,155.0,162.0,C,"In this paper, we present a system for the interactive visualization and exploration of graphs with many weakly connected components. The visualization of large graphs has recently received much research attention. However, specific systems for visual analysis of graph data sets consisting of many components are rare. In our approach, we rely on graph clustering using an extensive set of topology descriptors. Specifically, we use the self-organizing-map algorithm in conjunction with a user-adaptable combination of graph features for clustering of graphs. It offers insight into the overall structure of the data set. The clustering output is presented in a grid containing clusters of the connected components of the input graph. Interactive feature selection and task-tailored data views allow the exploration of the whole graph space. The system provides also tools for assessment and display of cluster quality. We demonstrate the usefulness of our system by application to a shareholder network analysis problem based on a large real-world data set. While so far our approach is applied to weighted directed graphs only, it can be used for various graph types.",Tatiana von Landesberger;Melanie Görner;Tobias Schreck,Tatiana von Landesberger;Melanie Gorner;Tobias Schreck,"Interactive Graphics Systems Group, Technische Universität Darmstadt and Fraunhofer IGD, Germany;Interactive Graphics Systems Group, Technische Universität Darmstadt, Germany;Interactive Graphics Systems Group, Technische Universität Darmstadt, Germany",10.1109/tvcg.2006.193;10.1109/tvcg.2008.135;10.1109/infvis.2003.1249011;10.1109/tvcg.2006.147;10.1109/tvcg.2006.193,,53.0,25.0,48.0,724.0,,,visualization large graphs;application shareholder network;set clustering output;weakly connected components;use self,0.6441;0.3520;0.3170;0.3022;0.1117,"[np.int64(-1), -1, -1, -1, -1]",165;-1;-1;-1;-1,165,165
InfoVis,2015,Beyond Memorability: Visualization Recognition and Recall,10.1109/tvcg.2015.2467732,http://dx.doi.org/10.1109/TVCG.2015.2467732,519.0,528.0,J,"In this paper we move beyond memorability and investigate how visualizations are recognized and recalled. For this study we labeled a dataset of 393 visualizations and analyzed the eye movements of 33 participants as well as thousands of participant-generated text descriptions of the visualizations. This allowed us to determine what components of a visualization attract people's attention, and what information is encoded into memory. Our findings quantitatively support many conventional qualitative design guidelines, including that (1) titles and supporting text should convey the message of a visualization, (2) if used appropriately, pictograms do not interfere with understanding and can improve recognition, and (3) redundancy helps effectively communicate the message. Importantly, we show that visualizations memorable “at-a-glance” are also capable of effectively conveying the message of the visualization. Thus, a memorable visualization is often also an effective one.",Michelle A. Borkin;Zoya Bylinskii;Nam Wook Kim;Constance May Bainbridge;Chelsea S. Yeh;Daniel Borkin;Hanspeter Pfister;Aude Oliva,Michelle A. Borkin;Zoya Bylinskii;Nam Wook Kim;Constance May Bainbridge;Chelsea S. Yeh;Daniel Borkin;Hanspeter Pfister;Aude Oliva,"University of British Columbia, Harvard University;Computer Science and Artificial Intelligence Laboratory (CSAIL), Massachusetts Institute of Technology (MIT);School of Engineering & Applied Sciences, Harvard University;Computer Science and Artificial Intelligence Laboratory (CSAIL), Massachusetts Institute of Technology (MIT);School of Engineering & Applied Sciences, Harvard University;University of Michigan;School of Engineering & Applied Sciences, Harvard University;Computer Science and Artificial Intelligence Laboratory (CSAIL), Massachusetts Institute of Technology (MIT)",10.1109/tvcg.2012.197;10.1109/tvcg.2013.234;10.1109/tvcg.2011.193;10.1109/tvcg.2012.233;10.1109/tvcg.2011.175;10.1109/tvcg.2013.234;10.1109/tvcg.2012.215;10.1109/vast.2010.5653598;10.1109/tvcg.2012.245;10.1109/tvcg.2012.221;10.1109/tvcg.2012.197,"Information visualization, memorability, recognition, recall, eye-tracking study",295.0,218.0,48.0,5663.0,,,visualizations memorable;recognized recalled study;titles supporting text;thousands;allowed determine,0.8168;0.1981;0.1948;0.0897;0.0073,"[np.int64(-1), -1, -1, -1, -1]",189;-1;-1;-1;-1,189,189
Vis,2000,multi-user view-dependent rendering,10.1109/visual.2000.885713,http://doi.ieeecomputersociety.org/10.1109/VISUAL.2000.885713,335.0,342.0,C,"We present a novel architecture which allows rendering of a large-shared dataset at interactive rates on an inexpensive workstation. The idea is based on view-dependent rendering on a client-server network. The server stores the large dataset and manages the selection of the various levels of detail while the inexpensive clients receive a stream of update operations that generate the appropriate level of detail in an incremental fashion. These update operations are based on changes in the clients' view-parameters. Our approach dramatically reduces the amount of memory needed by each client and the entire computing system since the dataset is stored only once on the server's local memory. In addition, it decreases the load on the network as results of the incremental update contributed by view-dependent rendering.",Jihad El-Sana,J. El-Sana,"Dept. of Comput. Sci., Ben-Gurion Univ. of the Negev, Beer-Sheva, Israel",10.1109/visual.1999.809877;10.1109/visual.1995.480805,,7.0,1.0,0.0,20.0,,,rendering client server;level incremental fashion;dataset manages selection;update contributed view;memory addition,0.5707;0.3089;0.1946;0.1890;0.1656,"[np.int64(-1), -1, -1, -1, -1]",314;-1;-1;-1;-1,314,314
InfoVis,2008,Spatially Ordered Treemaps,10.1109/tvcg.2008.165,http://dx.doi.org/10.1109/TVCG.2008.165,1348.0,1355.0,J,"Existing treemap layout algorithms suffer to some extent from poor or inconsistent mappings between data order and visual ordering in their representation, reducing their cognitive plausibility. While attempts have been made to quantify this mismatch, and algorithms proposed to minimize inconsistency, solutions provided tend to concentrate on one-dimensional ordering. We propose extensions to the existing squarified layout algorithm that exploit the two-dimensional arrangement of treemap nodes more effectively. Our proposed spatial squarified layout algorithm provides a more consistent arrangement of nodes while maintaining low aspect ratios. It is suitable for the arrangement of data with a geographic component and can be used to create tessellated cartograms for geovisualization. Locational consistency is measured and visualized and a number of layout algorithms are compared. CIELab color space and displacement vector overlays are used to assess and emphasize the spatial layout of treemap nodes. A case study involving locations of tagged photographs in the Flickr database is described.",Jo Wood;Jason Dykes,Jo Wood;Jason Dykes,"School of Informatics, City University, London, UK;School of Informatics, City University, London, UK",10.1109/infvis.2001.963283;10.1109/infvis.2001.963290;10.1109/tvcg.2007.70522;10.1109/tvcg.2007.70529;10.1109/infvis.2001.963283,"Geovisualization, treemaps, cartograms, CIELab, geographic information, tree structures",216.0,113.0,32.0,1570.0,,,spatial layout treemap;flickr database described;displacement vector;representation reducing cognitive;cielab,0.7244;0.2612;0.1402;0.1199;0.0422,"[np.int64(-1), -1, -1, -1, -1]",53;-1;-1;-1;-1,53,53
SciVis,2012,Automatic Detection and Visualization of Qualitative Hemodynamic Characteristics in Cerebral Aneurysms,10.1109/tvcg.2012.202,http://dx.doi.org/10.1109/TVCG.2012.202,2178.0,2187.0,J,"Cerebral aneurysms are a pathological vessel dilatation that bear a high risk of rupture. For the understanding and evaluation of the risk of rupture, the analysis of hemodynamic information plays an important role. Besides quantitative hemodynamic information, also qualitative flow characteristics, e.g., the inflow jet and impingement zone are correlated with the risk of rupture. However, the assessment of these two characteristics is currently based on an interactive visual investigation of the flow field, obtained by computational fluid dynamics (CFD) or blood flow measurements. We present an automatic and robust detection as well as an expressive visualization of these characteristics. The detection can be used to support a comparison, e.g., of simulation results reflecting different treatment options. Our approach utilizes local streamline properties to formalize the inflow jet and impingement zone. We extract a characteristic seeding curve on the ostium, on which an inflow jet boundary contour is constructed. Based on this boundary contour we identify the impingement zone. Furthermore, we present several visualization techniques to depict both characteristics expressively. Thereby, we consider accuracy and robustness of the extracted characteristics, minimal visual clutter and occlusions. An evaluation with six domain experts confirms that our approach detects both hemodynamic characteristics reasonably.",Rocco Gasteiger;Dirk J. Lehmann;Roy van Pelt;Gábor Janiga;Oliver Beuing;Anna Vilanova;Holger Theisel;Bernhard Preim,Rocco Gasteiger;Dirk J. Lehmann;Roy van Pelt;Gábor Janiga;Oliver Beuing;Anna Vilanova;Holger Theisel;Bernhard Preim,"Department of Simulation and Graphics, group Visualization, University of Magdeburg, Germany;Department of Simulation and Graphics, group Visual Computing, University of Magdeburg, Germany;Department of Biomedical Engineering, group of Biomedical Image Analysis, Eindhoven University of Technology, Netherlands;Institute of Fluid Dynamics and Thermodynamics, University of Magdeburg, Germany;Department of Neuroradiology, University Hospital Magdeburg, Germany;Department of Biomedical Engineering, group of Biomedical Image Analysis, Eindhoven University of Technology, Netherlands;Department of Simulation and Graphics, group Visual Computing, University of Magdeburg, Germany;Department of Simulation and Graphics, group Visualization, University of Magdeburg, Germany",10.1109/tvcg.2011.215;10.1109/tvcg.2011.159;10.1109/tvcg.2011.243;10.1109/tvcg.2009.138;10.1109/tvcg.2010.153;10.1109/tvcg.2010.173;10.1109/tvcg.2011.215,"Cerebral aneurysm, Hemodynamic, Inflow jet, Impingement zone, Visualization, Glyph",35.0,24.0,37.0,538.0,,,detects hemodynamic characteristics;computational fluid dynamics;contour constructed based;risk rupture understanding;depict,0.4898;0.4468;0.3354;0.2432;0.1740,"[-1, -1, -1, -1, -1]",-1;-1;-1;-1;-1,,-1
InfoVis,2019,Evaluating an Immersive Space-Time Cube Geovisualization for Intuitive Trajectory Data Exploration,10.1109/tvcg.2019.2934415,http://dx.doi.org/10.1109/TVCG.2019.2934415,514.0,524.0,J,"A Space-Time Cube enables analysts to clearly observe spatio-temporal features in movement trajectory datasets in geovisualization. However, its general usability is impacted by a lack of depth cues, a reported steep learning curve, and the requirement for efficient 3D navigation. In this work, we investigate a Space-Time Cube in the Immersive Analytics domain. Based on a review of previous work and selecting an appropriate exploration metaphor, we built a prototype environment where the cube is coupled to a virtual representation of the analyst's real desk, and zooming and panning in space and time are intuitively controlled using mid-air gestures. We compared our immersive environment to a desktop-based implementation in a user study with 20 participants across 7 tasks of varying difficulty, which targeted different user interface features. To investigate how performance is affected in the presence of clutter, we explored two scenarios with different numbers of trajectories. While the quantitative performance was similar for the majority of tasks, large differences appear when we analyze the patterns of interaction and consider subjective metrics. The immersive version of the Space-Time Cube received higher usability scores, much higher user preference, and was rated to have a lower mental workload, without causing participants discomfort in 25-minute-long VR sessions.",Jorge A. Wagner Filho;Wolfgang Stuerzlinger;Luciana P. Nedel,Jorge A. Wagner Filho;Wolfgang Stuerzlinger;Luciana Nedel,Federal University of Rio Grande do Sul and Simon Fraser University;Simon Fraser University;Federal University of Rio Grande do Sul,10.1109/tvcg.2018.2865191;10.1109/infvis.2004.27;10.1109/tvcg.2018.2865191,"Space-time cube,Trajectory visualization,Immersive analytics",59.0,83.0,59.0,2160.0,,,immersive analytics;space time intuitively;mid air gestures;tasks varying difficulty;25 minute,0.6740;0.3544;0.2332;0.1305;0.0487,"[np.int64(-1), -1, -1, -1, -1]",161;-1;-1;-1;-1,161,161
InfoVis,2005,An optimization-based approach to dynamic visual context management,10.1109/infvis.2005.1532146,http://dx.doi.org/10.1109/INFVIS.2005.1532146,187.0,194.0,C,"We are building an intelligent multimodal conversation system to aid users in exploring large and complex data sets. To tailor to diverse user queries introduced during a conversation, we automate the generation of system responses, including both spoken and visual outputs. In this paper, we focus on the problem of visual context management, a process that dynamically updates an existing visual display to effectively incorporate new information requested by subsequent user queries. Specifically, we develop an optimization based approach to visual context management. Compared to existing approaches, which normally handle predictable visual context updates, our work offers two unique contributions. First, we provide a general computational framework that can effectively manage a visual context for diverse, unanticipated situations encountered in a user system conversation. Moreover, we optimize the satisfaction of both semantic and visual constraints, which otherwise are difficult to balance using simple heuristics. Second, we present an extensible representation model that uses feature based metrics to uniformly define all constraints. We have applied our work to two different applications and our evaluation has shown the promise of this work.",Zhen Wen;Michelle X. Zhou;Vikram Aggarwal,Zhen Wen;M.X. Zhou;V. Aggarwal,"T.J. Watson Research Center, IBM, Hawthorne, NY, USA;T.J. Watson Research Center, IBM, Hawthorne, NY, USA;T.J. Watson Research Center, IBM, Hawthorne, NY, USA",10.1109/infvis.2000.885091;10.1109/infvis.2000.885093;10.1109/infvis.1997.636718;10.1109/infvis.2000.885091,"intelligent multimodal interfaces, visual context management, automated generation of visualization, visual momentum",18.0,1.0,21.0,218.0,,,visual context management;encountered user conversation;automate generation responses;based metrics uniformly;promise work,0.6174;0.3818;0.3717;0.0995;0.0149,"[np.int64(-1), -1, -1, -1, -1]",-1;-1;-1;-1;-1,,-1
Vis,2022,Multiple Forecast Visualizations (MFVs): Trade-offs in Trust and Performance in Multiple COVID-19 Forecast Visualizations,10.1109/tvcg.2022.3209457,http://dx.doi.org/10.1109/TVCG.2022.3209457,12.0,22.0,J,"The prevalence of inadequate SARS-COV-2 (COVID-19) responses may indicate a lack of trust in forecasts and risk communication. However, no work has empirically tested how multiple forecast visualization choices impact trust and task-based performance. The three studies presented in this paper ($N=1299$) examine how visualization choices impact trust in COVID-19 mortality forecasts and how they influence performance in a trend prediction task. These studies focus on line charts populated with real-time COVID-19 data that varied the number and color encoding of the forecasts and the presence of best/worst-case forecasts. The studies reveal that trust in COVID-19 forecast visualizations initially increases with the number of forecasts and then plateaus after 6–9 forecasts. However, participants were most trusting of visualizations that showed less visual information, including a 95% confidence interval, single forecast, and grayscale encoded forecasts. Participants maintained high trust in intervals labeled with 50% and 25% and did not proportionally scale their trust to the indicated interval size. Despite the high trust, the 95% CI condition was the most likely to evoke predictions that did not correspond with the actual COVID-19 trend. Qualitative analysis of participants' strategies confirmed that many participants trusted both the simplistic visualizations and those with numerous forecasts. This work provides practical guides for how COVID-19 forecast visualizations influence trust, including recommendations for identifying the range where forecasts balance trade-offs between trust and task-based performance.",Lace M. K. Padilla;Racquel Fygenson;Spencer C. Castro;Enrico Bertini,Lace Padilla;Racquel Fygenson;Spencer C. Castro;Enrico Bertini,"University of California Merced, USA;New York University, USA;University of California Merced, USA;Northeastern University, USA",10.1109/tvcg.2021.3114803;10.1109/tvcg.2014.2346298;10.1109/tvcg.2019.2934287;10.1109/tvcg.2017.2743898;10.1109/tvcg.2020.3030335;10.1109/tvcg.2018.2864909;10.1109/tvcg.2018.2865193;10.1109/infvis.2004.15;10.1109/tvcg.2021.3114803,"COVID-19,multiple forecast visualizations,uncertainty visualization,line charts,time-series data",,12.0,66.0,2809.0,BP,,visualizations influence trust;covid 19 forecast;interval size;grayscale encoded;confirmed,0.6872;0.4575;0.0894;0.0434;-0.0298,"[np.int64(-1), -1, -1, -1, -1]",168;-1;-1;-1;-1,168,168
VAST,2014,DecisionFlow: Visual Analytics for High-Dimensional Temporal Event Sequence Data,10.1109/tvcg.2014.2346682,http://dx.doi.org/10.1109/TVCG.2014.2346682,1783.0,1792.0,J,"Temporal event sequence data is increasingly commonplace, with applications ranging from electronic medical records to financial transactions to social media activity. Previously developed techniques have focused on low-dimensional datasets (e.g., with less than 20 distinct event types). Real-world datasets are often far more complex. This paper describes DecisionFlow, a visual analysis technique designed to support the analysis of high-dimensional temporal event sequence data (e.g., thousands of event types). DecisionFlow combines a scalable and dynamic temporal event data structure with interactive multi-view visualizations and ad hoc statistical analytics. We provide a detailed review of our methods, and present the results from a 12-person user study. The study results demonstrate that DecisionFlow enables the quick and accurate completion of a range of sequence analysis tasks for datasets containing thousands of event types and millions of individual events.",David Gotz;Harry Stavropoulos,David Gotz;Harry Stavropoulos,University of North Carolina at Chapel Hill;IBM T.J. Watson Research Center,10.1109/tvcg.2013.206;10.1109/tvcg.2012.225;10.1109/tvcg.2011.179;10.1109/infvis.2000.885097;10.1109/vast.2009.5332595;10.1109/vast.2010.5652890;10.1109/tvcg.2009.117;10.1109/vast.2006.261421;10.1109/tvcg.2013.200;10.1109/tvcg.2013.206,"Information Visualization, Temporal Event Sequences, Visual Analytics, Flow Diagrams, Medical Informatics",189.0,129.0,34.0,2726.0,,,event sequence data;statistical analytics;multi view visualizations;decisionflow enables quick;millions,0.6283;0.4229;0.3891;0.3674;0.1215,"[np.int64(-1), -1, -1, -1, -1]",126;-1;-1;-1;-1,126,126
VAST,2011,Analysis of large digital collections with interactive visualization,10.1109/vast.2011.6102462,http://dx.doi.org/10.1109/VAST.2011.6102462,241.0,250.0,C,"To make decisions about the long-term preservation and access of large digital collections, archivists gather information such as the collections' contents, their organizational structure, and their file format composition. To date, the process of analyzing a collection - from data gathering to exploratory analysis and final conclusions - has largely been conducted using pen and paper methods. To help archivists analyze large-scale digital collections for archival purposes, we developed an interactive visual analytics application. The application narrows down different kinds of information about the collection, and presents them as meaningful data views. Multiple views and analysis features can be linked or unlinked on demand to enable researchers to compare and contrast different analyses, and to identify trends. We describe and present two user scenarios to show how the application allowed archivists to learn about a collection with accuracy, facilitated decision-making, and helped them arrive at conclusions.",Weijia Xu;Maria Esteva;Suyog Dott Jain;Varun Jain,Weijia Xu;Maria Esteva;Suyog Dutt Jain;Varun Jain,"University of Texas, Austin, USA;University of Texas, Austin, USA;University of Texas, Austin, USA;University of Texas, Austin, USA",10.1109/infvis.2000.885091;10.1109/tvcg.2008.172;10.1109/tvcg.2009.176;10.1109/vast.2007.4389006;10.1109/infvis.2004.64;10.1109/vast.2010.5652931;10.1109/infvis.1999.801860,"Digital collections, archival analysis, visual anaytics, data curation",19.0,8.0,34.0,717.0,,,digital collections archivists;interactive visual analytics;file format;decision;application narrows different,0.7552;0.5398;0.1837;0.0647;0.0387,"[np.int64(-1), np.int64(-1), -1, -1, -1]",29;201;-1;-1;-1,29;201,29
Vis,2004,Visual Inspection Methods for Quality Control in Automotive Engineering,10.1109/visual.2004.111,http://dx.doi.org/10.1109/VISUAL.2004.111,3.0,3.0,M,"The automotive industry demands visual support for the verification of the quality of their products from the design phase to the manufacturing phase. This implies the need of tools for measurement planning, programming measuring devices, managing measurement data, and the visual exploration of the measurement results. To improve the quality control throughout the whole process chain an integration of such tools in a platform independent framework is crucial. We present eMMA (enhanced Measure Management Application), a client/server system integrating measurement planning, data management, and straightforward as well as sophisticated visual exploration tools in a single framework.",Hans Hagen;Andreas Disch;Jochen Ehret;Ralf Klein;Sascha Köhn;Dirk Zeckzer;Michael Münchhofen,H. Hagen;A. Disch;J. Ehret;R. Klein;S. Kohn;D. Zeckzer;M. Munchhofen,"DFKI GmbH, IVS, Kaiserslautern, Germany and IVs DFKI GmbH Kaiserslautern, Germany;DFKI GmbH, IVS, Kaiserslautern, Germany and IVs DFKI GmbH Kaiserslautern, Germany;DFKI GmbH, IVS, Kaiserslautern, Germany and IVs DFKI GmbH Kaiserslautern, Germany;DFKI GmbH, IVS, Kaiserslautern, Germany and IVs DFKI GmbH Kaiserslautern, Germany;DFKI GmbH, IVS, Kaiserslautern, Germany and IVs DFKI GmbH Kaiserslautern, Germany;DFKI GmbH, IVS, Kaiserslautern, Germany and IVs DFKI GmbH Kaiserslautern, Germany;ProCAEss GmbH Landau, Germany",,,4.0,0.0,0.0,328.0,,,visual exploration measurement;automotive industry demands;platform independent framework;implies need tools;verification,0.5622;0.3738;0.2810;0.2052;0.1541,"[np.int64(-1), -1, -1, -1, -1]",318;-1;-1;-1;-1,318,318
InfoVis,2010,ManiWordle: Providing Flexible Control over Wordle,10.1109/tvcg.2010.175,http://dx.doi.org/10.1109/TVCG.2010.175,1190.0,1197.0,J,"Among the multifarious tag-clouding techniques, Wordle stands out to the community by providing an aesthetic layout, eliciting the emergence of the participatory culture and usage of tag-clouding in the artistic creations. In this paper, we introduce ManiWordle, a Wordle-based visualization tool that revamps interactions with the layout by supporting custom manipulations. ManiWordle allows people to manipulate typography, color, and composition not only for the layout as a whole, but also for the individual words, enabling them to have better control over the layout result. We first describe our design rationale along with the interaction techniques for tweaking the layout. We then present the results both from the preliminary usability study and from the comparative study between ManiWordle and Wordle. The results suggest that ManiWordle provides higher user satisfaction and an efficient method of creating the desired ""art work,"" harnessing the power behind the ever-increasing popularity of Wordle.",Kyle Koh;Bongshin Lee;Bo Hyoung Kim;Jinwook Seo,Kyle Koh;Bongshin Lee;Bohyoung Kim;Jinwook Seo,"Seoul National University, South Korea;Microsoft Research Limited, USA;Seoul National University, South Korea;Seoul National University, South Korea",10.1109/tvcg.2007.70541;10.1109/tvcg.2007.70515;10.1109/tvcg.2009.171;10.1109/vast.2009.5333443;10.1109/infvis.2003.1249031;10.1109/tvcg.2007.70541,"Interaction design, direct manipulation, flexibilty-usability tradeoff, tag-cloud, participatory visualization, user study ",140.0,84.0,30.0,1462.0,,,wordle based visualization;tag clouding artistic;tweaking layout;design rationale;higher user,0.6447;0.4584;0.3590;0.2277;0.1104,"[np.int64(-1), -1, -1, -1, -1]",170;-1;-1;-1;-1,170,170
InfoVis,2015,How do People Make Sense of Unfamiliar Visualizations?: A Grounded Model of Novice's Information Visualization Sensemaking,10.1109/tvcg.2015.2467195,http://dx.doi.org/10.1109/TVCG.2015.2467195,499.0,508.0,J,"In this paper, we would like to investigate how people make sense of unfamiliar information visualizations. In order to achieve the research goal, we conducted a qualitative study by observing 13 participants when they endeavored to make sense of three unfamiliar visualizations (i.e., a parallel-coordinates plot, a chord diagram, and a treemap) that they encountered for the first time. We collected data including audio/video record of think-aloud sessions and semi-structured interview; and analyzed the data using the grounded theory method. The primary result of this study is a grounded model of NOvice's information VIsualization Sensemaking (NOVIS model), which consists of the five major cognitive activities: 1 encountering visualization, 2 constructing a frame, 3 exploring visualization, 4 questioning the frame, and 5 floundering on visualization. We introduce the NOVIS model by explaining the five activities with representative quotes from our participants. We also explore the dynamics in the model. Lastly, we compare with other existing models and share further research directions that arose from our observations.",Sukwon Lee;Sung-Hee Kim;Ya-Hsin Hung;Heidi Lam;Youn-Ah Kang;Ji Soo Yi,Sukwon Lee;Sung-Hee Kim;Ya-Hsin Hung;Heidi Lam;Youn-Ah Kang;Ji Soo Yi,"School of Industrial Engineering, Purdue University, West Lafayette, IN, USA;Department of Computer Science, University of British Columbia, Vancouver, BC, Canada;School of Industrial Engineering, Purdue University, West Lafayette, IN, USA;Google Inc., Mountain View, CA, USA;Techno-Art Division, Yonsei University, Incheon, South Korea;School of Industrial Engineering, Purdue University, West Lafayette, IN, USA",10.1109/tvcg.2013.234;10.1109/tvcg.2014.2346984;10.1109/tvcg.2010.164;10.1109/vast.2011.6102435;10.1109/tvcg.2014.2346452;10.1109/tvcg.2010.177;10.1109/tvcg.2014.2346481;10.1109/tvcg.2010.179;10.1109/tvcg.2007.70515;10.1109/tvcg.2013.234,"Sensemaking model, information visualization, novice users, grounded theory, qualitative study",147.0,91.0,48.0,4623.0,,,visualization sensemaking;paper like investigate;quotes;including audio video;primary,0.7649;0.1343;0.0587;0.0435;0.0190,"[np.int64(-1), -1, -1, -1, -1]",269;-1;-1;-1;-1,269,269
InfoVis,1998,Dynamic aggregation with circular visual designs,10.1109/infvis.1998.729557,http://dx.doi.org/10.1109/INFVIS.1998.729557,35.0,,C,"One very effective method for managing large data sets is aggregation or binning. We consider two aggregation methods that are tightly coupled with interactive manipulation and the visual representation of the data. Through this integration we hope to provide effective support for the aggregation process, specifically by enabling: 1) automatic aggregation, 2) continuous change and control of the aggregation level, 3) spatially based aggregates, 4) context maintenance across different aggregate levels, and 5) feedback on the level of aggregation.",Mei C. Chuah,M.C. Chuah,"School of Computer Science, Carnegie Mellon University, Pittsburgh, PA, USA",10.1109/infvis.1997.636787;10.1109/visual.1992.235206,,128.0,35.0,13.0,331.0,,,aggregation binning;interactive manipulation visual;context maintenance different;specifically;hope,0.6160;0.4696;0.1916;0.1244;0.0346,"[np.int64(-1), -1, -1, -1, -1]",228;-1;-1;-1;-1,228,228
Vis,2023,"2D, 2.5D, or 3D? An Exploratory Study on Multilayer Network Visualisations in Virtual Reality",10.1109/tvcg.2023.3327402,http://dx.doi.org/10.1109/TVCG.2023.3327402,469.0,479.0,J,"Relational information between different types of entities is often modelled by a multilayer network (MLN) – a network with subnetworks represented by layers. The layers of an MLN can be arranged in different ways in a visual representation, however, the impact of the arrangement on the readability of the network is an open question. Therefore, we studied this impact for several commonly occurring tasks related to MLN analysis. Additionally, layer arrangements with a dimensionality beyond 2D, which are common in this scenario, motivate the use of stereoscopic displays. We ran a human subject study utilising a Virtual Reality headset to evaluate 2D, 2.5D, and 3D layer arrangements. The study employs six analysis tasks that cover the spectrum of an MLN task taxonomy, from path finding and pattern identification to comparisons between and across layers. We found no clear overall winner. However, we explore the task-to-arrangement space and derive empirical-based recommendations on the effective use of 2D, 2.5D, and 3D layer arrangements for MLNs.",Stefan P. Feyer;Bruno Pinaud;Stephen G. Kobourov;Nicolas Brich;Michael Krone;Andreas Kerren;Michael Behrisch 0001;Falk Schreiber;Karsten Klein 0001,Stefan P. Feyer;Bruno Pinaud;Stephen Kobourov;Nicolas Brich;Michael Krone;Andreas Kerren;Michael Behrisch;Falk Schreiber;Karsten Klein,"Life Science Informatics, University of Konstanz, Germany;Univ. Bordeaux, CNRS, Bordeaux INP, LaBRI, UMR 5800, France;University of Arizona, USA;University of Tübingen, Germany;University of Tübingen, Germany;Linköping University, Sweden;Utrecht University, NL;University of Konstanz, Germany;Life Science Informatics, University of Konstanz, Germany",0.1109/infvis.2005.1532136;10.1109/tvcg.2016.2599107;10.1109/tvcg.2020.3030371;10.1109/tvcg.2021.3114863;10.1109/tvcg.2014.2346441;10.1109/tvcg.2020.3030427;10.1109/tvcg.2018.2865192,"Network,Guidelines,VisDesign,HumanQuant,CompSystems",,3.0,67.0,671.0,,,arrangement readability network;utilising virtual reality;layers layers;dimensionality 2d common;different,0.5976;0.3830;0.3112;0.3006;0.0549,"[np.int64(-1), -1, -1, -1, -1]",213;-1;-1;-1;-1,213,213
Vis,1991,Gray scale diagrams as business charts,10.1109/visual.1991.175791,http://dx.doi.org/10.1109/VISUAL.1991.175791,140.0,147.0,C,"Gray-scale diagrams, which can present large amounts of quantitative information in a compact format, are considered as a candidate for business charts. Hundreds of data points can easily be represented in one diagram, using small gray-scale squares (or tiles), without visually overloading a viewer. An experiment was done to compare the subjects' responses to questions from three types of charts, traditional column and line charts and gray-scale tile charts. The results showed that questions were answered more correctly and more quickly using gray-scale tile charts than using traditional charts. However, subjects reported they experienced more strain using gray-scale charts.&lt;&lt;ETX&gt;&gt;",W. R. Feeney,W.R. Feeney,"Infomation and Decision Systems Department, San Diego State University, San Diego, CA, USA",,,1.0,1.0,12.0,83.0,,,business charts;visually overloading viewer;scale tile;subjects reported experienced;answered,0.6852;0.2704;0.2298;0.1779;-0.0573,"[np.int64(-1), -1, -1, -1, -1]",90;-1;-1;-1;-1,90,90
Vis,2024,StuGPTViz: A Visual Analytics Approach to Understand Student-ChatGPT Interactions,10.1109/tvcg.2024.3456363,http://dx.doi.org/10.1109/TVCG.2024.3456363,908.0,918.0,J,"The integration of Large Language Models (LLMs), especially ChatGPT, into education is poised to revolutionize students' learning experiences by introducing innovative conversational learning methodologies. To empower students to fully leverage the capabilities of ChatGPT in educational scenarios, understanding students' interaction patterns with ChatGPT is crucial for instructors. However, this endeavor is challenging due to the absence of datasets focused on student-ChatGPT conversations and the complexities in identifying and analyzing the evolutional interaction patterns within conversations. To address these challenges, we collected conversational data from 48 students interacting with ChatGPT in a master's level data visualization course over one semester. We then developed a coding scheme, grounded in the literature on cognitive levels and thematic analysis, to categorize students' interaction patterns with ChatGPT. Furthermore, we present a visual analytics system, StuGPTViz, that tracks and compares temporal patterns in student prompts and the quality of ChatGPT's responses at multiple scales, revealing significant pedagogical insights for instructors. We validated the system's effectiveness through expert interviews with six data visualization instructors and three case studies. The results confirmed StuGPTViz's capacity to enhance educators' insights into the pedagogical value of ChatGPT. We also discussed the potential research opportunities of applying visual analytics in education and developing AI-driven personalized learning solutions.",Zixin Chen;Jiachen Wang;Meng Xia 0002;Kento Shigyo;Dingdong Liu;Rong Zhang 0011;Huamin Qu,Zixin Chen;Jiachen Wang;Meng Xia;Kento Shigyo;Dingdong Liu;Rong Zhang;Huamin Qu,"Hong Kong University of Science and Technology, Hong Kong, China;Hong Kong University of Science and Technology, Hong Kong, China;Texas A&M University, College Station, Texas, the United States;Hong Kong University of Science and Technology, Hong Kong, China;Hong Kong University of Science and Technology, Hong Kong, China;Hong Kong University of Science and Technology, Hong Kong, China;Hong Kong University of Science and Technology, Hong Kong, China",10.1109/tvcg.2023.3327378;10.1109/tvcg.2023.3327165;10.1109/tvcg.2013.162;10.1109/tvcg.2016.2598444;10.1109/vast.2011.6102472;10.1109/tvcg.2015.2467555;10.1109/infvis.2005.1532152;10.1109/tvcg.2014.2346481,"Visual analytics for education,ChatGPT for education,,,student-ChatGPT interaction",,0.0,77.0,429.0,,,visualization instructors;large language models;value chatgpt discussed;evolutional interaction patterns;studies results,0.5354;0.3632;0.2603;0.2269;0.1066,"[np.int64(-1), -1, -1, -1, -1]",211;-1;-1;-1;-1,211,211
Vis,2005,Extracting higher order critical points and topological simplification of 3D vector fields,10.1109/visual.2005.1532842,http://dx.doi.org/10.1109/VISUAL.2005.1532842,559.0,566.0,C,"This paper presents an approach to extracting and classifying higher order critical points of 3D vector fields. To do so, we place a closed convex surface s around the area of interest. Then we show that the complete 3D classification of a critical point into areas of different flow behavior is equivalent to extracting the topological skeleton of an appropriate 2D vector field on s, if each critical point is equipped with an additional bit of information. Out of this skeleton, we create an icon which replaces the complete topological structure inside s for the visualization. We apply our method to find a simplified visual representation of clusters of critical points, leading to expressive visualizations of topologically complex 3D vector fields.",Tino Weinkauf;Holger Theisel;Kuangyu Shi;Hans-Christian Hege;Hans-Peter Seidel,T. Weinkauf;H. Theisel;K. Shi;H.-C. Hege;H.-P. Seidel,"ZIB Berlin, Germany;MPI Saarbrücken, Germany;MPI Saarbrücken, Germany;ZIB Berlin, Germany;MPI Saarbrücken, Germany",10.1109/visual.1999.809907;10.1109/visual.2002.1183786;10.1109/visual.2000.885714;10.1109/visual.1991.175773;10.1109/visual.2000.885716;10.1109/visual.2001.964507;10.1109/visual.2003.1250376;10.1109/visual.1999.809907,,95.0,15.0,22.0,261.0,,,3d vector fields;expressive visualizations topologically;clusters critical;skeleton;method simplified,0.5923;0.5839;0.2501;0.0720;0.0347,"[np.int64(-1), np.int64(-1), -1, -1, -1]",40;306;-1;-1;-1,40;306,40
InfoVis,2019,The Perceptual Proxies of Visual Comparison,10.1109/tvcg.2019.2934786,http://dx.doi.org/10.1109/TVCG.2019.2934786,1012.0,1021.0,J,"Perceptual tasks in visualizations often involve comparisons. Of two sets of values depicted in two charts, which set had values that were the highest overall? Which had the widest range? Prior empirical work found that the performance on different visual comparison tasks (e.g., “biggest delta”, “biggest correlation”) varied widely across different combinations of marks and spatial arrangements. In this paper, we expand upon these combinations in an empirical evaluation of two new comparison tasks: the “biggest mean” and “biggest range” between two sets of values. We used a staircase procedure to titrate the difficulty of the data comparison to assess which arrangements produced the most precise comparisons for each task. We find visual comparisons of biggest mean and biggest range are supported by some chart arrangements more than others, and that this pattern is substantially different from the pattern for other tasks. To synthesize these dissonant findings, we argue that we must understand which features of a visualization are actually used by the human visual system to solve a given task. We call these perceptual proxies. For example, when comparing the means of two bar charts, the visual system might use a “Mean length” proxy that isolates the actual lengths of the bars and then constructs a true average across these lengths. Alternatively, it might use a “Hull Area” proxy that perceives an implied hull bounded by the bars of each chart and then compares the areas of these hulls. We propose a series of potential proxies across different tasks, marks, and spatial arrangements. Simple models of these proxies can be empirically evaluated for their explanatory power by matching their performance to human performance across these marks, arrangements, and tasks. We use this process to highlight candidates for perceptual proxies that might scale more broadly to explain performance in visual comparison.",Nicole Jardine;Brian D. Ondov;Niklas Elmqvist;Steven Franconeri,Nicole Jardine;Brian D. Ondov;Niklas Elmqvist;Steven Franconeri,"Cook County Assessor's Office, Northwestern University, Chicago;National Institutes of Health, Bethesda, USA and University of Maryland, College Park, USA;University of Maryland, College Park, USA;Cook County Assessor's Office, Northwestern University, Evanston, USA",10.1109/infvis.2005.1532136;10.1109/tvcg.2015.2466971;10.1109/tvcg.2017.2744199;10.1109/tvcg.2014.2346979;10.1109/tvcg.2010.162;10.1109/tvcg.2018.2864884;10.1109/tvcg.2007.70515,"Graphical perception,visual perception,visual comparison,crowdsourced evaluation",27.0,29.0,29.0,1253.0,HM,,visualizations involve comparisons;true average lengths;hull area proxy;actually used human;bar,0.6987;0.2348;0.2001;0.1303;0.1183,"[np.int64(-1), -1, -1, -1, -1]",320;-1;-1;-1;-1,320,320
Vis,2007,Efficient Visualization of Lagrangian Coherent Structures by filtered AMR Ridge Extraction,10.1109/tvcg.2007.70554,http://dx.doi.org/10.1109/TVCG.2007.70554,1456.0,1463.0,J,"This paper presents a method for filtered ridge extraction based on adaptive mesh refinement. It is applicable in situations where the underlying scalar field can be refined during ridge extraction. This requirement is met by the concept of Lagrangian coherent structures which is based on trajectories started at arbitrary sampling grids that are independent of the underlying vector field. The Lagrangian coherent structures are extracted as ridges in finite Lyapunov exponent fields computed from these grids of trajectories. The method is applied to several variants of finite Lyapunov exponents, one of which is newly introduced. High computation time due to the high number of required trajectories is a main drawback when computing Lyapunov exponents of 3-dimensional vector fields. The presented method allows a substantial speed-up by avoiding the seeding of trajectories in regions where no ridges are present or do not satisfy the prescribed filter criteria such as a minimum finite Lyapunov exponent.",Filip Sadlo;Ronald Peikert,Filip Sadlo;Ronald Peikert,"ETH Zurich, Switzerland;ETH Zurich, Switzerland",10.1109/visual.1999.809896;10.1109/visual.2004.99;10.1109/tvcg.2007.70551;10.1109/visual.1999.809896,"Ridge extraction, flow visualization, coherent structures, vector field topology, unsteady vector fields",213.0,127.0,30.0,778.0,,,filtered ridge extraction;computed grids trajectories;finite lyapunov exponents;field lagrangian;situations underlying,0.5971;0.5252;0.3308;0.2010;-0.1140,"[np.int64(-1), np.int64(-1), -1, -1, -1]",87;239;-1;-1;-1,87;239,87
InfoVis,2000,"Creativity, complexity, and precision: information visualization for (landscape) architecture",10.1109/infvis.2000.885105,http://dx.doi.org/10.1109/INFVIS.2000.885105,167.0,171.0,C,"Drawing on ethnographic studies of (landscape) architects at work, this paper presents a human-centered approach to information visualization. A 3D collaborative electronic workspace allows people to configure, save and browse arrangements of heterogeneous work materials. Spatial arrangements and links are created and maintained as an integral part of ongoing work with 'live' documents and objects. The result is an extension of the physical information space of the architects' studio that utilizes the potential of electronic data storage, visualization and network technologies to support work with information in context.",Monika Büscher;Dan Shapiro;Michael Christensen 0002;Preben Mogensen 0002;Peter Ørbæk,M. Buscher;D. Shapiro;M. Christensen;P. Mogensen;P. Orbaek,"Department of Computer Science, University of Århus, Aarhus, Denmark;Department of Computer Science, University of Århus, Aarhus, Denmark;Department of Computer Science, University of Århus, Aarhus, Denmark;Department of Sociology, Lancaster University, Lancaster, UK;Department of Sociology, Lancaster University, Lancaster, UK",,"Information visualization, architecture,work materials, context,spatio-temporal order, electronic workspace ",11.0,2.0,11.0,171.0,,,collaborative electronic workspace;visualization 3d;studies landscape architects;data;integral ongoing,0.6154;0.4276;0.4183;0.1960;0.0039,"[np.int64(-1), -1, -1, -1, -1]",231;-1;-1;-1;-1,231,231
Vis,2023,Dead or Alive: Continuous Data Profiling for Interactive Data Science,10.1109/tvcg.2023.3327367,http://dx.doi.org/10.1109/TVCG.2023.3327367,197.0,207.0,J,"Profiling data by plotting distributions and analyzing summary statistics is a critical step throughout data analysis. Currently, this process is manual and tedious since analysts must write extra code to examine their data after every transformation. This inefficiency may lead to data scientists profiling their data infrequently, rather than after each transformation, making it easy for them to miss important errors or insights. We propose continuous data profiling as a process that allows analysts to immediately see interactive visual summaries of their data throughout their data analysis to facilitate fast and thorough analysis. Our system, AutoProfiler, presents three ways to support continuous data profiling: (1) it automatically displays data distributions and summary statistics to facilitate data comprehension; (2) it is live, so visualizations are always accessible and update automatically as the data updates; (3) it supports follow up analysis and documentation by authoring code for the user in the notebook. In a user study with 16 participants, we evaluate two versions of our system that integrate different levels of automation: both automatically show data profiles and facilitate code authoring, however, one version updates reactively (“live”) and the other updates only on demand (“dead”). We find that both tools, dead or alive, facilitate insight discovery with 91% of user-generated insights originating from the tools rather than manual profiling code written by users. Participants found live updates intuitive and felt it helped them verify their transformations while those with on-demand profiles liked the ability to look at past visualizations. We also present a longitudinal case study on how AutoProfiler helped domain scientists find serendipitous insights about their data through automatic, live data profiles. Our results have implications for the design of future tools that offer automated data analysis support.",Will Epperson;Vaishnavi Gorantla;Dominik Moritz;Adam Perer,Will Epperson;Vaishnavi Gorantla;Dominik Moritz;Adam Perer,"Carnegie Mellon University, USA;Carnegie Mellon University, USA;Carnegie Mellon University, USA;Carnegie Mellon University, USA",0.1109/tvcg.2018.2865040;10.1109/tvcg.2012.219;10.1109/tvcg.2015.2467191,"Data Profiling,Data Quality,Exploratory Data Analysis,Interactive Data Science",,7.0,51.0,1797.0,HM,,data scientists profiling;past visualizations;live updates intuitive;verify transformations;easy,0.6679;0.3681;0.2892;0.1827;0.0973,"[np.int64(-1), -1, -1, -1, -1]",76;-1;-1;-1;-1,76,76
Vis,1992,Visualization of simulated airflow in a clean room,10.1109/visual.1992.235213,http://dx.doi.org/10.1109/VISUAL.1992.235213,156.0,163.0,C,"Techniques for visualizing a simulated air flow in a clean room are developed by using an efficient cell traverse of tetrahedral cells generated from irregular volumes. The proposed techniques, probing and stream line display, are related to the measurement techniques used in actual clean rooms. The efficient traverse makes it possible to move freely around a given irregular volume and to spawn off stream lines. A successful application of these techniques to a problem in a clean room is also described.&lt;&lt;ETX&gt;&gt;",Koji Koyamada,K. Koyamada,"Tokyo Research Laboratory, IBM Japan Limited, Japan",10.1109/visual.1991.175771;10.1109/visual.1991.175771,,12.0,7.0,9.0,101.0,,,visualizing simulated air;efficient cell;room developed using;display related measurement;problem clean,0.6619;0.3495;0.3461;0.2227;0.2006,"[np.int64(-1), -1, -1, -1, -1]",240;-1;-1;-1;-1,240,240
VAST,2010,An exploratory study of co-located collaborative visual analytics around a tabletop display,10.1109/vast.2010.5652880,http://dx.doi.org/10.1109/VAST.2010.5652880,179.0,186.0,C,"Co-located collaboration can be extremely valuable during complex visual analytics tasks. This paper presents an exploratory study of a system designed to support collaborative visual analysis tasks on a digital tabletop display. Fifteen participant pairs employed Cam-biera, a visual analytics system, to solve a problem involving 240 digital documents. Our analysis, supported by observations, system logs, questionnaires, and interview data, explores how pairs approached the problem around the table. We contribute a unique, rich understanding of how users worked together around the table and identify eight types of collaboration styles that can be used to identify how closely people work together while problem solving. We show how the closeness of teams' collaboration influenced how well they performed on the task overall. We further discuss the role of the tabletop for visual analytics tasks and derive novel design implications for future co-located collaborative tabletop problem solving systems.",Petra Isenberg;Danyel Fisher;Meredith Ringel Morris;Kori Inkpen;Mary Czerwinski,Petra Isenberg;Danyel Fisher;Meredith Ringel Morris;Kori Inkpen;Mary Czerwinski,"Microsoft Research Limited, USA and INRIA, France;Microsoft Research Limited, USA;Microsoft Research Limited, USA;Microsoft Research Limited, USA;Microsoft Research Limited, USA",10.1109/vast.2006.261439;10.1109/vast.2007.4389006;10.1109/vast.2006.261415;10.1109/tvcg.2007.70577;10.1109/vast.2008.4677358;10.1109/tvcg.2007.70568;10.1109/vast.2006.261420;10.1109/vast.2006.261439,,127.0,71.0,22.0,816.0,HM,,collaborative visual analysis;tabletop problem;logs questionnaires interview;biera;worked,0.7102;0.3995;0.1447;0.1400;0.0325,"[np.int64(-1), -1, -1, -1, -1]",193;-1;-1;-1;-1,193,193
Vis,2009,Color Seamlessness in Multi-Projector Displays Using Constrained Gamut Morphing,10.1109/tvcg.2009.124,http://dx.doi.org/10.1109/TVCG.2009.124,1317.0,1326.0,J,"Multi-projector displays show significant spatial variation in 3D color gamut due to variation in the chromaticity gamuts across the projectors, vignetting effect of each projector and also overlap across adjacent projectors. In this paper we present a new constrained gamut morphing algorithm that removes all these variations and results in true color seamlessness across tiled multi-projector displays. Our color morphing algorithm adjusts the intensities of light from each pixel of each projector precisely to achieve a smooth morphing from one projector's gamut to the other's through the overlap region. This morphing is achieved by imposing precise constraints on the perceptual difference between the gamuts of two adjacent pixels. In addition, our gamut morphing assures a C1 continuity yielding visually pleasing appearance across the entire display. We demonstrate our method successfully on a planar and a curved display using both low and high-end projectors. Our approach is completely scalable, efficient and automatic. We also demonstrate the real-time performance of our image correction algorithm on GPUs for interactive applications. To the best of our knowledge, this is the first work that presents a scalable method with a strong foundation in perception and realizes, for the first time, a truly seamless display where the number of projectors cannot be deciphered.",Behzad Sajadi;Maxim Lazarov;M. Gopi 0001;Aditi Majumder,Behzad Sajadi;Maxim Lazarov;M. Gopi;Aditi Majumder,"Computer Science Department, University of California, Irvine, USA;Computer Science Department, University of California, Irvine, USA;Computer Science Department, University of California, Irvine, USA;Computer Science Department, University of California, Irvine, USA",10.1109/visual.2001.964508;10.1109/visual.2002.1183793;10.1109/visual.2000.885684;10.1109/visual.1999.809883;10.1109/tvcg.2007.70586;10.1109/tvcg.2006.121;10.1109/visual.2001.964508,"Color Calibration, Multi-Projector Displays, Tiled Displays",87.0,43.0,19.0,738.0,,,morphing projector gamut;gpus;significant spatial variation;assures c1 continuity;realizes time truly,0.6748;0.2768;0.1986;0.0790;0.0175,"[np.int64(-1), -1, -1, -1, -1]",22;-1;-1;-1;-1,22,22
Vis,2024,“I Came Across a Junk”: Understanding Design Flaws of Data Visualization from the Public's Perspective,10.1109/tvcg.2024.3456341,http://dx.doi.org/10.1109/TVCG.2024.3456341,393.0,403.0,J,"The visualization community has a rich history of reflecting upon visualization design flaws. Although research in this area has remained lively, we believe it is essential to continuously revisit this classic and critical topic in visualization research by incorporating more empirical evidence from diverse sources, characterizing new design flaws, building more systematic theoretical frameworks, and understanding the underlying reasons for these flaws. To address the above gaps, this work investigated visualization design flaws through the lens of the public, constructed a framework to summarize and categorize the identified flaws, and explored why these flaws occur. Specifically, we analyzed 2227 flawed data visualizations collected from an online gallery and derived a design task-associated taxonomy containing 76 specific design flaws. These flaws were further classified into three high-level categories (i.e., misinformation, uninformativeness, unsociability) and ten subcategories (e.g., inaccuracy, unfairness, ambiguity). Next, we organized five focus groups to explore why these design flaws occur and identified seven causes of the flaws. Finally, we proposed a research agenda for combating visualization design flaws and summarize nine research opportunities.",Xingyu Lan;Yu Liu,Xingyu Lan;Yu Liu,"Fudan University, China;University of Edinburgh, U.K.",10.1109/tvcg.2023.3326914;10.1109/tvcg.2022.3209490;10.1109/tvcg.2021.3114830;10.1109/tvcg.2012.197;10.1109/tvcg.2013.234;10.1109/tvcg.2014.2346984;10.1109/tvcg.2021.3114835;10.1109/tvcg.2021.3114804;10.1109/tvcg.2007.70535;10.1109/tvcg.2023.3327385;10.1109/tvcg.2016.2598920;10.1109/tvcg.2018.2865240;10.1109/tvcg.2014.2346419;10.1109/tvcg.2021.3114959;10.1109/tvcg.2023.3327158;10.1109/tvcg.2019.2934538,"Visualization Design,General Public,,,Chart Junk,Deceptive Visualization,Misinformation,User Experience",,0.0,75.0,326.0,HM,,combating visualization design;inaccuracy unfairness ambiguity;online gallery;associated taxonomy containing;2227,0.8039;0.2087;0.1297;0.0192;-0.0595,"[np.int64(-1), -1, -1, -1, -1]",187;-1;-1;-1;-1,187,187
Vis,2010,Articulated Planar Reformation for Change Visualization in Small Animal Imaging,10.1109/tvcg.2010.134,http://dx.doi.org/10.1109/TVCG.2010.134,1396.0,1404.0,J,"The analysis of multi-timepoint whole-body small animal CT data is greatly complicated by the varying posture of the subject at different timepoints. Due to these variations, correctly relating and comparing corresponding regions of interest is challenging.In addition, occlusion may prevent effective visualization of these regions of interest. To address these problems, we have developed a method that fully automatically maps the data to a standardized layout of sub-volumes, based on an articulated atlas registration.We have dubbed this process articulated planar reformation, or APR. A sub-volume can be interactively selected for closer inspection and can be compared with the corresponding sub-volume at the other timepoints, employing a number of different comparative visualization approaches. We provide an additional tool that highlights possibly interesting areas based on the change of bone density between timepoints. Furthermore we allow visualization of the local registration error, to give an indication of the accuracy of the registration. We have evaluated our approach on a case that exhibits cancer-induced bone resorption.",Peter Kok;Martin Baiker;Emile A. Hendriks;Frits H. Post;Jouke Dijkstra;Clemens W. G. M. Löwik;Boudewijn P. F. Lelieveldt;Charl P. Botha,Peter Kok;Martin Baiker;Emile A. Hendriks;Frits H. Post;Jouke Dijkstra;Clemens W.G.M. Lowik;Boudewijn P.F. Lelieveldt;Charl P. Botha,"Division of Image Processing, Leiden University Medical Center, Netherlands and Computer Graphics section Department of Mediamatics, Delft University of Technnology, Netherlands;Division of Image Processing, Leiden University Medical Center, Netherlands;Vision Lab, Department of Mediamatics, Delft University of Technnology, Netherlands;Computer Graphics section Department of Mediamatics, Delft University of Technnology, Netherlands;Division of Image Processing, Leiden University Medical Center, Netherlands;Department of Endocrinology, Leiden University Medical Center, Netherlands;Division of Image Processing, Leiden University Medical Center, Netherlands and Vision Lab, Department of Mediamatics, Delft University of Technnology, Netherlands;Division of Image Processing, Leiden University Medical Center, Netherlands and Computer Graphics section Department of Mediamatics, Delft University of Technnology, Netherlands",10.1109/tvcg.2009.169;10.1109/visual.2002.1183754;10.1109/visual.2003.1250400;10.1109/tvcg.2006.140;10.1109/tvcg.2008.143;10.1109/tvcg.2006.164;10.1109/tvcg.2009.111;10.1109/tvcg.2009.169,"Small animal imaging, comparative visualization, multi-timepoint, molecular imaging, articulated planar reformation",44.0,22.0,28.0,439.0,,,animal ct data;articulated planar reformation;automatically maps data;registration error indication;timepoints employing number,0.5875;0.3796;0.2212;0.1676;0.0938,"[np.int64(-1), -1, -1, -1, -1]",63;-1;-1;-1;-1,63,63
Vis,1998,Pixel masks for screen-door transparency,10.1109/visual.1998.745323,http://dx.doi.org/10.1109/VISUAL.1998.745323,351.0,358.0,C,"Rendering objects transparently gives additional insight in complex and overlapping structures. However, traditional techniques for the rendering of transparent objects such as alpha blending are not very well suited for the rendering of multiple transparent objects in dynamic scenes. Screen door transparency is a technique to render transparent objects in a simple and efficient way: no sorting is required and intersecting polygons can be handled without further preprocessing. With this technique, polygons are rendered through a mask: only where the mask is present, pixels are set. However, artifacts such as incorrect opacities and distracting patterns can easily occur if the masks are not carefully designed. The requirements on the masks are considered. Next, three algorithms are presented for the generation of pixel masks. One algorithm is designed for the creation of small (e.g. 4/spl times/4) masks. The other two algorithms can be used for the creation of larger masks (e.g. 32/spl times/32). For each of these algorithms, results are presented and discussed.",Jurriaan D. Mulder;Frans C. A. Groen;Jarke J. van Wijk,J.D. Mulder;F.C.A. Groen;J.J. van Wijk,"Center of Mathematics and Computer Science, Amsterdam, Netherlands;Faculty of Mathematics, Computer Science, Physics, and Astronomy, University of Amsterdam, Netherlands;Faculty of Mathematics and Computer Science, Eindhovan University of Technology, Netherlands",10.1109/visual.1990.146361;10.1109/visual.1990.146361,Screen-Door Transparency,40.0,4.0,11.0,135.0,,,techniques rendering transparent;intersecting polygons;scenes screen door;algorithm designed creation;32,0.6147;0.3273;0.3244;0.1795;0.0310,"[np.int64(-1), -1, -1, -1, -1]",57;-1;-1;-1;-1,57,57
Vis,2000,Visualizing high-dimensional predictive model quality,10.1109/visual.2000.885740,http://dx.doi.org/10.1109/VISUAL.2000.885740,493.0,496.0,C,"Using inductive learning techniques to construct classification models from large, high-dimensional data sets is a useful way to make predictions in complex domains. However, these models can be difficult for users to understand. We have developed a set of visualization methods that help users to understand and analyze the behavior of learned models, including techniques for high-dimensional data space projection, display of probabilistic predictions, variable/class correlation, and instance mapping. We show the results of applying these techniques to models constructed from a benchmark data set of census data, and draw conclusions about the utility of these methods for model understanding.",Penny Rheingans;Marie desJardins,P. Rheingans;M. DesJardins,"Artificial Intelligence Center, SRI International, Inc., USA;Department of Computer Science and Electrical Engineering, University of Maryland Baltimore County, USA",10.1109/visual.1997.663922;10.1109/infvis.1998.729565;10.1109/visual.1990.146402;10.1109/visual.1997.663868;10.1109/visual.1997.663922,,57.0,12.0,14.0,166.0,,,using inductive learning;set visualization methods;census data;users understand developed;high,0.4724;0.3630;0.2960;0.2482;-0.0118,"[-1, -1, -1, -1, -1]",-1;-1;-1;-1;-1,,-1
Vis,1996,Flexible information visualization of multivariate data from biological sequence similarity searches,10.1109/visual.1996.567796,http://dx.doi.org/10.1109/VISUAL.1996.567796,133.0,140.0,C,"Information visualization faces challenges presented by the need to represent abstract data and the relationships within the data. Previously, we presented a system for visualizing similarities between a single DNA sequence and a large database of other DNA sequences (E.H. Chi et al., 1995). Similarity algorithms generate similarity information in textual reports that can be hundreds or thousands of pages long. Our original system visualized the most important variables from these reports. However, the biologists we work with found this system so useful they requested visual representations of other variables. We present an enhanced system for interactive exploration of this multivariate data. We identify a larger set of useful variables in the information space. The new system involves more variables, so it focuses on exploring subsets of the data. We present an interactive system allowing mapping of different variables to different axes, incorporating animation using a time axis, and providing tools for viewing subsets of the data. Detail-on-demand is preserved by hyperlinks to the analysis reports. We present three case studies illustrating the use of these techniques. The combined technique of applying a time axis with a 3D scatter plot and query filters to visualization of biological sequence similarity data is both powerful and novel.",Ed Huai-hsin Chi;John Riedl;Elizabeth Shoop;John V. Carlis;Ernest Retzel;Phillip Barry,E.H.-H. Chi;J. Riedl;E. Shoop;J.V. Carlis;E. Retzel;P. Barry,"Computational Biology Centers, Medical School, University of Minnesota, Minneapolis, MN, USA;Department of Computer Science, University of Minnesota, Minneapolis, MN, USA;Department of Computer Science, University of Minnesota, Minneapolis, MN, USA;Computer Science Department, University of Minnesota, Minneapolis, MN, USA;Computer Science Department, University of Minnesota, Minneapolis, MN, USA;Computer Science Department, University of Minnesota, USA",10.1109/visual.1993.398883;10.1109/visual.1990.146402;10.1109/visual.1995.480794;10.1109/visual.1993.398883,"Information Visualization, Biomedical Visualization, Multimodal and Multidimensional Visualization, Applications of Visualization",41.0,10.0,19.0,119.0,,,visualization biological sequence;similarities;hyperlinks analysis reports;3d scatter;variables present,0.6690;0.3110;0.3097;0.1536;0.0746,"[np.int64(-1), -1, -1, -1, -1]",117;-1;-1;-1;-1,117,117
Vis,2005,Eyegaze analysis of displays with combined 2D and 3D views,10.1109/visual.2005.1532837,http://dx.doi.org/10.1109/VISUAL.2005.1532837,519.0,526.0,C,"Displays combining both 2D and 3D views have been shown to support higher performance on certain visualization tasks. However, it is not clear how best to arrange a combination of 2D and 3D views spatially in a display. In this study, we analyzed the eyegaze strategies of participants using two arrangements of 2D and 3D views to estimate the relative position of objects in a 3D scene. Our results show that the 3D view was used significantly more often than individual 2D views in both displays, indicating the importance of the 3D view for successful task completion. However, viewing patterns were significantly different between the two displays: transitions through centrally-placed views were always more frequent, and users avoided saccades between views that were far apart. Although the change in viewing strategy did not result in significant performance differences, error analysis indicates that a 3D overview in the center may reduce the number of serious errors compared to a 3D overview placed off to the side.",Melanie Tory;M. Stella Atkins;Arthur E. Kirkpatrick;Marios Nicolaou;Guang-Zhong Yang,M. Tory;M.S. Atkins;A.E. Kirkpatrick;M. Nicolaou;G.-Z. Yang,"Department of Computer, Science University of British, Columbia, USA;School of Computing Science, Simon Fraser University, Canada;School of Computing Science, Simon Fraser University, Canada;Department of Computing, Imperial College London, UK;Department of Computing, Imperial College London, UK",10.1109/visual.2003.1250396;10.1109/visual.1997.663914;10.1109/visual.2003.1250396,"visualization, 2D/3D combination display, user study, experiment, eyegaze analysis",37.0,7.0,19.0,308.0,,,3d views;avoided saccades;participants using arrangements;performance differences error;importance,0.5731;0.3491;0.1595;0.1570;0.1190,"[np.int64(-1), -1, -1, -1, -1]",110;-1;-1;-1;-1,110,110
VAST,2014,EvoRiver: Visual Analysis of Topic Coopetition on Social Media,10.1109/tvcg.2014.2346919,http://dx.doi.org/10.1109/TVCG.2014.2346919,1753.0,1762.0,J,"Cooperation and competition (jointly called “coopetition”) are two modes of interactions among a set of concurrent topics on social media. How do topics cooperate or compete with each other to gain public attention? Which topics tend to cooperate or compete with one another? Who plays the key role in coopetition-related interactions? We answer these intricate questions by proposing a visual analytics system that facilitates the in-depth analysis of topic coopetition on social media. We model the complex interactions among topics as a combination of carry-over, coopetition recruitment, and coopetition distraction effects. This model provides a close functional approximation of the coopetition process by depicting how different groups of influential users (i.e., “topic leaders”) affect coopetition. We also design EvoRiver, a time-based visualization, that allows users to explore coopetition-related interactions and to detect dynamically evolving patterns, as well as their major causes. We test our model and demonstrate the usefulness of our system based on two Twitter data sets (social topics data and business topics data).",Guodao Sun;Yingcai Wu;Shixia Liu;Tai-Quan Peng;Jonathan J. H. Zhu;Ronghua Liang,Guodao Sun;Yingcai Wu;Shixia Liu;Tai-Quan Peng;Jonathan J. H. Zhu;Ronghua Liang,Zhejiang University of Technology;Microsoft Research;Microsoft Research;Nanyang Technological University;City University of Hong Kong;Zhejiang University of Technology,10.1109/vast.2010.5652931;10.1109/tvcg.2012.291;10.1109/tvcg.2008.166;10.1109/tvcg.2011.239;10.1109/tvcg.2012.253;10.1109/tvcg.2014.2346920;10.1109/tvcg.2013.221;10.1109/tvcg.2013.196;10.1109/tvcg.2013.162;10.1109/vast.2010.5652931,"Topic coopetition, information diffusion, information propagation, time-based visualization",128.0,94.0,46.0,2033.0,,,topics cooperate compete;influential users;time based visualization;carry coopetition recruitment;evoriver,0.6188;0.3926;0.3056;0.2482;0.1292,"[np.int64(-1), -1, -1, -1, -1]",45;-1;-1;-1;-1,45,45
Vis,1992,Optimizing triangulations by curvature equalization,10.1109/visual.1992.235191,http://dx.doi.org/10.1109/VISUAL.1992.235191,333.0,339.0,C,"An algorithm that attempts to improve a triangulation by shifting the vertices so that curvature within the triangles is nearly equal is presented. Unnecessary triangles are removed. The method is an effective way of guaranteeing that the triangle vertices are points of higher curvature, and that the triangle edges correspond to distinctive edges on the surfaces. Triangulations of surfaces with constant curvature-and hence no distinctive features-will gain nothing from this or any other optimization algorithm. As demonstrated by the results, the techinque of moving triangle vertices can improve some triangulation models. Greatest improvements occur with surfaces characterized by sharp edges, such as the pyramid and ridge models. Less improvement occurs on models that already approximate the surface topology and/or have less distinctive features.&lt;&lt;ETX&gt;&gt;",Lori L. Scarlatos;Theo Pavlidis,L.L. Scarlatos;T. Pavlidis,"Grumman Data Systems, Woodbury, NY, USA;Department of Computer Science, State University of New York, Stony Brook, NY, USA",,,30.0,8.0,14.0,52.0,,,edges surfaces triangulations;optimization algorithm;removed method effective;occurs models approximate;higher,0.7736;0.2509;0.0902;0.0891;0.0151,"[np.int64(-1), -1, -1, -1, -1]",108;-1;-1;-1;-1,108,108
Vis,2004,Panel 1: Can We Determine the Top Unresolved Problems of Visualization?,10.1109/visual.2004.76,http://dx.doi.org/10.1109/VISUAL.2004.76,563.0,566.0,M,"Many of us working in visualization have our own list of our top 5 or 10 unresolved problems in visualization. We have assembled a group of panelists to debate and perhaps reach concensus on the top problems in visualization that still need to be explored. We include panelists from both the information and scientific visualization domains. After our presentations, we encourage interaction with the audience to see if we can further formulate and perhaps finalize our list of top unresolved problems in visualization.",Theresa-Marie Rhyne;William L. Hibbard;Chris R. Johnson 0001;Chaomei Chen;Steve Eick,T. Rhyne;B. Hibbard;C. Johnson;Chaomei Chen;S. Eick,"North Carolina State University, USA;University of Wisconsin, Madison, USA;University of Utah, USA;Drexel University, USA;SSS-Research, Inc., University of Illinois, Chicago, USA",,,29.0,10.0,0.0,193.0,,,visualization need explored;panelists;list unresolved problems;scientific;reach,0.7006;0.2677;0.2152;0.1754;0.0523,"[np.int64(-1), -1, -1, -1, -1]",212;-1;-1;-1;-1,212,212
VAST,2006,"Toward a Multi-Analyst, Collaborative Framework for Visual Analytics",10.1109/vast.2006.261439,http://dx.doi.org/10.1109/VAST.2006.261439,129.0,136.0,C,"We describe a framework for the display of complex, multidimensional data, designed to facilitate exploration, analysis, and collaboration among multiple analysts. This framework aims to support human collaboration by making it easier to share representations, to translate from one point of view to another, to explain arguments, to update conclusions when underlying assumptions change, and to justify or account for decisions or actions. Multidimensional visualization techniques are used with interactive, context-sensitive, and tunable graphs. Visual representations are flexibly generated using a knowledge representation scheme based on annotated logic; this enables not only tracking and fusing different viewpoints, but also unpacking them. Fusing representations supports the creation of multidimensional meta-displays as well as the translation or mapping from one point of view to another. At the same time, analysts also need to be able to unpack one another's complex chains of reasoning, especially if they have reached different conclusions, and to determine the implications, if any, when underlying assumptions or evidence turn out to be false. The framework enables us to support a variety of scenarios as well as to systematically generate and test experimental hypotheses about the impact of different kinds of visual representations upon interactive collaboration by teams of distributed analysts",Susan E. Brennan;Klaus Mueller 0001;Gregory J. Zelinsky;I. V. Ramakrishnan;David Scott Warren;Arie E. Kaufman,Susan E. Brennan;Klaus Mueller;Greg Zelinsky;IV Ramakrishnan;David S. Warren;Arie Kaufman,"Psychology Department, Stony Brook University, Stony Brook, NY, USA;Computer Science Department, Stony Brook University, Stony Brook, NY, USA;Psychology Department, Stony Brook University, Stony Brook, NY, USA;Computer Science Department, Stony Brook University, Stony Brook, NY, USA;Computer Science Department, Stony Brook University, Stony Brook, NY, USA;Computer Science Department, Stony Brook University, Stony Brook, NY, USA",,"visual analytics, collaborative and distributed visualization, data management and knowledge representation, visual knowledge discovery",59.0,34.0,25.0,548.0,,,graphs visual representations;multiple analysts framework;explain arguments update;unpack;false framework enables,0.5803;0.4719;0.2316;0.1375;0.0030,"[np.int64(-1), -1, -1, -1, -1]",165;-1;-1;-1;-1,165,165
Vis,1992,Four-dimensional views of 3D scalar fields,10.1109/visual.1992.235222,http://dx.doi.org/10.1109/VISUAL.1992.235222,84.0,91.0,C,"Scalar functions of three variables, w=f(x, y, z), are common in many types of scientific and medical applications. Such 3D scalar fields can be understood as elevation maps in four dimensions, with three independent variables (x, y, z) and a fourth, dependent, variable w that corresponds to the elevations. It is shown how techniques developed originally for the display of 3-manifolds in 4D Euclidean space can be adapted to visualize 3D scalar fields in a variety of ways.&lt;&lt;ETX&gt;&gt;",Andrew J. Hanson;Pheng-Ann Heng,A.J. Hanson;P.A. Heng,"CN/AS Division, CERN, Geneva, Switzerland and Department of Computer Science, Indiana University, Bloomington, IN, USA;Department of Computer Science, Indiana University, Bloomington, IN, USA",10.1109/visual.1990.146363;10.1109/visual.1991.175821;10.1109/visual.1990.146391;10.1109/visual.1990.146363,,38.0,14.0,17.0,75.0,,,visualize 3d scalar;manifolds;fourth dependent;techniques developed originally;lt lt,0.7166;0.3632;0.1413;0.1258;-0.0472,"[np.int64(-1), -1, -1, -1, -1]",289;-1;-1;-1;-1,289,289
Vis,1993,Volume sampled voxelization of geometric primitives,10.1109/visual.1993.398854,http://dx.doi.org/10.1109/VISUAL.1993.398854,78.0,84.0,C,"We present a 3-D antialiasing algorithm for voxel-based geometric models. The technique band-limits the continuous object before sampling it at the desired 3-D raster resolution. By precomputing tables of filter values for different types and sizes of geometric objects, the algorithm is very efficient and has a complexity that is linear with the number of voxels generated. The algorithm not only creates voxel models which are free from object space aliasing, but it also incorporates the image space antialiasing information as part of the view independent voxel model. The resulting alias-free voxel models have been used to model synthetic scenes, for discrete ray tracing applications. The discrete ray-traced image is superior in quality to the image generated with a conventional surface-based ray tracer, since silhouettes of objects, shadows, and reflections appear smooth (jaggy-less). In addition, the alias-free models are also suitable for intermixing with sampled datasets, since they can be treated uniformly as one common data representation.&lt;&lt;ETX&gt;&gt;",Sidney W. Wang;Arie E. Kaufman,S.W. Wang;A.E. Kaufman,"Department of Computer Science, State University of New York, Stony Brook, Stony Brook, NY, USA;Department of Computer Science, State University of New York, Stony Brook, Stony Brook, NY, USA",10.1109/visual.1992.235190;10.1109/visual.1992.235190,"voxelization, volume sampling, discrete ray tracing, filtering",196.0,37.0,20.0,347.0,,,antialiasing algorithm voxel;addition alias free;view;tracing applications;different types,0.7458;0.1773;0.1507;0.1370;0.0142,"[np.int64(-1), -1, -1, -1, -1]",253;-1;-1;-1;-1,253,253
Vis,2006,Multifield-Graphs: An Approach to Visualizing Correlations in Multifield Scalar Data,10.1109/tvcg.2006.165,http://dx.doi.org/10.1109/TVCG.2006.165,917.0,924.0,J,"We present an approach to visualizing correlations in 3D multifield scalar data. The core of our approach is the computation of correlation fields, which are scalar fields containing the local correlations of subsets of the multiple fields. While the visualization of the correlation fields can be done using standard 3D volume visualization techniques, their huge number makes selection and handling a challenge. We introduce the multifield-graph to give an overview of which multiple fields correlate and to show the strength of their correlation. This information guides the selection of informative correlation fields for visualization. We use our approach to visually analyze a number of real and synthetic multifield datasets",Natascha Sauber;Holger Theisel;Hans-Peter Seidel,Natascha Sauber;Holger Theisel;Hans-peter Seidel,"MPI Informatik Saarbrücken, Germany;MPI Informatik Saarbrücken, Germany;MPI Informatik Saarbrücken, Germany",10.1109/visual.1999.809865;10.1109/visual.2004.68;10.1109/visual.2004.46;10.1109/visual.1999.809905;10.1109/visual.2003.1250362;10.1109/visual.1999.809865,"Visualization, multifield, correlation",151.0,89.0,28.0,887.0,,,correlation fields visualization;standard 3d volume;strength;containing local;number real,0.8313;0.3755;0.0691;0.0102;-0.0072,"[np.int64(-1), -1, -1, -1, -1]",289;-1;-1;-1;-1,289,289
Vis,2004,Immersive design of DNA molecules with a tangible interface,10.1109/visual.2004.47,http://dx.doi.org/10.1109/VISUAL.2004.47,227.0,234.0,C,"This work presents an experimental immersive interface for designing DNA components for application in nanotechnology. While much research has been done on immersive visualization, this is one of the first systems to apply advanced interface techniques to a scientific design problem. This system uses tangible 3D input devices (tongs, a raygun, and a multipurpose handle tool) to create and edit a purely digital representation of DNA. The tangible controllers are associated with functions (not data) while a virtual display is used to render the model. This interface was built in collaboration with a research group investigating the design of DNA tiles. A user study shows that scientists find the immersive interface more satisfying than a 2D interface due to the enhanced understanding gained by directly interacting with molecules in 3D space.",Steven Schkolne;Hiroshi Ishii 0001;Peter Schröder,S. Schkolne;H. Ishii;P. Schroder,"Caltech, USA;MIT Media Laboratory, USA;Caltech, USA",,"tangible user interface, molecular visualization, props, molecular modeling, spatial construction, virtual reality, augmented reality, responsive workbench, DNA design",46.0,27.0,34.0,237.0,,,representation dna tangible;virtual display used;tool create edit;controllers associated functions;study,0.7345;0.2054;0.1458;0.1114;-0.0080,"[np.int64(-1), -1, -1, -1, -1]",120;-1;-1;-1;-1,120,120
Vis,1998,Scientific visualization and data modeling of scattered sediment contaminant data in New York/New Jersey estuaries,10.1109/visual.1998.745345,http://dx.doi.org/10.1109/VISUAL.1998.745345,467.0,470.0,C,"Sediments in many parts of the New York and New Jersey estuary system are contaminated with toxic organic and inorganic compounds by different sources. Because of the potential environmental consequences, detailed information on the spatial distribution of sediment contaminants is essential in order to carry out routine shipping channel dredging in an environmentally responsible way, and to remediate hot spots cost-effectively and safely. Scientific visualization and scatter data modeling techniques have been successfully applied in analyzing the sparse sampling data of sediment contaminants in New York and New Jersey estuaries, the underlying spatial characteristics of which are otherwise difficult to comprehend. Continuous realizations of contaminant concentrations in the region were obtained by using a spectral domain-decomposition scattered data model and IBM Data Explorer which is a software package for scientific data visualization.",Hong Ma;Keith W. Jones;Eric A. Stern,H. Ma;K.W. Jones;E.A. Stern,"Brockhaven National Laboratory, Upton, NY, USA;Brockhaven National Laboratory, Upton, NY, USA;U.S. Enviromental Protection Agency, New York, NY, USA",,,8.0,1.0,9.0,83.0,,,data sediment contaminants;visualization;carry routine shipping;spectral domain;hot spots cost,0.6239;0.2579;0.1423;0.1239;0.0298,"[np.int64(-1), -1, -1, -1, -1]",278;-1;-1;-1;-1,278,278
VAST,2020,HypoML: Visual Analysis for Hypothesis-based Evaluation of Machine Learning Models,10.1109/tvcg.2020.3030449,http://dx.doi.org/10.1109/TVCG.2020.3030449,1417.0,1426.0,J,"In this paper, we present a visual analytics tool for enabling hypothesis-based evaluation of machine learning (ML) models. We describe a novel ML-testing framework that combines the traditional statistical hypothesis testing (commonly used in empirical research) with logical reasoning about the conclusions of multiple hypotheses. The framework defines a controlled configuration for testing a number of hypotheses as to whether and how some extra information about a “concept” or “feature” may benefit or hinder an ML model. Because reasoning multiple hypotheses is not always straightforward, we provide HypoML as a visual analysis tool, with which, the multi-thread testing results are first transformed to analytical results using statistical and logical inferences, and then to a visual representation for rapid observation of the conclusions and the logical flow between the testing results and hypotheses. We have applied HypoML to a number of hypothesized concepts, demonstrating the intuitive and explainable nature of the visual analysis.",Qianwen Wang;William Alexander;Jack Pegg;Huamin Qu;Min Chen 0001,Qianwen Wang;William Alexander;Jack Pegg;Huamin Qu;Min Chen,"Hong Kong University of Science and Technology, China;University of Oxford, UK;University of Oxford, UK;Hong Kong University of Science and Technology, China;University of Oxford, UK",10.1109/tvcg.2012.197;10.1109/tvcg.2019.2934659;10.1109/tvcg.2017.2744718;10.1109/tvcg.2017.2744938;10.1109/tvcg.2016.2598831;10.1109/tvcg.2017.2744358;10.1109/tvcg.2016.2598838;10.1109/tvcg.2016.2598828;10.1109/tvcg.2018.2864838;10.1109/tvcg.2017.2744158;10.1109/tvcg.2016.2598829;10.1109/tvcg.2019.2934619;10.1109/tvcg.2018.2864499;10.1109/tvcg.2018.2864500;10.1109/tvcg.2012.197,"Visual analytics,model-developmental visualization,machine learning,neural network,hypothesis test,HypoML",4.0,6.0,44.0,676.0,,,visual analytics;testing results hypotheses;hinder ml model;thread;framework defines controlled,0.5392;0.3999;0.2489;0.1407;0.0218,"[np.int64(-1), -1, -1, -1, -1]",201;-1;-1;-1;-1,201,201
Vis,2009,Continuous Parallel Coordinates,10.1109/tvcg.2009.131,http://dx.doi.org/10.1109/TVCG.2009.131,1531.0,1538.0,J,"Typical scientific data is represented on a grid with appropriate interpolation or approximation schemes,defined on a continuous domain. The visualization of such data in parallel coordinates may reveal patterns latently contained in the data and thus can improve the understanding of multidimensional relations. In this paper, we adopt the concept of continuous scatterplots for the visualization of spatially continuous input data to derive a density model for parallel coordinates. Based on the point-line duality between scatterplots and parallel coordinates, we propose a mathematical model that maps density from a continuous scatterplot to parallel coordinates and present different algorithms for both numerical and analytical computation of the resulting density field. In addition, we show how the 2-D model can be used to successively construct continuous parallel coordinates with an arbitrary number of dimensions. Since continuous parallel coordinates interpolate data values within grid cells, a scalable and dense visualization is achieved, which will be demonstrated for typical multi-variate scientific data.",Julian Heinrich;Daniel Weiskopf,Julian Heinrich;Daniel Weiskopf,"VISUS (Visualization Research Center), Universität Stuttgart, Stuttgart, Germany;VISUS (Visualization Research Center), Universität Stuttgart, Stuttgart, Germany",10.1109/tvcg.2006.168;10.1109/tvcg.2008.119;10.1109/tvcg.2008.131;10.1109/infvis.2005.1532139;10.1109/tvcg.2009.179;10.1109/tvcg.2006.138;10.1109/visual.1990.146402;10.1109/infvis.2005.1532138;10.1109/tvcg.2008.160;10.1109/infvis.2002.1173157;10.1109/visual.1999.809866;10.1109/tvcg.2006.170;10.1109/infvis.2004.68;10.1109/tvcg.2006.168,"Parallel coordinates, integrating spatial and non-spatial data visualization, multi-variate visualization, interpolation",128.0,86.0,28.0,1399.0,,,scatterplots visualization spatially;derive density model;values grid cells;different algorithms numerical;concept continuous,0.6153;0.3743;0.2460;0.2404;0.1304,"[np.int64(-1), -1, -1, -1, -1]",172;-1;-1;-1;-1,172,172
InfoVis,2011,Exploring Uncertainty in Geodemographics with Interactive Graphics,10.1109/tvcg.2011.197,http://dx.doi.org/10.1109/TVCG.2011.197,2545.0,2554.0,J,"Geodemographic classifiers characterise populations by categorising geographical areas according to the demographic and lifestyle characteristics of those who live within them. The dimension-reducing quality of such classifiers provides a simple and effective means of characterising population through a manageable set of categories, but inevitably hides heterogeneity, which varies within and between the demographic categories and geographical areas, sometimes systematically. This may have implications for their use, which is widespread in government and commerce for planning, marketing and related activities. We use novel interactive graphics to delve into OAC - a free and open geodemographic classifier that classifies the UK population in over 200,000 small geographical areas into 7 super-groups, 21 groups and 52 sub-groups. Our graphics provide access to the original 41 demographic variables used in the classification and the uncertainty associated with the classification of each geographical area on-demand. It also supports comparison geographically and by category. This serves the dual purpose of helping understand the classifier itself leading to its more informed use and providing a more comprehensive view of population in a comprehensible manner. We assess the impact of these interactive graphics on experienced OAC users who explored the details of the classification, its uncertainty and the nature of between - and within - class variation and then reflect on their experiences. Visualization of the complexities and subtleties of the classification proved to be a thought-provoking exercise both confirming and challenging users' understanding of population, the OAC classifier and the way it is used in their organisations. Users identified three contexts for which the techniques were deemed useful in the context of local government, confirming the validity of the proposed methods.",Aidan Slingsby;Jason Dykes;Jo Wood,Aidan Slingsby;Jason Dykes;Jo Wood,"City University London, UK;City University London, UK;City University London, UK",10.1109/infvis.1996.559216;10.1109/tvcg.2010.191;10.1109/tvcg.2007.70574;10.1109/tvcg.2010.186;10.1109/visual.1999.809866;10.1109/tvcg.2008.165;10.1109/tvcg.2006.202;10.1109/tvcg.2007.70515;10.1109/infvis.2004.12;10.1109/infvis.1996.559216,"Geodemographics, OAC, classification, cartography, uncertainty",82.0,38.0,58.0,1393.0,,,demographic categories geographical;reflect experiences visualization;understand classifier leading;52;access original,0.6723;0.3040;0.1435;0.1270;-0.0578,"[np.int64(-1), -1, -1, -1, -1]",18;-1;-1;-1;-1,18,18
Vis,1998,Data level comparison of wind tunnel and computational fluid dynamics data,10.1109/visual.1998.745332,http://dx.doi.org/10.1109/VISUAL.1998.745332,415.0,418.0,C,"The paper describes the architecture of a data level comparative visualization system and experiences using it to study computational fluid dynamics data and experimental wind tunnel data. We illustrate how the system can be used to compare data sets from different sources, data sets with different resolutions and data sets computed using different mathematical models of fluid flow. Suggested improvements to the system based on user feedback are also discussed.",Qin Shen;Alex Pang;Samuel P. Uselton,Q. Shen;A. Pang;S. Uselton,"Computer Science Department, University of California, Santa Cruz, USA;Computer Science Department, University of California, Santa Cruz, USA;MRJ Technology Solutions, Inc., USA",10.1109/visual.1997.663910;10.1109/visual.1996.568115;10.1109/visual.1996.568116;10.1109/visual.1997.663911;10.1109/visual.1997.663910,,54.0,11.0,10.0,145.0,,,level comparative visualization;computational fluid dynamics;tunnel data;experiences using;different sources,0.6719;0.4642;0.1647;0.1520;0.0902,"[np.int64(-1), -1, -1, -1, -1]",188;-1;-1;-1;-1,188,188
Vis,2021,Simultaneous Matrix Orderings for Graph Collections,10.1109/tvcg.2021.3114773,http://dx.doi.org/10.1109/TVCG.2021.3114773,1.0,10.0,J,"Undirected graphs are frequently used to model phenomena that deal with interacting objects, such as social networks, brain activity and communication networks. The topology of an undirected graph <inline-formula><tex-math notation=""LaTeX"">$G$</tex-math><alternatives><graphic orientation=""portrait"" position=""float"" xlink:href=""28tvcg01-beusekom-3114773-eqinline-1-small.tif"" xmlns:xlink=""http://www.w3.org/1999/xlink""/></alternatives></inline-formula> can be captured by an adjacency matrix; this matrix in turn can be visualized directly to give insight into the graph structure. Which visual patterns appear in such a matrix visualization crucially depends on the <i>ordering</i> of its rows and columns. Formally defining the quality of an ordering and then automatically computing a high-quality ordering are both challenging problems; however, effective heuristics exist and are used in practice. <p>Often, graphs do not exist in isolation but as part of a collection of graphs on the same set of vertices, for example, brain scans over time or of different people. To visualize such graph collections, we need a <i>single</i> ordering that works well for all matrices <i>simultaneously</i>. The current state-of-the-art solves this problem by taking a (weighted) union over all graphs and applying existing heuristics. However, this union leads to a loss of information, specifically in those parts of the graphs which are different. We propose a <i>collection-aware</i> approach to avoid this loss of information and apply it to two popular heuristic methods: leaf order and barycenter.</p> <p>The de-facto standard computational quality metrics for matrix ordering capture only block-diagonal patterns (cliques). Instead, we propose to use <i>Moran's</i> <inline-formula><tex-math notation=""LaTeX"">$I$</tex-math><alternatives><graphic orientation=""portrait"" position=""float"" xlink:href=""28tvcg01-beusekom-3114773-eqinline-2-small.tif"" xmlns:xlink=""http://www.w3.org/1999/xlink""/></alternatives></inline-formula>, a spatial auto-correlation metric, which captures the full range of established patterns. Moran's <inline-formula><tex-math notation=""LaTeX"">$I$</tex-math><alternatives><graphic orientation=""portrait"" position=""float"" xlink:href=""28tvcg01-beusekom-3114773-eqinline-3-small.tif"" xmlns:xlink=""http://www.w3.org/1999/xlink""/></alternatives></inline-formula> refines previously proposed stress measures. Furthermore, the popular leaf order method heuristically optimizes a similar measure which further supports the use of Moran's <inline-formula><tex-math notation=""LaTeX"">$I$</tex-math><alternatives><graphic orientation=""portrait"" position=""float"" xlink:href=""28tvcg01-beusekom-3114773-eqinline-4-small.tif"" xmlns:xlink=""http://www.w3.org/1999/xlink""/></alternatives></inline-formula> in this context. An ordering that maximizes Moran's <inline-formula><tex-math notation=""LaTeX"">$I$</tex-math><alternatives><graphic orientation=""portrait"" position=""float"" xlink:href=""28tvcg01-beusekom-3114773-eqinline-5-small.tif"" xmlns:xlink=""http://www.w3.org/1999/xlink""/></alternatives></inline-formula> can be computed via solutions to the Traveling Salesperson Problem (TSP); orderings that approximate the optimal ordering can be computed more efficiently, using any of the approximation algorithms for metric TSP.</p> <p>We evaluated our methods for simultaneous orderings on real-world datasets using Moran's <inline-formula><tex-math notation=""LaTeX"">$I$</tex-math><alternatives><graphic orientation=""portrait"" position=""float"" xlink:href=""28tvcg01-beusekom-3114773-eqinline-6-small.tif"" xmlns:xlink=""http://www.w3.org/1999/xlink""/></alternatives></inline-formula> as the quality metric. Our results show that our collection-aware approach matches or improves performance compared to the union approach, depending on the similarity of the graphs in the collection. Specifically, our Moran's <inline-formula><tex-math notation=""LaTeX"">$I$</tex-math><alternatives><graphic orientation=""portrait"" position=""float"" xlink:href=""28tvcg01-beusekom-3114773-eqinline-7-small.tif"" xmlns:xlink=""http://www.w3.org/1999/xlink""/></alternatives></inline-formula>-based collection-aware leaf order implementation consistently outperforms other implementations. Our collection-aware implementations carry no significant additional computational costs.</p>",Nathan van Beusekom;Wouter Meulemans;Bettina Speckmann,Nathan van Beusekom;Wouter Meulemans;Bettina Speckmann,"TU Eindhoven, the Netherlands;TU Eindhoven, the Netherlands;TU Eindhoven, the Netherlands",10.1109/tvcg.2016.2598862;10.1109/tvcg.2016.2598467;10.1109/infvis.2004.1;10.1109/tvcg.2020.3030373;10.1109/tvcg.2016.2598862,"Matrix ordering,graph visualization,algorithms,quality measures",7.0,8.0,34.0,1022.0,BP,,graph structure;example brain;auto correlation;capture block diagonal;implementations carry significant,0.6245;0.2782;0.2313;0.1192;0.0699,"[np.int64(-1), -1, -1, -1, -1]",39;-1;-1;-1;-1,39,39
InfoVis,2012,Graphical Tests for Power Comparison of Competing Designs,10.1109/tvcg.2012.230,http://dx.doi.org/10.1109/TVCG.2012.230,2441.0,2448.0,J,"Lineups [4, 28] have been established as tools for visual testing similar to standard statistical inference tests, allowing us to evaluate the validity of graphical findings in an objective manner. In simulation studies [12] lineups have been shown as being efficient: the power of visual tests is comparable to classical tests while being much less stringent in terms of distributional assumptions made. This makes lineups versatile, yet powerful, tools in situations where conditions for regular statistical tests are not or cannot be met. In this paper we introduce lineups as a tool for evaluating the power of competing graphical designs. We highlight some of the theoretical properties and then show results from two studies evaluating competing designs: both studies are designed to go to the limits of our perceptual abilities to highlight differences between designs. We use both accuracy and speed of evaluation as measures of a successful design. The first study compares the choice of coordinate system: polar versus cartesian coordinates. The results show strong support in favor of cartesian coordinates in finding fast and accurate answers to spotting patterns. The second study is aimed at finding shift differences between distributions. Both studies are motivated by data problems that we have recently encountered, and explore using simulated data to evaluate the plot designs under controlled conditions. Amazon Mechanical Turk (MTurk) is used to conduct the studies. The lineups provide an effective mechanism for objectively evaluating plot designs.",Heike Hofmann;Lendie Follett;Mahbubul Majumder;Dianne Cook,Heike Hofmann;Lendie Follett;Mahbubul Majumder;Dianne Cook,"Iowa State University, USA;Iowa State University, USA;Iowa State University, USA;Iowa State University, USA",10.1109/tvcg.2009.111;10.1109/tvcg.2010.161;10.1109/tvcg.2009.111,"Lineups, Visual inference, Power comparison, Efficiency of displays",56.0,31.0,27.0,914.0,,,competing graphical designs;statistical tests;lineups 28 established;coordinate polar;use accuracy speed,0.6987;0.3533;0.1688;0.1026;0.0864,"[np.int64(-1), -1, -1, -1, -1]",-1;-1;-1;-1;-1,,-1
Vis,1996,Complex-valued contour meshing,10.1109/visual.1996.568103,http://dx.doi.org/10.1109/VISUAL.1996.568103,173.0,180.0,C,"An isovalue contour of a function of two complex variables defines a surface in four-space. We present a robust technique for creating polygonal contours of complex-valued functions. The technique, contour meshing, generalizes well to larger dimensions.",Chris Weigle;David C. Banks,C. Weigle;D.C. Banks,"Department of Computer Science, Mississippi State University, USA;Department of Computer Science, Mississippi State University, USA",10.1109/visual.1993.398869;10.1109/visual.1991.175782;10.1109/visual.1993.398869,,62.0,18.0,15.0,68.0,,,polygonal contours complex;defines surface;valued functions;space present robust;technique creating,0.7111;0.3396;0.2191;0.1535;0.1322,"[np.int64(-1), -1, -1, -1, -1]",254;-1;-1;-1;-1,254,254
Vis,1997,Optimized geometry compression for real-time rendering,10.1109/visual.1997.663902,http://dx.doi.org/10.1109/VISUAL.1997.663902,347.0,354.0,C,"Most existing visualization applications use 3D geometry as their basic rendering primitive. As users demand more complex data sets, the memory requirements for retrieving and storing large 3D models are becoming excessive. In addition, the current 3D rendering hardware is facing a large memory bus bandwidth bottleneck at the processor to graphics pipeline interface. Rendering 1 million triangles with 24 bytes per triangle at 30 Hz requires as much as 720 MB/sec memory bus bandwidth. This transfer rate is well beyond the current low-cost graphics systems. A solution is to compress the static 3D geometry as an off-line pre-process. Then, only the compressed geometry needs to be stored in main memory and sent down to the graphics pipeline for real-time decompression and rendering. The author presents several new techniques for compression of 3D geometry that produce 2 to 3 times better compression ratios than existing methods. They first introduce several algorithms for the efficient encoding of the original geometry as generalized triangle meshes. This encoding allows most of the mesh vertices to be reused when forming new triangles. Their second contribution allows various parts of a geometric model to be compressed with different precision depending on the level of details present. Together, the meshifying algorithms and the variable compression method achieve compression ratios of 30 and 37 to one over ASCII encoded formats and 10 and 15 to one over binary encoded triangle strips. The experimental results show a dramatically lowered memory bandwidth required for real-time visualization of complex data sets.",Mike M. Chow,M.M. Chow,"Massachusetts Institute of Technology, USA",10.1109/visual.1996.568125;10.1109/visual.1996.568125,,320.0,57.0,11.0,320.0,,,compression 3d geometry;time visualization complex;large memory bus;primitive users;strips experimental results,0.6870;0.2673;0.2459;0.0767;0.0101,"[np.int64(-1), -1, -1, -1, -1]",80;-1;-1;-1;-1,80,80
Vis,2004,Constrained inverse volume rendering for planetary nebulae,10.1109/visual.2004.18,http://dx.doi.org/10.1109/VISUAL.2004.18,83.0,90.0,C,"Determining the three-dimensional structure of distant astronomical objects is a challenging task, given that terrestrial observations provide only one viewpoint. For this task, bipolar planetary nebulae are interesting objects of study because of their pronounced axial symmetry due to fundamental physical processes. Making use of this symmetry constraint, we present a technique to automatically recover the axisymmetric structure of bipolar planetary nebulae from two-dimensional images. With GPU-based volume rendering driving a nonlinear optimization, we estimate the nebula's local emission density as a function of its radial and axial coordinates, and we recover the orientation of the nebula relative to Earth. The optimization refines the nebula model and its orientation by minimizing the differences between the rendered image and the original astronomical image. The resulting model enables realistic 3D visualizations of planetary nebulae, e.g. for educational purposes in planetarium shows. In addition, the recovered spatial distribution of the emissive gas allows validating computer simulation results of the astrophysical formation processes of planetary nebulae.",Marcus A. Magnor;Gordon L. Kindlmann;Neb Duric;Charles D. Hansen,M. Magnor;G. Kindlmann;N. Duric;C. Hansen,"MPI Informatik, Germany;SCI Institute, University of Utah, USA;SCI Institute, University of Utah, USA;Department Physics and Astronomy, University of New Mexico, USA",,"volumetric modeling, inverse rendering, volume rendering, volume reconstruction, planetary nebulae",50.0,19.0,36.0,204.0,,,visualizations planetary nebulae;gpu based volume;model orientation minimizing;rendered image original;bipolar,0.7445;0.3452;0.2591;0.1749;0.0745,"[np.int64(-1), -1, -1, -1, -1]",103;-1;-1;-1;-1,103,103
Vis,1992,Logical time in visualizations produced by parallel programs,10.1109/visual.1992.235209,http://dx.doi.org/10.1109/VISUAL.1992.235209,186.0,193.0,C,"Techniques that manipulate logical time in order to produce coherent animations of parallel program behavior despite the presence of asynchrony are presented. The techniques interpret program behavior in light of user-defined abstractions and generate animations based on a logical, rather than a physical, view of time. If this interpretation succeeds, the resulting animation is easily understood. If it fails, the programmer can be assured that the failure was not an artifact of the visualization. It is shown that these techniques can be generally applied to enhance visualizations of a variety of types of data as they are produced by parallel, MIMD (multiple instruction stream, multiple data stream) computations.&lt;&lt;ETX&gt;&gt;",Janice E. Cuny;Alfred Hough;Joydip Kunda,J.E. Cuny;A.A. Hough;J. Kundu,"Dept. of Comput. Sci., Massachusetts Univ., Amherst, MA, USA;Department of Computer Science, University of Massachusetts, Amherst, MA, USA;Department of Computer Science, University of Massachusetts, Amherst, MA, USA",,,18.0,4.0,18.0,49.0,,,animations parallel program;manipulate logical time;failure artifact visualization;despite presence asynchrony;types data,0.5873;0.3939;0.3121;0.1590;0.1207,"[np.int64(-1), -1, -1, -1, -1]",9;-1;-1;-1;-1,9,9
Vis,2004,TetSplat: real-time rendering and volume clipping of large unstructured tetrahedral meshes,10.1109/visual.2004.102,http://dx.doi.org/10.1109/VISUAL.2004.102,433.0,440.0,C,"We present a novel approach to interactive visualization and exploration of large unstructured tetrahedral meshes. These massive 3D meshes are used in mission-critical CFD and structural mechanics simulations, and typically sample multiple field values on several millions of unstructured grid points. Our method relies on the preprocessing of the tetrahedral mesh to partition it into nonconvex boundaries and internal fragments that are subsequently encoded into compressed multiresolution data representations. These compact hierarchical data structures are then adaptively rendered and probed in real-time on a commodity PC. Our point-based rendering algorithm, which is inspired by QSplat, employs a simple but highly efficient splatting technique that guarantees interactive frame-rates regardless of the size of the input mesh and the available rendering hardware. It furthermore allows for real-time probing of the volumetric data-set through constructive solid geometry operations as well as interactive editing of color transfer functions for an arbitrary number of field values. Thus, the presented visualization technique allows end-users for the first time to interactively render and explore very large unstructured tetrahedral meshes on relatively inexpensive hardware.",Ken Museth;Santiago V. Lombeyda,K. Museth;S. Lombeyda,"Linköping Institute of Technology, Sweden;California Institute of Technology, USA",10.1109/visual.2000.885703;10.1109/visual.1998.745329;10.1109/visual.2000.885680;10.1109/visual.1997.663869;10.1109/visual.2000.885703,"Large volumetric data, tetrahedral meshes, real-time visualization, point-based rendering, constructive solid geometry",18.0,4.0,22.0,116.0,,,unstructured tetrahedral meshes;render explore large;mission critical cfd;qsplat;frame rates regardless,0.6729;0.2654;0.1721;0.1530;0.0744,"[np.int64(-1), -1, -1, -1, -1]",108;-1;-1;-1;-1,108,108
VAST,2015,Visually and statistically guided imputation of missing values in univariate seasonal time series,10.1109/vast.2015.7347672,http://dx.doi.org/10.1109/VAST.2015.7347672,189.0,190.0,M,"Missing values are a problem in many real world applications, for example failing sensor measurements. For further analysis these missing values need to be imputed. Thus, imputation of such missing values is important in a wide range of applications. We propose a visually and statistically guided imputation approach, that allows applying different imputation techniques to estimate the missing values as well as evaluating and fine tuning the imputation by visual guidance. In our approach we include additional visual information about uncertainty and employ the cyclic structure of time inherent in the data. Including this cyclic structure enables visually judging the adequateness of the estimated values with respect to the uncertainty/error boundaries and according to the patterns of the neighbouring time points in linear and cyclic (e.g., the months of the year) time.",Markus Bögl;Peter Filzmoser;Theresia Gschwandtner;Silvia Miksch;Wolfgang Aigner;Alexander Rind;Tim Lammarsch,M. Bögl;P. Filzmoser;T. Gschwandtner;S. Miksch;W. Aigner;A. Rind;T. Lammarsch,Vienna University of Technology;Vienna University of Technology;Vienna University of Technology;Vienna University of Technology;Vienna University of Technology;St.Pölten University of Applied Sciences;MODUL University Vienna,,,14.0,13.0,11.0,340.0,,,imputation visual guidance;sensor measurements analysis;months year time;cyclic structure;values important,0.6844;0.3035;0.1676;0.0931;0.0343,"[np.int64(-1), -1, -1, -1, -1]",314;-1;-1;-1;-1,314,314
Vis,2002,Face-based luminance matching for perceptual colormap generation,10.1109/visual.2002.1183788,http://dx.doi.org/10.1109/VISUAL.2002.1183788,299.0,306.0,C,"Most systems used for creating and displaying colormap-based visualizations are not photometrically calibrated. That is, the relationship between RGB input levels and perceived luminance is usually not known, due to variations in the monitor, hardware configuration, and the viewing environment. However, the luminance component of perceptually based colormaps should be controlled, due to the central role that luminance plays in our visual processing. We address this problem with a simple and effective method for performing luminance matching on an uncalibrated monitor. The method is akin to the minimally distinct border technique (a previous method of luminance matching used for measuring luminous efficiency), but our method relies on the brain's highly developed ability to distinguish human faces. We present a user study showing that our method produces equivalent results to the minimally distinct border technique, but with significantly improved precision. We demonstrate how results from our luminance matching method can be directly applied to create new univariate colormaps.",Gordon L. Kindlmann;Erik Reinhard;Sarah Creem,G. Kindlmann;E. Reinhard;S. Creem,"Sch. of Comput., Utah Univ., Salt Lake City, UT, USA;School of Electrical Engineering and Computer Science, University of Central Florida, USA;Department of Psychology, University of Utah, USA",10.1109/visual.1995.480803;10.1109/visual.1992.235201;10.1109/visual.2001.964510;10.1109/visual.1995.480803,"Colormaps, Color Scales, Isoluminance, Brightness Matching, Perceptually-based Visualization",110.0,36.0,26.0,679.0,,,perceptually based colormaps;used measuring luminous;human faces present;hardware configuration viewing;directly applied create,0.7173;0.3424;0.2470;0.1650;-0.0224,"[np.int64(-1), -1, -1, -1, -1]",129;-1;-1;-1;-1,129,129
InfoVis,2009,Interaction Techniques for Selecting and Manipulating Subgraphs in Network Visualizations,10.1109/tvcg.2009.151,http://dx.doi.org/10.1109/TVCG.2009.151,937.0,944.0,J,"We present a novel and extensible set of interaction techniques for manipulating visualizations of networks by selecting subgraphs and then applying various commands to modify their layout or graphical properties. Our techniques integrate traditional rectangle and lasso selection, and also support selecting a node's neighbourhood by dragging out its radius (in edges) using a novel kind of radial menu. Commands for translation, rotation, scaling, or modifying graphical properties (such as opacity) and layout patterns can be performed by using a hotbox (a transiently popped-up, semi-transparent set of widgets) that has been extended in novel ways to integrate specification of commands with 1D or 2D arguments. Our techniques require only one mouse button and one keyboard key, and are designed for fast, gestural, in-place interaction. We present the design and integration of these interaction techniques, and illustrate their use in interactive graph visualization. Our techniques are implemented in NAViGaTOR, a software package for visualizing and analyzing biological networks. An initial usability study is also reported.",Michael J. McGuffin;Igor Jurisica,Michael J. McGuffin;Igor Jurisica,"École de technologie supérieure, Montreal, Canada;PMH/UHN, Ontario Cancer Institute, Toronto, Canada",10.1109/infvis.2005.1532124;10.1109/infvis.1996.559216;10.1109/infvis.2005.1532124,"Interactive graph drawing, network layout, radial menus, marking menus, hotbox, biological networks",94.0,47.0,19.0,1060.0,HM,,interactive graph visualization;rectangle lasso selection;novel kind radial;menu commands translation;transiently,0.6490;0.3834;0.1368;0.1057;-0.0003,"[np.int64(-1), -1, -1, -1, -1]",165;-1;-1;-1;-1,165,165
Vis,2007,Interactive sound rendering in complex and dynamic scenes using frustum tracing,10.1109/tvcg.2007.70567,http://dx.doi.org/10.1109/TVCG.2007.70567,1672.0,1679.0,J,"We present a new approach for real-time sound rendering in complex, virtual scenes with dynamic sources and objects. Our approach combines the efficiency of interactive ray tracing with the accuracy of tracing a volumetric representation. We use a four-sided convex frustum and perform clipping and intersection tests using ray packet tracing. A simple and efficient formulation is used to compute secondary frusta and perform hierarchical traversal. We demonstrate the performance of our algorithm in an interactive system for complex environments and architectural models with tens or hundreds of thousands of triangles. Our algorithm can perform real-time simulation and rendering on a high-end PC.",Christian Lauterbach;Anish Chandak;Dinesh Manocha,Christian Lauterbach;Anish Chandak;Dinesh Manocha,"Department of Computer Science, University of North Carolina, Chapel Hill, Chapel Hill, NC, USA;Department of Computer Science, University of North Carolina, Chapel Hill, Chapel Hill, NC, USA;Department of Computer Science, University of North Carolina, Chapel Hill, Chapel Hill, NC, USA",10.1109/tvcg.2006.125;10.1109/visual.2005.1532790;10.1109/tvcg.2006.125,"Acoustic propagation,Interactive systems",87.0,38.0,48.0,460.0,,,sound rendering;clipping intersection tests;perform hierarchical traversal;packet tracing simple;thousands triangles,0.6883;0.2443;0.1646;0.1624;0.1534,"[np.int64(-1), -1, -1, -1, -1]",30;-1;-1;-1;-1,30,30
InfoVis,2020,Guidelines For Pursuing and Revealing Data Abstractions,10.1109/tvcg.2020.3030355,http://dx.doi.org/10.1109/TVCG.2020.3030355,1503.0,1513.0,J,"Many data abstraction types, such as networks or set relationships, remain unfamiliar to data workers beyond the visualization research community. We conduct a survey and series of interviews about how people describe their data, either directly or indirectly. We refer to the latter as latent data abstractions. We conduct a Grounded Theory analysis that (1) interprets the extent to which latent data abstractions exist, (2) reveals the far-reaching effects that the interventionist pursuit of such abstractions can have on data workers, (3) describes why and when data workers may resist such explorations, and (4) suggests how to take advantage of opportunities and mitigate risks through transparency about visualization research perspectives and agendas. We then use the themes and codes discovered in the Grounded Theory analysis to develop guidelines for data abstraction in visualization projects. To continue the discussion, we make our dataset open along with a visual interface for further exploration.",Alex Bigelow;Katy Williams;Katherine E. Isaacs,Alex Bigelow;Katy Williams;Katherine E. Isaacs,University of Arizona;University of Arizona;University of Arizona,10.1109/vast47406.2019.8986909;10.1109/infvis.2000.885092;10.1109/tvcg.2013.145;10.1109/vast.2011.6102441;10.1109/tvcg.2018.2865241;10.1109/tvcg.2014.2346331;10.1109/tvcg.2019.2934539;10.1109/tvcg.2009.111;10.1109/tvcg.2009.116;10.1109/tvcg.2012.213;10.1109/tvcg.2017.2744843;10.1109/tvcg.2019.2934538;10.1109/tvcg.2019.2934285;10.1109/vast47406.2019.8986909,"Data abstraction,Grounded theory,Survey design,Data wrangling",3.0,4.0,50.0,474.0,,,visualization research perspectives;make dataset open;exist reveals far;series interviews people;conduct grounded,0.6703;0.3002;0.1768;0.1685;0.1081,"[np.int64(-1), -1, -1, -1, -1]",209;-1;-1;-1;-1,209,209
VAST,2008,Grand challenge award 2008: Support for diverse analytic techniques - nSpace2 and GeoTime visual analytics,10.1109/vast.2008.4677385,http://dx.doi.org/10.1109/VAST.2008.4677385,,,M,"GeoTime and nSpace2 are interactive visual analytics tools that were used to examine and interpret all four of the 2008 VAST Challenge datasets. GeoTime excels in visualizing event patterns in time and space, or in time and any abstract landscape, while nSpace2 is a web-based analytical tool designed to support every step of the analytical process. nSpace2 is an integrating analytic environment. This paper highlights the VAST analytical experience with these tools that contributed to the success of these tools and this team for the third consecutive year.",Lynn Chien;Annie Tat;Pascale Proulx;Adeel Khamisa;William Wright,Lynn Chien;Annie Tat;Pascale Proulx;Adeel Khamisa;William Wright,"Oculus Info, Inc.;Oculus Info, Inc.;Oculus Info, Inc.;Oculus Info, Inc.;Oculus Info, Inc.",0.1109/vast.2008.4677355;10.1109/infvis.2004.27,,5.0,3.0,4.0,143.0,,,visualizing event patterns;interpret 2008 vast;geotime;landscape nspace2 web;integrating analytic,0.5481;0.4672;0.4009;0.1646;0.0907,"[np.int64(-1), -1, -1, -1, -1]",156;-1;-1;-1;-1,156,156
InfoVis,2019,A Comparison of Visualizations for Identifying Correlation over Space and Time,10.1109/tvcg.2019.2934807,http://dx.doi.org/10.1109/TVCG.2019.2934807,375.0,385.0,J,"Observing the relationship between two or more variables over space and time is essential in many domains. For instance, looking, for different countries, at the evolution of both the life expectancy at birth and the fertility rate will give an overview of their demographics. The choice of visual representation for such multivariate data is key to enabling analysts to extract patterns and trends. Prior work has compared geo-temporal visualization techniques for a single thematic variable that evolves over space and time, or for two variables at a specific point in time. But how effective visualization techniques are at communicating correlation between two variables that evolve over space and time remains to be investigated. We report on a study comparing three techniques that are representative of different strategies to visualize geo-temporal multivariate data: either juxtaposing all locations for a given time step, or juxtaposing all time steps for a given location; and encoding thematic attributes either using symbols overlaid on top of map features, or using visual channels of the map features themselves. Participants performed a series of tasks that required them to identify if two variables were correlated over time and if there was a pattern in their evolution. Tasks varied in granularity for both dimensions: time (all time steps, a subrange of steps, one step only) and space (all locations, locations in a subregion, one location only). Our results show that a visualization's effectiveness depends strongly on the task to be carried out. Based on these findings we present a set of design guidelines about geo-temporal visualization techniques for communicating correlation.",Vanessa Peña Araya;Emmanuel Pietriga;Anastasia Bezerianos,Vanessa Peña-Araya;Emmanuel Pietriga;Anastasia Bezerianos,"Univ. Paris-Sud, CNRS, INRIA, Université Paris-Saclay;Univ. Paris-Sud, CNRS, INRIA, Université Paris-Saclay;Univ. Paris-Sud, CNRS, INRIA, Université Paris-Saclay",10.1109/tvcg.2016.2598862;10.1109/tvcg.2011.185;10.1109/tvcg.2015.2467199;10.1109/tvcg.2007.70623;10.1109/tvcg.2014.2346979;10.1109/tvcg.2018.2865141;10.1109/tvcg.2015.2467671;10.1109/tvcg.2011.194;10.1109/tvcg.2008.125;10.1109/tvcg.2013.130;10.1109/tvcg.2015.2467091;10.1109/tvcg.2016.2598862,"geo-temporal data,bivariate maps,correlation,controlled study,bar chart,Dorling cartogram,small multiples",23.0,17.0,71.0,1302.0,,,visualize geo temporal;variables correlated;evolve;design guidelines;data key enabling,0.7163;0.3025;0.1180;0.1017;-0.0041,"[np.int64(-1), -1, -1, -1, -1]",222;-1;-1;-1;-1,222,222
Vis,2023,A Comparative Visual Analytics Framework for Evaluating Evolutionary Processes in Multi-Objective Optimization,10.1109/tvcg.2023.3326921,http://dx.doi.org/10.1109/TVCG.2023.3326921,661.0,671.0,J,"Evolutionary multi-objective optimization (EMO) algorithms have been demonstrated to be effective in solving multi-criteria decision-making problems. In real-world applications, analysts often employ several algorithms concurrently and compare their solution sets to gain insight into the characteristics of different algorithms and explore a broader range of feasible solutions. However, EMO algorithms are typically treated as black boxes, leading to difficulties in performing detailed analysis and comparisons between the internal evolutionary processes. Inspired by the successful application of visual analytics tools in explainable AI, we argue that interactive visualization can significantly enhance the comparative analysis between multiple EMO algorithms. In this paper, we present a visual analytics framework that enables the exploration and comparison of evolutionary processes in EMO algorithms. Guided by a literature review and expert interviews, the proposed framework addresses various analytical tasks and establishes a multi-faceted visualization design to support the comparative analysis of intermediate generations in the evolution as well as solution sets. We demonstrate the effectiveness of our framework through case studies on benchmarking and real-world multi-objective optimization problems to elucidate how analysts can leverage our framework to inspect and compare diverse algorithms.",Yansong Huang;Zherui Zhang;Ao Jiao;Yuxin Ma;Ran Cheng,Yansong Huang;Zherui Zhang;Ao Jiao;Yuxin Ma;Ran Cheng,"Department of Computer Science and Engineering, Southern University of Science and Technology, China;Department of Computer Science and Engineering, Southern University of Science and Technology, China;Department of Computer Science and Engineering, Southern University of Science and Technology, China;Department of Computer Science and Engineering, Southern University of Science and Technology, China;Department of Computer Science and Engineering, Southern University of Science and Technology, China",0.1109/tvcg.2015.2467851;10.1109/tvcg.2017.2744199;10.1109/tvcg.2018.2864500;10.1109/tvcg.2017.2744938;10.1109/tvcg.2017.2744378;10.1109/tvcg.2020.3028888;10.1109/tvcg.2014.2346578;10.1109/tvcg.2020.3030361;10.1109/tvcg.2020.3030347;10.1109/visual.2005.1532820;10.1109/vast50239.2020.00006;10.1109/tvcg.2021.3114790;10.1109/tvcg.2020.3030418;10.1109/tvcg.2020.3030458;10.1109/tvcg.2021.3114850;10.1109/vast50239.2020.00007;10.1109/tvcg.2020.3030432;10.1109/tvcg.2018.2864499,"Visual analytics,evolutionary multi-objective optimization",,2.0,79.0,900.0,,,evolutionary multi objective;analytics tools explainable;benchmarking real;paper;framework addresses,0.5723;0.4337;0.1664;0.0518;0.0134,"[np.int64(-1), -1, -1, -1, -1]",232;-1;-1;-1;-1,232,232
Vis,1997,Visualization of plant growth,10.1109/visual.1997.663925,http://dx.doi.org/10.1109/VISUAL.1997.663925,475.0,478.0,C,"The measurement, analysis and visualization of plant growth is of primary interest to plant biologists. We are developing software tools to support such investigations. There are two parts in this investigation, namely growth visualization of (i) a plant root and (ii) a plant stem. For both domains, the input data is a stream of images taken by cameras. The tools being developed make it possible to measure various time-varying quantities, such as differential growth. For both domains, the plant is modeled by using flexible templates to represent non-rigid motions.",Jeremy J. Loomis;Xiuwen Liu;Zhaohua Ding;Kikuo Fujimura;Michael L. Evans;Hideo Ishikawa,J.J. Loomis;Xiuwen Liu;Zhaohua Ding;K. Fujimura;M.L. Evans;H. Ishikawa,"Dept. of Computer and Information Science, The Ohio State University, Columbus, OH;Dept. of Computer and Information Science, The Ohio State University, Columbus, OH;Biomedical Engineering Center, The Ohio State University, Columbus, OH;Dept. of Computer and Information Science, The Ohio State University, Columbus, OH;Dept. of Plant Biology, The Ohio State University, Columbus, OH;Dept. of Plant Biology, The Ohio State University, Columbus, OH",,"Shape representation, image sequence analysis, non-rigid motion, plant biology",12.0,1.0,14.0,81.0,,,visualization plant growth;non rigid motions;taken cameras tools;using flexible templates;stream,0.7748;0.2947;0.2661;0.1491;0.0153,"[np.int64(-1), -1, -1, -1, -1]",298;-1;-1;-1;-1,298,298
InfoVis,2016,Many-to-Many Geographically-Embedded Flow Visualisation: An Evaluation,10.1109/tvcg.2016.2598885,http://dx.doi.org/10.1109/TVCG.2016.2598885,411.0,420.0,J,"Showing flows of people and resources between multiple geographic locations is a challenging visualisation problem. We conducted two quantitative user studies to evaluate different visual representations for such dense many-to-many flows. In our first study we compared a bundled node-link flow map representation and OD Maps [37] with a new visualisation we call MapTrix. Like OD Maps, MapTrix overcomes the clutter associated with a traditional flow map while providing geographic embedding that is missing in standard OD matrix representations. We found that OD Maps and MapTrix had similar performance while bundled node-link flow map representations did not scale at all well. Our second study compared participant performance with OD Maps and MapTrix on larger data sets. Again performance was remarkably similar.",Yalong Yang 0001;Tim Dwyer;Sarah Goodwin;Kim Marriott,Yalong Yang;Tim Dwyer;Sarah Goodwin;Kim Marriott,"Monash University, CSIRO, Victoria;Monash University;Monash University;Monash University, CSIRO, Victoria",10.1109/infvis.2004.1;10.1109/tvcg.2011.202;10.1109/tvcg.2014.2346441;10.1109/tvcg.2008.165;10.1109/infvis.2005.1532150;10.1109/infvis.2004.1,Flow Maps;Matrix Visualisation;Cartographic Information Visualisation,86.0,63.0,39.0,2539.0,HM,,flow map representations;people resources multiple;standard od matrix;bundled;second study compared,0.6535;0.2595;0.1523;0.0748;0.0130,"[np.int64(-1), -1, -1, -1, -1]",130;-1;-1;-1;-1,130,130
Vis,2010,Noodles: A Tool for Visualization of Numerical Weather Model Ensemble Uncertainty,10.1109/tvcg.2010.181,http://dx.doi.org/10.1109/TVCG.2010.181,1421.0,1430.0,J,"Numerical weather prediction ensembles are routinely used for operational weather forecasting. The members of these ensembles are individual simulations with either slightly perturbed initial conditions or different model parameterizations, or occasionally both. Multi-member ensemble output is usually large, multivariate, and challenging to interpret interactively. Forecast meteorologists are interested in understanding the uncertainties associated with numerical weather prediction; specifically variability between the ensemble members. Currently, visualization of ensemble members is mostly accomplished through spaghetti plots of a single midtroposphere pressure surface height contour. In order to explore new uncertainty visualization methods, the Weather Research and Forecasting (WRF) model was used to create a 48-hour, 18 member parameterization ensemble of the 13 March 1993 ""Superstorm"". A tool was designed to interactively explore the ensemble uncertainty of three important weather variables: water-vapor mixing ratio, perturbation potential temperature, and perturbation pressure. Uncertainty was quantified using individual ensemble member standard deviation, inter-quartile range, and the width of the 95% confidence interval. Bootstrapping was employed to overcome the dependence on normality in the uncertainty metrics. A coordinated view of ribbon and glyph-based uncertainty visualization, spaghetti plots, iso-pressure colormaps, and data transect plots was provided to two meteorologists for expert evaluation. They found it useful in assessing uncertainty in the data, especially in finding outliers in the ensemble run and therefore avoiding the WRF parameterizations that lead to these outliers. Additionally, the meteorologists could identify spatial regions where the uncertainty was significantly high, allowing for identification of poorly simulated storm environments and physical interpretation of these model issues.",Jibonananda Sanyal;Song Zhang 0004;Jamie L. Dyer;Andrew Mercer 0001;Philip Amburn;Robert J. Moorhead,Jibonananda Sanyal;Song Zhang;Jamie Dyer;Andrew Mercer;Philip Amburn;Robert Moorhead,"Geosystems Research Institute, Mississippi State University, USA;Department of Computer Science and Engineering, Mississippi State University, USA;Department of Geosciences, Mississippi State University, USA;Department of Geosciences and Northern Gulf Institute, Mississippi State University, USA;Geosystems Research Institute, Mississippi State University, USA;Geosystems Research Institute, Mississippi State University, USA",10.1109/tvcg.2009.114;10.1109/infvis.2002.1173145;10.1109/tvcg.2009.114,"Uncertainty visualization, weather ensemble, geographic/geospatial visualization, glyph-based techniques, time-varying data, qualitative evaluation",307.0,192.0,58.0,3132.0,,,weather prediction ensembles;uncertainty visualization spaghetti;midtroposphere pressure;view ribbon glyph;model used create,0.6616;0.5643;0.2166;0.1101;0.0729,"[np.int64(-1), np.int64(-1), -1, -1, -1]",48;159;-1;-1;-1,48;159,48
InfoVis,2013,Nanocubes for Real-Time Exploration of Spatiotemporal Datasets,10.1109/tvcg.2013.179,http://dx.doi.org/10.1109/TVCG.2013.179,2456.0,2465.0,J,"Consider real-time exploration of large multidimensional spatiotemporal datasets with billions of entries, each defined by a location, a time, and other attributes. Are certain attributes correlated spatially or temporally? Are there trends or outliers in the data? Answering these questions requires aggregation over arbitrary regions of the domain and attributes of the data. Many relational databases implement the well-known data cube aggregation operation, which in a sense precomputes every possible aggregate query over the database. Data cubes are sometimes assumed to take a prohibitively large amount of space, and to consequently require disk storage. In contrast, we show how to construct a data cube that fits in a modern laptop's main memory, even for billions of entries; we call this data structure a nanocube. We present algorithms to compute and query a nanocube, and show how it can be used to generate well-known visual encodings such as heatmaps, histograms, and parallel coordinate plots. When compared to exact visualizations created by scanning an entire dataset, nanocube plots have bounded screen error across a variety of scales, thanks to a hierarchical structure in space and time. We demonstrate the effectiveness of our technique on a variety of real-world datasets, and present memory, timing, and network bandwidth measurements. We find that the timings for the queries in our examples are dominated by network and user-interaction latencies.",Lauro Didier Lins;James T. Klosowski;Carlos Eduardo Scheidegger,Lauro Lins;James T. Klosowski;Carlos Scheidegger,"AT&T Research, USA;AT&T Research, USA;AT&T Research, USA",10.1109/tvcg.2006.161;10.1109/infvis.2002.1173141;10.1109/tvcg.2009.191;10.1109/vast.2008.4677357;10.1109/tvcg.2007.70594;10.1109/infvis.2002.1173156;10.1109/visual.1990.146386;10.1109/tvcg.2011.185;10.1109/tvcg.2006.161,"Data cube, Data structures, Interactive exploration",319.0,174.0,36.0,3076.0,HM,,data cubes;spatiotemporal;nanocube used;prohibitively;screen error,0.6653;0.3567;0.2817;0.1129;0.0109,"[np.int64(-1), -1, -1, -1, -1]",144;-1;-1;-1;-1,144,144
Vis,1998,Seabed visualization,10.1109/visual.1998.745348,http://dx.doi.org/10.1109/VISUAL.1998.745348,479.0,481.0,C,"The development of a high speed multi-frequency continuous scan sonar at Sonar Research &amp; Development Ltd has resulted in the acquisition of extremely accurate, high resolution bathymetric data. This rich underwater data provides new challenges and possibilities within the field of seabed visualization. This paper introduces the reader to seabed visualization by describing two example case studies which use the Seabed Visualization System developed at SRD. Both case studies, harbour wall and shipwreck visualization, are implemented using real survey data. The high resolution of the data obtained means slight changes in the seabed topography are easily distinguishable. Annual survey inspections in both case studies enable comparisons to be made between the data sets making the visualization system an important tool for management and planning.",Paul Chapman;Peter Stevens;Derek Wills;Graham R. Brookes,P. Chapman;P. Stevens;D. Wills;G. Brookes,"Department of Computer Science, University of Hull, UK;Department of Computer Science, University of Hull, UK;Department of Computer Science, University of Hull, UK;Department of Computer Science, University of Hull, UK",,,15.0,7.0,5.0,92.0,,,seabed visualization developed;survey data high;tool management planning;multi frequency continuous;resulted acquisition,0.8249;0.2173;0.1971;0.0857;-0.0184,"[np.int64(-1), -1, -1, -1, -1]",77;-1;-1;-1;-1,77,77
SciVis,2015,TelCoVis: Visual Exploration of Co-occurrence in Urban Human Mobility Based on Telco Data,10.1109/tvcg.2015.2467194,http://dx.doi.org/10.1109/TVCG.2015.2467194,935.0,944.0,J,"Understanding co-occurrence in urban human mobility (i.e. people from two regions visit an urban place during the same time span) is of great value in a variety of applications, such as urban planning, business intelligence, social behavior analysis, as well as containing contagious diseases. In recent years, the widespread use of mobile phones brings an unprecedented opportunity to capture large-scale and fine-grained data to study co-occurrence in human mobility. However, due to the lack of systematic and efficient methods, it is challenging for analysts to carry out in-depth analyses and extract valuable information. In this paper, we present TelCoVis, an interactive visual analytics system, which helps analysts leverage their domain knowledge to gain insight into the co-occurrence in urban human mobility based on telco data. Our system integrates visualization techniques with new designs and combines them in a novel way to enhance analysts' perception for a comprehensive exploration. In addition, we propose to study the correlations in co-occurrence (i.e. people from multiple regions visit different places during the same time span) by means of biclustering techniques that allow analysts to better explore coordinated relationships among different regions and identify interesting patterns. The case studies based on a real-world dataset and interviews with domain experts have demonstrated the effectiveness of our system in gaining insights into co-occurrence and facilitating various analytical tasks.",Wenchao Wu;Jiayi Xu 0001;Haipeng Zeng;Yixian Zheng;Huamin Qu;Bing Ni;Mingxuan Yuan;Lionel M. Ni,Wenchao Wu;Jiayi Xu;Haipeng Zeng;Yixian Zheng;Huamin Qu;Bing Ni;Mingxuan Yuan;Lionel M. Ni,"Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Noah's Ark Lab, Huawei Technologies Investment Co. Ltd.;Noah's Ark Lab, Huawei Technologies Investment Co. Ltd.;University of Macau",10.1109/vast.2010.5652478;10.1109/tvcg.2013.193;10.1109/tvcg.2014.2346276;10.1109/tvcg.2013.226;10.1109/tvcg.2011.166;10.1109/tvcg.2013.173;10.1109/tvcg.2014.2346271;10.1109/vast.2011.6102455;10.1109/infvis.2000.885091;10.1109/tvcg.2014.2346665;10.1109/tvcg.2012.265;10.1109/tvcg.2013.228;10.1109/vast.2014.7042490;10.1109/tvcg.2014.2346922;10.1109/vast.2010.5652478,"Co-occurrence, human mobility, telco data, bicluster, visual analytics",102.0,69.0,45.0,2158.0,,,urban human mobility;visual analytics;understanding occurrence;biclustering techniques;diseases recent,0.6425;0.4833;0.2891;0.2713;0.1051,"[np.int64(-1), np.int64(-1), -1, -1, -1]",67;201;-1;-1;-1,67;201,67
SciVis,2015,Distribution Driven Extraction and Tracking of Features for Time-varying Data Analysis,10.1109/tvcg.2015.2467436,http://dx.doi.org/10.1109/TVCG.2015.2467436,837.0,846.0,J,"Effective analysis of features in time-varying data is essential in numerous scientific applications. Feature extraction and tracking are two important tasks scientists rely upon to get insights about the dynamic nature of the large scale time-varying data. However, often the complexity of the scientific phenomena only allows scientists to vaguely define their feature of interest. Furthermore, such features can have varying motion patterns and dynamic evolution over time. As a result, automatic extraction and tracking of features becomes a non-trivial task. In this work, we investigate these issues and propose a distribution driven approach which allows us to construct novel algorithms for reliable feature extraction and tracking with high confidence in the absence of accurate feature definition. We exploit two key properties of an object, motion and similarity to the target feature, and fuse the information gained from them to generate a robust feature-aware classification field at every time step. Tracking of features is done using such classified fields which enhances the accuracy and robustness of the proposed algorithm. The efficacy of our method is demonstrated by successfully applying it on several scientific data sets containing a wide range of dynamic time-varying features.",Soumya Dutta;Han-Wei Shen,Soumya Dutta;Han-Wei Shen,"GRAVITY group, The Ohio State University;GRAVITY group, The Ohio State University",10.1109/tvcg.2007.70599;10.1109/visual.1993.398877;10.1109/visual.2004.107;10.1109/tvcg.2011.246;10.1109/tvcg.2007.70615;10.1109/visual.2003.1250374;10.1109/tvcg.2013.152;10.1109/tvcg.2014.2346423;10.1109/tvcg.2007.70579;10.1109/visual.1996.567807;10.1109/visual.1998.745288;10.1109/tvcg.2008.163;10.1109/tvcg.2008.140;10.1109/tvcg.2007.70599,"Gaussian mixture model (GMM), Incremental learning, Feature extraction and tracking, Time-varying data analysis",44.0,34.0,45.0,1230.0,,,time varying features;extraction tracking high;scientists vaguely;algorithms reliable;definition exploit key,0.5741;0.2709;0.2649;0.1686;-0.0001,"[np.int64(-1), -1, -1, -1, -1]",279;-1;-1;-1;-1,279,279
InfoVis,2004,Keynote Address: From Information Visualization to Sensemaking: Connecting the Mind's Eye to the Mind's Muscle,10.1109/infvis.2004.44,http://dx.doi.org/10.1109/INFVIS.2004.44,,,M,Provides an abstract of the keynote presentation and a brief professional biography of the presenter. The complete presentation was not made available for publication as part of the conference proceedings.,Stuart K. Card,S. Card,"Palo Alto Research Center, Inc.orporated, USA",,,9.0,1.0,0.0,182.0,,,abstract keynote presentation;provides;publication;professional;available,0.5086;0.2441;0.2099;0.1765;0.0690,"[np.int64(-1), -1, -1, -1, -1]",114;-1;-1;-1;-1,114,114
Vis,2001,PixelFlex: a reconfigurable multi-projector display system,10.1109/visual.2001.964508,http://dx.doi.org/10.1109/VISUAL.2001.964508,167.0,554.0,C,"This paper presents PixelFlex - a spatially reconfigurable multi-projector display system. The PixelFlex system is composed of ceiling-mounted projectors, each with computer-controlled pan, tilt, zoom and focus; and a camera for closed-loop calibration. Working collectively, these controllable projectors function as a single logical display capable of being easily modified into a variety of spatial formats of differing pixel density, size and shape. New layouts are automatically calibrated within minutes to generate the accurate warping and blending functions needed to produce seamless imagery across planar display surfaces, thus giving the user the flexibility to quickly create, save and restore multiple screen configurations. Overall, PixelFlex provides a new level of automatic reconfigurability and usage, departing from the static, one-size-fits-all design of traditional large-format displays. As a front-projection system, PixelFlex can be installed in most environments with space constraints and requires little or no post-installation mechanical maintenance because of the closed-loop calibration.",Ruigang Yang;David Gotz;Justin Hensley;Herman Towles;Michael S. Brown,Ruigang Yang;D. Gotz;J. Hensley;H. Towles;M.S. Brown,"Department of Computer Science, University of North Carolina, Chapel Hill, USA;Department of Computer Science, University of North Carolina, Chapel Hill, USA;Department of Computer Science, University of North Carolina, Chapel Hill, USA;Department of Computer Science, University of North Carolina, Chapel Hill, USA;Department of Computer Science, University of Kentucky, USA",10.1109/visual.2000.885685;10.1109/visual.1999.809890;10.1109/visual.1999.809883;10.1109/visual.2000.885712,"large-format projection display, camera-based registration and calibration",277.0,33.0,30.0,664.0,,,reconfigurable multi projector;overall pixelflex provides;little post installation;minutes generate accurate;logical,0.7340;0.3360;0.1055;0.0467;0.0329,"[np.int64(-1), -1, -1, -1, -1]",22;-1;-1;-1;-1,22,22
InfoVis,2004,BinX: Dynamic Exploration of Time Series Datasets Across Aggregation Levels,10.1109/infvis.2004.11,http://dx.doi.org/10.1109/INFVIS.2004.11,2.0,2.0,M,"Many fields of study produce time series datasets, and both the size and number of theses datasets are increasing rapidly due to the improvement of data accumulation methods such as small, cheap sensors and routine logging of events. Humans often fail to comprehend the structure of a long time series dataset because of the overwhelming amount of data and the range of different time scales at which there may be meaningful patterns. BinX is an interactive tool that provides dynamic visualization and manipulation of long time series datasets. The dataset is visualized through user controlled aggregation, augmented by various information visualization techniques.",Lior Berry;Tamara Munzner,L. Berry;T. Munzner,"University of British Columbia, Canada;University of British Columbia, Canada",0.1109/infvis.1999.801851;10.1109/infvis.1998.729557,,57.0,8.0,4.0,375.0,,,time series datasets;visualization techniques;binx interactive tool;increasing rapidly;structure,0.6074;0.4266;0.3065;0.1856;0.1475,"[np.int64(-1), -1, -1, -1, -1]",216;-1;-1;-1;-1,216,216
Vis,1996,Perceptualisation using a tactile mouse,10.1109/visual.1996.568104,http://dx.doi.org/10.1109/VISUAL.1996.568104,181.0,188.0,C,"Whilst there has been considerable effort in constructing force feedback devices for use in virtual environments, and in the use of touch as a prosthesis for the blind, there has been little work on the use of touch in the visualisation or more properly, perceptualisation of data. Touch potentially offers an additional dimension of perception where visualisation is limited by screen size, resolution, and visual overload. We describe some tactile mice and experiments in using tactile mice for a variety of perceptualisation tasks.",Robert G. Hughes;A. Robin Forrest,R.G. Hughes;A.R. Forrest,"School of Information Systems, University of East Anglia, Norwich, Norfolk, GB;School of Information Systems, University of East Anglia, Norwich, Norfolk, GB",10.1109/visual.1995.480802;10.1109/visual.1995.480802,,53.0,6.0,24.0,97.0,,,using tactile mice;resolution visual;effort constructing force;whilst;potentially offers,0.7391;0.3058;0.1666;0.0881;0.0030,"[np.int64(-1), -1, -1, -1, -1]",79;-1;-1;-1;-1,79,79
InfoVis,2004,Paint Inspired Color Mixing and Compositing for Visualization,10.1109/infvis.2004.52,http://dx.doi.org/10.1109/INFVIS.2004.52,113.0,118.0,C,"Color is often used to convey information, and color compositing is often required while visualizing multiattribute information. This paper proposes an alternative method for color compositing. In order to present understandable color blending to the general public, several techniques are proposed. First, a paint-inspired RYB color space is used. In addition, noise patterns are employed to produce subregions of pure color within an overlapped region. We show examples to demonstrate the effectiveness of our technique for visualization",Nathan Gossett;Baoquan Chen,N. Gossett;Baoquan Chen,"University of Minnesota, Twin city, France;University of Minnesota, Twin city, France",10.1109/visual.2003.1250362;10.1109/visual.2003.1250362,"RYB, Color Mixing, Perception",81.0,21.0,6.0,688.0,,,information color compositing;noise patterns;produce subregions;ryb;examples demonstrate,0.6945;0.3277;0.1913;0.1812;0.1530,"[np.int64(-1), -1, -1, -1, -1]",314;-1;-1;-1;-1,314,314
SciVis,2014,Visualizing 2-dimensional Manifolds with Curve Handles in 4D,10.1109/tvcg.2014.2346425,http://dx.doi.org/10.1109/TVCG.2014.2346425,2575.0,2584.0,J,"In this paper, we present a mathematical visualization paradigm for exploring curves embedded in 3D and surfaces in 4D mathematical world. The basic problem is that, 3D figures of 4D mathematical entities often twist, turn, and fold back on themselves, leaving important properties behind the surface sheets. We propose an interactive system to visualize the topological features of the original 4D surface by slicing its 3D figure into a series of feature diagram. A novel 4D visualization interface is designed to allow users to control 4D topological shapes via the collection of diagram handles using the established curve manipulation mechanism. Our system can support rich mathematical interaction of 4D mathematical objects which is very difficult with any existing approach. We further demonstrate the effectiveness of the proposed visualization tool using various experimental results and cases studies.",Hui Zhang 0006;Jianguang Weng;Guangchen Ruan,Hui Zhang;Jianguang Weng;Guangchen Ruan,"Pervasive Technology Institute, Indiana University;Zhejiang University of Media and Communication;School of Informatics and Computing, Indiana University",10.1109/tvcg.2012.242;10.1109/visual.2005.1532804;10.1109/visual.2005.1532843;10.1109/tvcg.2010.151;10.1109/visual.2005.1532833;10.1109/tvcg.2007.70593;10.1109/tvcg.2012.242,"math visualization, 4D, deformation, Reidemeister theorem",13.0,8.0,38.0,426.0,,,4d visualization interface;using established curve;twist turn;important properties;allow users,0.7245;0.1907;0.1797;0.0820;0.0515,"[np.int64(-1), -1, -1, -1, -1]",110;-1;-1;-1;-1,110,110
VAST,2015,Sequencing of categorical time series,10.1109/vast.2015.7347684,http://dx.doi.org/10.1109/VAST.2015.7347684,213.0,214.0,M,"Exploring and comparing categorical time series and finding temporal patterns are complex tasks in the field of time series data mining. Although different analysis approaches exist, these tasks remain challenging, especially when numerous time series are considered at once. We propose a visual analysis approach that supports exploring such data by ordering time series in meaningful ways. We provide interaction techniques to steer the automated arrangement and to allow users to investigate patterns in detail.",Christian Richter;Martin Luboschik;Martin Rohlig;Heidrun Schumann,Christian Richter;Martin Luboschik;Martin Röhlig;Heidrun Schumann,"Universitat Rostock, Rostock, Mecklenburg-Vorpommern, DE;Universitat Rostock, Rostock, Mecklenburg-Vorpommern, DE;Universitat Rostock, Rostock, Mecklenburg-Vorpommern, DE;University of Rostock",,,4.0,2.0,5.0,198.0,,,finding temporal patterns;propose visual;mining different;especially;allow users,0.6172;0.2316;0.2123;0.0445;-0.0565,"[np.int64(-1), -1, -1, -1, -1]",127;-1;-1;-1;-1,127,127
SciVis,2013,Acuity-Driven Gigapixel Visualization,10.1109/tvcg.2013.127,http://dx.doi.org/10.1109/TVCG.2013.127,2886.0,2895.0,J,"We present a framework for acuity-driven visualization of super-high resolution image data on gigapixel displays. Tiled display walls offer a large workspace that can be navigated physically by the user. Based on head tracking information, the physical characteristics of the tiled display and the formulation of visual acuity, we guide an out-of-core gigapixel rendering scheme by delivering high levels of detail only in places where it is perceivable to the user. We apply this principle to gigapixel image rendering through adaptive level of detail selection. Additionally, we have developed an acuity-driven tessellation scheme for high-quality Focus-and-Context (F+C) lenses that significantly reduces visual artifacts while accurately capturing the underlying lens function. We demonstrate this framework on the Reality Deck, an immersive gigapixel display. We present the results of a user study designed to quantify the impact of our acuity-driven rendering optimizations in the visual exploration process. We discovered no evidence suggesting a difference in search task performance between our framework and naive rendering of gigapixel resolution data, while realizing significant benefits in terms of data transfer overhead. Additionally, we show that our acuity-driven tessellation scheme offers substantially increased frame rates when compared to naive pre-tessellation, while providing indistinguishable image quality.",Charilaos Papadopoulos;Arie E. Kaufman,Charilaos Papadopoulos;Arie E. Kaufman,"Stony Brook University, USA;Stony Brook University, USA",10.1109/tvcg.2011.231;10.1109/infvis.2004.66,"Gigapixel visualization, visual acuity, focus and context, Reality Deck, gigapixel display",13.0,8.0,45.0,710.0,,,acuity driven rendering;guide core gigapixel;demonstrate framework reality;workspace navigated;benefits,0.6617;0.1607;0.1476;0.0903;0.0254,"[np.int64(-1), -1, -1, -1, -1]",61;-1;-1;-1;-1,61,61
VAST,2007,Balancing Interactive Data Management of Massive Data with Situational Awareness through Smart Aggregation,10.1109/vast.2007.4388998,http://dx.doi.org/10.1109/VAST.2007.4388998,67.0,74.0,C,"Designing a visualization system capable of processing, managing, and presenting massive data sets while maximizing the user's situational awareness (SA) is a challenging, but important, research question in visual analytics. Traditional data management and interactive retrieval approaches have often focused on solving the data overload problem at the expense of the user's SA. This paper discusses various data management strategies and the strengths and limitations of each approach in providing the user with SA. A new data management strategy, coined Smart Aggregation, is presented as a powerful approach to overcome the challenges of both massive data sets and maintaining SA. By combining automatic data aggregation with user-defined controls on what, how, and when data should be aggregated, we present a visualization system that can handle massive amounts of data while affording the user with the best possible SA. This approach ensures that a system is always usable in terms of both system resources and human perceptual resources. We have implemented our Smart Aggregation approach in a visual analytics system called VIAssist (Visual Assistant for Information Assurance Analysis) to facilitate exploration, discovery, and SA in the domain of Information Assurance.",Daniel R. Tesone;John R. Goodall,Daniel R. Tesone;John R. Goodall,"Division of Applied Visions Inc., Secure Decisions;Division of Applied Visions Inc., Secure Decisions",10.1109/vast.2006.261437;10.1109/visual.2005.1532792;10.1109/infvis.2004.10;10.1109/vast.2006.261437,"Data management, visual analytics, data retrieval, information visualization, smart aggregation, situational awareness",27.0,11.0,9.0,274.0,,,visual analytics;providing user sa;overload problem;important research;defined,0.6984;0.1942;0.1547;0.1065;0.0649,"[np.int64(-1), -1, -1, -1, -1]",201;-1;-1;-1;-1,201,201
SciVis,2014,Multiscale Symmetry Detection in Scalar Fields by Clustering Contours,10.1109/tvcg.2014.2346332,http://dx.doi.org/10.1109/TVCG.2014.2346332,2427.0,2436.0,J,"The complexity in visualizing volumetric data often limits the scope of direct exploration of scalar fields. Isocontour extraction is a popular method for exploring scalar fields because of its simplicity in presenting features in the data. In this paper, we present a novel representation of contours with the aim of studying the similarity relationship between the contours. The representation maps contours to points in a high-dimensional transformation-invariant descriptor space. We leverage the power of this representation to design a clustering based algorithm for detecting symmetric regions in a scalar field. Symmetry detection is a challenging problem because it demands both segmentation of the data and identification of transformation invariant segments. While the former task can be addressed using topological analysis of scalar fields, the latter requires geometry based solutions. Our approach combines the two by utilizing the contour tree for segmenting the data and the descriptor space for determining transformation invariance. We discuss two applications, query driven exploration and asymmetry visualization, that demonstrate the effectiveness of the approach.",Dilip Mathew Thomas;Vijay Natarajan,Dilip Mathew Thomas;Vijay Natarajan,"Department of Computer Science and Automation, Indian Institute of Science, Bangalore, India;Department of Computer Science and Automation and Supercomputer Education Research Centre, Indian Institute of Science, Bangalore, India",10.1109/tvcg.2013.142;10.1109/visual.1999.809869;10.1109/tvcg.2006.149;10.1109/tvcg.2011.236;10.1109/tvcg.2008.143;10.1109/tvcg.2011.258;10.1109/tvcg.2013.148;10.1109/tvcg.2013.142,"Scalar field visualization, symmetry detection, contour tree, data exploration",52.0,33.0,43.0,571.0,,,visualizing volumetric data;fields isocontour;identification transformation invariant;addressed using topological;combines,0.6331;0.4523;0.2882;0.2366;-0.0202,"[np.int64(-1), -1, -1, -1, -1]",84;-1;-1;-1;-1,84,84
Vis,2000,Simplification of tetrahedral meshes with accurate error evaluation,10.1109/visual.2000.885680,http://dx.doi.org/10.1109/VISUAL.2000.885680,85.0,92.0,C,"The techniques for reducing the size of a volume dataset by preserving both the geometrical/topological shape and the information encoded in an attached scalar field are attracting growing interest. Given the framework of incremental 3D mesh simplification based on edge collapse, we propose an approach for the integrated evaluation of the error introduced by both the modification of the domain and the approximation of the field of the original volume dataset. We present and compare various techniques to evaluate the approximation error or to produce a sound prediction. A flexible simplification tool has been implemented, which provides a different degree of accuracy and computational efficiency for the selection of the edge to be collapsed. Techniques for preventing a geometric or topological degeneration of the mesh are also presented.",Paolo Cignoni;D. Constanza;Claudio Montani;Claudio Rocchini;Roberto Scopigno,P. Cignoni;D. Costanza;C. Montani;C. Rocchini;R. Scopigno,"Istituto Scienza e Tecnologia dellInformazione, Consiglio Nationale delle Ricerche, Italy;Istituto Scienza e Tecnologia dellInformazione, Consiglio Nationale delle Ricerche, Italy;Istituto Scienza e Tecnologia dellInformazione, Consiglio Nationale delle Ricerche, Italy;Istituto Scienza e Tecnologia dellInformazione, Consiglio Nationale delle Ricerche, Italy;Istituto Scienza e Tecnologia dellInformazione, Consiglio Nationale delle Ricerche, Italy",10.1109/visual.1998.745315;10.1109/visual.1997.663907;10.1109/visual.1998.745329;10.1109/visual.1998.745312;10.1109/visual.1998.745315,"Simplicial Complexes, Mesh Simplification,Volume Visualization, Unstructured Grids",149.0,32.0,24.0,167.0,,,3d mesh simplification;original volume dataset;selection edge;integrated evaluation error;encoded attached scalar,0.6899;0.4667;0.0988;0.0922;0.0753,"[np.int64(-1), -1, -1, -1, -1]",112;-1;-1;-1;-1,112,112
SciVis,2014,ViSlang: A System for Interpreted Domain-Specific Languages for Scientific Visualization,10.1109/tvcg.2014.2346318,http://dx.doi.org/10.1109/TVCG.2014.2346318,2388.0,2396.0,J,"Researchers from many domains use scientific visualization in their daily practice. Existing implementations of algorithms usually come with a graphical user interface (high-level interface), or as software library or source code (low-level interface). In this paper we present a system that integrates domain-specific languages (DSLs) and facilitates the creation of new DSLs. DSLs provide an effective interface for domain scientists avoiding the difficulties involved with low-level interfaces and at the same time offering more flexibility than high-level interfaces. We describe the design and implementation of ViSlang, an interpreted language specifically tailored for scientific visualization. A major contribution of our design is the extensibility of the ViSlang language. Novel DSLs that are tailored to the problems of the domain can be created and integrated into ViSlang. We show that our approach can be added to existing user interfaces to increase the flexibility for expert users on demand, but at the same time does not interfere with the user experience of novice users. To demonstrate the flexibility of our approach we present new DSLs for volume processing, querying and visualization. We report the implementation effort for new DSLs and compare our approach with Matlab and Python implementations in terms of run-time performance.",Peter Rautek;Stefan Bruckner;M. Eduard Gröller;Markus Hadwiger,Peter Rautek;Stefan Bruckner;M. Eduard Gröller;Markus Hadwiger,"KAUST;University of Bergen;Vienna University of Technology, VrVis Research Center;KAUST",10.1109/visual.2005.1532792;10.1109/visual.1992.235219;10.1109/tvcg.2009.174;10.1109/tvcg.2014.2346322;10.1109/visual.2004.95;10.1109/tvcg.2011.185;10.1109/visual.2005.1532788;10.1109/visual.1992.235202;10.1109/tvcg.2008.184,"Domain-specific languages, Volume visualization, Volume visualization framework",28.0,23.0,42.0,800.0,,,scientific visualization;specific languages dsls;paper present integrates;usually;added,0.6753;0.3161;0.0955;-0.0231;-0.0353,"[np.int64(-1), -1, -1, -1, -1]",150;-1;-1;-1;-1,150,150
Vis,2022,Tac-Trainer: A Visual Analytics System for IoT-based Racket Sports Training,10.1109/tvcg.2022.3209352,http://dx.doi.org/10.1109/TVCG.2022.3209352,951.0,961.0,J,"Conventional racket sports training highly relies on coaches' knowledge and experience, leading to biases in the guidance. To solve this problem, smart wearable devices based on Internet of Things technology (IoT) have been extensively investigated to support data-driven training. Considerable studies introduced methods to extract valuable information from the sensor data collected by IoT devices. However, the information cannot provide actionable insights for coaches due to the large data volume and high data dimensions. We proposed an IoT + VA framework, Tac-Trainer, to integrate the sensor data, the information, and coaches' knowledge to facilitate racket sports training. Tac-Trainer consists of four components: device configuration, data interpretation, training optimization, and result visualization. These components collect trainees' kinematic data through IoT devices, transform the data into attributes and indicators, generate training suggestions, and provide an interactive visualization interface for exploration, respectively. We further discuss new research opportunities and challenges inspired by our work from two perspectives, VA for IoT and IoT for VA.",Jiachen Wang;Ji Ma;Kangping Hu;Zheng Zhou;Hui Zhang 0051;Xiao Xie;Yingcai Wu,Jiachen Wang;Ji Ma;Kangping Hu;Zheng Zhou;Hui Zhang;Xiao Xie;Yingcai Wu,"State Key Lab of CAD&CG, Zhejiang University, China;State Key Lab of CAD&CG, Zhejiang University, China;State Key Lab of CAD&CG, Zhejiang University, China;Department of Sports Science, Zhejiang University, China;Department of Sports Science, Zhejiang University, China;State Key Lab of CAD&CG, Zhejiang University, China;State Key Lab of CAD&CG, Zhejiang University, China",10.1109/tvcg.2013.178;10.1109/tvcg.2019.2934280;10.1109/tvcg.2021.3114806;10.1109/tvcg.2020.3030342;10.1109/tvcg.2021.3114861;10.1109/tvcg.2015.2468292;10.1109/tvcg.2011.208;10.1109/tvcg.2013.192;10.1109/tvcg.2019.2934243;10.1109/tvcg.2014.2346445;10.1109/tvcg.2017.2745181;10.1109/tvcg.2019.2934630;10.1109/tvcg.2017.2744218;10.1109/tvcg.2018.2865041;10.1109/tvcg.2020.3030359;10.1109/tvcg.2012.263;10.1109/tvcg.2013.178,"IoT,racket sports,training,sensor data,visual analytics",,10.0,91.0,1335.0,,,kinematic data iot;sports training highly;result visualization;va;experience leading biases,0.5765;0.4268;0.1613;0.1382;0.1080,"[np.int64(-1), -1, -1, -1, -1]",6;-1;-1;-1;-1,6,6
Vis,2001,Interactive volume rendering using multi-dimensional transfer functions and direct manipulation widgets,10.1109/visual.2001.964519,http://dx.doi.org/10.1109/VISUAL.2001.964519,255.0,262.0,C,"Most direct volume renderings produced today employ one-dimensional transfer functions, which assign color and opacity to the volume based solely on the single scalar quantity which comprises the dataset. Though they have not received widespread attention, multi-dimensional transfer functions are a very effective way to extract specific material boundaries and convey subtle surface properties. However, identifying good transfer functions is difficult enough in one dimension, let alone two or three dimensions. This paper demonstrates an important class of three-dimensional transfer functions for scalar data (based on data value, gradient magnitude, and a second directional derivative), and describes a set of direct manipulation widgets which make specifying such transfer functions intuitive and convenient. We also describe how to use modem graphics hardware to interactively render with multi-dimensional transfer functions. The transfer functions, widgets, and hardware combine to form a powerful system for interactive volume exploration.",Joe Kniss;Gordon L. Kindlmann;Charles D. Hansen,J. Kniss;G. Kindlmann;C. Hansen,"Scientific Computing and Imaging Institute, School of Computing, University of Utah, USA;Scientific Computing and Imaging Institute, School of Computing, University of Utah, USA;Scientific Computing and Imaging Institute, School of Computing, University of Utah, USA",10.1109/visual.1995.480803;10.1109/visual.1999.809908;10.1109/visual.1999.809889;10.1109/visual.1996.568113;10.1109/visual.1997.663875;10.1109/visual.1995.480803,"volume visualization, direct volume rendering, multi-dimensional transfer functions, direct manipulation widgets, graphics hardware",579.0,137.0,34.0,647.0,BP,,direct volume renderings;second directional derivative;functions widgets;assign color;identifying good transfer,0.7290;0.2627;0.1856;0.1317;0.1071,"[np.int64(-1), -1, -1, -1, -1]",98;-1;-1;-1;-1,98,98
VAST,2006,A Visual Interface for Multivariate Temporal Data: Finding Patterns of Events across Multiple Histories,10.1109/vast.2006.261421,http://dx.doi.org/10.1109/VAST.2006.261421,167.0,174.0,C,"Finding patterns of events over time is important in searching patient histories, Web logs, news stories, and criminal activities. This paper presents PatternFinder, an integrated interface for query and result-set visualization for search and discovery of temporal patterns within multivariate and categorical data sets. We define temporal patterns as sequences of events with inter-event time spans. PatternFinder allows users to specify the attributes of events and time spans to produce powerful pattern queries that are difficult to express with other formalisms. We characterize the range of queries PatternFinder supports as users vary the specificity at which events and time spans are defined. Pattern Finder's query capabilities together with coupled ball-and-chain and tabular visualizations enable users to effectively query, explore and analyze event patterns both within and across data entities (e.g. patient histories, terrorist groups, Web logs, etc.)",Jerry Alan Fails;Amy K. Karlson;Layla Shahamat;Ben Shneiderman,Jerry Alan Fails;Amy Karlson;Layla Shahamat;Ben Shneiderman,"Department of Computer Science & Human-Computer Interaction Lab, University of Maryland, College Park, Maryland, USA;Department of Computer Science & Human-Computer Interaction Lab, University of Maryland, College Park, Maryland, USA;Department of Computer Science & Human-Computer Interaction Lab, University of Maryland, College Park, Maryland, USA;Department of Computer Science & Human-Computer Interaction Lab, University of Maryland, College Park, Maryland",10.1109/infvis.2001.963273;10.1109/infvis.2001.963273,"Temporal query, information visualization, user interface",168.0,83.0,27.0,1188.0,TT,,event patterns data;finder;ball chain tabular;spans produce powerful;enable users,0.6779;0.2643;0.1712;0.1281;-0.0739,"[np.int64(-1), -1, -1, -1, -1]",126;-1;-1;-1;-1,126,126
SciVis,2012,Effects of Stereo and Screen Size on the Legibility of Three-Dimensional Streamtube Visualization,10.1109/tvcg.2012.216,http://dx.doi.org/10.1109/TVCG.2012.216,2130.0,2139.0,J,"We report the impact of display characteristics (stereo and size) on task performance in diffusion magnetic resonance imaging (DMRI) in a user study with 12 participants. The hypotheses were that (1) adding stereo and increasing display size would improve task accuracy and reduce completion time, and (2) the greater the complexity of a spatial task, the greater the benefits of an improved display. Thus we expected to see greater performance gains when detailed visual reasoning was required. Participants used dense streamtube visualizations to perform five representative tasks: (1) determine the higher average fractional anisotropy (FA) values between two regions, (2) find the endpoints of fiber tracts, (3) name a bundle, (4) mark a brain lesion, and (5) judge if tracts belong to the same bundle. Contrary to our hypotheses, we found the task completion time was not improved by the use of the larger display and that performance accuracy was hurt rather than helped by the introduction of stereo in our study with dense DMRI data. Bigger was not always better. Thus cautious should be taken when selecting displays for scientific visualization applications. We explored the results further using the body-scale unit and subjective size and stereo experiences.",Jian Chen 0006;Haipeng Cai;Alexander P. Auchus;David H. Laidlaw,Jian Chen;Haipeng Cai;Alexander P. Auchus;David H. Laidlaw,"University of Maryland, Baltimore, USA;University of Southern Mississippi, USA;University of Mississippi Medical Center, USA;Brown University, USA",10.1109/tvcg.2009.126;10.1109/visual.2000.885694;10.1109/visual.2003.1250414;10.1109/tvcg.2009.111;10.1109/tvcg.2009.138;10.1109/tvcg.2006.183;10.1109/tvcg.2009.126,"Display characteristics, diffusion tensor MRI, virtual environment",46.0,27.0,49.0,718.0,,,scientific visualization;use larger display;dmri user;task completion time;fractional anisotropy fa,0.5399;0.3152;0.1784;0.1593;0.1365,"[np.int64(-1), -1, -1, -1, -1]",150;-1;-1;-1;-1,150,150
InfoVis,2017,Orko: Facilitating Multimodal Interaction for Visual Exploration and Analysis of Networks,10.1109/tvcg.2017.2745219,http://dx.doi.org/10.1109/TVCG.2017.2745219,511.0,521.0,J,"Data visualization systems have predominantly been developed for WIMP-based direct manipulation interfaces. Only recently have other forms of interaction begun to appear, such as natural language or touch-based interaction, though usually operating only independently. Prior evaluations of natural language interfaces for visualization have indicated potential value in combining direct manipulation and natural language as complementary interaction techniques. We hypothesize that truly multimodal interfaces for visualization, those providing users with freedom of expression via both natural language and touch-based direct manipulation input, may provide an effective and engaging user experience. Unfortunately, however, little work has been done in exploring such multimodal visualization interfaces. To address this gap, we have created an architecture and a prototype visualization system called Orko that facilitates both natural language and direct manipulation input. Specifically, Orko focuses on the domain of network visualization, one that has largely relied on WIMP-based interfaces and direct manipulation interaction, and has little or no prior research exploring natural language interaction. We report results from an initial evaluation study of Orko, and use our observations to discuss opportunities and challenges for future work in multimodal network visualization interfaces.",Arjun Srinivasan;John T. Stasko,Arjun Srinivasan;John Stasko,Georgia Institute of Technology;Georgia Institute of Technology,10.1109/infvis.2005.1532136;10.1109/tvcg.2011.185;10.1109/tvcg.2013.124;10.1109/tvcg.2010.164;10.1109/tvcg.2012.204;10.1109/tvcg.2009.108;10.1109/tvcg.2016.2599107,"Multimodal interaction,network visualization,natural language input,direct manipulation,multitouch input",95.0,84.0,70.0,1864.0,,,visualization interfaces;manipulation natural language;orko facilitates;independently prior evaluations;natural,0.6567;0.3561;0.1856;0.0912;0.0815,"[np.int64(-1), -1, -1, -1, -1]",195;-1;-1;-1;-1,195,195
Vis,1992,Visualizing wind velocities by advecting cloud textures,10.1109/visual.1992.235210,http://dx.doi.org/10.1109/VISUAL.1992.235210,179.0,184.0,C,"In order to visualize both clouds and wind in climate simulations, clouds were rendered using a 3D texture which was advected by the wind flow. The simulation is described. Rendering, the advection of texture coordinates, and haze effects are discussed. Results are presented.&lt;&lt;ETX&gt;&gt;",Nelson L. Max;Roger Crawfis;Dean Williams,N. Max;R. Crawfis;D. Williams,"Lawrence Livemore National Laboratory, Livermore, CA, USA;Lawrence Livemore National Laboratory, Livermore, CA, USA;Lawrence Livemore National Laboratory, Livermore, CA, USA",10.1109/visual.1991.175773;10.1109/visual.1991.175773,"advection, 3-D texture, volume visualization, vectorfield, wind, clouds, climate modeling",89.0,28.0,11.0,133.0,,,visualize clouds wind;using 3d texture;rendering;simulation described;lt etx,0.7921;0.3951;0.3567;0.2015;-0.0109,"[np.int64(-1), -1, -1, -1, -1]",240;-1;-1;-1;-1,240,240
VAST,2020,HyperTendril: Visual Analytics for User-Driven Hyperparameter Optimization of Deep Neural Networks,10.1109/tvcg.2020.3030380,http://dx.doi.org/10.1109/TVCG.2020.3030380,1407.0,1416.0,J,"To mitigate the pain of manually tuning hyperparameters of deep neural networks, automated machine learning (AutoML) methods have been developed to search for an optimal set of hyperparameters in large combinatorial search spaces. However, the search results of AutoML methods significantly depend on initial configurations, making it a non-trivial task to find a proper configuration. Therefore, human intervention via a visual analytic approach bears huge potential in this task. In response, we propose HyperTendril, a web-based visual analytics system that supports user-driven hyperparameter tuning processes in a model-agnostic environment. HyperTendril takes a novel approach to effectively steering hyperparameter optimization through an iterative, interactive tuning procedure that allows users to refine the search spaces and the configuration of the AutoML method based on their own insights from given results. Using HyperTendril, users can obtain insights into the complex behaviors of various hyperparameter search algorithms and diagnose their configurations. In addition, HyperTendril supports variable importance analysis to help the users refine their search spaces based on the analysis of relative importance of different hyperparameters and their interaction effects. We present the evaluation demonstrating how HyperTendril helps users steer their tuning processes via a longitudinal user study based on the analysis of interaction logs and in-depth interviews while we deploy our system in a professional industrial environment.",Heungseok Park;Yoonsoo Nam;Jihoon Kim 0001;Jaegul Choo,Heungseok Park;Yoonsoo Nam;Ji-Hoon Kim;Jaegul Choo,"Clova AI Research, NAVER Corporation;Clova AI Research, NAVER Corporation;Clova AI Research, NAVER Corporation;KAIST",10.1109/tvcg.2016.2598829;10.1109/tvcg.2019.2934629;10.1109/tvcg.2018.2864838;10.1109/tvcg.2017.2744358;10.1109/tvcg.2014.2346248;10.1109/tvcg.2016.2598829,"Visual analytics,deep learning,machine learning,automated machine learning,human-centered computing",11.0,16.0,46.0,908.0,,,tuning hyperparameters deep;visual analytics;interviews deploy;takes novel approach;non,0.6389;0.4213;0.1474;0.1272;0.0368,"[np.int64(-1), np.int64(-1), -1, -1, -1]",50;201;-1;-1;-1,50;201,50
InfoVis,2014,NeuroLines: A Subway Map Metaphor for Visualizing Nanoscale Neuronal Connectivity,10.1109/tvcg.2014.2346312,http://dx.doi.org/10.1109/TVCG.2014.2346312,2369.0,2378.0,J,"We present NeuroLines, a novel visualization technique designed for scalable detailed analysis of neuronal connectivity at the nanoscale level. The topology of 3D brain tissue data is abstracted into a multi-scale, relative distance-preserving subway map visualization that allows domain scientists to conduct an interactive analysis of neurons and their connectivity. Nanoscale connectomics aims at reverse-engineering the wiring of the brain. Reconstructing and analyzing the detailed connectivity of neurons and neurites (axons, dendrites) will be crucial for understanding the brain and its development and diseases. However, the enormous scale and complexity of nanoscale neuronal connectivity pose big challenges to existing visualization techniques in terms of scalability. NeuroLines offers a scalable visualization framework that can interactively render thousands of neurites, and that supports the detailed analysis of neuronal structures and their connectivity. We describe and analyze the design of NeuroLines based on two real-world use-cases of our collaborators in developmental neuroscience, and investigate its scalability to large-scale neuronal connectivity data.",Ali K. Al-Awami;Johanna Beyer;Hendrik Strobelt;Narayanan Kasthuri;Jeff W. Lichtman;Hanspeter Pfister;Markus Hadwiger,Ali K. Al-Awami;Johanna Beyer;Hendrik Strobelt;Narayanan Kasthuri;Jeff W. Lichtman;Hanspeter Pfister;Markus Hadwiger,King Abdullah University of Science and Technology (KAUST);School of Engineering and Applied Sciences at Harvard University;School of Engineering and Applied Sciences at Harvard University;Center for Brain Science at Harvard University;Center for Brain Science at Harvard University;School of Engineering and Applied Sciences at Harvard University;King Abdullah University of Science and Technology (KAUST),10.1109/tvcg.2013.142;10.1109/tvcg.2012.240;10.1109/tvcg.2014.2346371;10.1109/tvcg.2009.121;10.1109/vast.2011.6102439;10.1109/tvcg.2009.108;10.1109/tvcg.2011.192;10.1109/visual.2002.1183754;10.1109/tvcg.2013.154;10.1109/tvcg.2013.142,"Connectomics, Neuroscience, Data Abstraction, Multi-Trees, Focus+Context",65.0,53.0,47.0,1357.0,HM,,connectivity nanoscale connectomics;visualization technique;thousands;development diseases;allows domain,0.6727;0.3517;0.0932;0.0762;0.0181,"[np.int64(-1), -1, -1, -1, -1]",21;-1;-1;-1;-1,21,21
Vis,2001,"Case study: reconstruction, visualization and quantification of neuronal fiber pathways",10.1109/visual.2001.964549,http://dx.doi.org/10.1109/VISUAL.2001.964549,453.0,456.0,C,"It is of significant interest for neurological studies to determine and visualize neuronal fiber pathways in the human brain. By exploiting the capability of diffusion tensor magnetic resonance imaging to detect local orientations of neuronal fibers, we have developed a system of algorithms to reconstruct, visualize and quantify neuronal fiber pathways in vivo. Illustrative results show that the system is a promising tool for visual analysis of fiber connectivity and quantitative studies of neuronal fibers.",Zhaohua Ding;John C. Gore;Adam W. Anderson,Zhaohua Ding;J.C. Gore;A.W. Anderson,"Department of Diagnostic Radiology, Yale University School of Medicine, USA;Department of Diagnostic Radiology, Yale University School of Medicine, USA;Department of Diagnostic Radiology, Yale University School of Medicine, USA",,"neuronal fiber pathway, diffusion tensor imaging",33.0,2.0,12.0,107.0,,,visualize neuronal fiber;diffusion tensor magnetic;detect local orientations;developed algorithms;significant,0.7095;0.4194;0.1689;0.1377;-0.0371,"[np.int64(-1), -1, -1, -1, -1]",136;-1;-1;-1;-1,136,136
Vis,1994,Challenges and opportunities in visualization for NASA's EOS Mission to Planet Earth,10.1109/visual.1994.346289,http://dx.doi.org/10.1109/VISUAL.1994.346289,392.0,395.0,M,"Visualization will be vital to the success of the NASA EOS Mission to Planet Earth (MTPE), which will gather, generate, and distribute an unprecedented volume of data for the purpose of global change research and environmental policy decisions. The paper focuses on the challenges and opportunities for visualization with regard to the Mission to Planet Earth. Directions presently being taken within NASA to fund and assist development of new tools are also discussed.&lt;&lt;ETX&gt;&gt;",Mike E. Botts;Jon D. Dykstra;Lee S. Elson;Steven J. Goodman;Meemong Lee,M. Botts;J.D. Dykstra;L.S. Elson;S.J. Goodman;Meemong Lee,"University of Alabama Huntsville, USA;Intergraph Corporation;Jet Propulsion Laboratory;NASA Marshall Space Flight Center;Jet Propulsion Laboratory",,,0.0,1.0,0.0,50.0,,,visualization regard mission;research environmental policy;earth;mtpe gather generate;etx gt gt,0.6161;0.2469;0.2435;0.1626;0.0350,"[np.int64(-1), -1, -1, -1, -1]",270;-1;-1;-1;-1,270,270
Vis,1998,Comparing LIC and spot noise,10.1109/visual.1998.745324,http://dx.doi.org/10.1109/VISUAL.1998.745324,359.0,365.0,C,Spot noise and line integral convolution (LIC) are two texture synthesis techniques for vector field visualization. The two techniques are compared. Continuous directional convolution is used as a common basis for comparing the techniques. It is shown that the techniques are based on the same mathematical concept. Comparisons of the visual appearance of the output and performance of the algorithms are made.,Wim C. de Leeuw;Robert van Liere,W. de Leeuw;R. van Liere,"Center for Mathematics and Computer Science, CWI, Mexico;Department of Software Engineering, CWI, Amsterdam, Netherlands",10.1109/visual.1997.663898;10.1109/visual.1997.663912;10.1109/visual.1995.480817;10.1109/visual.1997.663897;10.1109/visual.1997.663898,"flow visualization, texture synthesis",64.0,10.0,15.0,75.0,,,vector field visualization;convolution lic texture;noise;synthesis techniques;mathematical concept,0.6661;0.4450;0.2383;0.1823;0.1021,"[np.int64(-1), -1, -1, -1, -1]",140;-1;-1;-1;-1,140,140
InfoVis,2013,LineUp: Visual Analysis of Multi-Attribute Rankings,10.1109/tvcg.2013.173,http://dx.doi.org/10.1109/TVCG.2013.173,2277.0,2286.0,J,"Rankings are a popular and universal approach to structuring otherwise unorganized collections of items by computing a rank for each item based on the value of one or more of its attributes. This allows us, for example, to prioritize tasks or to evaluate the performance of products relative to each other. While the visualization of a ranking itself is straightforward, its interpretation is not, because the rank of an item represents only a summary of a potentially complicated relationship between its attributes and those of the other items. It is also common that alternative rankings exist which need to be compared and analyzed to gain insight into how multiple heterogeneous attributes affect the rankings. Advanced visual exploration tools are needed to make this process efficient. In this paper we present a comprehensive analysis of requirements for the visualization of multi-attribute rankings. Based on these considerations, we propose LineUp - a novel and scalable visualization technique that uses bar charts. This interactive technique supports the ranking of items based on multiple heterogeneous attributes with different scales and semantics. It enables users to interactively combine attributes and flexibly refine parameters to explore the effect of changes in the attribute combination. This process can be employed to derive actionable insights as to which attributes of an item need to be modified in order for its rank to change. Additionally, through integration of slope graphs, LineUp can also be used to compare multiple alternative rankings on the same set of items, for example, over time or across different attribute combinations. We evaluate the effectiveness of the proposed multi-attribute visualization technique in a qualitative study. The study shows that users are able to successfully solve complex ranking tasks in a short period of time.",Samuel Gratzl;Alexander Lex;Nils Gehlenborg;Hanspeter Pfister;Marc Streit,Samuel Gratzl;Alexander Lex;Nils Gehlenborg;Hanspeter Pfister;Marc Streit,"Johannes Kepler University of Linz, Austria;Johannes Kepler University of Linz, Austria;Harvard University, USA;Harvard University, USA;Harvard Medical School, USA",10.1109/tvcg.2012.253;10.1109/tvcg.2008.166;10.1109/visual.1996.568118;10.1109/tvcg.2008.181;10.1109/tvcg.2007.70539;10.1109/tvcg.2009.111,"Ranking visualization, ranking, scoring, multi-attribute, multifactorial, multi-faceted, stacked bar charts",329.0,219.0,35.0,2729.0,BP,,rankings advanced visual;structuring unorganized collections;qualitative study study;flexibly refine parameters;tools needed make,0.7460;0.2445;0.1338;0.1154;0.0254,"[np.int64(-1), -1, -1, -1, -1]",179;-1;-1;-1;-1,179,179
InfoVis,2004,Matrix Zoom: A Visual Interface to Semi-External Graphs,10.1109/infvis.2004.46,http://dx.doi.org/10.1109/INFVIS.2004.46,183.0,190.0,C,"In Web data, telecommunications traffic and in epidemiological studies, dense subgraphs correspond to subsets of subjects (i.e. users, patients) that share a collection of attributes values (i.e. accessed Web pages, email-calling patterns or disease diagnostic profiles). Visual and computational identification of these ""clusters"" becomes useful when domain experts desire to determine those factors of major influence in the formation of access and communication clusters or in the detection and contention of disease spread. With the current increases in graphic hardware capabilities and RAM sizes, it is more useful to relate graph sizes to the available screen real estate S and the amount of available RAM M, instead of the number of edges or nodes in the graph. We offer a visual interface that is parameterized by M and S and is particularly suited for navigation tasks that require the identification of subgraphs whose edge density is above certain threshold. This is achieved by providing a zoomable matrix view of the underlying data. This view is strongly coupled to a hierarchical view of the essential information elements present in the data domain. We illustrate the applicability of this work to the visual navigation of cancer incidence data and to an aggregated sample of phone call traffic",James Abello;Frank van Ham,J. Abello;F. van Ham,"DIMACS, Rutgers University, Piscataway, NJ, USA;Department of Mathematics and Computer Science, Technische Universiteit Eindhoven, The Netherlands",10.1109/infvis.2003.1249030;10.1109/infvis.2003.1249030,"Graph Visualization, Hierarchy Trees, Clustering, External Memory Algorithms, Cancer Data, Phone Traffic",163.0,34.0,14.0,695.0,,,studies dense subgraphs;providing zoomable matrix;web data;visual navigation cancer;email calling,0.5263;0.3792;0.3498;0.3225;0.1046,"[np.int64(-1), -1, -1, -1, -1]",280;-1;-1;-1;-1,280,280
InfoVis,2005,Visual correlation for situational awareness,10.1109/infvis.2005.1532134,http://dx.doi.org/10.1109/INFVIS.2005.1532134,95.0,102.0,C,"We present a novel visual correlation paradigm for situational awareness (SA) and suggest its usage in a diverse set of applications that require a high level of SA. Our approach is based on a concise and scalable representation, which leads to a flexible visualization tool that is both clear and intuitive to use. Situational awareness is the continuous extraction of environmental information, its integration with previous knowledge to form a coherent mental picture, and the use of that picture in anticipating future events. In this paper we build on our previous work on visualization for network intrusion detection and show how that approach can be generalized to encompass a much broader class of SA systems. We first propose a generalization that is based on what we term, the w/sup 3/ premise, namely that each event must have at least the what, when and where attributes. We also present a second generalization, which increases flexibility and facilitates complex visual correlations. Finally, we demonstrate the generality of our approaches by applying our visualization paradigm in a collection of diverse SA areas.",Yarden Livnat;James Agutter;Shaun Moon;Stefano Foresti,Y. Livnat;J. Agutter;Shaun Moon;S. Foresti,"Scientific Computing and Imaging Institute, University of Utah, USA;College of Architecture Planning, University of Utah, USA;College of Architecture Planning, University of Utah, USA;Center for High Performance Computing, University of Utah, USA",10.1109/visual.2003.1250415,"situation awareness, network intrusion, visualization",125.0,24.0,19.0,1025.0,,,visualization network intrusion;situational awareness continuous;environmental information integration;correlations finally demonstrate;build,0.5939;0.5237;0.3687;0.2436;0.0479,"[np.int64(-1), np.int64(-1), -1, -1, -1]",166;51;-1;-1;-1,51;166,166
SciVis,2013,ConnectomeExplorer: Query-Guided Visual Analysis of Large Volumetric Neuroscience Data,10.1109/tvcg.2013.142,http://dx.doi.org/10.1109/TVCG.2013.142,2868.0,2877.0,J,"This paper presents ConnectomeExplorer, an application for the interactive exploration and query-guided visual analysis of large volumetric electron microscopy (EM) data sets in connectomics research. Our system incorporates a knowledge-based query algebra that supports the interactive specification of dynamically evaluated queries, which enable neuroscientists to pose and answer domain-specific questions in an intuitive manner. Queries are built step by step in a visual query builder, building more complex queries from combinations of simpler queries. Our application is based on a scalable volume visualization framework that scales to multiple volumes of several teravoxels each, enabling the concurrent visualization and querying of the original EM volume, additional segmentation volumes, neuronal connectivity, and additional meta data comprising a variety of neuronal data attributes. We evaluate our application on a data set of roughly one terabyte of EM data and 750 GB of segmentation data, containing over 4,000 segmented structures and 1,000 synapses. We demonstrate typical use-case scenarios of our collaborators in neuroscience, where our system has enabled them to answer specific scientific questions using interactive querying and analysis on the full-size data for the first time.",Johanna Beyer;Ali K. Al-Awami;Narayanan Kasthuri;Jeff W. Lichtman;Hanspeter Pfister;Markus Hadwiger,Johanna Beyer;Ali Al-Awami;Narayanan Kasthuri;Jeff W. Lichtman;Hanspeter Pfister;Markus Hadwiger,"King Abdullah University of Science and Technology, Saudi Arabia;King Abdullah University of Science and Technology, Saudi Arabia;Center for Brain Science, Harvard University, USA;Center for Brain Science, Harvard University, USA;School of Engineering and Applied Sciences, Harvard University, USA;King Abdullah University of Science and Technology, Saudi Arabia",10.1109/infvis.2000.885086;10.1109/visual.2005.1532792;10.1109/tvcg.2009.178;10.1109/tvcg.2012.240;10.1109/tvcg.2006.195;10.1109/visual.1995.485139;10.1109/tvcg.2007.70560;10.1109/tvcg.2009.118;10.1109/tvcg.2009.121,"Connectomics, neuroscience, query algebra, visual knowledge discovery, petascale volume analysis",78.0,57.0,45.0,986.0,,,queries enable neuroscientists;step visual;large volumetric electron;framework scales multiple;teravoxels enabling concurrent,0.6055;0.2403;0.2167;0.1647;0.1275,"[np.int64(-1), -1, -1, -1, -1]",82;-1;-1;-1;-1,82,82
Vis,2009,A Visual Approach to Efficient Analysis and Quantification of Ductile Iron and Reinforced Sprayed Concrete,10.1109/tvcg.2009.115,http://dx.doi.org/10.1109/TVCG.2009.115,1343.0,1350.0,J,"This paper describes advanced volume visualization and quantification for applications in non-destructive testing (NDT), which results in novel and highly effective interactive workflows for NDT practitioners. We employ a visual approach to explore and quantify the features of interest, based on transfer functions in the parameter spaces of specific application scenarios. Examples are the orientations of fibres or the roundness of particles. The applicability and effectiveness of our approach is illustrated using two specific scenarios of high practical relevance. First, we discuss the analysis of Steel Fibre Reinforced Sprayed Concrete (SFRSpC). We investigate the orientations of the enclosed steel fibres and their distribution, depending on the concrete's application direction. This is a crucial step in assessing the material's behavior under mechanical stress, which is still in its infancy and therefore a hot topic in the building industry. The second application scenario is the designation of the microstructure of ductile cast irons with respect to the contained graphite. This corresponds to the requirements of the ISO standard 945-1, which deals with 2D metallographic samples. We illustrate how the necessary analysis steps can be carried out much more efficiently using our system for 3D volumes. Overall, we show that a visual approach with custom transfer functions in specific application domains offers significant benefits and has the potential of greatly improving and optimizing the workflows of domain scientists and engineers.",Laura Fritz;Markus Hadwiger;Georg Geier;Gerhard Pittino;M. Eduard Gröller,Laura Fritz;Markus Hadwiger;Georg Geier;Gerhard Pittino;M. Eduard Groller,"VRVis Research Center, Vienna, Austria;VRVis Research Center, Vienna, Austria;Austrian Foundry Research Institute, Leoben, Austria;Institute for Subsurface Engineering, University of Leoben, Austria;University of Technology, Vienna, Vienna, Austria",10.1109/tvcg.2008.147;10.1109/visual.2003.1250418;10.1109/tvcg.2008.162;10.1109/visual.2001.964519;10.1109/visual.2003.1250384;10.1109/tvcg.2007.70603;10.1109/tvcg.2008.147,"Non-Destructive Testing, Multi-Dimensional Transfer Functions, Direction Visualization, Volume Rendering",28.0,14.0,22.0,485.0,,,volume visualization quantification;destructive testing ndt;concrete application direction;steel fibres;transfer functions parameter,0.5896;0.3796;0.3755;0.3221;0.0775,"[np.int64(-1), -1, -1, -1, -1]",84;-1;-1;-1;-1,84,84
InfoVis,2012,Facilitating Discourse Analysis with Interactive Visualization,10.1109/tvcg.2012.226,http://dx.doi.org/10.1109/TVCG.2012.226,2639.0,2648.0,J,"A discourse parser is a natural language processing system which can represent the organization of a document based on a rhetorical structure tree-one of the key data structures enabling applications such as text summarization, question answering and dialogue generation. Computational linguistics researchers currently rely on manually exploring and comparing the discourse structures to get intuitions for improving parsing algorithms. In this paper, we present DAViewer, an interactive visualization system for assisting computational linguistics researchers to explore, compare, evaluate and annotate the results of discourse parsers. An iterative user-centered design process with domain experts was conducted in the development of DAViewer. We report the results of an informal formative study of the system to better understand how the proposed visualization and interaction techniques are used in the real research environment.",Jian Zhao 0010;Fanny Chevalier;Christopher Collins 0001;Ravin Balakrishnan,Jian Zhao;Fanny Chevalier;Christopher Collins;Ravin Balakrishnan,"University of Toronto, Canada;University of Toronto, Canada;University of Ontario Institute of Technology (UOIT), Canada;University of Toronto, Canada",10.1109/vast.2011.6102439;10.1109/tvcg.2007.70529;10.1109/tvcg.2009.122;10.1109/infvis.1999.801869;10.1109/infvis.2003.1249030;10.1109/vast.2011.6102439,"Discourse structure, tree comparison, computational linguisitics, visual analytics, interaction techniques",77.0,32.0,30.0,1447.0,,,discourse parser;daviewer interactive visualization;research environment;enabling applications text;proposed,0.7195;0.2872;0.1790;0.0870;0.0709,"[np.int64(-1), -1, -1, -1, -1]",115;-1;-1;-1;-1,115,115
VAST,2007,Activity Analysis Using Spatio-Temporal Trajectory Volumes in Surveillance Applications,10.1109/vast.2007.4388990,http://dx.doi.org/10.1109/VAST.2007.4388990,3.0,10.0,C,"In this paper, we present a system to analyze activities and detect anomalies in a surveillance application, which exploits the intuition and experience of security and surveillance experts through an easy- to-use visual feedback loop. The multi-scale and location specific nature of behavior patterns in space and time is captured using a wavelet-based feature descriptor. The system learns the fundamental descriptions of the behavior patterns in a semi-supervised fashion by the higher order singular value decomposition of the space described by the training data. This training process is guided and refined by the users in an intuitive fashion. Anomalies are detected by projecting the test data into this multi-linear space and are visualized by the system to direct the attention of the user to potential problem spots. We tested our system on real-world surveillance data, and it satisfied the security concerns of the environment.",Firdaus Janoos;Shantanu Singh;M. Okan Irfanoglu;Raghu Machiraju;Richard E. Parent,Firdaus Janoos;Shantanu Singh;Okan Irfanoglu;Raghu Machiraju;Richard Parent,"Department of Computer Science and Engineering, Ohio State Uinversity, USA;Department of Computer Science and Engineering, Ohio State Uinversity, USA;Department of Computer Science and Engineering, Ohio State Uinversity, USA;Department of Computer Science and Engineering, Ohio State Uinversity, USA;Department of Computer Science and Engineering, Ohio State Uinversity, USA",10.1109/tvcg.2006.194;10.1109/tvcg.2006.194,"wavelets, HOSVD, surveillance, anomaly detection, trajectory",28.0,9.0,29.0,345.0,,,detect anomalies surveillance;feature descriptor learns;using wavelet;multi linear space;easy use,0.5928;0.3474;0.3467;0.2139;0.1154,"[np.int64(-1), -1, -1, -1, -1]",122;-1;-1;-1;-1,122,122
VAST,2008,Visual mining of multimedia data for social and behavioral studies,10.1109/vast.2008.4677369,http://dx.doi.org/10.1109/VAST.2008.4677369,155.0,162.0,C,"With advances in computing techniques, a large amount of high-resolution high-quality multimedia data (video and audio, etc.) has been collected in research laboratories in various scientific disciplines, particularly in social and behavioral studies. How to automatically and effectively discover new knowledge from rich multimedia data poses a compelling challenge since state-of-the-art data mining techniques can most often only search and extract pre-defined patterns or knowledge from complex heterogeneous data. In light of this, our approach is to take advantages of both the power of human perception system and the power of computational algorithms. More specifically, we propose an approach that allows scientists to use data mining as a first pass, and then forms a closed loop of visual analysis of current results followed by more data mining work inspired by visualization, the results of which can be in turn visualized and lead to the next round of visual exploration and analysis. In this way, new insights and hypotheses gleaned from the raw data and the current level of analysis can contribute to further analysis. As a first step toward this goal, we implement a visualization system with three critical components: (1) A smooth interface between visualization and data mining. The new analysis results can be automatically loaded into our visualization tool. (2) A flexible tool to explore and query temporal data derived from raw multimedia data. We represent temporal data into two forms - continuous variables and event variables. We have developed various ways to visualize both temporal correlations and statistics of multiple variables with the same type, and conditional and high-order statistics between continuous and event variables. (3) A seamless interface between raw multimedia data and derived data. Our visualization tool allows users to explore, compare, and analyze multi-stream derived variables and simultaneously switch to access raw multimedia data. We demonstrate various functions in our visualization program using a set of multimedia data including video, audio and motion tracking data.",Chen Yu 0001;Yiwen Zhong;Thomas Smith 0003;Ikhyun Park;Weixia Huang,Chen Yu;Yiwen Zhong;Thomas Smith;Ikhyun Park;Weixia Huang,"Indiana University, USA;Indiana University, Fujian Agriculture and Forestry University, USA;Indiana University, USA;Indiana University, USA;Indiana University, USA",10.1109/infvis.2001.963273;10.1109/infvis.1999.801851;10.1109/infvis.2001.963273,"visual data mining, multimedia data",10.0,0.0,12.0,1219.0,,,visualization data mining;access raw multimedia;advantages power human;simultaneously;results automatically loaded,0.6850;0.2036;0.0877;0.0448;0.0357,"[np.int64(-1), -1, -1, -1, -1]",205;-1;-1;-1;-1,205,205
InfoVis,2010,Perceptual Guidelines for Creating Rectangular Treemaps,10.1109/tvcg.2010.186,http://dx.doi.org/10.1109/TVCG.2010.186,990.0,998.0,J,"Treemaps are space-filling visualizations that make efficient use of limited display space to depict large amounts of hierarchical data. Creating perceptually effective treemaps requires carefully managing a number of design parameters including the aspect ratio and luminance of rectangles. Moreover, treemaps encode values using area, which has been found to be less accurate than judgments of other visual encodings, such as length. We conduct a series of controlled experiments aimed at producing a set of design guidelines for creating effective rectangular treemaps. We find no evidence that luminance affects area judgments, but observe that aspect ratio does have an effect. Specifically, we find that the accuracy of area comparisons suffers when the compared rectangles have extreme aspect ratios or when both are squares. Contrary to common assumptions, the optimal distribution of rectangle aspect ratios within a treemap should include non-squares, but should avoid extremes. We then compare treemaps with hierarchical bar chart displays to identify the data densities at which length-encoded bar charts become less effective than area-encoded treemaps. We report the transition points at which treemaps exhibit judgment accuracy on par with bar charts for both leaf and non-leaf tree nodes. We also find that even at relatively low data densities treemaps result in faster comparisons than bar charts. Based on these results, we present a set of guidelines for the effective use of treemaps and suggest alternate approaches for treemap layout.",Nicholas Kong;Jeffrey Heer;Maneesh Agrawala,Nicholas Kong;Jeffrey Heer;Maneesh Agrawala,"Computer Science Division, University of California Berkeley, Berkeley, CA, USA;Computer Science Department, University of Stanford, Stanford, CA, USA;Computer Science Division, University of California Berkeley, Berkeley, CA, USA",10.1109/infvis.2000.885091;10.1109/infvis.2005.1532145;10.1109/infvis.2004.70;10.1109/infvis.2005.1532144;10.1109/tvcg.2007.70583;10.1109/infvis.2001.963283;10.1109/infvis.2001.963290;10.1109/tvcg.2008.171;10.1109/infvis.1999.801860;10.1109/infvis.2002.1173153;10.1109/infvis.2000.885091,"Graphical Perception, Visualization, Treemaps, Rectangular Area, Visual Encoding, Experiment, Mechanical Turk",132.0,72.0,45.0,1209.0,HM,,perceptually effective treemaps;data densities length;ratios squares contrary;encoded bar;carefully managing number,0.6396;0.2563;0.1546;0.1502;0.1282,"[np.int64(-1), -1, -1, -1, -1]",54;-1;-1;-1;-1,54,54
InfoVis,2009,Participatory Visualization with Wordle,10.1109/tvcg.2009.171,http://dx.doi.org/10.1109/TVCG.2009.171,1137.0,1144.0,J,"We discuss the design and usage of ldquoWordle,rdquo a Web-based tool for visualizing text. Wordle creates tag-cloud-like displays that give careful attention to typography, color, and composition. We describe the algorithms used to balance various aesthetic criteria and create the distinctive Wordle layouts. We then present the results of a study of Wordle usage, based both on spontaneous behaviour observed in the wild, and on a large-scale survey of Wordle users. The results suggest that Wordles have become a kind of medium of expression, and that a ldquoparticipatory culturerdquo has arisen around them.",Fernanda B. Viégas;Martin Wattenberg;Jonathan Feinberg,Fernanda B. Viegas;Martin Wattenberg;Jonathan Feinberg,"IBM Research, USA;IBM Research, USA;IBM Research, USA",10.1109/infvis.2005.1532122;10.1109/tvcg.2007.70577,"Visualization, text, tag cloud, participatory culture, memory, educational visualization, social data analysis",534.0,263.0,15.0,3675.0,,,visualizing text wordle;tag cloud;various aesthetic criteria;culturerdquo;algorithms used balance,0.6544;0.5103;0.3099;0.2951;0.0877,"[np.int64(-1), np.int64(-1), -1, -1, -1]",170;244;-1;-1;-1,170;244,170
Vis,2006,Scalable Data Servers for Large Multivariate Volume Visualization,10.1109/tvcg.2006.175,http://dx.doi.org/10.1109/TVCG.2006.175,1291.0,1298.0,J,"Volumetric datasets with multiple variables on each voxel over multiple time steps are often complex, especially when considering the exponentially large attribute space formed by the variables in combination with the spatial and temporal dimensions. It is intuitive, practical, and thus often desirable, to interactively select a subset of the data from within that high-dimensional value space for efficient visualization. This approach is straightforward to implement if the dataset is small enough to be stored entirely in-core. However, to handle datasets sized at hundreds of gigabytes and beyond, this simplistic approach becomes infeasible and thus, more sophisticated solutions are needed. In this work, we developed a system that supports efficient visualization of an arbitrary subset, selected by range-queries, of a large multivariate time-varying dataset. By employing specialized data structures and schemes of data distribution, our system can leverage a large number of networked computers as parallel data servers, and guarantees a near optimal load-balance. We demonstrate our system of scalable data servers using two large time-varying simulation datasets",Markus Glatter;Jian Huang 0007;Jinzhu Gao;Colin Mollenhour,Markus Glatter;Jian Huang;Jinzhu Gao;Colin Mollenhour,"University of Tennessee, USA;University of Tennessee, USA;University of Tennessee, USA;Oak Ridge National Laboratory, USA",10.1109/visual.2005.1532792;10.1109/visual.2005.1532794;10.1109/visual.1999.809910;10.1109/visual.1996.568121;10.1109/visual.2003.1250412;10.1109/visual.2001.964519;10.1109/visual.1998.745311;10.1109/visual.2000.885698,"Parallel and distributed volume visualization, large Data Set Visualization, multi-variate Visualization, volume Visualization",35.0,17.0,25.0,252.0,,,volumetric datasets;networked computers parallel;arbitrary subset selected;especially considering;time steps complex,0.6084;0.2580;0.1691;0.1431;0.0936,"[np.int64(-1), -1, -1, -1, -1]",255;-1;-1;-1;-1,255,255
Vis,1998,Fast and memory efficient polygonal simplification,10.1109/visual.1998.745314,http://dx.doi.org/10.1109/VISUAL.1998.745314,279.0,286.0,C,"Conventional wisdom says that in order to produce high-quality simplified polygonal models, one must retain and use information about the original model during the simplification process. We demonstrate that excellent simplified models can be produced without the need to compare against information from the original geometry while performing local changes to the model. We use edge collapses to perform simplification, as do a number of other methods. We select the position of the new vertex so that the original volume of the model is maintained and we minimize the per-triangle change in volume of the tetrahedra swept out by those triangles that are moved. We also maintain surface area near boundaries and minimize the per-triangle area changes. Calculating the edge collapse priorities and the positions of the new vertices requires only the face connectivity and the the vertex locations in the intermediate model. This approach is memory efficient, allowing the simplification of very large polygonal models, and it is also fast. Moreover, simplified models created using this technique compare favorably to a number of other published simplification methods in terms of mean geometric error.",Peter Lindstrom 0001;Greg Turk,P. Lindstrom;G. Turk,"Georgia Institute of Technology, USA;Georgia Institute of Technology, USA",10.1109/visual.1995.485142;10.1109/visual.1997.663883;10.1109/visual.1997.663908;10.1109/visual.1997.663906;10.1109/visual.1995.485142,,533.0,106.0,22.0,425.0,,,simplified polygonal models;edge collapse priorities;simplification large;performing local changes;conventional wisdom says,0.7173;0.4181;0.3222;0.1602;-0.0311,"[np.int64(-1), -1, -1, -1, -1]",89;-1;-1;-1;-1,89,89
SciVis,2014,Combined Visualization of Wall Thickness and Wall Shear Stress for the Evaluation of Aneurysms,10.1109/tvcg.2014.2346406,http://dx.doi.org/10.1109/TVCG.2014.2346406,2506.0,2515.0,J,"For an individual rupture risk assessment of aneurysms, the aneurysm's wall morphology and hemodynamics provide valuable information. Hemodynamic information is usually extracted via computational fluid dynamic (CFD) simulation on a previously extracted 3D aneurysm surface mesh or directly measured with 4D phase-contrast magnetic resonance imaging. In contrast, a noninvasive imaging technique that depicts the aneurysm wall in vivo is still not available. Our approach comprises an experiment, where intravascular ultrasound (IVUS) is employed to probe a dissected saccular aneurysm phantom, which we modeled from a porcine kidney artery. Then, we extracted a 3D surface mesh to gain the vessel wall thickness and hemodynamic information from a CFD simulation. Building on this, we developed a framework that depicts the inner and outer aneurysm wall with dedicated information about local thickness via distance ribbons. For both walls, a shading is adapted such that the inner wall as well as its distance to the outer wall is always perceivable. The exploration of the wall is further improved by combining it with hemodynamic information from the CFD simulation. Hence, the visual analysis comprises a brushing and linking concept for individual highlighting of pathologic areas. Also, a surface clustering is integrated to provide an automatic division of different aneurysm parts combined with a risk score depending on wall thickness and hemodynamic information. In general, our approach can be employed for vessel visualization purposes where an inner and outer wall has to be adequately represented.",Sylvia Glaßer;Kai Lawonn;Thomas Hoffmann 0002;Martin Skalej;Bernhard Preim,Sylvia Glaßer;Kai Lawonn;Thomas Hoffmann;Martin Skalej;Bernhard Preim,"Department for Simulation and Graphics, Otto von Guericke Universitat Magdeburg, Magdeburg, Sachsen-Anhalt, DE;Department for Simulation and Graphics, University of Magdeburg, Germany;Neuroradiology Department, University hospital of Magdeburg, Germany;Neuroradiology Department, University hospital of Magdeburg, Germany;Department for Simulation and Graphics, University of Magdeburg, Germany",10.1109/tvcg.2012.202;10.1109/tvcg.2007.70550;10.1109/visual.1995.480795;10.1109/tvcg.2011.189;10.1109/tvcg.2012.202,"Aneurysm, IVUS, Wall Thickness, Wall Shear Stress, Brushing and Linking, Focus + Context",27.0,24.0,43.0,718.0,,,3d aneurysm surface;fluid dynamic cfd;porcine kidney;contrast;clustering integrated provide,0.6912;0.2681;0.1721;0.1436;0.0818,"[np.int64(-1), -1, -1, -1, -1]",133;-1;-1;-1;-1,133,133
Vis,2003,Planet-sized batched dynamic adaptive meshes (P-BDAM),10.1109/visual.2003.1250366,http://dx.doi.org/10.1109/VISUAL.2003.1250366,147.0,154.0,C,"We describe an efficient technique for out-of-core management and interactive rendering of planet sized textured terrain surfaces. The technique, called planet-sized batched dynamic adaptive meshes (P-BDAM), extends the BDAM approach by using as basic primitive a general triangulation of points on a displaced triangle. The proposed framework introduces several advances with respect to the state of the art: thanks to a batched host-to-graphics communication model, we outperform current adaptive tessellation solutions in terms of rendering speed; we guarantee overall geometric continuity, exploiting programmable graphics hardware to cope with the accuracy issues introduced by single precision floating points; we exploit a compressed out of core representation and speculative prefetching for hiding disk latency during rendering of out-of-core data; we efficiently construct high quality simplified representations with a novel distributed out of core simplification algorithm working on a standard PC network.",Paolo Cignoni;Fabio Ganovelli;Enrico Gobbetti;Fabio Marton;Federico Ponchio;Roberto Scopigno,P. Cignoni;F. Ganovelli;E. Gobbetti;F. Marton;F. Ponchio;R. Scopigno,"ISTI-CNR, Pisa, Italy;ISTI-CNR, Italy;CRS4, Pula, Italy;CRS4, Italy;ISTI-CNR, Italy;ISTI-CNR, Italy",10.1109/visual.1997.663860;10.1109/visual.2002.1183783;10.1109/visual.1997.663902;10.1109/visual.1998.745282;10.1109/visual.2000.885699;10.1109/visual.2002.1183800;10.1109/visual.1996.567600;10.1109/visual.1998.745280;10.1109/visual.1999.809902;10.1109/visual.1996.568126;10.1109/visual.1997.663860," Multiresolution, terrains, huge dataset",222.0,46.0,33.0,181.0,,,adaptive tessellation;rendering core;hiding disk latency;single precision floating;host,0.5534;0.3863;0.1724;0.1695;0.1626,"[np.int64(-1), -1, -1, -1, -1]",111;-1;-1;-1;-1,111,111
Vis,2024,StyleRF-VolVis: Style Transfer of Neural Radiance Fields for Expressive Volume Visualization,10.1109/tvcg.2024.3456342,http://dx.doi.org/10.1109/TVCG.2024.3456342,613.0,623.0,J,"In volume visualization, visualization synthesis has attracted much attention due to its ability to generate novel visualizations without following the conventional rendering pipeline. However, existing solutions based on generative adversarial networks often require many training images and take significant training time. Still, issues such as low quality, consistency, and flexibility persist. This paper introduces StyleRF-VolVis, an innovative style transfer framework for expressive volume visualization (VolVis) via neural radiance field (NeRF). The expressiveness of StyleRF-VolVis is upheld by its ability to accurately separate the underlying scene geometry (i.e., content) and color appearance (i.e., style), conveniently modify color, opacity, and lighting of the original rendering while maintaining visual content consistency across the views, and effectively transfer arbitrary styles from reference images to the reconstructed 3D scene. To achieve these, we design a base NeRF model for scene geometry extraction, a palette color network to classify regions of the radiance field for photorealistic editing, and an unrestricted color network to lift the color palette constraint via knowledge distillation for non-photorealistic editing. We demonstrate the superior quality, consistency, and flexibility of StyleRF-VolVis by experimenting with various volume rendering scenes and reference images and comparing StyleRF-VolVis against other image-based (AdaIN), video-based (ReReVST), and NeRF-based (ARF and SNeRF) style rendering solutions.",Kaiyuan Tang;Chaoli Wang 0001,Kaiyuan Tang;Chaoli Wang,"Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, USA;Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, USA",10.1109/tvcg.2019.2934255;10.1109/tvcg.2021.3114815;10.1109/tvcg.2020.3030346;10.1109/tvcg.2019.2934312;10.1109/tvcg.2022.3209413;10.1109/tvcg.2023.3327194,"Style transfer,neural radiance field,,,knowledge distillation,volume visualization",,0.0,62.0,225.0,,,volume rendering scenes;palette color network;comparing stylerf;ability generate novel;time issues low,0.6243;0.4366;0.2263;0.1756;-0.0887,"[np.int64(-1), -1, -1, -1, -1]",95;-1;-1;-1;-1,95,95
Vis,2008,Hypothesis Generation in Climate Research with Interactive Visual Data Exploration,10.1109/tvcg.2008.139,http://dx.doi.org/10.1109/TVCG.2008.139,1579.0,1586.0,J,"One of the most prominent topics in climate research is the investigation, detection, and allocation of climate change. In this paper, we aim at identifying regions in the atmosphere (e.g., certain height layers) which can act as sensitive and robust indicators for climate change. We demonstrate how interactive visual data exploration of large amounts of multi-variate and time-dependent climate data enables the steered generation of promising hypotheses for subsequent statistical evaluation. The use of new visualization and interaction technology-in the context of a coordinated multiple views framework-allows not only to identify these promising hypotheses, but also to efficiently narrow down parameters that are required in the process of computational data analysis. Two datasets, namely an ECHAM5 climate model run and the ERA-40 reanalysis incorporating observational data, are investigated. Higher-order information such as linear trends or signal-to-noise ratio is derived and interactively explored in order to detect and explore those regions which react most sensitively to climate change. As one conclusion from this study, we identify an excellent potential for usefully generalizing our approach to other, similar application cases, as well.",Johannes Kehrer;Florian Ladstädter;Philipp Muigg;Helmut Doleisch;Andrea K. Steiner;Helwig Hauser,Johannes Kehrer;Florian Ladstädter;Philipp Muigg;Helmut Doleisch;Andrea Steiner;Helwig Hauser,"Department of Informatics, University of Bergen, Norway;Wegener Center for Climate and Global Change (WegCenter) and the Institute for Geophysics, Astrophysics,  and Meteorology (IGAM), University of Graz, Austria;VRVis Research Center, SimVis GmbH, Vienna, Austria;VRVis Research Center, SimVis GmbH, Vienna, Austria;Wegener Center for Climate and Global Change (WegCenter) and the Institute for Geophysics, Astrophysics,  and Meteorology (IGAM), University of Graz, Austria;Department of Informatics, University of Bergen, Norway",10.1109/infvis.2005.1532138;10.1109/visual.1994.346302;10.1109/visual.2005.1532850;10.1109/tvcg.2006.170;10.1109/infvis.2005.1532138,"Interactive visual hypothesis generation, interactive visual exploration and analysis, visualization for climate research",85.0,44.0,29.0,762.0,,,climate data enables;identify promising hypotheses;coordinated multiple views;sensitively;variate time,0.5995;0.3176;0.2248;0.0667;0.0582,"[np.int64(-1), -1, -1, -1, -1]",49;-1;-1;-1;-1,49,49
VAST,2018,RetainVis: Visual Analytics with Interpretable and Interactive Recurrent Neural Networks on Electronic Medical Records,10.1109/tvcg.2018.2865027,http://dx.doi.org/10.1109/TVCG.2018.2865027,299.0,309.0,J,"We have recently seen many successful applications of recurrent neural networks (RNNs) on electronic medical records (EMRs), which contain histories of patients' diagnoses, medications, and other various events, in order to predict the current and future states of patients. Despite the strong performance of RNNs, it is often challenging for users to understand why the model makes a particular prediction. Such black-box nature of RNNs can impede its wide adoption in clinical practice. Furthermore, we have no established methods to interactively leverage users' domain expertise and prior knowledge as inputs for steering the model. Therefore, our design study aims to provide a visual analytics solution to increase interpretability and interactivity of RNNs via a joint effort of medical experts, artificial intelligence scientists, and visual analytics researchers. Following the iterative design process between the experts, we design, implement, and evaluate a visual analytics tool called RetainVis, which couples a newly improved, interpretable, and interactive RNN-based model called RetainEX and visualizations for users' exploration of EMR data in the context of prediction tasks. Our study shows the effective use of RetainVis for gaining insights into how individual medical codes contribute to making risk predictions, using EMRs of patients with heart failure and cataract symptoms. Our study also demonstrates how we made substantial changes to the state-of-the-art RNN model called RETAIN in order to make use of temporal information and increase interactivity. This study will provide a useful guideline for researchers that aim to design an interpretable and interactive visual analytics tool for RNNs.",Bum Chul Kwon;Min-Je Choi;Joanne Taery Kim;Edward Choi;Young Bin Kim;Soonwook Kwon;Jimeng Sun 0001;Jaegul Choo,Bum Chul Kwon;Min-Je Choi;Joanne Taery Kim;Edward Choi;Young Bin Kim;Soonwook Kwon;Jimeng Sun;Jaegul Choo,"IBM T.J. Watson Research Center, Korea University;Korea University, Seongbuk-gu, Seoul, KR;Korea University, Seongbuk-gu, Seoul, KR;Georgia Institute of Technology, Atlanta, GA, US;Chung-Ang University, Seoul, Seoul, KR;Catholic University of Daegu, Gyeongsan, Gyeongsangbuk-do, KR;Georgia Institute of Technology, Atlanta, GA, US;Korea University, Seongbuk-gu, Seoul, KR",10.1109/tvcg.2013.212;10.1109/tvcg.2017.2745080;10.1109/tvcg.2012.277;10.1109/tvcg.2017.2744718;10.1109/tvcg.2017.2745085;10.1109/tvcg.2016.2598446;10.1109/tvcg.2015.2467555;10.1109/tvcg.2016.2598831;10.1109/vast.2017.8585721;10.1109/tvcg.2017.2744358;10.1109/tvcg.2016.2598838;10.1109/tvcg.2012.213;10.1109/tvcg.2017.2744158;10.1109/tvcg.2017.2744878;10.1109/tvcg.2015.2467591;10.1109/tvcg.2013.212,"Interactive Artificial Intelligence,XAI (Explainable Artificial Intelligence),Interpretable Deep Learning,Healthcare",224.0,187.0,85.0,4417.0,,,rnns electronic medical;interactive visual analytics;risk predictions using;understand;failure cataract symptoms,0.5265;0.4768;0.3812;0.2063;0.1518,"[np.int64(-1), np.int64(-1), -1, -1, -1]",7;201;-1;-1;-1,7;201,7
Vis,2003,A frequency-sensitive point hierarchy for images and volumes,10.1109/visual.2003.1250403,http://dx.doi.org/10.1109/VISUAL.2003.1250403,425.0,432.0,C,"This paper introduces a method for converting an image or volume sampled on a regular grid into a space-efficient irregular point hierarchy. The conversion process retains the original frequency characteristics of the dataset by matching the spatial distribution of sample points with the required frequency. To achieve good blending, the spherical points commonly used in volume rendering are generalized to ellipsoidal point primitives. A family of multiresolution, oriented Gabor wavelets provide the frequency-space analysis of the dataset. The outcome of this frequency analysis is the reduced set of points, in which the sampling rate is decreased in originally oversampled areas. During rendering, the traversal of the hierarchy can be controlled by any suitable error metric or quality criteria. The local level of refinement is also sensitive to the transfer function. Areas with density ranges mapped to high transfer function variability are rendered at higher point resolution than others. Our decomposition is flexible and can be used for iso-surface rendering, alpha compositing and X-ray rendering of volumes. We demonstrate our hierarchy with an interactive splatting volume renderer, in which the traversal of the point hierarchy for rendering is modulated by a user-specified frame rate.",Tomihisa Welsh;Klaus Mueller 0001,T. Welsh;K. Mueller,"Center for Visual Computing, Computer Science, Stony Brook University, USA;Center for Visual Computing, Computer Science, Stony Brook University, USA",10.1109/visual.2002.1183770;10.1109/visual.2001.964498;10.1109/visual.2002.1183776;10.1109/visual.2001.964492;10.1109/visual.2001.964491;10.1109/visual.2002.1183757;10.1109/visual.2001.964490;10.1109/visual.2002.1183770,"volume rendering, point-based rendering, splatting",26.0,3.0,32.0,96.0,,,volume rendering generalized;oriented gabor wavelets;points required frequency;primitives family;transfer,0.6428;0.3700;0.1926;0.0610;0.0262,"[np.int64(-1), -1, -1, -1, -1]",95;-1;-1;-1;-1,95,95
Vis,1996,Octree-based decimation of marching cubes surfaces,10.1109/visual.1996.568127,http://dx.doi.org/10.1109/VISUAL.1996.568127,335.0,342.0,C,"The marching cubes (MC) algorithm is a method for generating isosurfaces. It also generates an excessively large number of triangles to represent an isosurface; this increases the rendering time. This paper presents a decimation method to reduce the number of triangles generated. Decimation is carried out before creating a large number of triangles. Four major steps comprise the algorithm: surface tracking, merging, crack patching and triangulation. Surface tracking is an enhanced implementation of the MC algorithm. Starting from a seed point, the surface tracker visits only those cells likely to compose part of the desired isosurface. The cells making up the extracted surface are stored in an octree that is further processed. A bottom-up approach is taken in merging the cells containing a relatively flat approximating surface. The finer surface details are maintained. Cells are merged as long as the error due to such an operation is within a user-specified error parameter, or a cell acquires more than one connected surface component in it. A crack patching method is described that forces edges of smaller cells to lie along those of the larger neighboring cells. The overall saving in the number of triangles depends both on the specified error value and the nature of the data. Use of the hierarchical octree data structure also presents the potential of incremental representation of surfaces. We can generate a highly smoothed surface representation which can be progressively refined as the user-specified error value is decreased.",Raj Shekhar;Elias Fayyad;Roni Yagel;J. Fredrick Cornhill,R. Shekhar;E. Fayyad;R. Yagel;J.F. Cornhill,"Department of Biomedical Engineering, Cleveland Clinic Foundation, USA;Biomedical Engineering Center, USA;Department of Computer and Information Science, Ohio State Uinversity, USA;Department of Biomedical Engineering, Cleveland Clinic Foundation, USA",10.1109/visual.1994.346308;10.1109/visual.1994.346308,,333.0,74.0,7.0,669.0,,,marching cubes;surface component crack;use hierarchical;error parameter;relatively,0.5944;0.2573;0.1288;0.0064;-0.0037,"[np.int64(-1), -1, -1, -1, -1]",286;-1;-1;-1;-1,286,286
InfoVis,2011,Synthetic Generation of High-Dimensional Datasets,10.1109/tvcg.2011.237,http://dx.doi.org/10.1109/TVCG.2011.237,2317.0,2324.0,J,"Generation of synthetic datasets is a common practice in many research areas. Such data is often generated to meet specific needs or certain conditions that may not be easily found in the original, real data. The nature of the data varies according to the application area and includes text, graphs, social or weather data, among many others. The common process to create such synthetic datasets is to implement small scripts or programs, restricted to small problems or to a specific application. In this paper we propose a framework designed to generate high dimensional datasets. Users can interactively create and navigate through multi dimensional datasets using a suitable graphical user-interface. The data creation is driven by statistical distributions based on a few user-defined parameters. First, a grounding dataset is created according to given inputs, and then structures and trends are included in selected dimensions and orthogonal projection planes. Furthermore, our framework supports the creation of complex non-orthogonal trends and classified datasets. It can successfully be used to create synthetic datasets simulating important trends as multidimensional clusters, correlations and outliers.",Georgia Albuquerque;Thomas Löwe;Marcus A. Magnor,Georgia Albuquerque;Thomas Lowe;Marcus Magnor,"Computer Graphics Laboratory, TU Braunschweig, Germany;Computer Graphics Laboratory, TU Braunschweig, Germany;Computer Graphics Laboratory, TU Braunschweig, Germany",10.1109/infvis.2005.1532142;10.1109/visual.1994.346302;10.1109/vast.2010.5652433;10.1109/vast.2009.5332628;10.1109/infvis.2004.15;10.1109/tvcg.2008.153;10.1109/infvis.2005.1532142,"Synthetic data generation, multivariate data, high-dimensional data, interaction",71.0,35.0,20.0,2028.0,,,create synthetic datasets;multidimensional clusters correlations;trends;scripts programs restricted;navigate multi,0.7025;0.4607;0.2526;0.0753;0.0509,"[np.int64(-1), -1, -1, -1, -1]",216;-1;-1;-1;-1,216,216
Vis,2022,D-BIAS: A Causality-Based Human-in-the-Loop System for Tackling Algorithmic Bias,10.1109/tvcg.2022.3209484,http://dx.doi.org/10.1109/TVCG.2022.3209484,473.0,482.0,J,"With the rise of AI, algorithms have become better at learning underlying patterns from the training data including ingrained social biases based on gender, race, etc. Deployment of such algorithms to domains such as hiring, healthcare, law enforcement, etc. has raised serious concerns about fairness, accountability, trust and interpretability in machine learning algorithms. To alleviate this problem, we propose D-BIAS, a visual interactive tool that embodies human-in-the-loop AI approach for auditing and mitigating social biases from tabular datasets. It uses a graphical causal model to represent causal relationships among different features in the dataset and as a medium to inject domain knowledge. A user can detect the presence of bias against a group, say females, or a subgroup, say black females, by identifying unfair causal relationships in the causal network and using an array of fairness metrics. Thereafter, the user can mitigate bias by refining the causal model and acting on the unfair causal edges. For each interaction, say weakening/deleting a biased causal edge, the system uses a novel method to simulate a new (debiased) dataset based on the current causal model while ensuring a minimal change from the original dataset. Users can visually assess the impact of their interactions on different fairness metrics, utility metrics, data distortion, and the underlying data distribution. Once satisfied, they can download the debiased dataset and use it for any downstream application for fairer predictions. We evaluate D-BIAS by conducting experiments on 3 datasets and also a formal user study. We found that D-BIAS helps reduce bias significantly compared to the baseline debiasing approach across different fairness metrics while incurring little data distortion and a small loss in utility. Moreover, our human-in-the-loop based approach significantly outperforms an automated approach on trust, interpretability and accountability.",Bhavya Ghai;Klaus Mueller 0001,Bhavya Ghai;Klaus Mueller,"Computer Science department, Stony Brook University, USA;Computer Science department, Stony Brook University, USA",10.1109/tvcg.2019.2934262;10.1109/vast.2017.8585647;10.1109/tvcg.2021.3114850;10.1109/tvcg.2020.3028957;10.1109/vast47406.2019.8986948;10.1109/tvcg.2019.2934262,"Algorithmic Fairness,Causality,Debiasing,Human-in-the-loop,Visual Analytics",,18.0,50.0,1276.0,,,mitigating social biases;interpretability machine learning;original dataset;domains hiring;uses graphical,0.6165;0.4703;0.2379;0.1238;0.1083,"[np.int64(-1), -1, -1, -1, -1]",85;-1;-1;-1;-1,85,85
InfoVis,2009,Conjunctive Visual Forms,10.1109/tvcg.2009.129,http://dx.doi.org/10.1109/TVCG.2009.129,929.0,936.0,J,"Visual exploration of multidimensional data is a process of isolating and extracting relationships within and between dimensions. Coordinated multiple view approaches are particularly effective for visual exploration because they support precise expression of heterogeneous multidimensional queries using simple interactions. Recent visual analytics research has made significant progress in identifying and understanding patterns of composed views and coordinations that support fast, flexible, and open-ended data exploration. What is missing is formalization of the space of expressible queries in terms of visual representation and interaction. This paper introduces the conjunctive visual form model in which visual exploration consists of interactively-driven sequences of transitions between visual states that correspond to conjunctive normal forms in boolean logic. The model predicts several new and useful ways to extend the space of rapidly expressible queries through addition of simple interactive capabilities to existing compositional patterns. Two recent related visual tools offer a subset of these capabilities, providing a basis for conjecturing about such extensions.",Chris E. Weaver,Chris Weaver,"School of Computer Science and the Center Spatial Analysis, University of Oklahama, USA",10.1109/vast.2006.261427;10.1109/infvis.2001.963287;10.1109/infvis.2003.1249024;10.1109/tvcg.2007.70577;10.1109/visual.1995.485139;10.1109/tvcg.2007.70594;10.1109/infvis.1996.559216;10.1109/vast.2007.4389006;10.1109/vast.2008.4677370;10.1109/tvcg.2008.153;10.1109/vast.2006.261427,"Boolean query, brushing, conjunctive normal form, exploratory visualization, multiple views, visual abstraction",18.0,8.0,26.0,482.0,,,visual analytics;composed views coordinations;states correspond conjunctive;flexible open;driven sequences,0.6645;0.4438;0.3214;0.1365;0.1184,"[np.int64(-1), -1, -1, -1, -1]",201;-1;-1;-1;-1,201,201
Vis,2002,TetFusion: an algorithm for rapid tetrahedral mesh simplification,10.1109/visual.2002.1183767,http://dx.doi.org/10.1109/VISUAL.2002.1183767,133.0,140.0,C,"This paper introduces an algorithm for rapid progressive simplification of tetrahedral meshes: TetFusion. We describe how a simple geometry decimation operation steers a rapid and controlled progressive simplification of tetrahedral meshes, while also taking care of complex mesh-inconsistency problems. The algorithm features a high decimation ratio per step, and inherently discourages any cases of self-intersection of boundary, element-boundary intersection at concave boundary-regions, and negative volume tetrahedra (flipping). We achieved rigorous reduction ratios of up to 98% for meshes consisting of 827,904 elements in less than 2 minutes, progressing through a series of level-of-details (LoDs) of the mesh in a controlled manner. We describe how the approach supports a balanced re-distribution of space between tetrahedral elements, and explain some useful control parameters that make it faster and more intuitive than 'edge collapse'-based decimation methods for volumetric meshes. Finally, we discuss how this approach can be employed for rapid LoD prototyping of large time-varying datasets as an aid to interactive visualization.",Prashant Chopra;Joerg Meyer 0003,P. Chopra;J. Meyer,"Engineering Research Center, Mississippi State University, MS, USA;Engineering Research Center, Mississippi State University, MS, USA",10.1109/visual.1998.745329;10.1109/visual.1997.663883;10.1109/visual.1999.809868;10.1109/visual.2000.885680;10.1109/visual.1998.745315;10.1109/visual.1999.809901;10.1109/visual.1998.745329,"mesh simplification, multi resolution, level-of-detail, unstructured meshes",72.0,18.0,23.0,283.0,,,simplification tetrahedral meshes;lod prototyping;decimation ratio;time varying datasets;inherently discourages cases,0.7264;0.2805;0.2031;0.1673;-0.0195,"[np.int64(-1), -1, -1, -1, -1]",112;-1;-1;-1;-1,112,112
SciVis,2012,KnotPad: Visualizing and Exploring Knot Theory with Fluid Reidemeister Moves,10.1109/tvcg.2012.242,http://dx.doi.org/10.1109/TVCG.2012.242,2051.0,2060.0,J,"We present KnotPad, an interactive paper-like system for visualizing and exploring mathematical knots; we exploit topological drawing and math-aware deformation methods in particular to enable and enrich our interactions with knot diagrams. Whereas most previous efforts typically employ physically based modeling to simulate the 3D dynamics of knots and ropes, our tool offers a Reidemeister move based interactive environment that is much closer to the topological problems being solved in knot theory, yet without interfering with the traditional advantages of paper-based analysis and manipulation of knot diagrams. Drawing knot diagrams with many crossings and producing their equivalent is quite challenging and error-prone. KnotPad can restrict user manipulations to the three types of Reidemeister moves, resulting in a more fluid yet mathematically correct user experience with knots. For our principal test case of mathematical knots, KnotPad permits us to draw and edit their diagrams empowered by a family of interactive techniques. Furthermore, we exploit supplementary interface elements to enrich the user experiences. For example, KnotPad allows one to pull and drag on knot diagrams to produce mathematically valid moves. Navigation enhancements in KnotPad provide still further improvement: by remembering and displaying the sequence of valid moves applied during the entire interaction, KnotPad allows a much cleaner exploratory interface for the user to analyze and study knot equivalence. All these methods combine to reveal the complex spatial relationships of knot diagrams with a mathematically true and rich user experience.",Hui Zhang 0006;Jianguang Weng;Lin Jing;Yiwen Zhong,Hui Zhang;Jianguang Weng;Lin Jing;Yiwen Zhong,"Pervasive Technology Institute, Indiana University, USA;Zhejiang University of Media and Communications, China;Fujian Agriculture and Forestry University, China;Fujian Agriculture and Forestry University, China",10.1109/visual.2005.1532804;10.1109/visual.2005.1532843;10.1109/tvcg.2007.70593,"Knot Theory, Math Visualization",12.0,10.0,33.0,620.0,,,exploring mathematical knots;interactive paper like;3d;displaying sequence;allows cleaner,0.7388;0.4007;0.2401;0.0903;0.0710,"[np.int64(-1), -1, -1, -1, -1]",284;-1;-1;-1;-1,284,284
Vis,2021,VizLinter: A Linter and Fixer Framework for Data Visualization,10.1109/tvcg.2021.3114804,http://dx.doi.org/10.1109/TVCG.2021.3114804,206.0,216.0,J,"Despite the rising popularity of automated visualization tools, existing systems tend to provide direct results which do not always fit the input data or meet visualization requirements. Therefore, additional specification adjustments are still required in real-world use cases. However, manual adjustments are difficult since most users do not necessarily possess adequate skills or visualization knowledge. Even experienced users might create imperfect visualizations that involve chart construction errors. We present a framework, VizLinter, to help users detect flaws and rectify already-built but defective visualizations. The framework consists of two components, (1) a visualization linter, which applies well-recognized principles to inspect the legitimacy of rendered visualizations, and (2) a visualization fixer, which automatically corrects the detected violations according to the linter. We implement the framework into an online editor prototype based on Vega-Lite specifications. To further evaluate the system, we conduct an in-lab user study. The results prove its effectiveness and efficiency in identifying and fixing errors for data visualizations.",Qing Chen 0001;Fuling Sun;Xinyue Xu;Zui Chen;Jiazhe Wang;Nan Cao 0001,Qing Chen;Fuling Sun;Xinyue Xu;Zui Chen;Jiazhe Wang;Nan Cao,"Intelligent Big Data Visualization Lab at Tongji University, China;Intelligent Big Data Visualization Lab at Tongji University, China;Intelligent Big Data Visualization Lab at Tongji University, China;Intelligent Big Data Visualization Lab at Tongji University, China;Ant Group, China;Intelligent Big Data Visualization Lab at Tongji University, China",10.1109/tvcg.2008.166;10.1109/tvcg.2006.138;10.1109/tvcg.2006.163;10.1109/tvcg.2013.126;10.1109/tvcg.2012.219;10.1109/tvcg.2018.2865240;10.1109/tvcg.2017.2744198;10.1109/tvcg.2016.2599030;10.1109/tvcg.2017.2745140;10.1109/infvis.2000.885086;10.1109/tvcg.2020.3030467;10.1109/vast.2009.5332628;10.1109/infvis.2003.1249018;10.1109/tvcg.2018.2864912;10.1109/tvcg.2017.2745919;10.1109/tvcg.2015.2467191;10.1109/tvcg.2020.3030423;10.1109/tvcg.2013.234;10.1109/tvcg.2008.166,"Visualization Linting,Automated Visualization Design,Visualization Optimization",9.0,32.0,64.0,1919.0,,,visualizations visualization fixer;vega lite specifications;evaluate conduct lab;rising popularity;necessarily possess,0.7597;0.1966;0.1062;0.0410;0.0159,"[np.int64(-1), -1, -1, -1, -1]",315;-1;-1;-1;-1,315,315
InfoVis,2013,Empirical Guidance on Scatterplot and Dimension Reduction Technique Choices,10.1109/tvcg.2013.153,http://dx.doi.org/10.1109/TVCG.2013.153,2634.0,2643.0,J,"To verify cluster separation in high-dimensional data, analysts often reduce the data with a dimension reduction (DR) technique, and then visualize it with 2D Scatterplots, interactive 3D Scatterplots, or Scatterplot Matrices (SPLOMs). With the goal of providing guidance between these visual encoding choices, we conducted an empirical data study in which two human coders manually inspected a broad set of 816 scatterplots derived from 75 datasets, 4 DR techniques, and the 3 previously mentioned scatterplot techniques. Each coder scored all color-coded classes in each scatterplot in terms of their separability from other classes. We analyze the resulting quantitative data with a heatmap approach, and qualitatively discuss interesting scatterplot examples. Our findings reveal that 2D scatterplots are often 'good enough', that is, neither SPLOM nor interactive 3D adds notably more cluster separability with the chosen DR technique. If 2D is not good enough, the most promising approach is to use an alternative DR technique in 2D. Beyond that, SPLOM occasionally adds additional value, and interactive 3D rarely helps but often hurts in terms of poorer class separation and usability. We summarize these results as a workflow model and implications for design. Our results offer guidance to analysts during the DR exploration process.",Michael Sedlmair;Tamara Munzner;Melanie Tory,Michael Sedlmair;Tamara Munzner;Melanie Tory,"University of Vienna, Austria;University of British Columbia, Canada;University of Victoria, Canada",10.1109/tvcg.2009.127;10.1109/tvcg.2011.229;10.1109/tvcg.2007.70596;10.1109/infvis.2005.1532142;10.1109/infvis.1997.636793;10.1109/vast.2010.5652392;10.1109/vast.2012.6400490;10.1109/tvcg.2008.109;10.1109/vast.2009.5332628;10.1109/tvcg.2009.127,"Dimensionality reduction, scatterplots, quantitative study",186.0,124.0,53.0,1418.0,,,visualize 2d scatterplots;cluster separability chosen;datasets dr techniques;coders manually inspected;derived,0.5478;0.4412;0.3949;0.1608;0.1008,"[np.int64(-1), -1, -1, -1, -1]",172;-1;-1;-1;-1,172,172
SciVis,2013,Ambient Volume Scattering,10.1109/tvcg.2013.129,http://dx.doi.org/10.1109/TVCG.2013.129,2936.0,2945.0,J,"We present ambient scattering as a preintegration method for scattering on mesoscopic scales in direct volume rendering. Far-range scattering effects usually provide negligible contributions to a given location due to the exponential attenuation with increasing distance. This motivates our approach to preintegrating multiple scattering within a finite spherical region around any given sample point. To this end, we solve the full light transport with a Monte-Carlo simulation within a set of spherical regions, where each region may have different material parameters regarding anisotropy and extinction. This precomputation is independent of the data set and the transfer function, and results in a small preintegration table. During rendering, the look-up table is accessed for each ray sample point with respect to the viewing direction, phase function, and material properties in the spherical neighborhood of the sample. Our rendering technique is efficient and versatile because it readily fits in existing ray marching algorithms and can be combined with local illumination and volumetric ambient occlusion. It provides interactive volumetric scattering and soft shadows, with interactive control of the transfer function, anisotropy parameter of the phase function, lighting conditions, and viewpoint. A GPU implementation demonstrates the benefits of ambient scattering for the visualization of different types of data sets, with respect to spatial perception, high-quality illumination, translucency, and rendering speed.",Marco Ament;Filip Sadlo;Daniel Weiskopf,Marco Ament;Filip Sadlo;Daniel Weiskopf,"VISUS, University of Stuttgart, Germany;VISUS, University of Stuttgart, Germany;VISUS, University of Stuttgart, Germany",10.1109/tvcg.2011.211;10.1109/tvcg.2007.70555;10.1109/visual.2003.1250394;10.1109/visual.2000.885683;10.1109/tvcg.2010.187;10.1109/visual.2004.64;10.1109/visual.2003.1250406;10.1109/tvcg.2010.145;10.1109/tvcg.2012.232;10.1109/tvcg.2011.161;10.1109/tvcg.2011.198;10.1109/visual.2002.1183764;10.1109/visual.2005.1532803;10.1109/tvcg.2009.204;10.1109/tvcg.2011.211,"Direct volume rendering, volume illumination, ambient scattering, preintegrated light transport, gradient-free shading",41.0,29.0,50.0,784.0,HM,,interactive volumetric scattering;lighting conditions;table accessed;precomputation independent;increasing,0.7437;0.2664;0.0701;0.0660;0.0318,"[np.int64(-1), -1, -1, -1, -1]",294;-1;-1;-1;-1,294,294
VAST,2009,"VIScover: Visualizing, exploring, and analysing structured data",10.1109/vast.2009.5333946,http://dx.doi.org/10.1109/VAST.2009.5333946,,,M,"Today's challenging task in intelligent data processing is not to store large volumes of interlinked data but to visualize, explore, and understand its explicit or implicit relationships. Our solution to this is the VIScover system. VIScover combines semantic technologies with interactive exploration and visualization techniques able to analyze large volumes of structured data. We briefly describe our VIScover system and show its potential using the example of the VAST 2009 social network and geospatial data set.",Thorsten Liebig;Olaf Noppens;Friedrich W. von Henke,Thorsten Liebig;Olaf Noppens;Friedrich von Henke,"Derivo GmbH, Ulm University, Germany;Derivo GmbH, Ulm University, Germany;Ulm University, Germany",,,1.0,3.0,3.0,151.0,,,interlinked data visualize;semantic technologies;geospatial;processing store large;today,0.6089;0.5241;0.1857;0.1551;-0.0053,"[np.int64(-1), np.int64(-1), -1, -1, -1]",181;86;-1;-1;-1,86;181,181
Vis,2009,Verifiable Visualization for Isosurface Extraction,10.1109/tvcg.2009.194,http://dx.doi.org/10.1109/TVCG.2009.194,1227.0,1234.0,J,"Visual representations of isosurfaces are ubiquitous in the scientific and engineering literature. In this paper, we present techniques to assess the behavior of isosurface extraction codes. Where applicable, these techniques allow us to distinguish whether anomalies in isosurface features can be attributed to the underlying physical process or to artifacts from the extraction process. Such scientific scrutiny is at the heart of verifiable visualization - subjecting visualization algorithms to the same verification process that is used in other components of the scientific pipeline. More concretely, we derive formulas for the expected order of accuracy (or convergence rate) of several isosurface features, and compare them to experimentally observed results in the selected codes. This technique is practical: in two cases, it exposed actual problems in implementations. We provide the reader with the range of responses they can expect to encounter with isosurface techniques, both under ldquonormal operating conditionsrdquo and also under adverse conditions. Armed with this information - the results of the verification process - practitioners can judiciously select the isosurface extraction technique appropriate for their problem of interest, and have confidence in its behavior.",Tiago Etiene;Carlos Eduardo Scheidegger;Luis Gustavo Nonato;Robert M. Kirby;Cláudio T. Silva,Tiago Etiene;Carlos Scheidegger;Luis Gustavo Nonato;Robert Mike Kirby;Cláudio Silva,"School of Computing and Scientific Computing and Imaging Institute, University of Utah, Salt Lake, UT, USA;School of Computing and Scientific Computing and Imaging Institute, University of Utah, Salt Lake, UT, USA;University of São Paulo, Brazil;School of Computing and Scientific Computing and Imaging Institute, University of Utah, Salt Lake, UT, USA;School of Computing and Scientific Computing and Imaging Institute, University of Utah, Salt Lake, UT, USA",10.1109/tvcg.2006.149;10.1109/visual.1994.346331;10.1109/tvcg.2006.149,"Verification, V&V, Isosurface Extraction, Marching Cubes",35.0,20.0,29.0,350.0,,,behavior isosurface extraction;verifiable visualization;scientific pipeline;expected order accuracy;codes applicable,0.7395;0.4452;0.1665;0.1156;0.1127,"[np.int64(-1), -1, -1, -1, -1]",229;-1;-1;-1;-1,229,229
InfoVis,2004,The InfoVis Toolkit,10.1109/infvis.2004.64,http://dx.doi.org/10.1109/INFVIS.2004.64,167.0,174.0,C,"This article presents the InfoVis toolkit, designed to support the creation, extension and integration of advanced 2D information visualization components into interactive Java swing applications. The InfoVis toolkit provides specific data structures to achieve a fast action/feedback loop required by dynamic queries. It comes with a large set of components such as range sliders and tailored control panels required to control and configure the visualizations. These components are integrated into a coherent framework that simplifies the management of rich data structures and the design and extension of visualizations. Supported data structures currently include tables, trees and graphs. Supported visualizations include scatter plots, time series, parallel coordinates, treemaps, icicle trees, node-link diagrams for trees and graphs and adjacency matrices for graphs. All visualizations can use fisheye lenses and dynamic labeling. The InfoVis toolkit supports hardware acceleration when available through Agile2D, an implementation of the Java graphics API based on OpenGL, achieving speedups of 10 to 200 times. The article also shows how new visualizations can be added and extended to become components, enriching visualizations as well as general applications",Jean-Daniel Fekete,J.-D. Fekete,"INRIA Futurs/LRI, Université Paris Sud, Orsay, France",10.1109/infvis.2003.1249008;10.1109/infvis.2000.885086;10.1109/infvis.2002.1173156;10.1109/infvis.1995.528688;10.1109/infvis.2002.1173148;10.1109/infvis.2003.1249008,"Information Visualization, Toolkit, Graphics, Integration",424.0,109.0,27.0,1166.0,,,information visualization;java swing applications;time series parallel;set components range;added extended,0.6782;0.5017;0.1661;0.1202;-0.0210,"[np.int64(-1), np.int64(-1), -1, -1, -1]",207;231;-1;-1;-1,207;231,207
InfoVis,2019,Data Sampling in Multi-view and Multi-class Scatterplots via Set Cover Optimization,10.1109/tvcg.2019.2934799,http://dx.doi.org/10.1109/TVCG.2019.2934799,739.0,748.0,J,"We present a method for data sampling in scatterplots by jointly optimizing point selection for different views or classes. Our method uses space-filling curves (Z-order curves) that partition a point set into subsets that, when covered each by one sample, provide a sampling or coreset with good approximation guarantees in relation to the original point set. For scatterplot matrices with multiple views, different views provide different space-filling curves, leading to different partitions of the given point set. For multi-class scatterplots, the focus on either per-class distribution or global distribution provides two different partitions of the given point set that need to be considered in the selection of the coreset. For both cases, we convert the coreset selection problem into an Exact Cover Problem (ECP), and demonstrate with quantitative and qualitative evaluations that an approximate solution that solves the ECP efficiently is able to provide high-quality samplings.",Ruizhen Hu;Tingkai Sha;Oliver van Kaick;Oliver Deussen;Hui Huang 0004,Ruizhen Hu;Tingkai Sha;Oliver Van Kaick;Oliver Deussen;Hui Huang,"Shenzhen University, Visual Computing Research Center, China;Shenzhen University, Visual Computing Research Center, China;Carleton University, School of Computer Science, Canada;Konstanz University, Germany and Shenzhen VisuCA Key Lab, SIAT, China;Shenzhen University, Visual Computing Research Center, China",10.1109/tvcg.2018.2864912;10.1109/tvcg.2013.153;10.1109/tvcg.2010.176;10.1109/tvcg.2007.70535;10.1109/tvcg.2014.2346594;10.1109/tvcg.2011.229;10.1109/tvcg.2008.119;10.1109/tvcg.2006.170;10.1109/visual.1998.745301;10.1109/tvcg.2018.2864912,"Sampling,Scatterplot,SPLOM,Exact Cover Problem",19.0,16.0,43.0,842.0,,,sampling scatterplots;filling curves leading;jointly optimizing point;multi class;exact cover,0.7015;0.2494;0.2298;0.1837;0.1680,"[np.int64(-1), -1, -1, -1, -1]",286;-1;-1;-1;-1,286,286
Vis,1995,Turbulent flow visualization in computational and experimental hydraulics,10.1109/visual.1995.485158,http://dx.doi.org/10.1109/VISUAL.1995.485158,388.0,,C,"Many practical problems in open channel hydraulics that were traditionally investigated in hydraulic model experiments, are nowadays being solved by using computational fluid dynamics. However, in order to interpret computational results, there is a clear preference among scientists and engineers for visualization in analogy with experimental techniques. One such technique, particle tracing, enables a dynamic (Lagrangian) interpretation of a statically (Eulerian) computed vector field. However, quite often the emphasis in particle tracing is only on the mean flow properties, while effects due to dispersion and mixing are often not accounted for. Hence turbulent flow characteristics have to be incorporated in a visualization system for practical hydraulic engineering problems. The particle tracing technique presented in this case study has been specifically developed to combine both mean and fluctuating velocity vectors, thus simulating stochastic perturbations around mean flow conditions. A number of cases are presented that demonstrate the practical applicability of advanced visualization techniques in realistic engineering studies.",Arthur E. Mynett;I. Ari Sadarjoen;A. J. S. Hin,A.E. Mynett;I.A. Sadarjoen;A.J.S. Hin,"Strategic R&D, Delft Hydraulics, Delft, Netherlands;Department of Technical Informatics, Delft University of Technnology, Delft, Netherlands;Department of Computing Science, University of Groningam, Groningen, Netherlands",0.1109/visual.1994.346329,,7.0,3.0,6.0,134.0,,,visualization practical hydraulic;problems particle tracing;stochastic perturbations mean;eulerian computed vector;nowadays,0.6773;0.4138;0.1619;0.1348;0.0511,"[np.int64(-1), -1, -1, -1, -1]",146;-1;-1;-1;-1,146,146
InfoVis,2018,A Heuristic Approach to Value-Driven Evaluation of Visualizations,10.1109/tvcg.2018.2865146,http://dx.doi.org/10.1109/TVCG.2018.2865146,491.0,500.0,J,"Recently, an approach for determining the value of a visualization was proposed, one moving beyond simple measurements of task accuracy and speed. The value equation contains components for the time savings a visualization provides, the insights and insightful questions it spurs, the overall essence of the data it conveys, and the confidence about the data and its domain it inspires. This articulation of value is purely descriptive, however, providing no actionable method of assessing a visualization's value. In this work, we create a heuristic-based evaluation methodology to accompany the value equation for assessing interactive visualizations. We refer to the methodology colloquially as ICE-T, based on an anagram of the four value components. Our approach breaks the four components down into guidelines, each of which is made up of a small set of low-level heuristics. Evaluators who have knowledge of visualization design principles then assess the visualization with respect to the heuristics. We conducted an initial trial of the methodology on three interactive visualizations of the same data set, each evaluated by 15 visualization experts. We found that the methodology showed promise, obtaining consistent ratings across the three visualizations and mirroring judgments of the utility of the visualizations by instructors of the course in which they were developed.",Emily Wall;Meeshu Agnihotri;Laura E. Matzen;Kristin Divis;Michael Haass;Alex Endert;John T. Stasko,Emily Wall;Meeshu Agnihotri;Laura Matzen;Kristin Divis;Michael Haass;Alex Endert;John Stasko,"Georgia Institute of Technology, Atlanta, GA, US;Georgia Institute of Technology, Atlanta, GA, US;Sandia National Laboratories, Albuquerque, NM, US;Sandia National Laboratories, Albuquerque, NM, US;Sandia National Laboratories, Albuquerque, NM, US;Georgia Institute of Technology, Atlanta, GA, US;Georgia Institute of Technology, Atlanta, GA, US",10.1109/infvis.2001.963289;10.1109/visual.2003.1250401;10.1109/infvis.2001.963289,"Visualization evaluation,heuristics,value of visualization",61.0,67.0,35.0,2501.0,,,assessing visualization value;heuristic;colloquially ice;instructors course developed;equation contains components,0.7857;0.2580;0.1352;0.1090;-0.0337,"[np.int64(-1), -1, -1, -1, -1]",211;-1;-1;-1;-1,211,211
InfoVis,2012,Does an Eye Tracker Tell the Truth about Visualizations?: findings while Investigating Visualizations for Decision Making,10.1109/tvcg.2012.215,http://dx.doi.org/10.1109/TVCG.2012.215,2421.0,2430.0,J,"For information visualization researchers, eye tracking has been a useful tool to investigate research participants' underlying cognitive processes by tracking their eye movements while they interact with visual techniques. We used an eye tracker to better understand why participants with a variant of a tabular visualization called `SimulSort' outperformed ones with a conventional table and typical one-column sorting feature (i.e., Typical Sorting). The collected eye-tracking data certainly shed light on the detailed cognitive processes of the participants; SimulSort helped with decision-making tasks by promoting efficient browsing behavior and compensatory decision-making strategies. However, more interestingly, we also found unexpected eye-tracking patterns with Simul- Sort. We investigated the cause of the unexpected patterns through a crowdsourcing-based study (i.e., Experiment 2), which elicited an important limitation of the eye tracking method: incapability of capturing peripheral vision. This particular result would be a caveat for other visualization researchers who plan to use an eye tracker in their studies. In addition, the method to use a testing stimulus (i.e., influential column) in Experiment 2 to verify the existence of such limitations would be useful for researchers who would like to verify their eye tracking results.",Sung-Hee Kim;Zhihua Dong;Hanjun Xian;Benjavan Upatising;Ji Soo Yi,Sung-Hee Kim;Zhihua Dong;Hanjun Xian;Benjavan Upatising;Ji Soo Yi,"School of Industrial Engineering, Purdue University, USA;School of Industrial Engineering, Purdue University, USA;School of Engineering Education, Purdue University, USA;School of Industrial Engineering, Purdue University, USA;School of Industrial Engineering, Purdue University, USA",10.1109/visual.1990.146402;10.1109/tvcg.2011.193;10.1109/vast.2008.4677363;10.1109/tvcg.2010.149;10.1109/tvcg.2011.183;10.1109/vast.2009.5333920;10.1109/visual.1990.146402,"Visualized decision making, eye tracking, crowdsourcing, quantitative empirical study, limitations, peripheral vision",86.0,45.0,55.0,1611.0,,,visualization researchers eye;efficient browsing behavior;column sorting;cause unexpected patterns;compensatory decision,0.6825;0.3352;0.3260;0.1427;0.0423,"[np.int64(-1), -1, -1, -1, -1]",321;-1;-1;-1;-1,321,321
Vis,2005,On the optimization of visualizations of complex phenomena,10.1109/visual.2005.1532782,http://dx.doi.org/10.1109/VISUAL.2005.1532782,87.0,94.0,C,"The problem of perceptually optimizing complex visualizations is a difficult one, involving perceptual as well as aesthetic issues. In our experience, controlled experiments are quite limited in their ability to uncover interrelationships among visualization parameters, and thus may not be the most useful way to develop rules-of-thumb or theory to guide the production of high-quality visualizations. In this paper, we propose a new experimental approach to optimizing visualization quality that integrates some of the strong points of controlled experiments with methods more suited to investigating complex highly-coupled phenomena. We use human-in-the-loop experiments to search through visualization parameter space, generating large databases of rated visualization solutions. This is followed by data mining to extract results such as exemplar visualizations, guidelines for producing visualizations, and hypotheses about strategies leading to strong visualizations. The approach can easily address both perceptual and aesthetic concerns, and can handle complex parameter interactions. We suggest a genetic algorithm as a valuable way of guiding the human-in-the-loop search through visualization parameter space. We describe our methods for using clustering, histogramming, principal component analysis, and neural networks for data mining. The experimental approach is illustrated with a study of the problem of optimal texturing for viewing layered surfaces so that both surfaces are maximally observable.",Donald H. House;Alethea Bair;Colin Ware,D. House;A. Bair;C. Ware,"Texas A and M University, USA;Texas A and M University, USA;University of New Hampshire, USA",10.1109/visual.1996.568113;10.1109/visual.1996.567784,"perception, visualization evaluation,layered surfaces, genetic algorithm, data mining, principal component analysis, neural networks",40.0,6.0,30.0,238.0,,,optimizing visualization quality;neural networks data;loop search;genetic;coupled phenomena,0.6607;0.3107;0.1533;0.1508;0.0629,"[np.int64(-1), -1, -1, -1, -1]",186;-1;-1;-1;-1,186,186
SciVis,2013,Visualization of Morse Connection Graphs for Topologically Rich 2D Vector fields,10.1109/tvcg.2013.229,http://dx.doi.org/10.1109/TVCG.2013.229,2763.0,2772.0,J,"Recent advances in vector field topologymake it possible to compute its multi-scale graph representations for autonomous 2D vector fields in a robust and efficient manner. One of these representations is a Morse Connection Graph (MCG), a directed graph whose nodes correspond to Morse sets, generalizing stationary points and periodic trajectories, and arcs - to trajectories connecting them. While being useful for simple vector fields, the MCG can be hard to comprehend for topologically rich vector fields, containing a large number of features. This paper describes a visual representation of the MCG, inspired by previous work on graph visualization. Our approach aims to preserve the spatial relationships between the MCG arcs and nodes and highlight the coherent behavior of connecting trajectories. Using simulations of ocean flow, we show that it can provide useful information on the flow structure. This paper focuses specifically on MCGs computed for piecewise constant (PC) vector fields. In particular, we describe extensions of the PC framework that make it more flexible and better suited for analysis of data on complex shaped domains with a boundary. We also describe a topology simplification scheme that makes our MCG visualizations less ambiguous. Despite the focus on the PC framework, our approach could also be applied to graph representations or topological skeletons computed using different methods.",Andrzej Szymczak;Levente Sipeki,Andrzej Szymczak;Levente Sipeki,"Colorado School of Mines, USA;Colorado School of Mines, USA",10.1109/tvcg.2011.233;10.1109/tvcg.2008.135;10.1109/tvcg.2012.209;10.1109/visual.2000.885716;10.1109/tvcg.2011.233,"Morse connection graph, vector field topology",4.0,2.0,34.0,344.0,,,morse connection graph;ocean flow;mcgs computed piecewise;fields containing large;pc framework make,0.6049;0.3595;0.1092;0.0446;-0.0223,"[np.int64(-1), -1, -1, -1, -1]",226;-1;-1;-1;-1,226,226
Vis,2023,CLAMS: A Cluster Ambiguity Measure for Estimating Perceptual Variability in Visual Clustering,10.1109/tvcg.2023.3327201,http://dx.doi.org/10.1109/TVCG.2023.3327201,770.0,780.0,J,"Visual clustering is a common perceptual task in scatterplots that supports diverse analytics tasks (e.g., cluster identification). However, even with the same scatterplot, the ways of perceiving clusters (i.e., conducting visual clustering) can differ due to the differences among individuals and ambiguous cluster boundaries. Although such perceptual variability casts doubt on the reliability of data analysis based on visual clustering, we lack a systematic way to efficiently assess this variability. In this research, we study perceptual variability in conducting visual clustering, which we call Cluster Ambiguity. To this end, we introduce CLAMS, a data-driven visual quality measure for automatically predicting cluster ambiguity in monochrome scatterplots. We first conduct a qualitative study to identify key factors that affect the visual separation of clusters (e.g., proximity or size difference between clusters). Based on study findings, we deploy a regression module that estimates the human-judged separability of two clusters. Then, CLAMS predicts cluster ambiguity by analyzing the aggregated results of all pairwise separability between clusters that are generated by the module. CLAMS outperforms widely-used clustering techniques in predicting ground truth cluster ambiguity. Meanwhile, CLAMS exhibits performance on par with human annotators. We conclude our work by presenting two applications for optimizing and benchmarking data mining techniques using CLAMS. The interactive demo of CLAMS is available at clusterambiguity.dev.",Hyeon Jeon;Ghulam Jilani Quadri;Hyunwook Lee;Paul Rosen 0001;Danielle Albers Szafir;Jinwook Seo,Hyeon Jeon;Ghulam Jilani Quadri;Hyunwook Lee;Paul Rosen;Danielle Albers Szafir;Jinwook Seo,"Seoul National University, South Korea;University of North Carolina, Chapel Hill, USA;UNIST, South Korea;University of Utah, USA;Seoul National University, South Korea;Seoul National University, South Korea",0.1109/infvis.2005.1532136;10.1109/tvcg.2011.229;10.1109/tvcg.2013.124;10.1109/tvcg.2014.2346572;10.1109/tvcg.2021.3114833;10.1109/tvcg.2017.2744718;10.1109/tvcg.2019.2934811;10.1109/tvcg.2018.2865240;10.1109/tvcg.2020.3030365;10.1109/tvcg.2017.2744184;10.1109/tvcg.2018.2864912;10.1109/tvcg.2021.3114694,"Cluster,scatterplot,perception,cluster analysis,cluster ambiguity,visual quality measure",,8.0,86.0,977.0,HM,,visual separation clusters;benchmarking data;clams predicts;ambiguity end;key factors affect,0.6600;0.2530;0.2051;0.1275;0.0579,"[np.int64(-1), -1, -1, -1, -1]",283;-1;-1;-1;-1,283,283
Vis,1996,Choosing effective colours for data visualization,10.1109/visual.1996.568118,http://dx.doi.org/10.1109/VISUAL.1996.568118,263.0,270.0,C,"We describe a technique for choosing multiple colours for use during data visualization. Our goal is a systematic method for maximizing the total number of colours available for use, while still allowing an observer to rapidly and accurately search a display for any one of the given colours. Previous research suggests that we need to consider three separate effects during colour selection: colour distance, linear separation, and colour category. We describe a simple method for measuring and controlling all of these effects. Our method was tested by performing a set of target identification studies; we analysed the ability of thirty eight observers to find a colour target in displays that contained differently coloured background elements. Results showed our method can be used to select a group of colours that will provide good differentiation between data elements during data visualization.",Christopher G. Healey,C.G. Healey,"Department of Computer Science, University of British Columbia, Vancouver, BC, Canada",10.1109/visual.1995.480803;10.1109/visual.1993.398874;10.1109/visual.1995.480803,,417.0,87.0,22.0,2195.0,,,colour target displays;elements data visualization;choosing multiple;distance linear separation;research,0.6312;0.4158;0.2501;0.1923;0.0799,"[np.int64(-1), -1, -1, -1, -1]",25;-1;-1;-1;-1,25,25
Vis,2008,Continuous Scatterplots,10.1109/tvcg.2008.119,http://dx.doi.org/10.1109/TVCG.2008.119,1428.0,1435.0,J,"Scatterplots are well established means of visualizing discrete data values with two data variables as a collection of discrete points. We aim at generalizing the concept of scatterplots to the visualization of spatially continuous input data by a continuous and dense plot. An example of a continuous input field is data defined on an n-D spatial grid with respective interpolation or reconstruction of in-between values. We propose a rigorous, accurate, and generic mathematical model of continuous scatterplots that considers an arbitrary density defined on an input field on an n-D domain and that maps this density to m-D scatterplots. Special cases are derived from this generic model and discussed in detail: scatterplots where the n-D spatial domain and the m-D data attribute domain have identical dimension, 1-D scatterplots as a way to define continuous histograms, and 2-D scatterplots of data on 3-D spatial grids. We show how continuous histograms are related to traditional discrete histograms and to the histograms of isosurface statistics. Based on the mathematical model of continuous scatterplots, respective visualization algorithms are derived, in particular for 2-D scatterplots of data from 3-D tetrahedral grids. For several visualization tasks, we show the applicability of continuous scatterplots. Since continuous scatterplots do not only sample data at grid points but interpolate data values within cells, a dense and complete visualization of the data set is achieved that scales well with increasing data set size. Especially for irregular grids with varying cell size, improved results are obtained when compared to conventional scatterplots. Therefore, continuous scatterplots are a suitable extension of a statistics visualization technique to be applied to typical data from scientific computation.",Sven Bachthaler;Daniel Weiskopf,Sven Bachthaler;Daniel Weiskopf,"VISUS (Visualization Research Center), Universität Stuttgart, Stuttgart, Germany;VISUS (Visualization Research Center), Universität Stuttgart, Stuttgart, Germany",10.1109/tvcg.2006.168;10.1109/tvcg.2008.160;10.1109/tvcg.2006.168,"Scatterplot, histogram, continuous frequency plot, interpolation",193.0,121.0,15.0,1348.0,,,scatterplots visualization spatially;interpolation reconstruction values;size especially;example continuous;derived generic model,0.7308;0.2630;0.1009;0.0591;-0.0463,"[np.int64(-1), -1, -1, -1, -1]",172;-1;-1;-1;-1,172,172
Vis,1996,Anatomy-based facial tissue modeling using the finite element method,10.1109/visual.1996.567595,http://dx.doi.org/10.1109/VISUAL.1996.567595,21.0,28.0,C,"Anatomy-based facial tissue modeling for surgical simulation is a field whose time has come. Real-time facial animation has been created in the last few years using models based on the anatomical structure of the human skin. Anatomy-based models are also under development in the field of medical visualization, with which facial surgery can be realistically simulated. In this article, we present an anatomy-based 3D finite element tissue model. Integrated into a computer-aided surgical planning system, this model allows the precise prediction of soft tissue changes resulting from the realignment of the underlying bone structure. The model has already been used in our Department of Oral and Maxillofacial Surgery and has improved craniofacial surgical planning procedures. The model is described in detail, and surgical simulation results are shown and discussed.",Erwin Keeve;Sabine Girod;Paula Pfeifle;Bernd Girod,E. Keeve;S. Girod;P. Pfeifle;B. Girod,"Telecommunications Institute, University of Erlangen Nuremberg, Germany;Department of Oral and Maxillofacial Surgery, University of Erlangen Nuremberg, Germany;Telecommunications Institute, University of Erlangen Nuremberg, Germany;Telecommunications Institute, University of Erlangen Nuremberg, Germany",,"human facial modeling, finite element method, computer-aided surgery, surgery planning and simulation",158.0,32.0,12.0,306.0,,,visualization facial surgery;3d finite element;bone;precise prediction soft;development field,0.7270;0.4155;0.2123;0.1028;0.0867,"[np.int64(-1), -1, -1, -1, -1]",313;-1;-1;-1;-1,313,313
Vis,2021,E-ffective: A Visual Analytic System for Exploring the Emotion and Effectiveness of Inspirational Speeches,10.1109/tvcg.2021.3114789,http://dx.doi.org/10.1109/TVCG.2021.3114789,508.0,517.0,J,"What makes speeches effective has long been a subject for debate, and until today there is broad controversy among public speaking experts about what factors make a speech effective as well as the roles of these factors in speeches. Moreover, there is a lack of quantitative analysis methods to help understand effective speaking strategies. In this paper, we propose E-ffective, a visual analytic system allowing speaking experts and novices to analyze both the role of speech factors and their contribution in effective speeches. From interviews with domain experts and investigating existing literature, we identified important factors to consider in inspirational speeches. We obtained the generated factors from multi-modal data that were then related to effectiveness data. Our system supports rapid understanding of critical factors in inspirational speeches, including the influence of emotions by means of novel visualization methods and interaction. Two novel visualizations include E-spiral (that shows the emotional shifts in speeches in a visually compact way) and E-script (that connects speech content with key speech delivery information). In our evaluation we studied the influence of our system on experts' domain knowledge about speech factors. We further studied the usability of the system by speaking novices and experts on assisting analysis of inspirational speech effectiveness.",Kevin T. Maher;Ze-Yuan Huang;Jian-Cheng Song;Xiaoming Deng 0001;Yu-Kun Lai;Cuixia Ma;Hao Wang 0005;Yong-Jin Liu 0001;Hongan Wang,Kevin Maher;Zeyuan Huang;Jiancheng Song;Xiaoming Deng;Yu-Kun Lai;Cuixia Ma;Hao Wang;Yong-Jin Liu;Hongan Wang,"Institute of Software, Chinese Academy of Sciences, Tsinghua University, China;State Key Laboratory of Computer Science, Beijing Key Lab of Human-Computer Interaction, Institute of Software, Chinese Academy of Sciences, University of Chinese Academy of Sciences, China;State Key Laboratory of Computer Science, Beijing Key Lab of Human-Computer Interaction, Institute of Software, Chinese Academy of Sciences, University of Chinese Academy of Sciences, China;State Key Laboratory of Computer Science, Beijing Key Lab of Human-Computer Interaction, Institute of Software, Chinese Academy of Sciences, University of Chinese Academy of Sciences, China;Cardiff University, United Kingdom;State Key Laboratory of Computer Science, Beijing Key Lab of Human-Computer Interaction, Institute of Software, Chinese Academy of Sciences, University of Chinese Academy of Sciences, China;State Key Laboratory of Computer Science, Beijing Key Lab of Human-Computer Interaction, Institute of Software, Chinese Academy of Sciences, University of Chinese Academy of Sciences, China;Tsinghua University, China;Alibaba Group, China",10.1109/tvcg.2019.2934656;10.1109/tvcg.2019.2934656,"Affective visualization,multimodal analysis,speech effectiveness",1.0,8.0,34.0,1169.0,,,inspirational speech effectiveness;visualizations include spiral;multi modal;domain experts;generated factors,0.6466;0.3507;0.2039;0.1755;0.1196,"[np.int64(-1), -1, -1, -1, -1]",114;-1;-1;-1;-1,114,114
Vis,2024,Learnable and Expressive Visualization Authoring Through Blended Interfaces,10.1109/tvcg.2024.3456598,http://dx.doi.org/10.1109/TVCG.2024.3456598,459.0,469.0,J,"A wide range of visualization authoring interfaces enable the creation of highly customized visualizations. However, prioritizing expressiveness often impedes the learnability of the authoring interface. The diversity of users, such as varying computational skills and prior experiences in user interfaces, makes it even more challenging for a single authoring interface to satisfy the needs of a broad audience. In this paper, we introduce a framework to balance learnability and expressivity in a visualization authoring system. Adopting insights from learnability studies, such as multimodal interaction and visualization literacy, we explore the design space of blending multiple visualization authoring interfaces for supporting authoring tasks in a complementary and flexible manner. To evaluate the effectiveness of blending interfaces, we implemented a proof-of-concept system, Blace, that combines four common visualization authoring interfaces–template-based, shelf configuration, natural language, and code editor–that are tightly linked to one another to help users easily relate unfamiliar interfaces to more familiar ones. Using the system, we conducted a user study with 12 domain experts who regularly visualize genomics data as part of their analysis workflow. Participants with varied visualization and programming backgrounds were able to successfully reproduce unfamiliar visualization examples without a guided tutorial in the study. Feedback from a post-study qualitative questionnaire further suggests that blending interfaces enabled participants to learn the system easily and assisted them in confidently editing unfamiliar visualization grammar in the code editor, enabling expressive customization. Reflecting on our study results and the design of our system, we discuss the different interaction patterns that we identified and design implications for blending visualization authoring interfaces.",Sehi L'Yi;Astrid van den Brandt;Etowah Adams;Huyen N. Nguyen;Nils Gehlenborg,Sehi L’Yi;Astrid van den Brandt;Etowah Adams;Huyen N. Nguyen;Nils Gehlenborg,"Harvard Medical School, USA;Eindhoven University of Technology and Harvard Medical School, Netherlands;Harvard Medical School, USA;Harvard Medical School, USA;Harvard Medical School, USA",10.1109/tvcg.2011.185;10.1109/tvcg.2010.164;10.1109/tvcg.2017.2743859;10.1109/tvcg.2016.2598920;10.1109/tvcg.2022.3209398;10.1109/tvcg.2020.3030419;10.1109/tvcg.2021.3114876;10.1109/tvcg.2022.3209407;10.1109/tvcg.2014.2346291;10.1109/tvcg.2018.2865158;10.1109/tvcg.2016.2598839;10.1109/tvcg.2019.2934281;10.1109/tvcg.2016.2599030;10.1109/tvcg.2017.2745219;10.1109/tvcg.2023.3326585;10.1109/tvcg.2022.3209435;10.1109/tvcg.2022.3209357;10.1109/tvcg.2015.2467191;10.1109/tvcg.2020.3030367,"Visualization authoring,blended interfaces,,,genomics data visualization",,0.0,83.0,566.0,HM,,visualization authoring interfaces;natural language code;study;shelf configuration;blace combines common,0.6880;0.3507;0.1364;0.1008;0.0435,"[np.int64(-1), -1, -1, -1, -1]",195;-1;-1;-1;-1,195,195
VAST,2019,You can't always sketch what you want: Understanding Sensemaking in Visual Query Systems,10.1109/tvcg.2019.2934666,http://dx.doi.org/10.1109/TVCG.2019.2934666,1267.0,1277.0,J,"Visual query systems (VQSs) empower users to interactively search for line charts with desired visual patterns, typically specified using intuitive sketch-based interfaces. Despite decades of past work on VQSs, these efforts have not translated to adoption in practice, possibly because VQSs are largely evaluated in unrealistic lab-based settings. To remedy this gap in adoption, we collaborated with experts from three diverse domains—astronomy, genetics, and material science—via a year-long user-centered design process to develop a VQS that supports their workflow and analytical needs, and evaluate how VQSs can be used in practice. Our study results reveal that ad-hoc sketch-only querying is not as commonly used as prior work suggests, since analysts are often unable to precisely express their patterns of interest. In addition, we characterize three essential sensemaking processes supported by our enhanced VQS. We discover that participants employ all three processes, but in different proportions, depending on the analytical needs in each domain. Our findings suggest that all three sensemaking processes must be integrated in order to make future VQSs useful for a wide range of analytical inquiries.",Doris Jung Lin Lee;John Lee 0005;Tarique Siddiqui;Jaewoo Kim;Karrie Karahalios;Aditya G. Parameswaran,Doris Jung-Lin Lee;John Lee;Tarique Siddiqui;Jaewoo Kim;Karrie Karahalios;Aditya Parameswaran,"University of California, Berkeley;University of Illinois, Urbana-Champaign;University of Illinois, Urbana-Champaign;University of Illinois, Urbana-Champaign;University of Illinois, Urbana-Champaign;University of California, Berkeley",10.1109/infvis.2005.1532136;10.1109/vast.2008.4677353;10.1109/tvcg.2017.2743990;10.1109/vast.2016.7883519;10.1109/tvcg.2009.111;10.1109/tvcg.2012.213,"Visual analytics,exploratory analysis,visual queries",27.0,16.0,50.0,693.0,,,visual query systems;findings suggest sensemaking;astronomy genetics material;evaluated unrealistic lab;decades,0.6236;0.4161;0.2586;0.1759;0.0839,"[np.int64(-1), -1, -1, -1, -1]",268;-1;-1;-1;-1,268,268
Vis,1999,Structured spatial domain image and data comparison metrics,10.1109/visual.1999.809873,http://dx.doi.org/10.1109/VISUAL.1999.809873,97.0,515.0,C,"Often, images or datasets have to be compared to facilitate choices of visualization and simulation parameters respectively. Common comparison techniques include side-by-side viewing and juxtaposition, in order to facilitate visual verification of verisimilitude. We propose quantitative techniques which accentuate differences in images and datasets. The comparison is enabled through a collection of partial metrics which, essentially, measure the lack of correlation between the datasets or images being compared. That is, they attempt to expose and measure the extent of the inherent structures in the difference between images or datasets. Besides yielding numerical attributes, the metrics also produce images which can visually highlight differences. Our metrics are simple to compute and operate in the spatial domain. We demonstrate the effectiveness of our metrics through examples for comparing images and datasets.",Nivedita Sahasrabudhe;John E. West;Raghu Machiraju;Mark Janus,N. Sahasrabudhe;J.E. West;R. Machiraju;M. Janus,"NSF Engineering Research Center, Mississippi State University, USA;NSF Engineering Research Center, Mississippi State University, USA and DoD High Performance Computing Center, Information Technology Laboratory, USAE Waterways Experiment Station, USA;Department of Computer Science, NSF Engineering Research Center, Mississippi State University, USA;Department of AeroSpace Engineering, NSF Engineering Research Center, Mississippi State University, USA",10.1109/visual.1997.663848;10.1109/visual.1990.146360;10.1109/visual.1998.745332;10.1109/visual.1997.663848,"metrics, steering, rendering, correlation measure",33.0,14.0,20.0,103.0,,,comparing images datasets;visually highlight;simulation parameters;operate spatial domain;facilitate,0.6372;0.2931;0.1824;0.1797;0.0753,"[np.int64(-1), -1, -1, -1, -1]",56;-1;-1;-1;-1,56,56
VAST,2017,CRICTO: Supporting Sensemaking through Crowdsourced Information Schematization,10.1109/vast.2017.8585484,http://dx.doi.org/10.1109/VAST.2017.8585484,139.0,150.0,C,"We present CRICTO, a new crowdsourcing visual analytics environment for making sense of and analyzing text data, whereby multiple crowdworkers are able to parallelize the simple information schematization tasks of relating and connecting entities across documents. The diverse links from these schematization tasks are then automatically combined and the system visualizes them based on the semantic types of the linkages. CRICTO also includes several tools that allow analysts to interactively explore and refine crowdworkers' results to better support their own sensemaking processes. We evaluated CRICTO's techniques and analysis workflow with deployments of CRICTO using Amazon Mechanical Turk and a user study that assess the effect of crowdsourced schematization in sensemaking tasks. The results of our evaluation show that CRICTO's crowdsourcing approaches and workflow help analysts explore diverse aspects of datasets, and uncover more accurate hidden stories embedded in the text datasets.",Haeyong Chung;Sai Prashanth Dasari;Santhosh Nandhakumar;Christopher Andrews 0001,Haeyong Chung;Sai Prashanth Dasari;Santhosh Nandhakumar;Christopher Andrews,University of Alabama in Huntsville;University of Alabama in Huntsville;University of Alabama in Huntsville;Middlebury College,10.1109/vast.2007.4389006;10.1109/tvcg.2013.164;10.1109/tvcg.2007.70577;10.1109/vast.2009.5333878;10.1109/vast.2008.4677362;10.1109/tvcg.2014.2346573;10.1109/vast.2006.261439;10.1109/vast.2010.5652932;10.1109/vast.2007.4389011,"Visual text analytics,sensemaking,crowdsourcing",8.0,5.0,51.0,258.0,,,crowdsourced schematization sensemaking;analytics environment;stories embedded text;combined;cricto techniques,0.6727;0.2778;0.2542;0.1075;0.0919,"[np.int64(-1), -1, -1, -1, -1]",86;-1;-1;-1;-1,86,86
Vis,2023,Visualizing Historical Book Trade Data: An Iterative Design Study with Close Collaboration with Domain Experts,10.1109/tvcg.2023.3326923,http://dx.doi.org/10.1109/TVCG.2023.3326923,540.0,550.0,J,"The circulation of historical books has always been an area of interest for historians. However, the data used to represent the journey of a book across different places and times can be difficult for domain experts to digest due to buried geographical and chronological features within text-based presentations. This situation provides an opportunity for collaboration between visualization researchers and historians. This paper describes a design study where a variant of the Nine-Stage Framework [46] was employed to develop a Visual Analytics (VA) tool called DanteExploreVis. This tool was designed to aid domain experts in exploring, explaining, and presenting book trade data from multiple perspectives. We discuss the design choices made and how each panel in the interface meets the domain requirements. We also present the results of a qualitative evaluation conducted with domain experts. The main contributions of this paper include: 1) the development of a VA tool to support domain experts in exploring, explaining, and presenting book trade data; 2) a comprehensive documentation of the iterative design, development, and evaluation process following the variant Nine-Stage Framework; 3) a summary of the insights gained and lessons learned from this design study in the context of the humanities field; and 4) reflections on how our approach could be applied in a more generalizable way.",Yiwen Xing;Cristina Dondi;Rita Borgo;Alfie Abdul-Rahman,Yiwen Xing;Cristina Dondi;Rita Borgo;Alfie Abdul-Rahman,"King's College London, United Kingdom;University of Oxford, United Kingdom;King's College London, United Kingdom;King's College London, United Kingdom",0.1109/tvcg.2014.2346431;10.1109/tvcg.2013.124;10.1109/tvcg.2021.3114797;10.1109/tvcg.2015.2467771;10.1109/tvcg.2014.2346331;10.1109/tvcg.2009.111;10.1109/tvcg.2012.213;10.1109/tvcg.2022.3209483;10.1109/tvcg.2018.2865076,"Design study,application motivated visualization,geospatial data",,0.0,59.0,429.0,,,visualization researchers historians;framework summary insights;journey book different;tool support domain;trade,0.6661;0.3251;0.2991;0.1483;0.0136,"[np.int64(-1), -1, -1, -1, -1]",209;-1;-1;-1;-1,209,209
SciVis,2019,Multi-Scale Topological Analysis of Asymmetric Tensor Fields on Surfaces,10.1109/tvcg.2019.2934314,http://dx.doi.org/10.1109/TVCG.2019.2934314,270.0,279.0,J,"Asymmetric tensor fields have found applications in many science and engineering domains, such as fluid dynamics. Recent advances in the visualization and analysis of 2D asymmetric tensor fields focus on pointwise analysis of the tensor field and effective visualization metaphors such as colors, glyphs, and hyperstreamlines. In this paper, we provide a novel multi-scale topological analysis framework for asymmetric tensor fields on surfaces. Our multi-scale framework is based on the notions of eigenvalue and eigenvector graphs. At the core of our framework are the identification of atomic operations that modify the graphs and the scale definition that guides the order in which the graphs are simplified to enable clarity and focus for the visualization of topological analysis on data of different sizes. We also provide efficient algorithms to realize these operations. Furthermore, we provide physical interpretation of these graphs. To demonstrate the utility of our system, we apply our multi-scale analysis to data in computational fluid dynamics.",Fariba Khan;Lawrence Roy;Eugene Zhang;Botong Qu;Shih-Hsuan Hung;Harry Yeh;Robert S. Laramee;Yue Zhang 0009,Fariba Khan;Lawrence Roy;Eugene Zhang;Botong Qu;Shih-Hsuan Hung;Harry Yeh;Robert S. Laramee;Yue Zhang,Oregon State University;Oregon State University;Oregon State University;Oregon State University;Oregon State University;Oregon State University;Swansea University;Oregon State University,10.1109/visual.1994.346326;10.1109/visual.1998.745312;10.1109/tvcg.2016.2598998;10.1109/tvcg.2009.126;10.1109/visual.2005.1532850;10.1109/visual.2004.59;10.1109/visual.2004.59;10.1109/tvcg.2011.170;10.1109/tvcg.2010.199;10.1109/visual.2001.964507;10.1109/visual.2000.885716;10.1109/visual.2002.1183784;10.1109/visual.2005.1532770;10.1109/visual.1994.346326,"Tensor field visualization,tensor field topology,2D asymmetric tensor fields,2D asymmetric tensor field topology,eigenvalue graphs,eigenvector graphs",8.0,5.0,37.0,538.0,,,tensor fields surfaces;scale topological analysis;interpretation graphs demonstrate;notions eigenvalue;atomic operations modify,0.5757;0.4581;0.2877;0.2525;0.0418,"[np.int64(-1), -1, -1, -1, -1]",17;-1;-1;-1;-1,17,17
Vis,1998,Development of a multi-source visualization prototype,10.1109/visual.1998.745331,http://dx.doi.org/10.1109/VISUAL.1998.745331,411.0,414.0,C,"This case study describes the design and development of VISOR (Visual Integration of Simulated and Observed Results), a tool which supports the visualization and analysis of a wide variety of data relevant to aerospace engineering design. Integrating data from such disparate sources is challenging; overcoming the obstacles results in a powerful tool. The process has also been valuable in exposing requirements for the libraries of reusable software tools for visualization and data analysis being developed at NASA Ames.",Leslie Keely;Samuel P. Uselton,L. Keely;S. Uselton,"MRJ Technology Solutions, NASA Ames Research Center, USA;MRJ Technology Solutions, NASA Ames Research Center, USA",10.1109/visual.1997.663911;10.1109/visual.1996.568115;10.1109/visual.1998.745332;10.1109/visual.1997.663911,,7.0,2.0,8.0,48.0,,,aerospace engineering design;tool supports visualization;simulated observed;visor;disparate sources challenging,0.5701;0.5344;0.2434;0.2080;0.1840,"[np.int64(-1), np.int64(-1), -1, -1, -1]",13;196;-1;-1;-1,13;196,13
Vis,2021,Rotate or Wrap? Interactive Visualisations of Cyclical Data on Cylindrical or Toroidal Topologies,10.1109/tvcg.2021.3114693,http://dx.doi.org/10.1109/TVCG.2021.3114693,727.0,736.0,J,"In this paper, we report on a study of visual representations for cyclical data and the effect of interactively <i>wrapping</i> a bar chart ‘around its boundaries’. Compared to linear bar chart, polar (or radial) visualisations have the advantage that cyclical data can be presented continuously without mentally bridging the visual ‘cut’ across the left-and-right boundaries. To investigate this hypothesis and to assess the effect the cut has on analysis performance, this paper presents results from a crowdsourced, controlled experiment with 72 participants comparing new continuous panning technique to linear bar charts (<i>interactive wrapping</i>). Our results show that bar charts with interactive wrapping lead to less errors compared to standard bar charts or polar charts. Inspired by these results, we generalise the concept of interactive wrapping to other visualisations for cyclical or relational data. We describe a design space based on the concept of one-dimensional wrapping and two-dimensional wrapping, linked to two common 3D topologies; cylinder and torus that can be used to metaphorically explain one- and two-dimensional wrapping. This design space suggests that interactive wrapping is widely applicable to many different data types.",Kun-Ting Chen;Tim Dwyer;Benjamin Bach;Kim Marriott,Kun-Ting Chen;Tim Dwyer;Benjamin Bach;Kim Marriott,"Monash University, Australia;Monash University, Australia;University of Edinburgh, United Kingdom;Monash University, Australia",10.1109/tvcg.2015.2467851;10.1109/tvcg.2018.2865234;10.1109/tvcg.2013.124;10.1109/tvcg.2014.2346320;10.1109/tvcg.2012.265;10.1109/tvcg.2019.2934784;10.1109/tvcg.2011.195;10.1109/tvcg.2015.2467851,"Cyclic temporal data,cylindrical topologies,toroidal topologies,interaction techniques,bar charts,polar charts,crowdsourced experiment",3.0,3.0,46.0,575.0,,,visualisations cyclical;bar chart boundaries;data;wrapping lead;compared standard,0.7131;0.4545;0.2595;0.1391;0.1243,"[np.int64(-1), -1, -1, -1, -1]",-1;-1;-1;-1;-1,,-1
VAST,2013,Vis4Heritage: Visual Analytics Approach on Grotto Wall Painting Degradations,10.1109/tvcg.2013.219,http://dx.doi.org/10.1109/TVCG.2013.219,1982.0,1991.0,J,"For preserving the grotto wall paintings and protecting these historic cultural icons from the damage and deterioration in nature environment, a visual analytics framework and a set of tools are proposed for the discovery of degradation patterns. In comparison with the traditional analysis methods that used restricted scales, our method provides users with multi-scale analytic support to study the problems on site, cave, wall and particular degradation area scales, through the application of multidimensional visualization techniques. Several case studies have been carried out using real-world wall painting data collected from a renowned World Heritage site, to verify the usability and effectiveness of the proposed method. User studies and expert reviews were also conducted through by domain experts ranging from scientists such as microenvironment researchers, archivists, geologists, chemists, to practitioners such as conservators, restorers and curators.",Jiawan Zhang;Kai Kang;Dajian Liu;Ye Yuan;E. Yanli,Jiawan Zhang;Kai Kang;Dajian Liu;Ye Yuan;Yanli E.,"School of Computer Software and Information Technology Research Center for Cultural Heritage Conservation and Promotion, Tianjin University, China;School of Computer Software, Tianjin University, China;School of Computer Software, Tianjin University, China;School of Computer Software, Tianjin University, China;School of Computer Software, Tianjin University, Tianjin, Tianjin, CN",10.1109/tvcg.2011.239;10.1109/infvis.2004.1;10.1109/tvcg.2008.173;10.1109/infvis.2005.1532138;10.1109/tvcg.2006.147;10.1109/tvcg.2012.244;10.1109/vast.2007.4389013;10.1109/tvcg.2008.153;10.1109/infvis.2000.885098;10.1109/vast.2010.5651617;10.1109/tvcg.2011.239,"Cultural heritage, wall paintings, degradation, visual analytics",15.0,16.0,46.0,820.0,,,environment visual analytics;researchers archivists geologists;deterioration nature;wall paintings protecting;restricted scales method,0.5279;0.4085;0.3877;0.3561;0.2646,"[np.int64(-1), -1, -1, -1, -1]",161;-1;-1;-1;-1,161,161
Vis,2004,Visualizing cortical waves and timing from data,10.1109/visual.2004.121,http://dx.doi.org/10.1109/VISUAL.2004.121,401.0,408.0,C,"Waves are a fundamental mechanism for conveying information in many physical problems. Direct visualization techniques are often used to display wave fronts. However, the information derived from such visualizations may not be as central to an investigation as an understanding of how the location, structure and time course of the wave change as key experimental parameters are varied. In experimental data, these questions are confounded by noise and incomplete data. Recognition of waves in networks of neurons is additionally complicated by the presence of long-range physical connections and recurrent excitation. This work applies visual techniques to analyze the structural details of waves in response data from the turtle visual cortex. We emphasize low-cost visualizations that allow comparisons across neural data sets and variables to reconstruct the choreography for a complex response.",Kay A. Robbins;Mark A. Robinson;David M. Senseman,K.A. Robbins;M. Robinson;D.M. Senseman,"Cajal Neuroscience Research Center, University of Texas, San Antonio, USA;University of Texas, San Antonio, USA;Cajal Neuroscience Research Center, University of Texas, San Antonio, USA",10.1109/visual.2001.964493;10.1109/visual.1990.146402;10.1109/visual.2000.885686;10.1109/visual.2001.964493,"waves, neural networks, PCA, KL decomposition, wave subspaces, flow visualization",5.0,1.0,26.0,82.0,,,waves networks neurons;low cost visualizations;response data turtle;reconstruct choreography;central investigation understanding,0.6304;0.3667;0.3293;0.2141;0.0791,"[np.int64(-1), -1, -1, -1, -1]",213;-1;-1;-1;-1,213,213
Vis,1999,Visualizing the evolution of a subject domain: a case study,10.1109/visual.1999.809927,http://dx.doi.org/10.1109/VISUAL.1999.809927,449.0,561.0,C,"We explore the potential of information visualization techniques in enhancing existing methodologies for domain analysis and modeling. In this case study, we particularly focus on visualizing the evolution of the hypertext field based on author co-citation patterns, including the use of a sliding-window scheme to generate a series of annual snapshots of the domain structure, and a factor-referenced color-coding scheme to highlight predominant specialties in the field.",Chaomei Chen;Les Carr,C. Chen;L. Carr,"Brunei University, UK;Southampton University, UK",10.1109/visual.1993.398870;10.1109/visual.1993.398870,,67.0,10.0,13.0,110.0,,,visualizing evolution hypertext;predominant specialties field;color coding scheme;enhancing existing methodologies;generate series annual,0.5972;0.2668;0.2326;0.1940;0.0204,"[np.int64(-1), -1, -1, -1, -1]",296;-1;-1;-1;-1,296,296
VAST,2015,Integrating predictive analytics into a spatiotemporal epidemic simulation,10.1109/vast.2015.7347626,http://dx.doi.org/10.1109/VAST.2015.7347626,17.0,24.0,C,"The Epidemic Simulation System (EpiSimS) is a scalable, complex modeling tool for analyzing disease within the United States. Due to its high input dimensionality, time requirements, and resource constraints, simulating over the entire parameter space is unfeasible. One solution is to take a granular sampling of the input space and use simpler predictive models (emulators) in between. The quality of the implemented emulator depends on many factors: robustness, sophistication, configuration, and suitability to the input data. Visual analytics can be leveraged to provide guidance and understanding of these things to the user. In this paper, we have implemented a novel interface and workflow for emulator building and use. We introduce a workflow to build emulators, make predictions, and then analyze the results. Our prediction process first predicts temporal time series, and uses these to derive predicted spatial densities. Integrated into the EpiSimS framework, we target users who are non-experts at statistical modeling. This approach allows for a high level of analysis into the state of the built emulators and their resultant predictions. We present our workflow, models, the associated system, and evaluate the overall utility with feedback from EpiSimS scientists.",Chris Bryan;Xue Wu;Susan M. Mniszewski;Kwan-Liu Ma,Chris Bryan;Xue Wu;Susan Mniszewski;Kwan-Liu Ma,VIDi;VIDi;Los Alamos National Lab;VIDi,10.1109/vast.2011.6102457;10.1109/infvis.1998.729563;10.1109/tvcg.2014.2346926;10.1109/tvcg.2013.125;10.1109/tvcg.2010.181;10.1109/tvcg.2014.2346321;10.1109/tvcg.2011.248;10.1109/tvcg.2012.190;10.1109/vast.2011.6102457,"Predictive Modeling, Visual Analytics, Epidemic Visualization, Spatial-Temporal Systems",24.0,14.0,36.0,658.0,,,epidemic simulation episims;derive predicted spatial;input data visual;present workflow models;build,0.7212;0.3014;0.3000;0.2237;0.0817,"[np.int64(-1), -1, -1, -1, -1]",1;-1;-1;-1;-1,1,1
Vis,1994,"A distributed, parallel, interactive volume rendering package",10.1109/visual.1994.346341,http://dx.doi.org/10.1109/VISUAL.1994.346341,21.0,,C,"This paper presents a parallel ray-casting volume rendering algorithm and its implementation on the massively parallel IBM SP-1 computer using the Chameleon message passing library. Though this algorithm takes advantage of many of the unique features of the SP-1 (e.g. high-speed switch, large memory per node, high-speed disk array, HIPPI display, et al.), the use of Chameleon allows the code to be executed on any collection of workstations. The algorithm is image-ordered and distributes the data and the computational load to individual processors. After the volume data is distributed, all processors then perform local ray tracing of their respective subvolumes concurrently. No interprocess communication takes place during the ray tracing process. After a subimage is generated by each processor, the final image is obtained by composing subimages between all the processors. The program itself is implemented as an interactive process through a GUI residing on a graphics workstation which is coupled to the parallel rendering algorithm via sockets. The paper highlights the Chameleon implementation, the GUI, some optimization improvements, static load balancing, and direct parallel display to a HIPPI framebuffer.&lt;&lt;ETX&gt;&gt;",John S. Rowlan;G. Edward Lent;Nihar Gokhale;Shannon Bradshaw,J.S. Rowlan;G.E. Lent;N. Gokhale;S. Bradshaw,"Mathematics Computer Science Division, Argonne National Laboratory, Argonne, IL, USA;Mathematics Computer Science Division, Argonne National Laboratory, Argonne, IL, USA;Mathematics Computer Science Division, Argonne National Laboratory, Argonne, IL, USA;Mathematics Computer Science Division, Argonne National Laboratory, Argonne, IL, USA",,,58.0,9.0,11.0,65.0,,,parallel rendering algorithm;volume data;ibm sp computer;takes place ray;allows code executed,0.6638;0.3873;0.3332;0.2472;0.0031,"[np.int64(-1), -1, -1, -1, -1]",59;-1;-1;-1;-1,59,59
Vis,2022,BeauVis: A Validated Scale for Measuring the Aesthetic Pleasure of Visual Representations,10.1109/tvcg.2022.3209390,http://dx.doi.org/10.1109/TVCG.2022.3209390,363.0,373.0,J,"We developed and validated a rating scale to assess the aesthetic pleasure (or beauty) of a visual data representation: the BeauVis scale. With our work we offer researchers and practitioners a simple instrument to compare the visual appearance of different visualizations, unrelated to data or context of use. Our rating scale can, for example, be used to accompany results from controlled experiments or be used as informative data points during in-depth qualitative studies. Given the lack of an aesthetic pleasure scale dedicated to visualizations, researchers have mostly chosen their own terms to study or compare the aesthetic pleasure of visualizations. Yet, many terms are possible and currently no clear guidance on their effectiveness regarding the judgment of aesthetic pleasure exists. To solve this problem, we engaged in a multi-step research process to develop the first validated rating scale specifically for judging the aesthetic pleasure of a visualization (osf.io/fxs76). Our final BeauVis scale consists of five items, “enjoyable,” “likable,” “pleasing,” “nice,” and “appealing.” Beyond this scale itself, we contribute (a) a systematic review of the terms used in past research to capture aesthetics, (b) an investigation with visualization experts who suggested terms to use for judging the aesthetic pleasure of a visualization, and (c) a confirmatory survey in which we used our terms to study the aesthetic pleasure of a set of 3 visualizations.",Tingying He;Petra Isenberg;Raimund Dachselt;Tobias Isenberg 0001,Tingying He;Petra Isenberg;Raimund Dachselt;Tobias Isenberg,"Université Paris-Saclay, CNRS, Inria, LISN, France;Université Paris-Saclay, CNRS, Inria, LISN, France;Technische Universität Dresden, Germany;Université Paris-Saclay, CNRS, Inria, LISN, France",10.1109/infvis.2005.1532128;10.1109/tvcg.2006.187;10.1109/tvcg.2008.166;10.1109/tvcg.2020.3030411;10.1109/tvcg.2009.122;10.1109/infvis.1997.636793;10.1109/tvcg.2020.3030456;10.1109/tvcg.2010.134;10.1109/tvcg.2013.196;10.1109/tvcg.2010.199;10.1109/tvcg.2014.2352953;10.1109/tvcg.2020.3030400;10.1109/tvcg.2015.2467411;10.1109/tvcg.2012.189;10.1109/infvis.2005.1532128,"Aesthetics,aesthetic pleasure,validated scale,scale development,visual representations",,7.0,79.0,1083.0,,X,aesthetic pleasure visualizations;likable;data context use;contribute systematic review;set,0.8305;0.1944;0.1358;0.0676;0.0205,"[np.int64(-1), -1, -1, -1, -1]",189;-1;-1;-1;-1,189,189
VAST,2015,TargetVue: Visual Analysis of Anomalous User Behaviors in Online Communication Systems,10.1109/tvcg.2015.2467196,http://dx.doi.org/10.1109/TVCG.2015.2467196,280.0,289.0,J,"Users with anomalous behaviors in online communication systems (e.g. email and social medial platforms) are potential threats to society. Automated anomaly detection based on advanced machine learning techniques has been developed to combat this issue; challenges remain, though, due to the difficulty of obtaining proper ground truth for model training and evaluation. Therefore, substantial human judgment on the automated analysis results is often required to better adjust the performance of anomaly detection. Unfortunately, techniques that allow users to understand the analysis results more efficiently, to make a confident judgment about anomalies, and to explore data in their context, are still lacking. In this paper, we propose a novel visual analysis system, TargetVue, which detects anomalous users via an unsupervised learning model and visualizes the behaviors of suspicious users in behavior-rich context through novel visualization designs and multiple coordinated contextual views. Particularly, TargetVue incorporates three new ego-centric glyphs to visually summarize a user's behaviors which effectively present the user's communication activities, features, and social interactions. An efficient layout method is proposed to place these glyphs on a triangle grid, which captures similarities among users and facilitates comparisons of behaviors of different users. We demonstrate the power of TargetVue through its application in a social bot detection challenge using Twitter data, a case study based on email records, and an interview with expert users. Our evaluation shows that TargetVue is beneficial to the detection of users with anomalous communication behaviors.",Nan Cao 0001;Conglei Shi;W. Sabrina Lin;Jie Lu 0002;Yu-Ru Lin;Ching-Yung Lin,Nan Cao;Conglei Shi;Sabrina Lin;Jie Lu;Yu-Ru Lin;Ching-Yung Lin,IBM T. J. Watson Research Center;IBM T. J. Watson Research Center;IBM T. J. Watson Research Center;IBM T. J. Watson Research Center;University of Pissburg;IBM T. J. Watson Research Center,10.1109/tvcg.2012.291;10.1109/tvcg.2006.170;10.1109/visual.2002.1183816;10.1109/tvcg.2014.2346922;10.1109/tvcg.2012.291,"Anomaly Detection, Social Media, Visual Analysis",143.0,108.0,45.0,2928.0,,,anomalous users unsupervised;context novel visualization;place glyphs triangle;evaluation shows targetvue;allow,0.6253;0.3542;0.1719;0.1049;0.0575,"[np.int64(-1), -1, -1, -1, -1]",122;-1;-1;-1;-1,122,122
Vis,2008,VisComplete: Automating Suggestions for Visualization Pipelines,10.1109/tvcg.2008.174,http://dx.doi.org/10.1109/TVCG.2008.174,1691.0,1698.0,J,"Building visualization and analysis pipelines is a large hurdle in the adoption of visualization and workflow systems by domain scientists. In this paper, we propose techniques to help users construct pipelines by consensus-automatically suggesting completions based on a database of previously created pipelines. In particular, we compute correspondences between existing pipeline subgraphs from the database, and use these to predict sets of likely pipeline additions to a given partial pipeline. By presenting these predictions in a carefully designed interface, users can create visualizations and other data products more efficiently because they can augment their normal work patterns with the suggested completions. We present an implementation of our technique in a publicly-available, open-source scientific workflow system and demonstrate efficiency gains in real-world situations.",David Koop;Carlos Eduardo Scheidegger;Steven P. Callahan;Juliana Freire;Cláudio T. Silva,D. Koop;C.E. Scheidegger;S.P. Callahan;J. Freire;C.T. Silva,"School of Computing, University of Utah, USA;Scientific Computing and Imaging (SCI) Institute, University of Utah, USA;Scientific Computing and Imaging (SCI) Institute, University of Utah, USA;School of Computing, University of Utah, USA;Scientific Computing and Imaging (SCI) Institute, University of Utah, USA",10.1109/tvcg.2007.70584;10.1109/tvcg.2007.70577;10.1109/visual.2005.1532834;10.1109/visual.2005.1532833;10.1109/visual.2005.1532788;10.1109/visual.2005.1532795;10.1109/tvcg.2007.70584,"Scientific Workflows, Scientific Visualization, Auto Completion",132.0,65.0,39.0,823.0,,,visualization workflow systems;automatically suggesting completions;sets likely pipeline;scientists paper propose;given partial,0.6855;0.4821;0.3692;0.2669;0.0022,"[np.int64(-1), -1, -1, -1, -1]",191;-1;-1;-1;-1,191,191
VAST,2020,A Visual Analytics Framework for Explaining and Diagnosing Transfer Learning Processes,10.1109/tvcg.2020.3028888,http://dx.doi.org/10.1109/TVCG.2020.3028888,1385.0,1395.0,J,"Many statistical learning models hold an assumption that the training data and the future unlabeled data are drawn from the same distribution. However, this assumption is difficult to fulfill in real-world scenarios and creates barriers in reusing existing labels from similar application domains. Transfer Learning is intended to relax this assumption by modeling relationships between domains, and is often applied in deep learning applications to reduce the demand for labeled data and training time. Despite recent advances in exploring deep learning models with visual analytics tools, little work has explored the issue of explaining and diagnosing the knowledge transfer process between deep learning models. In this paper, we present a visual analytics framework for the multi-level exploration of the transfer learning processes when training deep neural networks. Our framework establishes a multi-aspect design to explain how the learned knowledge from the existing model is transferred into the new learning task when training deep neural networks. Based on a comprehensive requirement and task analysis, we employ descriptive visualization with performance measures and detailed inspections of model behaviors from the statistical, instance, feature, and model structure levels. We demonstrate our framework through two case studies on image classification by fine-tuning AlexNets to illustrate how analysts can utilize our framework.",Yuxin Ma;Arlen Fan;Jingrui He;Arun Reddy Nelakurthi;Ross Maciejewski,Yuxin Ma;Arlen Fan;Jingrui He;Arun Reddy Nelakurthi;Ross Maciejewski,Arizona State University;Arizona State University;University of Illinois at Urbana-Champaign;Samsung Research America;Arizona State University,10.1109/tvcg.2019.2934262;10.1109/tvcg.2015.2467618;10.1109/tvcg.2017.2744683;10.1109/tvcg.2013.124;10.1109/vast47406.2019.8986948;10.1109/tvcg.2011.188;10.1109/tvcg.2019.2934261;10.1109/tvcg.2014.2346594;10.1109/tvcg.2017.2744199;10.1109/tvcg.2019.2934659;10.1109/tvcg.2017.2744718;10.1109/tvcg.2014.2346482;10.1109/tvcg.2018.2865027;10.1109/vast.2018.8802509;10.1109/tvcg.2017.2744938;10.1109/tvcg.2016.2598831;10.1109/tvcg.2017.2744378;10.1109/tvcg.2019.2934631;10.1109/vast.2017.8585721;10.1109/tvcg.2018.2864812;10.1109/tvcg.2014.2346578;10.1109/tvcg.2017.2744358;10.1109/tvcg.2012.207;10.1109/tvcg.2016.2598838;10.1109/tvcg.2016.2598828;10.1109/tvcg.2019.2934629;10.1109/tvcg.2018.2865044;10.1109/visual.2005.1532820;10.1109/tvcg.2018.2864504;10.1109/tvcg.2019.2934619;10.1109/tvcg.2017.2744878;10.1109/tvcg.2018.2864499;10.1109/tvcg.2016.2598541;10.1109/tvcg.2018.2864475;10.1109/tvcg.2017.2744158;10.1109/tvcg.2018.2864500;10.1109/tvcg.2019.2934262,"Transfer learning,deep learning,visual analytics",15.0,23.0,84.0,1065.0,,,transfer learning;visual analytics tools;explaining diagnosing;structure levels;time despite,0.5664;0.3132;0.2694;0.0745;0.0418,"[np.int64(-1), -1, -1, -1, -1]",50;-1;-1;-1;-1,50,50
Vis,2024,Uncertainty Visualization of Critical Points of 2D Scalar Fields for Parametric and Nonparametric Probabilistic Models,10.1109/tvcg.2024.3456393,http://dx.doi.org/10.1109/TVCG.2024.3456393,108.0,118.0,J,"This paper presents a novel end-to-end framework for closed-form computation and visualization of critical point uncertainty in 2D uncertain scalar fields. Critical points are fundamental topological descriptors used in the visualization and analysis of scalar fields. The uncertainty inherent in data (e.g., observational and experimental data, approximations in simulations, and compression), however, creates uncertainty regarding critical point positions. Uncertainty in critical point positions, therefore, cannot be ignored, given their impact on downstream data analysis tasks. In this work, we study uncertainty in critical points as a function of uncertainty in data modeled with probability distributions. Although Monte Carlo (MC) sampling techniques have been used in prior studies to quantify critical point uncertainty, they are often expensive and are infrequently used in production-quality visualization software. We, therefore, propose a new end-to-end framework to address these challenges that comprises a threefold contribution. First, we derive the critical point uncertainty in closed form, which is more accurate and efficient than the conventional MC sampling methods. Specifically, we provide the closed-form and semianalytical (a mix of closed-form and MC methods) solutions for parametric (e.g., uniform, Epanechnikov) and nonparametric models (e.g., histograms) with finite support. Second, we accelerate critical point probability computations using a parallel implementation with the VTK-m library, which is platform portable. Finally, we demonstrate the integration of our implementation with the ParaView software system to demonstrate near-real-time results for real datasets.",Tushar M. Athawale;Zhe Wang;David Pugmire;Kenneth Moreland;Qian Gong;Scott Klasky;Chris R. Johnson 0001;Paul Rosen 0001,Tushar M. Athawale;Zhe Wang;David Pugmire;Kenneth Moreland;Qian Gong;Scott Klasky;Chris R. Johnson;Paul Rosen,"Oak Ridge National Laboratory, USA;Oak Ridge National Laboratory, USA;Oak Ridge National Laboratory, USA;Oak Ridge National Laboratory, USA;Oak Ridge National Laboratory, USA;Oak Ridge National Laboratory, USA;University of Utah, USA;University of Utah, USA",10.1109/tvcg.2013.208;10.1109/tvcg.2022.3209424;10.1109/tvcg.2020.3030394;10.1109/tvcg.2015.2467958;10.1109/tvcg.2023.3326592;10.1109/tvcg.2015.2467204;10.1109/visual.2002.1183769;10.1109/visual.2005.1532839;10.1109/tvcg.2017.2744099;10.1109/tvcg.2007.70518;10.1109/tvcg.2012.249;10.1109/tvcg.2017.2743938;10.1109/tvcg.2019.2934256;10.1109/tvcg.2019.2934242,"Topology,uncertainty,,,critical points,probabilistic analysis",,0.0,70.0,160.0,,,uncertainty critical points;visualization software propose;scalar fields;simulations compression creates;uniform,0.5196;0.3073;0.2860;0.2676;0.0331,"[np.int64(-1), -1, -1, -1, -1]",14;-1;-1;-1;-1,14,14
VAST,2010,A continuous analysis process between desktop and collaborative visual analytics environments,10.1109/vast.2010.5652958,http://dx.doi.org/10.1109/VAST.2010.5652958,231.0,232.0,M,"Since its inception, the field of visual analytics has undergone tremendous growth in understanding how to create interactive visual tools to solve analytical problems. However, with few exceptions, most of these tools have been designed for single users in desktop environments. While often effective on their own, most single-user systems do not reflect the collaborative nature of solving real-world analytical tasks. Many intelligence analysts, for example, have been observed to switch repeatedly between working alone and collaborating with members of a small team. In this paper, we propose that a complete visual analytical system designed for solving real-world tasks ought to have two integrated components: a single-user desktop system and a mirroring system suitable for a collaborative environment.",Dong Hyun Jeong;Evan A. Suma;Thomas Butkiewicz;William Ribarsky;Remco Chang,Dong Hyun Jeong;Evan Suma;Thomas Butkiewicz;William Ribarsky;Remco Chang,"University of District of Columbia, USA and University of North Carolina, Charlotte, USA;University of North Carolina, Charlotte, USA and University of Southern California, USA;University of North Carolina, Charlotte, USA;University of North Carolina, Charlotte, USA;University of North Carolina, Charlotte, USA and Tufts University, USA",,,1.0,2.0,2.0,150.0,,,visual analytics;single user desktop;repeatedly working collaborating;solving real;undergone,0.7263;0.3538;0.3308;0.0494;-0.0088,"[np.int64(-1), -1, -1, -1, -1]",201;-1;-1;-1;-1,201,201
SciVis,2020,Visual Analysis of Large Multivariate Scattered Data using Clustering and Probabilistic Summaries,10.1109/tvcg.2020.3030379,http://dx.doi.org/10.1109/TVCG.2020.3030379,1580.0,1590.0,J,"Rapidly growing data sizes of scientific simulations pose significant challenges for interactive visualization and analysis techniques. In this work, we propose a compact probabilistic representation to interactively visualize large scattered datasets. In contrast to previous approaches that represent blocks of volumetric data using probability distributions, we model clusters of arbitrarily structured multivariate data. In detail, we discuss how to efficiently represent and store a high-dimensional distribution for each cluster. We observe that it suffices to consider low-dimensional marginal distributions for two or three data dimensions at a time to employ common visual analysis techniques. Based on this observation, we represent high-dimensional distributions by combinations of low-dimensional Gaussian mixture models. We discuss the application of common interactive visual analysis techniques to this representation. In particular, we investigate several frequency-based views, such as density plots in 1D and 2D, density-based parallel coordinates, and a time histogram. We visualize the uncertainty introduced by the representation, discuss a level-of-detail mechanism, and explicitly visualize outliers. Furthermore, we propose a spatial visualization by splatting anisotropic 3D Gaussians for which we derive a closed-form solution. Lastly, we describe the application of brushing and linking to this clustered representation. Our evaluation on several large, real-world datasets demonstrates the scaling of our approach.",Tobias Rapp;Christoph Peters 0002;Carsten Dachsbacher,Tobias Rapp;Christoph Peters;Carsten Dachsbacher,Karlsruhe Institute of Technology;Karlsruhe Institute of Technology;Karlsruhe Institute of Technology,10.1109/infvis.2004.68;10.1109/tvcg.2008.119;10.1109/tvcg.2008.131;10.1109/visual.2003.1250389;10.1109/tvcg.2016.2598604;10.1109/tvcg.2010.176;10.1109/tvcg.2017.2744099;10.1109/tvcg.2018.2864801;10.1109/tvcg.2009.131;10.1109/infvis.2005.1532138;10.1109/tvcg.2006.170;10.1109/tvcg.2019.2934335;10.1109/tvcg.2014.2346324;10.1109/visual.2001.964490;10.1109/infvis.2004.68,"interactive visual analysis,probabilistic data summaries,multivariate data,scattered data,Gaussian mixture models,Gaussian rendering",2.0,7.0,49.0,642.0,,,spatial visualization splatting;store high dimensional;time histogram;gaussians derive closed;consider low,0.6011;0.3174;0.2361;0.1865;0.0355,"[np.int64(-1), -1, -1, -1, -1]",252;-1;-1;-1;-1,252,252
VAST,2013,Visual Traffic Jam Analysis Based on Trajectory Data,10.1109/tvcg.2013.228,http://dx.doi.org/10.1109/TVCG.2013.228,2159.0,2168.0,J,"In this work, we present an interactive system for visual analysis of urban traffic congestion based on GPS trajectories. For these trajectories we develop strategies to extract and derive traffic jam information. After cleaning the trajectories, they are matched to a road network. Subsequently, traffic speed on each road segment is computed and traffic jam events are automatically detected. Spatially and temporally related events are concatenated in, so-called, traffic jam propagation graphs. These graphs form a high-level description of a traffic jam and its propagation in time and space. Our system provides multiple views for visually exploring and analyzing the traffic condition of a large city as a whole, on the level of propagation graphs, and on road segment level. Case studies with 24 days of taxi GPS trajectories collected in Beijing demonstrate the effectiveness of our system.",Zuchao Wang;Min Lu 0002;Xiaoru Yuan;Junping Zhang;Huub van de Wetering,Zuchao Wang;Min Lu;Xiaoru Yuan;Junping Zhang;Huub van de Wetering,"Key Laboratory of Machine Perception (Ministry of Education), Peking University, China;Key Laboratory of Machine Perception (Ministry of Education), Peking University, China;Shanghai Key Laboratory of Intelligent Information Processing, and School of Computer Science, Fudan University, China and Key Laboratory of Machine Perception (Ministry of Education), Peking University;Shanghai Key Laboratory of Intelligent Information Processing, Fudan University, China;Department of Mathematics and Computer Science, Technische Universiteit Eindhoven, Eindhoven, Noord-Brabant, NL",10.1109/visual.1997.663866;10.1109/vast.2011.6102454;10.1109/tvcg.2009.145;10.1109/vast.2012.6400556;10.1109/infvis.2004.27;10.1109/vast.2008.4677356;10.1109/tvcg.2011.202;10.1109/vast.2012.6400553;10.1109/tvcg.2012.265;10.1109/tvcg.2011.181;10.1109/vast.2009.5332593;10.1109/tvcg.2008.125;10.1109/vast.2011.6102455;10.1109/vast.2010.5653580,"Traffic visualization, traffic jam propagation",401.0,263.0,54.0,7804.0,,,traffic jam information;visually exploring;cleaning trajectories matched;propagation time;extract derive,0.6824;0.2988;0.2927;0.1414;0.0307,"[np.int64(-1), -1, -1, -1, -1]",69;-1;-1;-1;-1,69,69
InfoVis,2020,Cartographic Relief Shading with Neural Networks,10.1109/tvcg.2020.3030456,http://dx.doi.org/10.1109/TVCG.2020.3030456,1225.0,1235.0,J,"Shaded relief is an effective method for visualising terrain on topographic maps, especially when the direction of illumination is adapted locally to emphasise individual terrain features. However, digital shading algorithms are unable to fully match the expressiveness of hand-crafted masterpieces, which are created through a laborious process by highly specialised cartographers. We replicate hand-drawn relief shading using U-Net neural networks. The deep neural networks are trained with manual shaded relief images of the Swiss topographic map series and terrain models of the same area. The networks generate shaded relief that closely resemble hand-drawn shaded relief art. The networks learn essential design principles from manual relief shading such as removing unnecessary terrain details, locally adjusting the illumination direction to accentuate individual terrain features, and varying brightness to emphasise larger landforms. Neural network shadings are generated from digital elevation models in a few seconds, and a study with 18 relief shading experts found that they are of high quality.",Bernhard Jenny;Magnus Heitzler;Dilpreet Singh;Marianna Farmakis-Serebryakova;Jeffery Chieh Liu;Lorenz Hurni,Bernhard Jenny;Magnus Heitzler;Dilpreet Singh;Marianna Farmakis-Serebryakova;Jeffery Chieh Liu;Lorenz Hurni,"Monash University, Melbourne;Institute of Cartography and Geoinformation, ETH, Zurich;Monash University, Melbourne;Institute of Cartography and Geoinformation, ETH, Zurich;Monash University, Melbourne;Institute of Cartography and Geoinformation, ETH, Zurich",10.1109/tvcg.2006.172;10.1109/tvcg.2006.172,"Relief shading,shaded relief,hillshade,neural rendering,illustrative visualisation,image-to-image translation",26.0,31.0,82.0,1024.0,,,visualising terrain topographic;deep neural;masterpieces created;adjusting illumination;study 18 relief,0.5775;0.4422;0.2537;0.2193;0.1283,"[np.int64(-1), -1, -1, -1, -1]",77;-1;-1;-1;-1,77,77
Vis,1992,Approximation and rendering of volume data using wavelet transforms,10.1109/visual.1992.235230,http://dx.doi.org/10.1109/VISUAL.1992.235230,21.0,28.0,C,"A method is presented to obtain a unique shape description of an object by using wavelet transforms. Wavelet transform is a signal analysis technique which decomposes a signal using a family of functions having a local property in both time and frequency domains. A multiresolution expression of 3D volume data was first obtained by applying 3D orthogonal wavelet transforms, with the shape then being approximated with a relatively small number of 3D orthogonal functions using only the significant functions. In addition, the resolution of the approximation can be varied point by point using the local property of the wavelets. The method is applied to real volume data, i.e. facial range data and MR images of a human head, and typical results are shown.&lt;&lt;ETX&gt;&gt;",Shigeru Muraki,S. Muraki,"Image Understanding Section, ElectroTechnical Laboratory, Tsukuba, Japan",,,,31.0,17.0,99.0,,,wavelet transforms;3d volume;human head typical;using local property;applied,0.6785;0.3675;0.2745;0.0667;0.0580,"[np.int64(-1), -1, -1, -1, -1]",99;-1;-1;-1;-1,99,99
InfoVis,2008,Who Votes For What? A Visual Query Language for Opinion Data,10.1109/tvcg.2008.187,http://dx.doi.org/10.1109/TVCG.2008.187,1197.0,1204.0,J,"Surveys and opinion polls are extremely popular in the media, especially in the months preceding a general election. However, the available tools for analyzing poll results often require specialized training. Hence, data analysis remains out of reach for many casual computer users. Moreover, the visualizations used to communicate the results of surveys are typically limited to traditional statistical graphics like bar graphs and pie charts, both of which are fundamentally noninteractive. We present a simple interactive visualization that allows users to construct queries on large tabular data sets, and view the results in real time. The results of two separate user studies suggest that our interface lowers the learning curve for naive users, while still providing enough analytical power to discover interesting correlations in the data.",Geoffrey M. Draper;Richard F. Riesenfeld,Geoffrey Draper;Richard Riesenfeld,"School of Computing, University of Utah, USA; School of Computing, University of Utah, USA",10.1109/tvcg.2007.70584;10.1109/infvis.1996.559210;10.1109/infvis.2005.1532134;10.1109/infvis.2001.963279;10.1109/visual.1990.146402;10.1109/tvcg.2007.70617;10.1109/vast.2006.261438;10.1109/infvis.1998.729570;10.1109/infvis.2001.963287;10.1109/infvis.2000.885086;10.1109/tvcg.2007.70539;10.1109/vast.2007.4389013;10.1109/infvis.2000.885091;10.1109/tvcg.2007.70577;10.1109/tvcg.2006.147;10.1109/tvcg.2007.70584,"Visual query languages, radial visualization, data analysis, human-computer interaction",43.0,16.0,45.0,406.0,,,analyzing poll results;data sets view;casual computer users;graphics like bar;lowers learning curve,0.6404;0.4228;0.3299;0.3166;0.1016,"[np.int64(-1), -1, -1, -1, -1]",114;-1;-1;-1;-1,114,114
Vis,2005,OpenGL multipipe SDK: a toolkit for scalable parallel rendering,10.1109/visual.2005.1532786,http://dx.doi.org/10.1109/VISUAL.2005.1532786,119.0,126.0,C,"We describe OpenGL multipipe SDK (MPK), a toolkit for scalable parallel rendering based on OpenGL. MPK provides a uniform application programming interface (API) to manage scalable graphics applications across many different graphics subsystems. MPK-based applications run seamlessly from single-processor, single-pipe desktop systems to large multi-processor, multipipe scalable graphics systems. The application is oblivious of the system configuration, which can be specified through a configuration file at run time. To scale application performance, MPK uses a decomposition system that supports different modes for task partitioning and implements optimized CPU-based composition algorithms. MPK also provides a customizable image composition interface, which can be used to apply post-processing algorithms on raw pixel data obtained from executing sub-tasks on multiple graphics pipes in parallel. This can be used to implement parallel versions of any CPU-based algorithm, not necessarily used for rendering. In this paper, we motivate the need for a scalable graphics API and discuss the architecture of MPK. We present MPK's graphics configuration interface, introduce the notion of compound-based decomposition schemes and describe our implementation. We present some results from our work on a couple of target system architectures and conclude with future directions of research in this area.",Praveen Bhaniramka;Philippe C. D. Robert;Stefan Eilemann,Praveen Bhaniramka;P.C.D. Robert;S. Eilemann,"Silicon Graphics, Inc.;University of Bern, Switzerland;University of Zurich, Switzerland",10.1109/visual.1999.809890;10.1109/visual.1999.809890,"Scalable Rendering, Parallel Rendering, Immersive Environments, Scalable Graphics Hardware",55.0,4.0,39.0,330.0,,,multipipe scalable graphics;sdk mpk;executing sub tasks;conclude;specified configuration file,0.7502;0.2575;0.2068;0.0668;0.0034,"[np.int64(-1), -1, -1, -1, -1]",250;-1;-1;-1;-1,250,250
InfoVis,2016,Screenit: Visual Analysis of Cellular Screens,10.1109/tvcg.2016.2598587,http://dx.doi.org/10.1109/TVCG.2016.2598587,591.0,600.0,J,"High-throughput and high-content screening enables large scale, cost-effective experiments in which cell cultures are exposed to a wide spectrum of drugs. The resulting multivariate data sets have a large but shallow hierarchical structure. The deepest level of this structure describes cells in terms of numeric features that are derived from image data. The subsequent level describes enveloping cell cultures in terms of imposed experiment conditions (exposure to drugs). We present Screenit, a visual analysis approach designed in close collaboration with screening experts. Screenit enables the navigation and analysis of multivariate data at multiple hierarchy levels and at multiple levels of detail. Screenit integrates the interactive modeling of cell physical states (phenotypes) and the effects of drugs on cell cultures (hits). In addition, quality control is enabled via the detection of anomalies that indicate low-quality data, while providing an interface that is designed to match workflows of screening experts. We demonstrate analyses for a real-world data set, CellMorph, with 6 million cells across 20,000 cell cultures.",Kasper Dinkla;Hendrik Strobelt;Bryan Genest;Stephan Reiling;Mark Borowsky;Hanspeter Pfister,Kasper Dinkla;Hendrik Strobelt;Bryan Genest;Stephan Reiling;Mark Borowsky;Hanspeter Pfister,Harvard University;Harvard University;Novartis Institute of BioMedical Research;Novartis Institute of BioMedical Research;Novartis Institute of BioMedical Research;Harvard University,10.1109/vast.2012.6400492;10.1109/tvcg.2014.2346752;10.1109/tvcg.2015.2466971;10.1109/tvcg.2011.253;10.1109/vast.2010.5652443;10.1109/tvcg.2012.213;10.1109/tvcg.2014.2346578;10.1109/tvcg.2013.173;10.1109/vast.2011.6102453;10.1109/tvcg.2014.2346482;10.1109/vast.2012.6400492,High-content screening;visual analysis;feature selection;image classification;biology;multivariate;hierarchy,9.0,8.0,48.0,717.0,,,interactive modeling cell;multivariate data sets;drugs present screenit;level describes enveloping;million,0.4817;0.2973;0.2717;0.1286;0.0104,"[-1, -1, -1, -1, -1]",-1;-1;-1;-1;-1,,-1
Vis,2022,A Scanner Deeply: Predicting Gaze Heatmaps on Visualizations Using Crowdsourced Eye Movement Data,10.1109/tvcg.2022.3209472,http://dx.doi.org/10.1109/TVCG.2022.3209472,396.0,406.0,J,"Visual perception is a key component of data visualization. Much prior empirical work uses eye movement as a proxy to understand human visual perception. Diverse apparatus and techniques have been proposed to collect eye movements, but there is still no optimal approach. In this paper, we review 30 prior works for collecting eye movements based on three axes: (1) the tracker technology used to measure eye movements; (2) the image stimulus shown to participants; and (3) the collection methodology used to gather the data. Based on this taxonomy, we employ a webcam-based eyetracking approach using task-specific visualizations as the stimulus. The low technology requirement means that virtually anyone can participate, thus enabling us to collect data at large scale using crowdsourcing: approximately 12,000 samples in total. Choosing visualization images as stimulus means that the eye movements will be specific to perceptual tasks associated with visualization. We use these data to propose a Scanner Deeply, a virtual eyetracker model that, given an image of a visualization, generates a gaze heatmap for that image. We employ a computationally efficient, yet powerful convolutional neural network for our model. We compare the results of our work with results from the DVS model and a neural network trained on the Salicon dataset. The analysis of our gaze patterns enables us to understand how users grasp the structure of visualized data. We also make our stimulus dataset of visualization images available as part of this paper's contribution.",Sungbok Shin;Sunghyo Chung;Sanghyun Hong 0001;Niklas Elmqvist,Sungbok Shin;Sunghyo Chung;Sanghyun Hong;Niklas Elmqvist,"University of Maryland, College Park, USA;Kakao Corp., South Korea;Oregon State University, USA;University of Maryland, College Park, USA",10.1109/tvcg.2015.2467732;10.1109/tvcg.2011.193;10.1109/tvcg.2018.2865138;10.1109/tvcg.2012.215;10.1109/tvcg.2015.2467195;10.1109/tvcg.2017.2743939;10.1109/tvcg.2015.2467732,"Gaze prediction,visualization,webcam-based eye-tracking,crowdsourcing,deep learning",,1.0,72.0,1262.0,,,deeply virtual eyetracker;heatmap image employ;collection methodology used;large;proxy understand,0.6366;0.3338;0.1759;0.0985;0.0177,"[np.int64(-1), -1, -1, -1, -1]",78;-1;-1;-1;-1,78,78
Vis,2008,Geodesic Distance-weighted Shape Vector Image Diffusion,10.1109/tvcg.2008.134,http://dx.doi.org/10.1109/TVCG.2008.134,1643.0,1650.0,J,"This paper presents a novel and efficient surface matching and visualization framework through the geodesic distance-weighted shape vector image diffusion. Based on conformal geometry, our approach can uniquely map a 3D surface to a canonical rectangular domain and encode the shape characteristics (e.g., mean curvatures and conformal factors) of the surface in the 2D domain to construct a geodesic distance-weighted shape vector image, where the distances between sampling pixels are not uniform but the actual geodesic distances on the manifold. Through the novel geodesic distance-weighted shape vector image diffusion presented in this paper, we can create a multiscale diffusion space, in which the cross-scale extrema can be detected as the robust geometric features for the matching and registration of surfaces. Therefore, statistical analysis and visualization of surface properties across subjects become readily available. The experiments on scanned surface models show that our method is very robust for feature extraction and surface matching even under noise and resolution change. We have also applied the framework on the real 3D human neocortical surfaces, and demonstrated the excellent performance of our approach in statistical analysis and integrated visualization of the multimodality volumetric data over the shape vector image.",Jing Hua 0001;Zhaoqiang Lai;Ming Dong 0001;Xianfeng Gu;Hong Qin 0001,Jing Hua;Zhaoqiang Lai;Ming Dong;Xianfeng Gu;Hong Qin,"Wayne State University, USA;Wayne State University, USA;Wayne State University, USA;Stony Brook University, USA;Stony Brook University, USA",,"Surface Matching, Shape Vector Image, Multiscale Diffusion, Visualization",54.0,31.0,32.0,436.0,,,surface matching visualization;multiscale diffusion space;novel geodesic;human neocortical;encode,0.5559;0.4570;0.3771;0.2295;0.0152,"[np.int64(-1), -1, -1, -1, -1]",242;-1;-1;-1;-1,242,242
InfoVis,2020,"Comparative Layouts Revisited: Design Space, Guidelines, and Future Directions",10.1109/tvcg.2020.3030419,http://dx.doi.org/10.1109/TVCG.2020.3030419,1525.0,1535.0,J,"We present a systematic review on three comparative layouts-juxtaposition, superposition, and explicit-encoding-which are information visualization (InfoVis) layouts designed to support comparison tasks. For the last decade, these layouts have served as fundamental idioms in designing many visualization systems. However, we found that the layouts have been used with inconsistent terms and confusion, and the lessons from previous studies are fragmented. The goal of our research is to distill the results from previous studies into a consistent and reusable framework. We review 127 research papers, including 15 papers with quantitative user studies, which employed comparative layouts. We first alleviate the ambiguous boundaries in the design space of comparative layouts by suggesting lucid terminology (e.g., chart-wise and item-wise juxtaposition). We then identify the diverse aspects of comparative layouts, such as the advantages and concerns of using each layout in the real-world scenarios and researchers' approaches to overcome the concerns. Building our knowledge on top of the initial insights gained from the Gleicher et al.'s survey [19], we elaborate on relevant empirical evidence that we distilled from our survey (e.g., the actual effectiveness of the layouts in different study settings) and identify novel facets that the original work did not cover (e.g., the familiarity of the layouts to people). Finally, we show the consistent and contradictory results on the performance of comparative layouts and offer practical implications for using the layouts by suggesting trade-offs and seven actionable guidelines.",Sehi L'Yi;Jaemin Jo;Jinwook Seo,Sehi LYi;Jaemin Jo;Jinwook Seo,Harvard Medical School;Sungkyunkwan University;Seoul National University,10.1109/tvcg.2007.70535;10.1109/tvcg.2017.2744199;10.1109/tvcg.2010.164;10.1109/tvcg.2007.70623;10.1109/tvcg.2007.70539;10.1109/tvcg.2019.2934786;10.1109/tvcg.2010.162;10.1109/tvcg.2013.122;10.1109/vast.2018.8802454;10.1109/tvcg.2013.161;10.1109/tvcg.2017.2745298;10.1109/tvcg.2019.2934801;10.1109/tvcg.2018.2864884;10.1109/tvcg.2017.2744198;10.1109/tvcg.2013.149;10.1109/tvcg.2013.233;10.1109/tvcg.2013.213;10.1109/tvcg.2016.2598796;10.1109/tvcg.2014.2346320;10.1109/tvcg.2012.237;10.1109/tvcg.2015.2467751;10.1109/tvcg.2018.2864510;10.1109/tvcg.2007.70535,"Comparative layout,visual comparison,literature review,juxtaposition,superposition,explicit-encoding",16.0,22.0,74.0,1471.0,,,visualization systems layouts;systematic review comparative;item wise;superposition explicit;relevant,0.6779;0.2878;0.1690;0.0677;0.0285,"[np.int64(-1), -1, -1, -1, -1]",183;-1;-1;-1;-1,183,183
InfoVis,2004,Visualizing and Interacting with Multi-Tree Hierarchical Data,10.1109/infvis.2004.74,http://dx.doi.org/10.1109/INFVIS.2004.74,15.0,15.0,M,This work focuses on visualizing highly cyclic hierarchical data. A user interface is discussed and its interaction is illustrated using a recipe database example. This example showcases a database with multiple categories for each recipe (database entry).,Mahnas Jean Mohammadi-Aragh;T. J. Jankun-Kelly,M.J. Mohammadi-Aragh;T.J. Jankun-Kelly,"Visualization, Analysis, and Imaging Laboratory, GeoResources Institute, Engineering Research Center, Mississippi State University, MS, USA;Department of Computer Science and Engineering, Mississippi State University, MS, USA",0.1109/infvis.2003.1249009,,0.0,0.0,5.0,99.0,,,cyclic hierarchical data;illustrated using recipe;showcases database multiple;highly;work focuses,0.6714;0.3648;0.3184;0.0768;0.0161,"[np.int64(-1), -1, -1, -1, -1]",11;-1;-1;-1;-1,11,11
SciVis,2016,Correlated Photon Mapping for Interactive Global Illumination of Time-Varying Volumetric Data,10.1109/tvcg.2016.2598430,http://dx.doi.org/10.1109/TVCG.2016.2598430,901.0,910.0,J,"We present a method for interactive global illumination of both static and time-varying volumetric data based on reduction of the overhead associated with re-computation of photon maps. Our method uses the identification of photon traces invariant to changes of visual parameters such as the transfer function (TF), or data changes between time-steps in a 4D volume. This lets us operate on a variant subset of the entire photon distribution. The amount of computation required in the two stages of the photon mapping process, namely tracing and gathering, can thus be reduced to the subset that are affected by a data or visual parameter change. We rely on two different types of information from the original data to identify the regions that have changed. A low resolution uniform grid containing the minimum and maximum data values of the original data is derived for each time step. Similarly, for two consecutive time-steps, a low resolution grid containing the difference between the overlapping data is used. We show that this compact metadata can be combined with the transfer function to identify the regions that have changed. Each photon traverses the low-resolution grid to identify if it can be directly transferred to the next photon distribution state or if it needs to be recomputed. An efficient representation of the photon distribution is presented leading to an order of magnitude improved performance of the raycasting step. The utility of the method is demonstrated in several examples that show visual fidelity, as well as performance. The examples show that visual quality can be retained when the fraction of retraced photons is as low as 40%-50%.",Daniel Jönsson;Anders Ynnerman,Daniel Jönsson;Anders Ynnerman,"Linköping University, Nörrköping, Sweden;Linköping University, Nörrköping, Sweden",10.1109/tvcg.2011.161;10.1109/tvcg.2014.2346333;10.1109/tvcg.2012.232;10.1109/tvcg.2007.70518;10.1109/tvcg.2011.198;10.1109/tvcg.2011.211;10.1109/tvcg.2011.161,Volume rendering;photon mapping;global illumination;participating media,22.0,17.0,45.0,875.0,HM,,photon maps;varying volumetric data;interactive global;needs recomputed efficient;derived time step,0.5950;0.3210;0.1762;0.1168;0.1034,"[np.int64(-1), -1, -1, -1, -1]",292;-1;-1;-1;-1,292,292
InfoVis,2016,An Evaluation of Visual Search Support in Maps,10.1109/tvcg.2016.2598898,http://dx.doi.org/10.1109/TVCG.2016.2598898,421.0,430.0,J,"Visual search can be time-consuming, especially if the scene contains a large number of possibly relevant objects. An instance of this problem is present when using geographic or schematic maps with many different elements representing cities, streets, sights, and the like. Unless the map is well-known to the reader, the full map or at least large parts of it must be scanned to find the elements of interest. In this paper, we present a controlled eye-tracking study (30 participants) to compare four variants of map annotation with labels: within-image annotations, grid reference annotation, directional annotation, and miniature annotation. Within-image annotation places labels directly within the map without any further search support. Grid reference annotation corresponds to the traditional approach known from atlases. Directional annotation utilizes a label in combination with an arrow pointing in the direction of the label within the map. Miniature annotation shows a miniature grid to guide the reader to the area of the map in which the label is located. The study results show that within-image annotation is outperformed by all other annotation approaches. Best task completion times are achieved with miniature annotation. The analysis of eye-movement data reveals that participants applied significantly different visual task solution strategies for the different visual annotations.",Rudolf Netzel;Marcel Hlawatsch;Michael Burch;Sanjeev Balakrishnan;Hansjörg Schmauder;Daniel Weiskopf,Rudolf Netzel;Marcel Hlawatsch;Michael Burch;Sanjeev Balakrishnan;Hansjörg Schmauder;Daniel Weiskopf,"VISUS, University of Stuttgart;VISUS, University of Stuttgart;VISUS, University of Stuttgart;VISUS, University of Stuttgart;VISUS, University of Stuttgart;VISUS, University of Stuttgart",10.1109/tvcg.2014.2346420;10.1109/tvcg.2010.191;10.1109/tvcg.2014.2346420,Visual search;laboratory study;eye tracking;map visualization,29.0,15.0,37.0,1064.0,,,map miniature annotation;eye tracking study;search support;different elements;unless,0.6142;0.3966;0.2876;0.0886;0.0104,"[np.int64(-1), -1, -1, -1, -1]",128;-1;-1;-1;-1,128,128
InfoVis,2007,Geographically Weighted Visualization: Interactive Graphics for Scale-Varying Exploratory Analysis,10.1109/tvcg.2007.70558,http://dx.doi.org/10.1109/TVCG.2007.70558,1161.0,1168.0,J,"We introduce a series of geographically weighted (GW) interactive graphics, or geowigs, and use them to explore spatial relationships at a range of scales. We visually encode information about geographic and statistical proximity and variation in novel ways through &lt;i&gt;gw-choropleth maps&lt;/i&gt;, multivariate &lt;i&gt;gw-boxplots, gw-shading&lt;/i&gt; and &lt;i&gt;scalograms&lt;/i&gt;. The new graphic types reveal information about GW statistics at several scales concurrently. We impement these views in prototype software containing dynamic links and GW interactions that encourage exploration and refine them to consider directional geographies. An informal evaluation uses interactive GW techniques to consider Guerry's dataset of 'moral statistics', casting doubt on correlations originally proposed through visual analysis, revealing new local anomalies and suggesting multivariate geographic relationships. Few attempts at visually synthesising geography with multivariate statistical values at multiple scales have been reported. The &lt;i&gt;geowigs &lt;/i&gt;proposed here provide informative representations of multivariate local variation, particularly when combined with interactions that coordinate views and result in &lt;i&gt;gw-shading&lt;/i&gt;. We argue that they are widely applicable to area and point-based geographic data and provide a set of methods to support visual analysis using GW statistics through which the effects of geography can be explored at multiple scales.",Jason Dykes;Chris Brunsdon,Jason Dykes;Chris Brunsdon,"Department of Information Science, City University, London, UK;Department of Geography, University of Leicester, Leicester, UK",,"Geographical weighting, exploratory data analysis, scale, multivariate, directional, interaction, coordinated views",68.0,50.0,21.0,861.0,,,visually synthesising geography;series geographically weighted;statistical values;interactions encourage;gw,0.6714;0.3647;0.2226;0.1621;0.0806,"[np.int64(-1), -1, -1, -1, -1]",154;-1;-1;-1;-1,154,154
InfoVis,2017,Data Visualization Saliency Model: A Tool for Evaluating Abstract Data Visualizations,10.1109/tvcg.2017.2743939,http://dx.doi.org/10.1109/TVCG.2017.2743939,563.0,573.0,J,"Evaluating the effectiveness of data visualizations is a challenging undertaking and often relies on one-off studies that test a visualization in the context of one specific task. Researchers across the fields of data science, visualization, and human-computer interaction are calling for foundational tools and principles that could be applied to assessing the effectiveness of data visualizations in a more rapid and generalizable manner. One possibility for such a tool is a model of visual saliency for data visualizations. Visual saliency models are typically based on the properties of the human visual cortex and predict which areas of a scene have visual features (e.g. color, luminance, edges) that are likely to draw a viewer's attention. While these models can accurately predict where viewers will look in a natural scene, they typically do not perform well for abstract data visualizations. In this paper, we discuss the reasons for the poor performance of existing saliency models when applied to data visualizations. We introduce the Data Visualization Saliency (DVS) model, a saliency model tailored to address some of these weaknesses, and we test the performance of the DVS model and existing saliency models by comparing the saliency maps produced by the models to eye tracking data obtained from human viewers. Finally, we describe how modified saliency models could be used as general tools for assessing the effectiveness of visualizations, including the strengths and weaknesses of this approach.",Laura E. Matzen;Michael J. Haass;Kristin M. Divis;Zhiyuan Wang;Andrew T. Wilson,Laura E. Matzen;Michael J. Haass;Kristin M. Divis;Zhiyuan Wang;Andrew T. Wilson,"Sandia National Laboratories;Sandia National Laboratories;Sandia National Laboratories;University of Illinois, Urbana-Champaign;Sandia National Laboratories",10.1109/tvcg.2015.2467732;10.1109/tvcg.2015.2467732,"Visual saliency,evaluation,eye tracking",45.0,40.0,49.0,2822.0,,,data visualization saliency;cortex predict;reasons poor;including;obtained,0.8226;0.2003;0.1008;0.0967;-0.1211,"[np.int64(-1), -1, -1, -1, -1]",264;-1;-1;-1;-1,264,264
Vis,1998,Wavelets over curvilinear grids,10.1109/visual.1998.745318,http://dx.doi.org/10.1109/VISUAL.1998.745318,313.0,317.0,C,"We develop multiresolution models for analyzing and visualizing two-dimensional flows over curvilinear grids. Our models are based upon nested spaces of piecewise defined functions defined over nested curvilinear grid domains. The nested domains are selected so as to maintain the original geometry of the inner boundary. We first give the refinement and decomposition equations for Haar wavelets over these domains. Next, using lifting techniques we develop and show examples of piecewise linear wavelets over curvilinear grids.",Gregory M. Nielson;Il-Hong Jung;Junwon Sung,G.M. Nielson;Il.-H. Jung;J. Sung,"Department of Computer Science and Engineering, Arizona State University, Tempe, AZ, USA;Department of Computer Science and Engineering, Arizona State University, Tempe, AZ, USA;Department of Computer Science and Engineering, Arizona State University, Tempe, AZ, USA",10.1109/visual.1997.663883;10.1109/visual.1997.663872;10.1109/visual.1997.663871;10.1109/visual.1997.663883,,17.0,3.0,11.0,64.0,,,wavelets curvilinear grids;piecewise defined;nested domains;equations haar;selected maintain original,0.7670;0.2674;0.2027;0.1468;-0.0496,"[np.int64(-1), -1, -1, -1, -1]",100;-1;-1;-1;-1,100,100
Vis,2005,Hardware-accelerated simulated radiography,10.1109/visual.2005.1532815,http://dx.doi.org/10.1109/VISUAL.2005.1532815,343.0,350.0,C,"We present the application of hardware accelerated volume rendering algorithms to the simulation of radiographs as an aid to scientists designing experiments, validating simulation codes, and understanding experimental data. The techniques presented take advantage of 32-bit floating point texture capabilities to obtain solutions to the radiative transport equation for X-rays. The hardware accelerated solutions are accurate enough to enable scientists to explore the experimental design space with greater efficiency than the methods currently in use. An unsorted hexahedron projection algorithm is presented for curvilinear hexahedral meshes that produces simulated radiographs in the absorption-only regime. A sorted tetrahedral projection algorithm is presented that simulates radiographs of emissive materials. We apply the tetrahedral projection algorithm to the simulation of experimental diagnostics for inertial confinement fusion experiments on a laser at the University of Rochester.",Daniel E. Laney;Steven P. Callahan;Nelson L. Max;Cláudio T. Silva;Steven Langer;Randall Frank,D. Laney;S.P. Callahan;N. Max;C.T. Silva;S. Langer;R. Frank,"Lawrence Livemore National Laboratory, USA;University of Utah, USA;Lawrence Livemore National Laboratory, USA;University of Utah, USA;Lawrence Livemore National Laboratory, USA;Computational Engineering International",10.1109/visual.2000.885683;10.1109/visual.2004.85;10.1109/visual.2003.1250390;10.1109/visual.2000.885683," volume rendering, hardware acceleration",19.0,3.0,20.0,129.0,,,algorithms simulation radiographs;curvilinear hexahedral meshes;confinement fusion;32 bit floating;aid,0.6261;0.4121;0.3163;0.2315;-0.0426,"[np.int64(-1), -1, -1, -1, -1]",314;-1;-1;-1;-1,314,314
Vis,2010,Computing Robustness and Persistence for Images,10.1109/tvcg.2010.139,http://dx.doi.org/10.1109/TVCG.2010.139,1251.0,1260.0,J,"We are interested in 3-dimensional images given as arrays of voxels with intensity values. Extending these values to a continuous function, we study the robustness of homology classes in its level and interlevel sets, that is, the amount of perturbation needed to destroy these classes. The structure of the homology classes and their robustness, over all level and interlevel sets, can be visualized by a triangular diagram of dots obtained by computing the extended persistence of the function. We give a fast hierarchical algorithm using the dual complexes of oct-tree approximations of the function. In addition, we show that for balanced oct-trees, the dual complexes are geometrically realized in R&lt;sup&gt;3&lt;/sup&gt; and can thus be used to construct level and interlevel sets. We apply these tools to study 3-dimensional images of plant root systems.",Paul Bendich;Herbert Edelsbrunner;Michael Kerber,Paul Bendich;Herbert Edelsbrunner;Michael Kerber,"IST Austria, Austria;IST Austria, Duke University, USA;IST Austria, Austria",10.1109/visual.1997.663875,"Voxel arrays, oct-trees, persistent homology, persistence diagrams, level sets, robustness, approximations, plant roots",114.0,70.0,20.0,642.0,,,dimensional images plant;complexes oct tree;robustness homology;level interlevel sets;destroy classes structure,0.5143;0.4537;0.3993;0.3262;0.1091,"[np.int64(-1), -1, -1, -1, -1]",298;-1;-1;-1;-1,298,298
Vis,2003,Counting cases in marching cubes: toward a generic algorithm for producing substitopes,10.1109/visual.2003.1250354,http://dx.doi.org/10.1109/VISUAL.2003.1250354,51.0,58.0,C,"We describe how to count the cases that arise in a family of visualization techniques, including marching cubes, sweeping simplices, contour meshing, interval volumes, and separating surfaces. Counting the cases is the first step toward developing a generic visualization algorithm to produce substitopes (geometric substitution of polytopes). We demonstrate the method using a software system (""GAP"") for computational group theory. The case-counts are organized into a table that provides taxonomy of members of the family; numbers in the table are derived from actual lists of cases, which are computed by our methods. The calculation confirms previously reported case-counts for large dimensions that are too large to check by hand, and predicts the number of cases that will arise in algorithms that have not yet been invented.",David C. Banks;Stephen A. Linton,D.C. Banks;S. Linton,"Florida State University, USA;University of Saint Andrews, UK",10.1109/visual.2000.885704;10.1109/visual.1997.663886;10.1109/visual.1996.568103;10.1109/visual.1996.568121;10.1109/visual.1995.480806;10.1109/visual.1991.175780;10.1109/visual.1997.663887;10.1109/visual.2001.964564;10.1109/visual.2000.885704,"level set, isosurface, orbit, group action, Marching Cubes, separating surfaces, geometric substitution, substitope",46.0,11.0,31.0,166.0,BP,,visualization techniques including;geometric substitution polytopes;gap computational group;methods calculation confirms;previously reported case,0.5734;0.5251;0.3866;0.1014;0.0101,"[np.int64(-1), np.int64(-1), -1, -1, -1]",212;254;-1;-1;-1,212;254,212
Vis,1995,Interactive realism for visualization using ray tracing,10.1109/visual.1995.480791,http://dx.doi.org/10.1109/VISUAL.1995.480791,19.0,,C,"Visual realism is necessary for many virtual reality applications. In order to convince the user that the virtual environment is real, the scene presented should faithfully model the expected actual environment. A highly accurate, fully modeled, interactive environment is thus seen as ""virtually real"". The paper addresses the problem of interactive visual realism and discusses a possible solution: a hybrid rendering paradigm that ties distributed graphics hardware and ray tracing systems together for use in interactive, high visual realism applications. This new paradigm is examined in the context of a working rendering system. This system is capable of producing images of higher fidelity than possible through the use of graphics hardware alone, able both to render images at speeds useful for interactive systems and to progressively refine static, high quality snapshots.",Robert A. Cross,R.A. Cross,"Naval Research Laboratory, Inc., Washington D.C., DC, USA",,,22.0,3.0,12.0,68.0,,,interactive visual realism;user virtual;ray;tracing systems use;addresses problem,0.7206;0.2967;0.2422;0.1888;0.0073,"[np.int64(-1), -1, -1, -1, -1]",227;-1;-1;-1;-1,227,227
VAST,2017,BiDots: Visual Exploration of Weighted Biclusters,10.1109/tvcg.2017.2744458,http://dx.doi.org/10.1109/TVCG.2017.2744458,195.0,204.0,J,"Discovering and analyzing biclusters, i.e., two sets of related entities with close relationships, is a critical task in many real-world applications, such as exploring entity co-occurrences in intelligence analysis, and studying gene expression in bio-informatics. While the output of biclustering techniques can offer some initial low-level insights, visual approaches are required on top of that due to the algorithmic output complexity. This paper proposes a visualization technique, called BiDots, that allows analysts to interactively explore biclusters over multiple domains. BiDots overcomes several limitations of existing bicluster visualizations by encoding biclusters in a more compact and cluster-driven manner. A set of handy interactions is incorporated to support flexible analysis of biclustering results. More importantly, BiDots addresses the cases of weighted biclusters, which has been underexploited in the literature. The design of BiDots is grounded by a set of analytical tasks derived from previous work. We demonstrate its usefulness and effectiveness for exploring computed biclusters with an investigative document analysis task, in which suspicious people and activities are identified from a text corpus.",Jian Zhao 0010;Maoyuan Sun;Francine Chen 0001;Patrick Chiu,Jian Zhao;Maoyuan Sun;Francine Chen;Patrick Chiu,"FX Palo Alto Laboratory;University of Massachusetts, Dartmouth;FX Palo Alto Laboratory;FX Palo Alto Laboratory",10.1109/tvcg.2012.252;10.1109/tvcg.2008.153;10.1109/tvcg.2013.223;10.1109/tvcg.2007.70582;10.1109/visual.1990.146402;10.1109/tvcg.2011.250;10.1109/tvcg.2010.138;10.1109/tvcg.2016.2598831;10.1109/tvcg.2014.2346752;10.1109/vast.2007.4389006;10.1109/tvcg.2015.2467813;10.1109/tvcg.2014.2346665;10.1109/tvcg.2013.167;10.1109/tvcg.2012.252,"Biclustering,coordinated relationship analysis,visual analytics",23.0,20.0,41.0,938.0,,,bicluster visualizations;sets related entities;task suspicious people;expression bio;multiple domains,0.6813;0.3254;0.2991;0.1986;0.0674,"[np.int64(-1), -1, -1, -1, -1]",164;-1;-1;-1;-1,164,164
Vis,1990,The VIS-5D system for easy interactive visualization,10.1109/visual.1990.146361,http://dx.doi.org/10.1109/VISUAL.1990.146361,28.0,,C,"The VIS-5D system provides highly interactive visual access to five-dimensional data sets containing up to 50 million data points. VIS-5D runs on the Stardent ST-1000 and ST-2000 workstations and generates animated three-dimensional graphics from gridded data sets in real time. It provides a widget-based user interface and fast visual response which allows scientists to interactively explore their data sets. VIS-5D generates literal and intuitive depictions of data, has user controls that are data oriented rather than graphics oriented, and provides a WYSIWYG (what-you-see-is-what-you-get) response. The result is a system that enables scientists to produce and direct their own animations.&lt;&lt;ETX&gt;&gt;",William L. Hibbard;David A. Santek,B. Hibbard;D. Santek,"Space Science and Engineering Center, University of Wisconsin, Madison, USA;Space Science and Engineering Center, University of Wisconsin, Madison, USA",,,139.0,24.0,2.0,179.0,,,allows scientists interactively;graphics gridded data;vis 5d runs;animated;sets containing,0.5946;0.4545;0.4453;0.3070;0.0041,"[np.int64(-1), -1, -1, -1, -1]",291;-1;-1;-1;-1,291,291
Vis,2022,Studying Early Decision Making with Progressive Bar Charts,10.1109/tvcg.2022.3209426,http://dx.doi.org/10.1109/TVCG.2022.3209426,407.0,417.0,J,"We conduct a user study to quantify and compare user performance for a value comparison task using four bar chart designs, where the bars show the mean values of data loaded progressively and updated every second (progressive bar charts). Progressive visualization divides different stages of the visualization pipeline—data loading, processing, and visualization—into iterative animated steps to limit the latency when loading large amounts of data. An animated visualization appearing quickly, unfolding, and getting more accurate with time, enables users to make early decisions. However, intermediate mean estimates are computed only on partial data and may not have time to converge to the true means, potentially misleading users and resulting in incorrect decisions. To address this issue, we propose two new designs visualizing the history of values in progressive bar charts, in addition to the use of confidence intervals. We comparatively study four progressive bar chart designs: with/without confidence intervals, and using near-history representation with/without confidence intervals, on three realistic data distributions. We evaluate user performance based on the percentage of correct answers (accuracy), response time, and user confidence. Our results show that, overall, users can make early and accurate decisions with 92% accuracy using only 18% of the data, regardless of the design. We find that our proposed bar chart design with only near-history is comparable to bar charts with only confidence intervals in performance, and the qualitative feedback we received indicates a preference for designs with history.",Ameya Patil;Gaëlle Richer;Christopher Jermaine;Dominik Moritz;Jean-Daniel Fekete,Ameya Patil;Gaëlle Richer;Christopher Jermaine;Dominik Moritz;Jean-Daniel Fekete,"University of Washington, Seattle, USA;Inria & Université Paris-Saclay, France;Rice University, USA;Carnegie Mellon University, USA;Inria & Université Paris-Saclay, France",10.1109/infvis.2005.1532136;10.1109/tvcg.2021.3114803;10.1109/tvcg.2014.2346298;10.1109/tvcg.2019.2934287;10.1109/tvcg.2011.175;10.1109/tvcg.2018.2864909;10.1109/tvcg.2014.2346452;10.1109/tvcg.2008.125;10.1109/tvcg.2014.2346320;10.1109/tvcg.2018.2864889;10.1109/tvcg.2014.2346574;10.1109/infvis.2005.1532136,"Progressive visualization,Uncertainty,Bar charts,Confidence intervals",,6.0,60.0,735.0,,,progressive bar charts;user confidence results;history comparable;value;latency loading large,0.6157;0.4470;0.2514;0.2109;0.1570,"[np.int64(-1), -1, -1, -1, -1]",123;-1;-1;-1;-1,123,123
Vis,2023,Classes are Not Clusters: Improving Label-Based Evaluation of Dimensionality Reduction,10.1109/tvcg.2023.3327187,http://dx.doi.org/10.1109/TVCG.2023.3327187,781.0,791.0,J,"A common way to evaluate the reliability of dimensionality reduction (DR) embeddings is to quantify how well labeled classes form compact, mutually separated clusters in the embeddings. This approach is based on the assumption that the classes stay as clear clusters in the original high-dimensional space. However, in reality, this assumption can be violated; a single class can be fragmented into multiple separated clusters, and multiple classes can be merged into a single cluster. We thus cannot always assure the credibility of the evaluation using class labels. In this paper, we introduce two novel quality measures—Label-Trustworthiness and Label-Continuity (Label-T&C)—advancing the process of DR evaluation based on class labels. Instead of assuming that classes are well-clustered in the original space, Label-T&C work by (1) estimating the extent to which classes form clusters in the original and embedded spaces and (2) evaluating the difference between the two. A quantitative evaluation showed that Label-T&C outperform widely used DR evaluation measures (e.g., Trustworthiness and Continuity, Kullback-Leibler divergence) in terms of the accuracy in assessing how well DR embeddings preserve the cluster structure, and are also scalable. Moreover, we present case studies demonstrating that Label-T&C can be successfully used for revealing the intrinsic characteristics of DR techniques and their hyperparameters.",Hyeon Jeon;Yun-Hsin Kuo;Michaël Aupetit 0001;Kwan-Liu Ma;Jinwook Seo,Hyeon Jeon;Yun-Hsin Kuo;Michaël Aupetit;Kwan-Liu Ma;Jinwook Seo,"Seoul National University, South Korea;University of California, Davis, South Korea;Qatar Computing Research Institute, Hamad Bin Khalifa University, Qatar;University of California, Davis, South Korea;Seoul National University, South Korea",0.1109/tvcg.2021.3114833;10.1109/tvcg.2011.220;10.1109/tvcg.2017.2745085;10.1109/tvcg.2020.3030365;10.1109/tvcg.2013.153;10.1109/tvcg.2017.2745258;10.1109/tvcg.2022.3209423;10.1109/tvcg.2021.3114694,"Dimensionality Reduction,Reliability,Clustering,Clustering Validation Measures,Dimensionality Reduction Evaluation",,2.0,74.0,887.0,,,embeddings quantify labeled;way evaluate reliability;clear clusters original;space reality assumption;divergence terms,0.6255;0.1905;0.1679;0.1537;0.0227,"[np.int64(-1), -1, -1, -1, -1]",31;-1;-1;-1;-1,31,31
Vis,1997,Viewing IGES files through VRML,10.1109/visual.1997.663924,http://dx.doi.org/10.1109/VISUAL.1997.663924,471.0,474.0,C,This paper describes our experiences with using the Virtual Reality Modeling Language (VRML) to view files in the Initial Graphics Exchange Specification (IGES) format using a Java-based translator from IGES to VRML and HTML (Hypertext Markup Language). The paper examines the conversion problems between IGES and VRML and presents some results of the process.,Jed Marti,J. Marti,"Defense Group, Inc., Salt Lake, UT, USA",,"Computer-aided Design, Applications of Visualization",9.0,1.0,10.0,62.0,,,virtual reality modeling;java based translator;iges format using;html hypertext markup;view files initial,0.6072;0.4025;0.3689;0.3373;0.1739,"[np.int64(-1), -1, -1, -1, -1]",74;-1;-1;-1;-1,74,74
Vis,2004,STEPS - an application for simulation of transsphenoidal endonasal pituitary surgery,10.1109/visual.2004.98,http://dx.doi.org/10.1109/VISUAL.2004.98,513.0,520.0,C,"Endonasal transsphenoidal pituitary surgery is a minimally invasive endoscopic procedure, applied to remove various kinds of pituitary tumors. To reduce the risk associated with this treatment, the surgeon must be skilled and well-prepared. Virtual endoscopy can be beneficial as a tool for training, preoperative planning and intraoperative support. This work introduces STEPS, a virtual endoscopy system designed to aid surgeons in getting acquainted with the endoscopic view, the handling of instruments, the transsphenoidal approach and challenges associated with the procedure. STEPS also assists experienced surgeons in planning a real endoscopic intervention by getting familiar with the individual patient anatomy, identifying landmarks, planning the approach and deciding upon the ideal target position of the actual surgical activity. Besides interactive visualization using two different first-hit ray casting techniques, the application provides navigation and perception aids and the possibility to simulate the procedure, including haptic feedback and simulation of surgical instruments.",André Neubauer 0002;Stefan Wolfsberger;Marie-Thérèse Forster;Lukas Mroz;Rainer Wegenkittl;Katja Bühler,A. Neubauer;L. Mroz;S. Wolfsberger;R. Wegenkittl;M.-T. Forster;K. Buhler,"Research Center, VRVis Research Center, Vienna, Austria;Department of Neurosurgery, Medical University, Vienna, Austria;Department of Neurosurgery, Medical University, Vienna, Austria;;Research Center, VRVis Research Center, Vienna, Austria;Research Center, VRVis Research Center, Vienna, Austria",10.1109/visual.2000.885732;10.1109/visual.2000.885702;10.1109/visual.2000.885673;10.1109/visual.2000.885732,"virtual endoscopy, ray casting, iso-surfacing, pituitary surgery",46.0,11.0,21.0,165.0,BA,,virtual endoscopy designed;pituitary tumors reduce;activity interactive visualization;hit ray casting;support work,0.6431;0.3430;0.2354;0.1127;0.1002,"[np.int64(-1), -1, -1, -1, -1]",4;-1;-1;-1;-1,4,4
Vis,2001,Visualizing 2D probability distributions from EOS satellite image-derived data sets: a case study,10.1109/visual.2001.964550,http://dx.doi.org/10.1109/VISUAL.2001.964550,457.0,460.0,C,"Maps of biophysical and geophysical variables using Earth Observing System (EOS) satellite image data are an important component of Earth science. These maps have a single value derived at every grid cell and standard techniques are used to visualize them. Current tools fall short, however, when it is necessary to describe a distribution of values at each grid cell. Distributions may represent a frequency of occurrence over time, frequency of occurrence from multiple runs of an ensemble forecast or possible values from an uncertainty model. We identify these ""distribution data sets"" and present a case study to visualize such 2D distributions. Distribution data sets are different from multivariate data sets in the sense that the values are for a single variable instead of multiple variables. Data for this case study consists of multiple realizations of percent forest cover, generated using a geostatistical technique that combines ground measurements and satellite imagery to model uncertainty about forest cover. We present two general approaches for analyzing and visualizing such data sets. The first is a pixel-wise analysis of the probability density functions for the 2D image while the second is an analysis of features identified within the image. Such pixel-wise and feature-wise views will give Earth scientists a more complete understanding of distribution data sets. See www.cse.ucsc.edu/research/avis/nasa is for additional information.",David L. Kao;Jennifer L. Dungan;Alex Pang,D. Kao;J.L. Dungan;A. Pang,"Ames Research Center, NASA, USA;Ames Research Center, NASA, USA;Computer Science Department, University of California, Santa Cruz, USA",,"uncertainty, probability density function, geostatistics, conditional simulation, data assimilation",70.0,21.0,15.0,349.0,,,earth science maps;cell distributions represent;percent forest;multiple runs ensemble;value derived,0.5706;0.4599;0.4047;0.1009;0.0523,"[np.int64(-1), -1, -1, -1, -1]",-1;-1;-1;-1;-1,,-1
VAST,2009,Solving the traffic and flitter challenges with tulip,10.1109/vast.2009.5334456,http://dx.doi.org/10.1109/VAST.2009.5334456,,,M,"We present our visualization systems and findings for the badge and network traffic as well as the social network and geospatial challenges of the 2009 VAST contest. The summary starts by presenting an overview of our time series encoding of badge information and network traffic. Our findings suggest that employee 30 may be of interest. In the second part of the paper, we describe our system for finding subgraphs in the social network subject to degree constraints. Subsequently, we present our most likely candidate network which is similar to scenario B.",Paolo Simonetto;Pierre-Yves Koenig;Faraz Zaidi;Daniel Archambault;Frédéric Gilbert 0001;Trung-Tien Phan-Quang;Morgan Mathiaut;Antoine Lambert;Jonathan Dubois;Ronan Sicre;Mathieu Brulin;Rémy Vieux;Guy Melançon,Paolo Simonetto;Mathieu Brulin;Remy Vieux;Guy Melancon;Pierre-Yves Koenig;Faraz Zaidi;Daniel Archambault;Frederic Gilbert;Trung-Tien Phan-Quang;Morgan Mathiaut;Antoine Lambert;Jonathan Dubois;Ronan Sicre,"INRIA Bordeaux Sud-Ouest and LaBRI, Université de Bordeaux 1, France;INRIA Bordeaux Sud-Ouest and LaBRI, Université de Bordeaux 1, France;INRIA Bordeaux Sud-Ouest and LaBRI, Université de Bordeaux 1, France;INRIA Bordeaux Sud-Ouest and LaBRI, Université de Bordeaux 1, France;INRIA Bordeaux Sud-Ouest and LaBRI, Université de Bordeaux 1, France;INRIA Bordeaux Sud-Ouest and LaBRI, Université de Bordeaux 1, France;INRIA Bordeaux Sud-Ouest and LaBRI, Université de Bordeaux 1, France;INRIA Bordeaux Sud-Ouest and LaBRI, Université de Bordeaux 1, France;INRIA Bordeaux Sud-Ouest and LaBRI, Université de Bordeaux 1, France;INRIA Bordeaux Sud-Ouest and LaBRI, Université de Bordeaux 1, France;INRIA Bordeaux Sud-Ouest and LaBRI, Université de Bordeaux 1, France;INRIA Bordeaux Sud-Ouest and LaBRI, Université de Bordeaux 1, France;INRIA Bordeaux Sud-Ouest and LaBRI, Université de Bordeaux 1, France",,,1.0,0.0,1.0,113.0,,,badge network;geospatial challenges 2009;overview time series;likely candidate;constraints subsequently present,0.6148;0.3643;0.2219;0.1744;0.0236,"[np.int64(-1), -1, -1, -1, -1]",244;-1;-1;-1;-1,244,244
Vis,2000,Topology preserving compression of 2D vector fields,10.1109/visual.2000.885714,http://dx.doi.org/10.1109/VISUAL.2000.885714,343.0,350.0,C,"We present an algorithm for compressing 2D vector fields that preserves topology. Our approach is to simplify the given data set using constrained clustering. We employ different types of global and local error metrics including the earth mover's distance metric to measure the degradation in topology as well as weighted magnitude and angular errors. As a result, we obtain precise error bounds in the compressed vector fields. Experiments with both analytic and simulated data sets are presented. Results indicate that one can obtain significant compression with low errors without losing topology information.",Suresh K. Lodha;Jose C. Renteria;Krishna M. Roskin,S.K. Lodha;J.C. Renteria;K.M. Roskin,"Department of Computer Science, University of California, Santa Cruz, CA, USA;Department of Computer Science, University of California, Santa Cruz, CA, USA;Department of Computer Science, University of California, Santa Cruz, CA, USA",10.1109/visual.1999.809865;10.1109/visual.1998.745291;10.1109/visual.1999.809907;10.1109/visual.1998.745297;10.1109/visual.1999.809863;10.1109/visual.1999.809897;10.1109/visual.1991.175773;10.1109/visual.1997.663858;10.1109/visual.1998.745284;10.1109/visual.1999.809874;10.1109/visual.1999.809865,"compression, topology, vector fields, error metrics,clustering",87.0,24.0,15.0,134.0,,,compressed vector fields;topology weighted magnitude;clustering employ different;including earth;angular errors,0.6067;0.3415;0.2734;0.1233;0.0424,"[np.int64(-1), -1, -1, -1, -1]",8;-1;-1;-1;-1,8,8
Vis,1999,Isosurface extraction techniques for Web-based volume visualization,10.1109/visual.1999.809878,http://dx.doi.org/10.1109/VISUAL.1999.809878,139.0,519.0,C,"The reconstruction of isosurfaces from scalar volume data has positioned itself as a fundamental visualization technique in many different applications. But the dramatically increasing size of volumetric data sets often prohibits the handling of these models on affordable low-end single processor architectures. Distributed client-server systems integrating high-bandwidth transmission channels and Web based visualization tools are one alternative to attack this particular problem, but therefore new approaches to reduce the load of numerical processing and the number of generated primitives are required. We outline different scenarios for distributed isosurface reconstruction from large scale volumetric data sets. We demonstrate how to directly generate stripped surface representations and we introduce adaptive and hierarchical concepts to minimize the number of vertices that have to be reconstructed, transmitted and rendered. Furthermore, we propose a novel computation scheme, which allows the user to flexibly exploit locally available resources. The proposed algorithms have been merged together in order to build a platform-independent Web based application. Extensive use of VRML and Java OpenGL bindings allows for the exploration of large scale volume data quite efficiently.",Klaus D. Engel;Rüdiger Westermann;Thomas Ertl,K. Engel;R. Westermann;T. Ertl,"Visualization and Interactive Systems Group, University of Stuttgart, Germany;Department of Computer Science, University of Utah, USA;Visualization and Interactive Systems Group, University of Stuttgart, Germany",10.1109/visual.1997.663891;10.1109/visual.1996.568121;10.1109/visual.1995.480806;10.1109/visual.1991.175782;10.1109/visual.1998.745300;10.1109/visual.1996.568127;10.1109/visual.1996.568125;10.1109/visual.1997.663891,"Volume visualization, Isosurface reconstruction, Distributed Systems, Web-based Applications",101.0,18.0,26.0,124.0,,,distributed isosurface reconstruction;volume data;opengl bindings allows;java;approaches reduce load,0.6732;0.3966;0.2379;0.1114;0.1054,"[np.int64(-1), -1, -1, -1, -1]",92;-1;-1;-1;-1,92,92
Vis,1994,The design and implementation of the Cortex visualization system,10.1109/visual.1994.346310,http://dx.doi.org/10.1109/VISUAL.1994.346310,265.0,,C,"Cortex has been designed for interactive analysis and display of simulation data generated by CFD applications based on unstructured-grid solvers. Unlike post-processing visualization environments, Cortex is designed to work in co-processing mode with the CFD application. This significantly reduces data storage and data movement requirements for visualization and also allows users to interactively steer the application. Further, Cortex supports high-performance by running on massively parallel computers and workstation clusters. An important goal for Cortex, is to provide visualization to a variety of solvers which differ in their solution methodologies and supported flow models. Coupled with the co-processing requirement, this has required the development of a well defined programming interface to the CFD solver that lets the visualization system communicate efficiently with the solver, and requires minimal programming effort for porting to new solvers. Further, the requirement for targeting multiple solvers and application niches demands that the visualization system be rapidly and easily modifiable. Such flexibility is attained in Cortex by using the high-level, interpreted language Scheme for implementing user-interfaces and high-level visualization functions. By making the Scheme interpreter available from the Cortex text interface, the user can also customize and extend the visualization system.&lt;&lt;ETX&gt;&gt;",Deb Banerjee;Chris Morley;Wayne Smith,D. Banerjee;C. Morley;W. Smith,"Centerra Resource Park, Fluent, Inc., Lebanon, NH, USA;Centerra Resource Park, Fluent, Inc., Lebanon, NH, USA;Centerra Resource Park, Fluent, Inc., Lebanon, NH, USA",10.1109/visual.1992.235223;10.1109/visual.1991.175833;10.1109/visual.1990.146360;10.1109/visual.1992.235202;10.1109/visual.1992.235223,"interactive, extensible, spray rendering, smart particles, visualization environment",5.0,2.0,14.0,61.0,,,cfd solver;unstructured grid;cortex text interface;application niches demands;significantly,0.6052;0.4127;0.2785;0.1542;0.0280,"[np.int64(-1), -1, -1, -1, -1]",47;-1;-1;-1;-1,47,47
Vis,2008,Invariant Crease Lines for Topological and Structural Analysis of Tensor fields,10.1109/tvcg.2008.148,http://dx.doi.org/10.1109/TVCG.2008.148,1627.0,1634.0,J,"We introduce a versatile framework for characterizing and extracting salient structures in three-dimensional symmetric second-order tensor fields. The key insight is that degenerate lines in tensor fields, as defined by the standard topological approach, are exactly crease (ridge and valley) lines of a particular tensor invariant called mode. This reformulation allows us to apply well-studied approaches from scientific visualization or computer vision to the extraction of topological lines in tensor fields. More generally, this main result suggests that other tensor invariants, such as anisotropy measures like fractional anisotropy (FA), can be used in the same framework in lieu of mode to identify important structural properties in tensor fields. Our implementation addresses the specific challenge posed by the non-linearity of the considered scalar measures and by the smoothness requirement of the crease manifold computation. We use a combination of smooth reconstruction kernels and adaptive refinement strategy that automatically adjust the resolution of the analysis to the spatial variation of the considered quantities. Together, these improvements allow for the robust application of existing ridge line extraction algorithms in the tensor context of our problem. Results are proposed for a diffusion tensor MRI dataset, and for a benchmark stress tensor field used in engineering research.",Xavier Tricoche;Gordon L. Kindlmann;Carl-Fredrik Westin,Xavier Tricoche;Gordon Kindlmann;Carl-Fredrik Westin,"Computer Science Department, Purdue University, USA;Brigham and Women's Hospital, Harvard Medical School;Brigham and Women's Hospital, Harvard Medical School",10.1109/visual.2004.105;10.1109/tvcg.2007.70602;10.1109/visual.1999.809896;10.1109/visual.1991.175773;10.1109/visual.1994.346326;10.1109/visual.1994.346326;10.1109/visual.1990.146359;10.1109/tvcg.2007.70554;10.1109/visual.2004.105,"Tensor fields, tensor invariants, ridge lines, crease extraction, structural analysis, topology",69.0,45.0,43.0,422.0,,,tensor mri;extraction topological lines;symmetric second order;adaptive refinement strategy;important,0.6317;0.4068;0.1310;0.0755;0.0586,"[np.int64(-1), -1, -1, -1, -1]",44;-1;-1;-1;-1,44,44
SciVis,2018,Visualization of Neuronal Structures in Wide-Field Microscopy Brain Images,10.1109/tvcg.2018.2864852,http://dx.doi.org/10.1109/TVCG.2018.2864852,1018.0,1028.0,J,"Wide-field microscopes are commonly used in neurobiology for experimental studies of brain samples. Available visualization tools are limited to electron, two-photon, and confocal microscopy datasets, and current volume rendering techniques do not yield effective results when used with wide-field data. We present a workflow for the visualization of neuronal structures in wide-field microscopy images of brain samples. We introduce a novel gradient-based distance transform that overcomes the out-of-focus blur caused by the inherent design of wide-field microscopes. This is followed by the extraction of the 3D structure of neurites using a multi-scale curvilinear filter and cell-bodies using a Hessian-based enhancement filter. The response from these filters is then applied as an opacity map to the raw data. Based on the visualization challenges faced by domain experts, our workflow provides multiple rendering modes to enable qualitative analysis of neuronal structures, which includes separation of cell-bodies from neurites and an intensity-based classification of the structures. Additionally, we evaluate our visualization results against both a standard image processing deconvolution technique and a confocal microscopy image of the same specimen. We show that our method is significantly faster and requires less computational resources, while producing high quality visualizations. We deploy our workflow in an immersive gigapixel facility as a paradigm for the processing and visualization of large, high-resolution, wide-field microscopy brain datasets.",Saeed Boorboor;Shreeraj Jadhav;Mala Ananth 0001;David Talmage;Lorna Role;Arie E. Kaufman,Saeed Boorboor;Shreeraj Jadhav;Mala Ananth;David Talmage;Lorna Role;Arie Kaufman,"Department of Computer Science, Stony Brook University;Department of Computer Science, Stony Brook University;Department of Neurobiology & behavior, Stony Brook University;Department of Neurobiology & behavior, Stony Brook University;Department of Neurobiology & behavior, Stony Brook University;Department of Computer Science, Stony Brook University and Connectomics project, Harvard University",10.1109/tvcg.2014.2346312;10.1109/tvcg.2013.142;10.1109/tvcg.2012.203;10.1109/tvcg.2017.2744079;10.1109/tvcg.2009.118;10.1109/tvcg.2016.2598472;10.1109/tvcg.2014.2346312,"Wide-field microscopy,volume visualization,neuron visualization,neuroscience",13.0,15.0,58.0,1009.0,,,visualization neuronal structures;curvilinear filter;focus blur caused;deploy workflow;faster requires,0.6539;0.2281;0.1513;0.0554;0.0393,"[np.int64(-1), -1, -1, -1, -1]",136;-1;-1;-1;-1,136,136
VAST,2012,Spatiotemporal social media analytics for abnormal event detection and examination using seasonal-trend decomposition,10.1109/vast.2012.6400557,http://dx.doi.org/10.1109/VAST.2012.6400557,143.0,152.0,C,"Recent advances in technology have enabled social media services to support space-time indexed data, and internet users from all over the world have created a large volume of time-stamped, geo-located data. Such spatiotemporal data has immense value for increasing situational awareness of local events, providing insights for investigations and understanding the extent of incidents, their severity, and consequences, as well as their time-evolving nature. In analyzing social media data, researchers have mainly focused on finding temporal trends according to volume-based importance. Hence, a relatively small volume of relevant messages may easily be obscured by a huge data set indicating normal situations. In this paper, we present a visual analytics approach that provides users with scalable and interactive social media data analysis and visualization including the exploration and examination of abnormal topics and events within various social media data sources, such as Twitter, Flickr and YouTube. In order to find and understand abnormal events, the analyst can first extract major topics from a set of selected messages and rank them probabilistically using Latent Dirichlet Allocation. He can then apply seasonal trend decomposition together with traditional control chart methods to find unusual peaks and outliers within topic time series. Our case studies show that situational awareness can be improved by incorporating the anomaly and trend examination techniques into a highly interactive visual analysis process.",Junghoon Chae;Dennis Thom;Harald Bosch;Yun Jang;Ross Maciejewski;David S. Ebert;Thomas Ertl,Junghoon Chae;Dennis Thom;Harald Bosch;Yun Jang;Ross Maciejewski;David S. Ebert;Thomas Ertl,Purdue University;University of Stuttgart;University of Stuttgart;Sejong University;Arizona State University;Purdue University;University of Stuttgart,10.1109/vast.2011.6102456;10.1109/vast.2011.6102461;10.1109/tvcg.2008.175;10.1109/vast.2011.6102488;10.1109/vast.2011.6102456,,354.0,171.0,39.0,3235.0,,,finding temporal trends;interactive social media;understand abnormal;messages easily obscured;located,0.5448;0.3739;0.2836;0.1939;0.0495,"[np.int64(-1), -1, -1, -1, -1]",127;-1;-1;-1;-1,127,127
Vis,2009,An interactive visualization tool for multi-channel confocal microscopy data in neurobiology research,10.1109/tvcg.2009.118,http://dx.doi.org/10.1109/TVCG.2009.118,1489.0,1496.0,J,"Confocal microscopy is widely used in neurobiology for studying the three-dimensional structure of the nervous system. Confocal image data are often multi-channel, with each channel resulting from a different fluorescent dye or fluorescent protein; one channel may have dense data, while another has sparse; and there are often structures at several spatial scales: subneuronal domains, neurons, and large groups of neurons (brain regions). Even qualitative analysis can therefore require visualization using techniques and parameters fine-tuned to a particular dataset. Despite the plethora of volume rendering techniques that have been available for many years, the techniques standardly used in neurobiological research are somewhat rudimentary, such as looking at image slices or maximal intensity projections. Thus there is a real demand from neurobiologists, and biologists in general, for a flexible visualization tool that allows interactive visualization of multi-channel confocal data, with rapid fine-tuning of parameters to reveal the three-dimensional relationships of structures of interest. Together with neurobiologists, we have designed such a tool, choosing visualization methods to suit the characteristics of confocal data and a typical biologist's workflow. We use interactive volume rendering with intuitive settings for multidimensional transfer functions, multiple render modes and multi-views for multi-channel volume data, and embedding of polygon data into volume data for rendering and editing. As an example, we apply this tool to visualize confocal microscopy datasets of the developing zebrafish visual system.",Yong Wan;Hideo Otsuna;Chi-Bin Chien;Charles D. Hansen,Yong Wan;Hideo Otsuna;Chi-Bin Chien;Charles Hansen,"Scientific and Imaging Institute, University of Utah, USA;Department of Neurobiology and Anatomy, University of Utah, USA;Department of Neurobiology and Anatomy, University of Utah, USA;Scientific and Imaging Institute, University of Utah, USA",10.1109/visual.1999.809887;10.1109/tvcg.2006.148;10.1109/visual.1999.809887,"Visualization, neurobiology, confocal microscopy, qualitative analysis, volume rendering",103.0,93.0,26.0,786.0,,,visualize confocal microscopy;polygon data volume;intuitive settings multidimensional;standardly used neurobiological;different,0.6352;0.3340;0.3017;0.2662;0.0148,"[np.int64(-1), -1, -1, -1, -1]",288;-1;-1;-1;-1,288,288
VAST,2016,Patterns and Sequences: Interactive Exploration of Clickstreams to Understand Common Visitor Paths,10.1109/tvcg.2016.2598797,http://dx.doi.org/10.1109/TVCG.2016.2598797,321.0,330.0,J,"Modern web clickstream data consists of long, high-dimensional sequences of multivariate events, making it difficult to analyze. Following the overarching principle that the visual interface should provide information about the dataset at multiple levels of granularity and allow users to easily navigate across these levels, we identify four levels of granularity in clickstream analysis: patterns, segments, sequences and events. We present an analytic pipeline consisting of three stages: pattern mining, pattern pruning and coordinated exploration between patterns and sequences. Based on this approach, we discuss properties of maximal sequential patterns, propose methods to reduce the number of patterns and describe design considerations for visualizing the extracted sequential patterns and the corresponding raw sequences. We demonstrate the viability of our approach through an analysis scenario and discuss the strengths and limitations of the methods based on user feedback.",Zhicheng Liu 0001;Yang Wang;Mira Dontcheva;Matthew Hoffman 0001;Seth Walker;Alan Wilson 0004,Zhicheng Liu;Yang Wang;Mira Dontcheva;Matthew Hoffman;Seth Walker;Alan Wilson,"Adobe Research;University of California, Davis;Adobe Research;Adobe Research;Adobe Research;Adobe Systems Inc.",10.1109/vast.2010.5652910;10.1109/vast.2010.5652926;10.1109/tvcg.2013.225;10.1109/tvcg.2013.200;10.1109/infvis.2005.1532152;10.1109/infvis.2000.885091;10.1109/tvcg.2014.2346574;10.1109/vast.2007.4389008;10.1109/tvcg.2011.185;10.1109/vast.2014.7042487;10.1109/tvcg.2015.2467622;10.1109/vast.2012.6400494;10.1109/vast.2010.5652910,event sequences;Clickstream Data;sequence mining;visual analytics,125.0,86.0,38.0,2153.0,,,clickstream analysis patterns;visualizing extracted;easily navigate;levels granularity allow;long,0.7830;0.3205;0.2871;0.1904;0.0266,"[np.int64(-1), -1, -1, -1, -1]",122;-1;-1;-1;-1,122,122
Vis,2001,Distance-field based skeletons for virtual navigation,10.1109/visual.2001.964517,http://dx.doi.org/10.1109/VISUAL.2001.964517,239.0,246.0,C,"We present a generic method for rapid flight planning, virtual navigation and effective camera control in a volumetric environment. Directly derived from an accurate distance from boundary (DFB) field, our automatic path planning algorithm rapidly generates centered flight paths, a skeleton, in the navigable region of the virtual environment. Based on precomputed flight paths and the DFB field, our dual-mode physically based camera control model supports a smooth, safe, and sticking-free virtual navigation with six degrees of freedom. By using these techniques, combined with accelerated volume rendering, we have successfully developed a real-time virtual colonoscopy system on low-cost PCs and confirmed the high speed, high accuracy and robustness of our techniques on more than 40 patient datasets.",Ming Wan;Frank Dachille;Arie E. Kaufman,Ming Wan;F. Dachille;A. Kaufman,"Boeing Company, Seattle, WA, USA;Department of Computer Science, State University of New York, Stony Brook, Stony Brook, NY, USA;Department of Computer Science, State University of New York, Stony Brook, Stony Brook, NY, USA",10.1109/visual.1997.663915;10.1109/visual.2000.885675,"Distance fields, path planning, centerline, camera control, virtual navigation, volumetric environment, physically based modeling, virtual colonoscopy",160.0,7.0,27.0,259.0,,,virtual colonoscopy;camera control model;flight paths dfb;volume rendering successfully;confirmed,0.6376;0.3483;0.2843;0.2403;-0.0204,"[np.int64(-1), -1, -1, -1, -1]",4;-1;-1;-1;-1,4,4
Vis,1995,Virtual GIS: a real-time 3D geographic information system,10.1109/visual.1995.480800,http://dx.doi.org/10.1109/VISUAL.1995.480800,94.0,,C,"Advances in computer graphics hardware and algorithms, visualization, and interactive techniques for analysis offer the components for a highly integrated, efficient real-time 3D Geographic Information System. We have developed ""Virtual GIS"", a system with truly immersive capability for navigating and understanding complex and dynamic terrain-based databases. The system provides the means for visualizing terrain models consisting of elevation and imagery data, along with GIS raster layers, protruding features, buildings, vehicles, and other objects. We have implemented window-based and virtual reality versions and in both cases provide a direct manipulation, visual interface for accessing the GIS data. Unique terrain data structures and algorithms allow rendering of large, high resolution datasets at interactive rates.",David Koller;Peter Lindstrom 0001;William Ribarsky;Larry F. Hodges;Nickolas Faust;Gregory A. Turner,D. Koller;P. Lindstrom;W. Ribarsky;L.F. Hodges;N. Faust;G. Turner,"Coll. of Comput., Georgia Inst. of Technol., Atlanta, GA, USA;Graphics Visualizaton Usability Center College of Computing, Georgia Institute of Technology, Atlanta, GA, USA;Graphics Visualizaton Usability Center College of Computing, Georgia Institute of Technology, Atlanta, GA, USA;Graphics Visualizaton Usability Center College of Computing, Georgia Institute of Technology, Atlanta, GA, USA;Georgia Tech Research Institute, Georgia Institute of Technology, USA;Army Research Laboratory, Information Processing Branch",0.1109/visual.1994.346284,,313.0,36.0,19.0,584.0,,,gis truly immersive;hardware algorithms;layers protruding features;versions cases;high,0.6661;0.1667;0.1441;0.0311;0.0311,"[np.int64(-1), -1, -1, -1, -1]",305;-1;-1;-1;-1,305,305
VAST,2007,Stories in GeoTime,10.1109/vast.2007.4388992,http://dx.doi.org/10.1109/VAST.2007.4388992,19.0,26.0,C,"A story is a powerful abstraction used by intelligence analysts to conceptualize threats and understand patterns as part of the analytical process. This paper demonstrates a system that detects geo-temporal patterns and integrates story narration to increase analytic sense-making cohesion in GeoTime. The GeoTime geo-temporal event visualization tool was augmented with a story system that uses narratives, hypertext linked visualizations, visual annotations, and pattern detection to create an environment for analytic exploration and communication, thereby assisting the analyst in identifying, extracting, arranging and presenting stories within the data The story system lets analysts operate at the story level with higher-level abstractions of data, such as behaviors and events, while staying connected to the evidence. The story system was developed and evaluated in collaboration with analysts.",Ryan Eccles;Thomas Kapler;Robert Harper 0002;William Wright,Ryan Eccles;Thomas Kapler;Robert Harper;William Wright,"Oculus Info, Inc., USA;Oculus Info, Inc., USA;Oculus Info, Inc., USA;Oculus Info, Inc., USA",10.1109/infvis.2004.27;10.1109/vast.2006.261436;10.1109/infvis.2004.27,"human information interaction, visual analytics, sense-making, narrative, pattern detection, story making, story telling",0.0,43.0,19.0,940.0,,,temporal event visualization;intelligence analysts conceptualize;story;detects geo;hypertext linked,0.5759;0.4957;0.2619;0.2266;0.1916,"[np.int64(-1), -1, -1, -1, -1]",156;-1;-1;-1;-1,156,156
VAST,2010,"Geo-historical context support for information foraging and sensemaking: Conceptual model, implementation, and assessment",10.1109/vast.2010.5652895,http://dx.doi.org/10.1109/VAST.2010.5652895,139.0,146.0,C,"Information foraging and sensemaking with heterogeneous information are context-dependent activities. Thus visual analytics tools to support these activities must incorporate context. But, context is a difficult concept to define, model, and represent. Creating and representing context in support of visually-enabled reasoning about complex problems with complex information is a complementary but different challenge than that addressed in context-aware computing. In the latter, the goal is automated adaptation of the system to meet user needs for applications such as mobile location-based services where information about the location, the user, and the user goals filters what gets presented on a small mobile device. In contrast, for visual analytics-enabled information foraging and sensemaking, the user is likely to take an active role in foraging for the contextual information needed to support sensemaking in relation to some multifaceted problem. In this paper, we address the challenges of constructing and representing context within visual interfaces that support analytical reasoning in crisis management and humanitarian relief. The challenges stem from the diverse forms of information that can provide context and difficulty in defining and operationalizing context itself. Here, we pay particular attention to document foraging to support construction of the geographic and historical context within which monitoring and sensemaking can be carried out. Specifically, we present the concept of geo-historical context (GHC) and outline an empirical assessment of both the concept and its implementation in the Context Discovery Application, a web-based tool that supports document foraging and sensemaking.",Brian M. Tomaszewski;Alan M. MacEachren,Brian Tomaszewski;Alan M. MacEachren,"Department of Information Sciences and Technologies, Rochester Institute of Technology, Rochester, NY, USA;Department of Geography and GeoVISTA Center, Pennsylvania State University, University Park, PA, USA",,"context, foraging, sensemaking, mapping, text analysis, geographic information retrieval",23.0,10.0,32.0,373.0,,,context monitoring sensemaking;geographic historical;diverse forms information;relief challenges stem;likely,0.6379;0.3356;0.2990;0.1701;0.0268,"[np.int64(-1), -1, -1, -1, -1]",86;-1;-1;-1;-1,86,86
Vis,2001,Continuous topology simplification of planar vector fields,10.1109/visual.2001.964507,http://dx.doi.org/10.1109/VISUAL.2001.964507,159.0,166.0,C,"Vector fields can present complex structural behavior, especially in turbulent computational fluid dynamics. The topological analysis of these data sets reduces the information, but one is usually still left with too many details for interpretation. In this paper, we present a simplification approach that removes pairs of critical points from the data set, based on relevance measures. In contrast to earlier methods, no grid changes are necessary, since the whole method uses small local changes of the vector values defining the vector field. An interpretation in terms of bifurcations underlines the continuous, natural flavor of the algorithm.",Xavier Tricoche;Gerik Scheuermann;Hans Hagen,X. Tricoche;G. Scheuermann;H. Hagen,"Computer Science Department, University of Kaiserslautern, Kaiserslautern, Germany;Computer Science Department, University of Kaiserslautern, Kaiserslautern, Germany;Computer Science Department, University of Kaiserslautern, Kaiserslautern, Germany",10.1109/visual.2000.885716;10.1109/visual.1998.745318;10.1109/visual.1991.175773;10.1109/visual.1999.809907;10.1109/visual.2000.885716,"vector field topology, flow visualization, unstructured grid, simplification",183.0,55.0,10.0,245.0,,,turbulent computational;defining vector field;pairs critical points;topological analysis;relevance measures contrast,0.6324;0.3404;0.3194;0.2567;0.1671,"[np.int64(-1), -1, -1, -1, -1]",66;-1;-1;-1;-1,66,66
InfoVis,2016,booc.io: An Education System with Hierarchical Concept Maps and Dynamic Non-linear Learning Plans,10.1109/tvcg.2016.2598518,http://dx.doi.org/10.1109/TVCG.2016.2598518,571.0,580.0,J,"Information hierarchies are difficult to express when real-world space or time constraints force traversing the hierarchy in linear presentations, such as in educational books and classroom courses. We present booc.io, which allows linear and non-linear presentation and navigation of educational concepts and material. To support a breadth of material for each concept, booc.io is Web based, which allows adding material such as lecture slides, book chapters, videos, and LTIs. A visual interface assists the creation of the needed hierarchical structures. The goals of our system were formed in expert interviews, and we explain how our design meets these goals. We adapt a real-world course into booc.io, and perform introductory qualitative evaluation with students.",Michail Schwab;Hendrik Strobelt;James Tompkin 0001;Colin Fredericks;Connor Huff;Dana Higgins;Anton Strezhnev;Mayya Komisarchik;Gary King;Hanspeter Pfister,Michail Schwab;Hendrik Strobelt;James Tompkin;Colin Fredericks;Connor Huff;Dana Higgins;Anton Strezhnev;Mayya Komisarchik;Gary King;Hanspeter Pfister,Harvard Paulson SEAS;Harvard Paulson SEAS;Harvard Paulson SEAS;HarvardX;Harvard Institute for Quantitative Social Sciences;Harvard Institute for Quantitative Social Sciences;Harvard Institute for Quantitative Social Sciences;Harvard Institute for Quantitative Social Sciences;Harvard Institute for Quantitative Social Sciences;Harvard Paulson SEAS,0.1109/tvcg.2006.147,education;Hierarchies;information visualization,39.0,21.0,37.0,1408.0,,,presentation navigation educational;hierarchies;non linear;material;booc io allows,0.6516;0.3868;0.1959;0.1256;0.1074,"[np.int64(-1), -1, -1, -1, -1]",230;-1;-1;-1;-1,230,230
Vis,1992,Visual query specification in a multimedia database system,10.1109/visual.1992.235208,http://dx.doi.org/10.1109/VISUAL.1992.235208,194.0,201.0,C,"A visual interface for a multimedia database management system (MDBMS) is described. DBMS query languages are linear in syntax. Although natural language interfaces have been found to be useful, natural language is ambiguous and difficult to process. For queries on standard (relational) data, these difficulties can be avoided with the use of a visual, graphical interface to guide the user in specifying the query. For image and other media data which are ambiguous in nature, natural language processing, combined with direct graphical access to the domain knowledge, is used to interpret and evaluate the natural language query. The system fully supports graphical and image input/output in different formats. The combination of visual effect and natural language specification, the support of media data, and the allowance of incremental query specification simplify the process of query specification not only for image or multimedia databases but also for all databases.&lt;&lt;ETX&gt;&gt;",Daniel A. Keim;Vincent Y. Lum,D.A. Keim;V. Lum,"Institut für Informatik, Universität Munchen, Munchen, Germany;Systems Engineering, Chinese University of Hong Kong, Sha Tin, Hong Kong, China",,"Visual Query Specijication, Graphical User Interface, Multimedia Database System, Natural-Language Interface, Information Retrieval, Image Data Management",19.0,1.0,15.0,92.0,,,multimedia database management;interface guide user;specifying query;interpret evaluate natural;combination visual effect,0.6983;0.3490;0.3078;0.2164;0.1808,"[np.int64(-1), -1, -1, -1, -1]",29;-1;-1;-1;-1,29,29
SciVis,2012,Visualization of Astronomical Nebulae via Distributed Multi-GPU Compressed Sensing Tomography,10.1109/tvcg.2012.281,http://dx.doi.org/10.1109/TVCG.2012.281,2188.0,2197.0,J,"The 3D visualization of astronomical nebulae is a challenging problem since only a single 2D projection is observable from our fixed vantage point on Earth. We attempt to generate plausible and realistic looking volumetric visualizations via a tomographic approach that exploits the spherical or axial symmetry prevalent in some relevant types of nebulae. Different types of symmetry can be implemented by using different randomized distributions of virtual cameras. Our approach is based on an iterative compressed sensing reconstruction algorithm that we extend with support for position-dependent volumetric regularization and linear equality constraints. We present a distributed multi-GPU implementation that is capable of reconstructing high-resolution datasets from arbitrary projections. Its robustness and scalability are demonstrated for astronomical imagery from the Hubble Space Telescope. The resulting volumetric data is visualized using direct volume rendering. Compared to previous approaches, our method preserves a much higher amount of detail and visual variety in the 3D visualization, especially for objects with only approximate symmetry.",Stephan Wenger;Marco Ament;Stefan Guthe;Dirk A. Lorenz;Andreas M. Tillmann;Daniel Weiskopf;Marcus A. Magnor,Stephan Wenger;Marco Ament;Stefan Guthe;Dirk Lorenz;Andreas Tillmann;Daniel Weiskopf;Marcus Magnor,"Institut für Computergraphik, Technical University of Braunschweig, Germany;VISUS, University of Stuttgart, Germany;Institut für Computergraphik, Technical University of Braunschweig, Germany;Institute for Analysis and Algebra, Technical University of Braunschweig, Germany;Research Group Optimization, Technical University of Darmstadt, Germany;VISUS, University of Stuttgart, Germany;Institut für Computergraphik, Technical University of Braunschweig, Germany",10.1109/visual.2005.1532803;10.1109/visual.2004.18;10.1109/visual.1994.346331,"Astronomical visualization, distributed volume reconstruction, direct volume rendering",18.0,10.0,38.0,711.0,,,visualization astronomical nebulae;resulting volumetric data;based iterative compressed;symmetry prevalent;regularization linear equality,0.6658;0.4099;0.3893;0.2112;0.1123,"[np.int64(-1), -1, -1, -1, -1]",103;-1;-1;-1;-1,103,103
Vis,2006,Mesh Layouts for Block-Based Caches,10.1109/tvcg.2006.162,http://dx.doi.org/10.1109/TVCG.2006.162,1213.0,1220.0,J,"Current computer architectures employ caching to improve the performance of a wide variety of applications. One of the main characteristics of such cache schemes is the use of block fetching whenever an uncached data element is accessed. To maximize the benefit of the block fetching mechanism, we present novel cache-aware and cache-oblivious layouts of surface and volume meshes that improve the performance of interactive visualization and geometric processing algorithms. Based on a general I/O model, we derive new cache-aware and cache-oblivious metrics that have high correlations with the number of cache misses when accessing a mesh. In addition to guiding the layout process, our metrics can be used to quantify the quality of a layout, e.g. for comparing different layouts of the same mesh and for determining whether a given layout is amenable to significant improvement. We show that layouts of unstructured meshes optimized for our metrics result in improvements over conventional layouts in the performance of visualization applications such as isosurface extraction and view-dependent rendering. Moreover, we improve upon recent cache-oblivious mesh layouts in terms of performance, applicability, and accuracy",Sung-Eui Yoon;Peter Lindstrom 0001,Sung-eui Yoon;Peter Lindstrom,"Lawrence Livemore National Laboratory, USA;Lawrence Livemore National Laboratory, USA",10.1109/visual.2004.86;10.1109/visual.2003.1250408;10.1109/visual.2001.964533;10.1109/visual.1996.568125;10.1109/visual.2005.1532800;10.1109/visual.2002.1183794;10.1109/tvcg.2006.162;10.1109/visual.2004.86,"Mesh and graph layouts, cache-aware and cache-oblivious layouts, metrics for cache coherence, data locality",58.0,35.0,32.0,281.0,,,cache oblivious mesh;isosurface extraction view;quantify quality layout;current computer architectures;element,0.5769;0.4316;0.3483;0.2836;0.0036,"[np.int64(-1), -1, -1, -1, -1]",235;-1;-1;-1;-1,235,235
SciVis,2015,CPU Ray Tracing Large Particle Data with Balanced P-k-d Trees,10.1109/scivis.2015.7429492,http://dx.doi.org/10.1109/SciVis.2015.7429492,57.0,64.0,C,"We present a novel approach to rendering large particle data sets from molecular dynamics, astrophysics and other sources. We employ a new data structure adapted from the original balanced k-d tree, which allows for representation of data with trivial or no overhead. In the OSPRay visualization framework, we have developed an efficient CPU algorithm for traversing, classifying and ray tracing these data. Our approach is able to render up to billions of particles on a typical workstation, purely on the CPU, without any approximations or level-of-detail techniques, and optionally with attribute-based color mapping, dynamic range query, and advanced lighting models such as ambient occlusion and path tracing.",Ingo Wald;Aaron Knoll;Gregory P. Johnson;Will Usher 0001;Valerio Pascucci;Michael E. Papka,Ingo Wald;Aaron Knoll;Gregory P. Johnson;Will Usher;Valerio Pascucci;Michael E. Papka,"Intel Corporation;SCI Institute, University of Utah;Intel Corporation;SCI Institute, University of Utah;SCI Institute, University of Utah;Argonne National Laboratory, Northern Illinois University",10.1109/tvcg.2010.148;10.1109/tvcg.2009.142;10.1109/tvcg.2012.282;10.1109/tvcg.2010.148,"Ray tracing, Visualization, Particle Data, k-d Trees",38.0,22.0,27.0,446.0,,,render billions particles;ospray visualization framework;tracing data;balanced tree;optionally attribute,0.6260;0.4728;0.2322;0.1843;-0.0696,"[np.int64(-1), -1, -1, -1, -1]",34;-1;-1;-1;-1,34,34
InfoVis,1997,Cacti: a front end for program visualization,10.1109/infvis.1997.636785,http://dx.doi.org/10.1109/INFVIS.1997.636785,46.0,49.0,C,"We describe a system that allows the user to rapidly construct program visualizations over a variety of data sources. Such a system is a necessary foundation for using visualization as an aid to software understanding. The system supports an arbitrary set of data sources so that information from both static and dynamic analysis can be combined to offer meaningful software visualizations. It provides the user with a visual universal-relation front end that supports the definition of queries over multiple data sources without knowledge of the structure or contents of the sources. It uses a flexible back end with a range of different visualizations, most geared to the efficient display of large amounts of data. The result is a high-quality, easy-to-define program visualization that can address specific problems and hence is useful for software understanding. The overall system is flexible and extensible in that both the underlying data model and the set of visualizations are defined in resource files.",Steven P. Reiss,S.P. Reiss,"Department of Computer Science, Brown University, Providence, RI, USA",10.1109/infvis.1996.559210;10.1109/infvis.1996.559210,,24.0,4.0,24.0,131.0,,,software visualizations;definition queries;defined resource files;end range different;necessary foundation,0.7378;0.3047;0.2636;0.0593;0.0144,"[np.int64(-1), -1, -1, -1, -1]",196;-1;-1;-1;-1,196,196
Vis,1995,An architecture for retaining and analyzing visual explorations of databases,10.1109/visual.1995.480801,http://dx.doi.org/10.1109/VISUAL.1995.480801,101.0,108.0,C,"A software architecture is presented to integrate a database management system with data visualization. One of its primary objectives, the retention of user-data interactions, is detailed. By storing all queries over the data along with high-level descriptions of the query results and the associated visualization, the processes by which a database is explored can be analyzed. This approach can lead to important contributions in the development of user models as ""data explorers"", metadata models for scientific databases, intelligent assistants and data exploration services. We describe the underlying elements of this approach, specifically the visual database exploration model and the metadata objects that support the model.",John Peter Lee;Georges G. Grinstein,J.P. Lee;G.G. Grinstein,"Institute for Visualization and Perception Research, University of Massachusetts, Lowell, Lowell, MA, USA;Institute for Visualization and Perception Research, University of Massachusetts, Lowell, Lowell, MA, USA and MITRE Corporation, Bedford, MA, USA",10.1109/visual.1994.346304;10.1109/visual.1994.346303;10.1109/visual.1990.146375;10.1109/visual.1992.235203;10.1109/visual.1993.398874;10.1109/visual.1993.398857;10.1109/visual.1994.346304,"visual database exploration, database visualization, metadata, user modeling, interaction",58.0,17.0,23.0,108.0,,,visual database exploration;intelligent assistants data;metadata objects support;storing;important contributions,0.7841;0.3812;0.3578;0.1818;0.0437,"[np.int64(-1), -1, -1, -1, -1]",268;-1;-1;-1;-1,268,268
VAST,2009,Interactive visual analysis of location reporting patterns,10.1109/vast.2009.5333453,http://dx.doi.org/10.1109/VAST.2009.5333453,223.0,224.0,M,Interactive visualization methods are often used to aid in the analysis of large datasets. We present a novel interactive visualization technique designed specifically for the analysis of location reporting patterns within large time-series datasets. We use a set of triangles with color coding to indicate the time between location reports. This allows reporting patterns (expected and unexpected) to be easily discerned during interactive analysis. We discuss the details of our method and describe evaluation both from expert opinion and from a user study.,Derek Overby;John Keyser;Jim Wall,Derek Overby;John Keyser;Jim Wall,"Department of Computer Science and Engineering, Texas A and M University, USA;Department of Computer Science and Engineering, Texas A and M University, USA;Department of Industrial and Systems Engineering, Texas A and M University, USA",0.1109/vast.2006.261428,,4.0,0.0,4.0,112.0,,,location reporting patterns;discerned interactive analysis;series;set triangles color;time,0.5877;0.3708;0.1712;0.1362;0.1252,"[np.int64(-1), -1, -1, -1, -1]",236;-1;-1;-1;-1,236,236
Vis,1992,A characterization of the scientific data analysis process,10.1109/visual.1992.235203,http://dx.doi.org/10.1109/VISUAL.1992.235203,235.0,242.0,C,"It is shown how data visualization fits into the broader process of scientific data analysis. Scientists from several disciplines were observed while they analyzed their own data. Examination of the observations exposed process elements outside conventional image viewing. For example, analysts queried for quantitative information, made a variety of comparisons, applied math, managed data, and kept records. The characterization of scientific data analysis reveals activity beyond that traditionally supported by computer. It offers an understanding which has the potential to be applied to many future designs, and suggests specific recommendations for improving the support of this important aspect of scientific computing.&lt;&lt;ETX&gt;&gt;",R. R. Springmeyer;Meera Blattner;Nelson L. Max,R.R. Springmeyer;M.M. Blattner;N.L. Max,"Lawrence Livermore National Laboratory, University of California, Livermore, CA, USA;Lawrence Livermore National Laboratory, University of California, Livermore, CA, USA;Lawrence Livermore National Laboratory, University of California, Livermore, CA, USA",10.1109/visual.1990.146399,,167.0,45.0,15.0,183.0,,,scientific data analysis;reveals activity;outside conventional image;understanding potential;lt lt etx,0.6852;0.1869;0.1673;0.1467;0.0583,"[np.int64(-1), -1, -1, -1, -1]",281;-1;-1;-1;-1,281,281
Vis,1999,Visualizing Planar Vector Fields with Normal Component Using Line Integral Convolution,10.1109/visual.1999.809895,http://doi.ieeecomputersociety.org/10.1109/VISUAL.1999.809895,255.0,261.0,C,"We present a method for visualizing three dimensional vector fields which are defined on a two dimensional manifold only. These vector fields do exist in real application, as we show by an example of an optical measuring instrument which can gauge the displacement at the surface of a mechanical part. The general idea is to compute LIC textures in the manifold's tangent space and to deform the manifold according to the normal information. The resulting LIC texture is mapped onto the deformed manifold and is rendered as a three dimensional scene. Due to the light's reflection on the deformed manifold, one can interactively explore the result of the deformation.",Gerik Scheuermann;Holger Burbach;Hans Hagen,G. Scheuermann;H. Barbach;H. Hagen,"Technische Universität Kaiserslautern, Kaiserslautern, Rheinland-Pfalz, DE;Technische Universität Kaiserslautern, Kaiserslautern, Rheinland-Pfalz, DE;Technische Universität Kaiserslautern, Kaiserslautern, Rheinland-Pfalz, DE",10.1109/visual.1994.346312;10.1109/visual.1994.346313;10.1109/visual.1990.146360;10.1109/visual.1998.745324,"LIC, vector field visualization, deformation",30.0,6.0,0.0,26.0,,,deformed manifold interactively;lic textures;vector;measuring instrument;fields exist real,0.6086;0.3148;0.2274;0.1729;0.0913,"[np.int64(-1), -1, -1, -1, -1]",5;-1;-1;-1;-1,5,5
InfoVis,1998,IVORY-an object-oriented framework for physics-based information visualization in Java,10.1109/infvis.1998.729562,http://dx.doi.org/10.1109/INFVIS.1998.729562,79.0,,C,"We present IVORY a newly developed, platform-independent framework for physics based visualization. IVORY is especially designed for information visualization applications and multidimensional graph layout. It is fully implemented in Java 1.1 and its architecture features client server setup, which allows us to run the visualization even on thin clients. In addition, VRML 2.0 exports can be viewed by any VRML plugged-in WWW browser. Individual visual metaphors are invoked into IVORY via an advanced plug-in mechanism, where plug-ins can be implemented by any experienced user. The configuration of IVORY is accomplished using a script language, called IVML. Some interactive visualization examples, such as the integration of a haptic interface illustrate the performance and versatility of our system. Our current implementation supports NT 4.0.",Thomas C. Sprenger;Markus H. Gross;Daniel Bielser;Tobias Strasser,T.C. Sprenger;M.H. Gross;D. Bielser;T. Strasser,"Department of Computer Science, Swiss Federal Institute of Technology, Zurich, Switzerland;Department of Computer Science, Swiss Federal Institute of Technology, Zurich, Switzerland;Department of Computer Science, Swiss Federal Institute of Technology, Zurich, Switzerland;Department of Computer Science, Swiss Federal Institute of Technology, Zurich, Switzerland",10.1109/infvis.1995.528691;10.1109/visual.1996.567752;10.1109/infvis.1997.636759;10.1109/infvis.1995.528688;10.1109/infvis.1996.559226;10.1109/infvis.1995.528691,"three-dimensional information visualization,physics-based graph layout, object-oriented visualization toolkit,multidimensional information modeling, time varying data",31.0,6.0,26.0,89.0,,,ivml interactive visualization;framework physics;supports nt;script;ivory newly developed,0.6468;0.2724;0.1701;0.1420;0.0344,"[np.int64(-1), -1, -1, -1, -1]",319;-1;-1;-1;-1,319,319
Vis,2005,Curve-skeleton applications,10.1109/visual.2005.1532783,http://dx.doi.org/10.1109/VISUAL.2005.1532783,95.0,102.0,C,"Curve-skeletons are a 1D subset of the medial surface of a 3D object and are useful for many visualization tasks including virtual navigation, reduced-model formulation, visualization improvement, mesh repair, animation, etc. There are many algorithms in the literature describing extraction methodologies for different applications; however, it is unclear how general and robust they are. In this paper, we provide an overview of many curve-skeleton applications and compile a set of desired properties of such representations. We also give a taxonomy of methods and analyze the advantages and drawbacks of each class of algorithms.",Nicu D. Cornea;Deborah Silver;Patrick Min,N.D. Cornea;D. Silver;P. Min,"Rutgers University, NJ, USA;Rutgers University, NJ, USA;John Cabot University, Rome, Italy",10.1109/visual.2004.34;10.1109/visual.2004.104;10.1109/visual.2002.1183754;10.1109/visual.1994.346327;10.1109/visual.1999.809912;10.1109/visual.2003.1250353;10.1109/visual.2001.964517;10.1109/visual.2004.34,"skeleton, curve-skeleton",133.0,20.0,97.0,728.0,,,curve skeletons 1d;subset medial surface;reduced model formulation;literature describing extraction;including virtual navigation,0.6498;0.3541;0.2026;0.1960;0.1847,"[np.int64(-1), -1, -1, -1, -1]",33;-1;-1;-1;-1,33,33
Vis,2003,Space efficient fast isosurface extraction for large datasets,10.1109/visual.2003.1250373,http://dx.doi.org/10.1109/VISUAL.2003.1250373,201.0,208.0,C,"In this paper, we present a space efficient algorithm for speeding up isosurface extraction. Even though there exist algorithms that can achieve optimal search performance to identify isosurface cells, they prove impractical for large datasets due to a high storage overhead. With the dual goals of achieving fast isosurface extraction and simultaneously reducing the space requirement, we introduce an algorithm based on transform coding to compress the interval information of the cells in a dataset. Compression is achieved by first transforming the cell intervals (minima, maxima) into a form which allows more efficient compaction. It is followed by a dataset optimized non-uniform quantization stage. The compressed data is stored in a data structure that allows fast searches in the compression domain, thus eliminating the need to retrieve the original representation of the intervals at run-time. The space requirement of our search data structure is the mandatory cost of storing every cell ID once, plus an overhead for quantization information. The overhead is typically in the order of a few hundredths of the dataset size.",Udeepta Bordoloi;Han-Wei Shen,U.D. Bordoloi;Han-Wei Shen,"Department of Computer and Information Science, Ohio State Uinversity, USA;Department of Computer and Information Science, Ohio State Uinversity, USA",10.1109/visual.1998.745299;10.1109/visual.1997.663895;10.1109/visual.1996.568121;10.1109/visual.1991.175780;10.1109/visual.1995.480806;10.1109/visual.1998.745299," Isosurface, Compression, Transform Coding, Quantization",43.0,5.0,15.0,88.0,,,fast isosurface extraction;cells dataset compression;retrieve original;interval;overhead dual goals,0.7021;0.5225;0.1013;0.0977;0.0485,"[np.int64(-1), np.int64(-1), -1, -1, -1]",91;42;-1;-1;-1,42;91,91
Vis,2022,Breaking the Fourth Wall of Data Stories through Interaction,10.1109/tvcg.2022.3209409,http://dx.doi.org/10.1109/TVCG.2022.3209409,972.0,982.0,J,"Interaction is increasingly integrating into data stories to support data exploration and explanation. Interaction can also be combined with the narrative device, breaking the fourth wall (BTFW), to build a deeper connection between readers and data stories. BTFW interaction directly addresses readers by requiring their input. Such user input is then integrated into the narrative or visuals of data stories to encourage readers to inspect the stories more closely. In this work, we explore the design patterns of BTFW interaction commonly used in data stories. Six design patterns were identified through the analysis of 58 high-quality data stories collected from a range of online sources. Specifically, the data stories were categorized using a coding framework, including the input of BTFW interaction provided by readers and the output of BTFW interaction generated by data stories to respond to the input. To explore the benefits as well as concerns of using BTFW interaction, we conducted a three-session user study including the reading, interview, and recall sessions. The results of our user study suggested that BTFW interaction has a positive impact on self-story connection, user engagement, and information recall. We also discussed design implications to address the possible negative effects on the interactivity-comprehensibility balance, information privacy, and the learning curve of interaction brought by BTFW interaction.",Yang Shi 0007;Tian Gao;Xiaohan Jiao;Nan Cao 0001,Yang Shi;Tian Gao;Xiaohan Jiao;Nan Cao,"Intelligent Big Data Visualization Lab, Tongji University, China;Intelligent Big Data Visualization Lab, Tongji University, China;Intelligent Big Data Visualization Lab, Tongji University, China;Intelligent Big Data Visualization Lab, Tongji University, China",10.1109/tvcg.2015.2467201;10.1109/tvcg.2013.124;10.1109/tvcg.2019.2934283;10.1109/tvcg.2013.130;10.1109/tvcg.2013.120;10.1109/tvcg.2010.179;10.1109/tvcg.2007.70515;10.1109/tvcg.2015.2467201;10.1109/tvcg.2021.3114849,"Interaction,data-driven storytelling,narrative devices",,6.0,78.0,1252.0,HM,,readers data stories;interaction generated;explanation;device breaking fourth;wall btfw,0.7015;0.2481;0.2370;0.2184;0.1407,"[np.int64(-1), -1, -1, -1, -1]",124;-1;-1;-1;-1,124,124
Vis,1991,Golf green visualization,10.1109/visual.1991.175787,http://dx.doi.org/10.1109/VISUAL.1991.175787,116.0,,C,"Television coverage of golf fails to bring the viewer an appreciation of the complex topography of a golf green and how that topography affects the putting of golf balls. A computer graphics simulation that enhances the viewer's perception of these features using shaded polygonal models of the actual golf green used in tournaments is presented. Mathematical modeling of the golf ball's trajectory on its way toward the hole further enhances viewer understanding. A putting difficulty map assesses the relative difficulty of putting from each location on the green to a given pin position. The object-oriented system is written in C and runs on a variety of 3D graphics workstations. As an experiment, the system was used at a professional golf tournament and correctly simulated all putts during the final round.&lt;&lt;ETX&gt;&gt;",William E. Lorensen;Boris Yamrom,W.E. Lorensen;B. Yamron,"Corporate Research and Development, General Electric Company Limited, Schenectady, NY, USA;General Electric Co., Schenectady, NY, USA",,,28.0,1.0,14.0,100.0,,,modeling golf;3d graphics workstations;using shaded polygonal;topography affects;fails bring viewer,0.7296;0.3496;0.3347;0.2704;0.0395,"[np.int64(-1), -1, -1, -1, -1]",300;-1;-1;-1;-1,300,300
Vis,1997,A topology modifying progressive decimation algorithm,10.1109/visual.1997.663883,http://dx.doi.org/10.1109/VISUAL.1997.663883,205.0,212.0,C,"Triangle decimation techniques reduce the number of triangles in a mesh, typically to improve interactive rendering performance or reduce data storage and transmission requirements. Most of these algorithms are designed to preserve the original topology of the mesh. Unfortunately, this characteristic is a strong limiting factor in overall reduction capability, since objects with a large number of holes or other topological constraints cannot be effectively reduced. The author presents an algorithm that yields a guaranteed reduction level, modifying topology as necessary to achieve the desired result. In addition, the algorithm is based on a fast local decimation technique, and its operations can be encoded for progressive storage, transmission, and reconstruction. He describes the new progressive decimation algorithm, introduces mesh splitting operations and shows how they can be encoded as a progressive mesh. He also demonstrates the utility of the algorithm on models ranging in size from 1,132 to 1.68 million triangles and reduction ratios of up to 200:1.",William J. Schroeder,W.J. Schroeder,"GE Corporate Research and Development Center, USA",10.1109/visual.1995.485142;10.1109/visual.1993.398868;10.1109/visual.1996.568124;10.1109/visual.1995.485142,,196.0,45.0,12.0,191.0,,,triangle decimation techniques;original topology mesh;data storage transmission;million;describes new progressive,0.6927;0.4503;0.1213;0.0928;0.0247,"[np.int64(-1), -1, -1, -1, -1]",102;-1;-1;-1;-1,102,102
VAST,2007,Visual Analytics Approach to User-Controlled Evacuation Scheduling,10.1109/vast.2007.4388995,http://dx.doi.org/10.1109/VAST.2007.4388995,43.0,50.0,C,"Application of the ideas of visual analytics is a promising approach to supporting decision making, in particular, where the problems have geographic (or spatial) and temporal aspects. Visual analytics may be especially helpful in time-critical applications, which pose hard challenges to decision support. We have designed a suite of tools to support transportation-planning tasks such as emergency evacuation of people from a disaster- affected area. The suite combines a tool for automated scheduling based on a genetic algorithm with visual analytics techniques allowing the user to evaluate tool results and direct its work. A transportation schedule, which is generated by the tool, is a complex construct involving geographical space, time, and heterogeneous objects (people and vehicles) with states and positions varying in time. We apply task-analytical approach to design techniques that could effectively support a human planner in the analysis of this complex information H. 1.2 [User/Machine Systems]: Human information processing - Visual Analytics; 1.6.9 [Visualization]: information visualization.",Gennady L. Andrienko;Natalia V. Andrienko;Ulrich Bartling,Gennady Andrienko;Natalia Andrienko;Ulrich Bartling,"Fraunhofer Institute of Intelligent Analysis and Information Systems (IAIS), Germany;Fraunhofer Institute of Intelligent Analysis and Information Systems (IAIS), Germany;Fraunhofer Institute of Intelligent Analysis and Information Systems (IAIS), Germany",,"Geovisualization, transportation planning, vehicle scheduling, task-centered design, coordinated multiple views",32.0,5.0,16.0,304.0,,,support transportation planning;varying time apply;genetic;evaluate tool results;applications pose hard,0.6015;0.2313;0.2304;0.1369;0.1249,"[np.int64(-1), -1, -1, -1, -1]",236;-1;-1;-1;-1,236,236
Vis,2004,Interactive point-based isosurface extraction,10.1109/visual.2004.52,http://dx.doi.org/10.1109/VISUAL.2004.52,457.0,464.0,C,"We propose a novel point-based approach to view dependent isosurface extraction. We introduce a fast visibility query system for the view dependent traversal, which exhibits moderate memory requirements. This technique allows for an interactive interrogation of the full visible woman dataset (1GB) at four to fifteen frames per second on a desktop computer. The point-based approach is built on an extraction scheme that classifies different sections of the isosurface into four categories, depending on the size of the geometry when projected onto the screen. In particular, we use points to represent small and subpixel triangles, as well as larger sections of the isosurface whose projection has subpixel size. To assign consistent and robust normals to individual points representing such regions, we propose to compute them during post processing of the extracted isosurface and provide the corresponding hardware implementation.",Yarden Livnat;Xavier Tricoche,Y. Livnat;X. Tricoche,"Scientific Computing and Imaging Institute, University of Utah, USA;Scientific Computing and Imaging Institute, University of Utah, USA",10.1109/visual.1998.745713;10.1109/visual.1998.745299;10.1109/visual.1997.663895;10.1109/visual.1995.480806;10.1109/visual.1996.568123;10.1109/visual.2002.1183810;10.1109/visual.1991.175780;10.1109/visual.1998.745300;10.1109/visual.1994.346334;10.1109/visual.1998.745713,"Isosurface, point-based, view-dependent, large datasets, interactive",64.0,16.0,30.0,107.0,,,view dependent isosurface;visible woman dataset;built extraction scheme;moderate memory requirements;point,0.6304;0.4580;0.2500;0.0924;0.0582,"[np.int64(-1), -1, -1, -1, -1]",229;-1;-1;-1;-1,229,229
InfoVis,2004,WilmaScope Graph Visualisation,10.1109/infvis.2004.77,http://dx.doi.org/10.1109/INFVIS.2004.77,,,M,"Our visualisation of the IEEE InfoVis citation network is based on 3D graph visualisation techniques. To make effective use of the third dimension we use a layered approach, constraining nodes to lie on parallel planes depending on parameters such as year of publication or link degree. Within the parallel planes nodes are arranged using a fast force-directed layout method. A number of clusters representing different research areas were identified using a self organising map approach.",Adel Ahmed;Tim Dwyer;Colin Murray;Le Song;Ying Xin Wu,A. Ahmed;T. Dwyer;C. Murray;Le Song;Ying Xin Wu,"School of Information Technologies, University of Sydney, Australia;School of Information Technologies, University of Sydney, Australia;School of Information Technologies, University of Sydney, Australia;School of Information Technologies, University of Sydney, Australia;School of Information Technologies, University of Sydney, Australia",,,28.0,5.0,7.0,238.0,,,3d graph visualisation;ieee infovis citation;self organising;using fast force;lie,0.6106;0.4344;0.2448;0.0495;-0.0524,"[np.int64(-1), -1, -1, -1, -1]",-1;-1;-1;-1;-1,,-1
Vis,2021,KD-Box: Line-segment-based KD-tree for Interactive Exploration of Large-scale Time-Series Data,10.1109/tvcg.2021.3114865,http://dx.doi.org/10.1109/TVCG.2021.3114865,890.0,900.0,J,"Time-series data-usually presented in the form of lines-plays an important role in many domains such as finance, meteorology, health, and urban informatics. Yet, little has been done to support interactive exploration of large-scale time-series data, which requires a clutter-free visual representation with low-latency interactions. In this paper, we contribute a novel line-segment-based KD-tree method to enable interactive analysis of many time series. Our method enables not only fast queries over time series in selected regions of interest but also a line splatting method for efficient computation of the density field and selection of representative lines. Further, we develop KD-Box, an interactive system that provides rich interactions, e.g., timebox, attribute filtering, and coordinated multiple views. We demonstrate the effectiveness of KD-Box in supporting efficient line query and density field computation through a quantitative comparison and show its usefulness for interactive visual analysis on several real-world datasets.",Yue Zhao;Yunhai Wang;Jian Zhang 0070;Chi-Wing Fu;Mingliang Xu;Dominik Moritz,Yue Zhao;Yunhai Wang;Jian Zhang;Chi-Wing Fu;Mingliang Xu;Dominik Moritz,"Shandong University, Qingdao, China;Shandong University, Qingdao, China;CNIC, CAS., United States;Chinese University of Hong Kong, China;Zhengzhou University, China;Carnegie Mellon University, United States",10.1109/infvis.2004.68;10.1109/tvcg.2011.226;10.1109/vast.2008.4677357;10.1109/tvcg.2010.176;10.1109/tvcg.2010.162;10.1109/tvcg.2013.179;10.1109/tvcg.2014.2346452;10.1109/visual.2005.1532779;10.1109/tvcg.2006.170;10.1109/tvcg.2011.181;10.1109/infvis.1999.801851;10.1109/infvis.2001.963273;10.1109/tvcg.2011.195,"Many time series,density-based visualization,interactive visualization for large-scale data",4.0,30.0,58.0,1225.0,,,interactive visual analysis;timebox attribute;density field computation;meteorology health;kd,0.5855;0.2511;0.2271;0.1611;0.1219,"[np.int64(-1), -1, -1, -1, -1]",318;-1;-1;-1;-1,318,318
Vis,2011,iView: A Feature Clustering Framework for Suggesting Informative Views in Volume Visualization,10.1109/tvcg.2011.218,http://dx.doi.org/10.1109/TVCG.2011.218,1959.0,1968.0,J,"The unguided visual exploration of volumetric data can be both a challenging and a time-consuming undertaking. Identifying a set of favorable vantage points at which to start exploratory expeditions can greatly reduce this effort and can also ensure that no important structures are being missed. Recent research efforts have focused on entropy-based viewpoint selection criteria that depend on scalar values describing the structures of interest. In contrast, we propose a viewpoint suggestion pipeline that is based on feature-clustering in high-dimensional space. We use gradient/normal variation as a metric to identify interesting local events and then cluster these via k-means to detect important salient composite features. Next, we compute the maximum possible exposure of these composite feature for different viewpoints and calculate a 2D entropy map parameterized in longitude and latitude to point out promising view orientations. Superimposed onto an interactive track-ball interface, users can then directly use this entropy map to quickly navigate to potentially interesting viewpoints where visibility-based transfer functions can be employed to generate volume renderings that minimize occlusions. To give full exploration freedom to the user, the entropy map is updated on the fly whenever a view has been selected, pointing to new and promising but so far unseen view directions. Alternatively, our system can also use a set-cover optimization algorithm to provide a minimal set of views needed to observe all features. The views so generated could then be saved into a list for further inspection or into a gallery for a summary presentation.",Ziyi Zheng;Nafees U. Ahmed;Klaus Mueller 0001,Ziyi Zheng;Nafees Ahmed;Klaus Mueller,"Visual Analytics and Imaging (VAI) Laboratory, Center for Visual Computing, Computer Science Department, Stony Brook University, NY, USA;Visual Analytics and Imaging (VAI) Laboratory, Center for Visual Computing, Computer Science Department, Stony Brook University, NY, USA;Visual Analytics and Imaging (VAI) Laboratory, Center for Visual Computing, Computer Science Department, Stony Brook University, NY, USA",10.1109/tvcg.2009.156;10.1109/tvcg.2007.70576;10.1109/tvcg.2008.162;10.1109/tvcg.2008.159;10.1109/tvcg.2010.214;10.1109/tvcg.2009.172;10.1109/visual.2005.1532833;10.1109/visual.2005.1532818;10.1109/tvcg.2006.124;10.1109/tvcg.2009.185;10.1109/tvcg.2009.189;10.1109/visual.2003.1250414;10.1109/visual.2005.1532834;10.1109/tvcg.2009.156,"Direct volume rendering, k-means, entropy, view suggestion, set-cover problem, ant colony optimization",31.0,18.0,42.0,833.0,,,visual exploration volumetric;local events cluster;cover optimization algorithm;directly use entropy;map parameterized longitude,0.6591;0.2753;0.2236;0.2055;0.1655,"[np.int64(-1), -1, -1, -1, -1]",84;-1;-1;-1;-1,84,84
VAST,2009,Merging visual analysis with automated reasoning: Using Prajna to solve the traffic challenge,10.1109/vast.2009.5332481,http://dx.doi.org/10.1109/VAST.2009.5332481,,,M,"The Internet traffic challenge required the development of a custom application to analyze internet traffic patterns coupled with building access records. To solve this challenge, the author applied the Prajna Project, an open-source Java toolkit designed to provide various capabilities for visualization, knowledge representation, semantic reasoning, and data fusion. By applying some of the capabilities of Prajna to this challenge, the author could quickly develop a custom application for visual analysis. The author determined that he could solve some of the analytical components of this challenge using automated reasoning techniques. Prajna includes interfaces to incorporate automated reasoners into visual applications. By blending the automated reasoning processes with visual analysis, the author could design a flexible, useful application to solve this challenge.",Edward Swing,Edward Swing,"Vision Systems & Technology, Inc., USA",0.1109/vast.2006.261430,,0.0,0.0,4.0,118.0,,,analyze internet traffic;knowledge representation semantic;applications blending automated;building access;techniques prajna includes,0.5840;0.3422;0.2991;0.2508;0.1370,"[np.int64(-1), -1, -1, -1, -1]",64;-1;-1;-1;-1,64,64
Vis,1995,3D computational steering with parametrized geometric objects,10.1109/visual.1995.485143,http://dx.doi.org/10.1109/VISUAL.1995.485143,304.0,,C,"Computational steering is the ultimate goal of interactive simulation: researchers change parameters of their simulation and immediately receive feedback on the effect. We present a general and flexible graphics tool that is part of an environment for computational steering developed at CWI. It enables the researcher to interactively develop his own interface with the simulation. This interface is constructed with 3D parametrized geometric objects. The properties of the objects are parametrized to output data and input parameters of the simulation. The objects visualize the output of the simulation, while the researcher can steer the simulation by direct manipulation of the objects. Several applications of 3D computational steering are presented.",Jurriaan D. Mulder;Jarke J. van Wijk,J.D. Mulder;J.J. van Wijk,"Centre for Mathematics,Computer Science, CWI, Amsterdam, Netherlands;Netherlands Energy Research, Foundation ECN, Petten, Netherlands",10.1109/visual.1991.175812;10.1109/visual.1993.398895;10.1109/visual.1990.146382;10.1109/visual.1991.175812,,,12.0,16.0,72.0,,,interactive simulation;steering developed cwi;3d parametrized geometric;researchers change;objects properties objects,0.6247;0.4493;0.3244;0.1039;0.0807,"[np.int64(-1), -1, -1, -1, -1]",218;-1;-1;-1;-1,218,218
Vis,2021,KG4Vis: A Knowledge Graph-Based Approach for Visualization Recommendation,10.1109/tvcg.2021.3114863,http://dx.doi.org/10.1109/TVCG.2021.3114863,195.0,205.0,J,"Visualization recommendation or automatic visualization generation can significantly lower the barriers for general users to rapidly create effective data visualizations, especially for those users without a background in data visualizations. However, existing rule-based approaches require tedious manual specifications of visualization rules by visualization experts. Other machine learning-based approaches often work like black-box and are difficult to understand why a specific visualization is recommended, limiting the wider adoption of these approaches. This paper fills the gap by presenting KG4Vis, a knowledge graph (KG)-based approach for visualization recommendation. It does not require manual specifications of visualization rules and can also guarantee good explainability. Specifically, we propose a framework for building knowledge graphs, consisting of three types of entities (i.e., data features, data columns and visualization design choices) and the relations between them, to model the mapping rules between data and effective visualizations. A TransE-based embedding technique is employed to learn the embeddings of both entities and relations of the knowledge graph from existing dataset-visualization pairs. Such embeddings intrinsically model the desirable visualization rules. Then, given a new dataset, effective visualizations can be inferred from the knowledge graph with semantically meaningful rules. We conducted extensive evaluations to assess the proposed approach, including quantitative comparisons, case studies and expert interviews. The results demonstrate the effectiveness of our approach.",Haotian Li 0001;Yong Wang 0021;Songheng Zhang;Yangqiu Song;Huamin Qu,Haotian Li;Yong Wang;Songheng Zhang;Yangqiu Song;Huamin Qu,"Hong Kong University of Science and Technology and Singapore Management University, Hong Kong;Singapore Management University, Singapore;Singapore Management University, Singapore;Hong Kong University of Science and Technology, Hong Kong;Hong Kong University of Science and Technology, Hong Kong",10.1109/tvcg.2011.185;10.1109/tvcg.2020.3030338;10.1109/tvcg.2019.2934810;10.1109/tvcg.2020.3030469;10.1109/tvcg.2007.70594;10.1109/tvcg.2018.2864812;10.1109/tvcg.2018.2865240;10.1109/tvcg.2015.2467091;10.1109/tvcg.2019.2934798;10.1109/tvcg.2015.2467191;10.1109/tvcg.2020.3030423;10.1109/tvcg.2011.185,"Data visualization,Visualization recommendation,Knowledge graph",17.0,69.0,60.0,3452.0,HM,,visualization recommendation automatic;building knowledge graphs;model mapping rules;lower barriers;employed,0.7211;0.4235;0.2265;0.1271;0.0478,"[np.int64(-1), -1, -1, -1, -1]",264;-1;-1;-1;-1,264,264
InfoVis,2017,Nonlinear Dot Plots,10.1109/tvcg.2017.2744018,http://dx.doi.org/10.1109/TVCG.2017.2744018,616.0,625.0,J,"Conventional dot plots use a constant dot size and are typically applied to show the frequency distribution of small data sets. Unfortunately, they are not designed for a high dynamic range of frequencies. We address this problem by introducing nonlinear dot plots. Adopting the idea of nonlinear scaling from logarithmic bar charts, our plots allow for dots of varying size so that columns with a large number of samples are reduced in height. For the construction of these diagrams, we introduce an efficient two-way sweep algorithm that leads to a dense and symmetrical layout. We compensate aliasing artifacts at high dot densities by a specifically designed low-pass filtering method. Examples of nonlinear dot plots are compared to conventional dot plots as well as linear and logarithmic histograms. Finally, we include feedback from an expert review.",Nils Rodrigues;Daniel Weiskopf,Nils Rodrigues;Daniel Weiskopf,"VISUS, University of Stuttgart, Germany;VISUS, University of Stuttgart, Germany",10.1109/tvcg.2016.2598592;10.1109/tvcg.2014.2346428;10.1109/tvcg.2010.197;10.1109/tvcg.2011.160;10.1109/tvcg.2009.127;10.1109/tvcg.2016.2598592,"Nonlinear dot plot,statistical graphics,sweep algorithm,layout",14.0,10.0,38.0,1146.0,,,dot plots;scaling logarithmic bar;high dynamic range;efficient way sweep;allow,0.6524;0.3162;0.2999;0.1873;-0.0262,"[np.int64(-1), -1, -1, -1, -1]",152;-1;-1;-1;-1,152,152
Vis,2005,Prefiltered Gaussian reconstruction for high-quality rendering of volumetric data sampled on a body-centered cubic grid,10.1109/visual.2005.1532810,http://dx.doi.org/10.1109/VISUAL.2005.1532810,311.0,318.0,C,"In this paper a novel high-quality reconstruction scheme is presented. Although our method is mainly proposed to reconstruct volumetric data sampled on an optimal body-centered cubic (BCC) grid, it can be easily adapted lo the conventional regular rectilinear grid as well. The reconstruction process is decomposed into two steps. The first step, which is considered to be a preprocessing, is a discrete Gaussian deconvolution performed only once in the frequency domain. Afterwards, the second step is a spatial-domain convolution with a truncated Gaussian kernel, which is used to interpolate arbitrary samples for ray casting. Since the preprocessing is actually a discrete prefiltering, we call our technique prefiltered Gaussian reconstruction (PGR). It is shown that the impulse response of PGR well approximates the ideal reconstruction kernel. Therefore the quality of PGR is much higher than that of previous reconstruction techniques proposed for optimally sampled data, which are based on linear and cubic box splines adapted to the BCC grid. Concerning the performance, PGR is slower than linear box-spline reconstruction but significantly faster than cubic box-spline reconstruction.",Balázs Csébfalvi,B. Csebfalvi,"Department of Control Engineering and Information Technology, Budapest University슠of슠Technology슠and슠Economics, Hungary",10.1109/visual.2004.70;10.1109/visual.2004.65;10.1109/visual.2001.964498;10.1109/visual.1997.663848;10.1109/visual.1994.346331;10.1109/visual.2001.964499;10.1109/visual.2004.70,"Body-Centered Cubic Grid, Reconstruction, Optimal Regular Volume Sampling, Radial Basis Function Interpolation",44.0,8.0,31.0,123.0,,,rectilinear grid reconstruction;ray casting;actually discrete prefiltering;optimal body;performed frequency,0.6068;0.3573;0.2413;0.1725;0.0011,"[np.int64(-1), -1, -1, -1, -1]",102;-1;-1;-1;-1,102,102
Vis,2005,Topology-based simplification for feature extraction from 3D scalar fields,10.1109/visual.2005.1532839,http://dx.doi.org/10.1109/VISUAL.2005.1532839,535.0,542.0,C,"In this paper, we present a topological approach for simplifying continuous functions defined on volumetric domains. We introduce two atomic operations that remove pairs of critical points of the function and design a combinatorial algorithm that simplifies the Morse-Smale complex by repeated application of these operations. The Morse-Smale complex is a topological data structure that provides a compact representation of gradient flow between critical points of a function. Critical points paired by the Morse-Smale complex identify topological features and their importance. The simplification procedure leaves important critical points untouched, and is therefore useful for extracting desirable features. We also present a visualization of the simplified topology.",Attila Gyulassy;Vijay Natarajan;Valerio Pascucci;Peer-Timo Bremer;Bernd Hamann,A. Gyulassy;Vijay Natarajan,"Dept. of Comput. Sci., California Univ., Davis, CA, USA;Dept. of Comput. Sci., California Univ., Davis, CA, USA;Center for Applied Scientific Computing, Lawrence Livermore National Laboratory, Livermore, CA, USA;Dept. of Computer Science, University of Illinois, Urbana Champaign, IL, USA;Dept. of Comput. Sci., California Univ., Davis, CA, USA",10.1109/visual.1999.809907;10.1109/visual.2000.885680;10.1109/visual.2004.96;10.1109/visual.2001.964507;10.1109/visual.1999.809907,"Morse theory, Morse-Smale complexes, computational topology, multiresolution, simplification, feature detection, 3D scalar fields",161.0,24.0,22.0,377.0,,,topological approach simplifying;representation gradient flow;critical points function;defined volumetric;design combinatorial algorithm,0.5800;0.3982;0.3170;0.2695;0.1801,"[np.int64(-1), -1, -1, -1, -1]",10;-1;-1;-1;-1,10,10
InfoVis,2004,Dynamic Drawing of Clustered Graphs,10.1109/infvis.2004.18,http://dx.doi.org/10.1109/INFVIS.2004.18,191.0,198.0,C,This paper presents an algorithm for drawing a sequence of graphs that contain an inherent grouping of their vertex set into clusters. It differs from previous work on dynamic graph drawing in the emphasis that is put on maintaining the clustered structure of the graph during incremental layout. The algorithm works online and allows arbitrary modifications to the graph. It is generic and can be implemented using a wide range of static force-directed graph layout tools. The paper introduces several metrics for measuring layout quality of dynamic clustered graphs. The performance of our algorithm is analyzed using these metrics. The algorithm has been successfully applied to visualizing mobile object software,Yaniv Frishman;Ayellet Tal,Y. Frishman;Ayellet Tal,"Department of Computer Science, Technion-Israel Institute of Technology, Israel;Department of Computer Science, Technion-Israel Institute of Technology, Israel",10.1109/infvis.1999.801859;10.1109/infvis.1999.801859,"graph drawing, dynamic layout, mobile objects, software visualization",168.0,53.0,32.0,622.0,,,directed graph layout;mobile object software;quality dynamic clustered;static force;generic,0.6698;0.3549;0.3243;0.0966;0.0438,"[np.int64(-1), -1, -1, -1, -1]",39;-1;-1;-1;-1,39,39
InfoVis,2000,Redefining the focus and context of focus+context visualization,10.1109/infvis.2000.885094,http://dx.doi.org/10.1109/INFVIS.2000.885094,85.0,89.0,C,"The increasing diversity of computers, especially among small mobile devices such as mobile phones and PDAs, raise new questions about information visualization techniques developed for the desktop computer. Using a series of examples ranging from applications for ordinary desktop displays to web-browsers and other applications for PDAs, we describe how a focus+context technique, Flip Zooming, is changed due to the situation it is used in. Based on these examples, we discuss how the use of ""focus"" and ""context"" in focus+context techniques change in order to fit new areas of use for information visualization.",Staffan Björk;Johan Redström,S. Bjork;J. Redstrom,"Applied research on art and technology, Interactive Institute, Gothenburg, Sweden;Applied research on art and technology, Interactive Institute, Gothenburg, Sweden",10.1109/infvis.1997.636786;10.1109/infvis.1999.801857,,74.0,9.0,28.0,306.0,,,information visualization;pdas focus;flip zooming changed;especially;raise new,0.5463;0.4949;0.4178;0.0656;0.0126,"[np.int64(-1), -1, -1, -1, -1]",207;-1;-1;-1;-1,207,207
InfoVis,2004,faMailiar & Intimacy-Based Email Visualization,10.1109/infvis.2004.26,http://dx.doi.org/10.1109/INFVIS.2004.26,14.0,14.0,M,"Email has developed into one of the most extensively used computer applications. Email interfaces, on the other hand, have gone through very few transformations since their inception, and as the growing volumes of email data accumulate in users' email boxes, these interfaces fail to provide effective message handling and browsing support. Saved email messages provide not only a vast record of one's electronic past, but also a potential source of valuable insights into the structure and dynamics of one's social network. In this paper, we present faMailiar, a novel email visualization that draws upon email's inherently personal character by using intimacy as a key visualization parameter. The program presents a visualization of email use over time. faMailiar facilitates navigation through large email collections, enabling the user to discover communication rhythms and patterns.",Mirko Mandic;Andruid Kerne,M. Mandic;A. Kerne,"Interface Ecology Lab, Texas A&M Computer Science Department, Center for Digital Libraries, USA;Interface Ecology Lab, Texas A&M Computer Science Department, Center for Digital Libraries, USA",,,20.0,5.0,12.0,137.0,,,novel email visualization;intimacy;vast record;used computer;structure dynamics,0.7483;0.2862;0.1740;0.1708;0.0732,"[np.int64(-1), -1, -1, -1, -1]",178;-1;-1;-1;-1,178,178
VAST,2019,Summit: Scaling Deep Learning Interpretability by Visualizing Activation and Attribution Summarizations,10.1109/tvcg.2019.2934659,http://dx.doi.org/10.1109/TVCG.2019.2934659,1096.0,1106.0,J,"Deep learning is increasingly used in decision-making tasks. However, understanding how neural networks produce final predictions remains a fundamental challenge. Existing work on interpreting neural network predictions for images often focuses on explaining predictions for single images or neurons. As predictions are often computed from millions of weights that are optimized over millions of images, such explanations can easily miss a bigger picture. We present Summit, an interactive system that scalably and systematically summarizes and visualizes what features a deep learning model has learned and how those features interact to make predictions. Summit introduces two new scalable summarization techniques: (1) activation aggregation discovers important neurons, and (2) neuron-influence aggregation identifies relationships among such neurons. Summit combines these techniques to create the novel attribution graph that reveals and summarizes crucial neuron associations and substructures that contribute to a model's outcomes. Summit scales to large data, such as the ImageNet dataset with 1.2M images, and leverages neural network feature visualization and dataset examples to help users distill large, complex neural network models into compact, interactive visualizations. We present neural network exploration scenarios where Summit helps us discover multiple surprising insights into a prevalent, large-scale image classifier's learned representations and informs future neural network architecture design. The Summit visualization runs in modern web browsers and is open-sourced.",Fred Hohman;Haekyu Park;Caleb Robinson;Duen Horng (Polo) Chau,Fred Hohman;Haekyu Park;Caleb Robinson;Duen Horng Polo Chau,Georgia Tech.;Georgia Tech.;Georgia Tech.;Georgia Tech.,10.1109/tvcg.2017.2744683;10.1109/tvcg.2017.2744718;10.1109/tvcg.2018.2864500;10.1109/vast.2018.8802509;10.1109/tvcg.2016.2598831;10.1109/tvcg.2016.2598828;10.1109/tvcg.2009.108;10.1109/tvcg.2017.2744878;10.1109/tvcg.2017.2744683,"Deep learning interpretability,visual analytics,scalable summarization,attribution graph",3.0,125.0,60.0,2752.0,,,visualizes features deep;contribute model outcomes;summit combines;computed millions;modern web browsers,0.6499;0.2430;0.1548;0.1413;0.0475,"[np.int64(-1), -1, -1, -1, -1]",135;-1;-1;-1;-1,135,135
VAST,2011,A state transition approach to understanding users' interactions,10.1109/vast.2011.6102476,http://dx.doi.org/10.1109/VAST.2011.6102476,285.0,286.0,M,"Understanding users' interactions is considered as one of the important research topics in visual analytics. Although numerous empirical user studies have been performed to understand a user's interaction, a limited study has been successful in connecting the user's interaction to his/her reasoning. In this paper, we present an approach of understanding experts' interactive analysis by connecting their interactions to conclusions (i.e. findings) through a state transition approach.",Dong Hyun Jeong;Soo-Yeon Ji;William Ribarsky;Remco Chang,Dong Hyun Jeong;Soo-Yeon Ji;William Ribarsky;Remco Chang,"University of District of Columbia, USA;Bowie State University, USA;University of North Carolina, Charlotte, USA;Tufts University, USA",0.1109/vast.2007.4389009;10.1109/vast.2008.4677360,,1.0,3.0,5.0,135.0,,,visual analytics;approach understanding experts;interactions conclusions;state transition;considered,0.6299;0.4876;0.2921;0.2298;0.0475,"[np.int64(-1), -1, -1, -1, -1]",201;-1;-1;-1;-1,201,201
Vis,1990,Extracting geometric models through constraint minimization,10.1109/visual.1990.146367,http://dx.doi.org/10.1109/VISUAL.1990.146367,74.0,,C,"The authors propose a methodology that will extract a topologically closed geometric model from a two-dimensional image. This is accomplished by starting with a simple model that is already topologically closed and deforming the model, based on a set of constraints, so that the model grows (shrinks) to fit the feature within the image while maintaining its closed and locally simple nature. The initial model is a non-self-intersecting polygon that is either embedded in the feature or surrounds the feature. There is a cost function associated with every vertex that quantifies its deformation, the properties of simple polygons, and the relationship between noise and feature. The constraints embody local properties of simple polygons and the nature of the relationship between noise and the features in the image.&lt;&lt;ETX&gt;&gt;",James V. Miller;David E. Breen;Michael J. Wozny,J.V. Miller;D.E. Breen;M.J. Wozny,"Rensselaer Polytechnic Institute, Rensselaer Design Research Center, Troy, NY, USA;Rensselaer Polytechnic Institute, Rensselaer Design Research Center, Troy, NY, USA;Rensselaer Polytechnic Institute, Rensselaer Design Research Center, Troy, NY, USA",,,23.0,6.0,14.0,55.0,,,closed geometric model;extract topologically;noise features image;deformation properties simple;authors,0.5620;0.5106;0.3972;0.3238;-0.0022,"[np.int64(-1), np.int64(-1), -1, -1, -1]",89;10;-1;-1;-1,10;89,89
VAST,2013,An Extensible Framework for Provenance in Human Terrain Visual Analytics,10.1109/tvcg.2013.132,http://dx.doi.org/10.1109/TVCG.2013.132,2139.0,2148.0,J,"We describe and demonstrate an extensible framework that supports data exploration and provenance in the context of Human Terrain Analysis (HTA). Working closely with defence analysts we extract requirements and a list of features that characterise data analysed at the end of the HTA chain. From these, we select an appropriate non-classified data source with analogous features, and model it as a set of facets. We develop ProveML, an XML-based extension of the Open Provenance Model, using these facets and augment it with the structures necessary to record the provenance of data, analytical process and interpretations. Through an iterative process, we develop and refine a prototype system for Human Terrain Visual Analytics (HTVA), and demonstrate means of storing, browsing and recalling analytical provenance and process through analytic bookmarks in ProveML. We show how these bookmarks can be combined to form narratives that link back to the live data. Throughout the process, we demonstrate that through structured workshops, rapid prototyping and structured communication with intelligence analysts we are able to establish requirements, and design schema, techniques and tools that meet the requirements of the intelligence community. We use the needs and reactions of defence analysts in defining and steering the methods to validate the framework.",Rick Walker;Aidan Slingsby;Jason Dykes;Kai Xu 0003;Jo Wood;Phong Hai Nguyen;Derek Stephens;B. L. William Wong;Yongjun Zheng,Rick Walker;Aiden Slingsby;Jason Dykes;Kai Xu;Jo Wood;Phong H. Nguyen;Derek Stephens;B.L. William Wong;Yongjun Zheng,"Middlesex University, UK;GiCentre, London City University, London, UK;GiCentre, London City University, London, UK;Middlesex University, UK;GiCentre, London City University, London, UK;Middlesex University, UK;Loughborough University, UK;Middlesex University, UK;Middlesex University, UK",10.1109/tvcg.2012.252;10.1109/tvcg.2010.191;10.1109/vast.2007.4388992;10.1109/tvcg.2006.142;10.1109/vast.2006.261431;10.1109/tvcg.2010.154;10.1109/tvcg.2012.213;10.1109/infvis.2000.885086;10.1109/tvcg.2007.70577;10.1109/tvcg.2009.111;10.1109/vast.2008.4677366;10.1109/vast.2008.4677365;10.1109/vast.2007.4388992;10.1109/tvcg.2009.128;10.1109/vast.2009.5332611;10.1109/tvcg.2010.183;10.1109/vast.2009.5333919;10.1109/tvcg.2011.209;10.1109/tvcg.2009.139;10.1109/tvcg.2008.175;10.1109/tvcg.2012.252,"Human terrain analysis, provenance, framework, bookmarks, narratives",56.0,26.0,59.0,1032.0,,,data exploration provenance;human terrain visual;reactions defence analysts;demonstrate extensible framework;defining,0.6263;0.3641;0.2594;0.1887;0.0975,"[np.int64(-1), -1, -1, -1, -1]",259;-1;-1;-1;-1,259,259
SciVis,2013,Contour Boxplots: A Method for Characterizing Uncertainty in Feature Sets from Simulation Ensembles,10.1109/tvcg.2013.143,http://dx.doi.org/10.1109/TVCG.2013.143,2713.0,2722.0,J,"Ensembles of numerical simulations are used in a variety of applications, such as meteorology or computational solid mechanics, in order to quantify the uncertainty or possible error in a model or simulation. Deriving robust statistics and visualizing the variability of an ensemble is a challenging task and is usually accomplished through direct visualization of ensemble members or by providing aggregate representations such as an average or pointwise probabilities. In many cases, the interesting quantities in a simulation are not dense fields, but are sets of features that are often represented as thresholds on physical or derived quantities. In this paper, we introduce a generalization of boxplots, called contour boxplots, for visualization and exploration of ensembles of contours or level sets of functions. Conventional boxplots have been widely used as an exploratory or communicative tool for data analysis, and they typically show the median, mean, confidence intervals, and outliers of a population. The proposed contour boxplots are a generalization of functional boxplots, which build on the notion of data depth. Data depth approximates the extent to which a particular sample is centrally located within its density function. This produces a center-outward ordering that gives rise to the statistical quantities that are essential to boxplots. Here we present a generalization of functional data depth to contours and demonstrate methods for displaying the resulting boxplots for two-dimensional simulation data in weather forecasting and computational fluid dynamics.",Ross T. Whitaker;Mahsa Mirzargar;Robert M. Kirby,Ross T. Whitaker;Mahsa Mirzargar;Robert M. Kirby,"Scientific Computing and Imaging Institute and School of Computing, University of Utah, Salt Lake, UT, USA;Scientific Computing and Imaging Institute and School of Computing, University of Utah, Salt Lake, UT, USA;Scientific Computing and Imaging Institute and School of Computing, University of Utah, Salt Lake, UT, USA",10.1109/visual.2002.1183769;10.1109/visual.1996.568105;10.1109/visual.2005.1532807;10.1109/tvcg.2010.181;10.1109/visual.2002.1183769,"Uncertainty visualization, boxplots, band depth, ensemble visualization, order statistics",190.0,149.0,38.0,1552.0,,,visualizing variability ensemble;contours level sets;computational fluid dynamics;functions conventional;build,0.6572;0.4130;0.3307;0.1212;0.0059,"[np.int64(-1), -1, -1, -1, -1]",106;-1;-1;-1;-1,106,106
Vis,1996,A 3D Contextual Shading Method for Visualization of Diecasting Defects,10.1109/visual.1996.568143,http://doi.ieeecomputersociety.org/10.1109/VISUAL.1996.568143,405.0,407.0,C,"In many mechanical design-related activities, the visualization tool needs to convey not only the shape of the objects, but also their interior problem regions. Due to the binary nature of these models, existing shading models often fall short of supporting a realistic display. In this case study, we present several new contextual shading methods that we originally developed for our design visualization tools. The results are then compared with gray-scale shading applied to a gray-level version of the binary object. The comparison shows that our method can be applied to any binary object and yields promising results.",Shao-Chiung Lu;Alec B. Rebello;D. H. Cui;Roni Yagel;Richard Allen Miller;Gary L. Kinzel,S.C. Lu;A.B. Rebello;D.H. Cui;R. Yagel;R.A. Miller;G.L. Kinzel,The Ohio State University;The Ohio State University;The Ohio State University;The Ohio State University;The Ohio State University;The Ohio State University,,,14.0,2.0,0.0,24.0,,,design visualization;shading applied gray;regions binary nature;object yields promising;short,0.6209;0.3723;0.2708;0.1752;-0.0217,"[np.int64(-1), -1, -1, -1, -1]",196;-1;-1;-1;-1,196,196
VAST,2017,Clustervision: Visual Supervision of Unsupervised Clustering,10.1109/tvcg.2017.2745085,http://dx.doi.org/10.1109/TVCG.2017.2745085,142.0,151.0,J,"Clustering, the process of grouping together similar items into distinct partitions, is a common type of unsupervised machine learning that can be useful for summarizing and aggregating complex multi-dimensional data. However, data can be clustered in many ways, and there exist a large body of algorithms designed to reveal different patterns. While having access to a wide variety of algorithms is helpful, in practice, it is quite difficult for data scientists to choose and parameterize algorithms to get the clustering results relevant for their dataset and analytical tasks. To alleviate this problem, we built Clustervision, a visual analytics tool that helps ensure data scientists find the right clustering among the large amount of techniques and parameters available. Our system clusters data using a variety of clustering techniques and parameters and then ranks clustering results utilizing five quality metrics. In addition, users can guide the system to produce more relevant results by providing task-relevant constraints on the data. Our visual user interface allows users to find high quality clustering results, explore the clusters using several coordinated visualization techniques, and select the cluster result that best suits their task. We demonstrate this novel approach using a case study with a team of researchers in the medical domain and showcase that our system empowers users to choose an effective representation of their complex data.",Bum Chul Kwon;Ben Eysenbach;Janu Verma;Kenney Ng;Christopher deFilippi;Walter F. Stewart;Adam Perer,Bum Chul Kwon;Ben Eysenbach;Janu Verma;Kenney Ng;Christopher De Filippi;Walter F. Stewart;Adam Perer,"IBM T.J. Watson Research Center, NY, USA;Massachusetts Institute of Technology, Cambridge, MA, USA;IBM T.J. Watson Research Center, NY, USA;IBM T.J. Watson Research Center, NY, USA;Inova Heart and Vascular Institute, Fairfax, VA, USA;Sutter Health Research, Walnut Creek, California, USA;IBM T.J. Watson Research Center, NY, USA",10.1109/tvcg.2011.188;10.1109/tvcg.2014.2346321;10.1109/tvcg.2015.2467717;10.1109/tvcg.2011.188,"Unsupervised Clustering,Visual Analytics,Quality Metrics,Interactive Visual Clustering",122.0,96.0,46.0,2568.0,,,clustervision visual analytics;learning useful summarizing;empowers users choose;researchers medical;items distinct,0.6289;0.3354;0.2612;0.2057;0.1236,"[np.int64(-1), -1, -1, -1, -1]",164;-1;-1;-1;-1,164,164
SciVis,2012,Visual Steering and Verification of Mass Spectrometry Data Factorization in Air Quality Research,10.1109/tvcg.2012.280,http://dx.doi.org/10.1109/TVCG.2012.280,2275.0,2284.0,J,"The study of aerosol composition for air quality research involves the analysis of high-dimensional single particle mass spectrometry data. We describe, apply, and evaluate a novel interactive visual framework for dimensionality reduction of such data. Our framework is based on non-negative matrix factorization with specifically defined regularization terms that aid in resolving mass spectrum ambiguity. Thereby, visualization assumes a key role in providing insight into and allowing to actively control a heretofore elusive data processing step, and thus enabling rapid analysis meaningful to domain scientists. In extending existing black box schemes, we explore design choices for visualizing, interacting with, and steering the factorization process to produce physically meaningful results. A domain-expert evaluation of our system performed by the air quality research experts involved in this effort has shown that our method and prototype admits the finding of unambiguous and physically correct lower-dimensional basis transformations of mass spectrometry data at significantly increased speed and a higher degree of ease.",Daniel Engel;Klaus Greff;Christoph Garth;Keith Bein;Anthony S. Wexler;Bernd Hamann;Hans Hagen,Daniel Engel;Klaus Greff;Christoph Garth;Keith Bein;Anthony Wexler;Bernd Hamann;Hans Hagen,"University of Kaiserslautern, Germany;University of Kaiserslautern, Germany;University of Kaiserslautern, Germany;Air Quality Research Center (AQRC), University of California, Davis, CA, USA;Air Quality Research Center (AQRC), University of California, Davis, CA, USA;Institute for Data Analysis and Visualization (IDAV), Department of Computer Science, University of California, Davis, CA, USA;University of Kaiserslautern, Germany",10.1109/infvis.2004.68;10.1109/infvis.2004.15;10.1109/infvis.2005.1532138;10.1109/tvcg.2008.116;10.1109/visual.2000.885734;10.1109/infvis.2003.1249015;10.1109/tvcg.2010.223;10.1109/visual.2005.1532850;10.1109/infvis.2002.1173157;10.1109/tvcg.2008.153;10.1109/infvis.2004.68,"Dimension reduction, mass spectrometry data, matrix factorization, visual encodings of numerical error metrics, multi-dimensional data visualization",14.0,10.0,44.0,377.0,,,dimensionality reduction data;aerosol;mass spectrum ambiguity;extending existing black;key role,0.4860;0.3228;0.2995;0.1445;0.0824,"[-1, -1, -1, -1, -1]",-1;-1;-1;-1;-1,,-1
InfoVis,2002,Visualizing data with bounded uncertainty,10.1109/infvis.2002.1173145,http://dx.doi.org/10.1109/INFVIS.2002.1173145,37.0,40.0,C,"Visualization is a powerful way to facilitate data analysis, but it is crucial that visualization systems explicitly convey the presence, nature, and degree of uncertainty to users. Otherwise, there is a danger that data will be falsely interpreted, potentially leading to inaccurate conclusions. A common method for denoting uncertainty is to use error bars or similar techniques designed to convey the degree of statistical uncertainty. While uncertainty can often be modeled statistically, a second form of uncertainty, bounded uncertainty, can also arise that has very different properties than statistical uncertainty. Error bars should not be used for bounded uncertainty because they do not convey the correct properties, so a different technique should be used instead. We describe a technique for conveying bounded uncertainty in visualizations and show how it can be applied systematically to common displays of abstract charts and graphs. Interestingly, it is not always possible to show the exact degree of uncertainty, and in some cases it can only be displayed approximately.",Chris Olston;Jock D. Mackinlay,C. Olston;J.D. Mackinlay,"University of Stanford, USA;Palo Alto Research Center, Inc.orporated, USA",10.1109/visual.1994.346317;10.1109/visual.2000.885679;10.1109/infvis.1999.801858;10.1109/visual.1994.346317,"uncertainty visualization, bounded uncertainty",131.0,24.0,17.0,1020.0,,,uncertainty visualizations;conveying bounded;data falsely interpreted;common displays abstract;correct,0.8365;0.3289;0.2582;0.1982;0.0129,"[np.int64(-1), -1, -1, -1, -1]",159;-1;-1;-1;-1,159,159
InfoVis,2018,Visualizing Uncertain Tropical Cyclone Predictions using Representative Samples from Ensembles of Forecast Tracks,10.1109/tvcg.2018.2865193,http://dx.doi.org/10.1109/TVCG.2018.2865193,882.0,891.0,J,"A common approach to sampling the space of a prediction is the generation of an ensemble of potential outcomes, where the ensemble's distribution reveals the statistical structure of the prediction space. For example, the US National Hurricane Center generates multiple day predictions for a storm's path, size, and wind speed, and then uses a Monte Carlo approach to sample this prediction into a large ensemble of potential storm outcomes. Various forms of summary visualizations are generated from such an ensemble, often using spatial spread to indicate its statistical characteristics. However, studies have shown that changes in the size of such summary glyphs, representing changes in the uncertainty of the prediction, are frequently confounded with other attributes of the phenomenon, such as its size or strength. In addition, simulation ensembles typically encode multivariate information, which can be difficult or confusing to include in a summary display. This problem can be overcome by directly displaying the ensemble as a set of annotated trajectories, however this solution will not be effective if ensembles are densely overdrawn or structurally disorganized. We propose to overcome these difficulties by selectively sampling the original ensemble, constructing a smaller representative and spatially well organized ensemble. This can be drawn directly as a set of paths that implicitly reveals the underlying spatial uncertainty distribution of the prediction. Since this approach does not use a visual channel to encode uncertainty, additional information can more easily be encoded in the display without leading to visual confusion. To demonstrate our argument, we describe the development of a visualization for ensembles of tropical cyclone forecast tracks, explaining how their spatial and temporal predictions, as well as other crucial storm characteristics such as size and intensity, can be clearly revealed. We verify the effectiveness of this visualization approach through a cognitive study exploring how storm damage estimates are affected by the density of tracks drawn, and by the presence or absence of annotating information on storm size and intensity.",Le Liu 0007;Lace M. K. Padilla;Sarah H. Creem-Regehr;Donald H. House,Le Liu;Lace Padilla;Sarah H. Creem-Regehr;Donald H. House,"Magic Weaver Inc., Santa Clara, CA;Northwestern University, Evanston, IL, US;University of Utah, Salt Lake City, UT, US;Clemson University, Clemson, SC, US",10.1109/tvcg.2017.2743898;10.1109/tvcg.2010.181;10.1109/tvcg.2014.2346455;10.1109/tvcg.2017.2743898,"uncertainty visualization,hurricane forecasts,ensemble visualization,ensemble sampling,implicit uncertainty",46.0,44.0,32.0,1205.0,,,visualizations generated ensemble;tropical cyclone forecast;underlying spatial uncertainty;wind speed uses;crucial,0.6522;0.4466;0.3999;0.2041;0.0711,"[np.int64(-1), -1, -1, -1, -1]",106;-1;-1;-1;-1,106,106
InfoVis,1996,Animating multidimensional scaling to visualize N-dimensional data sets,10.1109/infvis.1996.559223,http://dx.doi.org/10.1109/INFVIS.1996.559223,72.0,,M,"Many techniques have been developed for visualizing multivariate (multidimensional) data. Most, if not all, are limited by the number of dimensions which can be effectively displayed. Multidimensional scaling (MDS) is an iterative non-linear technique for projecting n-D data down to a lower number of dimensions. This work presents extensions to MDS that enhance visualization of high-dimensional data sets. These extensions include animation, stochastic perturbation, and flow visualization techniques.",Chris Bentley;Matthew O. Ward,C.L. Bentley;M.O. Ward,"Computer Science Department, Worcester Polytechnic Institute, Worcester, MA, USA;Computer Science Department, Worcester Polytechnic Institute, Worcester, MA, USA",0.1109/visual.1990.146402;10.1109/visual.1994.346302;10.1109/infvis.1995.528686,,62.0,25.0,5.0,223.0,,,visualization high dimensional;include animation stochastic;data lower number;extensions mds;non,0.7465;0.3539;0.1131;0.1029;-0.0598,"[np.int64(-1), -1, -1, -1, -1]",182;-1;-1;-1;-1,182,182
Vis,1994,A library for visualizing combinatorial structures,10.1109/visual.1994.346323,http://dx.doi.org/10.1109/VISUAL.1994.346323,164.0,,C,"Describes ANIM3D, a 3D animation library targeted at visualizing combinatorial structures. In particular, we are interested in algorithm animation. Constructing a new view for an algorithm typically takes dozens of design iterations, and can be very time-consuming. Our library eases the programmer's burden by providing high-level constructs for performing animations, and by offering an interpretive environment that eliminates the need for recompilations. We also illustrate ANIM3D's expressiveness by developing a 3D animation of Dijkstra's shortest-path algorithm in just 70 lines of code.&lt;&lt;ETX&gt;&gt;",Marc Najork;Marc H. Brown,M.A. Najork;M.H. Brown,"DEC Systems Research Center, Palo Alto, CA, USA;DEC Systems Research Center, Palo Alto, CA, USA",,,19.0,3.0,19.0,64.0,,,algorithm animation;developing 3d;dijkstra;consuming library;describes,0.6652;0.4349;0.3585;0.1271;0.0984,"[np.int64(-1), -1, -1, -1, -1]",9;-1;-1;-1;-1,9,9
SciVis,2015,NeuroBlocks - Visual Tracking of Segmentation and Proofreading for Large Connectomics Projects,10.1109/tvcg.2015.2467441,http://dx.doi.org/10.1109/TVCG.2015.2467441,738.0,746.0,J,"In the field of connectomics, neuroscientists acquire electron microscopy volumes at nanometer resolution in order to reconstruct a detailed wiring diagram of the neurons in the brain. The resulting image volumes, which often are hundreds of terabytes in size, need to be segmented to identify cell boundaries, synapses, and important cell organelles. However, the segmentation process of a single volume is very complex, time-intensive, and usually performed using a diverse set of tools and many users. To tackle the associated challenges, this paper presents NeuroBlocks, which is a novel visualization system for tracking the state, progress, and evolution of very large volumetric segmentation data in neuroscience. NeuroBlocks is a multi-user web-based application that seamlessly integrates the diverse set of tools that neuroscientists currently use for manual and semi-automatic segmentation, proofreading, visualization, and analysis. NeuroBlocks is the first system that integrates this heterogeneous tool set, providing crucial support for the management, provenance, accountability, and auditing of large-scale segmentations. We describe the design of NeuroBlocks, starting with an analysis of the domain-specific tasks, their inherent challenges, and our subsequent task abstraction and visual representation. We demonstrate the utility of our design based on two case studies that focus on different user roles and their respective requirements for performing and tracking the progress of segmentation and proofreading in a large real-world connectomics project.",Ali K. Al-Awami;Johanna Beyer;Daniel Haehn;Narayanan Kasthuri;Jeff W. Lichtman;Hanspeter Pfister;Markus Hadwiger,Ali K. Ai-Awami;Johanna Beyer;Daniel Haehn;Narayanan Kasthuri;Jeff W. Lichtman;Hanspeter Pfister;Markus Hadwiger,"King Abdullah University of Science and Technology (KAUST);School of Engineering and Applied Sciences, Harvard University;School of Engineering and Applied Sciences, Harvard University;School of Medicine, Boston University;Center for Brain Science, Harvard University;School of Engineering and Applied Sciences, Harvard University;King Abdullah University of Science and Technology (KAUST)",10.1109/tvcg.2014.2346312;10.1109/visual.2005.1532788;10.1109/tvcg.2013.142;10.1109/tvcg.2009.121;10.1109/tvcg.2012.240;10.1109/tvcg.2014.2346371;10.1109/tvcg.2013.174;10.1109/tvcg.2014.2346249;10.1109/tvcg.2007.70584;10.1109/tvcg.2014.2346312,"Neuroscience, Segmentation, Proofreading, Data and Provenance Tracking",36.0,34.0,40.0,1407.0,,,visualization analysis neuroblocks;important cell organelles;provenance;application seamlessly integrates;different user roles,0.5866;0.2466;0.2064;0.1266;0.0692,"[np.int64(-1), -1, -1, -1, -1]",134;-1;-1;-1;-1,134,134
InfoVis,2015,SchemeLens: A Content-Aware Vector-Based Fisheye Technique for Navigating Large Systems Diagrams,10.1109/tvcg.2015.2467035,http://dx.doi.org/10.1109/TVCG.2015.2467035,330.0,338.0,J,"System schematics, such as those used for electrical or hydraulic systems, can be large and complex. Fisheye techniques can help navigate such large documents by maintaining the context around a focus region, but the distortion introduced by traditional fisheye techniques can impair the readability of the diagram. We present SchemeLens, a vector-based, topology-aware fisheye technique which aims to maintain the readability of the diagram. Vector-based scaling reduces distortion to components, but distorts layout. We present several strategies to reduce this distortion by using the structure of the topology, including orthogonality and alignment, and a model of user intention to foster smooth and predictable navigation. We evaluate this approach through two user studies: Results show that (1) SchemeLens is 16-27% faster than both round and rectangular flat-top fisheye lenses at finding and identifying a target along one or several paths in a network diagram; (2) augmenting SchemeLens with a model of user intentions aids in learning the network topology.",Aurélie Cohé;Bastien Liutkus;Gilles Bailly;James Eagan;Eric Lecolinet,Aurélie Cohé;Bastien Liutkus;Gilles Bailly;James Eagan;Eric Lecolinet,"Télécom ParisTech;Télécom ParisTech;CNRS LTCI & Télécom ParisTech;Télécom ParisTech, CNRS LTCI;Télécom ParisTech, CNRS LTCI",10.1109/infvis.2004.66;10.1109/tvcg.2012.245;10.1109/infvis.2003.1249008,"Fisheye, vector-scaling, content-aware, network schematics, interactive zoom, navigation, information visualization",14.0,9.0,33.0,666.0,,,topology aware fisheye;maintain readability;components distorts layout;used electrical hydraulic;27 faster,0.6324;0.2793;0.2098;0.1596;0.0290,"[np.int64(-1), -1, -1, -1, -1]",242;-1;-1;-1;-1,242,242
Vis,2003,Signed distance transform using graphics hardware,10.1109/visual.2003.1250358,http://dx.doi.org/10.1109/VISUAL.2003.1250358,83.0,90.0,C,"This paper presents a signed distance transform algorithm using graphics hardware, which computes the scalar valued function of the Euclidean distance to a given manifold of co-dimension one. If the manifold is closed and orientable, the distance has a negative sign on one side of the manifold and a positive sign on the other. Triangle meshes are considered for the representation of a two-dimensional manifold and the distance function is sampled on a regular Cartesian grid. In order to achieve linear complexity in the number of grid points, to each primitive we assign a simple polyhedron enclosing its Voronoi cell. Voronoi cells are known to contain exactly all points that lay closest to its corresponding primitive. Thus, the distance to the primitive only has to be computed for grid points inside its polyhedron. Although Voronoi cells partition space, the polyhedrons enclosing these cells do overlap. In regions where these overlaps occur, the minimum of all computed distances is assigned to a grid point. In order to speed up computations, points inside each polyhedron are determined by scan conversion of grid slices using graphics hardware. For this task, a fragment program is used to perform the nonlinear interpolation and minimization of distance values.",Christian Sigg;Ronald Peikert;Markus H. Gross,C. Sigg;R. Peikert;M. Gross,"Computer Graphics Laboratory, Computer Science Dep, ETH Zürich, Zurich, Switzerland;Computer Graphics Laboratory, Computer Science Dep, ETH Zürich, Zurich, Switzerland;Computer Graphics Laboratory, Computer Science Dep, ETH Zürich, Zurich, Switzerland",10.1109/visual.2001.964518;10.1109/visual.2001.964517,"Distance field, distance transform, Voronoi diagram, fragment program, scan conversion",163.0,47.0,16.0,483.0,,,distance transform algorithm;polyhedron enclosing voronoi;graphics hardware computes;manifold closed orientable;exactly,0.6337;0.4725;0.3037;0.1633;0.0291,"[np.int64(-1), -1, -1, -1, -1]",234;-1;-1;-1;-1,234,234
Vis,2006,fine-grained Visualization Pipelines and Lazy Functional Languages,10.1109/tvcg.2006.145,http://dx.doi.org/10.1109/TVCG.2006.145,973.0,980.0,J,"The pipeline model in visualization has evolved from a conceptual model of data processing into a widely used architecture for implementing visualization systems. In the process, a number of capabilities have been introduced, including streaming of data in chunks, distributed pipelines, and demand-driven processing. Visualization systems have invariably built on stateful programming technologies, and these capabilities have had to be implemented explicitly within the lower layers of a complex hierarchy of services. The good news for developers is that applications built on top of this hierarchy can access these capabilities without concern for how they are implemented. The bad news is that by freezing capabilities into low-level services expressive power and flexibility is lost. In this paper we express visualization systems in a programming language that more naturally supports this kind of processing model. Lazy functional languages support fine-grained demand-driven processing, a natural form of streaming, and pipeline-like function composition for assembling applications. The technology thus appears well suited to visualization applications. Using surface extraction algorithms as illustrative examples, and the lazy functional language Haskell, we argue the benefits of clear and concise expression combined with fine-grained, demand-driven computation. Just as visualization provides insight into data, functional abstraction provides new insight into visualization",David J. Duke;Malcolm Wallace;Rita Borgo;Colin Runciman,David Duke;Malcolm Wallace;Rita Borgo;Colin Runciman,"School of Computing, University of Leeds, UK;Colin Runciman and Malcolm Wallace are with the Department of Computer Science, University of York, UK;School of Computing, University of Leeds, UK;Colin Runciman and Malcolm Wallace are with the Department of Computer Science, University of York, UK",10.1109/visual.1994.346311;10.1109/visual.1999.809864;10.1109/visual.1993.398880;10.1109/visual.1999.809891;10.1109/visual.2005.1532800;10.1109/visual.1997.663888;10.1109/visual.1994.346311,"Pipeline model, laziness, functional programming",18.0,10.0,29.0,300.0,,,processing visualization systems;model lazy functional;explicitly;capabilities concern implemented;news freezing,0.6483;0.3166;0.2579;0.1892;0.0095,"[np.int64(-1), -1, -1, -1, -1]",276;-1;-1;-1;-1,276,276
VAST,2016,SemanticTraj: A New Approach to Interacting with Massive Taxi Trajectories,10.1109/tvcg.2016.2598416,http://dx.doi.org/10.1109/TVCG.2016.2598416,11.0,20.0,J,"Massive taxi trajectory data is exploited for knowledge discovery in transportation and urban planning. Existing tools typically require users to select and brush geospatial regions on a map when retrieving and exploring taxi trajectories and passenger trips. To answer seemingly simple questions such as “What were the taxi trips starting from Main Street and ending at Wall Street in the morning?” or “Where are the taxis arriving at the Art Museum at noon typically coming from?”, tedious and time consuming interactions are usually needed since the numeric GPS points of trajectories are not directly linked to the keywords such as “Main Street”, “Wall Street”, and “Art Museum”. In this paper, we present SemanticTraj, a new method for managing and visualizing taxi trajectory data in an intuitive, semantic rich, and efficient means. With SemanticTraj, domain and public users can find answers to the aforementioned questions easily through direct queries based on the terms. They can also interactively explore the retrieved data in visualizations enhanced by semantic information of the trajectories and trips. In particular, taxi trajectories are converted into taxi documents through a textualization transformation process. This process maps GPS points into a series of street/POI names and pick-up/drop-off locations. It also converts vehicle speeds into user-defined descriptive terms. Then, a corpus of taxi documents is formed and indexed to enable flexible semantic queries over a text search engine. Semantic labels and meta-summaries of the results are integrated with a set of visualizations in a SemanticTraj prototype, which helps users study taxi trajectories quickly and easily. A set of usage scenarios are presented to show the usability of the system. We also collected feedback from domain experts and conducted a preliminary user study to evaluate the visual system.",Shamal Al-Dohuki;Yingyu Wu;Farah Kamw;Jing Yang 0001;Xin Li;Ye Zhao 0003;Xinyue Ye;Wei Chen 0001;Chao Ma 0023;Fei Wang 0016,Shamal Al-Dohuki;Yingyu Wu;Farah Kamw;Jing Yang;Xin Li;Ye Zhao;Xinyue Ye;Wei Chen;Chao Ma;Fei Wang,"Department of Computer Science, Kent State University;Department of Computer Science, Kent State University;Department of Computer Science, Kent State University;Department of Computer Science, University of North Carolina, Charlotte and UNC Charlotte;China Petroleum University;Department of Computer Science, Kent State University;Department of Geography and Kent State University;Department of Computer Science, Zhejiang University;Department of Computer Science, Kent State University;Department of Computer Science, Zhejiang University",10.1109/tvcg.2015.2467732;10.1109/tvcg.2013.226;10.1109/vast.2014.7042486;10.1109/vast.2011.6102455;10.1109/tvcg.2014.2346746;10.1109/tvcg.2013.228;10.1109/vast.2010.5652885;10.1109/tvcg.2015.2467732,Taxi Trajectories;Taxi Document;Textualization;Name Query;Semantic Interaction;Text Search Engine,95.0,80.0,44.0,3012.0,,,exploring taxi trajectories;text search engine;enable flexible semantic;select brush geospatial;domain public,0.6752;0.3297;0.2802;0.1135;0.0609,"[np.int64(-1), -1, -1, -1, -1]",68;-1;-1;-1;-1,68,68
Vis,2024,Practices and Strategies in Responsive Thematic Map Design: A Report from Design Workshops with Experts,10.1109/tvcg.2024.3456352,http://dx.doi.org/10.1109/TVCG.2024.3456352,1148.0,1157.0,J,"This paper discusses challenges and design strategies in responsive design for thematic maps in information visualization. Thematic maps pose a number of unique challenges for responsiveness, such as inflexible aspect ratios that do not easily adapt to varying screen dimensions, or densely clustered visual elements in urban areas becoming illegible at smaller scales. However, design guidance on how to best address these issues is currently lacking. We conducted design sessions with eight professional designers and developers of web-based thematic maps for information visualization. Participants were asked to redesign a given map for various screen sizes and aspect ratios and to describe their reasoning for when and how they adapted the design. We report general observations of practitioners' motivations, decision-making processes, and personal design frameworks. We then derive seven challenges commonly encountered in responsive maps, and 17 strategies to address them, such as repositioning elements, segmenting the map, or using alternative visualizations. We compile these challenges and strategies into an illustrated cheat sheet targeted at anyone designing or learning to design responsive maps. The cheat sheet is available online: responsive-vis.github.io/map-cheat-sheet.",Sarah Schöttler;Uta Hinrichs;Benjamin Bach,Sarah Schöttler;Uta Hinrichs;Benjamin Bach,"University of Edinburgh, U.K.;University of Edinburgh, U.K.;Inria and the University of Edinburgh, U.K.",10.1109/tvcg.2021.3114782;10.1109/tvcg.2009.111;10.1109/tvcg.2021.3114959;10.1109/tvcg.2012.213;10.1109/tvcg.2020.3030423,"information visualization,responsive visualization,,,thematic map design",,0.0,35.0,125.0,,,design responsive maps;visualization thematic;elements segmenting;practitioners motivations;illegible,0.7592;0.5158;0.1898;0.1437;0.1101,"[np.int64(-1), np.int64(-1), -1, -1, -1]",83;269;-1;-1;-1,83;269,83
InfoVis,1995,Research report: information animation applications in the capital markets,10.1109/infvis.1995.528682,http://dx.doi.org/10.1109/INFVIS.1995.528682,19.0,25.0,C,"3D computer graphics can be extremely expressive. It is possible to display an entire securities market, like the S&amp;P 500, on a single screen. With the correct approach to the visual design of the layout, these massive amounts of information can be quickly and easily comprehended by a human observer. By using motion and animated interaction, it is possible to use 3D as a reliable, accurate and precise decision-support tool. Information animation applications are particularly suited to the securities industry because that is where we find huge amounts of data, the value of which declines rapidly with time, and where critical decisions are being made on this data in very short periods of time. Information animation technology is an important new tool for the securities industry, where people need to be in the decision-making loop without suffering from information overload. Several examples are discussed including equity trading analytics, fixed income trading analytics and fixed-income risk viewing.",W. Wright,W. Wright,"Visible Decisions, Inc., Toronto, Canada",,,106.0,9.0,10.0,218.0,,,information animation applications;trading analytics fixed;single screen correct;discussed including equity;overload,0.6785;0.2902;0.1798;0.1548;0.1197,"[np.int64(-1), -1, -1, -1, -1]",317;-1;-1;-1;-1,317,317
Vis,2004,Interactive thickness visualization of articular cartilage,10.1109/visual.2004.56,http://dx.doi.org/10.1109/VISUAL.2004.56,521.0,527.0,C,"This work describes a method to visualize the thickness of curved thin objects. Given the MRI volume data of articular cartilage, medical doctors investigate pathological changes of the thickness. Since the tissue is very thin, it is impossible to reliably map the thickness information by direct volume rendering. Our idea is based on unfolding of such structures preserving their thickness. This allows to perform anisotropic geometrical operations (e.g., scaling the thickness). However, flattening of a curved structure implies a distortion of its surface. The distortion problem is alleviated through a focus-and-context minimization approach. Distortion is smallest close to a focal point which can be interactively selected by the user.",Matej Mlejnek;Anna Vilanova;M. Eduard Gröller,M. Mlejnek;A. Vilanova;M.E. Groller,"ICGA, University of Technology, Vienna, Austria;Department of Biomedical Engineering, Eindhovan University of Technology, Netherlands;ICGA, University of Technology, Vienna, Austria",10.1109/visual.2002.1183795;10.1109/visual.2002.1183754;10.1109/visual.2001.964540;10.1109/visual.2002.1183795,"visualization in medicine, applications of visualization",24.0,7.0,23.0,83.0,,,visualize thickness curved;based unfolding structures;cartilage medical doctors;focus context minimization;reliably,0.6034;0.3239;0.2894;0.2630;0.0334,"[np.int64(-1), -1, -1, -1, -1]",241;-1;-1;-1;-1,241,241
VAST,2017,SkyLens: Visual Analysis of Skyline on Multi-Dimensional Data,10.1109/tvcg.2017.2744738,http://dx.doi.org/10.1109/TVCG.2017.2744738,246.0,255.0,J,"Skyline queries have wide-ranging applications in fields that involve multi-criteria decision making, including tourism, retail industry, and human resources. By automatically removing incompetent candidates, skyline queries allow users to focus on a subset of superior data items (i.e., the skyline), thus reducing the decision-making overhead. However, users are still required to interpret and compare these superior items manually before making a successful choice. This task is challenging because of two issues. First, people usually have fuzzy, unstable, and inconsistent preferences when presented with multiple candidates. Second, skyline queries do not reveal the reasons for the superiority of certain skyline points in a multi-dimensional space. To address these issues, we propose SkyLens, a visual analytic system aiming at revealing the superiority of skyline points from different perspectives and at different scales to aid users in their decision making. Two scenarios demonstrate the usefulness of SkyLens on two datasets with a dozen of attributes. A qualitative study is also conducted to show that users can efficiently accomplish skyline understanding and comparison tasks with SkyLens.",Xun Zhao;Yanhong Wu;Weiwei Cui;Xinnan Du;Yuan Chen;Yong Wang 0021;Dik Lun Lee;Huamin Qu,Xun Zhao;Yanhong Wu;Weiwei Cui;Xinnan Du;Yuan Chen;Yong Wang;Dik Lun Lee;Huamin Qu,Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Microsoft Research Asia;Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Hong Kong University of Science and Technology,10.1109/tvcg.2013.173;10.1109/tvcg.2016.2598432;10.1109/tvcg.2016.2598589;10.1109/tvcg.2015.2468011;10.1109/tvcg.2013.173,"Skyline query,skyline visualization,multi-dimensional data,visual analytics,multi-criteria decision making",39.0,34.0,49.0,1895.0,,,accomplish skyline understanding;inconsistent preferences presented;usually fuzzy;allow users focus;resources,0.6511;0.2521;0.0962;0.0885;0.0660,"[np.int64(-1), -1, -1, -1, -1]",237;-1;-1;-1;-1,237,237
Vis,2008,Relation-Aware Volume Exploration Pipeline,10.1109/tvcg.2008.159,http://dx.doi.org/10.1109/TVCG.2008.159,1683.0,1690.0,J,"Volume exploration is an important issue in scientific visualization. Research on volume exploration has been focused on revealing hidden structures in volumetric data. While the information of individual structures or features is useful in practice, spatial relations between structures are also important in many applications and can provide further insights into the data. In this paper, we systematically study the extraction, representation,exploration, and visualization of spatial relations in volumetric data and propose a novel relation-aware visualization pipeline for volume exploration. In our pipeline, various relations in the volume are first defined and measured using region connection calculus (RCC) and then represented using a graph interface called relation graph. With RCC and the relation graph, relation query and interactive exploration can be conducted in a comprehensive and intuitive way. The visualization process is further assisted with relation-revealing viewpoint selection and color and opacity enhancement. We also introduce a quality assessment scheme which evaluates the perception of spatial relations in the rendered images. Experiments on various datasets demonstrate the practical use of our system in exploratory visualization.",Ming-Yuen Chan;Huamin Qu;Ka-Kei Chung;Wai-Ho Mak;Yingcai Wu,Ming-Yuen Chan;Huamin Qu;Ka-Kei Chung;Wai-Ho Mak;Yingcai Wu,"Department of Computer Science and Engineering, Hong Kong University of Science and Technology, Kowloon, Hong Kong, China;Department of Computer Science and Engineering, Hong Kong University of Science and Technology, Kowloon, Hong Kong, China;Department of Computer Science and Engineering, Hong Kong University of Science and Technology, Kowloon, Hong Kong, China;Department of Computer Science and Engineering, Hong Kong University of Science and Technology, Kowloon, Hong Kong, China;Department of Computer Science and Engineering, Hong Kong University of Science and Technology, Kowloon, Hong Kong, China",10.1109/tvcg.2007.70584;10.1109/tvcg.2007.70515;10.1109/tvcg.2006.144;10.1109/visual.1999.809871;10.1109/tvcg.2007.70535;10.1109/tvcg.2007.70576;10.1109/visual.2000.885694;10.1109/infvis.2003.1249009;10.1109/tvcg.2007.70555;10.1109/visual.2005.1532835;10.1109/visual.2005.1532788;10.1109/tvcg.2007.70591;10.1109/visual.2005.1532834;10.1109/visual.2005.1532856;10.1109/tvcg.2007.70572;10.1109/visual.2005.1532833;10.1109/tvcg.2007.70584,"Exploratory Visualization, Relation-Based Visualization, Visualization Pipeline",26.0,11.0,28.0,264.0,,,visualization spatial relations;volume exploration pipeline;color opacity enhancement;calculus rcc;conducted,0.7113;0.4786;0.1496;0.1164;-0.1192,"[np.int64(-1), -1, -1, -1, -1]",154;-1;-1;-1;-1,154,154
InfoVis,2019,A Comparison of Radial and Linear Charts for Visualizing Daily Patterns,10.1109/tvcg.2019.2934784,http://dx.doi.org/10.1109/TVCG.2019.2934784,1033.0,1042.0,J,"Radial charts are generally considered less effective than linear charts. Perhaps the only exception is in visualizing periodical time-dependent data, which is believed to be naturally supported by the radial layout. It has been demonstrated that the drawbacks of radial charts outweigh the benefits of this natural mapping. Visualization of daily patterns, as a special case, has not been systematically evaluated using radial charts. In contrast to yearly or weekly recurrent trends, the analysis of daily patterns on a radial chart may benefit from our trained skill on reading radial clocks that are ubiquitous in our culture. In a crowd-sourced experiment with 92 non-expert users, we evaluated the accuracy, efficiency, and subjective ratings of radial and linear charts for visualizing daily traffic accident patterns. We systematically compared juxtaposed 12-hours variants and single 24-hours variants for both layouts in four low-level tasks and one high-level interpretation task. Our results show that over all tasks, the most elementary 24-hours linear bar chart is most accurate and efficient and is also preferred by the users. This provides strong evidence for the use of linear layouts – even for visualizing periodical daily patterns.",Manuela Waldner;Alexandra Diehl;Denis Gracanin;Rainer Splechtna;Claudio Delrieux;Kresimir Matkovic,Manuela Waldner;Alexandra Diehl;Denis Gračanin;Rainer Splechtna;Claudio Delrieux;Krešimir Matković,"TU Wien;University of Zurich;Virginia Tech;VRVis Research Center;Electric and Computer Eng. Dept., Universidad Nacional del SUR and CONICET;VRVis Research Center",10.1109/tvcg.2013.184;10.1109/tvcg.2018.2865142;10.1109/tvcg.2013.234;10.1109/tvcg.2018.2865234;10.1109/infvis.1998.729557;10.1109/tvcg.2010.209;10.1109/tvcg.2014.2346426;10.1109/tvcg.2018.2865077;10.1109/tvcg.2015.2467771;10.1109/tvcg.2010.162;10.1109/tvcg.2018.2865158;10.1109/infvis.2000.885091;10.1109/tvcg.2014.2346320;10.1109/infvis.2001.963273;10.1109/tvcg.2013.184,"Radial charts,time series series data,daily patterns,crowd-sourced experiment",23.0,15.0,54.0,1344.0,,,visualization daily patterns;drawbacks radial;expert users evaluated;layouts low level;accident,0.6421;0.2441;0.2402;0.1285;0.0950,"[np.int64(-1), -1, -1, -1, -1]",163;-1;-1;-1;-1,163,163
Vis,1997,VizWiz: a Java applet for interactive 3D scientific visualization on the Web,10.1109/visual.1997.663891,http://dx.doi.org/10.1109/VISUAL.1997.663891,261.0,267.0,C,"VizWiz is a Java applet that provides basic interactive scientific visualization functionality, such as isosurfaces, cutting planes, and elevation plots, for 2D and 3D datasets that can be loaded into the applet by the user via, the applet's Web server. VizWiz is unique in that it is a completely platform independent scientific visualization tool, and is usable over the Web, without being manually downloaded or installed. Its 3D graphics are implemented using only the Java AWT API, making them portable across all Java supporting platforms. The paper describes the implementation of VizWiz, including design tradeoffs. Graphics performance figures are provided for a number of different platforms. A solution to the problem of uploading user data files into a Java applet, working around security limitations, is demonstrated. The lessons learned from this project are discussed.",Cherilyn Michaels;Michael J. Bailey,C. Michaels;M. Bailey,"Department of Computer Science B Engineering, University of California, San Diego, La Jolla, CA, USA;Department of Computer Science and Engineering, University of California, San Diego, La Jolla, CA, USA and San Diego Supercomputing Center, San Diego, CA, USA",10.1109/visual.1990.146361;10.1109/visual.1990.146361,,63.0,10.0,6.0,143.0,,,scientific visualization functionality;portable java;isosurfaces cutting;awt api;loaded,0.6660;0.3591;0.2656;0.2277;-0.0005,"[np.int64(-1), -1, -1, -1, -1]",149;-1;-1;-1;-1,149,149
InfoVis,1996,Interactive visualization of multiway tables,10.1109/infvis.1996.559221,http://dx.doi.org/10.1109/INFVIS.1996.559221,68.0,,M,Many business data visualization applications involve large databases with dozens of fields and millions of rows. Interactive visualization of these databases is difficult because of the large amount of data involved. We present a method of summarizing large databases which is well suited to interactive visualization. We illustrate this with a visualization tool for the domain of call billing data.,Kenneth C. Cox;Dianne Hackborn,K.C. Cox;D. Hackborn,"Lucent Technologies, Bell Laboratories, Naperville, IL, USA;Oregon State University, Corvallis, OR, USA",0.1109/visual.1991.175794;10.1109/visual.1990.146389,,3.0,0.0,6.0,118.0,,,business data visualization;method summarizing;domain billing;dozens;suited,0.7556;0.3155;0.2121;0.1603;0.0144,"[np.int64(-1), -1, -1, -1, -1]",198;-1;-1;-1;-1,198,198
Vis,2001,A tetrahedra-based stream surface algorithm,10.1109/visual.2001.964506,http://dx.doi.org/10.1109/VISUAL.2001.964506,151.0,158.0,C,"This paper presents a new algorithm for the calculation of stream surfaces for tetrahedral grids. It propagates the surface through the tetrahedra, one at a time, calculating the intersections with the tetrahedral faces. The method allows us to incorporate topological information from the cells, e.g. critical points. The calculations are based on barycentric coordinates, since this simplifies the theory and the algorithm. The stream surfaces are ruled surfaces inside each cell, and their construction starts with line segments on the faces. Our method supports the analysis of velocity fields resulting from computational fluid dynamics (CFD) simulations.",Gerik Scheuermann;Tom Bobach;Hans Hagen;Karim Mahrous;Bernd Hamann;Kenneth I. Joy;Wolfgang Kollmann,G. Scheuermann;T. Bobach;H. Hagen;K. Mahrous;B. Hamann;K.I. Joy;W. Kollmann,"Computer Science Department, University of Kaiserslautern, Kaiserslautern, Germany and Center for image Processing and Integrated Computing (CIPIC), Department of Computer Science, University of California, Davis, CA;Computer Science Department, University of Kaiserslautern, Kaiserslautern, Germany;Computer Science Department, University of Kaiserslautern, Kaiserslautern, Germany;Center for image Processing and Integrated Computing (CIPIC), Department of Computer Science, University of California, Davis, CA;Center for image Processing and Integrated Computing (CIPIC), Department of Computer Science, University of California, Davis, CA;Center for image Processing and Integrated Computing (CIPIC), Department of Computer Science, University of California, Davis, CA;Department of mechanaical and Aeronanutical Engineering, University of California, Davis, CA",10.1109/visual.1993.398875;10.1109/visual.1992.235211;10.1109/visual.1995.485145;10.1109/visual.1999.809896;10.1109/visual.1997.663910;10.1109/visual.1993.398875,"vector field visualization, flow visualization, tetrahedral grid, unstructured grid, flow surface",85.0,22.0,13.0,170.0,,,stream surfaces tetrahedral;dynamics cfd simulations;time calculating intersections;inside cell;method supports,0.7305;0.4283;0.2043;0.0754;-0.0059,"[np.int64(-1), -1, -1, -1, -1]",307;-1;-1;-1;-1,307,307
Vis,1992,"Color, change, and control of quantitative data display",10.1109/visual.1992.235201,http://dx.doi.org/10.1109/VISUAL.1992.235201,252.0,259.0,C,"Calico, a dynamic tool for the creation and manipulation of color mappings for the exploration of multivariate, quantitative data, was used to study the effects of user control and smooth change on user preference, accuracy, and confidence. The results of the study, as well as other user experiences with Calico, support the hypothesis that dynamic manipulation of color mappings is a useful feature of systems for the exploration of quantitative data using color. The main effect observed is a clear user preference for representations providing control over the mapping, a small but significant increase in accuracy, and greater confidence in information gleaned from manipulable displays. A smaller and less consistent effect showed greater user preference for an confidence in representations which provided smooth change between images.&lt;&lt;ETX&gt;&gt;",Penny Rheingans,P. Rheingans,"Department of Computer Science, North Carolina State University, Chapel Hill, NC, USA",10.1109/visual.1990.146383;10.1109/visual.1990.146383,,62.0,11.0,13.0,138.0,,,color mappings useful;systems exploration quantitative;calico dynamic tool;change user preference;small significant increase,0.5820;0.2917;0.2588;0.2361;0.1284,"[np.int64(-1), -1, -1, -1, -1]",129;-1;-1;-1;-1,129,129
Vis,2023,"PROWIS: A Visual Approach for Building, Managing, and Analyzing Weather Simulation Ensembles at Runtime",10.1109/tvcg.2023.3326514,http://dx.doi.org/10.1109/TVCG.2023.3326514,738.0,747.0,J,"Weather forecasting is essential for decision-making and is usually performed using numerical modeling. Numerical weather models, in turn, are complex tools that require specialized training and laborious setup and are challenging even for weather experts. Moreover, weather simulations are data-intensive computations and may take hours to days to complete. When the simulation is finished, the experts face challenges analyzing its outputs, a large mass of spatiotemporal and multivariate data. From the simulation setup to the analysis of results, working with weather simulations involves several manual and error-prone steps. The complexity of the problem increases exponentially when the experts must deal with ensembles of simulations, a frequent task in their daily duties. To tackle these challenges, we propose ProWis: an interactive and provenance-oriented system to help weather experts build, manage, and analyze simulation ensembles at runtime. Our system follows a human-in-the-loop approach to enable the exploration of multiple atmospheric variables and weather scenarios. ProWis was built in close collaboration with weather experts, and we demonstrate its effectiveness by presenting two case studies of rainfall events in Brazil.",Carolina Veiga Ferreira de Souza;Suzanna Maria Bonnet;Daniel de Oliveira 0001;Márcio Cataldi;Fabio Miranda 0001;Marcos Lage,Carolina Veiga Ferreira de Souza;Suzanna Maria Bonnet;Daniel de Oliveira;Marcio Cataldi;Fabio Miranda;Marcos Lage,"Universidade Federal Fluminense and the University of Illinois, USA;Universidade Federal do Rio de Janeiro, Brazil;Universidade Federal Fluminense, Brazil;Universidade Federal Fluminense, Brazil;University of Illinois Chicago, USA;Universidade Federal Fluminense, Brazil",0.1109/tvcg.2016.2598869;10.1109/tvcg.2010.181;10.1109/tvcg.2018.2865024;10.1109/tvcg.2016.2598830;10.1109/tvcg.2011.225,"Weather visualization,Ensemble visualization,Provenance management,WRF visual setup",,0.0,36.0,488.0,HM,,experts weather simulations;interactive provenance;events brazil;problem increases;usually,0.7316;0.4091;0.1403;0.0304;0.0036,"[np.int64(-1), -1, -1, -1, -1]",48;-1;-1;-1;-1,48,48
Vis,1996,BLaC-wavelets: a multiresolution analysis with non-nested spaces,10.1109/visual.1996.567602,http://dx.doi.org/10.1109/VISUAL.1996.567602,43.0,48.0,C,"In the last five years, there has been numerous applications of wavelets and multiresolution analysis in many fields of computer graphics as different as geometric modelling, volume visualization or illumination modelling. Classical multiresolution analysis is based on the knowledge of a nested set of functional spaces in which the successive approximations of a given function converge to that function, and can be efficiently computed. This paper first proposes a theoretical framework which enables multiresolution analysis even if the functional spaces are not nested, as long as they still have the property that the successive approximations converge to the given function. Based on this concept, we finally introduce a new multiresolution analysis with exact reconstruction for large data sets defined on uniform grids. We construct a one-parameter family of multiresolution analyses which is a blending of Haar and linear multiresolution, using BLaC (Blending of Linear and Constant) wavelets.",Georges-Pierre Bonneau;Stefanie Hahmann;Gregory M. Nielson,G.-P. Bonneau;S. Hahmann;G.M. Nielson,"Laboratoire LMC, CNRS, Grenoble, France;Laboratoire LMC, CNRS, Grenoble, France;Arizona State University, Tempe, USA",,,73.0,21.0,6.0,86.0,,,wavelets multiresolution;visualization illumination modelling;graphics different geometric;functional spaces;converge given,0.6827;0.4322;0.2160;0.1287;0.0250,"[np.int64(-1), -1, -1, -1, -1]",99;-1;-1;-1;-1,99,99
Vis,1999,C1-interpolation for vector field topology visualization,10.1109/visual.1999.809897,http://dx.doi.org/10.1109/VISUAL.1999.809897,271.0,533.0,C,An application of C/sup 1/ scalar interpolation for 2D vector field topology visualization is presented. Powell-Sabin and Nielson interpolants are considered which both make use of Nielson's Minimum Norm Network for the precomputation of the derivatives in our implementation. A comparison of their results to the commonly used linear interpolant underlines their significant improvement of singularity location and topological skeleton depiction. Evaluation is based upon the processing of polynomial vector fields with known topology containing higher order singularities.,Gerik Scheuermann;Xavier Tricoche;Hans Hagen,G. Scheuermann;X. Tricoche;H. Hagen,"Department of Computer Science, Computer Graphics & CAGD, University of Kaiserslautern, Kaiserslautern, Germany;Department of Computer Science, Computer Graphics & CAGD, University of Kaiserslautern, Kaiserslautern, Germany;Department of Computer Science, Computer Graphics & CAGD, University of Kaiserslautern, Kaiserslautern, Germany",10.1109/visual.1991.175773;10.1109/visual.1998.745284;10.1109/visual.1998.745296;10.1109/visual.1991.175773,"vector field visualization, topology, critical point theory, C1-interpolation",45.0,15.0,13.0,116.0,,,field topology visualization;linear interpolant;higher order singularities;derivatives implementation comparison;commonly used,0.6261;0.4328;0.3277;0.2654;0.0302,"[np.int64(-1), -1, -1, -1, -1]",153;-1;-1;-1;-1,153,153
Vis,2006,High-Quality Extraction of Isosurfaces from Regular and Irregular Grids,10.1109/tvcg.2006.149,http://dx.doi.org/10.1109/TVCG.2006.149,1205.0,1212.0,J,"Isosurfaces are ubiquitous in many fields, including visualization, graphics, and vision. They are often the main computational component of important processing pipelines (e.g., surface reconstruction), and are heavily used in practice. The classical approach to compute isosurfaces is to apply the Marching Cubes algorithm, which although robust and simple to implement, generates surfaces that require additional processing steps to improve triangle quality and mesh size. An important issue is that in some cases, the surfaces generated by Marching Cubes are irreparably damaged, and important details are lost which can not be recovered by subsequent processing. The main motivation of this work is to develop a technique capable of constructing high-quality and high-fidelity isosurfaces. We propose a new advancing front technique that is capable of creating high-quality isosurfaces from regular and irregular volumetric datasets. Our work extends the guidance field framework of Schreiner et al. to implicit surfaces, and improves it in significant ways. In particular, we describe a set of sampling conditions that guarantee that surface features will be captured by the algorithm. We also describe an efficient technique to compute a minimal guidance field, which greatly improves performance. Our experimental results show that our technique can generate high-quality meshes from complex datasets",John M. Schreiner;Carlos Eduardo Scheidegger;Cláudio T. Silva,John Schreiner;Carlos Scheidegger;Claudio Silva,"SCI Institute at the University of Utah, USA;SCI Institute at the University of Utah, USA;SCI Institute at the University of Utah, USA",10.1109/visual.1991.175782;10.1109/visual.2000.885705;10.1109/visual.1997.663930;10.1109/visual.2003.1250414;10.1109/visual.2004.52;10.1109/visual.1991.175782,"Isosurface Extraction, Curvature, Advancing Front",113.0,57.0,51.0,788.0,,,high fidelity isosurfaces;cubes irreparably damaged;marching;generated;subsequent processing main,0.7204;0.1826;0.1672;0.1124;-0.0189,"[np.int64(-1), -1, -1, -1, -1]",92;-1;-1;-1;-1,92,92
Vis,2009,Curve-Centric Volume Reformation for Comparative Visualization,10.1109/tvcg.2009.136,http://dx.doi.org/10.1109/TVCG.2009.136,1235.0,1242.0,J,"We present two visualization techniques for curve-centric volume reformation with the aim to create compelling comparative visualizations. A curve-centric volume reformation deforms a volume, with regards to a curve in space, to create a new space in which the curve evaluates to zero in two dimensions and spans its arc-length in the third. The volume surrounding the curve is deformed such that spatial neighborhood to the curve is preserved. The result of the curve-centric reformation produces images where one axis is aligned to arc-length, and thus allows researchers and practitioners to apply their arc-length parameterized data visualizations in parallel for comparison. Furthermore we show that when visualizing dense data, our technique provides an inside out projection, from the curve and out into the volume, which allows for inspection what is around the curve. Finally we demonstrate the usefulness of our techniques in the context of two application cases. We show that existing data visualizations of arc-length parameterized data can be enhanced by using our techniques, in addition to creating a new view and perspective on volumetric data around curves. Additionally we show how volumetric data can be brought into plotting environments that allow precise readouts. In the first case we inspect streamlines in a flow field around a car, and in the second we inspect seismic volumes and well logs from drilling.",Ove Daae Lampe;Carlos D. Correa;Kwan-Liu Ma;Helwig Hauser,Ove Daae Lampe;Carlos Correa;Kwan-Liu Ma;Helwig Hauser,"CMR AS, University of Bergen, Norway;University of California, Davis, USA;University of California, Davis, USA;University of Bergen, Norway",10.1109/tvcg.2006.144;10.1109/visual.2002.1183754;10.1109/visual.2001.964540;10.1109/visual.1992.235194;10.1109/visual.2003.1250353;10.1109/tvcg.2006.144,"Volume Deformation, Curve-Centric-Reformation, Comparative Visualization, Radial Ray-Casting",44.0,29.0,29.0,574.0,,,volumetric data curves;aligned arc length;parallel comparison;reformation produces;aim,0.6169;0.2294;0.1326;0.1231;-0.0200,"[np.int64(-1), -1, -1, -1, -1]",293;-1;-1;-1;-1,293,293
InfoVis,1999,Domain analysis: a technique to design a user-centered visualization framework,10.1109/infvis.1999.801856,http://dx.doi.org/10.1109/INFVIS.1999.801856,44.0,,C,"Domain Analysis for Data Visualization (DADV) is a technique to use when investigating a domain where data visualizations are going to be designed and added to existing software systems. DADV was used to design the data visualization in VisEIO-LCA, which is a framework to visualize environmental data about products. Most of the visualizations are designed using the following stages: formatting data in tables, selecting visual structures, and rendering the data on the screen. Although many visualization authors perform implicit domain analysis, in this paper domain analysis is added explicitly to the process of designing visualizations with the goal of producing move usable software tools. Environmental Life-Cycle Assessment (LCA) is used as a test bed for this technique.",Octavio Juarez Espinosa;Chris Hendrickson;James H. Garrett Jr.,O.J. Espinosa;C. Hendrickson;J.H. Garrett,"Civil and Environmental Engineering Department, Carnegie Mellon University, Pittsburgh, PA, USA;Civil and Environmental Engineering Department, Carnegie Mellon University, Pittsburgh, PA, USA;Civil and Environmental Engineering Department, Carnegie Mellon University, Pittsburgh, PA, USA",10.1109/infvis.1996.559210;10.1109/visual.1991.175815;10.1109/infvis.1996.559210,"Visualization framework, Life-Cycle Assessment, user tasks, computer-human interaction, domain analysis, economic input-output",24.0,3.0,25.0,201.0,,,domain data visualizations;explicitly process designing;environmental life cycle;viseio lca;dadv technique,0.6774;0.3809;0.3620;0.1923;0.0462,"[np.int64(-1), -1, -1, -1, -1]",198;-1;-1;-1;-1,198,198
InfoVis,2011,"VisBricks: Multiform Visualization of Large, Inhomogeneous Data",10.1109/tvcg.2011.250,http://dx.doi.org/10.1109/TVCG.2011.250,2291.0,2300.0,J,"Large volumes of real-world data often exhibit inhomogeneities: vertically in the form of correlated or independent dimensions and horizontally in the form of clustered or scattered data items. In essence, these inhomogeneities form the patterns in the data that researchers are trying to find and understand. Sophisticated statistical methods are available to reveal these patterns, however, the visualization of their outcomes is mostly still performed in a one-view-fits-all manner, In contrast, our novel visualization approach, VisBricks, acknowledges the inhomogeneity of the data and the need for different visualizations that suit the individual characteristics of the different data subsets. The overall visualization of the entire data set is patched together from smaller visualizations, there is one VisBrick for each cluster in each group of interdependent dimensions. Whereas the total impression of all VisBricks together gives a comprehensive high-level overview of the different groups of data, each VisBrick independently shows the details of the group of data it represents, State-of-the-art brushing and visual linking between all VisBricks furthermore allows the comparison of the groupings and the distribution of data items among them. In this paper, we introduce the VisBricks visualization concept, discuss its design rationale and implementation, and demonstrate its usefulness by applying it to a use case from the field of biomedicine.",Alexander Lex;Hans-Jörg Schulz;Marc Streit;Christian Partl;Dieter Schmalstieg,Alexander Lex;Hans-Jorg Schulz;Marc Streit;Christian Partl;Dieter Schmalstieg,"Graz University of Technology, Austria;Graz University of Technology, Austria;Graz University of Technology, Austria;Graz University of Technology, Austria;Graz University of Technology, Austria",10.1109/infvis.2005.1532129;10.1109/tvcg.2010.138;10.1109/tvcg.2006.120;10.1109/tvcg.2007.70582;10.1109/infvis.2003.1249006;10.1109/tvcg.2006.147;10.1109/tvcg.2009.167;10.1109/tvcg.2010.216;10.1109/tvcg.2006.166;10.1109/tvcg.2007.70521;10.1109/infvis.2005.1532129,"Inhomogeneous data, multiple coordinated views, multiform visualization",67.0,48.0,34.0,1173.0,,,visualizations visbrick cluster;acknowledges inhomogeneity data;comparison;case field biomedicine;brushing,0.6155;0.2827;0.1658;0.1584;0.0669,"[np.int64(-1), -1, -1, -1, -1]",164;-1;-1;-1;-1,164,164
InfoVis,1998,Saying it in graphics: from intentions to visualizations,10.1109/infvis.1998.729564,http://dx.doi.org/10.1109/INFVIS.1998.729564,97.0,101.0,C,"The authors propose a methodology for automatically realizing communicative goals in graphics. It features a task model that mediates the communicative intent and the selection of graphical techniques. The methodology supports the following functions: isolating assertions presentable in graphics; mapping such assertions into tasks for the potential reader, and selecting graphical techniques that support those tasks. They illustrate the methodology by redesigning a textual argument into a multimedia one with the same rhetorical and content structures but employing graphics to achieve some of the intentions.",Stephan M. Kerpedjiev;Giuseppe Carenini;Nancy L. Green;Johanna D. Moore;Steven F. Roth,S. Kerpedjiev;G. Carenini;N. Green;J. Moore;S. Roth,"Carnegie Mellon University, Pittsburgh, PA, USA;University of Pittsburgh, Pittsburgh, PA, USA;Carnegie Mellon University, Pittsburgh, PA, USA;University of Pittsburgh, Pittsburgh, PA, USA;Carnegie Mellon University, Pittsburgh, PA, USA",,,43.0,4.0,11.0,94.0,,,communicative goals graphics;textual argument;authors propose;automatically;following functions isolating,0.7272;0.4981;0.0699;0.0476;0.0076,"[np.int64(-1), -1, -1, -1, -1]",173;-1;-1;-1;-1,173,173
Vis,2024,PREVis: Perceived Readability Evaluation for Visualizations,10.1109/tvcg.2024.3456318,http://dx.doi.org/10.1109/TVCG.2024.3456318,1083.0,1093.0,J,"We developed and validated an instrument to measure the perceived readability in data visualization: PREVis. Researchers and practitioners can easily use this instrument as part of their evaluations to compare the perceived readability of different visual data representations. Our instrument can complement results from controlled experiments on user task performance or provide additional data during in-depth qualitative work such as design iterations when developing a new technique. Although readability is recognized as an essential quality of data visualizations, so far there has not been a unified definition of the construct in the context of visual representations. As a result, researchers often lack guidance for determining how to ask people to rate their perceived readability of a visualization. To address this issue, we engaged in a rigorous process to develop the first validated instrument targeted at the subjective readability of visual data representations. Our final instrument consists of 11 items across 4 dimensions: understandability, layout clarity, readability of data values, and readability of data patterns. We provide the questionnaire as a document with implementation guidelines on osf.io/9cg8j. Beyond this instrument, we contribute a discussion of how researchers have previously assessed visualization readability, and an analysis of the factors underlying perceived readability in visual data representations.",Anne-Flore Cabouat;Tingying He;Petra Isenberg;Tobias Isenberg 0001,Anne-Flore Cabouat;Tingying He;Petra Isenberg;Tobias Isenberg,"CNRS, Inria, LISN, Université Paris-Saclay, France;CNRS, Inria, LISN, Université Paris-Saclay, France;CNRS, Inria, LISN, Université Paris-Saclay, France;CNRS, Inria, LISN, Université Paris-Saclay, France",10.1109/infvis.2005.1532136;10.1109/tvcg.2010.159;10.1109/tvcg.2014.2346984;10.1109/infvis.1997.636794;10.1109/tvcg.2013.124;10.1109/tvcg.2020.3030404;10.1109/tvcg.2023.3327165;10.1109/tvcg.2023.3326579;10.1109/tvcg.2023.3326596;10.1109/tvcg.2014.2346435;10.1109/tvcg.2021.3114805;10.1109/tvcg.2022.3209390;10.1109/tvcg.2008.141;10.1109/tvcg.2013.126;10.1109/tvcg.2015.2467195;10.1109/tvcg.2016.2598920;10.1109/tvcg.2022.3209459;10.1109/tvcg.2014.2346481;10.1109/tvcg.2012.255;10.1109/tvcg.2022.3209472;10.1109/tvcg.2007.70529;10.1109/tvcg.2023.3327148;10.1109/tvcg.2022.3209405,"Visualization,readability,,,validated instrument,perception,user experiments,empirical methods,methodology",,0.0,113.0,276.0,HM,X,assessed visualization readability;data patterns provide;use instrument;far unified definition;address,0.8529;0.2255;0.0849;0.0756;-0.0225,"[np.int64(-1), -1, -1, -1, -1]",266;-1;-1;-1;-1,266,266
VAST,2016,PorosityAnalyzer: Visual Analysis and Evaluation of Segmentation Pipelines to Determine the Porosity in Fiber-Reinforced Polymers,10.1109/vast.2016.7883516,http://dx.doi.org/10.1109/VAST.2016.7883516,101.0,110.0,C,"In this paper we present PorosityAnalyzer, a novel tool for detailed evaluation and visual analysis of pore segmentation pipelines to determine the porosity in fiber-reinforced polymers (FRPs). The presented tool consists of two modules: the computation module and the analysis module. The computation module enables a convenient setup and execution of distributed off-line-computations on industrial 3D X-ray computed tomography datasets. It allows the user to assemble individual segmentation pipelines in the form of single pipeline steps, and to specify the parameter ranges as well as the sampling of the parameter-space of each pipeline segment. The result of a single segmentation run consists of the input parameters, the calculated 3D binary-segmentation mask, the resulting porosity value, and other derived results (e.g., segmentation pipeline run-time). The analysis module presents the data at different levels of detail by drill-down filtering in order to determine accurate and robust segmentation pipelines. Overview visualizations allow to initially compare and evaluate the segmentation pipelines. With a scatter plot matrix (SPLOM), the segmentation pipelines are examined in more detail based on their input and output parameters. Individual segmentation-pipeline runs are selected in the SPLOM and visually examined and compared in 2D slice views and 3D renderings by using aggregated segmentation masks and statistical contour renderings. PorosityAnalyzer has been thoroughly evaluated with the help of twelve domain experts. Two case studies demonstrate the applicability of our proposed concepts and visualization techniques, and show that our tool helps domain experts to gain new insights and improve their workflow efficiency.",Johannes Weissenbock;Artem Amirkhanov;M. Eduard Gröller;Johann Kastner;Christoph Heinzl,Johannes Weissenböck;Artem Amirkhanov;Eduard Gröller;Johann Kastner;Christoph Heinzl,"University of Applied Sciences, Wels, Upper Austria, Austria;University of Applied Sciences, Wels, Upper Austria, Austria;VrVis Research Center, Austria and TU Wien, Vienna, Austria;University of Applied Sciences, Wels, Upper Austria, Austria;University of Applied Sciences, Wels, Upper Austria, Austria",10.1109/tvcg.2013.147;10.1109/tvcg.2008.153;10.1109/visual.1993.398859;10.1109/tvcg.2012.200;10.1109/tvcg.2011.253;10.1109/tvcg.2014.2346321;10.1109/tvcg.2013.177;10.1109/tvcg.2011.248;10.1109/tvcg.2013.147,,21.0,11.0,33.0,520.0,,,contour renderings porosityanalyzer;fiber reinforced polymers;3d binary;pipeline runs selected;using aggregated,0.6155;0.3547;0.3002;0.1404;0.0299,"[np.int64(-1), -1, -1, -1, -1]",254;-1;-1;-1;-1,254,254
Vis,1996,Results in mathematics and music: Visualization of roughness in musical consonance,10.1109/visual.1996.568130,http://dx.doi.org/10.1109/VISUAL.1996.568130,355.0,357.0,C,"The definition of consonance as the ability to resolve a sound into the pitch categories is introduced. For a vector space of chords a norm is used to evaluate the consonance linearly in dependence of the instrument used. It is shown that in the corresponding Hilbert space the chords which usually appear together in a conventional musical piece are recognized in terms of ""closeness"".",Florian Sobieczky,F. Sobieczky,,,,3.0,2.0,10.0,174.0,,,hilbert space chords;definition consonance ability;conventional musical piece;resolve sound;closeness,0.5781;0.4295;0.3850;0.3070;0.2227,"[np.int64(-1), -1, -1, -1, -1]",27;-1;-1;-1;-1,27,27
VAST,2018,Lessons Learned Developing a Visual Analytics Solution for Investigative Analysis of Scamming Activities,10.1109/tvcg.2018.2865023,http://dx.doi.org/10.1109/TVCG.2018.2865023,225.0,234.0,J,"The forensic investigation of communication datasets which contain unstructured text, social network information, and metadata is a complex task that is becoming more important due to the immense amount of data being collected. Currently there are limited approaches that allow an investigator to explore the network, text and metadata in a unified manner. We developed Beagle as a forensic tool for email datasets that allows investigators to flexibly form complex queries in order to discover important information in email data. Beagle was successfully deployed at a security firm which had a large email dataset that was difficult to properly investigate. We discuss our experience developing Beagle as well as the lessons we learned applying visual analytic techniques to a difficult real-world problem.",Jay Koven;Cristian Felix;Hossein Siadati;Markus Jakobsson;Enrico Bertini,Jay Koven;Cristian Felix;Hossein Siadati;Markus Jakobsson;Enrico Bertini,"New York University, New York, NY, US;New York University, New York, NY, US;New York University, New York, NY, US;Amber Solutions Inc.;New York University, New York, NY, US",10.1109/vast.2007.4389011;10.1109/vast.2010.5652968;10.1109/infvis.2003.1249028;10.1109/tvcg.2009.111;10.1109/tvcg.2014.2346481;10.1109/tvcg.2012.213,"Visual Analytics,Email Investigation,Email Forensics",13.0,7.0,26.0,976.0,,,forensic tool email;visual analytic techniques;datasets allows;developed beagle;unified manner,0.6511;0.3313;0.3026;0.1437;0.0539,"[np.int64(-1), -1, -1, -1, -1]",125;-1;-1;-1;-1,125,125
VAST,2007,Analysis Guided Visual Exploration of Multivariate Data,10.1109/vast.2007.4389000,http://dx.doi.org/10.1109/VAST.2007.4389000,83.0,90.0,C,"Visualization systems traditionally focus on graphical representation of information. They tend not to provide integrated analytical services that could aid users in tackling complex knowledge discovery tasks. Users' exploration in such environments is usually impeded due to several problems: 1) valuable information is hard to discover when too much data is visualized on the screen; 2) Users have to manage and organize their discoveries off line, because no systematic discovery management mechanism exists; 3) their discoveries based on visual exploration alone may lack accuracy; 4) and they have no convenient access to the important knowledge learned by other users. To tackle these problems, it has been recognized that analytical tools must be introduced into visualization systems. In this paper, we present a novel analysis-guided exploration system, called the nugget management system (NMS). It leverages the collaborative effort of human comprehensibility and machine computations to facilitate users' visual exploration processes. Specifically, NMS first extracts the valuable information (nuggets) hidden in datasets based on the interests of users. Given that similar nuggets may be re-discovered by different users, NMS consolidates the nugget candidate set by clustering based on their semantic similarity. To solve the problem of inaccurate discoveries, localized data mining techniques are applied to refine the nuggets to best represent the captured patterns in datasets. Lastly, the resulting well-organized nugget pool is used to guide users' exploration. To evaluate the effectiveness of NMS, we integrated NMS into Xmd- vTool, a freeware multivariate visualization system. User studies were performed to compare the users' efficiency and accuracy in finishing tasks on real datasets, with and without the help of NMS. Our user studies confirmed the effectiveness of NMS.",Di Yang 0003;Elke A. Rundensteiner;Matthew O. Ward,Di Yang;Elke A. Rundensteiner;Matthew O. Ward,"Worcester Polytechnic Institute, USA;Worcester Polytechnic Institute, USA;Worcester Polytechnic Institute, USA",10.1109/visual.1994.346302;10.1109/vast.2006.261415;10.1109/infvis.2004.71;10.1109/infvis.1997.636793;10.1109/vast.2006.261430;10.1109/visual.1994.346302,"Visual Analytics, Visual Knowledge Discovery, Discovery Management, Analysis Guided Exploration",74.0,15.0,27.0,434.0,,,discover data visualized;consolidates nugget candidate;freeware;different users nms;hard,0.6579;0.2297;0.1765;0.0671;0.0103,"[np.int64(-1), -1, -1, -1, -1]",259;-1;-1;-1;-1,259,259
Vis,2004,Intuitive and interactive modification of large finite element models,10.1109/visual.2004.58,http://dx.doi.org/10.1109/VISUAL.2004.58,361.0,368.0,C,"Virtual prototyping is increasingly replacing real mock-ups and experiments in industrial product development. Part of this process is the simulation of structural and functional properties, which is in many cases based on finite element analysis (FEA). One prominent example from the automotive industry is the safety improvement resulting from crash worthiness simulations. A simulation model for this purpose usually consists of up to one million finite elements and is assembled from many parts, which are individually meshed out of their CAD representation. In order to accelerate the development cycle, simulation engineers want to be able to modify their FE models without going back to the CAD department. Furthermore, valid CAD models might even not be available in preliminary design stages. However, in contrast to CAD, there is a lack of tools that offer the possibility of modification and processing of finite element components while maintaining the properties relevant to the simulation. In this application paper we present interactive algorithms for intuitive and fast editing of FE models and appropriate visualization techniques to support engineers in understating these models. This includes new kinds of manipulators, feedback mechanisms and facilities for virtual reality and immersion at the workplace, e.g. autostereoscopic displays and haptic devices.",Dirc Rose;Katrin Bidmon;Thomas Ertl,D. Rose;K. Bidmon;T. Ertl,"Visualization and Interactive Systems Group, University of Stuttgart, Germany;Visualization and Interactive Systems Group, University of Stuttgart, Germany;Visualization and Interactive Systems Group, University of Stuttgart, Germany",10.1109/visual.2002.1183829;10.1109/visual.2002.1183829,"finite element modeling, interaction, manipulators, autostereoscopy",11.0,2.0,36.0,115.0,,,virtual prototyping;manipulators feedback mechanisms;element analysis fea;contrast cad lack;resulting crash worthiness,0.6021;0.2541;0.2367;0.1868;0.0903,"[np.int64(-1), -1, -1, -1, -1]",36;-1;-1;-1;-1,36,36
Vis,2022,Affective Learning Objectives for Communicative Visualizations,10.1109/tvcg.2022.3209500,http://dx.doi.org/10.1109/TVCG.2022.3209500,1.0,11.0,J,"When designing communicative visualizations, we often focus on goals that seek to convey patterns, relations, or comparisons (cognitive learning objectives). We pay less attention to affective intents–those that seek to influence or leverage the audience's opinions, attitudes, or values in some way. Affective objectives may range in outcomes from making the viewer care about the subject, strengthening a stance on an opinion, or leading them to take further action. Because such goals are often considered a violation of perceived ‘neutrality’ or are ‘political,’ designers may resist or be unable to describe these intents, let alone formalize them as learning objectives. While there are notable exceptions–such as advocacy visualizations or persuasive cartography–we find that visualization designers rarely acknowledge or formalize affective objectives. Through interviews with visualization designers, we expand on prior work on using learning objectives as a framework for describing and assessing communicative intent. Specifically, we extend and revise the framework to include a set of affective learning objectives. This structured taxonomy can help designers identify and declare their goals and compare and assess designs in a more principled way. Additionally, the taxonomy can enable external critique and analysis of visualizations. We illustrate the use of the taxonomy with a critical analysis of an affective visualization.",Elsie Lee-Robbins;Eytan Adar,Elsie Lee-Robbins;Eytan Adar,"University of Michigan, USA;University of Michigan, USA",10.1109/tvcg.2020.3030375;10.1109/tvcg.2013.234;10.1109/tvcg.2011.255;10.1109/tvcg.2021.3114775;10.1109/tvcg.2021.3114811;10.1109/tvcg.2014.2346419;10.1109/tvcg.2020.3030472;10.1109/tvcg.2020.3030375,"Affective visualization,communicative visualization,learning objectives",,32.0,81.0,1592.0,BP,,designing communicative visualizations;affective learning objectives;perceived neutrality political;resist;framework include,0.7212;0.4309;0.2747;0.1546;-0.0306,"[np.int64(-1), -1, -1, -1, -1]",173;-1;-1;-1;-1,173,173
Vis,2022,PMU Tracker: A Visualization Platform for Epicentric Event Propagation Analysis in the Power Grid,10.1109/tvcg.2022.3209380,http://dx.doi.org/10.1109/TVCG.2022.3209380,1081.0,1090.0,J,"The electrical power grid is a critical infrastructure, with disruptions in transmission having severe repercussions on daily activities, across multiple sectors. To identify, prevent, and mitigate such events, power grids are being refurbished as ‘smart’ systems that include the widespread deployment of GPS-enabled phasor measurement units (PMUs). PMUs provide fast, precise, and time-synchronized measurements of voltage and current, enabling real-time wide-area monitoring and control. However, the potential benefits of PMUs, for analyzing grid events like abnormal power oscillations and load fluctuations, are hindered by the fact that these sensors produce large, concurrent volumes of noisy data. In this paper, we describe working with power grid engineers to investigate how this problem can be addressed from a visual analytics perspective. As a result, we have developed PMU Tracker, an event localization tool that supports power grid operators in visually analyzing and identifying power grid events and tracking their propagation through the power grid's network. As a part of the PMU Tracker interface, we develop a novel visualization technique which we term an epicentric cluster dendrogram, which allows operators to analyze the effects of an event as it propagates outwards from a source location. We robustly validate PMU Tracker with: (1) a usage scenario demonstrating how PMU Tracker can be used to analyze anomalous grid events, and (2) case studies with power grid operators using a real-world interconnection dataset. Our results indicate that PMU Tracker effectively supports the analysis of power grid events; we also demonstrate and discuss how PMU Tracker's visual analytics approach can be generalized to other domains composed of time-varying networks with epicentric event characteristics.",Anjana Arunkumar;Andrea Pinceti;Lalitha Sankar;Chris Bryan,Anjana Arunkumar;Andrea Pinceti;Lalitha Sankar;Chris Bryan,"Arizona State University, USA;Arizona State University, USA;Arizona State University, USA;Arizona State University, USA",10.1109/tvcg.2017.2744419;10.1109/infvis.2000.885101;10.1109/tvcg.2008.140;10.1109/tvcg.2018.2864825;10.1109/tvcg.2017.2744419,"Human-centered computing,Dendrograms,Visualization design and evaluation methods,Cyber-physical networks",,2.0,45.0,529.0,,,power grid events;tracker visual analytics;cluster dendrogram allows;localization tool;volumes,0.6435;0.4130;0.3183;0.1274;0.1132,"[np.int64(-1), -1, -1, -1, -1]",20;-1;-1;-1;-1,20,20
Vis,2024,SLInterpreter: An Exploratory and Iterative Human-AI Collaborative System for GNN-Based Synthetic Lethal Prediction,10.1109/tvcg.2024.3456325,http://dx.doi.org/10.1109/TVCG.2024.3456325,919.0,929.0,J,"Synthetic Lethal (SL) relationships, though rare among the vast array of gene combinations, hold substantial promise for targeted cancer therapy. Despite advancements in AI model accuracy, there is still a significant need among domain experts for interpretive paths and mechanism explorations that align better with domain-specific knowledge, particularly due to the high costs of experimentation. To address this gap, we propose an iterative Human-AI collaborative framework with two key components: 1) Human-Engaged Knowledge Graph Refinement based on Metapath Strategies, which leverages insights from interpretive paths and domain expertise to refine the knowledge graph through metapath strategies with appropriate granularity. 2) Cross-Granularity SL Interpretation Enhancement and Mechanism Analysis, which aids experts in organizing and comparing predictions and interpretive paths across different granularities, uncovering new SL relationships, enhancing result interpretation, and elucidating potential mechanisms inferred by Graph Neural Network (GNN) models. These components cyclically optimize model predictions and mechanism explorations, enhancing expert involvement and intervention to build trust. Facilitated by SLInterpreter, this framework ensures that newly generated interpretive paths increasingly align with domain knowledge and adhere more closely to real-world biological principles through iterative Human-AI collaboration. We evaluate the framework's efficacy through a case study and expert interviews.",Haoran Jiang;Shaohan Shi;Shuhao Zhang;Jie Zheng 0002;Quan Li,Haoran Jiang;Shaohan Shi;Shuhao Zhang;Jie Zheng;Quan Li,"School of Information Science and Technology, ShanghaiTech University and Shanghai Engineering Research Center of Intelligent Vision and Imaging, China;School of Information Science and Technology, ShanghaiTech University and Shanghai Engineering Research Center of Intelligent Vision and Imaging, China;School of Information Science and Technology, ShanghaiTech University and Shanghai Engineering Research Center of Intelligent Vision and Imaging, China;School of Information Science and Technology, ShanghaiTech University and Shanghai Engineering Research Center of Intelligent Vision and Imaging, China;School of Information Science and Technology, ShanghaiTech University and Shanghai Engineering Research Center of Intelligent Vision and Imaging, China",10.1109/infvis.2005.1532128;10.1109/tvcg.2022.3209384;10.1109/tvcg.2022.3209435;10.1109/tvcg.2021.3114837,"Synthetic Lethality,Model Interpretability,,,Visual Analytics,Iterative Human-AI Collaboration",,0.0,70.0,202.0,,,predictions interpretive paths;refine knowledge graph;promise targeted cancer;gene combinations;real,0.4742;0.3934;0.3775;0.2562;0.0966,"[-1, -1, -1, -1, -1]",-1;-1;-1;-1;-1,,-1
VAST,2015,Exploring Evolving Media Discourse Through Event Cueing,10.1109/tvcg.2015.2467991,http://dx.doi.org/10.1109/TVCG.2015.2467991,220.0,229.0,J,"Online news, microblogs and other media documents all contain valuable insight regarding events and responses to events. Underlying these documents is the concept of framing, a process in which communicators act (consciously or unconsciously) to construct a point of view that encourages facts to be interpreted by others in a particular manner. As media discourse evolves, how topics and documents are framed can undergo change, shifting the discussion to different viewpoints or rhetoric. What causes these shifts can be difficult to determine directly; however, by linking secondary datasets and enabling visual exploration, we can enhance the hypothesis generation process. In this paper, we present a visual analytics framework for event cueing using media data. As discourse develops over time, our framework applies a time series intervention model which tests to see if the level of framing is different before or after a given date. If the model indicates that the times before and after are statistically significantly different, this cues an analyst to explore related datasets to help enhance their understanding of what (if any) events may have triggered these changes in discourse. Our framework consists of entity extraction and sentiment analysis as lenses for data exploration and uses two different models for intervention analysis. To demonstrate the usage of our framework, we present a case study on exploring potential relationships between climate change framing and conflicts in Africa.",Yafeng Lu;Michael Steptoe;Sarah E. Burke;Hong Wang;Jiun-Yi Tsai;Hasan Davulcu;Douglas C. Montgomery;Steven R. Corman;Ross Maciejewski,Yafeng Lu;Michael Steptoe;Sarah Burke;Hong Wang;Jiun-Yi Tsai;Hasan Davulcu;Douglas Montgomery;Steven R. Corman;Ross Maciejewski,Arizona State University;Arizona State University;Arizona State University;Arizona State University;Arizona State University;Arizona State University;Arizona State University;Arizona State University;Arizona State University,10.1109/tvcg.2013.222;10.1109/vast.2011.6102488;10.1109/vast.2012.6400557;10.1109/vast.2012.6400485;10.1109/tvcg.2013.162;10.1109/vast.2008.4677364;10.1109/tvcg.2014.2346682;10.1109/vast.2014.7042484;10.1109/tvcg.2011.179;10.1109/vast.2014.7042494;10.1109/vast.2012.6400491;10.1109/vast.2009.5333919;10.1109/infvis.1999.801851;10.1109/tvcg.2012.225;10.1109/tvcg.2014.2346913;10.1109/tvcg.2013.222,"Media Analysis, Time Series Analysis, Event Detection",,29.0,43.0,1261.0,,,media discourse evolves;event cueing using;datasets enabling visual;indicates times statistically;africa,0.5385;0.2750;0.2129;0.1950;0.1446,"[np.int64(-1), -1, -1, -1, -1]",233;-1;-1;-1;-1,233,233
InfoVis,2004,Artifacts of the Presence Era: Using Information Visualization to Create an Evocative Souvenir,10.1109/infvis.2004.8,http://dx.doi.org/10.1109/INFVIS.2004.8,105.0,111.0,C,"We present Artifacts of the Presence Era, a digital installation that uses a geological metaphor to visualize the events in a physical space over time. The piece captures video and audio from a museum and constructs an impressionistic visualization of the evolving history in the space. Instead of creating a visualization tool for data analysis, we chose to produce a piece that functions as a souvenir of a particular time and place. We describe the design choices we made in creating this installation, the visualization techniques we developed, and the reactions we observed from users and the media. We suggest that the same approach can be applied to a more general set of visualization contexts, ranging from email archives to newsgroups conversations",Fernanda B. Viégas;Ethan Perry;Ethan Howe;Judith S. Donath,F.B. Viegas;E. Perry;E. Howe;J. Donath,"MIT Media Laboratory, USA;MIT Media Laboratory, USA;MIT Media Laboratory, USA;MIT Media Laboratory, USA",,"visualization, history, public space",60.0,18.0,15.0,372.0,,,presence era digital;visualization evolving history;museum constructs;geological metaphor;email archives newsgroups,0.6492;0.4872;0.4530;0.3888;0.1921,"[np.int64(-1), -1, -1, -1, -1]",79;-1;-1;-1;-1,79,79
Vis,2007,Lattice-Based Volumetric Global Illumination,10.1109/tvcg.2007.70573,http://dx.doi.org/10.1109/TVCG.2007.70573,1576.0,1583.0,J,"We describe a novel volumetric global illumination framework based on the face-centered cubic (FCC) lattice. An FCC lattice has important advantages over a Cartesian lattice. It has higher packing density in the frequency domain, which translates to better sampling efficiency. Furthermore, it has the maximal possible kissing number (equivalent to the number of nearest neighbors of each site), which provides optimal 3D angular discretization among all lattices. We employ a new two-pass (illumination and rendering) global illumination scheme on an FCC lattice. This scheme exploits the angular discretization to greatly simplify the computation in multiple scattering and to minimize illumination information storage. The GPU has been utilized to further accelerate the rendering stage. We demonstrate our new framework with participating media and volume rendering with multiple scattering, where both are significantly faster than traditional techniques with comparable quality.",Feng Qiu;Fang Xu;Zhe Fan;Neophytos Neophytou;Arie E. Kaufman;Klaus Mueller 0001,Feng Qiu;Fang Xu;Zhe Fan;Neophytou Neophytos;Arie Kaufman;Klaus Mueller,"Department of Computer Science, Stony Brook University, Stony Brook, NY, USA;Department of Computer Science, Stony Brook University, Stony Brook, NY, USA;Department of Computer Science, Stony Brook University, Stony Brook, NY, USA;Department of Computer Science, Stony Brook University, Stony Brook, NY, USA;Department of Computer Science, Stony Brook University, Stony Brook, NY, USA;Department of Computer Science, Stony Brook University, Stony Brook, NY, USA",10.1109/visual.2004.65;10.1109/visual.2001.964498;10.1109/visual.2003.1250384;10.1109/visual.2005.1532811;10.1109/visual.2004.65,"Volume visualization, volume rendering, participating media, lattice, FCC lattice, sampling, multiple scattering, GPU",42.0,26.0,29.0,248.0,,,volumetric global illumination;lattice scheme exploits;gpu;multiple scattering significantly;equivalent number nearest,0.6756;0.2621;0.2613;0.2234;-0.0098,"[np.int64(-1), -1, -1, -1, -1]",256;-1;-1;-1;-1,256,256
SciVis,2018,Interactive obstruction-free lensing for volumetric data visualization,10.1109/tvcg.2018.2864690,http://dx.doi.org/10.1109/TVCG.2018.2864690,1029.0,1039.0,J,"Occlusion is an issue in volumetric visualization as it prevents direct visualization of the region of interest. While many techniques such as transfer functions, volume segmentation or view distortion have been developed to address this, there is still room for improvement to better support the understanding of objects' vicinity. However, most existing Focus+Context fail to solve partial occlusion in datasets where the target and the occluder are very similar density-wise. For these reasons, we investigate a new technique which maintains the general structure of the investigated volumetric dataset while addressing occlusion issues. With our technique, the user interactively defines an area of interest where an occluded region or object is partially visible. Then our lens starts pushing at its border occluding objects, thus revealing hidden volumetric data. Next, the lens is modified with an extended field of view (fish-eye deformation) to better see the vicinity of the selected region. Finally, the user can freely explore the surroundings of the area under investigation within the lens. To provide real-time exploration, we implemented our lens using a GPU accelerated ray-casting framework to handle ray deformations, local lighting, and local viewpoint manipulation. We illustrate our technique with five application scenarios in baggage inspection, 3D fluid flow visualization, chest radiology, air traffic planning, and DTI fiber exploration.",Michael Traoré;Christophe Hurter;Alexandru C. Telea,Michael Traoré;Christophe Hurter;Alexandru Telea,"ENACFrench Civil Aviation University;ENAC, French Civil Aviation University;Rijksuniversiteit Groningen, Groningen, Groningen, NL",10.1109/tvcg.2006.140;10.1109/tvcg.2006.144;10.1109/tvcg.2007.70565;10.1109/tvcg.2010.127;10.1109/tvcg.2009.138;10.1109/visual.2004.32;10.1109/tvcg.2011.223;10.1109/tvcg.2010.193;10.1109/tvcg.2006.124;10.1109/visual.2003.1250400;10.1109/visual.1999.809865;10.1109/tvcg.2012.265;10.1109/tvcg.2016.2599049;10.1109/visual.2005.1532818;10.1109/tvcg.2009.145;10.1109/tvcg.2006.140,"Interaction techniques,focus + context,volume visualization,volume rendering,raycasting",0.0,9.0,51.0,837.0,,,volumetric visualization;visible lens starts;using gpu accelerated;casting framework handle;fail solve partial,0.6340;0.2650;0.2016;0.0051;-0.0417,"[np.int64(-1), -1, -1, -1, -1]",84;-1;-1;-1;-1,84,84
Vis,1991,Scientific visualization from inside the metacomputer,10.1109/visual.1991.175767,http://dx.doi.org/10.1109/VISUAL.1991.175767,2.0,,M,"Summary form only given, as follows. Historically, scientific visualization has been carried out in two primary modes: interactive on desktop computers, and batch on high-performance computers. The next decade will see a merging of these two approaches with the advent of high-speed networking. The networking is hierarchical in speed from Ethernet to FDDI to HiPPI. This network effectively unites desktop computers with higher-value remote resources into a single metacomputer. To take advantage of this new hardware configuration, distributed visualization software is being developed which allows the flexibility of the local workstation to be coupled with the computing power of distant supercomputers. Examples are discussed for 2D raster graphics and 3D rendered surface and volumetric graphics. These new capabilities are having a remarkable impact on computational science.&lt;&lt;ETX&gt;&gt;",L.L. Smarr,L.L. Smarr,"National Center for Supercomputing Applications, Champaign, IL, USA",,,,0.0,0.0,54.0,,,scientific visualization;metacomputer advantage;remote resources single;ethernet fddi;gt gt,0.6851;0.3520;0.1236;0.0963;0.0139,"[np.int64(-1), -1, -1, -1, -1]",150;-1;-1;-1;-1,150,150
Vis,1998,Production visualization for the ASCI One TeraFLOPS machine,10.1109/visual.1998.745343,http://dx.doi.org/10.1109/VISUAL.1998.745343,459.0,462.0,C,"The delivery of the first one tera-operations/sec computer has significantly impacted production data visualization, affecting data transfer, post processing, and rendering. Terascale computing has motivated a need to consider the entire data visualization system; improving a single algorithm is not sufficient. This paper presents a systems approach to decrease by a factor of four the time required to prepare large data sets for visualization. For daily production use, all stages in the processing pipeline from physics simulation code to pixels on a screen, must be balanced to yield good overall performance. Performance of the initial visualization system is compared with recent improvements. ""Lessons learned"" from the coordinated deployment of improved algorithms also are discussed, including the need for 64 bit addressing and a fully parallel data visualization pipeline.",Philip D. Heermann,P.D. Heermann,"Sandia National Laboratories, USA",,,37.0,10.0,5.0,52.0,BCS,,rendering terascale computing;physics simulation code;impacted production data;time required prepare;transfer post,0.6760;0.3374;0.2993;0.1374;0.0349,"[np.int64(-1), -1, -1, -1, -1]",175;-1;-1;-1;-1,175,175
SciVis,2017,On the Treatment of Field Quantities and Elemental Continuity in FEM Solutions,10.1109/tvcg.2017.2744058,http://dx.doi.org/10.1109/TVCG.2017.2744058,903.0,912.0,J,"As the finite element method (FEM) and the finite volume method (FVM), both traditional and high-order variants, continue their proliferation into various applied engineering disciplines, it is important that the visualization techniques and corresponding data analysis tools that act on the results produced by these methods faithfully represent the underlying data. To state this in another way: the interpretation of data generated by simulation needs to be consistent with the numerical schemes that underpin the specific solver technology. As the verifiable visualization literature has demonstrated: visual artifacts produced by the introduction of either explicit or implicit data transformations, such as data resampling, can sometimes distort or even obfuscate key scientific features in the data. In this paper, we focus on the handling of elemental continuity, which is often only<inline-formula><tex-math notation=""LaTeX"">$C^{0}$</tex-math><alternatives><inline-graphic xlink:href=""24tvcg01-jallepalli-2744058-ieq-1-source.tif"" xmlns:xlink=""http://www.w3.org/1999/xlink""/></alternatives></inline-formula>continuous or piecewise discontinuous, when visualizing primary or derived fields from FEM or FVM simulations. We demonstrate that traditional data handling and visualization of these fields introduce visual errors. In addition, we show how the use of the recently proposed line-SIAC filter provides a way of handling elemental continuity issues in an accuracy-conserving manner with the added benefit of casting the data in a smooth context even if the representation is element discontinuous.",Ashok Jallepalli;Julia Docampo-Sánchez;Jennifer K. Ryan;Robert Haimes;Robert M. Kirby,Ashok Jallepalli;Julia Docampo-Sánchez;Jennifer K. Ryan;Robert Haimes;Robert M. Kirby,"SCI Institute, University of Utah;School of Mathematics, University of East Anglia;School of Mathematics, University of East Anglia;Department of Aeronautics, MIT;SCI Institute, University of Utah",10.1109/visual.2004.65;10.1109/tvcg.2011.206;10.1109/tvcg.2012.218;10.1109/tvcg.2009.194;10.1109/visual.2004.65,"Flow Visualization,discontinuous Galerkin (dG) methods,continuous Galerkin (cG) methods,finite element methods (FEM),finite volume methods,filtering techniques,Scalar Field Data,Irregular and Unstructured Grids,Extraction of Surfaces((Isosurfaces)",12.0,11.0,30.0,521.0,,,finite element method;line siac filter;verifiable visualization literature;data resampling distort;interpretation,0.5514;0.2877;0.2734;0.1442;0.0383,"[np.int64(-1), -1, -1, -1, -1]",13;-1;-1;-1;-1,13,13
InfoVis,2005,PRISAD: a partitioned rendering infrastructure for scalable accordion drawing,10.1109/infvis.2005.1532127,http://dx.doi.org/10.1109/INFVIS.2005.1532127,41.0,48.0,C,"We present PRISAD, the first generic rendering infrastructure for information visualization applications that use the accordion drawing technique: rubber sheet navigation with guaranteed visibility for marked areas of interest. Our new rendering algorithms are based on the partitioning of screen space, which allows us to handle dense dataset regions correctly. The algorithms in previous work led to incorrect visual representations because of overculling, and to inefficiencies due to overdrawing multiple items in the same region. Our pixel based drawing infrastructure guarantees correctness by eliminating overculling, and improves rendering performance with tight bounds on overdrawing. PRITree and PRISeq are applications built on PRISAD, with the feature sets of TreeJuxtaposer and SequenceJuxtaposer, respectively. We describe our PRITree and PRISeq dataset traversal algorithms, which are used for efficient rendering, culling, and layout of datasets within the PRISAD framework. We also discuss PRITree node marking techniques, which offer order-of-magnitude improvements to both memory and time performance versus previous range storage and retrieval techniques. Our PRITree implementation features a five fold increase in rendering speed for nontrivial tree structures, and also reduces memory requirements in some real world datasets by up to eight times, so we are able to handle trees of several million nodes. PRISeq renders fifteen times faster and handles datasets twenty times larger than previous work.",James Slack;Kristian Hildebrand;Tamara Munzner,J. Slack;K. Hildebrand;T. Munzner,"University of British Columbia, Canada;University of British Columbia, Canada;Bauhaus University Weimar, Germany",10.1109/infvis.2002.1173156;10.1109/infvis.2004.64,"Focus+Context, Information Visualization, Real Time Rendering, Progressive Rendering",18.0,3.0,14.0,132.0,,,information visualization applications;fold increase rendering;overdrawing pritree priseq;sheet navigation guaranteed;work led,0.6409;0.2622;0.2408;0.1548;-0.0107,"[np.int64(-1), -1, -1, -1, -1]",206;-1;-1;-1;-1,206,206
InfoVis,2020,NL4DV: A Toolkit for Generating Analytic Specifications for Data Visualization from Natural Language Queries,10.1109/tvcg.2020.3030378,http://dx.doi.org/10.1109/TVCG.2020.3030378,369.0,379.0,J,"Natural language interfaces (NLls) have shown great promise for visual data analysis, allowing people to flexibly specify and interact with visualizations. However, developing visualization NLIs remains a challenging task, requiring low-level implementation of natural language processing (NLP) techniques as well as knowledge of visual analytic tasks and visualization design. We present NL4DV, a toolkit for natural language-driven data visualization. NL4DV is a Python package that takes as input a tabular dataset and a natural language query about that dataset. In response, the toolkit returns an analytic specification modeled as a JSON object containing data attributes, analytic tasks, and a list of Vega-Lite specifications relevant to the input query. In doing so, NL4DV aids visualization developers who may not have a background in NLP, enabling them to create new visualization NLIs or incorporate natural language input within their existing systems. We demonstrate NL4DV's usage and capabilities through four examples: 1) rendering visualizations using natural language in a Jupyter notebook, 2) developing a NLI to specify and edit Vega-Lite charts, 3) recreating data ambiguity widgets from the DataTone system, and 4) incorporating speech input to create a multimodal visualization system.",Arpit Narechania;Arjun Srinivasan;John T. Stasko,Arpit Narechania;Arjun Srinivasan;John Stasko,"Georgia Institute of Technology, Atlanta, GA, USA;Georgia Institute of Technology, Atlanta, GA, USA;Georgia Institute of Technology, Atlanta, GA, USA",10.1109/infvis.2005.1532136;10.1109/tvcg.2009.174;10.1109/tvcg.2011.185;10.1109/tvcg.2010.144;10.1109/tvcg.2017.2744684;10.1109/tvcg.2007.70594;10.1109/tvcg.2018.2865240;10.1109/tvcg.2016.2599030;10.1109/tvcg.2015.2467091;10.1109/tvcg.2018.2865152;10.1109/tvcg.2017.2745219;10.1109/infvis.2000.885086;10.1109/vast47406.2019.8986918;10.1109/tvcg.2015.2467191;10.1109/tvcg.2019.2934668,"Natural Language Interfaces,Visualization Toolkits",53.0,77.0,71.0,2388.0,,,developing visualization nlis;specify edit vega;toolkit returns analytic;json object containing;promise,0.6959;0.2051;0.1495;0.1459;0.0437,"[np.int64(-1), -1, -1, -1, -1]",266;-1;-1;-1;-1,266,266
SciVis,2015,Diderot: a Domain-Specific Language for Portable Parallel Scientific Visualization and Image Analysis,10.1109/tvcg.2015.2467449,http://dx.doi.org/10.1109/TVCG.2015.2467449,867.0,876.0,J,"Many algorithms for scientific visualization and image analysis are rooted in the world of continuous scalar, vector, and tensor fields, but are programmed in low-level languages and libraries that obscure their mathematical foundations. Diderot is a parallel domain-specific language that is designed to bridge this semantic gap by providing the programmer with a high-level, mathematical programming notation that allows direct expression of mathematical concepts in code. Furthermore, Diderot provides parallel performance that takes advantage of modern multicore processors and GPUs. The high-level notation allows a concise and natural expression of the algorithms and the parallelism allows efficient execution on real-world datasets.",Gordon L. Kindlmann;Charisee Chiw;Nicholas Seltzer;Lamont Samuels;John H. Reppy,Gordon Kindlmann;Charisee Chiw;Nicholas Seltzer;Lamont Samuels;John Reppy,"Department of Computer Science, University of Chicago;Department of Computer Science, University of Chicago;Department of Computer Science, University of Chicago;Department of Computer Science, University of Chicago;Department of Computer Science, University of Chicago",10.1109/tvcg.2009.174;10.1109/tvcg.2011.185;10.1109/visual.2005.1532856;10.1109/tvcg.2014.2346322;10.1109/tvcg.2012.240;10.1109/visual.2003.1250414;10.1109/visual.1999.809896;10.1109/tvcg.2007.70534;10.1109/tvcg.2014.2346318;10.1109/visual.1998.745290;10.1109/tvcg.2008.148;10.1109/tvcg.2008.163;10.1109/tvcg.2009.174,"Domain specific language, portable parallel programming, scientific visualization, tensor fields",46.0,25.0,53.0,774.0,,,algorithms scientific visualization;parallel domain specific;vector tensor;level languages libraries;diderot,0.5691;0.3899;0.3287;0.3119;0.2454,"[np.int64(-1), -1, -1, -1, -1]",-1;-1;-1;-1;-1,,-1
Vis,2022,Comparison Conundrum and the Chamber of Visualizations: An Exploration of How Language Influences Visual Design,10.1109/tvcg.2022.3209456,http://dx.doi.org/10.1109/TVCG.2022.3209456,1211.0,1221.0,J,"The language for expressing comparisons is often complex and nuanced, making supporting natural language-based visual comparison a non-trivial task. To better understand how people reason about comparisons in natural language, we explore a design space of utterances for comparing data entities. We identified different parameters of comparison utterances that indicate what is being compared (i.e., data variables and attributes) as well as how these parameters are specified (i.e., explicitly or implicitly). We conducted a user study with sixteen data visualization experts and non-experts to investigate how they designed visualizations for comparisons in our design space. Based on the rich set of visualization techniques observed, we extracted key design features from the visualizations and synthesized them into a subset of sixteen representative visualization designs. We then conducted a follow-up study to validate user preferences for the sixteen representative visualizations corresponding to utterances in our design space. Findings from these studies suggest guidelines and future directions for designing natural language interfaces and recommendation tools to better support natural language comparisons in visual analytics.",Aimen Gaba;Vidya Setlur;Arjun Srinivasan;Jane Hoffswell;Cindy Xiong,Aimen Gaba;Vidya Setlur;Arjun Srinivasan;Jane Hoffswell;Cindy Xiong,"UMass Amherst, USA;Tableau Research, USA;Tableau Research, USA;Adobe Research, USA;UMass Amherst, USA",10.1109/tvcg.2017.2744199;10.1109/tvcg.2013.183;10.1109/tvcg.2007.70556;10.1109/tvcg.2019.2934786;10.1109/tvcg.2011.194;10.1109/tvcg.2019.2934801;10.1109/tvcg.2016.2599030;10.1109/tvcg.2021.3114823;10.1109/tvcg.2019.2934399;10.1109/tvcg.2021.3114814;10.1109/tvcg.2016.2598920;10.1109/tvcg.2017.2744199,"Comparative constructions,cardinality,explicit and implicit comparisons,natural language,intent,visual analysis",,8.0,74.0,541.0,,,comparisons visual analytics;support natural language;studies suggest guidelines;parameters specified explicitly;sixteen,0.7566;0.3226;0.1695;0.0081;0.0056,"[np.int64(-1), -1, -1, -1, -1]",270;-1;-1;-1;-1,270,270
Vis,2011,Features in Continuous Parallel Coordinates,10.1109/tvcg.2011.200,http://dx.doi.org/10.1109/TVCG.2011.200,1912.0,1921.0,J,"Continuous Parallel Coordinates (CPC) are a contemporary visualization technique in order to combine several scalar fields, given over a common domain. They facilitate a continuous view for parallel coordinates by considering a smooth scalar field instead of a finite number of straight lines. We show that there are feature curves in CPC which appear to be the dominant structures of a CPC. We present methods to extract and classify them and demonstrate their usefulness to enhance the visualization of CPCs. In particular, we show that these feature curves are related to discontinuities in Continuous Scatterplots (CSP). We show this by exploiting a curve-curve duality between parallel and Cartesian coordinates, which is a generalization of the well-known point-line duality. Furthermore, we illustrate the theoretical considerations. Concluding, we discuss relations and aspects of the CPC's/CSP's features concerning the data analysis.",Dirk J. Lehmann;Holger Theisel,Dirk J. Lehmann;Holger Theisel,"Department of Simulation and Graphics, University of Magdeburg, Germany;Department of Simulation and Graphics, University of Magdeburg, Germany",10.1109/tvcg.2008.119;10.1109/tvcg.2010.146;10.1109/visual.1998.745284;10.1109/tvcg.2009.131;10.1109/visual.1999.809896;10.1109/tvcg.2008.119,"Features, Parallel Coordinates, Topology, Visualization",21.0,10.0,28.0,544.0,,,continuous parallel coordinates;feature curves;combine scalar fields;usefulness enhance;cpc,0.5849;0.5108;0.2170;0.1162;0.0816,"[np.int64(-1), np.int64(-1), -1, -1, -1]",65;246;-1;-1;-1,65;246,65
SciVis,2012,Automatic Tuning of Spatially Varying Transfer Functions for Blood Vessel Visualization,10.1109/tvcg.2012.203,http://dx.doi.org/10.1109/TVCG.2012.203,2345.0,2354.0,J,"Computed Tomography Angiography (CTA) is commonly used in clinical routine for diagnosing vascular diseases. The procedure involves the injection of a contrast agent into the blood stream to increase the contrast between the blood vessels and the surrounding tissue in the image data. CTA is often visualized with Direct Volume Rendering (DVR) where the enhanced image contrast is important for the construction of Transfer Functions (TFs). For increased efficiency, clinical routine heavily relies on preset TFs to simplify the creation of such visualizations for a physician. In practice, however, TF presets often do not yield optimal images due to variations in mixture concentration of contrast agent in the blood stream. In this paper we propose an automatic, optimization-based method that shifts TF presets to account for general deviations and local variations of the intensity of contrast enhanced blood vessels. Some of the advantages of this method are the following. It computationally automates large parts of a process that is currently performed manually. It performs the TF shift locally and can thus optimize larger portions of the image than is possible with manual interaction. The method is based on a well known vesselness descriptor in the definition of the optimization criterion. The performance of the method is illustrated by clinically relevant CT angiography datasets displaying both improved structural overviews of vessel trees and improved adaption to local variations of contrast concentration.",Gunnar Läthén;Stefan Lindholm;Reiner Lenz;Anders Persson;Magnus Borga,Gunnar Läthén;Stefan Lindholm;Reiner Lenz;Anders Persson;Magnus Borga,"Center for Medical Image Science and Visualization (CMIV), Department of Science and Technology, Linköping University, Sweden;Center for Medical Image Science and Visualization (CMIV), Department of Science and Technology, Linköping University, Sweden;Center for Medical Image Science and Visualization (CMIV), Department of Science and Technology, Linköping University, Sweden;Center for Medical Image Science and Visualization (CMIV), Department of Medical and Health Sciences, Linköping University, Sweden;Center for Medical Image Science and Visualization (CMIV), Department of Biomedical Engineering, Linköping University, Sweden",10.1109/visual.2003.1250414;10.1109/tvcg.2009.120;10.1109/visual.2001.964516;10.1109/visual.1996.568113;10.1109/tvcg.2008.162;10.1109/tvcg.2010.195;10.1109/tvcg.2008.123,"Direct volume rendering, transfer functions, vessel visualization",29.0,14.0,34.0,513.0,,,contrast blood vessels;simplify creation visualizations;data cta;shift locally optimize;definition,0.6180;0.2914;0.2725;0.2608;0.0304,"[np.int64(-1), -1, -1, -1, -1]",133;-1;-1;-1;-1,133,133
Vis,2005,Sort-middle multi-projector immediate-mode rendering in Chromium,10.1109/visual.2005.1532784,http://dx.doi.org/10.1109/VISUAL.2005.1532784,103.0,110.0,C,"Traditionally, sort-middle is a technique that has been difficult to attain on clusters because of the tight coupling of geometry and rasterization processes on commodity graphics hardware. In this paper, we describe the implementation of a new sort-middle approach for performing immediate-mode rendering in Chromium. The Chromium Rendering System is used extensively to drive multi-projector displays on PC clusters with inexpensive commodity graphics components. By default, Chromium uses a sort-first approach to distribute rendering work to individual nodes in a PC cluster. While this sort-first approach works effectively in retained-mode rendering, it suffers from various network bottlenecks when rendering in immediate-mode. Current techniques avoid these bottlenecks by sorting vertex data as a pre-processing step and grouping vertices into specific bounding boxes, using Chromium's bounding box extension. These steps may be expensive, especially if the dataset is dynamic. In our approach, we utilize standard programmable graphics hardware and extend standard APIs to achieve a separation in the rendering pipeline. The pre-processing of vertex data or the grouping of vertices into bounding boxes are not required. Additionally, the amount of OpenGL state commands transmitted through the network are reduced. Our results indicate that the approach can attain twice the frame rates as compared to Chromium's sort-first approach when rendering in immediate-mode.",Jorge Luis Williams;Robert E. Hiromoto,J.L. Williams;R.E. Hiromoto,"Department of Computer Science, University of Idaho, USA;Department of Computer Science, University of Idaho, USA",,"Cluster Rendering, Sort-Middle, Multi-Projector, Tile Displays, Immediate-Mode Rendering",9.0,2.0,18.0,141.0,,,displays pc clusters;chromium uses sort;retained mode rendering;pre processing step;suffers,0.5404;0.4290;0.2790;0.1302;0.0714,"[np.int64(-1), -1, -1, -1, -1]",-1;-1;-1;-1;-1,,-1
Vis,2004,Augmented reality with tangible auto-fabricated models for molecular biology applications,10.1109/visual.2004.7,http://dx.doi.org/10.1109/VISUAL.2004.7,235.0,241.0,C,"The evolving technology of computer auto-fabrication (""3D printing"") now makes it possible to produce physical models for complex biological molecules and assemblies. We report on an application that demonstrates the use of auto-fabricated tangible models and augmented reality for research and education in molecular biology, and for enhancing the scientific environment for collaboration and exploration. We have adapted an augmented reality system to allow virtual 3D representations (generated by the Python Molecular Viewer) to be overlaid onto a tangible molecular model. Users can easily change the overlaid information, switching between different representations of the molecule, displays of molecular properties such as electrostatics, or dynamic information. The physical model provides a powerful, intuitive interface for manipulating the computer models, streamlining the interface between human intent, the physical model, and the computational activity.",Alexandre Gillet;Michel F. Sanner;Daniel Stoffler;David S. Goodsell;Arthur J. Olson,A. Gillet;M. Sanner;D. Stoffler;D. Goodsell;A. Olson,"Scripps Research Institute, USA;Scripps Research Institute, USA;Scripps Research Institute, USA;Scripps Research Institute, USA;Scripps Research Institute, USA",,"Molecular Modeling, Molecular Visualization, Augmented Reality",86.0,42.0,15.0,608.0,,,tangible molecular model;augmented reality research;auto fabricated;change overlaid information;environment collaboration,0.7026;0.4073;0.1730;0.1429;0.1366,"[np.int64(-1), -1, -1, -1, -1]",120;-1;-1;-1;-1,120,120
SciVis,2014,Trajectory-Based Flow Feature Tracking in Joint Particle/Volume Datasets,10.1109/tvcg.2014.2346423,http://dx.doi.org/10.1109/TVCG.2014.2346423,2565.0,2574.0,J,"Studying the dynamic evolution of time-varying volumetric data is essential in countless scientific endeavors. The ability to isolate and track features of interest allows domain scientists to better manage large complex datasets both in terms of visual understanding and computational efficiency. This work presents a new trajectory-based feature tracking technique for use in joint particle/volume datasets. While traditional feature tracking approaches generally require a high temporal resolution, this method utilizes the indexed trajectories of corresponding Lagrangian particle data to efficiently track features over large jumps in time. Such a technique is especially useful for situations where the volume dataset is either temporally sparse or too large to efficiently track a feature through all intermediate timesteps. In addition, this paper presents a few other applications of this approach, such as the ability to efficiently track the internal properties of volumetric features using variables from the particle data. We demonstrate the effectiveness of this technique using real world combustion and atmospheric datasets and compare it to existing tracking methods to justify its advantages and accuracy.",Franz Sauer;Hongfeng Yu 0001;Kwan-Liu Ma,Franz Sauer;Hongfeng Yu;Kwan-Liu Ma,"University of California, Davis;University of Nebraska, Lincoln;University of California, Davis",10.1109/visual.1997.663930;10.1109/visual.1996.567807;10.1109/tvcg.2007.70599;10.1109/visual.2003.1250374;10.1109/visual.1990.146391;10.1109/visual.1998.745288;10.1109/tvcg.2008.184;10.1109/vast.2012.6400532;10.1109/visual.1997.663930,"Feature extraction and tracking, particle data, volume data, particle trajectories, flow visualization",36.0,20.0,26.0,655.0,,,particle volume datasets;efficiently track feature;evolution time varying;world combustion;corresponding lagrangian,0.6150;0.4542;0.2438;0.2304;0.1056,"[np.int64(-1), -1, -1, -1, -1]",-1;-1;-1;-1;-1,,-1
VAST,2017,E-Map: A Visual Analytics Approach for Exploring Significant Event Evolutions in Social Media,10.1109/vast.2017.8585638,http://dx.doi.org/10.1109/VAST.2017.8585638,36.0,47.0,C,"Significant events are often discussed and spread through social media, involving many people. Reposting activities and opinions expressed in social media offer good opportunities to understand the evolution of events. However, the dynamics of reposting activities and the diversity of user comments pose challenges to understand event-related social media data. We propose E-Map, a visual analytics approach that uses map-like visualization tools to help multi-faceted analysis of social media data on a significant event and in-depth understanding of the development of the event. E-Map transforms extracted keywords, messages, and reposting behaviors into map features such as cities, towns, and rivers to build a structured and semantic space for users to explore. It also visualizes complex posting and reposting behaviors as simple trajectories and connections that can be easily followed. By supporting multi-level spatial temporal exploration, E-Map helps to reveal the patterns of event development and key players in an event, disclosing the ways they shape and affect the development of the event. Two cases analysing real-world events confirm the capacities of E-Map in facilitating the analysis of event evolution with social media data.",Siming Chen 0001;Shuai Chen 0001;Lijing Lin;Xiaoru Yuan;Jie Liang 0004;Xiaolong Zhang 0001,Siming Chen;Shuai Chen;Lijing Lin;Xiaoru Yuan;Jie Liang;Xiaolong Zhang,"Key Laboratory of Machine Perception (Ministry of Education) and School of EECS, Peking University, China;Key Laboratory of Machine Perception (Ministry of Education) and School of EECS, Peking University, China;Key Laboratory of Machine Perception (Ministry of Education) and School of EECS, Peking University, China;Key Laboratory of Machine Perception (Ministry of Education) and School of EECS, Peking University, China;Faculty of Engineer and Information Technology, The University of Technology, Sydney, Australia;College of Information Sciences and Technology, Pennsylvania State University, USA",10.1109/vast.2008.4677356;10.1109/tvcg.2013.186;10.1109/tvcg.2011.185;10.1109/tvcg.2012.291;10.1109/vast.2012.6400557;10.1109/vast.2016.7883510;10.1109/tvcg.2015.2467619;10.1109/tvcg.2014.2346433;10.1109/tvcg.2010.129;10.1109/vast.2012.6400485;10.1109/tvcg.2013.162;10.1109/infvis.2005.1532126;10.1109/tvcg.2007.70582;10.1109/tvcg.2016.2598590;10.1109/tvcg.2015.2467554;10.1109/vast.2015.7347632;10.1109/tvcg.2013.196;10.1109/vast.2011.6102456;10.1109/tvcg.2016.2598919;10.1109/tvcg.2009.171;10.1109/vast.2016.7883511;10.1109/tvcg.2015.2467691;10.1109/tvcg.2014.2346920;10.1109/tvcg.2013.221;10.1109/tvcg.2014.2346922;10.1109/vast.2014.7042496;10.1109/tvcg.2014.2346919;10.1109/vast.2008.4677356,"Social Media,Event Analysis,Map-like Visual Metaphor,Spatial Temporal Visual Analytics",35.0,24.0,63.0,1122.0,,,map visual analytics;significant event;people reposting activities;diversity user comments;understand evolution,0.5636;0.2864;0.2686;0.2160;0.1796,"[np.int64(-1), -1, -1, -1, -1]",174;-1;-1;-1;-1,174,174
Vis,2004,Stream line and path line oriented topology for 2D time-dependent vector fields,10.1109/visual.2004.99,http://dx.doi.org/10.1109/VISUAL.2004.99,321.0,328.0,C,"Topological methods aim at the segmentation of a vector field into areas of different flow behavior. For 2D time-dependent vector fields, two such segmentations are possible: either concerning the behavior of stream lines, or of path lines. While stream line oriented topology is well established, we introduce path line oriented topology as a new visualization approach in this paper. As a contribution to stream line oriented topology we introduce new methods to detect global bifurcations like saddle connections and cyclic fold bifurcations. To get the path line oriented topology we segment the vector field into areas of attracting, repelling and saddle-like behavior of the path lines. We compare both kinds of topologies and apply them to a number of data sets.",Holger Theisel;Tino Weinkauf;Hans-Christian Hege;Hans-Peter Seidel,H. Theisel;T. Weinkauf;H.-C. Hege;H.-P. Seidel,"MPI Informatik Saarbrücken, Germany;Zuse Institute Berlin, Germany;Zuse Institute Berlin, Germany;MPI Informatik Saarbrücken, Germany",10.1109/visual.1999.809907;10.1109/visual.2000.885714;10.1109/visual.1993.398849;10.1109/visual.1991.175773;10.1109/visual.1996.567777;10.1109/visual.2000.885716;10.1109/visual.2001.964507;10.1109/visual.2003.1250376;10.1109/visual.1999.809907,"flow visualization, vector field topology, bifurcations, stream lines, path lines",66.0,27.0,28.0,184.0,,,detect global bifurcations;visualization approach;topology segment vector;different flow behavior;apply,0.6327;0.3686;0.3426;0.2808;0.0174,"[np.int64(-1), -1, -1, -1, -1]",282;-1;-1;-1;-1,282,282
SciVis,2015,Rotation Invariant Vortices for Flow Visualization,10.1109/tvcg.2015.2467200,http://dx.doi.org/10.1109/TVCG.2015.2467200,817.0,826.0,J,"We propose a new class of vortex definitions for flows that are induced by rotating mechanical parts, such as stirring devices, helicopters, hydrocyclones, centrifugal pumps, or ventilators. Instead of a Galilean invariance, we enforce a rotation invariance, i.e., the invariance of a vortex under a uniform-speed rotation of the underlying coordinate system around a fixed axis. We provide a general approach to transform a Galilean invariant vortex concept to a rotation invariant one by simply adding a closed form matrix to the Jacobian. In particular, we present rotation invariant versions of the well-known Sujudi-Haimes, Lambda-2, and Q vortex criteria. We apply them to a number of artificial and real rotating flows, showing that for these cases rotation invariant vortices give better results than their Galilean invariant counterparts.",Tobias Günther;Maik Schulze;Holger Theisel,Tobias Günther;Maik Schulze;Holger Theisel,"Visual Computing Group, University of Magdeburg;MAXON Computer;Visual Computing Group, University of Magdeburg",10.1109/tvcg.2014.2346415;10.1109/visual.2002.1183789;10.1109/tvcg.2014.2346412;10.1109/tvcg.2011.249;10.1109/tvcg.2013.189;10.1109/visual.1999.809917;10.1109/visual.1999.809896;10.1109/visual.1998.745296;10.1109/visual.2005.1532851;10.1109/tvcg.2007.70545;10.1109/tvcg.2010.198;10.1109/tvcg.2014.2346415,"Vortex cores, rotation invariance, Galilean invariance, scientific visualization, flow visualization, line fields",38.0,33.0,49.0,995.0,HM,,rotation invariant vortices;mechanical parts;instead galilean;known sujudi haimes;simply adding closed,0.7194;0.1576;0.1333;0.1019;0.0144,"[np.int64(-1), -1, -1, -1, -1]",224;-1;-1;-1;-1,224,224
Vis,1998,Interactive ray tracing for isosurface rendering,10.1109/visual.1998.745713,http://dx.doi.org/10.1109/VISUAL.1998.745713,233.0,238.0,C,"We show that it is feasible to perform interactive isosurfacing of very large rectilinear datasets with brute-force ray tracing on a conventional (distributed) shared-memory multiprocessor machine. Rather than generate geometry representing the isosurface and render with a z-buffer, for each pixel we trace a ray through a volume and do an analytic isosurface intersection computation. Although this method has a high intrinsic computational cost, its simplicity and scalability make it ideal for large datasets on current high-end systems. Incorporating simple optimizations, such as volume bricking and a shallow hierarchy, enables interactive rendering (i.e. 10 frames per second) of the 1 GByte full resolution Visible Woman dataset on an SGI Reality Monster. The graphics capabilities of the Reality Monster are used only for display of the final color image.",Steven G. Parker;Peter Shirley;Yarden Livnat;Charles D. Hansen;Peter-Pike J. Sloan,S. Parker;P. Shirley;Y. Livnat;C. Hansen;P.-P. Sloan,"Computer Science Department, University of Utah, USA;Computer Science Department, University of Utah, USA;Computer Science Department, University of Utah, USA;Computer Science Department, University of Utah, USA;Computer Science Department, University of Utah, USA",10.1109/visual.1997.663888;10.1109/visual.1994.346331;10.1109/visual.1994.346320;10.1109/visual.1995.485154;10.1109/visual.1998.745300;10.1109/visual.1997.663888,,526.0,116.0,17.0,568.0,BP,,ray tracing;isosurface intersection;memory multiprocessor machine;brute;hierarchy enables interactive,0.5952;0.3322;0.2070;0.1020;0.0996,"[np.int64(-1), -1, -1, -1, -1]",60;-1;-1;-1;-1,60,60
Vis,1990,Dynamic graphics for network visualization,10.1109/visual.1990.146369,http://dx.doi.org/10.1109/VISUAL.1990.146369,93.0,,C,"The authors describe several dynamic graphics tools for visualizing network data involving statistics associated with the nodes or links in a network. The authors suggest a number of ideas for the static display of network data, while motivating the need for interaction through dynamic graphics. A brief discussion of dynamic graphics in general is presented. The authors specialize this to the case of network data. An example is presented.&lt;&lt;ETX&gt;&gt;",Richard A. Becker;Stephen G. Eick;Eileen O. Miller;Allan R. Wilks,R.A. Becker;S.G. Eick;E.O. Miller;A.R. Wilks,"AT and T Bell Laboratories, Inc., Murray Hill, NJ, USA;AT and T Bell Laboratories, Inc., Murray Hill, NJ, USA;AT and T Bell Laboratories, Inc., Murray Hill, NJ, USA;AT and T Bell Laboratories, Inc., Murray Hill, NJ, USA",,,24.0,3.0,3.0,146.0,,,visualizing network data;static display;involving statistics;authors dynamic;lt lt,0.8045;0.2791;0.2078;0.2013;0.0560,"[np.int64(-1), -1, -1, -1, -1]",169;-1;-1;-1;-1,169,169
Vis,2009,Automatic Transfer Function Generation Using Contour Tree Controlled Residue Flow Model and Color Harmonics,10.1109/tvcg.2009.120,http://dx.doi.org/10.1109/TVCG.2009.120,1481.0,1488.0,J,"Transfer functions facilitate the volumetric data visualization by assigning optical properties to various data features and scalar values. Automation of transfer function specifications still remains a challenge in volume rendering. This paper presents an approach for automating transfer function generations by utilizing topological attributes derived from the contour tree of a volume. The contour tree acts as a visual index to volume segments, and captures associated topological attributes involved in volumetric data. A residue flow model based on Darcy's law is employed to control distributions of opacity between branches of the contour tree. Topological attributes are also used to control color selection in a perceptual color space and create harmonic color transfer functions. The generated transfer functions can depict inclusion relationship between structures and maximize opacity and color differences between them. The proposed approach allows efficient automation of transfer function generations, and exploration on the data to be carried out based on controlling of opacity residue flow rate instead of complex low-level transfer function parameter adjustments. Experiments on various data sets demonstrate the practical use of our approach in transfer function generations.",Jianlong Zhou;Masahiro Takatsuka,Jianlong Zhou;Masahiro Takatsuka,"School of Information Technologies, University of Sydney, NSW, Australia and NICTA, Australia;School of Information Technologies, University of Sydney, NSW, Australia and NICTA, Australia",10.1109/visual.1998.745319;10.1109/tvcg.2008.118;10.1109/visual.1999.809932;10.1109/visual.2003.1250414;10.1109/visual.2004.96;10.1109/tvcg.2007.70591;10.1109/tvcg.2008.162;10.1109/visual.2001.964519;10.1109/visual.2003.1250413;10.1109/visual.1997.663875;10.1109/tvcg.2006.148;10.1109/visual.1998.745319,"Volume Rendering, Transfer Function, Contour Tree, Residue Flow, Harmonic Color",91.0,49.0,30.0,672.0,,,volumetric data visualization;contour tree acts;controlling opacity;transfer function generations;law employed,0.6273;0.3493;0.3224;0.2052;-0.0433,"[np.int64(-1), -1, -1, -1, -1]",84;-1;-1;-1;-1,84,84
VAST,2011,Supporting effective common ground construction in Asynchronous Collaborative Visual Analytics,10.1109/vast.2011.6102447,http://dx.doi.org/10.1109/VAST.2011.6102447,101.0,110.0,C,"Asynchronous Collaborative Visual Analytics (ACVA) leverages group sensemaking by releasing the constraints on when, where, and who works collaboratively. A significant task to be addressed before ACVA can reach its full potential is effective common ground construction, namely the process in which users evaluate insights from individual work to develop a shared understanding of insights and collectively pool them. This is challenging due to the lack of instant communication and scale of collaboration in ACVA. We propose a novel visual analytics approach that automatically gathers, organizes, and summarizes insights to form common ground with reduced human effort. The rich set of visualization and interaction techniques provided in our approach allows users to effectively and flexibly control the common ground construction and review, explore, and compare insights in detail. A working prototype of the approach has been implemented. We have conducted a case study and a user study to demonstrate its effectiveness.",Yang Chen;Jamal Alsakran;Scott Barlowe;Jing Yang 0001;Ye Zhao 0003,Yang Chen;Jamal Alsakran;Scott Barlowe;Jing Yang;Ye Zhao,"University of North Carolina, Charlotte, USA;Kent University, USA;University of North Carolina, Charlotte, USA;University of North Carolina, Charlotte, USA;Kent State Univer, USA",10.1109/tvcg.2007.70541;10.1109/vast.2009.5333023;10.1109/tvcg.2007.70577;10.1109/vast.2010.5652879;10.1109/vast.2008.4677358;10.1109/vast.2010.5652932;10.1109/vast.2007.4389011;10.1109/vast.2008.4677365;10.1109/tvcg.2006.166;10.1109/vast.2010.5652885;10.1109/tvcg.2007.70541,"Visual analytics, asynchronous collaboration, insight, multidimensional visualization",28.0,14.0,30.0,592.0,,,collaborative visual analytics;understanding;acva propose novel;reach potential;conducted case,0.7708;0.1905;0.1437;0.0487;0.0041,"[np.int64(-1), -1, -1, -1, -1]",193;-1;-1;-1;-1,193,193
Vis,2005,Farthest point seeding for efficient placement of streamlines,10.1109/visual.2005.1532832,http://dx.doi.org/10.1109/VISUAL.2005.1532832,479.0,486.0,C,"We propose a novel algorithm for placement of streamlines from two-dimensional steady vector or direction fields. Our method consists of placing one streamline at a time by numerical integration starting at the furthest away from all previously placed streamlines. Such a farthest point seeding strategy leads to high quality placements by favoring long streamlines, while retaining uniformity with the increasing density. Our greedy approach generates placements of comparable quality with respect to the optimization approach from Turk and Banks, while being 200 times faster. Simplicity, robustness as well as efficiency is achieved through the use of a Delaunay triangulation to model the streamlines, address proximity queries and determine the biggest voids by exploiting the empty circle property. Our method handles variable density and extends to multiresolution.",Abdelkrim Mebarki;Pierre Alliez;Olivier Devillers,A. Mebarki;P. Alliez;O. Devillers,"I.N.R.I.A. Sophia Antipolis, France;I.N.R.I.A. Sophia Antipolis, France;I.N.R.I.A. Sophia Antipolis, France",10.1109/visual.2000.885690;10.1109/visual.2000.885690,"Streamline placement, farthest point seeding, Delaunay triangulation, variable density, multiresolution",176.0,29.0,22.0,656.0,,,placement streamlines;density extends multiresolution;exploiting circle property;time numerical;turk,0.6958;0.1807;0.1439;0.0355;0.0289,"[np.int64(-1), -1, -1, -1, -1]",240;-1;-1;-1;-1,240,240
InfoVis,2011,Adaptive Privacy-Preserving Visualization Using Parallel Coordinates,10.1109/tvcg.2011.163,http://dx.doi.org/10.1109/TVCG.2011.163,2241.0,2248.0,J,"Current information visualization techniques assume unrestricted access to data. However, privacy protection is a key issue for a lot of real-world data analyses. Corporate data, medical records, etc. are rich in analytical value but cannot be shared without first going through a transformation step where explicit identifiers are removed and the data is sanitized. Researchers in the field of data mining have proposed different techniques over the years for privacy-preserving data publishing and subsequent mining techniques on such sanitized data. A well-known drawback in these methods is that for even a small guarantee of privacy, the utility of the datasets is greatly reduced. In this paper, we propose an adaptive technique for privacy preser vation in parallel coordinates. Based on knowledge about the sensitivity of the data, we compute a clustered representation on the fly, which allows the user to explore the data without breaching privacy. Through the use of screen-space privacy metrics, the technique adapts to the user's screen parameters and interaction. We demonstrate our method in a case study and discuss potential attack scenarios.",Aritra Dasgupta;Robert Kosara,Aritra Dasgupta;Robert Kosara,"UNC-Charlotte, USA;UNC-Charlotte, USA",10.1109/visual.1990.146402;10.1109/infvis.2005.1532138;10.1109/tvcg.2010.184;10.1109/visual.1999.809866;10.1109/tvcg.2006.170;10.1109/visual.1990.146402,"Parallel coordinates, privacy, clustering",56.0,34.0,30.0,1310.0,,,privacy preserving data;parallel coordinates;discuss potential attack;adapts user screen;rich,0.5841;0.2353;0.1608;0.1577;0.0765,"[np.int64(-1), -1, -1, -1, -1]",278;-1;-1;-1;-1,278,278
Vis,2022,RASIPAM: Interactive Pattern Mining of Multivariate Event Sequences in Racket Sports,10.1109/tvcg.2022.3209452,http://dx.doi.org/10.1109/TVCG.2022.3209452,940.0,950.0,J,"Experts in racket sports like tennis and badminton use tactical analysis to gain insight into competitors' playing styles. Many data-driven methods apply pattern mining to racket sports data — which is often recorded as multivariate event sequences — to uncover sports tactics. However, tactics obtained in this way are often inconsistent with those deduced by experts through their domain knowledge, which can be confusing to those experts. This work introduces RASIPAM, a RAcket-Sports Interactive PAttern Mining system, which allows experts to incorporate their knowledge into data mining algorithms to discover meaningful tactics interactively. RASIPAM consists of a constraint-based pattern mining algorithm that responds to the analysis demands of experts: Experts provide suggestions for finding tactics in intuitive written language, and these suggestions are translated into constraints to run the algorithm. RASIPAM further introduces a tailored visual interface that allows experts to compare the new tactics with the original ones and decide whether to apply a given adjustment. This interactive workflow iteratively progresses until experts are satisfied with all tactics. We conduct a quantitative experiment to show that our algorithm supports real-time interaction. Two case studies in tennis and in badminton respectively, each involving two domain experts, are conducted to show the effectiveness and usefulness of the system.",Jiang Wu;Dongyu Liu;Ziyang Guo;Yingcai Wu,Jiang Wu;Dongyu Liu;Ziyang Guo;Yingcai Wu,"State Key Lab of CAD&CG, Zhejiang University, China;MIT, USA;State Key Lab of CAD&CG, Zhejiang University, China;State Key Lab of CAD&CG, Zhejiang University, China",10.1109/tvcg.2017.2745278;10.1109/tvcg.2021.3114861;10.1109/vast.2006.261421;10.1109/tvcg.2013.173;10.1109/tvcg.2018.2865018;10.1109/tvcg.2015.2467325;10.1109/tvcg.2021.3114848;10.1109/tvcg.2012.271;10.1109/tvcg.2012.213;10.1109/tvcg.2015.2467931;10.1109/vast.2017.8585647;10.1109/tvcg.2019.2934630;10.1109/vast50239.2020.00009;10.1109/tvcg.2021.3114832;10.1109/tvcg.2017.2744218;10.1109/tvcg.2018.2865041;10.1109/tvcg.2020.3030359;10.1109/tvcg.2021.3114877;10.1109/tvcg.2022.3209447;10.1109/tvcg.2019.2934668;10.1109/tvcg.2019.2934267;10.1109/tvcg.2022.3209360;10.1109/tvcg.2017.2745278,"Sports Analytics,Multivariate Event Sequence,Interactive Pattern Mining,Comparative Visual Design",,6.0,52.0,638.0,,,mining racket sports;methods apply pattern;multivariate event sequences;adjustment interactive workflow;confusing,0.6636;0.2601;0.2435;0.2411;0.0697,"[np.int64(-1), -1, -1, -1, -1]",228;-1;-1;-1;-1,228,228
Vis,2022,GenoREC: A Recommendation System for Interactive Genomics Data Visualization,10.1109/tvcg.2022.3209407,http://dx.doi.org/10.1109/TVCG.2022.3209407,570.0,580.0,J,"Interpretation of genomics data is critically reliant on the application of a wide range of visualization tools. A large number of visualization techniques for genomics data and different analysis tasks pose a significant challenge for analysts: which visualization technique is most likely to help them generate insights into their data? Since genomics analysts typically have limited training in data visualization, their choices are often based on trial and error or guided by technical details, such as data formats that a specific tool can load. This approach prevents them from making effective visualization choices for the many combinations of data types and analysis questions they encounter in their work. Visualization recommendation systems assist non-experts in creating data visualization by recommending appropriate visualizations based on the data and task characteristics. However, existing visualization recommendation systems are not designed to handle domain-specific problems. To address these challenges, we designed GenoREC, a novel visualization recommendation system for genomics. GenoREC enables genomics analysts to select effective visualizations based on a description of their data and analysis tasks. Here, we present the recommendation model that uses a knowledge-based method for choosing appropriate visualizations and a web application that enables analysts to input their requirements, explore recommended visualizations, and export them for their usage. Furthermore, we present the results of two user studies demonstrating that GenoREC recommends visualizations that are both accepted by domain experts and suited to address the given genomics analysis problem. All supplemental materials are available at https://osf.io/y73pt/.",Aditeya Pandey;Sehi L'Yi;Qianwen Wang;Michelle A. Borkin;Nils Gehlenborg,Aditeya Pandey;Sehi L'Yi;Qianwen Wang;Michelle A. Borkin;Nils Gehlenborg,"Northeastern University, MA, US;Harvard Medical School, MA, US;Harvard Medical School, MA, US;Northeastern University, MA, US;Harvard Medical School, MA, US",10.1109/tvcg.2013.234;10.1109/tvcg.2013.124;10.1109/tvcg.2021.3114860;10.1109/tvcg.2022.3209398;10.1109/tvcg.2020.3030419;10.1109/tvcg.2021.3114876;10.1109/tvcg.2007.70594;10.1109/tvcg.2009.167;10.1109/tvcg.2018.2865240;10.1109/tvcg.2018.2865240;10.1109/tvcg.2017.2744198;10.1109/tvcg.2019.2934784;10.1109/tvcg.2015.2467191;10.1109/tvcg.2020.3030423;10.1109/tvcg.2021.3114814;10.1109/tvcg.2013.234,"genomics,visualization,recommendation systems,data,tasks",,7.0,62.0,2485.0,,,visualization recommendation genomics;model uses knowledge;export usage furthermore;typically;https osf,0.7961;0.2351;0.1123;0.0364;0.0101,"[np.int64(-1), -1, -1, -1, -1]",116;-1;-1;-1;-1,116,116
Vis,2007,Conjoint Analysis to Measure the Perceived Quality in Volume Rendering,10.1109/tvcg.2007.70542,http://dx.doi.org/10.1109/TVCG.2007.70542,1664.0,1671.0,J,"Visualization algorithms can have a large number of parameters, making the space of possible rendering results rather high-dimensional. Only a systematic analysis of the perceived quality can truly reveal the optimal setting for each such parameter. However, an exhaustive search in which all possible parameter permutations are presented to each user within a study group would be infeasible to conduct. Additional complications may result from possible parameter co-dependencies. Here, we will introduce an efficient user study design and analysis strategy that is geared to cope with this problem. The user feedback is fast and easy to obtain and does not require exhaustive parameter testing. To enable such a framework we have modified a preference measuring methodology, conjoint analysis, that originated in psychology and is now also widely used in market research. We demonstrate our framework by a study that measures the perceived quality in volume rendering within the context of large parameter spaces.",Joachim Giesen;Klaus Mueller 0001;Eva Schuberth;Lujin Wang;Peter Zolliker,Joachim Giesen;Klaus Mueller;Eva Schuberth;Lujin Wang;Peter Zolliker,"MPI Informatik, Germany;Stony Brook University, USA;ETH Zürich, Switzerland;Stony Brook University, USA;EMPA Dübendorf, Switzerland",10.1109/tvcg.2006.137;10.1109/visual.2005.1532834;10.1109/tvcg.2006.174;10.1109/visual.2003.1250412;10.1109/infvis.2005.1532149;10.1109/tvcg.2006.113;10.1109/tvcg.2006.137,"Conjoint Analysis, Parameterized Algorithms, Volume Visualization",36.0,18.0,14.0,321.0,,,visualization algorithms;perceived quality truly;conjoint;context large parameter;testing enable,0.6168;0.4125;0.2120;0.1627;-0.0290,"[np.int64(-1), -1, -1, -1, -1]",274;-1;-1;-1;-1,274,274
Vis,2006,Understanding the Structure of the Turbulent Mixing Layer in Hydrodynamic Instabilities,10.1109/tvcg.2006.186,http://dx.doi.org/10.1109/TVCG.2006.186,1053.0,1060.0,J,"When a heavy fluid is placed above a light fluid, tiny vertical perturbations in the interface create a characteristic structure of rising bubbles and falling spikes known as Rayleigh-Taylor instability. Rayleigh-Taylor instabilities have received much attention over the past half-century because of their importance in understanding many natural and man-made phenomena, ranging from the rate of formation of heavy elements in supernovae to the design of capsules for Inertial Confinement Fusion. We present a new approach to analyze Rayleigh-Taylor instabilities in which we extract a hierarchical segmentation of the mixing envelope surface to identify bubbles and analyze analogous segmentations of fields on the original interface plane. We compute meaningful statistical information that reveals the evolution of topological features and corroborates the observations made by scientists. We also use geometric tracking to follow the evolution of single bubbles and highlight merge/split events leading to the formation of the large and complex structures characteristic of the later stages. In particular we (i) Provide a formal definition of a bubble; (ii) Segment the envelope surface to identify bubbles; (iii) Provide a multi-scale analysis technique to produce statistical measures of bubble growth; (iv) Correlate bubble measurements with analysis of fields on the interface plane; (v) Track the evolution of individual bubbles over time. Our approach is based on the rigorous mathematical foundations of Morse theory and can be applied to a more general class of applications",David E. Laney;Peer-Timo Bremer;Ajith Mascarenhas;Paul L. Miller;Valerio Pascucci,D. Laney;P.-t. Bremer;A. Mascarenhas;P. Miller;V. Pascucci,"Lawrence Livemore National Laboratory, USA;Lawrence Livemore National Laboratory, USA;Lawrence Livemore National Laboratory, USA;Lawrence Livemore National Laboratory, USA;Lawrence Livemore National Laboratory, USA",10.1109/visual.2003.1250376;10.1109/visual.2002.1183772;10.1109/visual.2005.1532842;10.1109/visual.2000.885716;10.1109/visual.2004.96;10.1109/visual.2003.1250408;10.1109/visual.2004.107;10.1109/visual.1999.809907;10.1109/visual.1998.745288;10.1109/visual.2005.1532839;10.1109/visual.2003.1250376,"topology, multi-resolution, Morse theory",216.0,118.0,33.0,609.0,BA,,structure rising bubbles;analyze rayleigh taylor;inertial confinement fusion;morse;definition,0.5716;0.2492;0.2463;0.2024;0.0284,"[np.int64(-1), -1, -1, -1, -1]",295;-1;-1;-1;-1,295,295
Vis,2006,Vortex Visualization for Practical Engineering Applications,10.1109/tvcg.2006.201,http://dx.doi.org/10.1109/TVCG.2006.201,957.0,964.0,J,"In order to understand complex vortical flows in large data sets, we must be able to detect and visualize vortices in an automated fashion. In this paper, we present a feature-based vortex detection and visualization technique that is appropriate for large computational fluid dynamics data sets computed on unstructured meshes. In particular, we focus on the application of this technique to visualization of the flow over a serrated wing and the flow field around a spinning missile with dithering canards. We have developed a core line extraction technique based on the observation that vortex cores coincide with local extrema in certain scalar fields. We also have developed a novel technique to handle complex vortex topology that is based on k-means clustering. These techniques facilitate visualization of vortices in simulation data that may not be optimally resolved or sampled. Results are included that highlight the strengths and weaknesses of our approach. We conclude by describing how our approach can be improved to enhance robustness and expand its range of applicability",Monika Jankun-Kelly;Ming Jiang 0005;David S. Thompson;Raghu Machiraju,Monika Jankun-Kelly;Ming Jiang;David Thompson;Raghu Machiraju,"Graduate Research Assistant at the Computational Simulation and Design Center, Mississippi State University, USA;Postdoctoral Researcher at the Center for Applied Scientific Computing, Lawrence Livemore National Laboratory, USA;Department of AeroSpace Engineering, Mississippi State University, USA;Department of Computer Science and Engineering, Ohio State Uinversity, USA",10.1109/visual.1997.663894;10.1109/visual.2002.1183789;10.1109/visual.2005.1532830;10.1109/visual.1998.745296;10.1109/visual.1998.745288;10.1109/visual.1999.809896,"Vortex detection, vortex visualization, feature mining",42.0,25.0,31.0,588.0,,,vortex detection visualization;unstructured meshes particular;data optimally;cores coincide local;sets able,0.7662;0.3446;0.1518;0.1388;-0.0513,"[np.int64(-1), -1, -1, -1, -1]",142;-1;-1;-1;-1,142,142
VAST,2020,"A Visual Analytics Approach to Debugging Cooperative, Autonomous Multi-Robot Systems’ Worldviews",10.1109/vast50239.2020.00008,http://dx.doi.org/10.1109/VAST50239.2020.00008,24.0,35.0,C,"Autonomous multi-robot systems, where a team of robots shares information to perform tasks that are beyond an individual robot’s abilities, hold great promise for a number of applications, such as planetary exploration missions. Each robot in a multi-robot system that uses the shared-world coordination paradigm autonomously schedules which robot should perform a given task, and when, using its worldview–the robot’s internal representation of its belief about both its own state, and other robots’ states. A key problem for operators is that robots’ worldviews can fall out of sync (often due to weak communication links), leading to desynchronization of the robots’ scheduling decisions and inconsistent emergent behavior (e.g., tasks not performed, or performed by multiple robots). Operators face the time-consuming and difficult task of making sense of the robots’ scheduling decisions, detecting de-synchronizations, and pinpointing the cause by comparing every robot’s worldview. To address these challenges, we introduce MOSAIC Viewer, a visual analytics system that helps operators (i) make sense of the robots’ schedules and (ii) detect and conduct a root cause analysis of the robots’ desynchronized worldviews. Over a year-long partnership with roboticists at the NASA Jet Propulsion Laboratory, we conduct a formative study to identify the necessary system design requirements and a qualitative evaluation with 12 roboticists. We find that MOSAIC Viewer is faster- and easier-to-use than the users’ current approaches, and it allows them to stitch low-level details to formulate a high-level understanding of the robots’ schedules and detect and pinpoint the cause of the desynchronized worldviews.","Suyun ""Sandra"" Bae;Federico Rossi 0001;Joshua Vander Hook;Scott Davidoff;Kwan-Liu Ma",Suyun “Sandra” Bae;Federico Rossi;Joshua Vander Hook;Scott Davidoff;Kwan-Liu Ma,"University of California, Davis;Jet Propulsion Laboratory, California Institute of Technology;Jet Propulsion Laboratory, California Institute of Technology;Jet Propulsion Laboratory, California Institute of Technology;University of California, Davis",10.1109/tvcg.2011.185;10.1109/tvcg.2010.197;10.1109/vast.2006.261421;10.1109/tvcg.2014.2346454;10.1109/tvcg.2015.2467451;10.1109/tvcg.2017.2745298;10.1109/tvcg.2014.2346249;10.1109/tvcg.2012.213;10.1109/infvis.2003.1249018;10.1109/tvcg.2019.2934619;10.1109/tvcg.2011.185,"Multi-Robot Systems,Human-Subjects Qualitative Studies,Debugging,I.3.8 [Computer Graphics],Applications",6.0,4.0,78.0,444.0,,,robots desynchronized worldviews;introduce mosaic viewer;nasa jet propulsion;qualitative evaluation 12;number applications planetary,0.6760;0.2528;0.0885;0.0877;0.0792,"[np.int64(-1), -1, -1, -1, -1]",51;-1;-1;-1;-1,51,51
VAST,2018,Visual Abstraction of Large Scale Geospatial Origin-Destination Movement Data,10.1109/tvcg.2018.2864503,http://dx.doi.org/10.1109/TVCG.2018.2864503,43.0,53.0,J,"A variety of human movement datasets are represented in an Origin-Destination(OD) form, such as taxi trips, mobile phone locations, etc. As a commonly-used method to visualize OD data, flow map always fails to discover patterns of human mobility, due to massive intersections and occlusions of lines on a 2D geographical map. A large number of techniques have been proposed to reduce visual clutter of flow maps, such as filtering, clustering and edge bundling, but the correlations of OD flows are often neglected, which makes the simplified OD flow map present little semantic information. In this paper, a characterization of OD flows is established based on an analogy between OD flows and natural language processing (NPL) terms. Then, an iterative multi-objective sampling scheme is designed to select OD flows in a vectorized representation space. To enhance the readability of sampled OD flows, a set of meaningful visual encodings are designed to present the interactions of OD flows. We design and implement a visual exploration system that supports visual inspection and quantitative evaluation from a variety of perspectives. Case studies based on real-world datasets and interviews with domain experts have demonstrated the effectiveness of our system in reducing the visual clutter and enhancing correlations of OD flows.",Zhiguang Zhou;Linhao Meng;Cheng Tang;Ying Zhao 0001;Zhiyong Guo;Miaoxin Hu;Wei Chen 0001,Zhiguang Zhou;Linhao Meng;Cheng Tang;Ying Zhao;Zhiyong Guo;Miaoxin Hu;Wei Chen,"School of Information, Zhejiang University of Finance and Economics;State Key Lab of CAD & CG, Zhejiang University;Information School, Zhejiang Sci-tech University;Central South University;School of Information, Zhejiang University of Finance and Economics;School of Information, Zhejiang University of Finance and Economics;State Key Lab of CAD & CG, Zhejiang University",10.1109/tvcg.2017.2744322;10.1109/tvcg.2016.2598667;10.1109/tvcg.2011.202;10.1109/tvcg.2014.2346594;10.1109/tvcg.2008.135;10.1109/tvcg.2011.233;10.1109/tvcg.2013.226;10.1109/tvcg.2009.143;10.1109/tvcg.2014.2346271;10.1109/tvcg.2016.2598432;10.1109/tvcg.2013.196;10.1109/infvis.2005.1532150;10.1109/tvcg.2015.2467691;10.1109/tvcg.2014.2346746;10.1109/tvcg.2016.2598885;10.1109/tvcg.2017.2744322,"Visual abstraction,human mobility,origin-destination,flow map,representation learning",87.0,80.0,51.0,2699.0,,,patterns human mobility;datasets interviews domain;od;evaluation variety perspectives;fails discover,0.6100;0.2729;0.1082;0.0893;-0.0223,"[np.int64(-1), -1, -1, -1, -1]",67;-1;-1;-1;-1,67,67
Vis,2005,Differential protein expression analysis via liquid-chromatography/mass-spectrometry data visualization,10.1109/visual.2005.1532828,http://dx.doi.org/10.1109/VISUAL.2005.1532828,447.0,454.0,C,"Differential protein expression analysis is one of the main challenges in proteomics. It denotes the search for proteins, whose encoding genes are differentially expressed under a given experimental setup. An important task in this context is to identify the differentially expressed proteins or, more generally, all proteins present in the sample. One of the most promising and recently widely used approaches for protein identification is to cleave proteins into peptides, separate the peptides using liquid chromatography, and determine the masses of the separated peptides using mass spectrometry. The resulting data needs to be analyzed and matched against protein sequence databases. The analysis step is typically done by searching for intensity peaks in a large number of 2D graphs. We present an interactive visualization tool for the exploration of liquid-chromatography/mass-spectrometry data in a 3D space, which allows for the understanding of the data in its entirety and a detailed analysis of regions of interest. We compute differential expression over the liquid-chromatography/mass-spectrometry domain and embed it visually in our system. Our exploration tool can treat single liquid-chromatography/mass-spectrometry data sets as well as data acquired using multi-dimensional protein identification technology. For efficiency purposes we perform a peak-preserving data resampling and multiresolution hierarchy generation prior to visualization.",Lars Linsen;Julia Löcherbach;Matthias Berth;Jörg Bernhardt;Dörte Becher,L. Linsen;J. Locherbach;M. Berth;J. Bernhardt;D. Becher,"Department of Mathematics and Computer Science, Ernst Moritz Arndt University슠of Greifswald, Greifswald, Germany;Department of Mathematics and Computer Science, Ernst Moritz Arndt University슠of Greifswald, Greifswald, Germany;DECODON GmbH, Greifswald, Germany;Department of Microbiology, Ernst Moritz Arndt University슠of Greifswald, Greifswald, Germany;Department of Microbiology, Ernst Moritz Arndt University슠of Greifswald, Greifswald, Germany",10.1109/visual.1997.663907;10.1109/visual.1997.663907,"interactive visual exploration, hierarchical data representation, visualization in bioinformatics, proteomics",17.0,4.0,22.0,239.0,,,protein expression analysis;2d graphs;preserving data resampling;intensity peaks large;liquid,0.6266;0.2685;0.1511;0.1309;0.0924,"[np.int64(-1), -1, -1, -1, -1]",217;-1;-1;-1;-1,217,217
InfoVis,2004,GeoTime Information Visualization,10.1109/infvis.2004.27,http://dx.doi.org/10.1109/INFVIS.2004.27,25.0,32.0,C,"Analyzing observations over time and geography is a common task but typically requires multiple, separate tools. The objective of our research has been to develop a method to visualize, and work with, the spatial interconnectedness of information over time and geography within a single, highly interactive 3D view. A novel visualization technique for displaying and tracking events, objects and activities within a combined temporal and geospatial display has been developed. This technique has been implemented as a demonstratable prototype called GeoTime in order to determine potential utility. Initial evaluations have been with military users. However, we believe the concept is applicable to a variety of government and business analysis tasks",Thomas Kapler;William Wright,T. Kapler;W. Wright,"Oculus Info, Inc.;Oculus Info, Inc.",10.1109/infvis.2003.1249006;10.1109/infvis.2003.1249006,"3-D visualization, spatiotemporal, geospatial, interactive visualization, visual data analysis, link analysis",359.0,68.0,22.0,853.0,,,temporal geospatial display;interconnectedness information;government business analysis;multiple separate tools;called,0.7018;0.3276;0.2802;0.0706;0.0165,"[np.int64(-1), -1, -1, -1, -1]",222;-1;-1;-1;-1,222,222
VAST,2020,Visual Analytics of Multivariate Event Sequence Data in Racquet Sports,10.1109/vast50239.2020.00009,http://dx.doi.org/10.1109/VAST50239.2020.00009,36.0,47.0,C,"In this work, we propose a generic visual analytics framework to support tactic analysis based on data collected from racquet sports (such as tennis and badminton). The proposed approach models each rally in a game as a sequence of hits (i.e., events) until one athlete scores a point. Each hit can be described with a set of attributes, such as the positions of the ball and the techniques used to hit the ball (such as drive and volley in tennis). Thus, the mentioned sequence of hits can be viewed as a multivariate event sequence. By detecting and analyzing the multivariate subsequences that frequently occur in the rallies (namely, tactical patterns), athletes can gain insights into the playing styles adopted by their opponents, and therefore help them identify systematic weaknesses of the opponents and develop counter strategies in matches. To support such analysis effectively, we propose a steerable multivariate sequential pattern mining algorithm with adjustable weights over event attributes, such that the domain expert can obtain frequent tactical patterns according to the attributes specified by himself. We also propose a re-configurable glyph design to help users simultaneously analyze multiple attributes of the hits. The framework further supports comparative analysis of the tactical patterns, e.g., for different athletes or the same athlete playing under different conditions. By applying the framework on two datasets collected in tennis and badminton matches, we demonstrate that the system is generic and effective for tactic analysis in sports and can help identify signature techniques used by individual athletes. Finally, we discuss the strengths and limitations of the proposed approach based on the feedback from the domain experts.",Jiang Wu;Ziyang Guo;Zuobin Wang;Qingyang Xu;Yingcai Wu,Jiang Wu;Ziyang Guo;Zuobin Wang;Qingyang Xu;Yingcai Wu,"The State Key Lab of CAD&CG, Zhejiang University;The State Key Lab of CAD&CG, Zhejiang University;The State Key Lab of CAD&CG, Zhejiang University;The State Key Lab of CAD&CG, Zhejiang University;The State Key Lab of CAD&CG, Zhejiang University",10.1109/tvcg.2019.2934209;10.1109/tvcg.2017.2745278;10.1109/tvcg.2017.2745083;10.1109/tvcg.2019.2934670;10.1109/vast.2014.7042478;10.1109/vast.2016.7883512;10.1109/vast.2006.261421;10.1109/tvcg.2018.2864885;10.1109/tvcg.2017.2745320;10.1109/vast.2007.4389008;10.1109/tvcg.2016.2598797;10.1109/tvcg.2015.2467325;10.1109/tvcg.2013.192;10.1109/tvcg.2019.2934243;10.1109/tvcg.2014.2346445;10.1109/infvis.2000.885091;10.1109/tvcg.2009.117;10.1109/tvcg.2019.2934630;10.1109/tvcg.2017.2744218;10.1109/tvcg.2018.2865041;10.1109/tvcg.2020.3030359;10.1109/tvcg.2020.3030392;10.1109/tvcg.2019.2934209,"Sports Analytics,Event Sequence,Multivariate Data,Sequential Pattern Mining,Comparative Analysis",13.0,20.0,55.0,967.0,,,tactic analysis sports;pattern mining algorithm;analytics framework support;multivariate subsequences frequently;configurable glyph,0.6334;0.4195;0.2353;0.2323;0.1290,"[np.int64(-1), -1, -1, -1, -1]",75;-1;-1;-1;-1,75,75
Vis,2007,Interactive Isosurface Ray Tracing of Time-Varying Tetrahedral Volumes,10.1109/tvcg.2007.70566,http://dx.doi.org/10.1109/TVCG.2007.70566,1727.0,1734.0,J,"We describe a system for interactively rendering isosurfaces of tetrahedral finite-element scalar fields using coherent ray tracing techniques on the CPU. By employing state-of-the art methods in polygonal ray tracing, namely aggressive packet/frustum traversal of a bounding volume hierarchy, we can accommodate large and time-varying unstructured data. In conjunction with this efficiency structure, we introduce a novel technique for intersecting ray packets with tetrahedral primitives. Ray tracing is flexible, allowing for dynamic changes in isovalue and time step, visualization of multiple isosurfaces, shadows, and depth-peeling transparency effects. The resulting system offers the intuitive simplicity of isosurfacing, guaranteed-correct visual results, and ultimately a scalable, dynamic and consistently interactive solution for visualizing unstructured volumes.",Ingo Wald;Heiko Friedrich;Aaron Knoll;Charles D. Hansen,Ingo Wald;Heiko Friedrich;Aaron Knoll;Charles D. Hansen,"SCI Institute, Intel Corp, University of Utah, Santa Clara, CA, USA;Computer Graphics Group, University of Saarland, Saarbruecken, Germany;SCI Institute, University of Utah, USA;SCI Institute, University of Utah, USA",10.1109/visual.2005.1532796;10.1109/tvcg.2006.171;10.1109/visual.2003.1250390;10.1109/tvcg.2006.110;10.1109/visual.2003.1250384;10.1109/visual.1998.745713;10.1109/visual.1998.745300;10.1109/visual.2005.1532796,"Ray Tracing, Isosurfaces, Unstructured meshes, Tetrahedra, Scalar Fields, Time-varying data",33.0,17.0,41.0,276.0,,,polygonal ray tracing;volume hierarchy accommodate;dynamic changes isovalue;fields;cpu employing,0.6420;0.2833;0.1468;0.1095;0.0760,"[np.int64(-1), -1, -1, -1, -1]",60;-1;-1;-1;-1,60,60
VAST,2016,DropoutSeer: Visualizing learning patterns in Massive Open Online Courses for dropout reasoning and prediction,10.1109/vast.2016.7883517,http://dx.doi.org/10.1109/VAST.2016.7883517,111.0,120.0,C,"Aiming at massive participation and open access education, Massive Open Online Courses (MOOCs) have attracted millions of learners over the past few years. However, the high dropout rate of learners is considered to be one of the most crucial factors that may hinder the development of MOOCs. To tackle this problem, statistical models have been developed to predict dropout behavior based on learner activity logs. Although predictive models can foresee the dropout behavior, it is still difficult for users to understand the reasons behind the predicted results and further design interventions to prevent dropout. In addition, with a better understanding of dropout, researchers in the area of predictive modeling in turn can improve the models. In this paper, we introduce DropoutSeer, a visual analytics system which not only helps instructors and education experts understand the reasons for dropout, but also allows researchers to identify crucial features which can further improve the performance of the models. Both the heterogeneous data extracted from three different kinds of learner activity logs (i.e., clickstream, forum posts and assignment records) and the predicted results are visualized in the proposed system. Case studies and expert interviews have been conducted to demonstrate the usefulness and effectiveness of DropoutSeer.",Yuanzhe Chen;Qing Chen 0001;Mingqian Zhao;Sebastien Boyer;Kalyan Veeramachaneni;Huamin Qu,Yuanzhe Chen;Qing Chen;Mingqian Zhao;Sebastien Boyer;Kalyan Veeramachaneni;Huamin Qu,Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Massachusetts Institute of Technology;Massachusetts Institute of Technology;Hong Kong University of Science and Technology,10.1109/infvis.1999.801851;10.1109/tvcg.2015.2468151;10.1109/infvis.2000.885098;10.1109/vast.2010.5652931;10.1109/tvcg.2010.129;10.1109/vast.2012.6400557;10.1109/infvis.2001.963273;10.1109/tvcg.2013.221;10.1109/tvcg.2007.70515;10.1109/tvcg.2011.239;10.1109/infvis.1999.801851,,81.0,42.0,41.0,1249.0,,,predict dropout behavior;visual analytics;logs clickstream forum;massive open online;addition better understanding,0.6385;0.3669;0.3090;0.2649;0.1099,"[np.int64(-1), np.int64(-1), -1, -1, -1]",23;201;-1;-1;-1,23;201,23
Vis,1996,Two-handed interactive stereoscopic visualization,10.1109/visual.1996.568109,http://dx.doi.org/10.1109/VISUAL.1996.568109,205.0,210.0,C,"This paper describes a minimally immersive interactive system for visualization of multivariate volumetric data. The system, SFA, uses glyph-based volume rendering which does not suffer the initial costs of isosurface rendering or voxel-based volume rendering, while offering the capability of viewing the entire volume. Glyph rendering also allows the simultaneous display of multiple data values per volume location. Two-handed interaction using three-space magnetic trackers and stereoscopic viewing are combined to produce a minimally immersive volumetric visualization system that enhances the user's three-dimensional perception of the data. We describe the usefulness of this system for visualizing volumetric scalar and vector data. SFA allows the three-dimensional volumetric visualization, manipulation, navigation, and analysis of multivariate, time-varying volumetric data, increasing the quantity and clarity of the information conveyed from the visualization system.",David S. Ebert;Christopher D. Shaw;Amen Zwa;Cindy Starr,D.S. Ebert;C.D. Shaw;A. Zwa;C. Starr,"Computer Science and Electrical Engineering Department, University of Maryland Baltimore County, Baltimore, MD, USA;Department of Computer Science, University of Regina, Regina, SAS, Canada;Computer Science and Electrical Engineering Department, University of Maryland Baltimore County, Baltimore, MD, USA;Scientific Visualization Studio, NASA Goddard Space Flight Center, Greenbelt, MD, USA",10.1109/visual.1995.485141;10.1109/infvis.1996.559220;10.1109/visual.1995.485141,,51.0,10.0,20.0,76.0,,,immersive volumetric visualization;space magnetic trackers;sfa uses glyph;multiple data values;minimally,0.7864;0.3425;0.1990;0.1761;0.0886,"[np.int64(-1), -1, -1, -1, -1]",84;-1;-1;-1;-1,84,84
InfoVis,2016,The Attraction Effect in Information Visualization,10.1109/tvcg.2016.2598594,http://dx.doi.org/10.1109/TVCG.2016.2598594,471.0,480.0,J,"The attraction effect is a well-studied cognitive bias in decision making research, where one's choice between two alternatives is influenced by the presence of an irrelevant (dominated) third alternative. We examine whether this cognitive bias, so far only tested with three alternatives and simple presentation formats such as numerical tables, text and pictures, also appears in visualizations. Since visualizations can be used to support decision making - e.g., when choosing a house to buy or an employee to hire - a systematic bias could have important implications. In a first crowdsource experiment, we indeed partially replicated the attraction effect with three alternatives presented as a numerical table, and observed similar effects when they were presented as a scatterplot. In a second experiment, we investigated if the effect extends to larger sets of alternatives, where the number of alternatives is too large for numerical tables to be practical. Our findings indicate that the bias persists for larger sets of alternatives presented as scatterplots. We discuss implications for future research on how to further study and possibly alleviate the attraction effect.",Evanthia Dimara;Anastasia Bezerianos;Pierre Dragicevic,Evanthia Dimara;Anastasia Bezerianos;Pierre Dragicevic,"Inria and Université Paris-Saclay;Inria, Université Paris-Saclay;Inria and Université Paris-Saclay",10.1109/tvcg.2008.153;10.1109/tvcg.2014.2346984;10.1109/vast.2008.4677363;10.1109/tvcg.2014.2346298;10.1109/tvcg.2012.199;10.1109/tvcg.2010.174;10.1109/vast.2009.5333920;10.1109/tvcg.2008.153,cognitive bias;Information visualization;decision-making;decoy effect;attraction effect;asymmetric dominance effect,91.0,62.0,61.0,2929.0,HM,,studied cognitive bias;alternatives presented scatterplots;choosing house buy;large numerical tables;text pictures appears,0.5115;0.4279;0.2304;0.1814;0.1171,"[np.int64(-1), -1, -1, -1, -1]",85;-1;-1;-1;-1,85,85
Vis,2002,A new object-order ray-casting algorithm,10.1109/visual.2002.1183776,http://dx.doi.org/10.1109/VISUAL.2002.1183776,203.0,210.0,C,"Many direct volume rendering algorithms have been proposed during the last decade to render 256/sup 3/ voxels interactively. However a lot of limitations are inherent to all of them, like low-quality images, a small viewport size or a fixed classification. In contrast, interactive high quality algorithms are still a challenge nowadays. We introduce here an efficient and accurate technique called object-order ray-casting that can achieve up to 10 fps on current workstations. Like usual ray-casting, colors and opacities are evenly sampled along the ray, but now within a new object-order algorithm. Thus, it allows to combine the main advantages of both worlds in term of speed and quality. We also describe an efficient hidden volume removal technique to compensate for the loss of early ray termination.",Benjamin Mora;Jean-Pierre Jessel;René Caubet,B. Mora;J.-P. Jessel;R. Caubet,"Institut de Recherche en Informatique de Toulouse, Université Paul Sabatier, Toulouse, France;Institut de Recherche en Informatique de Toulouse, Université Paul Sabatier, Toulouse, France;Institut de Recherche en Informatique de Toulouse, Université Paul Sabatier, Toulouse, France",10.1109/visual.2001.964498;10.1109/visual.2001.964521;10.1109/visual.1999.809889;10.1109/visual.1998.745309;10.1109/visual.2000.885698;10.1109/visual.1999.809911;10.1109/visual.1999.809909;10.1109/visual.1994.346331;10.1109/visual.1995.480792;10.1109/visual.2001.964498,"Volume Rendering, Scientific Visualization, Medical Imaging, Ray Tracing",90.0,18.0,37.0,328.0,,,volume rendering algorithms;order ray;256 sup;casting achieve;nowadays,0.7300;0.3291;0.2047;0.1233;0.0578,"[np.int64(-1), -1, -1, -1, -1]",96;-1;-1;-1;-1,96,96
Vis,1994,Differential volume rendering: a fast volume visualization technique for flow animation,10.1109/visual.1994.346321,http://dx.doi.org/10.1109/VISUAL.1994.346321,180.0,,C,"We present a direct volume rendering algorithm to speed up volume animation for flow visualizations. Data coherency between consecutive simulation time steps is used to avoid casting rays from those pixels retaining color values assigned to the previous image. The algorithm calculates the differential information among a sequence of 3D volumetric simulation data. At each time step the differential information is used to compute the locations of pixels that need updating and a ray-casting method as utilized to produce the updated image. We illustrate the utility and speed of the differential volume rendering algorithm with simulation data from computational bioelectric and fluid dynamics applications. We can achieve considerable disk-space savings and nearly real-time rendering of 3D flows using low-cost, single processor workstations for models which contain hundreds of thousands of data points.&lt;&lt;ETX&gt;&gt;",Han-Wei Shen;Christopher R. Johnson 0001,Han-Wei Shen;C.R. Johnson,"Department of Computer Science, University of Utah, Salt Lake, UT, USA;Department of Computer Science, University of Utah, Salt Lake, UT, USA",10.1109/visual.1993.398877;10.1109/visual.1992.235227;10.1109/visual.1992.235210;10.1109/visual.1991.175772;10.1109/visual.1993.398852;10.1109/visual.1991.175773;10.1109/visual.1993.398846;10.1109/visual.1993.398877,,132.0,28.0,14.0,161.0,,,volume rendering algorithm;differential information sequence;bioelectric;single processor workstations;avoid casting,0.7031;0.1556;0.1326;0.0713;0.0089,"[np.int64(-1), -1, -1, -1, -1]",96;-1;-1;-1;-1,96,96
Vis,2002,Exploring surface characteristics with interactive Gaussian images (a case study),10.1109/visual.2002.1183828,http://dx.doi.org/10.1109/VISUAL.2002.1183828,553.0,556.0,C,"The Gauss map projects surface normals to a unit sphere, providing a powerful visualization of the geometry of a graphical object. it can be used to predict visual events caused by changes in lighting, shading, and camera control. We present an interactive technique for portraying the Gauss map of polygonal models, mapping surface normals and the magnitudes of surface curvature using a spherical projection. Unlike other visualizations of surface curvature, we create our Gauss map directly from polygonal meshes without requiring any complex intermediate calculations of differential geometry. For anything other than simple shapes, surface information is densely mapped into the Gaussian normal image, inviting the use of visualization techniques to amplify and emphasize details hidden within the wealth of data. We present the use of interactive visualization tools such as brushing and linking to explore the surface properties of solid shapes. The Gauss map is shown to be simple to compute, easy to view dynamically, and effective at portraying important features of polygonal models.",Bradley C. Lowekamp;Penny Rheingans;Terry S. Yoo,B. Lowekamp;P. Rheingans;T.S. Yoo,"University of Maryland, Baltimore, USA;University of Maryland, Baltimore, USA;National Library of Medicine, USA",10.1109/visual.2001.964529;10.1109/visual.2001.964529,"Computational Geometry, Gauss map, Illumination and shading, Interactive visualization",10.0,5.0,12.0,106.0,,,visualizations surface curvature;gaussian;changes lighting;view dynamically;tools brushing linking,0.6414;0.2848;0.1970;0.1592;0.1437,"[np.int64(-1), -1, -1, -1, -1]",241;-1;-1;-1;-1,241,241
Vis,2010,Spatial Conditioning of Transfer Functions Using Local Material Distributions,10.1109/tvcg.2010.195,http://dx.doi.org/10.1109/TVCG.2010.195,1301.0,1310.0,J,"In many applications of Direct Volume Rendering (DVR) the importance of a certain material or feature is highly dependent on its relative spatial location. For instance, in the medical diagnostic procedure, the patient's symptoms often lead to specification of features, tissues and organs of particular interest. One such example is pockets of gas which, if found inside the body at abnormal locations, are a crucial part of a diagnostic visualization. This paper presents an approach that enhances DVR transfer function design with spatial localization based on user specified material dependencies. Semantic expressions are used to define conditions based on relations between different materials, such as only render iodine uptake when close to liver. The underlying methods rely on estimations of material distributions which are acquired by weighing local neighborhoods of the data against approximations of material likelihood functions. This information is encoded and used to influence rendering according to the user's specifications. The result is improved focus on important features by allowing the user to suppress spatially less-important data. In line with requirements from actual clinical DVR practice, the methods do not require explicit material segmentation that would be impossible or prohibitively time-consuming to achieve in most real cases. The scheme scales well to higher dimensions which accounts for multi-dimensional transfer functions and multivariate data. Dual-Energy Computed Tomography, an important new modality in radiology, is used to demonstrate this scalability. In several examples we show significantly improved focus on clinically important aspects in the rendered images.",Stefan Lindholm;Patric Ljung;Claes Lundström;Anders Persson;Anders Ynnerman,Stefan Lindholm;Patric Ljung;Claes Lundstrom;Anders Persson;Anders Ynnerman,"Linköping University, Sweden and Siemens AG Corporate Research and Development, USA;Siemens AG Corporate Research and Development, USA;Sectra Imtec AB, Sweden;CMIV, Linköping University, Sweden;Linköping University, Sweden",10.1109/tvcg.2009.185;10.1109/tvcg.2009.120;10.1109/tvcg.2008.147;10.1109/visual.2003.1250412;10.1109/tvcg.2007.70591;10.1109/visual.2001.964516;10.1109/tvcg.2009.189;10.1109/tvcg.2008.162;10.1109/visual.2003.1250413;10.1109/visual.1999.809932;10.1109/tvcg.2006.148;10.1109/visual.2004.57;10.1109/tvcg.2009.185,"Direct Volume Rendering, Transfer Function, Spatial Conditioning, Neighborhood Meta-Data",26.0,16.0,39.0,732.0,,,direct volume rendering;material dependencies semantic;neighborhoods data approximations;diagnostic procedure;localization based user,0.6322;0.3240;0.3195;0.1288;0.0656,"[np.int64(-1), -1, -1, -1, -1]",98;-1;-1;-1;-1,98,98
Vis,1991,Applying 3D visualization techniques to finite element analysis,10.1109/visual.1991.175823,http://dx.doi.org/10.1109/VISUAL.1991.175823,330.0,335.0,M,"Addresses 3D visualization techniques now being developed that are specific to coarse, irregular grid fields such as finite-element models. These include direct-generation of isovalues from finite elements, display of 3D gradient and tensor quantities, and the display of multiple states of behavior, items common to general 3D visualization, but with specific algorithmic and implementation issues in finite element analysis.&lt;&lt;ETX&gt;&gt;",R.S. Gallagher;R.B. Haber;G. Ferguson;D. Parker;D. Stillman;J. Winget,R.S. Gallagher;R.B. Haber;G. Ferguson;D. Parker;D. Stillman;J. Winget,"Swanson Analysis Systems, Inc.;University of Illinois, USA;Visual Kinematics, Inc.;Centric, Inc.;Livermore Software Technology, Inc.;Silicon Graphics Computer Systems",0.1109/visual.1990.146390,,,3.0,12.0,63.0,,,finite elements display;3d gradient tensor;generation isovalues;techniques developed specific;general,0.6341;0.3864;0.2358;0.2111;0.0699,"[np.int64(-1), -1, -1, -1, -1]",-1;-1;-1;-1;-1,,-1
SciVis,2015,Visualizing Tensor Normal Distributions at Multiple Levels of Detail,10.1109/tvcg.2015.2467031,http://dx.doi.org/10.1109/TVCG.2015.2467031,975.0,984.0,J,"Despite the widely recognized importance of symmetric second order tensor fields in medicine and engineering, the visualization of data uncertainty in tensor fields is still in its infancy. A recently proposed tensorial normal distribution, involving a fourth order covariance tensor, provides a mathematical description of how different aspects of the tensor field, such as trace, anisotropy, or orientation, vary and covary at each point. However, this wealth of information is far too rich for a human analyst to take in at a single glance, and no suitable visualization tools are available. We propose a novel approach that facilitates visual analysis of tensor covariance at multiple levels of detail. We start with a visual abstraction that uses slice views and direct volume rendering to indicate large-scale changes in the covariance structure, and locations with high overall variance. We then provide tools for interactive exploration, making it possible to drill down into different types of variability, such as in shape or orientation. Finally, we allow the analyst to focus on specific locations of the field, and provide tensor glyph animations and overlays that intuitively depict confidence intervals at those points. Our system is demonstrated by investigating the effects of measurement noise on diffusion tensor MRI, and by analyzing two ensembles of stress tensor fields from solid mechanics.",Amin Abbasloo;Vitalis Wiens;Max Hermann;Thomas Schultz 0001,Amin Abbasloo;Vitalis Wiens;Max Hermann;Thomas Schultz,University of Bonn;University of Bonn;University of Bonn;University of Bonn,10.1109/tvcg.2009.170;10.1109/tvcg.2009.184;10.1109/visual.2005.1532773;10.1109/tvcg.2006.181;10.1109/tvcg.2006.134;10.1109/tvcg.2010.199;10.1109/tvcg.2008.128;10.1109/tvcg.2007.70602;10.1109/tvcg.2015.2467435;10.1109/tvcg.2009.170,"Uncertainty visualization, tensor visualization, direct volume rendering, interaction, glyph based visualization",31.0,18.0,60.0,785.0,,,visual analysis tensor;animations overlays intuitively;vary covary;despite widely recognized;confidence intervals,0.6222;0.2094;0.1798;0.0996;0.0710,"[np.int64(-1), -1, -1, -1, -1]",245;-1;-1;-1;-1,245,245
Vis,2023,Reclaiming the Horizon: Novel Visualization Designs for Time-Series Data with Large Value Ranges,10.1109/tvcg.2023.3326576,http://dx.doi.org/10.1109/TVCG.2023.3326576,1161.0,1171.0,J,"We introduce two novel visualization designs to support practitioners in performing identification and discrimination tasks on large value ranges (i.e., several orders of magnitude) in time-series data: (1) The order of magnitude horizon graph, which extends the classic horizon graph; and (2) the order of magnitude line chart, which adapts the log-line chart. These new visualization designs visualize large value ranges by explicitly splitting the mantissa $m$ and exponent $e$ of a value $v=m\cdot 10^{e}$. We evaluate our novel designs against the most relevant state-of-the-art visualizations in an empirical user study. It focuses on four main tasks commonly employed in the analysis of time-series and large value ranges visualization: identification, discrimination, estimation, and trend detection. For each task we analyze error, confidence, and response time. The new order of magnitude horizon graph performs better or equal to all other designs in identification, discrimination, and estimation tasks. Only for trend detection tasks, the more traditional horizon graphs reported better performance. Our results are domain-independent, only requiring time-series data with large value ranges.",Daniel Braun 0010;Rita Borgo;Max Sondag;Tatiana von Landesberger,Daniel Braun;Rita Borgo;Max Sondag;Tatiana von Landesberger,"University of Cologne, Germany;King's College London, USA;University of Cologne, Germany;University of Cologne, Germany",0.1109/infvis.2005.1532136;10.1109/tvcg.2014.2346428;10.1109/tvcg.2013.234;10.1109/tvcg.2013.124;10.1109/tvcg.2018.2865077;10.1109/infvis.2000.885098;10.1109/tvcg.2010.162;10.1109/infvis.2005.1532144;10.1109/tvcg.2012.253,"Visualization techniques,time-series,design study,orders of magnitude,logarithmic scale",,2.0,47.0,496.0,,,ranges visualization identification;series large value;adapts log;better equal;independent requiring time,0.6204;0.2129;0.1456;0.0822;0.0559,"[np.int64(-1), -1, -1, -1, -1]",-1;-1;-1;-1;-1,,-1
Vis,2005,The value of visualization,10.1109/visual.2005.1532781,http://dx.doi.org/10.1109/VISUAL.2005.1532781,79.0,86.0,C,"The field of visualization is getting mature. Many problems have been solved, and new directions are sought for. In order to make good choices, an understanding of the purpose and meaning of visualization is needed. Especially, it would be nice if we could assess what a good visualization is. In this paper an attempt is made to determine the value of visualization. A technological viewpoint is adopted, where the value of visualization is measured based on effectiveness and efficiency. An economic model of visualization is presented, and benefits and costs are established. Next, consequences (brand limitations of visualization are discussed (including the use of alternative methods, high initial costs, subjective/less, and the role of interaction), as well as examples of the use of the model for the judgement of existing classes of methods and understanding why they are or are not used in practice. Furthermore, two alternative views on visualization are presented and discussed: viewing visualization as an art or as a scientific discipline. Implications and future directions are identified.",Jarke J. van Wijk,J.J. van Wijk,"Department Mathematics and Computer Science, Technische Universiteit Eindhoven, Netherlands",10.1109/visual.1991.175815;10.1109/infvis.2004.70;10.1109/visual.2001.964505;10.1109/visual.2003.1250354;10.1109/infvis.2001.963285;10.1109/infvis.1999.801851;10.1109/visual.2004.76;10.1109/infvis.1999.801860;10.1109/visual.1991.175815,"Visualization, evaluation",397.0,81.0,30.0,5967.0,TT;BP,,visualization technological viewpoint;consequences brand;attempt determine value;including use alternative;especially nice,0.6930;0.1520;0.1033;0.0934;0.0414,"[np.int64(-1), -1, -1, -1, -1]",321;-1;-1;-1;-1,321,321
InfoVis,2011,Exploratory Analysis of Time-Series with ChronoLenses,10.1109/tvcg.2011.195,http://dx.doi.org/10.1109/TVCG.2011.195,2422.0,2431.0,J,"Visual representations of time-series are useful for tasks such as identifying trends, patterns and anomalies in the data. Many techniques have been devised to make these visual representations more scalable, enabling the simultaneous display of multiple variables, as well as the multi-scale display of time-series of very high resolution or that span long time periods. There has been comparatively little research on how to support the more elaborate tasks associated with the exploratory visual analysis of timeseries, e.g., visualizing derived values, identifying correlations, or discovering anomalies beyond obvious outliers. Such tasks typically require deriving new time-series from the original data, trying different functions and parameters in an iterative manner. We introduce a novel visualization technique called ChronoLenses, aimed at supporting users in such exploratory tasks. ChronoLenses perform on-the-fly transformation of the data points in their focus area, tightly integrating visual analysis with user actions, and enabling the progressive construction of advanced visual analysis pipelines.",Jian Zhao 0010;Fanny Chevalier;Emmanuel Pietriga;Ravin Balakrishnan,Jian Zhao;Fanny Chevalier;Emmanuel Pietriga;Ravin Balakrishnan,"DGP, University of Toronto, Canada;OCAD University, Canada;INRIA, France;DGP, University of Toronto, Canada",10.1109/tvcg.2010.162;10.1109/infvis.1999.801851;10.1109/vast.2007.4389007;10.1109/infvis.2001.963273;10.1109/infvis.2005.1532148;10.1109/tvcg.2007.70583;10.1109/tvcg.2010.193;10.1109/tvcg.2010.162,"Time-series Data, Exploratory Visualization, Focus+Context, Lens, Interaction Techniques",113.0,63.0,41.0,2118.0,,,visual analysis timeseries;outliers tasks typically;resolution span long;different;user actions enabling,0.7518;0.3121;0.1169;0.0517;0.0160,"[np.int64(-1), -1, -1, -1, -1]",163;-1;-1;-1;-1,163,163
Vis,2009,Sampling and Visualizing Creases with Scale-Space Particles,10.1109/tvcg.2009.177,http://dx.doi.org/10.1109/TVCG.2009.177,1415.0,1424.0,J,"Particle systems have gained importance as a methodology for sampling implicit surfaces and segmented objects to improve mesh generation and shape analysis. We propose that particle systems have a significantly more general role in sampling structure from unsegmented data. We describe a particle system that computes samplings of crease features (i.e. ridges and valleys, as lines or surfaces) that effectively represent many anatomical structures in scanned medical data. Because structure naturally exists at a range of sizes relative to the image resolution, computer vision has developed the theory of scale-space, which considers an n-D image as an (n + 1)-D stack of images at different blurring levels. Our scale-space particles move through continuous four-dimensional scale-space according to spatial constraints imposed by the crease features, a particle-image energy that draws particles towards scales of maximal feature strength, and an inter-particle energy that controls sampling density in space and scale. To make scale-space practical for large three-dimensional data, we present a spline-based interpolation across scale from a small number of pre-computed blurrings at optimally selected scales. The configuration of the particle system is visualized with tensor glyphs that display information about the local Hessian of the image, and the scale of the particle. We use scale-space particles to sample the complex three-dimensional branching structure of airways in lung CT, and the major white matter structures in brain DTI.",Gordon L. Kindlmann;Raúl San José Estépar;Stephen M. Smith 0001;Carl-Fredrik Westin,Gordon L. Kindlmann;Raúl San José Estepar;Stephen M. Smith;Carl-Fredrik Westin,"Department of Computer Science and the Computation Institute, University of Chicago, USA;Department of Radiology, Harvard Medical School, Brigham and Women's Hospital, USA;Centre for Functional MRI of the Brain, John Radcliffe Hospital, Oxford University, UK;Department of Radiology, Harvard Medical School, Brigham and Women's Hospital, USA",10.1109/tvcg.2008.154;10.1109/visual.1993.398880;10.1109/tvcg.2007.70604;10.1109/tvcg.2008.148;10.1109/visual.1997.663930;10.1109/tvcg.2008.167;10.1109/visual.1999.809896;10.1109/tvcg.2010.199;10.1109/tvcg.2008.154,"Particle Systems, Crease Features, Ridge and Valley Detection, Lung CT, Diffusion Tensor MRI",80.0,56.0,72.0,758.0,,,draws particles scales;imposed crease features;space considers image;information local hessian;medical,0.5892;0.2916;0.2841;0.1811;0.0729,"[np.int64(-1), -1, -1, -1, -1]",34;-1;-1;-1;-1,34,34
Vis,2024,"Visualization Atlases: Explaining and Exploring Complex Topics Through Data, Visualization, and Narration",10.1109/tvcg.2024.3456311,http://dx.doi.org/10.1109/TVCG.2024.3456311,437.0,447.0,J,"This paper defines, analyzes, and discusses the emerging genre of visualization atlases. We currently witness an increase in web-based, data-driven initiatives that call themselves “atlases” while explaining complex, contemporary issues through data and visualizations: climate change, sustainability, AI, or cultural discoveries. To understand this emerging genre and inform their design, study, and authoring support, we conducted a systematic analysis of 33 visualization atlases and semi-structured interviews with eight visualization atlas creators. Based on our results, we contribute (1) a definition of a visualization atlas as a compendium of (web) pages aimed at explaining and supporting exploration of data about a dedicated topic through data, visualizations and narration. (2) a set of design patterns of 8 design dimensions, (3) insights into the atlas creation from interviews and (4) the definition of 5 visualization atlas genres. We found that visualization atlases are unique in the way they combine i) exploratory visualization, ii) narrative elements from data-driven storytelling and iii) structured navigation mechanisms. They target a wide range of audiences with different levels of domain knowledge, acting as tools for study, communication, and discovery. We conclude with a discussion of current design practices and emerging questions around the ethics and potential real-world impact of visualization atlases, aimed to inform the design and study of visualization atlases.",Jinrui Wang;Xinhuan Shu;Benjamin Bach;Uta Hinrichs,Jinrui Wang;Xinhuan Shu;Benjamin Bach;Uta Hinrichs,"The University of Edinburgh, Scotland;Newcastle University, UK;The University of Edinburgh, Scotland;The University of Edinburgh, Scotland",10.1109/tvcg.2022.3209448;10.1109/tvcg.2023.3326917;10.1109/tvcg.2023.3327385;10.1109/tvcg.2022.3209436;10.1109/tvcg.2014.2346279;10.1109/tvcg.2010.179;10.1109/tvcg.2023.3327197;10.1109/tvcg.2020.3030396;10.1109/tvcg.2018.2864914;10.1109/tvcg.2007.70577;10.1109/tvcg.2021.3114849,"Visualization Atlases,Information Visualization,,,Data-driven Storytelling",,0.0,63.0,282.0,,,study visualization atlases;climate change;semi structured interviews;ethics potential real;witness increase web,0.7136;0.2576;0.1735;0.0844;0.0681,"[np.int64(-1), -1, -1, -1, -1]",267;-1;-1;-1;-1,267,267
Vis,2021,Rethinking the Ranks of Visual Channels,10.1109/tvcg.2021.3114684,http://dx.doi.org/10.1109/TVCG.2021.3114684,707.0,717.0,J,"Data can be visually represented using visual channels like position, length or luminance. An existing ranking of these visual channels is based on how accurately participants could report the ratio between two depicted values. There is an assumption that this ranking should hold for different tasks and for different numbers of marks. However, there is surprisingly little existing work that tests this assumption, especially given that visually computing ratios is relatively unimportant in real-world visualizations, compared to seeing, remembering, and comparing trends and motifs, across displays that almost universally depict more than two values. To simulate the information extracted from a glance at a visualization, we instead asked participants to immediately reproduce a set of values from memory after they were shown the visualization. These values could be shown in a bar graph (position (bar)), line graph (position (line)), heat map (luminance), bubble chart (area), misaligned bar graph (length), or ‘wind map’ (angle). With a Bayesian multilevel modeling approach, we show how the rank positions of visual channels shift across different numbers of marks (2, 4 or 8) and for bias, precision, and error measures. The ranking did not hold, even for reproductions of only 2 marks, and the new probabilistic ranking was highly inconsistent for reproductions of different numbers of marks. Other factors besides channel choice had an order of magnitude more influence on performance, such as the number of values in the series (e.g., more marks led to larger errors), or the value of each mark (e.g., small values were systematically overestimated). Every visual channel was worse for displays with 8 marks than 4, consistent with established limits on visual memory. These results point to the need for a body of empirical studies that move beyond two-value ratio judgments as a baseline for reliably ranking the quality of a visual channel, including testing new tasks (detection of trends or motifs), timescales (immediate computation, or later comparison), and the number of values (from a handful, to thousands).",Caitlyn M. McColeman;Fumeng Yang;Timothy F. Brady;Steven Franconeri,Caitlyn M. McColeman;Fumeng Yang;Timothy F. Brady;Steven Franconeri,"Northwestern University, USA;Brown University, USA;University of San Diego, USA;Northwestern University, USA",10.1109/infvis.2005.1532136;10.1109/tvcg.2015.2467732;10.1109/tvcg.2020.3030422;10.1109/tvcg.2010.132;10.1109/tvcg.2014.2346979;10.1109/tvcg.2019.2934786;10.1109/tvcg.2020.3030335;10.1109/tvcg.2015.2467671;10.1109/tvcg.2020.3030345;10.1109/tvcg.2018.2865240;10.1109/tvcg.2019.2934801;10.1109/tvcg.2018.2864884;10.1109/tvcg.2020.3030429;10.1109/tvcg.2015.2467758;10.1109/tvcg.2020.3030421;10.1109/tvcg.2018.2865264;10.1109/tvcg.2017.2744359;10.1109/tvcg.2014.2346320;10.1109/infvis.2005.1532136,"DataType Agnostic,Human-Subjects Quantitative Studies,Perception & Cognition,Charts, Diagrams, and Plots",10.0,17.0,87.0,1106.0,HM,,visualizations compared seeing;bayesian multilevel modeling;computing ratios relatively;set values memory;misaligned bar,0.5639;0.2915;0.2351;0.1658;0.1321,"[np.int64(-1), -1, -1, -1, -1]",208;-1;-1;-1;-1,208,208
VAST,2020,Visual Analysis of Argumentation in Essays,10.1109/tvcg.2020.3030425,http://dx.doi.org/10.1109/TVCG.2020.3030425,1139.0,1148.0,J,"This paper presents a visual analytics system for exploring, analyzing and comparing argument structures in essay corpora. We provide an overview of the corpus by a list of ArguLines which represent the argument units of each essay by a sequence of glyphs. Each glyph encodes the stance, the depth and the relative position of an argument unit. The overview can be ordered in various ways to reveal patterns and outliers. Subsets of essays can be selected and analyzed in detail using the Argument Unit Occurrence Tree which aggregates the argument structures using hierarchical histograms. This hierarchical view facilitates the estimation of statistics and trends concerning the progression of the argumentation in the essays. It also provides insights into the commonalities and differences between selected subsets. The text view is the necessary textual basis to verify conclusions from the other views and the annotation process. Linking the views and interaction techniques for visual filtering, studying the evolution of stance within a subset of essays and scrutinizing the order of argumentative units enable a deep analysis of essay corpora. Our expert reviews confirmed the utility of the system and revealed detailed and previously unknown information about the argumentation in our sample corpus.",Dora Kiesel;Patrick Riehmann;Henning Wachsmuth;Benno Stein 0001;Bernd Fröhlich 0001,Dora Kiesel;Patrick Riehmann;Henning Wachsmuth;Benno Stein;Bernd Froehlich,Bauhaus-Universität Weimar;Bauhaus-Universität Weimar;Paderborn University;Bauhaus-Universität Weimar;Bauhaus-Universität Weimar,10.1109/vast.2011.6102439;10.1109/tvcg.2017.2745278;10.1109/tvcg.2013.200;10.1109/tvcg.2012.226;10.1109/vast.2011.6102439,"Information Visualization,Text Analysis,User Interfaces,Visual Analytics,Argumentation Visualization,Glyph-based Techniques,Text and Document Data,Tree-based Visualization,Coordinated and Multiple Views,Close and Distant Reading",6.0,6.0,51.0,783.0,,,argumentation sample corpus;visual analytics;stance depth;glyph encodes;confirmed,0.6374;0.3919;0.1900;0.1122;-0.0599,"[np.int64(-1), np.int64(-1), -1, -1, -1]",115;201;-1;-1;-1,115;201,115
InfoVis,2011,A Study on Dual-Scale Data Charts,10.1109/tvcg.2011.160,http://dx.doi.org/10.1109/TVCG.2011.160,2469.0,2478.0,J,"We present the results of a user study that compares different ways of representing Dual-Scale data charts. Dual-Scale charts incorporate two different data resolutions into one chart in order to emphasize data in regions of interest or to enable the comparison of data from distant regions. While some design guidelines exist for these types of charts, there is currently little empirical evidence on which to base their design. We fill this gap by discussing the design space of Dual-Scale cartesian-coordinate charts and by experimentally comparing the performance of different chart types with respect to elementary graphical perception tasks such as comparing lengths and distances. Our study suggests that cut-out charts which include collocated full context and focus are the best alternative, and that superimposed charts in which focus and context overlap on top of each other should be avoided.",Petra Isenberg;Anastasia Bezerianos;Pierre Dragicevic;Jean-Daniel Fekete,Petra Isenberg;Anastasia Bezerianos;Pierre Dragicevic;Jean-Daniel Fekete,"INRIA, France;École Centrale Paris (SAP BusinessObjects) and LRI, University Paris-Sud & CNRS) & INRIA, France;INRIA, France;INRIA, France",10.1109/infvis.1998.729558;10.1109/tvcg.2009.174;10.1109/tvcg.2007.70577;10.1109/infvis.1998.729558,"Focus+Context, Quantitative Experiment, Dual-Scale Charts",52.0,29.0,36.0,785.0,,,dual scale charts;overlap avoided;collocated context focus;guidelines exist types;results user,0.6640;0.2119;0.1521;0.0582;0.0033,"[np.int64(-1), -1, -1, -1, -1]",113;-1;-1;-1;-1,113,113
VAST,2020,STULL: Unbiased Online Sampling for Visual Exploration of Large Spatiotemporal Data,10.1109/vast50239.2020.00012,http://dx.doi.org/10.1109/VAST50239.2020.00012,72.0,83.0,C,"Online sampling-supported visual analytics is increasingly important, as it allows users to explore large datasets with acceptable approximate answers at interactive rates. However, existing online spatiotemporal sampling techniques are often biased, as most researchers have primarily focused on reducing computational latency. Biased sampling approaches select data with unequal probabilities and produce results that do not match the exact data distribution, leading end users to incorrect interpretations. In this paper, we propose a novel approach to perform unbiased online sampling of large spatiotemporal data. The proposed approach ensures the same probability of selection to every point that qualifies the specifications of a user’s multidimensional query. To achieve unbiased sampling for accurate representative interactive visualizations, we design a novel data index and an associated sample retrieval plan. Our proposed sampling approach is suitable for a wide variety of visual analytics tasks, e.g., tasks that run aggregate queries of spatiotemporal data. Extensive experiments confirm the superiority of our approach over a state-of-the-art spatial online sampling technique, demonstrating that within the same computational time, data samples generated in our approach are at least 50% more accurate in representing the actual spatial distribution of the data and enable approximate visualizations to present closer visual appearances to the exact ones.",Guizhen Wang;Jingjing Guo;Mingjie Tang;José Florencio de Queiroz Neto;Calvin Yau;Anas Daghistani;Morteza Karimzadeh;Walid G. Aref;David S. Ebert,Guizhen Wang;Jingjing Guo;Mingjie Tang;José Florencio de Queiroz Neto;Calvin Yau;Anas Daghistani;Morteza Karimzadeh;Walid G. Aref;David S. Ebert,Purdue University;Purdue University;Chinese Academy of Science;Federal University of Ceara;Purdue University;Umm Al-Qura University;University of Colorado Boulder;Purdue University;University of Oklahoma,10.1109/vast.2012.6400557;10.1109/vast.2008.4677357;10.1109/tvcg.2014.2346594;10.1109/tvcg.2019.2934541;10.1109/tvcg.2019.2934799;10.1109/tvcg.2013.179;10.1109/tvcg.2019.2934434;10.1109/tvcg.2014.2346452;10.1109/tvcg.2014.2346926;10.1109/tvcg.2016.2598624;10.1109/tvcg.2019.2934208;10.1109/tvcg.2016.2598867;10.1109/vast.2012.6400557,"Geospatial data,large-scale data techniques,data management,visual analytics",5.0,4.0,67.0,333.0,,,representative interactive visualizations;latency biased sampling;run aggregate;time;data enable,0.6329;0.3596;0.1871;0.1121;0.0917,"[np.int64(-1), -1, -1, -1, -1]",194;-1;-1;-1;-1,194,194
VAST,2013,UTOPIAN: User-Driven Topic Modeling Based on Interactive Nonnegative Matrix Factorization,10.1109/tvcg.2013.212,http://dx.doi.org/10.1109/TVCG.2013.212,1992.0,2001.0,J,"Topic modeling has been widely used for analyzing text document collections. Recently, there have been significant advancements in various topic modeling techniques, particularly in the form of probabilistic graphical modeling. State-of-the-art techniques such as Latent Dirichlet Allocation (LDA) have been successfully applied in visual text analytics. However, most of the widely-used methods based on probabilistic modeling have drawbacks in terms of consistency from multiple runs and empirical convergence. Furthermore, due to the complicatedness in the formulation and the algorithm, LDA cannot easily incorporate various types of user feedback. To tackle this problem, we propose a reliable and flexible visual analytics system for topic modeling called UTOPIAN (User-driven Topic modeling based on Interactive Nonnegative Matrix Factorization). Centered around its semi-supervised formulation, UTOPIAN enables users to interact with the topic modeling method and steer the result in a user-driven manner. We demonstrate the capability of UTOPIAN via several usage scenarios with real-world document corpuses such as InfoVis/VAST paper data set and product review data sets.",Jaegul Choo;Changhyun Lee;Chandan K. Reddy;Haesun Park,Jaegul Choo;Changhyun Lee;Chandan K. Reddy;Haesun Park,"Georgia Institute of Technology, USA;Georgia Institute of Technology, USA;Georgia Institute of Technology, USA;Georgia Institute of Technology, USA",10.1109/tvcg.2012.258;10.1109/vast.2009.5332629;10.1109/tvcg.2011.239;10.1109/vast.2011.6102461;10.1109/vast.2012.6400485;10.1109/vast.2007.4388999;10.1109/vast.2007.4389006;10.1109/tvcg.2008.138;10.1109/vast.2010.5652443;10.1109/tvcg.2012.258,"Latent Dirichlet allocation, nonnegative matrix factorization, topic modeling, visual analytics, interactive clustering, text analytics",317.0,188.0,36.0,3118.0,,,topic modeling;interactive nonnegative matrix;review data sets;successfully applied visual;particularly,0.6754;0.2643;0.2365;0.1236;0.0396,"[np.int64(-1), -1, -1, -1, -1]",46;-1;-1;-1;-1,46,46
SciVis,2013,Colon Flattening Using Heat Diffusion Riemannian Metric,10.1109/tvcg.2013.139,http://dx.doi.org/10.1109/TVCG.2013.139,2848.0,2857.0,J,"We propose a new colon flattening algorithm that is efficient, shape-preserving, and robust to topological noise. Unlike previous approaches, which require a mandatory topological denoising to remove fake handles, our algorithm directly flattens the colon surface without any denoising. In our method, we replace the original Euclidean metric of the colon surface with a heat diffusion metric that is insensitive to topological noise. Using this heat diffusion metric, we then solve a Laplacian equation followed by an integration step to compute the final flattening. We demonstrate that our method is shape-preserving and the shape of the polyps are well preserved. The flattened colon also provides an efficient way to enhance the navigation and inspection in virtual colonoscopy. We further show how the existing colon registration pipeline is made more robust by using our colon flattening. We have tested our method on several colon wall surfaces and the experimental results demonstrate the robustness and the efficiency of our method.",Krishna Chaitanya Gurijala;Rui Shi;Wei Zeng 0002;Xianfeng Gu;Arie E. Kaufman,Krishna Chaitanya Gurijala;Rui Shi;Wei Zeng;Xianfeng Gu;Arie Kaufman,"Stony Brook University, USA;Stony Brook University, USA;Florida International University, USA;Stony Brook University, USA;Stony Brook University, USA",10.1109/visual.2001.964540;10.1109/tvcg.2006.112;10.1109/visual.2001.964540;10.1109/tvcg.2010.200,"Colon flattening, heat diffusion, virtual colonoscopy, volume rendering, topological noise, shape-preserving mapping",18.0,16.0,46.0,410.0,,,colon surface denoising;preserving shape polyps;fake handles algorithm;original euclidean metric;heat,0.6739;0.4188;0.2574;0.1524;-0.0140,"[np.int64(-1), -1, -1, -1, -1]",247;-1;-1;-1;-1,247,247
Vis,2021,Gender in 30 Years of IEEE Visualization,10.1109/tvcg.2021.3114787,http://dx.doi.org/10.1109/TVCG.2021.3114787,497.0,507.0,J,"We present an exploratory analysis of gender representation among the authors, committee members, and award winners at the IEEE Visualization (VIS) conference over the last 30 years. Our goal is to provide descriptive data on which diversity discussions and efforts in the community can build. We look in particular at the gender of VIS authors as a proxy for the community at large. We consider measures of overall gender representation among authors, differences in careers, positions in author lists, and collaborations. We found that the proportion of female authors has increased from 9% in the first five years to 22% in the last five years of the conference. Over the years, we found the same representation of women in program committees and slightly more women in organizing committees. Women are less likely to appear in the last author position, but more in the middle positions. In terms of collaboration patterns, female authors tend to collaborate more than expected with other women in the community. All non-gender related data is available on https://osf.io/ydfj4/ and the gender-author matching can be accessed through https://nyu.databrary.org/volume/1301.",Natkamon Tovanich;Pierre Dragicevic;Petra Isenberg,Natkamon Tovanich;Pierre Dragicevic;Petra Isenberg,"IRT SystemX, Paris-Saclay, Palaiseau, France and Université Paris-Saclay, CNRS, Inria, LISN, Orsay, France;Université Paris-Saclay, CNRS, Inria, LISN, Orsay, France;Université Paris-Saclay, CNRS, Inria, LISN, Orsay, France",,"visualization,gender,diversity,publication,scientometry,collaboration",5.0,10.0,49.0,718.0,,,gender representation authors;visualization vis conference;differences careers;increased years;matching accessed https,0.6438;0.4969;0.2598;0.0926;-0.0172,"[np.int64(-1), -1, -1, -1, -1]",114;-1;-1;-1;-1,114,114
VAST,2016,ViDX: Visual Diagnostics of Assembly Line Performance in Smart Factories,10.1109/tvcg.2016.2598664,http://dx.doi.org/10.1109/TVCG.2016.2598664,291.0,300.0,J,"Visual analytics plays a key role in the era of connected industry (or industry 4.0, industrial internet) as modern machines and assembly lines generate large amounts of data and effective visual exploration techniques are needed for troubleshooting, process optimization, and decision making. However, developing effective visual analytics solutions for this application domain is a challenging task due to the sheer volume and the complexity of the data collected in the manufacturing processes. We report the design and implementation of a comprehensive visual analytics system, ViDX. It supports both real-time tracking of assembly line performance and historical data exploration to identify inefficiencies, locate anomalies, and form hypotheses about their causes and effects. The system is designed based on a set of requirements gathered through discussions with the managers and operators from manufacturing sites. It features interlinked views displaying data at different levels of detail. In particular, we apply and extend the Marey's graph by introducing a time-aware outlier-preserving visual aggregation technique to support effective troubleshooting in manufacturing processes. We also introduce two novel interaction techniques, namely the quantiles brush and samples brush, for the users to interactively steer the outlier detection algorithms. We evaluate the system with example use cases and an in-depth user interview, both conducted together with the managers and operators from manufacturing plants. The result demonstrates its effectiveness and reports a successful pilot application of visual analytics for manufacturing in smart factories.",Panpan Xu;Honghui Mei;Liu Ren;Wei Chen 0001,Panpan Xu;Honghui Mei;Liu Ren;Wei Chen,Bosch Research North America;Zhejiang University;Bosch Research North America;Zhejiang University,10.1109/tvcg.2014.2346454;10.1109/tvcg.2015.2467592;10.1109/tvcg.2006.170;10.1109/tvcg.2015.2467622;10.1109/tvcg.2014.2346682;10.1109/tvcg.2012.225;10.1109/tvcg.2013.200;10.1109/infvis.2002.1173149;10.1109/tvcg.2011.185;10.1109/tvcg.2014.2346454,Temporal Data;Marey's Graph;Visual Analytics;Manufacturing;Smart Factory;Connected Industry;Industry 4.0,119.0,93.0,36.0,3547.0,HM,,visual analytics manufacturing;time aware outlier;brush users;vidx supports;interlinked,0.7275;0.3122;0.1254;0.1198;0.1183,"[np.int64(-1), -1, -1, -1, -1]",201;-1;-1;-1;-1,201,201
VAST,2012,An adaptive parameter space-filling algorithm for highly interactive cluster exploration,10.1109/vast.2012.6400493,http://dx.doi.org/10.1109/VAST.2012.6400493,13.0,22.0,C,"For a user to perceive continuous interactive response time in a visualization tool, the rule of thumb is that it must process, deliver, and display rendered results for any given interaction in under 100 milliseconds. In many visualization systems, successive interactions trigger independent queries and caching of results. Consequently, computationally expensive queries like multidimensional clustering cannot keep up with rapid sequences of interactions, precluding visual benefits such as motion parallax. In this paper, we describe a heuristic prefetching technique to improve the interactive response time of KMeans clustering in dynamic query visualizations of multidimensional data. We address the tradeoff between high interaction and intense query computation by observing how related interactions on overlapping data subsets produce similar clustering results, and characterizing these similarities within a parameter space of interaction. We focus on the two-dimensional parameter space defined by the minimum and maximum values of a time range manipulated by dragging and stretching a one-dimensional filtering lens over a plot of time series data. Using calculation of nearest neighbors of interaction points in parameter space, we reuse partial query results from prior interaction sequences to calculate both an immediate best-effort clustering result and to schedule calculation of an exact result. The method adapts to user interaction patterns in the parameter space by reprioritizing the interaction neighbors of visited points in the parameter space. A performance study on Mesonet meteorological data demonstrates that the method is a significant improvement over the baseline scheme in which interaction triggers on-demand, exact-range clustering with LRU caching. We also present initial evidence that approximate, temporary clustering results are sufficiently accurate (compared to exact results) to convey useful cluster structure during rapid and protracted interaction.",Zafar Ahmed;Chris E. Weaver,Zafar Ahmed;Chris Weaver,School of Computer Science and Center for Spatial Analysis The University of Oklahoma;School of Computer Science and Center for Spatial Analysis The University of Oklahoma,10.1109/tvcg.2007.70515;10.1109/infvis.2004.12;10.1109/vast.2009.5332629;10.1109/vast.2008.4677357;10.1109/tvcg.2011.188;10.1109/visual.1994.346302;10.1109/infvis.1998.729559;10.1109/vast.2007.4388999;10.1109/tvcg.2007.70515,,13.0,7.0,31.0,496.0,,,query visualizations multidimensional;temporary clustering results;interaction 100 milliseconds;meteorological;dragging stretching,0.5939;0.4006;0.2355;0.2187;0.1821,"[np.int64(-1), -1, -1, -1, -1]",181;-1;-1;-1;-1,181,181
InfoVis,2003,Thread Arcs: an email thread visualization,10.1109/infvis.2003.1249028,http://dx.doi.org/10.1109/INFVIS.2003.1249028,211.0,218.0,C,"This paper describes Thread Arcs, a novel interactive visualization technique designed to help people use threads found in email. Thread Arcs combine the chronology of messages with the branching tree structure of a conversational thread in a mixed-model visualization by Venolia and Neustaedter (2003) that is stable and compact. By quickly scanning and interacting with Thread Arcs, people can see various attributes of conversations and find relevant messages in them easily. We tested this technique against other visualization techniques with users' own email in a functional prototype email client. Thread Arcs proved an excellent match for the types of threads found in users' email for the qualities users wanted in small-scale visualizations.",Bernard Kerr,B. Kerr,"Collaborative User Experience Group, IBM Research, USA",10.1109/infvis.2002.1173155;10.1109/infvis.2001.963290;10.1109/infvis.2002.1173155,"conversations, discussions, electronic mail, email, information visualization, threads, tree structures, user interfaces",243.0,35.0,11.0,933.0,,,email thread arcs;novel interactive visualization;combine chronology;use;stable compact,0.6429;0.4537;0.2001;0.1707;0.0209,"[np.int64(-1), -1, -1, -1, -1]",233;-1;-1;-1;-1,233,233
SciVis,2017,Visualization Multi-Pipeline for Communicating Biology,10.1109/tvcg.2017.2744518,http://dx.doi.org/10.1109/TVCG.2017.2744518,883.0,892.0,J,"We propose a system to facilitate biology communication by developing a pipeline to support the instructional visualization of heterogeneous biological data on heterogeneous user-devices. Discoveries and concepts in biology are typically summarized with illustrations assembled manually from the interpretation and application of heterogenous data. The creation of such illustrations is time consuming, which makes it incompatible with frequent updates to the measured data as new discoveries are made. Illustrations are typically non-interactive, and when an illustration is updated, it still has to reach the user. Our system is designed to overcome these three obstacles. It supports the integration of heterogeneous datasets, reflecting the knowledge that is gained from different data sources in biology. After pre-processing the datasets, the system transforms them into visual representations as inspired by scientific illustrations. As opposed to traditional scientific illustration these representations are generated in real-time - they are interactive. The code generating the visualizations can be embedded in various software environments. To demonstrate this, we implemented both a desktop application and a remote-rendering server in which the pipeline is embedded. The remote-rendering server supports multi-threaded rendering and it is able to handle multiple users simultaneously. This scalability to different hardware environments, including multi-GPU setups, makes our system useful for efficient public dissemination of biological discoveries.",Peter Mindek;David Kouril;Johannes Sorger;Daniel Toloudis;Blair Lyons;Graham Johnson;M. Eduard Gröller;Ivan Viola,Peter Mindek;David Kouřil;Johannes Sorger;Daniel Toloudis;Blair Lyons;Graham Johnson;M. Eduard Gröller;Ivan Viola,TU Wien;TU Wien;TU Wien;Allen Institute for Cell Science;Allen Institute for Cell Science;Allen Institute for Cell Science;VRVis Research Center and TU Wien;TU Wien,10.1109/visual.2005.1532856;10.1109/visual.2000.885729;10.1109/scivis.2015.7429514,"Biological visualization,remote rendering,public dissemination",24.0,16.0,33.0,805.0,,,visualization heterogeneous biological;remote rendering;server pipeline embedded;reflecting knowledge gained;desktop,0.6884;0.4289;0.1877;0.1702;0.1664,"[np.int64(-1), -1, -1, -1, -1]",310;-1;-1;-1;-1,310,310
Vis,2024,Discursive Patinas: Anchoring Discussions in Data Visualizations,10.1109/tvcg.2024.3456334,http://dx.doi.org/10.1109/TVCG.2024.3456334,1246.0,1256.0,J,"This paper presents discursive patinas, a technique to visualize discussions onto data visualizations, inspired by how people leave traces in the physical world. While data visualizations are widely discussed in online communities and social media, comments tend to be displayed separately from the visualization and we lack ways to relate these discussions back to the content of the visualization, e.g., to situate comments, explain visual patterns, or question assumptions. In our visualization annotation interface, users can designate areas within the visualization. Discursive patinas are made of overlaid visual marks (anchors), attached to textual comments with category labels, likes, and replies. By coloring and styling the anchors, a meta visualization emerges, showing what and where people comment and annotate the visualization. These patinas show regions of heavy discussions, recent commenting activity, and the distribution of questions, suggestions, or personal stories. We ran workshops with 90 students, domain experts, and visualization researchers to study how people use anchors to discuss visualizations and how patinas influence people's understanding of the discussion. Our results show that discursive patinas improve the ability to navigate discussions and guide people to comments that help understand, contextualize, or scrutinize the visualization. We discuss the potential of anchors and patinas to support discursive engagements, including critical readings of visualizations, design feedback, and feminist approaches to data visualization.",Tobias Kauer;Derya Akbaba;Marian Dörk;Benjamin Bach,Tobias Kauer;Derya Akbaba;Marian Dörk;Benjamin Bach,"University of Edinburgh (UK) and the Potsdam University of Applied Sciences (DE), U.K.;Linköping University (SE), Sweden;Potsdam University of Applied Sciences (DE), U.K.;Inria (FR) and the University of Edinburgh (UK), U.K.",10.1109/tvcg.2014.2346984;10.1109/tvcg.2016.2599058;10.1109/tvcg.2023.3326917;10.1109/tvcg.2016.2598920;10.1109/tvcg.2022.3209451;10.1109/tvcg.2018.2864913;10.1109/tvcg.2007.70541;10.1109/tvcg.2007.70577;10.1109/tvcg.2007.70589;10.1109/tvcg.2022.3209405;10.1109/tvcg.2023.3327356,"Data Visualization,Discussion,,,Annotation",,0.0,51.0,194.0,,,discussions data visualizations;anchors attached textual;people leave traces;feminist;patinas technique,0.7272;0.2516;0.2020;0.1887;0.1804,"[np.int64(-1), -1, -1, -1, -1]",265;-1;-1;-1;-1,265,265
Vis,1999,Interactive exploration of volume line integral convolution based on 3D-texture mapping,10.1109/visual.1999.809892,http://dx.doi.org/10.1109/VISUAL.1999.809892,233.0,528.0,C,"Line integral convolution (LIC) is an effective technique for visualizing vector fields. The application of LIC to 3D flow fields has yet been limited by difficulties to efficiently display and animate the resulting 3D-images. Texture-based volume rendering allows interactive visualization and manipulation of 3D-LIC textures. In order to ensure the comprehensive and convenient exploration of flow fields, we suggest interactive functionality including transfer functions and different clipping mechanisms. Thereby, we efficiently substitute the calculation of LIC based on sparse noise textures and show the convenient visual access of interior structures. Further on, we introduce two approaches for animating static 3D-flow fields without the computational expense and the immense memory requirements for pre-computed 3D-textures and without loss of interactivity. This is achieved by using a single 3D-LIC texture and a set of time surfaces as clipping geometries. In our first approach we use the clipping geometry to pre-compute a special 3D-LIC texture that can be animated by time-dependent color tables. Our second approach uses time volumes to actually clip the 3D-LIC volume interactively during rasterization. Additionally, several examples demonstrate the value of our strategy in practice.",Christof Rezk-Salama;Peter Hastreiter;Christian Teitzel;Thomas Ertl,C. Rezk-Salama;P. Hastreiter;C. Teitzel;T. Ertl,"Computer Graphics Group, University of Erlangen Nuremberg, Germany;Computer Graphics Group, University of Erlangen Nuremberg, Germany;Computer Graphics Group, University of Erlangen Nuremberg, Germany;Computer Graphics Group, University of Erlangen Nuremberg, Germany",10.1109/visual.1993.398877;10.1109/visual.1993.398846;10.1109/visual.1995.485141;10.1109/visual.1994.346313;10.1109/visual.1994.346314;10.1109/visual.1990.146391;10.1109/visual.1997.663898;10.1109/visual.1997.663897;10.1109/visual.1997.663899;10.1109/visual.1993.398877,"Flow Visualization, Animated LIC, Direct Volume Rendering, 3D-Textures Mapping, Interactive Volume Exploration",155.0,39.0,35.0,185.0,,,3d flow fields;texture set time;interactive functionality including;lic effective;substitute calculation,0.6892;0.1808;0.1609;0.0751;-0.0325,"[np.int64(-1), -1, -1, -1, -1]",40;-1;-1;-1;-1,40,40
VAST,2015,SensePath: Understanding the Sensemaking Process Through Analytic Provenance,10.1109/tvcg.2015.2467611,http://dx.doi.org/10.1109/TVCG.2015.2467611,41.0,50.0,J,"Sensemaking is described as the process of comprehension, finding meaning and gaining insight from information, producing new knowledge and informing further action. Understanding the sensemaking process allows building effective visual analytics tools to make sense of large and complex datasets. Currently, it is often a manual and time-consuming undertaking to comprehend this: researchers collect observation data, transcribe screen capture videos and think-aloud recordings, identify recurring patterns, and eventually abstract the sensemaking process into a general model. In this paper, we propose a general approach to facilitate such a qualitative analysis process, and introduce a prototype, SensePath, to demonstrate the application of this approach with a focus on browser-based online sensemaking. The approach is based on a study of a number of qualitative research sessions including observations of users performing sensemaking tasks and post hoc analyses to uncover their sensemaking processes. Based on the study results and a follow-up participatory design session with HCI researchers, we decided to focus on the transcription and coding stages of thematic analysis. SensePath automatically captures user's sensemaking actions, i.e., analytic provenance, and provides multi-linked views to support their further analysis. A number of other requirements elicited from the design session are also implemented in SensePath, such as easy integration with existing qualitative analysis workflow and non-intrusive for participants. The tool was used by an experienced HCI researcher to analyze two sensemaking sessions. The researcher found the tool intuitive and considerably reduced analysis time, allowing better understanding of the sensemaking process.",Phong Hai Nguyen;Kai Xu 0003;Ashley Wheat;B. L. William Wong;Simon Attfield;Bob Fields,Phong H. Nguyen;Kai Xu;Ashley Wheat;B.L. William Wong;Simon Attfield;Bob Fields,Middlesex University;Middlesex University;Middlesex University;Middlesex University;Middlesex University;Middlesex University,10.1109/visual.2005.1532788;10.1109/tvcg.2011.185;10.1109/tvcg.2014.2346575;10.1109/vast.2008.4677365;10.1109/tvcg.2008.137;10.1109/vast.2009.5333020;10.1109/tvcg.2013.132,"Sensemaking, analytic provenance, transcription, coding, qualitative research, timeline visualization",,29.0,42.0,1425.0,,,user sensemaking;hci;aloud recordings;study results;focus browser based,0.7342;0.2422;0.1679;0.1167;0.0293,"[np.int64(-1), -1, -1, -1, -1]",86;-1;-1;-1;-1,86,86
VAST,2020,Visilant: Visual Support for the Exploration and Analytical Process Tracking in Criminal Investigations,10.1109/tvcg.2020.3030356,http://dx.doi.org/10.1109/TVCG.2020.3030356,881.0,890.0,J,"The daily routine of criminal investigators consists of a thorough analysis of highly complex and heterogeneous data of crime cases. Such data can consist of case descriptions, testimonies, criminal networks, spatial and temporal information, and virtually any other data that is relevant for the case. Criminal investigators work under heavy time pressure to analyze the data for relationships, propose and verify several hypotheses, and derive conclusions, while the data can be incomplete or inconsistent and is changed and updated throughout the investigation, as new findings are added to the case. Based on a four-year intense collaboration with criminalists, we present a conceptual design for a visual tool supporting the investigation workflow and Visilant, a web-based tool for the exploration and analysis of criminal data guided by the proposed design. Visilant aims to support namely the exploratory part of the investigation pipeline, from case overview, through exploration and hypothesis generation, to the case presentation. Visilant tracks the reasoning process and as the data is changing, it informs investigators which hypotheses are affected by the data change and should be revised. The tool was evaluated by senior criminology experts within two sessions and their feedback is summarized in the paper. Additional supplementary material contains the technical details and exemplary case study.",Kristína Zákopcanová;Marko Rehácek;Jozef Bátrna;Daniel Plakinger;Sergej Stoppel;Barbora Kozlíková,Kristína Zákopčanová;Marko Řeháček;Jozef Bátrna;Daniel Plakinger;Sergej Stoppel;Barbora Kozlíková,Masaryk University;Masaryk University;Masaryk University;Masaryk University;University of Bergen and Rainfall AS Bergen;Masaryk University,10.1109/tvcg.2013.223;10.1109/tvcg.2008.137;10.1109/infvis.2004.2;10.1109/tvcg.2014.2346573;10.1109/tvcg.2019.2934539;10.1109/tvcg.2018.2865149;10.1109/tvcg.2015.2467551;10.1109/tvcg.2012.255;10.1109/tvcg.2018.2865024;10.1109/tvcg.2014.2346441;10.1109/tvcg.2013.223,"Criminal investigation,visualization,network,exploration,interaction,tracking,diagram",4.0,2.0,43.0,709.0,,,criminal data guided;workflow visilant web;verify hypotheses;virtually;added,0.6420;0.3551;0.2374;0.0418;-0.0128,"[np.int64(-1), -1, -1, -1, -1]",125;-1;-1;-1;-1,125,125
Vis,1999,Tensorlines: Advection-Diffusion based Propagation through Diffusion Tensor Fields,10.1109/visual.1999.809894,http://dx.doi.org/10.1109/VISUAL.1999.809894,249.0,253.0,C,"Tracking linear features through tensor field datasets is an open research problem with widespread utility in medical and engineering disciplines. Existing tracking methods, which consider only the preferred local diffusion direction as they propagate, fail to accurately follow features as they enter regions of local complexity. This shortcoming is a result of partial voluming; that is, voxels in these regions often contain contributions from multiple features. These combined contributions result in ambiguities when deciding local primary feature orientation based solely on the preferred diffusion direction. We introduce a novel feature extraction method which we term tensorline propagation. Our method resolves the above ambiguity by incorporating information about the nearby orientation of the feature, as well as the anisotropic classification of the local tensor. The nearby orientation information is added in the spirit of an advection term in a standard diffusion based propagation technique, and has the effect of stabilizing the tracking. To demonstrate the efficacy of tensorlines, we apply this method to the neuroscience problem of tracking white-matter bundles within the brain.",David M. Weinstein;Gordon L. Kindlmann;Eric C. Lundberg,D. Weinstein;G. Kindlmann;E. Lundberg,"University of Utah, Salt Lake City, UT, US;University of Utah, Salt Lake City, UT, US;University of Utah, Salt Lake City, UT, US",10.1109/visual.1993.398849;10.1109/visual.1991.175789;10.1109/visual.1992.235193;10.1109/visual.1995.485141;10.1109/visual.1998.745294;10.1109/visual.1999.809886,,370.0,100.0,0.0,158.0,,,tensorline propagation;voxels regions contain;disciplines existing tracking;spirit advection term;solely,0.6184;0.2270;0.1684;0.1051;0.0231,"[np.int64(-1), -1, -1, -1, -1]",17;-1;-1;-1;-1,17,17
Vis,2011,FoamVis: Visualization of 2D Foam Simulation Data,10.1109/tvcg.2011.204,http://dx.doi.org/10.1109/TVCG.2011.204,2096.0,2105.0,J,"Research in the field of complex fluids such as polymer solutions, particulate suspensions and foams studies how the flow of fluids with different material parameters changes as a result of various constraints. Surface Evolver, the standard solver software used to generate foam simulations, provides large, complex, time-dependent data sets with hundreds or thousands of individual bubbles and thousands of time steps. However this software has limited visualization capabilities, and no foam specific visualization software exists. We describe the foam research application area where, we believe, visualization has an important role to play. We present a novel application that provides various techniques for visualization, exploration and analysis of time-dependent 2D foam simulation data. We show new features in foam simulation data and new insights into foam behavior discovered using our application.",Dan R. Lipsa;Robert S. Laramee;Simon J. Cox 0002;Tudur Davies,Dan Lipsa;Robert Laramee;Simon Cox;Tudur Davies,"Swansea University, UK;Swansea University, UK;Aberystwyth University, UK;Aberystwyth University, UK",10.1109/tvcg.2008.147;10.1109/tvcg.2008.139;10.1109/tvcg.2008.147,"Surface Evolver, bubble-scale simulation, time-dependent visualizations",10.0,6.0,31.0,634.0,,,foam specific visualization;software used generate;dependent data sets;suspensions;large complex time,0.7677;0.1257;0.0990;0.0720;0.0596,"[np.int64(-1), -1, -1, -1, -1]",295;-1;-1;-1;-1,295,295
Vis,2023,Heuristics for Supporting Cooperative Dashboard Design,10.1109/tvcg.2023.3327158,http://dx.doi.org/10.1109/TVCG.2023.3327158,370.0,380.0,J,"Dashboards are no longer mere static displays of metrics; through functionality such as interaction and storytelling, they have evolved to support analytic and communicative goals like monitoring and reporting. Existing dashboard design guidelines, however, are often unable to account for this expanded scope as they largely focus on best practices for visual design. In contrast, we frame dashboard design as facilitating an analytical conversation: a cooperative, interactive experience where a user may interact with, reason about, or freely query the underlying data. By drawing on established principles of conversational flow and communication, we define the concept of a cooperative dashboard as one that enables a fruitful and productive analytical conversation, and derive a set of 39 dashboard design heuristics to support effective analytical conversations. To assess the utility of this framing, we asked 52 computer science and engineering graduate students to apply our heuristics to critique and design dashboards as part of an ungraded, opt-in homework assignment. Feedback from participants demonstrates that our heuristics surface new reasons dashboards may fail, and encourage a more fluid, supportive, and responsive style of dashboard design. Our approach suggests several compelling directions for future work, including dashboard authoring tools that better anticipate conversational turn-taking, repair, and refinement and extending cooperative principles to other analytical workflows.",Vidya Setlur;Michael Correll;Arvind Satyanarayan;Melanie Tory,Vidya Setlur;Michael Correll;Arvind Satyanarayan;Melanie Tory,"Tableau Research, USA;Tableau Research, USA;MIT CSAIL, USA;Northeastern University, USA",0.1109/tvcg.2022.3209448;10.1109/tvcg.2021.3114760;10.1109/tvcg.2020.3030338;10.1109/tvcg.2019.2934283;10.1109/tvcg.2016.2599058;10.1109/tvcg.2017.2744684;10.1109/tvcg.2017.2745240;10.1109/tvcg.2021.3114860;10.1109/tvcg.2017.2744319;10.1109/tvcg.2022.3209500;10.1109/tvcg.2022.3209451;10.1109/tvcg.2017.2744198;10.1109/tvcg.2018.2864903;10.1109/tvcg.2022.3209409;10.1109/tvcg.2018.2865145;10.1109/tvcg.2017.2745219;10.1109/vast47406.2019.8986918;10.1109/vast.2017.8585669;10.1109/tvcg.2021.3114862;10.1109/tvcg.2021.3114826;10.1109/tvcg.2022.3209493,"Gricean maxims,interactive visualization,conversation initiation,grounding,turn-taking,repair and refinement",,3.0,99.0,1506.0,,,critique design dashboards;better anticipate conversational;define concept cooperative;homework assignment;freely query underlying,0.7128;0.2577;0.1735;0.0893;0.0557,"[np.int64(-1), -1, -1, -1, -1]",192;-1;-1;-1;-1,192,192
InfoVis,2017,The Hologram in My Hand: How Effective is Interactive Exploration of 3D Visualizations in Immersive Tangible Augmented Reality?,10.1109/tvcg.2017.2745941,http://dx.doi.org/10.1109/TVCG.2017.2745941,457.0,467.0,J,"We report on a controlled user study comparing three visualization environments for common 3D exploration. Our environments differ in how they exploit natural human perception and interaction capabilities. We compare an augmented-reality head-mounted display (Microsoft HoloLens), a handheld tablet, and a desktop setup. The novel head-mounted HoloLens display projects stereoscopic images of virtual content into a user's real world and allows for interaction in-situ at the spatial position of the 3D hologram. The tablet is able to interact with 3D content through touch, spatial positioning, and tangible markers, however, 3D content is still presented on a 2D surface. Our hypothesis is that visualization environments that match human perceptual and interaction capabilities better to the task at hand improve understanding of 3D visualizations. To better understand the space of display and interaction modalities in visualization environments, we first propose a classification based on three dimensions: perception, interaction, and the spatial and cognitive proximity of the two. Each technique in our study is located at a different position along these three dimensions. We asked 15 participants to perform four tasks, each task having different levels of difficulty for both spatial perception and degrees of freedom for interaction. Our results show that each of the tested environments is more effective for certain tasks, but that generally the desktop environment is still fastest and most precise in almost all cases.",Benjamin Bach;Ronell Sicat;Johanna Beyer;Maxime Cordeil;Hanspeter Pfister,Benjamin Bach;Ronell Sicat;Johanna Beyer;Maxime Cordeil;Hanspeter Pfister,Harvard University;Harvard University;Harvard University;Monash University;Harvard University,10.1109/tvcg.2011.234;10.1109/tvcg.2012.216;10.1109/tvcg.2016.2599107;10.1109/tvcg.2008.153;10.1109/tvcg.2013.121;10.1109/tvcg.2013.134;10.1109/tvcg.2015.2467202;10.1109/tvcg.2011.234,"Augmented Reality,3D Interaction,User Study,Immersive Displays",212.0,163.0,67.0,6281.0,,,3d visualizations;hololens handheld tablet;cognitive proximity;task having different;real,0.5798;0.4689;0.3827;0.1120;0.0782,"[np.int64(-1), -1, -1, -1, -1]",110;-1;-1;-1;-1,110,110
Vis,2004,Modeling Decomposing Objects under Combustion,10.1109/visual.2004.71,http://dx.doi.org/10.1109/VISUAL.2004.71,14.0,14.0,M,"We present a simple yet effective method for modeling of object decomposition under combustion. A separate simulation models the flame production and generates heat from a combustion process, which is used to trigger pyrolysis of the solid object. The decomposition is modeled using level set methods, and can handle complex topological changes. Even with a very simple flame model on a coarse grid, we can achieve a plausible decomposition of the burning object.",Zeki Melek;John Keyser,Z. Melek;J. Keyser,"Computer Science Department, Texas A and M University, USA;Computer Science Department, Texas A and M University, USA",,,3.0,3.0,7.0,45.0,,,object decomposition combustion;level set methods;separate simulation models;complex topological;handle,0.6968;0.3707;0.1607;0.1584;0.0519,"[np.int64(-1), -1, -1, -1, -1]",228;-1;-1;-1;-1,228,228
Vis,2001,Approximate shading for the re-illumination of synthetic images,10.1109/visual.2001.964535,http://dx.doi.org/10.1109/VISUAL.2001.964535,379.0,386.0,C,"Presents a method to estimate illumination dependent properties in image synthesis prior to rendering. A preprocessing step is described in which a linear image basis is developed and a lighting-independent formulation defined. A reflection function, similar to hemispherical reflectance, approximates normal Lambertian shading. Intensity errors resulting from this approximation are reduced by use of a polynomial gamma correction function and scaling to a normalized display range. This produces images that are similar to normal Lambertian shading without employing the maximum (max) function. For a single object view, images can then be expressed in a linear form so that lighting direction can be factored out. During normal rendering, image quantities for arbitrary light directions can be found without rendering. This method is demonstrated for estimating image intensity and level-of-detail error prior to rendering an object.",Randy K. Scoggins;Raghu Machiraju;Robert J. Moorhead,R. Scoggins;R. Machiraju;R.J. Moorhead,"U.S. Army Engineer Research and Development Center, USA;Computer Information and Science, Ohio State Uinversity, USA;Engineering Research Center, Mississippi State University, USA",10.1109/visual.1999.809869;10.1109/visual.2000.885691;10.1109/visual.1999.809869,"rendering, level-of-detail, image metrics, perception",6.0,1.0,25.0,81.0,,,estimate illumination;linear image basis;scaling normalized display;preprocessing step;developed,0.6461;0.3387;0.2768;0.1819;0.0425,"[np.int64(-1), -1, -1, -1, -1]",3;-1;-1;-1;-1,3,3
InfoVis,1998,BiblioMapper: a cluster-based information visualization technique,10.1109/infvis.1998.729569,http://dx.doi.org/10.1109/INFVIS.1998.729569,130.0,136.0,C,"The purpose of the paper is to develop a visualization system of a document space, called BiblioMapper, for CISI collections, one of the bibliographic databases available on the Internet. The major function of BiblioMapper is to visualize the document space with a cluster-based visualization technique. The cluster-based visualization technique assembles a set of documents according to semantic similarities. One advantage of this technique is that users are able to focus on and assess each cluster and the documents which the cluster comprises according to their information needs.",Min Song,Min Song,"School of Library and Information Science, Indiana University, Bloomington, IN, USA",10.1109/infvis.1996.559228;10.1109/infvis.1995.528686;10.1109/infvis.1996.559228,"Visualization, Information Retrieval,Clustering Algorithms, Textual Information",19.0,2.0,17.0,160.0,,,bibliomapper visualize;technique cluster based;document space;cisi collections;called,0.6781;0.4135;0.3429;0.2778;0.0585,"[np.int64(-1), -1, -1, -1, -1]",265;-1;-1;-1;-1,265,265
Vis,2001,Salient iso-surface detection with model-independent statistical signatures,10.1109/visual.2001.964516,http://dx.doi.org/10.1109/VISUAL.2001.964516,231.0,238.0,C,"Volume graphics has not been accepted for widespread use. One of the inhibiting reasons is the lack of general methods for data-analysis and simple interfaces for data exploration. An error-and-trial iterative procedure is often used to select a desirable transfer function or mine the dataset for salient iso-values. New semi-automatic methods that are also data-centric have shown much promise. However, general and robust methods are still needed for data-exploration and analysis. In this paper, we propose general model-independent statistical methods based on central moments of data. Using these techniques we show how salient iso-surfaces at material boundaries can be determined. We provide examples from the medical and computational domain to demonstrate the effectiveness of our methods.",Shivaraj Tenginakai;Jinho Lee;Raghu Machiraju,S. Tenginakai;Jinho Lee;R. Machiraju,"Computer and Information Science, Ohio State Uinversity, USA;Computer and Information Science, Ohio State Uinversity, USA;Computer and Information Science, Ohio State Uinversity, USA",10.1109/visual.1998.745319;10.1109/visual.1997.663875;10.1109/visual.1996.568113,"Iso-values, Transfer Functions, Surface Extraction, Direct Volume Rendering",96.0,24.0,13.0,180.0,,,salient iso surfaces;volume;medical computational domain;moments data using;general model independent,0.5065;0.3557;0.2892;0.2585;0.1472,"[np.int64(-1), -1, -1, -1, -1]",229;-1;-1;-1;-1,229,229
VAST,2020,Revisiting the Modifiable Areal Unit Problem in Deep Traffic Prediction with Visual Analytics,10.1109/tvcg.2020.3030410,http://dx.doi.org/10.1109/TVCG.2020.3030410,839.0,848.0,J,"Deep learning methods are being increasingly used for urban traffic prediction where spatiotemporal traffic data is aggregated into sequentially organized matrices that are then fed into convolution-based residual neural networks. However, the widely known modifiable areal unit problem within such aggregation processes can lead to perturbations in the network inputs. This issue can significantly destabilize the feature embeddings and the predictions - rendering deep networks much less useful for the experts. This paper approaches this challenge by leveraging unit visualization techniques that enable the investigation of many-to-many relationships between dynamically varied multi-scalar aggregations of urban traffic data and neural network predictions. Through regular exchanges with a domain expert, we design and develop a visual analytics solution that integrates 1) a Bivariate Map equipped with an advanced bivariate colormap to simultaneously depict input traffic and prediction errors across space, 2) a Moran's I Scatterplot that provides local indicators of spatial association analysis, and 3) a Multi-scale Attribution View that arranges non-linear dot plots in a tree layout to promote model analysis and comparison across scales. We evaluate our approach through a series of case studies involving a real-world dataset of Shenzhen taxi trips, and through interviews with domain experts. We observe that geographical scale variations have important impact on prediction performances, and interactive visual exploration of dynamically varying inputs and outputs benefit experts in the development of deep traffic prediction models.",Wei Zeng 0004;Chengqiao Lin;Juncong Lin;Jincheng Jiang;Jiazhi Xia;Cagatay Turkay;Wei Chen 0001,Wei Zeng;Chengqiao Lin;Juncong Lin;Jincheng Jiang;Jiazhi Xia;Cagatay Turkay;Wei Chen,"Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, China;Xiamen University, China;Xiamen University, China;Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, China;Central South University, China;University of Warwick, UK;State Key Lab of CAD&CG, Zhejiang University, China",10.1109/vast.2018.8802509;10.1109/tvcg.2019.2934670;10.1109/tvcg.2015.2467199;10.1109/tvcg.2009.143;10.1109/tvcg.2018.2865027;10.1109/tvcg.2016.2598831;10.1109/vast.2017.8585721;10.1109/tvcg.2017.2744358;10.1109/tvcg.2017.2744018;10.1109/tvcg.2014.2346321;10.1109/tvcg.2017.2744159;10.1109/tvcg.2017.2744158;10.1109/tvcg.2014.2346265;10.1109/tvcg.2018.2865126;10.1109/tvcg.2019.2934619;10.1109/tvcg.2016.2598541,"MAUP,traffic prediction,deep learning,model diagnostic,visual analytics",24.0,28.0,54.0,1312.0,,,urban traffic prediction;unit visualization techniques;deep;exchanges domain expert;processes lead perturbations,0.5852;0.3508;0.2122;0.0963;0.0743,"[np.int64(-1), -1, -1, -1, -1]",234;-1;-1;-1;-1,234,234
InfoVis,2016,"Hashedcubes: Simple, Low Memory, Real-Time Visual Exploration of Big Data",10.1109/tvcg.2016.2598624,http://dx.doi.org/10.1109/TVCG.2016.2598624,671.0,680.0,J,"We propose Hashedcubes, a data structure that enables real-time visual exploration of large datasets that improves the state of the art by virtue of its low memory requirements, low query latencies, and implementation simplicity. In some instances, Hashedcubes notably requires two orders of magnitude less space than recent data cube visualization proposals. In this paper, we describe the algorithms to build and query Hashedcubes, and how it can drive well-known interactive visualizations such as binned scatterplots, linked histograms and heatmaps. We report memory usage, build time and query latencies for a variety of synthetic and real-world datasets, and find that although sometimes Hashedcubes offers slightly slower querying times to the state of the art, the typical query is answered fast enough to easily sustain a interaction. In datasets with hundreds of millions of elements, only about 2% of the queries take longer than 40ms. Finally, we discuss the limitations of data structure, potential spacetime tradeoffs, and future research directions.",Cicero Augusto de Lara Pahins;Sean A. Stephens;Carlos Scheidegger;João Luiz Dihl Comba,Cícero A. L. Pahins;Sean A. Stephens;Carlos Scheidegger;João L. D. Comba,"Instituto de Informática, UFRGS;University of Arizona;University of Arizona;Instituto de Informática, UFRGS",10.1109/tvcg.2013.179;10.1109/tvcg.2014.2346452;10.1109/tvcg.2014.2346574;10.1109/tvcg.2015.2467771;10.1109/tvcg.2013.179,Scalability;data cube;multidimensional data;interactive exploration,116.0,67.0,45.0,1898.0,,,data cube visualization;hashedcubes notably requires;hundreds millions;variety synthetic real;longer 40ms,0.6796;0.4589;0.1272;0.0828;-0.0159,"[np.int64(-1), -1, -1, -1, -1]",261;-1;-1;-1;-1,261,261
SciVis,2018,DT-MRI Streamsurfaces Revisited,10.1109/tvcg.2018.2864845,http://dx.doi.org/10.1109/TVCG.2018.2864845,1112.0,1121.0,J,"DT-MRI streamsurfaces, defined as surfaces that are everywhere tangential to the major and medium eigenvector fields, have been proposed as a tool for visualizing regions of predominantly planar behavior in diffusion tensor MRI. Even though it has long been known that their construction assumes that the involved eigenvector fields satisfy an integrability condition, it has never been tested systematically whether this condition is met in real-world data. We introduce a suitable and efficiently computable test to the visualization literature, demonstrate that it can be used to distinguish integrable from nonintegrable configurations in simulations, and apply it to whole-brain datasets of 15 healthy subjects. We conclude that streamsurface integrability is approximately satisfied in a substantial part of the brain, but not everywhere, including some regions of planarity. As a consequence, algorithms for streamsurface extraction should explicitly test local integrability. Finally, we propose a novel patch-based approach to streamsurface visualization that reduces visual artifacts, and is shown to more fully sample the extent of streamsurfaces.",Michael Ankele;Thomas Schultz 0001,Michael Ankele;Thomas Schultz,University of Bonn;University of Bonn,10.1109/tvcg.2007.70551;10.1109/visual.1992.235211;10.1109/tvcg.2007.70554;10.1109/tvcg.2007.70602;10.1109/tvcg.2008.148;10.1109/tvcg.2007.70551,"Diffusion Tensor MRI,streamsurfaces,Frobenius theorem,Lie bracket",1.0,2.0,36.0,300.0,,,diffusion tensor mri;computable test visualization;streamsurface;planarity consequence;distinguish integrable nonintegrable,0.6814;0.2174;0.2059;0.1818;0.1791,"[np.int64(-1), -1, -1, -1, -1]",43;-1;-1;-1;-1,43,43
Vis,2023,Image or Information? Examining the Nature and Impact of Visualization Perceptual Classification,10.1109/tvcg.2023.3326919,http://dx.doi.org/10.1109/TVCG.2023.3326919,1030.0,1040.0,J,"How do people internalize visualizations: as images or information? In this study, we investigate the nature of internalization for visualizations (i.e., how the mind encodes visualizations in memory) and how memory encoding affects its retrieval. This exploratory work examines the influence of various design elements on a user's perception of a chart. Specifically, which design elements lead to perceptions of visualization as an image (aims to provide visual references, evoke emotions, express creativity, and inspire philosophic thought) or as information (aims to present complex data, information, or ideas concisely and promote analytical thinking)? Understanding how design elements contribute to viewers perceiving a visualization more as an image or information will help designers decide which elements to include to achieve their communication goals. For this study, we annotated 500 visualizations and analyzed the responses of 250 online participants, who rated the visualizations on a bilinear scale as ‘image’ or ‘information.’ We then conducted an in-person study ($n = 101$) using a free recall task to examine how the image/information ratings and design elements impacted memory. The results revealed several interesting findings: Image-rated visualizations were perceived as more aesthetically ‘appealing,’ ‘enjoyable,’ and ‘pleasing.’ Information-rated visualizations were perceived as less ‘difficult to understand’ and more aesthetically ‘likable’ and ‘nice,’ though participants expressed higher ‘positive’ sentiment when viewing image-rated visualizations and felt less ‘guided to a conclusion.’ The presence of axes and text annotations heavily influenced the likelihood of participants rating the visualization as ‘information.’ We also found different patterns among participants that were older. Importantly, we show that visualizations internalized as ‘images’ are less effective in conveying trends and messages, though they elicit a more positive emotional judgment, while ‘informative’ visualizations exhibit annotation focused recall and elicit a more positive design judgment. We discuss the implications of this dissociation between aesthetic pleasure and perceived ease of use in visualization design.",Anjana Arunkumar;Lace M. K. Padilla;Gi-Yeul Bae;Chris Bryan,Anjana Arunkumar;Lace Padilla;Gi-Yeul Bae;Chris Bryan,"Arizona State University, USA;Northeastern University, USA;Arizona State University, USA;Arizona State University, USA",0.1109/tvcg.2020.3030375;10.1109/infvis.2005.1532136;10.1109/tvcg.2012.197;10.1109/tvcg.2015.2467732;10.1109/tvcg.2013.234;10.1109/tvcg.2013.124;10.1109/tvcg.2022.3209390;10.1109/tvcg.2011.175;10.1109/tvcg.2011.255;10.1109/infvis.1998.729564;10.1109/tvcg.2016.2598620;10.1109/tvcg.2022.3209500;10.1109/tvcg.2012.221;10.1109/tvcg.2022.3209421;10.1109/tvcg.2022.3209383;10.1109/tvcg.2007.70577;10.1109/tvcg.2012.262;10.1109/tvcg.2021.3114823,"Information Visualization,Human-Centered Computing,Perception & Cognition,Takeaways",,1.0,84.0,620.0,,,people internalize visualizations;image information help;annotation focused recall;rated;decide elements include,0.7553;0.3009;0.1913;0.0724;0.0226,"[np.int64(-1), -1, -1, -1, -1]",271;-1;-1;-1;-1,271,271
Vis,1991,The stream polygon: A technique for 3D vector field visualization,10.1109/visual.1991.175789,http://dx.doi.org/10.1109/VISUAL.1991.175789,126.0,,C,"A method is presented for the visualization of 3D vector fields. The stream polygon, which is a regular, n-sided polygon, oriented normal to the local vector, can present local deformations due to rigid body rotation and both normal and shear strain. The effect of translation and scalar functions can be represented by sweeping the stream polygon along the streamline, and by appropriately varying the radius and shading the surface of the resulting streamtube. A mathematical foundation for the stream is developed, and examples with application to velocity field visualization are provided.&lt;&lt;ETX&gt;&gt;",William J. Schroeder;Christopher R. Volpe;William E. Lorensen,W.J. Schroeder;C.R. Volpe;W.E. Lorensen,"GE Corporate Research and Development Center, Schenectady, NY, USA;GE Corporate Research and Development Center, Schenectady, NY, USA;GE Corporate Research and Development Center, Schenectady, NY, USA",,,157.0,42.0,10.0,157.0,,,velocity field visualization;shear strain effect;body rotation;polygon regular;developed examples,0.7452;0.3334;0.2595;0.1523;0.1085,"[np.int64(-1), -1, -1, -1, -1]",140;-1;-1;-1;-1,140,140
SciVis,2020,V2V: A Deep Learning Approach to Variable-to-Variable Selection and Translation for Multivariate Time-Varying Data,10.1109/tvcg.2020.3030346,http://dx.doi.org/10.1109/TVCG.2020.3030346,1290.0,1300.0,J,"We present V2V, a novel deep learning framework, as a general-purpose solution to the variable-to-variable (V2V) selection and translation problem for multivariate time-varying data (MTVD) analysis and visualization. V2V leverages a representation learning algorithm to identify transferable variables and utilizes Kullback-Leibler divergence to determine the source and target variables. It then uses a generative adversarial network (GAN) to learn the mapping from the source variable to the target variable via the adversarial, volumetric, and feature losses. V2V takes the pairs of time steps of the source and target variable as input for training, Once trained, it can infer unseen time steps of the target variable given the corresponding time steps of the source variable. Several multivariate time-varying data sets of different characteristics are used to demonstrate the effectiveness of V2V, both quantitatively and qualitatively. We compare V2V against histogram matching and two other deep learning solutions (Pix2Pix and CycleGAN).",Jun Han 0010;Hao Zheng 0006;Yunhao Xing;Danny Z. Chen;Chaoli Wang 0001,Jun Han;Hao Zheng;Yunhao Xing;Danny Z. Chen;Chaoli Wang,University of Notre Dame;University of Notre Dame;Sichuan University;University of Notre Dame;University of Notre Dame,10.1109/tvcg.2013.133;10.1109/tvcg.2019.2934332;10.1109/tvcg.2006.175;10.1109/tvcg.2019.2934255;10.1109/tvcg.2019.2934312;10.1109/tvcg.2015.2467431;10.1109/tvcg.2007.70523;10.1109/tvcg.2006.165;10.1109/tvcg.2018.2864808;10.1109/tvcg.2013.133,"Multivariate time-varying data,variable selection and translation,generative adversarial network,data extrapolation",24.0,24.0,47.0,1063.0,,,gan learn mapping;time varying data;qualitatively compare v2v;kullback leibler;takes pairs,0.4878;0.4288;0.2300;0.0615;0.0547,"[-1, -1, -1, -1, -1]",-1;-1;-1;-1;-1,,-1
VAST,2008,Maintaining interactivity while exploring massive time series,10.1109/vast.2008.4677357,http://dx.doi.org/10.1109/VAST.2008.4677357,59.0,66.0,C,"The speed of data retrieval qualitatively affects how analysts visually explore and analyze their data. To ensure smooth interactions in massive time series datasets, one needs to address the challenges of computing &lt;i&gt;ad&lt;/i&gt; &lt;i&gt;hoc&lt;/i&gt; queries, distributing query load, and hiding system latency. In this paper, we present ATLAS, a visualization tool for temporal data that addresses these issues using a combination of high performance database technology, predictive caching, and level of detail management. We demonstrate ATLAS using commodity hardware on a network traffic dataset of more than a billion records.",Sye-Min Chan;Ling Xiao 0005;John Gerth;Pat Hanrahan,Sye-Min Chan;Ling Xiao;John Gerth;Pat Hanrahan,"University of Stanford, USA;University of Stanford, USA;University of Stanford, USA;University of Stanford, USA",10.1109/vast.2006.261437;10.1109/vast.2007.4388998;10.1109/vast.2006.261437,,94.0,18.0,30.0,677.0,,,visualization tool temporal;dataset billion records;query load hiding;qualitatively affects analysts;combination high,0.5319;0.4918;0.2498;0.2359;0.0889,"[np.int64(-1), -1, -1, -1, -1]",156;-1;-1;-1;-1,156,156
SciVis,2012,Interactive Retro-Deformation of Terrain for Reconstructing 3D Fault Displacements,10.1109/tvcg.2012.239,http://dx.doi.org/10.1109/TVCG.2012.239,2208.0,2215.0,J,"Planetary topography is the result of complex interactions between geological processes, of which faulting is a prominent component. Surface-rupturing earthquakes cut and move landforms which develop across active faults, producing characteristic surface displacements across the fault. Geometric models of faults and their associated surface displacements are commonly applied to reconstruct these offsets to enable interpretation of the observed topography. However, current 2D techniques are limited in their capability to convey both the three-dimensional kinematics of faulting and the incremental sequence of events required by a given reconstruction. Here we present a real-time system for interactive retro-deformation of faulted topography to enable reconstruction of fault displacement within a high-resolution (sub 1m/pixel) 3D terrain visualization. We employ geometry shaders on the GPU to intersect the surface mesh with fault-segments interactively specified by the user and transform the resulting surface blocks in realtime according to a kinematic model of fault motion. Our method facilitates a human-in-the-loop approach to reconstruction of fault displacements by providing instant visual feedback while exploring the parameter space. Thus, scientists can evaluate the validity of traditional point-to-point reconstructions by visually examining a smooth interpolation of the displacement in 3D. We show the efficacy of our approach by using it to reconstruct segments of the San Andreas fault, California as well as a graben structure in the Noctis Labyrinthus region on Mars.",Rolf Westerteiger;Tracy Compton;Tony Bernardin;Eric S. Cowgill;Klaus Gwinner;Bernd Hamann;Andreas Gerndt;Hans Hagen,Rolf Westerteiger;Tracy Compton;Tony Bernadin;Eric Cowgill;Klaus Gwinner;Bernd Hamann;Andreas Gerndt;Hans Hagen,"German Aerospace Center, University of Kaiserslautern, Germany;Department of Geology, University of California, Davis, USA;University of California Center Sacramento, Sacramento, CA, US;Department of Geology, University of California, Davis, USA;Institute of Planetary Research, German Aerospace Center (DLR), Berlin, Germany;Department of Computer Science, University of California, Davis, USA;German Aerospace Center, Germany;University of Kaiserslautern, Germany",,"Terrain rendering, interactive, fault simulation, mesh deformation",5.0,2.0,20.0,505.0,,,deformation faulted topography;convey dimensional kinematics;mars;shaders gpu intersect;evaluate,0.6433;0.3291;0.2397;0.2260;-0.0159,"[np.int64(-1), -1, -1, -1, -1]",251;-1;-1;-1;-1,251,251
InfoVis,2012,Visualizing Student Histories Using Clustering and Composition,10.1109/tvcg.2012.288,http://dx.doi.org/10.1109/TVCG.2012.288,2809.0,2818.0,J,"While intuitive time-series visualizations exist for common datasets, student course history data is difficult to represent using traditional visualization techniques due its concurrent nature. A visual composition process is developed and applied to reveal trends across various groupings. By working closely with educators, analytic strategies and techniques are developed to leverage the visualization composition to reveal unknown trends in the data. Furthermore, clustering algorithms are developed to group common course-grade histories for further analysis. Lastly, variations of the composition process are implemented to reveal subtle differences in the underlying data. These analytic tools and techniques enabled educators to confirm expected trends and to discover new ones.",David Trimm;Penny Rheingans;Marie desJardins,David Trimm;Penny Rheingans;Marie desJardins,"University of Maryland Baltimore County, USA;University of Maryland Baltimore County, USA;University of Maryland Baltimore County, USA",10.1109/infvis.2005.1532140;10.1109/tvcg.2007.70623;10.1109/tvcg.2009.131;10.1109/infvis.2005.1532140,"Clustering, aggregate visualization, student performance analysis, visualization composition",24.0,15.0,16.0,1036.0,,,time series visualizations;educators analytic strategies;common course grade;subtle differences underlying;group,0.6795;0.3300;0.3145;0.1977;0.0887,"[np.int64(-1), -1, -1, -1, -1]",163;-1;-1;-1;-1,163,163
Vis,2004,Compatible triangulations of spatial decompositions,10.1109/visual.2004.15,http://dx.doi.org/10.1109/VISUAL.2004.15,211.0,217.0,C,"We describe a general algorithm to produce compatible 3D triangulations from spatial decompositions. Such triangulations match edges and faces across spatial cell boundaries, solving several problems in graphics and visualization including the crack problem found in adaptive isosurface generation, triangulation of arbitrary grids (including unstructured grids), clipping, and the interval tetrahedrization problem. The algorithm produces compatible triangulations on a cell-by-cell basis, using a modified Delaunay triangulation with a simple point ordering rule to resolve degenerate cases and produce unique triangulations across cell boundaries. The algorithm is naturally parallel since it requires no neighborhood cell information, only a unique, global point numbering. We show application of this algorithm to adaptive contour generation; tetrahedrization of unstructured meshes; clipping and interval volume mesh generation.",William J. Schroeder;Berk Geveci;Mathieu Malaterre,W.J. Schroeder;B. Geveci;M. Malaterre,"Kitware, Inc;Kitware, Inc.;Kitware, Inc.",10.1109/visual.1996.568127;10.1109/visual.1997.663869;10.1109/visual.1997.663886;10.1109/visual.1996.568127,"triangulation, tetrahedrization, adaptive grid, clipping, contouring, template, Delaunay, parallel",34.0,7.0,33.0,147.0,,,3d triangulations;including crack problem;clipping interval volume;naturally;cases produce unique,0.7330;0.1672;0.1624;0.0380;-0.0031,"[np.int64(-1), -1, -1, -1, -1]",108;-1;-1;-1;-1,108,108
Vis,2021,FairRankVis: A Visual Analytics Framework for Exploring Algorithmic Fairness in Graph Mining Models,10.1109/tvcg.2021.3114850,http://dx.doi.org/10.1109/TVCG.2021.3114850,368.0,377.0,J,"Graph mining is an essential component of recommender systems and search engines. Outputs of graph mining models typically provide a ranked list sorted by each item's relevance or utility. However, recent research has identified issues of algorithmic bias in such models, and new graph mining algorithms have been proposed to correct for bias. As such, algorithm developers need tools that can help them uncover potential biases in their models while also exploring the impacts of correcting for biases when employing fairness-aware algorithms. In this paper, we present FairRankVis, a visual analytics framework designed to enable the exploration of multi-class bias in graph mining algorithms. We support both group and individual fairness levels of comparison. Our framework is designed to enable model developers to compare multi-class fairness between algorithms (for example, comparing PageRank with a debiased PageRank algorithm) to assess the impacts of algorithmic debiasing with respect to group and individual fairness. We demonstrate our framework through two usage scenarios inspecting algorithmic fairness.",Tiankai Xie;Yuxin Ma;Jian Kang 0008;Hanghang Tong;Ross Maciejewski,Tiankai Xie;Yuxin Ma;Jian Kang;Hanghang Tong;Ross Maciejewski,"Arizona State University, United States;Southern University of Science and Technology, China;University of Illinois at Urbana-Champaign, United States;University of Illinois at Urbana-Champaign, United States;Arizona State University, United States",10.1109/tvcg.2019.2934262;10.1109/tvcg.2011.185;10.1109/vast47406.2019.8986948;10.1109/tvcg.2020.3030471;10.1109/tvcg.2020.3028958;10.1109/tvcg.2019.2934262,"Graph ranking,fairness,visual analytics",4.0,12.0,37.0,1346.0,,,fairrankvis visual analytics;respect group individual;correcting;enable model;framework usage scenarios,0.6496;0.2652;0.0713;0.0446;-0.0102,"[np.int64(-1), -1, -1, -1, -1]",179;-1;-1;-1;-1,179,179
Vis,2024,Quality Metrics and Reordering Strategies for Revealing Patterns in BioFabric Visualizations,10.1109/tvcg.2024.3456312,http://dx.doi.org/10.1109/TVCG.2024.3456312,1039.0,1049.0,J,"Visualizing relational data is crucial for understanding complex connections between entities in social networks, political affiliations, or biological interactions. Well-known representations like node-link diagrams and adjacency matrices offer valuable insights, but their effectiveness relies on the ability to identify patterns in the underlying topological structure. Reordering strategies and layout algorithms play a vital role in the visualization process since the arrangement of nodes, edges, or cells influences the visibility of these patterns. The BioFabric visualization combines elements of node-link diagrams and adjacency matrices, leveraging the strengths of both, the visual clarity of node-link diagrams and the tabular organization of adjacency matrices. A unique characteristic of BioFabric is the possibility to reorder nodes and edges separately. This raises the question of which combination of layout algorithms best reveals certain patterns. In this paper, we discuss patterns and anti-patterns in BioFabric, such as staircases or escalators, relate them to already established patterns, and propose metrics to evaluate their quality. Based on these quality metrics, we compared combinations of well-established reordering techniques applied to BioFabric with a well-known benchmark data set. Our experiments indicate that the edge order has a stronger influence on revealing patterns than the node layout. The results show that the best combination for revealing staircases is a barycentric node layout, together with an edge order based on node indices and length. Our research contributes a first building block for many promising future research directions, which we also share and discuss. A free copy of this paper and all supplemental materials are available at https://osf.io/9mt8r/?view_only=b7t0dfbe550e3404f83059afdc60184c6.",Johannes Fuchs 0001;Alexander Frings;Maria-Viktoria Heinle;Daniel A. Keim;Sara Di Bartolomeo,Johannes Fuchs;Alexander Frings;Maria-Viktoria Heinle;Daniel A. Keim;Sara Di Bartolomeo,"University of Konstanz, Germany;University of Konstanz, Germany;University of Konstanz, Germany;University of Konstanz, Germany;University of Konstanz and TU Wien, Germany",10.1109/infvis.2003.1249011;10.1109/tvcg.2008.117;10.1109/tvcg.2016.2598467;10.1109/tvcg.2021.3114756;10.1109/tvcg.2006.147;10.1109/infvis.2003.1249028;10.1109/infvis.2002.1173155,"Network Visualization,Graph Drawing,,,Graph Layout Algorithms,BioFabric,Graph Motif",,0.0,53.0,137.0,,,visualizing relational data;biofabric staircases escalators;layout edge order;barycentric;effectiveness relies,0.6195;0.3959;0.3872;0.1942;0.0415,"[np.int64(-1), -1, -1, -1, -1]",199;-1;-1;-1;-1,199,199
VAST,2014,Visual Methods for Analyzing Probabilistic Classification Data,10.1109/tvcg.2014.2346660,http://dx.doi.org/10.1109/TVCG.2014.2346660,1703.0,1712.0,J,"Multi-class classifiers often compute scores for the classification samples describing probabilities to belong to different classes. In order to improve the performance of such classifiers, machine learning experts need to analyze classification results for a large number of labeled samples to find possible reasons for incorrect classification. Confusion matrices are widely used for this purpose. However, they provide no information about classification scores and features computed for the samples. We propose a set of integrated visual methods for analyzing the performance of probabilistic classifiers. Our methods provide insight into different aspects of the classification results for a large number of samples. One visualization emphasizes at which probabilities these samples were classified and how these probabilities correlate with classification error in terms of false positives and false negatives. Another view emphasizes the features of these samples and ranks them by their separation power between selected true and false classifications. We demonstrate the insight gained using our technique in a benchmarking classification dataset, and show how it enables improving classification performance by interactively defining and evaluating post-classification rules.",Bilal Alsallakh;Allan Hanbury;Helwig Hauser;Silvia Miksch;Andreas Rauber,Bilal Alsallakh;Allan Hanbury;Helwig Hauser;Silvia Miksch;Andreas Rauber,Vienna University of Technology;Vienna University of Technology;University of Bergen;Vienna University of Technology;Vienna University of Technology,10.1109/visual.2000.885740;10.1109/vast.2010.5652398;10.1109/vast.2009.5332628;10.1109/tvcg.2012.277;10.1109/vast.2012.6400486;10.1109/tvcg.2013.184;10.1109/tvcg.2012.254;10.1109/vast.2011.6102448;10.1109/vast.2011.6102453;10.1109/vast.2012.6400492;10.1109/vast.2010.5652443;10.1109/visual.2000.885740,"Probabilistic classification, confusion analysis, feature evaluation and selection, visual inspection",121.0,88.0,43.0,2408.0,,,analyze classification results;visualization emphasizes probabilities;integrated visual;true;set,0.5926;0.4962;0.2484;0.0816;0.0254,"[np.int64(-1), -1, -1, -1, -1]",217;-1;-1;-1;-1,217,217
Vis,1998,Large scale terrain visualization using the restricted quadtree triangulation,10.1109/visual.1998.745280,http://dx.doi.org/10.1109/VISUAL.1998.745280,19.0,26.0,C,"Real-time rendering of triangulated surfaces has attracted growing interest in the last few years. However, interactive visualization of very large scale grid digital elevation models is still difficult. The graphics load must be controlled by adaptive surface triangulation and by taking advantage of different levels of detail. Furthermore, management of the visible scene requires efficient access to the terrain database. We describe an all-in-one visualization system which integrates adaptive triangulation, dynamic scene management and spatial data handling. The triangulation model is based on the restricted quadtree triangulation. Furthermore, we present new algorithms of restricted quadtree triangulation. These include among others exact error approximation, progressive meshing, performance enhancements and spatial access.",Renato Pajarola,R. Pajarola,"ETH, Zurich, Switzerland",10.1109/visual.1997.663860;10.1109/visual.1995.480800;10.1109/visual.1995.480799;10.1109/visual.1998.745280;10.1109/visual.1997.663860,"algorithms, computer graphics, virtual reality, triangulated surfaces, terrain visualization, terascale visualization",534.0,89.0,17.0,530.0,,,adaptive surface triangulation;access terrain database;visualization large;restricted;exact error,0.6716;0.3444;0.3177;0.0363;0.0287,"[np.int64(-1), -1, -1, -1, -1]",105;-1;-1;-1;-1,105,105
Vis,2003,Vicinity shading for enhanced perception of volumetric data,10.1109/visual.2003.1250394,http://dx.doi.org/10.1109/VISUAL.2003.1250394,355.0,362.0,C,"This paper presents a shading model for volumetric data which enhances the perception of surfaces within the volume. The model incorporates uniform diffuse illumination, which arrives equally from all directions at each surface point in the volume. This illumination is attenuated by occlusions in the local vicinity of the surface point, resulting in shadows in depressions and crevices. Experiments by other authors have shown that perception of a surface is superior under uniform diffuse lighting, compared to illumination from point source lighting.",A. James Stewart,A.J. Stewart,"School of Computing, Queen's University, Canada",10.1109/visual.2002.1183761;10.1109/visual.2002.1183764,"volume rendering, shading model, diffuse illumination, perceptual cues",105.0,32.0,25.0,141.0,,,shading model volumetric;surface;data enhances perception;crevices experiments;presents,0.6766;0.3940;0.3685;0.2590;0.0459,"[np.int64(-1), -1, -1, -1, -1]",256;-1;-1;-1;-1,256,256
SciVis,2013,A Lightweight Tangible 3D Interface for Interactive Visualization of Thin fiber Structures,10.1109/tvcg.2013.121,http://dx.doi.org/10.1109/TVCG.2013.121,2802.0,2809.0,J,"We present a prop-based, tangible interface for 3D interactive visualization of thin fiber structures. These data are commonly found in current bioimaging datasets, for example second-harmonic generation microscopy of collagen fibers in tissue. Our approach uses commodity visualization technologies such as a depth sensing camera and low-cost 3D display. Unlike most current uses of these emerging technologies in the games and graphics communities, we employ the depth sensing camera to create a fish-tank sterePoscopic virtual reality system at the scientist's desk that supports tracking of small-scale gestures with objects already found in the work space. We apply the new interface to the problem of interactive exploratory visualization of three-dimensional thin fiber data. A critical task for the visual analysis of these data is understanding patterns in fiber orientation throughout a volume.The interface enables a new, fluid style of data exploration and fiber orientation analysis by using props to provide needed passive-haptic feedback, making 3D interactions with these fiber structures more controlled. We also contribute a low-level algorithm for extracting fiber centerlines from volumetric imaging. The system was designed and evaluated with two biophotonic experts who currently use it in their lab. As compared to typical practice within their field, the new visualization system provides a more effective way to examine and understand the 3D bioimaging datasets they collect.",Bret Jackson;Tung Yuen Lau;David Schroeder;Kimani C. Toussaint;Daniel F. Keefe,Bret Jackson;Tung Yuen Lau;David Schroeder;Kimani C. Toussaint;Daniel F. Keefe,"University of Minnesota, USA;University of Illinois, Urbana-Champaign, USA;University of Minnesota, USA;University of Illinois, Urbana-Champaign, USA;University of Minnesota, USA",10.1109/tvcg.2009.138;10.1109/visual.2005.1532846;10.1109/visual.2002.1183753;10.1109/visual.1997.663912;10.1109/tvcg.2009.138,"Scientific visualization, 3D interaction, tangible interaction, microscopy visualization",74.0,52.0,26.0,1500.0,,,interactive visualization fiber;understand 3d;harmonic generation microscopy;fish tank stereposcopic;sensing camera low,0.5980;0.4014;0.2479;0.2338;0.0867,"[np.int64(-1), -1, -1, -1, -1]",319;-1;-1;-1;-1,319,319
Vis,2022,MEDLEY: Intent-based Recommendations to Support Dashboard Composition,10.1109/tvcg.2022.3209421,http://dx.doi.org/10.1109/TVCG.2022.3209421,1135.0,1145.0,J,"Despite the ever-growing popularity of dashboards across a wide range of domains, their authoring still remains a tedious and complex process. Current tools offer considerable support for creating individual visualizations but provide limited support for discovering groups of visualizations that can be collectively useful for composing analytic dashboards. To address this problem, we present Medley, a mixed-initiative interface that assists in dashboard composition by recommending dashboard collections (i.e., a logically grouped set of views and filtering widgets) that map to specific analytical intents. Users can specify dashboard intents (namely, measure analysis, change analysis, category analysis, or distribution analysis) explicitly through an input panel in the interface or implicitly by selecting data attributes and views of interest. The system recommends collections based on these analytic intents, and views and widgets can be selected to compose a variety of dashboards. Medley also provides a lightweight direct manipulation interface to configure interactions between views in a dashboard. Based on a study with 13 participants performing both targeted and open-ended tasks, we discuss how Medley's recommendations guide dashboard composition and facilitate different user workflows. Observations from the study identify potential directions for future work, including combining manual view specification with dashboard recommendations and designing natural language interfaces for dashboard authoring.",Aditeya Pandey;Arjun Srinivasan;Vidya Setlur,Aditeya Pandey;Arjun Srinivasan;Vidya Setlur,"Northeastern University, USA;Tableau Research, Germany;Tableau Research, Germany",10.1109/infvis.2005.1532136;10.1109/tvcg.2013.124;10.1109/tvcg.2020.3030338;10.1109/tvcg.2020.3030424;10.1109/tvcg.2021.3114860;10.1109/tvcg.2021.3114848;10.1109/tvcg.2007.70594;10.1109/tvcg.2020.3030378;10.1109/tvcg.2017.2744198;10.1109/tvcg.2018.2864903;10.1109/tvcg.2017.2744184;10.1109/tvcg.2016.2599030;10.1109/tvcg.2013.120;10.1109/tvcg.2018.2865145;10.1109/tvcg.2019.2934398;10.1109/tvcg.2015.2467191;10.1109/tvcg.2021.3114826,"Dashboards,intent,recommendations,direct manipulation,multi-view coordination",,8.0,55.0,1537.0,HM,,composing analytic dashboards;intents views widgets;interface implicitly selecting;domains authoring;13,0.7419;0.3339;0.1427;0.0401;-0.0049,"[np.int64(-1), -1, -1, -1, -1]",197;-1;-1;-1;-1,197,197
Vis,2007,Transform Coding for Hardware-accelerated Volume Rendering,10.1109/tvcg.2007.70516,http://dx.doi.org/10.1109/TVCG.2007.70516,1600.0,1607.0,J,"Hardware-accelerated volume rendering using the GPU is now the standard approach for real-time volume rendering, although limited graphics memory can present a problem when rendering large volume data sets. Volumetric compression in which the decompression is coupled to rendering has been shown to be an effective solution to this problem; however, most existing techniques were developed in the context of software volume rendering, and all but the simplest approaches are prohibitive in a real-time hardware-accelerated volume rendering context. In this paper we present a novel block-based transform coding scheme designed specifically with real-time volume rendering in mind, such that the decompression is fast without sacrificing compression quality. This is made possible by consolidating the inverse transform with dequantization in such a way as to allow most of the reprojection to be precomputed. Furthermore, we take advantage of the freedom afforded by offline compression in order to optimize the encoding as much as possible while hiding this complexity from the decoder. In this context we develop a new block classification scheme which allows us to preserve perceptually important features in the compression. The result of this work is an asymmetric transform coding scheme that allows very large volumes to be compressed and then decompressed in real-time while rendering on the GPU.",Nathaniel Fout;Kwan-Liu Ma,Nathaniel Fout;Kwan-Liu Ma,"Department of Computer Science, University of California, Davis, USA;Department of Computer Science, University of California, Davis, USA",10.1109/visual.2002.1183757;10.1109/visual.2001.964520;10.1109/visual.2004.95;10.1109/visual.1993.398845;10.1109/visual.2003.1250357;10.1109/visual.1995.480812;10.1109/visual.2003.1250385;10.1109/visual.2002.1183757,"Volume Compression, Compressed Volume Rendering, Transform Coding, Hardware-accelerated Volume Rendering",89.0,47.0,25.0,501.0,,,accelerated volume rendering;optimize encoding;block classification scheme;inverse transform;specifically real,0.6373;0.3664;0.3427;0.2593;0.1586,"[np.int64(-1), -1, -1, -1, -1]",93;-1;-1;-1;-1,93,93
VAST,2013,Identifying Redundancy and Exposing Provenance in Crowdsourced Data Analysis,10.1109/tvcg.2013.164,http://dx.doi.org/10.1109/TVCG.2013.164,2198.0,2206.0,J,"We present a system that lets analysts use paid crowd workers to explore data sets and helps analysts interactively examine and build upon workers' insights. We take advantage of the fact that, for many types of data, independent crowd workers can readily perform basic analysis tasks like examining views and generating explanations for trends and patterns. However, workers operating in parallel can often generate redundant explanations. Moreover, because workers have different competencies and domain knowledge, some responses are likely to be more plausible than others. To efficiently utilize the crowd's work, analysts must be able to quickly identify and consolidate redundant responses and determine which explanations are the most plausible. In this paper, we demonstrate several crowd-assisted techniques to help analysts make better use of crowdsourced explanations: (1) We explore crowd-assisted strategies that utilize multiple workers to detect redundant explanations. We introduce color clustering with representative selection-a strategy in which multiple workers cluster explanations and we automatically select the most-representative result-and show that it generates clusterings that are as good as those produced by experts. (2) We capture explanation provenance by introducing highlighting tasks and capturing workers' browsing behavior via an embedded web browser, and refine that provenance information via source-review tasks. We expose this information in an explanation-management interface that allows analysts to interactively filter and sort responses, select the most plausible explanations, and decide which to explore further.",Wesley Willett;Shiry Ginosar;Avital Steinitz;Björn Hartmann;Maneesh Agrawala,Wesley Willett;Shiry Ginosar;Avital Steinitz;Björn Hartmann;Maneesh Agrawala,"INRIA, France;University of California, Berkeley, USA;University of California, Berkeley, USA;University of California, Berkeley, USA;University of California, Berkeley, USA",10.1109/tvcg.2007.70577;10.1109/tvcg.2007.70577,"Crowdsourcing, social data analysis",38.0,24.0,23.0,847.0,,,crowdsourced explanations explore;analysts make;browser refine provenance;utilize multiple workers;filter sort,0.7458;0.3675;0.2448;0.2381;0.0873,"[np.int64(-1), -1, -1, -1, -1]",81;-1;-1;-1;-1,81,81
Vis,2007,CoViCAD: Comprehensive Visualization of Coronary Artery Disease,10.1109/tvcg.2007.70550,http://dx.doi.org/10.1109/TVCG.2007.70550,1632.0,1639.0,J,"We present novel, comprehensive visualization techniques for the diagnosis of patients with coronary artery disease using segmented cardiac MRI data. We extent an accepted medical visualization technique called the bull's eye plot by removing discontinuities, preserving the volumetric nature of the left ventricular wall and adding anatomical context. The resulting volumetric bull's eye plot can be used for the assessment of transmurality. We link these visualizations to a 3D view that presents viability information in a detailed anatomical context. We combine multiple MRI scans (whole heart anatomical data, late enhancement data) and multiple segmentations (polygonal heart model, late enhancement contours, coronary artery tree). By selectively combining different rendering techniques we obtain comprehensive yet intuitive visualizations of the various data sources.",Maurice Termeer;Javier Oliván Bescós;Marcel Breeuwer;Anna Vilanova;Frans A. Gerritsen;M. Eduard Gröller,Maurice Termeer;Javier Oliván Bescós;Marcel Breeuwer;Anna Vilanova;Frans Gerritsen;Eduard Gröller,"Institute of Computer Graphics and Algorithms, Vienna University of Technology, Austria;Philips Medical Systems;Philips Medical Systems, Netherlands;Eindhoven University of Technology, Netherlands;Philips Medical Systems, Netherlands;Institute of Computer Graphics and Algorithms, Vienna University of Technology, Austria",10.1109/visual.2003.1250386;10.1109/visual.2002.1183754;10.1109/tvcg.2006.152;10.1109/visual.2004.104;10.1109/visual.2003.1250386,"Cardiac MRI, late enhancement, viability, bull's eye plot",68.0,41.0,14.0,569.0,,,segmented cardiac mri;intuitive visualizations;transmurality link;viability information;called bull,0.6329;0.4175;0.1724;0.1453;0.0838,"[np.int64(-1), -1, -1, -1, -1]",132;-1;-1;-1;-1,132,132
VAST,2019,Galex: Exploring the Evolution and Intersection of Disciplines,10.1109/tvcg.2019.2934667,http://dx.doi.org/10.1109/TVCG.2019.2934667,1182.0,1192.0,J,"Revealing the evolution of science and the intersections among its sub-fields is extremely important to understand the characteristics of disciplines, discover new topics, and predict the future. The current work focuses on either building the skeleton of science, lacking interaction, detailed exploration and interpretation or on the lower topic level, missing high-level macro-perspective. To fill this gap, we design and implement Galaxy Evolution Explorer (Galex), a hierarchical visual analysis system, in combination with advanced text mining technologies, that could help analysts to comprehend the evolution and intersection of one discipline rapidly. We divide Galex into three progressively fine-grained levels: discipline, area, and institution levels. The combination of interactions enables analysts to explore an arbitrary piece of history and an arbitrary part of the knowledge space of one discipline. Using a flexible spotlight component, analysts could freely select and quickly understand an exploration region. A tree metaphor allows analysts to perceive the expansion, decline, and intersection of topics intuitively. A synchronous spotlight interaction aids in comparing research contents among institutions easily. Three cases demonstrate the effectiveness of our system.",Zeyu Li 0003;Changhong Zhang;Shichao Jia;Jiawan Zhang,Zeyu Li;Changhong Zhang;Shichao Jia;Jiawan Zhang,"College of Intelligence and Computing, Tianjin University;College of Intelligence and Computing, Tianjin University;College of Intelligence and Computing, Tianjin University;College of Intelligence and Computing, Tianjin University and Tianjin cultural heritage conservation and inheritance engineering technology center, Key Research Center for Surface Monitoring and Analysis of Relics, State Administration of Cultural Heritage, China",10.1109/vast.2009.5333443;10.1109/tvcg.2011.239;10.1109/vast.2012.6400485;10.1109/tvcg.2013.162;10.1109/visual.1996.568118;10.1109/tvcg.2015.2467621;10.1109/vast.2016.7883507;10.1109/tvcg.2016.2598827;10.1109/infvis.2004.22;10.1109/tvcg.2018.2865022;10.1109/vast.2014.7042494;10.1109/vast.2007.4389006;10.1109/tvcg.2018.2864912;10.1109/infvis.1995.528686;10.1109/tvcg.2013.167;10.1109/vast.2009.5333443,"Science evolution,science mapping,interdisciplinary,knowledge domain visualization,visual analysis",23.0,9.0,66.0,992.0,,,disciplines discover;visual analysis combination;flexible spotlight component;tree metaphor;history arbitrary,0.5635;0.3582;0.2658;0.2220;0.1485,"[np.int64(-1), -1, -1, -1, -1]",280;-1;-1;-1;-1,280,280
VAST,2009,A framework for uncertainty-aware visual analytics,10.1109/vast.2009.5332611,http://dx.doi.org/10.1109/VAST.2009.5332611,51.0,58.0,C,"Visual analytics has become an important tool for gaining insight on large and complex collections of data. Numerous statistical tools and data transformations, such as projections, binning and clustering, have been coupled with visualization to help analysts understand data better and faster. However, data is inherently uncertain, due to error, noise or unreliable sources. When making decisions based on uncertain data, it is important to quantify and present to the analyst both the aggregated uncertainty of the results and the impact of the sources of that uncertainty. In this paper, we present a new framework to support uncertainty in the visual analytics process, through statistic methods such as uncertainty modeling, propagation and aggregation. We show that data transformations, such as regression, principal component analysis and k-means clustering, can be adapted to account for uncertainty. This framework leads to better visualizations that improve the decision-making process and help analysts gain insight on the analytic process itself.",Carlos D. Correa;Yu-Hsuan Chan;Kwan-Liu Ma,Carlos D. Correa;Yu-Hsuan Chan;Kwan-Liu Ma,"University of California,슠Davis, USA;University of California Davis, USA;University of California,슠Davis, USA",10.1109/vast.2008.4677368;10.1109/vast.2007.4389000,"Uncertainty, Data Transformations, Principal Component Analysis, Model fitting",154.0,68.0,35.0,1357.0,,,uncertainty visual analytics;means clustering;principal component;impact sources;adapted,0.8087;0.3492;0.1777;0.1376;0.0595,"[np.int64(-1), -1, -1, -1, -1]",159;-1;-1;-1;-1,159,159
Vis,2005,Exploiting frame-to-frame coherence for accelerating high-quality volume raycasting on graphics hardware,10.1109/visual.2005.1532799,http://dx.doi.org/10.1109/VISUAL.2005.1532799,223.0,230.0,C,GPU-based raycasting offers an interesting alternative to conventional slice-based volume rendering due to the inherent flexibility and the high quality of the generated images. Recent advances in graphics hardware allow for the ray traversal and volume sampling to be executed on a per-fragment level completely on the GPU leading to interactive framerates. In this work we present optimization techniques that improve the performance and quality of GPU-based volume raycasting. We apply a hybrid image/object space approach to accelerate the ray traversal in animation sequences that works for both isosurface rendering and semi-transparent volume rendering. An empty-space-leaping technique that exploits the spatial coherence between consecutively rendered images is used to estimate the optimal initial ray sampling point for each image pixel. These can double the rendering performance for typical volumetric data sets without sacrificing image quality. The achieved speed-up allows for further improvements of image quality. We demonstrate an object space antialiasing technique based on selective super-sampling at sharp creases and silhouette edges which also benefits from exploiting frame-to-frame coherence.,Thomas Klein;Magnus Strengert;Simon Stegmaier;Thomas Ertl,T. Klein;M. Strengert;S. Stegmaier;T. Ertl,"Institute for Visualization and Interactive Systems, University of Stuttgart, Germany;Institute for Visualization and Interactive Systems, University of Stuttgart, Germany;Institute for Visualization and Interactive Systems, University of Stuttgart, Germany;Institute for Visualization and Interactive Systems, University of Stuttgart, Germany",10.1109/visual.2002.1183764;10.1109/visual.1993.398852;10.1109/visual.2001.964521;10.1109/visual.2003.1250388;10.1109/visual.2002.1183775;10.1109/visual.2003.1250390;10.1109/visual.2002.1183776;10.1109/visual.2003.1250384;10.1109/visual.2004.63;10.1109/visual.2002.1183764,"Volume Raycasting, Programmable Graphics Hardware, Frame-to-Frame Coherence, Space Leaping",66.0,4.0,24.0,217.0,,,based volume raycasting;completely gpu;consecutively rendered images;estimate optimal initial;improve,0.6639;0.3649;0.2670;0.0824;-0.0025,"[np.int64(-1), -1, -1, -1, -1]",256;-1;-1;-1;-1,256,256
Vis,2021,Lumos: Increasing Awareness of Analytic Behavior during Visual Data Analysis,10.1109/tvcg.2021.3114827,http://dx.doi.org/10.1109/TVCG.2021.3114827,1009.0,1018.0,J,"Visual data analysis tools provide people with the agency and flexibility to explore data using a variety of interactive functionalities. However, this flexibility may introduce potential consequences in situations where users unknowingly overemphasize or underemphasize specific subsets of the data or attribute space they are analyzing. For example, users may overemphasize specific attributes and/or their values (e.g., Gender is always encoded on the X axis), underemphasize others (e.g., Religion is never encoded), ignore a subset of the data (e.g., older people are filtered out), etc. In response, we present Lumos, a visual data analysis tool that captures and shows the interaction history with data to increase awareness of such analytic behaviors. Using in-situ (at the place of interaction) and ex-situ (in an external view) visualization techniques, Lumos provides real-time feedback to users for them to reflect on their activities. For example, Lumos highlights datapoints that have been previously examined in the same visualization (in-situ) and also overlays them on the underlying data distribution (i.e., baseline distribution) in a separate visualization (ex-situ). Through a user study with 24 participants, we investigate how Lumos helps users' data exploration and decision-making processes. We found that Lumos increases users' awareness of visual data analysis practices in real-time, promoting reflection upon and acknowledgement of their intentions and potentially influencing subsequent interactions.",Arpit Narechania;Adam Coscia;Emily Wall;Alex Endert,Arpit Narechania;Adam Coscia;Emily Wall;Alex Endert,"Georgia Institute of Technology, United States;Georgia Institute of Technology, United States;Emory University, United States;Georgia Institute of Technology, United States",10.1109/vast.2017.8585665;10.1109/tvcg.2016.2598594;10.1109/tvcg.2016.2599058;10.1109/tvcg.2018.2865117;10.1109/tvcg.2008.137;10.1109/tvcg.2014.2346452;10.1109/tvcg.2015.2467551;10.1109/tvcg.2016.2598466;10.1109/tvcg.2017.2744138;10.1109/vast.2017.8585669;10.1109/tvcg.2021.3114862;10.1109/tvcg.2007.70589;10.1109/vast.2017.8585665,"visual data analysis,interaction traces,analytic provenance,awareness,human bias",6.0,10.0,38.0,665.0,,,examined visualization;older people;agency flexibility;lumos helps;religion encoded ignore,0.5747;0.2477;0.1437;0.1243;0.0319,"[np.int64(-1), -1, -1, -1, -1]",208;-1;-1;-1;-1,208,208
InfoVis,2014,"Overview: The Design, Adoption, and Analysis of a Visual Document Mining Tool for Investigative Journalists",10.1109/tvcg.2014.2346431,http://dx.doi.org/10.1109/TVCG.2014.2346431,2271.0,2280.0,J,"For an investigative journalist, a large collection of documents obtained from a Freedom of Information Act request or a leak is both a blessing and a curse: such material may contain multiple newsworthy stories, but it can be difficult and time consuming to find relevant documents. Standard text search is useful, but even if the search target is known it may not be possible to formulate an effective query. In addition, summarization is an important non-search task. We present Overview, an application for the systematic analysis of large document collections based on document clustering, visualization, and tagging. This work contributes to the small set of design studies which evaluate a visualization system “in the wild”, and we report on six case studies where Overview was voluntarily used by self-initiated journalists to produce published stories. We find that the frequently-used language of “exploring” a document collection is both too vague and too narrow to capture how journalists actually used our application. Our iterative process, including multiple rounds of deployment and observations of real world usage, led to a much more specific characterization of tasks. We analyze and justify the visual encoding and interaction techniques used in Overview's design with respect to our final task abstractions, and propose generalizable lessons for visualization design methodology.",Matthew Brehmer;Stephen Ingram;Jonathan Stray;Tamara Munzner,Matthew Brehmer;Stephen Ingram;Jonathan Stray;Tamara Munzner,University of British Columbia;University of British Columbia;Columbia Journalism School and the Associated Press;University of British Columbia,10.1109/tvcg.2009.127;10.1109/infvis.2004.19;10.1109/tvcg.2012.224;10.1109/tvcg.2012.213;10.1109/tvcg.2012.260;10.1109/tvcg.2009.140;10.1109/tvcg.2013.162;10.1109/tvcg.2013.153;10.1109/tvcg.2009.148;10.1109/tvcg.2013.124;10.1109/tvcg.2011.239;10.1109/vast.2010.5652940;10.1109/tvcg.2011.209;10.1109/tvcg.2009.127,"Design study, investigative journalism, task and requirements analysis, text and document data, text analysis",128.0,60.0,53.0,2713.0,,,document clustering visualization;journalist large collection;task abstractions propose;obtained freedom information;rounds deployment,0.6350;0.4744;0.3392;0.0859;0.0395,"[np.int64(-1), -1, -1, -1, -1]",167;-1;-1;-1;-1,167,167
VAST,2007,TextPlorer: An application supporting text analysis,10.1109/vast.2007.4389019,http://dx.doi.org/10.1109/VAST.2007.4389019,205.0,206.0,M,"TexPlorer is an integrated system for exploring and analyzing large amounts of text documents. The data processing modules of TexPlorer consist of named entity extraction, entity relation extraction, hierarchical clustering, and text summarization tools. Using a timeline tool, tree-view, table-view, and concept maps, TexPlorer provides an analytical interface for exploring a set of text documents from different perspectives and allows users to explore vast amount of text documents efficiently.",Chi-Chun Pan;Anuj R. Jaiswal;Junyan Luo;Anthony C. Robinson,Chi-Chun Pan;Anuj R. Jaiswal;Junyan Luo;Anthony Robinson,"Pennsylvania State University, USA;Pennsylvania State University, USA;Pennsylvania State University, USA;Pennsylvania State University, USA",0.1109/vast.2007.4388991,,3.0,0.0,3.0,231.0,,,text documents data;extraction hierarchical clustering;processing modules texplorer;integrated exploring;named,0.5623;0.4652;0.4352;0.1890;0.0642,"[np.int64(-1), -1, -1, -1, -1]",243;-1;-1;-1;-1,243,243
VAST,2011,Using random projections to identify class-separating variables in high-dimensional spaces,10.1109/vast.2011.6102465,http://dx.doi.org/10.1109/VAST.2011.6102465,263.0,264.0,M,"Projection Pursuit has been an effective method for finding interesting low-dimensional (usually 2D) projections in multidimensional spaces. Unfortunately, projection pursuit is not scalable to high-dimensional spaces. We introduce a novel method for approximating the results of projection pursuit to find class-separating views by using random projections. We build an analytic visualization platform based on this algorithm that is scalable to extremely large problems. Then, we discuss its extension to the recognition of other noteworthy configurations in high-dimensional spaces.",Anushka Anand;Leland Wilkinson;Dang Tuan Nhon,Anushka Anand;Leland Wilkinson;Tuan Nhon Dang,"Department of Computer Science, University of Illinois, Chicago, USA;Department of Computer Science, University of Illinois, Chicago, USA;Department of Computer Science, University of Illinois, Chicago, USA",,,3.0,1.0,12.0,153.0,,,random projections;class separating views;analytic visualization platform;extremely large problems;noteworthy,0.6326;0.3176;0.2885;0.2668;0.1547,"[np.int64(-1), -1, -1, -1, -1]",37;-1;-1;-1;-1,37,37
VAST,2015,Interactive visual steering of hierarchical simulation ensembles,10.1109/vast.2015.7347635,http://dx.doi.org/10.1109/VAST.2015.7347635,89.0,96.0,C,"Multi-level simulation models, i.e., models where different components are simulated using sub-models of varying levels of complexity, belong to the current state-of-the-art in simulation. The existing analysis practice for multi-level simulation results is to manually compare results from different levels of complexity, amounting to a very tedious and error-prone, trial-and-error exploration process. In this paper, we introduce hierarchical visual steering, a new approach to the exploration and design of complex systems. Hierarchical visual steering makes it possible to explore and analyze hierarchical simulation ensembles at different levels of complexity. At each level, we deal with a dynamic simulation ensemble - the ensemble grows during the exploration process. There is at least one such ensemble per simulation level, resulting in a collection of dynamic ensembles, analyzed simultaneously. The key challenge is to map the multi-dimensional parameter space of one ensemble to the multi-dimensional parameter space of another ensemble (from another level). In order to support the interactive visual analysis of such complex data we propose a novel approach to interactive and semi-automatic parameter space segmentation and comparison. The approach combines a novel interaction technique and automatic, computational methods - clustering, concave hull computation, and concave polygon overlapping - to support the analysts in the cross-ensemble parameter space mapping. In addition to the novel parameter space segmentation we also deploy coordinated multiple views with standard plots. We describe the abstract analysis tasks, identified during a case study, i.e., the design of a variable valve actuation system of a car engine. The study is conducted in cooperation with experts from the automotive industry. Very positive feedback indicates the usefulness and efficiency of the newly proposed approach.",Rainer Splechtna;Kresimir Matkovic;Denis Gracanin;Mario Jelovic;Helwig Hauser,Rainer Splechtna;Krešimir Matković;Denis Gračanin;Mario Jelović;Helwig Hauser,"VRVis Research Center in Vienna, Austria;VRVis Research Center in Vienna, Austria;Virginia Tech, Blacksburg, VA, USA;AVL-AST, Zagreb, Croatia;University of Bergen, Norway",10.1109/tvcg.2008.145;10.1109/tvcg.2014.2346744;10.1109/tvcg.2014.2346321;10.1109/vast.2009.5333081;10.1109/tvcg.2010.223,"Interactive Visual Analysis, Simulation-Ensemble Steering, Multi-resolution simulation",19.0,12.0,20.0,462.0,,,analyze hierarchical simulation;actuation car engine;dimensional parameter space;concave hull;views standard,0.5912;0.2810;0.2453;0.1692;0.0565,"[np.int64(-1), -1, -1, -1, -1]",0;-1;-1;-1;-1,0,0
InfoVis,2009,Configuring Hierarchical Layouts to Address Research Questions,10.1109/tvcg.2009.128,http://dx.doi.org/10.1109/TVCG.2009.128,977.0,984.0,J,"We explore the effects of selecting alternative layouts in hierarchical displays that show multiple aspects of large multivariate datasets, including spatial and temporal characteristics. Hierarchical displays of this type condition a dataset by multiple discrete variable values, creating nested graphical summaries of the resulting subsets in which size, shape and colour can be used to show subset properties. These 'small multiples' are ordered by the conditioning variable values and are laid out hierarchically using dimensional stacking. Crucially, we consider the use of different layouts at different hierarchical levels, so that the coordinates of the plane can be used more effectively to draw attention to trends and anomalies in the data. We argue that these layouts should be informed by the type of conditioning variable and by the research question being explored. We focus on space-filling rectangular layouts that provide data-dense and rich overviews of data to address research questions posed in our exploratory analysis of spatial and temporal aspects of property sales in London. We develop a notation ('HiVE') that describes visualisation and layout states and provides reconfiguration operators, demonstrate its use for reconfiguring layouts to pursue research questions and provide guidelines for this process. We demonstrate how layouts can be related through animated transitions to reduce the cognitive load associated with their reconfiguration whilst supporting the exploratory process.",Aidan Slingsby;Jason Dykes;Jo Wood,Aidan Slingsby;Jason Dykes;Jo Wood,"Department of Information Science, City University of London, UK;Department of Information Science, City University of London, UK;Department of Information Science, City University of London, UK",10.1109/tvcg.2007.70515;10.1109/infvis.2003.1249006;10.1109/visual.1990.146386;10.1109/tvcg.2008.125;10.1109/tvcg.2007.70539;10.1109/visual.2002.1183791;10.1109/tvcg.2008.165;10.1109/tvcg.2007.70515,"Geovisualization, hierarchical, layout, guidelines, exploratory, notation",112.0,61.0,38.0,1003.0,HM,,describes visualisation layout;property sales;animated transitions reduce;conditioning variable values;address research questions,0.6387;0.2346;0.2240;0.1211;0.0741,"[np.int64(-1), -1, -1, -1, -1]",183;-1;-1;-1;-1,183,183
Vis,2007,Visualizing Whole-Brain DTI Tractography with GPU-based Tuboids and LoD Management,10.1109/tvcg.2007.70532,http://dx.doi.org/10.1109/TVCG.2007.70532,1488.0,1495.0,J,"Diffusion tensor imaging (DTI) of the human brain, coupled with tractography techniques, enable the extraction of large- collections of three-dimensional tract pathways per subject. These pathways and pathway bundles represent the connectivity between different brain regions and are critical for the understanding of brain related diseases. A flexible and efficient GPU-based rendering technique for DTI tractography data is presented that addresses common performance bottlenecks and image-quality issues, allowing interactive render rates to be achieved on commodity hardware. An occlusion query-based pathway LoD management system for streamlines/streamtubes/tuboids is introduced that optimizes input geometry, vertex processing, and fragment processing loads, and helps reduce overdraw. The tuboid, a fully-shaded streamtube impostor constructed entirely on the GPU from streamline vertices, is also introduced. Unlike full streamtubes and other impostor constructs, tuboids require little to no preprocessing or extra space over the original streamline data. The supported fragment processing levels of detail range from texture-based draft shading to full raycast normal computation, Phong shading, environment mapping, and curvature-correct text labeling. The presented text labeling technique for tuboids provides adaptive, aesthetically pleasing labels that appear attached to the surface of the tubes. Furthermore, an occlusion query aggregating and scheduling scheme for tuboids is described that reduces the query overhead. Results for a tractography dataset are presented, and demonstrate that LoD-managed tuboids offer benefits over traditional streamtubes both in performance and appearance.",Vid Petrovic;James H. Fallon;Falko Kuester,Vid Petrovic;James Fallon;Falko Kuester,"Calit2 at the University of California, Irvine, USA;University of California, Irvine, USA;Calit2 at the University of California, San Diego, USA",10.1109/visual.2002.1183799;10.1109/visual.2005.1532859;10.1109/visual.2004.30;10.1109/tvcg.2006.151;10.1109/visual.2003.1250368;10.1109/tvcg.2006.197;10.1109/visual.1996.567777;10.1109/visual.2002.1183799,"Tuboids, stream tubes, interactive gpu-centric rendering, neuronal pathways",69.0,36.0,23.0,678.0,,,diffusion tensor imaging;streamline data supported;occlusion query based;pleasing labels;helps reduce,0.5722;0.3222;0.2673;0.1625;0.0997,"[np.int64(-1), -1, -1, -1, -1]",43;-1;-1;-1;-1,43,43
InfoVis,2005,Flow map layout,10.1109/infvis.2005.1532150,http://dx.doi.org/10.1109/INFVIS.2005.1532150,219.0,224.0,C,"Cartographers have long used flow maps to show the movement of objects from one location to another, such as the number of people in a migration, the amount of goods being traded, or the number of packets in a network. The advantage of flow maps is that they reduce visual clutter by merging edges. Most flow maps are drawn by hand and there are few computer algorithms available. We present a method for generating flow maps using hierarchical clustering given a set of nodes, positions, and flow data between the nodes. Our techniques are inspired by graph layout algorithms that minimize edge crossings and distort node positions while maintaining their relative position to one another. We demonstrate our technique by producing flow maps for network traffic, census data, and trade data.",Doantam Phan;Ling Xiao 0005;Ron B. Yeh;Pat Hanrahan;Terry Winograd,Doantam Phan;Ling Xiao;R. Yeh;P. Hanrahan;Terry Winograd,Stanford University;Stanford University;Stanford University;Stanford University;Stanford University,10.1109/infvis.1995.528697;10.1109/infvis.1996.559226;10.1109/infvis.1995.528697,"flow maps, GIS, hierarchical clustering",423.0,33.0,21.0,1813.0,,,flow maps;using hierarchical clustering;census data;crossings distort node;traded number,0.5829;0.4706;0.3160;0.2538;0.0380,"[np.int64(-1), -1, -1, -1, -1]",130;-1;-1;-1;-1,130,130
SciVis,2014,Multi-Charts for Comparative 3D Ensemble Visualization,10.1109/tvcg.2014.2346448,http://dx.doi.org/10.1109/TVCG.2014.2346448,2694.0,2703.0,J,"A comparative visualization of multiple volume data sets is challenging due to the inherent occlusion effects, yet it is important to effectively reveal uncertainties, correlations and reliable trends in 3D ensemble fields. In this paper we present bidirectional linking of multi-charts and volume visualization as a means to analyze visually 3D scalar ensemble fields at the data level. Multi-charts are an extension of conventional bar and line charts: They linearize the 3D data points along a space-filling curve and draw them as multiple charts in the same plot area. The bar charts encode statistical information on ensemble members, such as histograms and probability densities, and line charts are overlayed to allow comparing members against the ensemble. Alternative linearizations based on histogram similarities or ensemble variation allow clustering of spatial locations depending on data distribution. Multi-charts organize the data at multiple scales to quickly provide overviews and enable users to select regions exhibiting interesting behavior interactively. They are further put into a spatial context by allowing the user to brush or query value intervals and specific distributions, and to simultaneously visualize the corresponding spatial points via volume rendering. By providing a picking mechanism in 3D and instantly highlighting the corresponding data points in the chart, the user can go back and forth between the abstract and the 3D view to focus the analysis.",Ismail Demir;Christian Dick;Rüdiger Westermann,Ismail Demir;Christian Dick;Rüdiger Westermann,"Computer Graphics and Visualization Group, Technische Universität München Informatik 15, Garching, Germany;Computer Graphics and Visualization Group, Technische Universität München Informatik 15, Garching, Germany;Computer Graphics and Visualization Group, Technische Universität München Informatik 15, Garching, Germany",10.1109/tvcg.2013.143;10.1109/visual.2000.885739;10.1109/tvcg.2006.159;10.1109/tvcg.2008.139;10.1109/tvcg.2007.70518;10.1109/tvcg.2010.181;10.1109/tvcg.2009.198;10.1109/infvis.2002.1173157;10.1109/visual.1999.809921;10.1109/tvcg.2013.143,"Ensemble visualization, brushing and linking, statistical analysis",86.0,57.0,57.0,1463.0,,,volume visualization;ensemble members;reliable trends;comparative;bidirectional linking,0.6491;0.2625;0.2083;0.1189;-0.0377,"[np.int64(-1), -1, -1, -1, -1]",84;-1;-1;-1;-1,84,84
VAST,2020,"StackGenVis: Alignment of Data, Algorithms, and Models for Stacking Ensemble Learning Using Performance Metrics",10.1109/tvcg.2020.3030352,http://dx.doi.org/10.1109/TVCG.2020.3030352,1547.0,1557.0,J,"In machine learning (ML), ensemble methods-such as bagging, boosting, and stacking-are widely-established approaches that regularly achieve top-notch predictive performance. Stacking (also called “stacked generalization”) is an ensemble method that combines heterogeneous base models, arranged in at least one layer, and then employs another metamodel to summarize the predictions of those models. Although it may be a highly-effective approach for increasing the predictive performance of ML, generating a stack of models from scratch can be a cumbersome trial-and-error process. This challenge stems from the enormous space of available solutions, with different sets of data instances and features that could be used for training, several algorithms to choose from, and instantiations of these algorithms using diverse parameters (i.e., models) that perform differently according to various metrics. In this work, we present a knowledge generation model, which supports ensemble learning with the use of visualization, and a visual analytics system for stacked generalization. Our system, StackGenVis, assists users in dynamically adapting performance metrics, managing data instances, selecting the most important features for a given data set, choosing a set of top-performant and diverse algorithms, and measuring the predictive performance. In consequence, our proposed tool helps users to decide between distinct models and to reduce the complexity of the resulting stack by removing overpromising and underperforming models. The applicability and effectiveness of StackGenVis are demonstrated with two use cases: a real-world healthcare data set and a collection of data related to sentiment/stance detection in texts. Finally, the tool has been evaluated through interviews with three ML experts.",Angelos Chatzimparmpas;Rafael Messias Martins;Kostiantyn Kucher;Andreas Kerren,Angelos Chatzimparmpas;Rafael M. Martins;Kostiantyn Kucher;Andreas Kerren,"Linnaeus University, Växjö, Sweden;Linnaeus University, Växjö, Sweden;Linnaeus University, Växjö, Sweden;Linnaeus University, Växjö, Sweden",10.1109/tvcg.2013.124;10.1109/tvcg.2017.2744378;10.1109/tvcg.2019.2934631;10.1109/tvcg.2019.2934267;10.1109/tvcg.2018.2865240;10.1109/tvcg.2013.125;10.1109/tvcg.2015.2467551;10.1109/tvcg.2014.2346481;10.1109/tvcg.2014.2346574;10.1109/tvcg.2018.2864825;10.1109/tvcg.2018.2864499;10.1109/tvcg.2018.2864475;10.1109/tvcg.2013.124,"Stacking,stacked generalization,ensemble learning,visual analytics,visualization",32.0,56.0,68.0,1679.0,,,stacked generalization ensemble;use visualization;sentiment stance;layer employs metamodel;set collection,0.6135;0.3376;0.3196;0.1760;0.1195,"[np.int64(-1), -1, -1, -1, -1]",50;-1;-1;-1;-1,50,50
InfoVis,2003,Between aesthetics and utility: designing ambient information visualizations,10.1109/infvis.2003.1249031,http://dx.doi.org/10.1109/INFVIS.2003.1249031,233.0,240.0,C,"Unlike traditional information visualization, ambient information visualizations reside in the environment of the user rather than on the screen of a desktop computer. Currently, most dynamic information that is displayed in public places consists of text and numbers. We argue that information visualization can be employed to make such dynamic data more useful and appealing. However, visualizations intended for non-desktop spaces will have to both provide valuable information and present an attractive addition to the environment - they must strike a balance between aesthetical appeal and usefulness. To explore this, we designed a real-time visualization of bus departure times and deployed it in a public space, with about 300 potential users. To make the presentation more visually appealing, we took inspiration from a modern abstract artist. The visualization was designed in two passes. First, we did a preliminary version that was presented to and discussed with prospective users. Based on their input, we did a final design. We discuss the lessons learned in designing this and previous ambient information visualizations, including how visual art can be used as a design constraint, and how the choice of information and the placement of the display affect the visualization.",Tobias Skog;Sara Ljungblad;Lars Erik Holmquist,T. Skog;S. Ljungblad;L.E. Holmquist,"Viktoria Institute, Future Applications Laboratory, Sweden;Viktoria Institute, Future Applications Laboratory, Sweden;Viktoria Institute, Future Applications Laboratory",,"Ambient information visualization, informative art, ambient displays, calm technology",177.0,34.0,20.0,1299.0,,,ambient information visualizations;bus departure times;unlike traditional;used design constraint;strike,0.6959;0.3251;0.1422;0.1301;0.0273,"[np.int64(-1), -1, -1, -1, -1]",-1;-1;-1;-1;-1,,-1
Vis,2011,The FLOWLENS: A Focus-and-Context Visualization Approach for Exploration of Blood Flow in Cerebral Aneurysms,10.1109/tvcg.2011.243,http://dx.doi.org/10.1109/TVCG.2011.243,2183.0,2192.0,J,"Blood flow and derived data are essential to investigate the initiation and progression of cerebral aneurysms as well as their risk of rupture. An effective visual exploration of several hemodynamic attributes like the wall shear stress (WSS) and the inflow jet is necessary to understand the hemodynamics. Moreover, the correlation between focus-and-context attributes is of particular interest. An expressive visualization of these attributes and anatomic information requires appropriate visualization techniques to minimize visual clutter and occlusions. We present the FLOWLENS as a focus-and-context approach that addresses these requirements. We group relevant hemodynamic attributes to pairs of focus-and-context attributes and assign them to different anatomic scopes. For each scope, we propose several FLOWLENS visualization templates to provide a flexible visual filtering of the involved hemodynamic pairs. A template consists of the visualization of the focus attribute and the additional depiction of the context attribute inside the lens. Furthermore, the FLOWLENS supports local probing and the exploration of attribute changes over time. The FLOWLENS minimizes visual cluttering, occlusions, and provides a flexible exploration of a region of interest. We have applied our approach to seven representative datasets, including steady and unsteady flow data from CFD simulations and 4D PC-MRI measurements. Informal user interviews with three domain experts confirm the usefulness of our approach.",Rocco Gasteiger;Mathias Neugebauer;Oliver Beuing;Bernhard Preim,Rocco Gasteiger;Mathias Neugebauer;Oliver Beuing;Bernhard Preim,"Department of Simulation and Graphics, University of Magdeburg, Germany;Department of Simulation and Graphics, University of Magdeburg, Germany;Department of Neuroradiology, University Hospital Magdeburg, Germany;Department of Simulation and Graphics, University of Magdeburg, Germany",10.1109/tvcg.2010.166;10.1109/tvcg.2009.138;10.1109/tvcg.2010.153;10.1109/tvcg.2006.124;10.1109/tvcg.2009.126;10.1109/visual.2005.1532818;10.1109/tvcg.2010.166,"Flow Visualization, Focus-and-Context, Illustrative Rendering, Aneurysm",102.0,53.0,41.0,948.0,,,visual exploration hemodynamic;cerebral aneurysms risk;supports local probing;experts confirm;context attributes assign,0.7240;0.3923;0.1554;0.0984;0.0724,"[np.int64(-1), -1, -1, -1, -1]",133;-1;-1;-1;-1,133,133
InfoVis,2018,Hypothetical Outcome Plots Help Untrained Observers Judge Trends in Ambiguous Data,10.1109/tvcg.2018.2864909,http://dx.doi.org/10.1109/TVCG.2018.2864909,892.0,902.0,J,"Animated representations of outcomes drawn from distributions (hypothetical outcome plots, or HOPs) are used in the media and other public venues to communicate uncertainty. HOPs greatly improve multivariate probability estimation over conventional static uncertainty visualizations and leverage the ability of the visual system to quickly, accurately, and automatically process the summary statistical properties of ensembles. However, it is unclear how well HOPs support applied tasks resembling real world judgments posed in uncertainty communication. We identify and motivate an appropriate task to investigate realistic judgments of uncertainty in the public domain through a qualitative analysis of uncertainty visualizations in the news. We contribute two crowdsourced experiments comparing the effectiveness of HOPs, error bars, and line ensembles for supporting perceptual decision-making from visualized uncertainty. Participants infer which of two possible underlying trends is more likely to have produced a sample of time series data by referencing uncertainty visualizations which depict the two trends with variability due to sampling error. By modeling each participant's accuracy as a function of the level of evidence presented over many repeated judgments, we find that observers are able to correctly infer the underlying trend in samples conveying a lower level of evidence when using HOPs rather than static aggregate uncertainty visualizations as a decision aid. Modeling approaches like ours contribute theoretically grounded and richly descriptive accounts of user perceptions to visualization evaluation.",Alex Kale;Francis Nguyen;Matthew Kay 0001;Jessica Hullman,Alex Kale;Francis Nguyen;Matthew Kay;Jessica Hullman,University of Washington;University of Washington;University of Michigan;Northwestern University,10.1109/tvcg.2017.2743898;10.1109/tvcg.2007.70518;10.1109/tvcg.2017.2744359;10.1109/tvcg.2011.175;10.1109/tvcg.2014.2346298;10.1109/tvcg.2017.2743898,"uncertainty visualization,hypothetical outcome plots,psychometric functions",98.0,66.0,66.0,1368.0,,,making visualized uncertainty;trend;hypothetical outcome;used media public;using hops static,0.7447;0.2291;0.1691;0.0801;0.0506,"[np.int64(-1), -1, -1, -1, -1]",159;-1;-1;-1;-1,159,159
Vis,1998,Continuous cartogram construction,10.1109/visual.1998.745303,http://dx.doi.org/10.1109/VISUAL.1998.745303,197.0,204.0,C,"Area cartograms are used for visualizing geographically distributed data by attaching measurements to regions of a map and scaling the regions such that their areas are proportional to the measured quantities. A continuous area cartogram is a cartogram that is constructed without changing the underlying map topology. We present a new algorithm for the construction of continuous area cartograms that was developed by viewing their construction as a constrained optimization problem. The algorithm uses a relaxation method that exploits hierarchical resolution, constrained dynamics, and a scheme that alternates goals of achieving correct region areas and adjusting region shapes. It is compared favorably to existing methods in its ability to preserve region shape recognition cues, while still achieving high accuracy.",Donald H. House;Christopher J. Kocmoud,D.H. House;C.J. Kocmoud,"Visualization Lab., Texas A&M Univ., College Station, TX, USA;Texas Engineering Experiment Station, College Station, TX, USA and Texas Center for Applied Technology, Texas A and M University, USA",,"cartogram, value-by-area map, map transformation,anamorphosis, thematic cartography, constrained optimization",107.0,20.0,0.0,233.0,,,area cartograms;resolution constrained dynamics;changing underlying map;new algorithm;preserve,0.6887;0.2986;0.2426;0.1801;0.1292,"[np.int64(-1), -1, -1, -1, -1]",128;-1;-1;-1;-1,128,128
InfoVis,2009,Interactive Dimensionality Reduction Through User-defined Combinations of Quality Metrics,10.1109/tvcg.2009.153,http://dx.doi.org/10.1109/TVCG.2009.153,993.0,1000.0,J,"Multivariate data sets including hundreds of variables are increasingly common in many application areas. Most multivariate visualization techniques are unable to display such data effectively, and a common approach is to employ dimensionality reduction prior to visualization. Most existing dimensionality reduction systems focus on preserving one or a few significant structures in data. For many analysis tasks, however, several types of structures can be of high significance and the importance of a certain structure compared to the importance of another is often task-dependent. This paper introduces a system for dimensionality reduction by combining user-defined quality metrics using weight functions to preserve as many important structures as possible. The system aims at effective visualization and exploration of structures within large multivariate data sets and provides enhancement of diverse structures by supplying a range of automatic variable orderings. Furthermore it enables a quality-guided reduction of variables through an interactive display facilitating investigation of trade-offs between loss of structure and the number of variables to keep. The generality and interactivity of the system is demonstrated through a case scenario.",,Sara Johansson;Jimmy Johansson,"Norrköping Visualization and Interaction Studio (NVIS), Linköping University, Sweden;Norrköping Visualization and Interaction Studio (NVIS), Linköping University, Sweden",10.1109/infvis.2005.1532142;10.1109/infvis.2003.1249015;10.1109/infvis.1998.729559;10.1109/tvcg.2006.161;10.1109/infvis.2004.60;10.1109/infvis.2004.3;10.1109/infvis.2004.71;10.1109/tvcg.2008.138;10.1109/infvis.2004.15;10.1109/infvis.2005.1532142,"dimensionality reduction, interactivity, quality metrics, variable ordering",174.0,101.0,27.0,1552.0,,,multivariate visualization;quality guided reduction;significance importance;using weight functions;structure number,0.6924;0.4455;0.2089;0.1919;0.1396,"[np.int64(-1), -1, -1, -1, -1]",185;-1;-1;-1;-1,185,185
Vis,1994,Strata-various: multi-layer visualization of dynamics in software system behavior,10.1109/visual.1994.346322,http://dx.doi.org/10.1109/VISUAL.1994.346322,172.0,,C,"Current software visualization tools are inadequate for understanding, debugging, and tuning realistically complex applications. These tools often present only static structure, or they present dynamics from only a few of the many layers of a program and its underlying system. This paper introduces ""PV"", a prototype program visualization system which provides concurrent visual presentation of behavior from all layers, including: the program itself, user-level libraries, the operating system, and the hardware, as this behavior unfolds over time. PV juxtaposes views from different layers in order to facilitate visual correlation, and allows these views to be navigated in a coordinated fashion. This results in an extremely powerful mechanism for exploring application behavior. Experience is presented from actual use of PV in production settings with programmers facing real deadlines and serious performance problems.&lt;&lt;ETX&gt;&gt;",Doug Kimelman;Bryan S. Rosenburg;Tova Roth,D. Kimelman;B. Rosenburg;T. Roth,"IBM Thomas J. Watson Research Center, Yorktown Heights, NY, USA;IBM Thomas J. Watson Research Center, Yorktown Heights, NY, USA;IBM Thomas J. Watson Research Center, Yorktown Heights, NY, USA",,,61.0,14.0,18.0,87.0,,,program visualization;dynamics layers;deadlines performance problems;correlation;lt lt,0.7322;0.2253;0.2095;0.1141;0.0268,"[np.int64(-1), -1, -1, -1, -1]",196;-1;-1;-1;-1,196,196
SciVis,2012,Evaluation of Fast-Forward Video Visualization,10.1109/tvcg.2012.222,http://dx.doi.org/10.1109/TVCG.2012.222,2095.0,2103.0,J,"We evaluate and compare video visualization techniques based on fast-forward. A controlled laboratory user study (n = 24) was conducted to determine the trade-off between support of object identification and motion perception, two properties that have to be considered when choosing a particular fast-forward visualization. We compare four different visualizations: two representing the state-of-the-art and two new variants of visualization introduced in this paper. The two state-of-the-art methods we consider are frame-skipping and temporal blending of successive frames. Our object trail visualization leverages a combination of frame-skipping and temporal blending, whereas predictive trajectory visualization supports motion perception by augmenting the video frames with an arrow that indicates the future object trajectory. Our hypothesis was that each of the state-of-the-art methods satisfies just one of the goals: support of object identification or motion perception. Thus, they represent both ends of the visualization design. The key findings of the evaluation are that object trail visualization supports object identification, whereas predictive trajectory visualization is most useful for motion perception. However, frame-skipping surprisingly exhibits reasonable performance for both tasks. Furthermore, we evaluate the subjective performance of three different playback speed visualizations for adaptive fast-forward, a subdomain of video fast-forward.",Markus Höferlin;Kuno Kurzhals;Benjamin Höferlin;Gunther Heidemann;Daniel Weiskopf,Markus Höferlin;Kuno Kurzhals;Benjamin Höferlin;Gunther Heidemann;Daniel Weiskopf,"Visualization Research Center (VISUS), University of Stuttgart, Germany;Visualization Research Center (VISUS), University of Stuttgart, Germany;Computer Vision Group, Institute of Cognitive Science, University of Osnabrück, Germany;Computer Vision Group, Institute of Cognitive Science, University of Osnabrück, Germany;Visualization Research Center (VISUS), University of Stuttgart, Germany",10.1109/tvcg.2007.70542;10.1109/tvcg.2007.70617;10.1109/tvcg.2008.125;10.1109/tvcg.2007.70539;10.1109/tvcg.2006.194;10.1109/tvcg.2007.70542,"Video visualization, adaptive fast-forward, controlled laboratory user study",20.0,15.0,38.0,786.0,,,fast forward visualization;subdomain video;performance different;supports object;conducted,0.6229;0.2499;0.2070;0.1070;-0.0266,"[np.int64(-1), -1, -1, -1, -1]",121;-1;-1;-1;-1,121,121
Vis,1993,A climate simulation case study,10.1109/visual.1993.398900,http://dx.doi.org/10.1109/VISUAL.1993.398900,397.0,401.0,C,"A supercomputing-visualization facility for science and engineering applications was used for processing and visualizing supercomputer-generated data. This facility includes a vector-processing supercomputer, a graphics workstation, a general purpose workstation, a high-resolution color printer, a scanner, a film recorder, a video tape recorder, and a video laser disc recorder. The facility is using a network system to connect computers, workstations, and graphical input/output devices. The supercomputer generates time-dependent multivariate data using a global climate simulation model. Visualization software systems are used for visualizing these model-produced data. Visualization techniques including: iso-contouring, iso-surface generation, vectors and streamlines generation are used.&lt;&lt;ETX&gt;&gt;",P. C. Chen,P.C. Chen,"Fujitsu America, Inc., San Jose, CA, USA",,,15.0,2.0,4.0,77.0,,,supercomputing visualization;climate simulation model;generates;using network connect;recorder video laser,0.6332;0.5158;0.1520;0.1350;0.0829,"[np.int64(-1), np.int64(-1), -1, -1, -1]",175;48;-1;-1;-1,48;175,175
InfoVis,2013,Visualizing Fuzzy Overlapping Communities in Networks,10.1109/tvcg.2013.232,http://dx.doi.org/10.1109/TVCG.2013.232,2486.0,2495.0,J,"An important feature of networks for many application domains is their community structure. This is because objects within the same community usually have at least one property in common. The investigation of community structure can therefore support the understanding of object attributes from the network topology alone. In real-world systems, objects may belong to several communities at the same time, i.e., communities can overlap. Analyzing fuzzy community memberships is essential to understand to what extent objects contribute to different communities and whether some communities are highly interconnected. We developed a visualization approach that is based on node-link diagrams and supports the investigation of fuzzy communities in weighted undirected graphs at different levels of detail. Starting with the network of communities, the user can continuously drill down to the network of individual nodes and finally analyze the membership distribution of nodes of interest. Our approach uses layout strategies and further visual mappings to graphically encode the fuzzy community memberships. The usefulness of our approach is illustrated by two case studies analyzing networks of different domains: social networking and biological interactions. The case studies showed that our layout and visualization approach helps investigate fuzzy overlapping communities. Fuzzy vertices as well as the different communities to which they belong can be easily identified based on node color and position.",Corinna Vehlow;Thomas Reinhardt;Daniel Weiskopf,Corinna Vehlow;Thomas Reinhardt;Daniel Weiskopf,"VISUS, University of Stuttgart, Germany;VISUS, University of Stuttgart, Germany;University of Stuttgart, Germany",10.1109/visual.1993.398872;10.1109/infvis.2005.1532126;10.1109/tvcg.2011.186;10.1109/tvcg.2010.210;10.1109/tvcg.2009.122;10.1109/infvis.2004.43;10.1109/tvcg.2009.113;10.1109/visual.1993.398872,"Overlapping community visualization, fuzzy clustering, graph visualization, uncertainty visualization",57.0,43.0,52.0,1847.0,,,fuzzy overlapping communities;node link;showed layout visualization;understanding object attributes;helps,0.6199;0.2730;0.2530;0.2349;0.1090,"[np.int64(-1), -1, -1, -1, -1]",220;-1;-1;-1;-1,220,220
Vis,2024,HiRegEx: Interactive Visual Query and Exploration of Multivariate Hierarchical Data,10.1109/tvcg.2024.3456389,http://dx.doi.org/10.1109/TVCG.2024.3456389,699.0,709.0,J,"When using exploratory visual analysis to examine multivariate hierarchical data, users often need to query data to narrow down the scope of analysis. However, formulating effective query expressions remains a challenge for multivariate hierarchical data, particularly when datasets become very large. To address this issue, we develop a declarative grammar, HiRegEx (Hierarchical data Regular Expression), for querying and exploring multivariate hierarchical data. Rooted in the extended multi-level task topology framework for tree visualizations (e-MLTT), HiRegEx delineates three query targets (node, path, and subtree) and two aspects for querying these targets (features and positions), and uses operators developed based on classical regular expressions for query construction. Based on the HiRegEx grammar, we develop an exploratory framework for querying and exploring multivariate hierarchical data and integrate it into the TreeQueryER prototype system. The exploratory framework includes three major components: top-down pattern specification, bottom-up data-driven inquiry, and context-creation data overview. We validate the expressiveness of HiRegEx with the tasks from the e-MLTT framework and showcase the utility and effectiveness of TreeQueryER system through a case study involving expert users in the analysis of a citation tree dataset.",Guozheng Li 0002;Haotian Mi;Chi Harold Liu;Takayuki Itoh;Guoren Wang,Guozheng Li;Haotian Mi;Chi Harold Liu;Takayuki Itoh;Guoren Wang,"Beijing Institute of Technology, China;Beijing Institute of Technology, China;Beijing Institute of Technology, China;Ochanomizu University, Japan;Beijing Institute of Technology, China",10.1109/tvcg.2013.124;10.1109/tvcg.2017.2745278;10.1109/vast.2008.4677365;10.1109/tvcg.2020.3030360;10.1109/tvcg.2015.2467622;10.1109/tvcg.2018.2864886;10.1109/tvcg.2019.2934666;10.1109/tvcg.2022.3209354;10.1109/tvcg.2019.2934535;10.1109/tvcg.2017.2744938;10.1109/tvcg.2017.2744898;10.1109/tvcg.2016.2599030;10.1109/tvcg.2009.128;10.1109/tvcg.2023.3327388;10.1109/tvcg.2015.2467191;10.1109/tvcg.2016.2598664,"Multivariate hierarchical data,declarative grammar,,,visual query",,0.0,69.0,167.0,,,tree visualizations;querying exploring multivariate;users analysis citation;regular expression;expressiveness hiregex tasks,0.6114;0.3892;0.3707;0.2189;0.2097,"[np.int64(-1), -1, -1, -1, -1]",147;-1;-1;-1;-1,147,147
Vis,1990,Interactive investigation of fluid mechanics data sets,10.1109/visual.1990.146416,http://dx.doi.org/10.1109/VISUAL.1990.146416,435.0,,C,"FIELDVIEW, a visual analysis tool designed to facilitate the interactive investigation of fluid mechanics data sets by providing an easy-to-use interface to the flow field data, is presented. Operating on NASA Plot three-dimensional format data, FIELDVIEW computes scalar and vector flow quantities and displays them using a variety of representations, including animation. An interactive viewing interface allows free motion around the data under study to allow the researcher to locate and study the interesting flow features of three-dimensional fluid dynamic data.&lt;&lt;ETX&gt;&gt;",Steve M. Legensky,S.M. Legensky,Intelligent Light,,,17.0,6.0,5.0,57.0,,,fluid mechanics data;including animation interactive;operating nasa;fieldview;computes scalar vector,0.6195;0.2611;0.2397;0.2028;0.1336,"[np.int64(-1), -1, -1, -1, -1]",307;-1;-1;-1;-1,307,307
Vis,2023,LiberRoad: Probing into the Journey of Chinese Classics Through Visual Analytics,10.1109/tvcg.2023.3326944,http://dx.doi.org/10.1109/TVCG.2023.3326944,529.0,539.0,J,"Books act as a crucial carrier of cultural dissemination in ancient times. This work involves joint efforts between visualization and humanities researchers, aiming at building a holistic view of the cultural exchange and integration between China and Japan brought about by the overseas circulation of Chinese classics. Book circulation data consist of uncertain spatiotemporal trajectories, with multiple dimensions, and movement across hierarchical spaces forms a compound network. LiberRoad visualizes the circulation of books collected in the Imperial Household Agency of Japan, and can be generalized to other book movement data. The LiberRoad system enables a smooth transition between three views (Location Graph, map, and timeline) according to the desired perspectives (spatial or temporal), as well as flexible filtering and selection. The Location Graph is a novel uncertainty-aware visualization method that employs improved circle packing to represent spatial hierarchy. The map view intuitively shows the overall circulation by clustering and allows zooming into single book trajectory with lenses magnifying local movements. The timeline view ranks dynamically in response to user interaction to facilitate the discovery of temporal events. The evaluation and feedback from the expert users demonstrate that LiberRoad is helpful in revealing movement patterns and comparing circulation characteristics of different times and spaces.",Yuhan Guo;Yuchu Luo;Keer Lu;Linfang Li;Haizheng Yang;Xiaoru Yuan,Yuhan Guo;Yuchu Luo;Keer Lu;Linfang Li;Haizheng Yang;Xiaoru Yuan,"Key Laboratory of Machine Perception (Ministry of Education), School of AI, Peking University, China;Key Laboratory of Machine Perception (Ministry of Education), School of AI, Peking University, China;Key Laboratory of Machine Perception (Ministry of Education), School of AI, Peking University, China;Department of Chinese Language & Literature, Center for Ancient Chinese Classics & Archives, Peking University, China;Department of Chinese Language & Literature, Center for Ancient Chinese Classics & Archives, Peking University, China;Key Laboratory of Machine Perception (Ministry of Education), School of AI, Peking University, China",0.1109/vast.2009.5332584;10.1109/vast.2011.6102454;10.1109/tvcg.2015.2467619;10.1109/vast.2009.5332593;10.1109/tvcg.2020.3030442;10.1109/tvcg.2017.2743959;10.1109/tvcg.2019.2934661;10.1109/tvcg.2015.2467752;10.1109/tvcg.2014.2346271;10.1109/tvcg.2017.2745320;10.1109/tvcg.2006.147;10.1109/tvcg.2011.179;10.1109/tvcg.2013.196;10.1109/tvcg.2012.279;10.1109/tvcg.2021.3114868;10.1109/tvcg.2022.3209436;10.1109/infvis.2005.1532152;10.1109/tvcg.2012.212;10.1109/tvcg.2012.265;10.1109/tvcg.2014.2346746;10.1109/tvcg.2012.225,"Visual analytics,digital humanities,spatial uncertainty,trajectory visualization,book movement,historical data",,2.0,68.0,826.0,,,visualizes circulation books;uncertain spatiotemporal;ancient times work;integration china;data liberroad enables,0.6065;0.2733;0.2486;0.1559;0.1301,"[np.int64(-1), -1, -1, -1, -1]",-1;-1;-1;-1;-1,,-1
VAST,2014,A Visual Reasoning Approach for Data-driven Transport Assessment on Urban Roads,10.1109/vast.2014.7042486,http://dx.doi.org/10.1109/VAST.2014.7042486,103.0,112.0,C,"Transport assessment plays a vital role in urban planning and traffic control, which are influenced by multi-faceted traffic factors involving road infrastructure and traffic flow. Conventional solutions can hardly meet the requirements and expectations of domain experts. In this paper we present a data-driven solution by leveraging a visual analysis system to evaluate the real traffic situations based on taxi trajectory data. A sketch-based visual interface is designed to support dynamic query and visual reasoning of traffic situations within multiple coordinated views. In particular, we propose a novel road-based query model for analysts to interactively conduct evaluation tasks. This model is supported by a bi-directional hash structure, TripHash, which enables real-time responses to the data queries over a huge amount of trajectory data. Case studies with a real taxi GPS trajectory dataset (&amp;gt; 30GB) show that our system performs well for on-demand transport assessment and reasoning.",Fei Wang 0016;Wei Chen 0001;Feiran Wu;Ye Zhao 0003;Han Hong;Tianyu Gu;Long Wang;Ronghua Liang;Hujun Bao,Fei Wang;Wei Chen;Feiran Wu;Ye Zhao;Han Hong;Tianyu Gu;Long Wang;Ronghua Liang;Hujun Bao,"Hunan Normal University and State Key Lab of CAD&CG, Zhejiang University;Cyber Innovation Joint Research Center, Zhejiang University;State Key Lab of CAD&CG, Zhejiang University;Kent State University;State Key Lab of CAD&CG, Zhejiang University;State Key Lab of CAD&CG, Zhejiang University;State Key Lab of CAD&CG, Zhejiang University;Zhejiang University of Technology;State Key Lab of CAD&CG, Zhejiang University",10.1109/vast.2011.6102458;10.1109/tvcg.2013.226;10.1109/tvcg.2013.228;10.1109/tvcg.2013.179;10.1109/vast.2011.6102455;10.1109/tvcg.2013.133;10.1109/vast.2011.6102458,"Road-based Query, Taxi Trajectory, Hash Index, Visual Analysis",65.0,34.0,48.0,960.0,,,taxi trajectory data;visual reasoning;support dynamic query;triphash enables;evaluate real,0.5790;0.4122;0.2649;0.2039;0.1229,"[np.int64(-1), -1, -1, -1, -1]",68;-1;-1;-1;-1,68,68
Vis,1991,Shadowed hedgehogs: a technique for visualizing 2D slices of 3D vector fields,10.1109/visual.1991.175792,http://dx.doi.org/10.1109/VISUAL.1991.175792,148.0,153.0,C,"The technique of placing directed line segments at grid points, known as hedgehogging, which has been used for visualizing 2D vector fields, is considered. A means of rapidly rendering a slice of a 3D field, suitable for a bilevel display, is provided. Shape and shadowing are used to disambiguate orientation. Liberal use of lookup tables makes the technique very fast.&lt;&lt;ETX&gt;&gt;",R. Victor Klassen;Steven J. Harrington,R.V. Klassen;S.J. Harrington,"Xerox Webster Research Center, Webster, NY, USA;Xerox Webster Research Center, Webster, NY, USA",,,85.0,13.0,8.0,157.0,,,hedgehogging used visualizing;3d field;line segments grid;use lookup tables;lt lt,0.6303;0.5829;0.4249;0.1131;0.0342,"[np.int64(-1), np.int64(-1), -1, -1, -1]",134;40;-1;-1;-1,40;134,134
InfoVis,2019,Estimating Color-Concept Associations from Image Statistics,10.1109/tvcg.2019.2934536,http://dx.doi.org/10.1109/TVCG.2019.2934536,1226.0,1235.0,J,"To interpret the meanings of colors in visualizations of categorical information, people must determine how distinct colors correspond to different concepts. This process is easier when assignments between colors and concepts in visualizations match people's expectations, making color palettes semantically interpretable. Efforts have been underway to optimize color palette design for semantic interpretablity, but this requires having good estimates of human color-concept associations. Obtaining these data from humans is costly, which motivates the need for automated methods. We developed and evaluated a new method for automatically estimating color-concept associations in a way that strongly correlates with human ratings. Building on prior studies using Google Images, our approach operates directly on Google Image search results without the need for humans in the loop. Specifically, we evaluated several methods for extracting raw pixel content of the images in order to best estimate color-concept associations obtained from human ratings. The most effective method extracted colors using a combination of cylindrical sectors and color categories in color space. We demonstrate that our approach can accurately estimate average human color-concept associations for different fruits using only a small set of images. The approach also generalizes moderately well to more complicated recycling-related concepts of objects that can appear in any color.",Ragini Rathore;Zachary Leggon;Laurent Lessard;Karen B. Schloss,Ragini Rathore;Zachary Leggon;Laurent Lessard;Karen B. Schloss,"Computer Sciences and Wisconsin Institute for Discovery (WID), University of Wisconsin–Madison;Biology and WID, University of Wisconisn–Madison;Electrical and Computer Engineering and WID, University of Wisconsin–Madison;Psychology and WID, University of Wisconsin–Madison",10.1109/tvcg.2016.2598918;10.1109/visual.1996.568118;10.1109/tvcg.2018.2865147;10.1109/tvcg.2015.2467471;10.1109/tvcg.2017.2744359;10.1109/tvcg.2016.2598918,"Visual Reasoning,Visual Communication,Visual Encoding,Color Perception,Color Cognition,Color Categories",21.0,6.0,53.0,752.0,,,color concept associations;moderately complicated recycling;having good estimates;obtained human;cylindrical sectors,0.7337;0.2671;0.1241;0.0444;-0.0092,"[np.int64(-1), -1, -1, -1, -1]",219;-1;-1;-1;-1,219,219
InfoVis,2011,Improved Similarity Trees and their Application to Visual Data Classification,10.1109/tvcg.2011.212,http://dx.doi.org/10.1109/TVCG.2011.212,2459.0,2468.0,J,"An alternative form to multidimensional projections for the visual analysis of data represented in multidimensional spaces is the deployment of similarity trees, such as Neighbor Joining trees. They organize data objects on the visual plane emphasizing their levels of similarity with high capability of detecting and separating groups and subgroups of objects. Besides this similarity-based hierarchical data organization, some of their advantages include the ability to decrease point clutter; high precision; and a consistent view of the data set during focusing, offering a very intuitive way to view the general structure of the data set as well as to drill down to groups and subgroups of interest. Disadvantages of similarity trees based on neighbor joining strategies include their computational cost and the presence of virtual nodes that utilize too much of the visual space. This paper presents a highly improved version of the similarity tree technique. The improvements in the technique are given by two procedures. The first is a strategy that replaces virtual nodes by promoting real leaf nodes to their place, saving large portions of space in the display and maintaining the expressiveness and precision of the technique. The second improvement is an implementation that significantly accelerates the algorithm, impacting its use for larger data sets. We also illustrate the applicability of the technique in visual data mining, showing its advantages to support visual classification of data sets, with special attention to the case of image classification. We demonstrate the capabilities of the tree for analysis and iterative manipulation and employ those capabilities to support evolving to a satisfactory data organization and classification.",Jose Gustavo Paiva;Laura Florian;Hélio Pedrini;Guilherme P. Telles;Rosane Minghim,Jose Gustavo Paiva;Laura Florian;Helio Pedrini;Guilherme Telles;Rosane Minghim,"Federal University of Uberlândia and ICMC, Brazil;Universidade de Sao Paulo, Sao Paulo, SÃ£o Paulo, BR;IC-University of Campinas, Brazil;IC-University of Campinas, Brazil;ICMC-University of São Paulo, Brazil",10.1109/infvis.1999.801855;10.1109/tvcg.2009.140;10.1109/vast.2007.4389002;10.1109/tvcg.2008.138;10.1109/visual.1996.567787;10.1109/tvcg.2010.207;10.1109/tvcg.2010.170;10.1109/infvis.2002.1173148;10.1109/infvis.1999.801855,"Similarity Trees, Multidimensional Projections, Image Classification",65.0,35.0,42.0,1500.0,,,visual data mining;trees neighbor;place saving large;subgroups objects;disadvantages,0.6654;0.3395;0.1874;0.1775;0.0618,"[np.int64(-1), -1, -1, -1, -1]",205;-1;-1;-1;-1,205,205
SciVis,2018,A Study of the Trade-off Between Reducing Precision and Reducing Resolution for Data Analysis and Visualization,10.1109/tvcg.2018.2864853,http://dx.doi.org/10.1109/TVCG.2018.2864853,1193.0,1203.0,J,"There currently exist two dominant strategies to reduce data sizes in analysis and visualization: reducing the precision of the data, e.g., through quantization, or reducing its resolution, e.g., by subsampling. Both have advantages and disadvantages and both face fundamental limits at which the reduced information ceases to be useful. The paper explores the additional gains that could be achieved by combining both strategies. In particular, we present a common framework that allows us to study the trade-off in reducing precision and/or resolution in a principled manner. We represent data reduction schemes as progressive streams of bits and study how various bit orderings such as by resolution, by precision, etc., impact the resulting approximation error across a variety of data sets as well as analysis tasks. Furthermore, we compute streams that are optimized for different tasks to serve as lower bounds on the achievable error. Scientific data management systems can use the results presented in this paper as guidance on how to store and stream data to make efficient use of the limited storage and bandwidth in practice.",Duong Hoang;Pavol Klacansky;Harsh Bhatia;Peer-Timo Bremer;Peter Lindstrom 0001;Valerio Pascucci,Duong Hoang;Pavol Klacansky;Harsh Bhatia;Peer-Timo Bremer;Peter Lindstrom;Valerio Pascucci,"University of Utah, Salt Lake City, UT, US;University of Utah, Salt Lake City, UT, US;Lawrence Livemore National Laboratory, USA;Lawrence Livemore National Laboratory, USA;Lawrence Livemore National Laboratory, USA;University of Utah, Salt Lake City, UT, US",10.1109/tvcg.2009.194;10.1109/tvcg.2007.70516;10.1109/visual.2002.1183757;10.1109/tvcg.2012.240;10.1109/visual.1999.809908;10.1109/tvcg.2014.2346458;10.1109/tvcg.2006.143;10.1109/visual.2004.51;10.1109/visual.2003.1250385;10.1109/tvcg.2011.214;10.1109/tvcg.2012.274;10.1109/tvcg.2015.2467412;10.1109/tvcg.2009.194,"data compression,bit ordering,multi-resolution,data analysis",15.0,16.0,70.0,853.0,,,data quantization reducing;schemes progressive streams;achievable error scientific;represent;explores additional,0.6744;0.3281;0.2860;0.1034;0.0382,"[np.int64(-1), -1, -1, -1, -1]",42;-1;-1;-1;-1,42,42
Vis,2000,WEAVE: a system for visually linking 3-D and statistical visualizations applied to cardiac simulation and measurement data,10.1109/visual.2000.885739,http://dx.doi.org/10.1109/VISUAL.2000.885739,489.0,492.0,C,"WEAVE (Workbench Environment for Analysis and Visual Exploration) is an environment for creating interactive visualization applications. WEAVE differs from previous systems in that it provides transparent linking between custom 3D visualizations and multidimensional statistical representations, and provides interactive color brushing between all visualizations. The authors demonstrate how WEAVE can be used to rapidly prototype a biomedical application, weaving together simulation data, measurement data, and 3D anatomical data concerning the propagation of excitation in the heart. These linked statistical and custom three-dimensional visualizations of the heart can allow scientists to more effectively study the correspondence of structure and behavior.",Donna L. Gresh;Bernice E. Rogowitz;Raimond L. Winslow;David F. Scollan;Christina K. Yung,D.L. Gresh;B.E. Rogowitz;R.L. Winslow;D.F. Scollan;C.K. Yung,"Department of Biomedical Engineering, Johns Hopkins University School of Medicine, USA;Department of Biomedical Engineering, Johns Hopkins University School of Medicine, USA;IBM Thomas J. Watson Research Center, USA;IBM Thomas J. Watson Research Center, USA;Department of Biomedical Engineering, Johns Hopkins University School of Medicine, USA",10.1109/visual.1992.235219;10.1109/visual.1999.809894;10.1109/infvis.1995.528688;10.1109/visual.1991.175794;10.1109/infvis.1996.559210;10.1109/visual.1992.235219,"visualization, medical, heart, data synthesis",131.0,35.0,18.0,154.0,,,visualizations heart;rapidly prototype biomedical;linking custom 3d;data concerning propagation;weave differs previous,0.6253;0.3998;0.2957;0.2324;0.1530,"[np.int64(-1), -1, -1, -1, -1]",180;-1;-1;-1;-1,180,180
Vis,2022,RISeer: Inspecting the Status and Dynamics of Regional Industrial Structure via Visual Analytics,10.1109/tvcg.2022.3209351,http://dx.doi.org/10.1109/TVCG.2022.3209351,1070.0,1080.0,J,"Restructuring the regional industrial structure (RIS) has the potential to halt economic recession and achieve revitalization. Understanding the current status and dynamics of RIS will greatly assist in studying and evaluating the current industrial structure. Previous studies have focused on qualitative and quantitative research to rationalize RIS from a macroscopic perspective. Although recent studies have traced information at the industrial enterprise level to complement existing research from a micro perspective, the ambiguity of the underlying variables contributing to the industrial sector and its composition, the dynamic nature, and the large number of multivariant features of RIS records have obscured a deep and fine-grained understanding of RIS. To this end, we propose an interactive visualization system, RISeer, which is based on interpretable machine learning models and enhanced visualizations designed to identify the evolutionary patterns of the RIS and facilitate inter-regional inspection and comparison. Two case studies confirm the effectiveness of our approach, and feedback from experts indicates that RISeer helps them to gain a fine-grained understanding of the dynamics and evolution of the RIS.",Longfei Chen;Yang Ouyang;Haipeng Zhang;Suting Hong;Quan Li,Longfei Chen;Yang Ouyang;Haipeng Zhang;Suting Hong;Quan Li,"School of Information Science and Technology, ShanghaiTech University, China;School of Information Science and Technology, ShanghaiTech University, China;School of Information Science and Technology, ShanghaiTech University, China;School of Entrepreneurship and Management, ShanghaiTech University, China;School of Information Science and Technology, ShanghaiTech University, China",10.1109/tvcg.2009.122;10.1109/tvcg.2013.173;10.1109/vast.2018.8802454;10.1109/tvcg.2006.179;10.1109/tvcg.2016.2598838;10.1109/infvis.2005.1532152;10.1109/tvcg.2015.2468078;10.1109/tvcg.2017.2744738;10.1109/tvcg.2009.122,"Spatiotemporal dynamics,multivariate time series,regional industrial structure,visualization",,3.0,70.0,688.0,,,regional industrial structure;visualization riseer;interpretable machine learning;understanding current;end,0.6823;0.3457;0.3268;0.0753;0.0031,"[np.int64(-1), -1, -1, -1, -1]",18;-1;-1;-1;-1,18,18
InfoVis,2011,BallotMaps: Detecting Name Bias in Alphabetically Ordered Ballot Papers,10.1109/tvcg.2011.174,http://dx.doi.org/10.1109/TVCG.2011.174,2384.0,2391.0,J,"The relationship between candidates' position on a ballot paper and vote rank is explored in the case of 5000 candidates for the UK 2010 local government elections in the Greater London area. This design study uses hierarchical spatially arranged graphics to represent two locations that affect candidates at very different scales: the geographical areas for which they seek election and the spatial location of their names on the ballot paper. This approach allows the effect of position bias to be assessed; that is, the degree to which the position of a candidate's name on the ballot paper influences the number of votes received by the candidate, and whether this varies geographically. Results show that position bias was significant enough to influence rank order of candidates, and in the case of many marginal electoral wards, to influence who was elected to government. Position bias was observed most strongly for Liberal Democrat candidates but present for all major political parties. Visual analysis of classification of candidate names by ethnicity suggests that this too had an effect on votes received by candidates, in some cases overcoming alphabetic name bias. The results found contradict some earlier research suggesting that alphabetic name bias was not sufficiently significant to affect electoral outcome and add new evidence for the geographic and ethnicity influences on voting behaviour. The visual approach proposed here can be applied to a wider range of electoral data and the patterns identified and hypotheses derived from them could have significant implications for the design of ballot papers and the conduct of fair elections.",Jo Wood;Donia Badawood;Jason Dykes;Aidan Slingsby,Jo Wood;Donia Badawood;Jason Dykes;Aidan Slingsby,"GiCentre, School of Informatics, City University London, UK;GiCentre, School of Informatics, City University London, UK;GiCentre, School of Informatics, City University London, UK;GiCentre, School of Informatics, City University London, UK",10.1109/tvcg.2009.128;10.1109/tvcg.2008.165;10.1109/tvcg.2010.161;10.1109/tvcg.2009.128,"Voting, election, bias, democracy, governance, treemaps, geovisualization, hierarchy, governance",56.0,29.0,27.0,1078.0,,,election spatial;rank order;names ethnicity suggests;behaviour visual approach;contradict earlier research,0.6572;0.2971;0.2616;0.1708;0.0646,"[np.int64(-1), -1, -1, -1, -1]",305;-1;-1;-1;-1,305,305
Vis,1992,Techniques for managing very large scientific databases,10.1109/visual.1992.235187,http://dx.doi.org/10.1109/VISUAL.1992.235187,362.0,365.0,M,"Discusses issues relating to the state of the art in scientific data management. Management of scientific data sets or databases is reviewed. The generic science requirements, as well as a case example that drives the underlying data management system architecture are explored, showing current technology limitations. A concept of intelligent information fusion with sufficient detail on how to integrate advanced technologies to enhance scientific production, is presented. Emphasis is on user interfaces, spatial data structure, uses of neural networks for extracting information from scientific imagery, uses of object-oriented database management systems, animation, and visualization techniques.&lt;&lt;ETX&gt;&gt;",W.J. Campbell;R.F. Cromp;G. Fekete;R. Wall;M. Goldberg,W.J. Campbell;R.F. Cromp;G. Fekete;R. Wall;M. Goldberg,;;;;,,,,5.0,0.0,59.0,,,scientific data management;systems animation visualization;imagery uses object;intelligent;fusion sufficient integrate,0.7683;0.2798;0.1939;0.1616;0.1224,"[np.int64(-1), -1, -1, -1, -1]",281;-1;-1;-1;-1,281,281
Vis,2011,Image Plane Sweep Volume Illumination,10.1109/tvcg.2011.211,http://dx.doi.org/10.1109/TVCG.2011.211,2125.0,2134.0,J,"In recent years, many volumetric illumination models have been proposed, which have the potential to simulate advanced lighting effects and thus support improved image comprehension. Although volume ray-casting is widely accepted as the volume rendering technique which achieves the highest image quality, so far no volumetric illumination algorithm has been designed to be directly incorporated into the ray-casting process. In this paper we propose image plane sweep volume illumination (IPSVI), which allows the integration of advanced illumination effects into a GPU-based volume ray-caster by exploiting the plane sweep paradigm. Thus, we are able to reduce the problem complexity and achieve interactive frame rates, while supporting scattering as well as shadowing. Since all illumination computations are performed directly within a single rendering pass, IPSVI does not require any preprocessing nor does it need to store intermediate results within an illumination volume. It therefore has a significantly lower memory footprint than other techniques. This makes IPSVI directly applicable to large data sets. Furthermore, the integration into a GPU-based ray-caster allows for high image quality as well as improved rendering performance by exploiting early ray termination. This paper discusses the theory behind IPSVI, describes its implementation, demonstrates its visual results and provides performance measurements.",Erik Sundén;Anders Ynnerman;Timo Ropinski,Erik Sunden;Anders Ynnerman;Timo Ropinski,"Scientific Visualization Group, Linköping University, Sweden;Scientific Visualization Group, Linköping University, Sweden;Scientific Visualization Group, Linköping University, Sweden",10.1109/tvcg.2011.161;10.1109/visual.2002.1183761;10.1109/visual.2003.1250394;10.1109/visual.2002.1183764;10.1109/tvcg.2007.70573;10.1109/visual.2003.1250384;10.1109/tvcg.2009.164;10.1109/tvcg.2011.161,"Interactive volume rendering, GPU-based ray-casting, Advanced illumination",36.0,23.0,44.0,815.0,,,volumetric illumination algorithm;interactive frame rates;sweep paradigm;caster allows;significantly,0.6902;0.2406;0.1371;0.0861;0.0505,"[np.int64(-1), -1, -1, -1, -1]",256;-1;-1;-1;-1,256,256
Vis,2007,Molecular Surface Abstraction,10.1109/tvcg.2007.70578,http://dx.doi.org/10.1109/TVCG.2007.70578,1608.0,1615.0,J,"In this paper we introduce a visualization technique that provides an abstracted view of the shape and spatio-physico-chemical properties of complex molecules. Unlike existing molecular viewing methods, our approach suppresses small details to facilitate rapid comprehension, yet marks the location of significant features so they remain visible. Our approach uses a combination of filters and mesh restructuring to generate a simplified representation that conveys the overall shape and spatio-physico-chemical properties (e.g. electrostatic charge). Surface markings are then used in the place of important removed details, as well as to supply additional information. These simplified representations are amenable to display using stylized rendering algorithms to further enhance comprehension. Our initial experience suggests that our approach is particularly useful in browsing collections of large molecules and in readily making comparisons between them.",Gregory Cipriano;Michael Gleicher,Gregory Cipriano;Michael Gleicher,"Department of Computer Sciences, University of Wisconsin, Madison, USA;Department of Computer Sciences, University of Wisconsin, Madison, USA",10.1109/visual.1993.398882;10.1109/visual.2002.1183769;10.1109/visual.2005.1532822;10.1109/visual.2002.1183780;10.1109/visual.2004.62;10.1109/tvcg.2006.115;10.1109/visual.1993.398882,"molecular surfaces, molecular visualization, surfaces, textures, cartographic labeling",51.0,30.0,39.0,291.0,,,existing molecular viewing;mesh restructuring generate;algorithms enhance comprehension;properties electrostatic;removed,0.6198;0.3282;0.2566;0.1205;-0.0383,"[np.int64(-1), -1, -1, -1, -1]",288;-1;-1;-1;-1,288,288
Vis,1999,Animating wrinkles on clothes,10.1109/visual.1999.809885,http://dx.doi.org/10.1109/VISUAL.1999.809885,175.0,523.0,C,"This paper describes a method to simulate realistic wrinkles on clothes without fine mesh and large computational overheads. Cloth has very little in-plane deformations, as most of the deformations come from buckling. This can be looked at as area conservation property of cloth. The area conservation formulation of the method modulates the user defined wrinkle pattern, based on deformation of individual triangle. The methodology facilitates use of small in-plane deformation stiffnesses and a coarse mesh for the numerical simulation, this makes cloth simulation fast and robust. Moreover, the ability to design wrinkles (even on generalized deformable models) makes this method versatile for synthetic image generation. The method inspired from cloth wrinkling problem, being geometric in nature, can be extended to other wrinkling phenomena.",Sunil Hadap;Endre Bangerter;Pascal Volino;Nadia Magnenat-Thalmann,S. Hadap;E. Bongarter;P. Volino;N. Magnenat-Thalmann,"MIRA Laboratory, CUI, University of Genova, Switzerland and Universite de Geneve, Geneva, GE, CH;;MIRA Laboratory, CUI, University of Genova, Switzerland;MIRA Laboratory, CUI, University of Genova, Switzerland",,"clothmodeling,wrinklemodeling,deformablemodels",133.0,33.0,14.0,203.0,,,inspired cloth wrinkling;mesh numerical;image generation method;facilitates use small;fast,0.7493;0.4186;0.2877;0.0436;0.0313,"[np.int64(-1), -1, -1, -1, -1]",308;-1;-1;-1;-1,308,308
InfoVis,2015,HOLA: Human-like Orthogonal Network Layout,10.1109/tvcg.2015.2467451,http://dx.doi.org/10.1109/TVCG.2015.2467451,349.0,358.0,J,"Over the last 50 years a wide variety of automatic network layout algorithms have been developed. Some are fast heuristic techniques suitable for networks with hundreds of thousands of nodes while others are multi-stage frameworks for higher-quality layout of smaller networks. However, despite decades of research currently no algorithm produces layout of comparable quality to that of a human. We give a new “human-centred” methodology for automatic network layout algorithm design that is intended to overcome this deficiency. User studies are first used to identify the aesthetic criteria algorithms should encode, then an algorithm is developed that is informed by these criteria and finally, a follow-up study evaluates the algorithm output. We have used this new methodology to develop an automatic orthogonal network layout method, HOLA, that achieves measurably better (by user study) layout than the best available orthogonal layout algorithm and which produces layouts of comparable quality to those produced by hand.",Steve Kieffer;Tim Dwyer;Kim Marriott;Michael Wybrow,Steve Kieffer;Tim Dwyer;Kim Marriott;Michael Wybrow,Monash University and NICTA Victoria;Monash University;Monash University and NICTA Victoria;Monash University,10.1109/tvcg.2006.120;10.1109/tvcg.2012.208;10.1109/tvcg.2013.151;10.1109/tvcg.2006.156;10.1109/tvcg.2009.109;10.1109/tvcg.2008.141;10.1109/tvcg.2006.147;10.1109/tvcg.2012.245;10.1109/tvcg.2008.155;10.1109/tvcg.2006.120,"Graph layout, orthogonal layout, automatic layout algorithms, user-generated layout, graph-drawing aesthetics",80.0,55.0,36.0,1959.0,BP,,network layout algorithm;aesthetic criteria;better user study;hola;despite decades,0.7937;0.2665;0.1819;0.0197;0.0093,"[np.int64(-1), -1, -1, -1, -1]",39;-1;-1;-1;-1,39,39
Vis,1996,FEL: The Field Encapsulation Library,10.1109/visual.1996.568115,http://doi.ieeecomputersociety.org/10.1109/VISUAL.1996.568115,241.0,247.0,C,"The paper describes the Field Encapsulation Library (FEL), which provides a grid independent application programmer's interface to gridded three dimensional field data. The C++ implementation of FEL is described, stressing the way in which the class hierarchy hides the underlying grid structure in a way that allows visualization algorithms to be written in a completely grid independent manner. Appropriately defined coordinate classes play an important role in providing this grid independence. High performance point location routines for data access are described and performance times are provided.",Steve Bryson;David N. Kenwright;Michael J. Gerald-Yamasaki,S. Bryson;D. Kenwright;M. Gerald-Yamasaki,"NASA Ames Res. Center, Moffett Field, CA, USA;NASA Ames Res. Center, Moffett Field, CA, USA;NASA Ames Res. Center, Moffett Field, CA, USA",10.1109/visual.1995.485145;10.1109/visual.1991.175771;10.1109/visual.1992.235202,,27.0,11.0,0.0,35.0,,,gridded dimensional field;encapsulation library;allows visualization;described performance times;completely,0.5443;0.4022;0.3911;0.0924;0.0276,"[np.int64(-1), -1, -1, -1, -1]",286;-1;-1;-1;-1,286,286
VAST,2020,SMAP: A Joint Dimensionality Reduction Scheme for Secure Multi-Party Visualization,10.1109/vast50239.2020.00015,http://dx.doi.org/10.1109/VAST50239.2020.00015,107.0,118.0,C,"Nowadays, as data becomes increasingly complex and distributed, data analyses often involve several related datasets that are stored on different servers and probably owned by different stakeholders. While there is an emerging need to provide these stakeholders with a full picture of their data under a global context, conventional visual analytical methods, such as dimensionality reduction, could expose data privacy when multi-party datasets are fused into a single site to build point-level relationships. In this paper, we reformulate the conventional t-SNE method from the single-site mode into a secure distributed infrastructure. We present a secure multi-party scheme for joint t-SNE computation, which can minimize the risk of data leakage. Aggregated visualization can be optionally employed to hide disclosure of point-level relationships. We build a prototype system based on our method, SMAP, to support the organization, computation, and exploration of secure joint embedding. We demonstrate the effectiveness of our approach with three case studies, one of which is based on the deployment of our system in real-world applications.",Jiazhi Xia;Tianxiang Chen;Lei Zhang;Wei Chen 0001;Yang Chen;Xiaolong Zhang 0001;Cong Xie;Tobias Schreck,Jiazhi Xia;Tianxiang Chen;Lei Zhang;Wei Chen;Yang Chen;Xiaolong Zhang;Cong Xie;Tobias Schreck,"School of Computer Science and Engineering, Central South University;School of Computer Science and Engineering, Central South University;School of Computer Science and Engineering, Central South University;State Key Lab of CAD&CG, Zhejiang University;I4 data;Pennsylvania State University, University Park, PA;Facebook;Graz University of Technology",10.1109/tvcg.2011.163;10.1109/tvcg.2018.2865141;10.1109/tvcg.2018.2864843;10.1109/tvcg.2018.2865021;10.1109/tvcg.2017.2745139;10.1109/vast47406.2019.8986943;10.1109/tvcg.2011.163,"High-Dimensional Data Visualization,Secure Visualization,Dimensionality Reduction,Secure Multi-Party Computation",9.0,10.0,51.0,543.0,,,secure joint embedding;visualization optionally;data global;disclosure point level;analytical methods,0.6077;0.3326;0.3236;0.1960;0.1017,"[np.int64(-1), -1, -1, -1, -1]",27;-1;-1;-1;-1,27,27
InfoVis,2011,D³ Data-Driven Documents,10.1109/tvcg.2011.185,http://dx.doi.org/10.1109/TVCG.2011.185,2301.0,2309.0,J,"Data-Driven Documents (D3) is a novel representation-transparent approach to visualization for the web. Rather than hide the underlying scenegraph within a toolkit-specific abstraction, D3 enables direct inspection and manipulation of a native representation: the standard document object model (DOM). With D3, designers selectively bind input data to arbitrary document elements, applying dynamic transforms to both generate and modify content. We show how representational transparency improves expressiveness and better integrates with developer tools than prior approaches, while offering comparable notational efficiency and retaining powerful declarative components. Immediate evaluation of operators further simplifies debugging and allows iterative development. Additionally, we demonstrate how D3 transforms naturally enable animation and interaction with dramatic performance improvements over intermediate representations.",Michael Bostock;Vadim Ogievetsky;Jeffrey Heer,Michael Bostock;Vadim Ogievetsky;Jeffrey Heer,"Computer Science Department, Stanford University, Stanford, CA, USA;Computer Science Department, Stanford University, Stanford, CA, USA;Computer Science Department, Stanford University, Stanford, CA, USA",10.1109/infvis.2000.885091;10.1109/infvis.2000.885098;10.1109/tvcg.2010.144;10.1109/tvcg.2009.174;10.1109/infvis.2004.12;10.1109/tvcg.2006.178;10.1109/infvis.2005.1532122;10.1109/tvcg.2008.166;10.1109/infvis.2004.64;10.1109/tvcg.2007.70539;10.1109/infvis.2000.885091,"Information visualization, user interfaces, toolkits, 2D graphics",3795.0,2178.0,41.0,11668.0,TT,,data driven documents;representation transparent;d3;performance improvements intermediate;enable animation,0.6279;0.2776;0.2412;0.1540;0.1097,"[np.int64(-1), -1, -1, -1, -1]",124;-1;-1;-1;-1,124,124
Vis,2021,Interactive Data Comics,10.1109/tvcg.2021.3114849,http://dx.doi.org/10.1109/TVCG.2021.3114849,944.0,954.0,J,"This paper investigates how to make data comics interactive. Data comics are an effective and versatile means for visual communication, leveraging the power of sequential narration and combined textual and visual content, while providing an overview of the storyline through panels assembled in expressive layouts. While a powerful static storytelling medium that works well on paper support, adding interactivity to data comics can enable non-linear storytelling, personalization, levels of details, explanations, and potentially enriched user experiences. This paper introduces a set of operations tailored to support data comics narrative goals that go beyond the traditional linear, immutable storyline curated by a story author. The goals and operations include adding and removing panels into pre-defined layouts to support branching, change of perspective, or access to detail-on-demand, as well as providing and modifying data, and interacting with data representation, to support personalization and reader-defined data focus. We propose a lightweight specification language, COMICSCRIPT, for designers to add such interactivity to static comics. To assess the viability of our authoring process, we recruited six professional illustrators, designers and data comics enthusiasts and asked them to craft an interactive comic, allowing us to understand authoring workflow and potential of our approach. We present examples of interactive comics in a gallery. This initial step towards understanding the design space of interactive comics can inform the design of creation tools and experiences for interactive storytelling.",Zezhong Wang 0001;Hugo Romat;Fanny Chevalier;Nathalie Henry Riche;Dave Murray-Rust;Benjamin Bach,Zezhong Wang;Hugo Romat;Fanny Chevalier;Nathalie Henry Riche;Dave Murray-Rust;Benjamin Bach,"University of Edinburgh, Scotland;ETH Zurich, Switzerland;University of Toronto, Canada;Microsoft Research, United States;TU Delft, Netherlands;University of Edinburgh, Scotland",10.1109/tvcg.2016.2598647;10.1109/tvcg.2018.2865119;10.1109/tvcg.2016.2598609;10.1109/tvcg.2015.2467201;10.1109/tvcg.2013.210;10.1109/tvcg.2008.127;10.1109/tvcg.2016.2598620;10.1109/tvcg.2020.3028948;10.1109/tvcg.2018.2865158;10.1109/tvcg.2016.2599030;10.1109/tvcg.2010.179;10.1109/tvcg.2020.3030433;10.1109/infvis.2005.1532122;10.1109/tvcg.2016.2598647,"Data comics,Non-linear narrative,interactive storytelling",9.0,14.0,108.0,1602.0,,,interactive comics;understand authoring workflow;defined data;story;change perspective access,0.7655;0.2983;0.2580;0.1626;0.1200,"[np.int64(-1), -1, -1, -1, -1]",317;-1;-1;-1;-1,317,317
Vis,1990,Volume microscopy of biological specimens based on non-confocal imaging techniques,10.1109/visual.1990.146413,http://dx.doi.org/10.1109/VISUAL.1990.146413,424.0,428.0,C,An approach that uses advanced computer graphics workstations and volume rendering algorithms for accurate reconstruction of volumetric microscopy data is described. It has been found that excellent reconstructions can be made from serial sections acquired using a charge-coupled device and a conventional light microscope. Both confocal and nonconfocal reconstructions are examined. The effects of differing light sources are considered 3D image processing results are presented.&lt;&lt;ETX&gt;&gt;,Stephen L. Senft;Vincent J. Argio;William L. van Zandt,S.L. Senft;V.J. Argiro;W.L. VanZandt,"Division of Experimental Neurology and Neurosurgery, Washington University School of Medicine, Saint Louis, MO, USA;Department of Physiological and Biological Sciences, Maharishi International University and Vital Images, Inc., Fairfield, IA, USA;Department of Physiological and Biological Sciences, Maharishi International University and Vital Images, Inc., Fairfield, IA, USA",,,7.0,3.0,10.0,60.0,,,reconstruction volumetric microscopy;rendering algorithms accurate;effects differing light;uses advanced computer;charge coupled,0.7381;0.3143;0.1161;0.0790;0.0247,"[np.int64(-1), -1, -1, -1, -1]",312;-1;-1;-1;-1,312,312
Vis,2024,LLM Comparator: Interactive Analysis of Side-by-Side Evaluation of Large Language Models,10.1109/tvcg.2024.3456354,http://dx.doi.org/10.1109/TVCG.2024.3456354,503.0,513.0,J,"Evaluating large language models (LLMs) presents unique challenges. While automatic side-by-side evaluation, also known as LLM-as-a-judge, has become a promising solution, model developers and researchers face difficulties with scalability and interpretability when analyzing these evaluation outcomes. To address these challenges, we introduce LLM Comparator, a new visual analytics tool designed for side-by-side evaluations of LLMs. This tool provides analytical workflows that help users understand when and why one LLM outperforms or underperforms another, and how their responses differ. Through close collaboration with practitioners developing LLMs at Google, we have iteratively designed, developed, and refined the tool. Qualitative feedback from these users highlights that the tool facilitates in-depth analysis of individual examples while enabling users to visually overview and flexibly slice data. This empowers users to identify undesirable patterns, formulate hypotheses about model behavior, and gain insights for model improvement. LLM Comparator has been integrated into Google's LLM evaluation platforms and open-sourced.",Minsuk Kahng;Ian Tenney;Mahima Pushkarna;Michael Xieyang Liu;James Wexler;Emily Reif;Krystal Kallarackal;Minsuk Chang;Michael Terry;Lucas Dixon,Minsuk Kahng;Ian Tenney;Mahima Pushkarna;Michael Xieyang Liu;James Wexler;Emily Reif;Krystal Kallarackal;Minsuk Chang;Michael Terry;Lucas Dixon,"Google Research (now with Google DeepMind), USA;Google Research (now with Google DeepMind), USA;Google Research (now with Google DeepMind), USA;Google Research (now with Google DeepMind), USA;Google Research (now with Google DeepMind), USA;Google Research (now with Google DeepMind), USA;Google Research (now with Google DeepMind), USA;Google Research (now with Google DeepMind), USA;Google Research (now with Google DeepMind), USA;Google Research (now with Google DeepMind), USA",10.1109/tvcg.2020.3030342;10.1109/tvcg.2022.3209466;10.1109/tvcg.2022.3209384;10.1109/tvcg.2017.2744718;10.1109/tvcg.2018.2864812;10.1109/tvcg.2022.3209458;10.1109/tvcg.2022.3209479;10.1109/tvcg.2019.2934619;10.1109/tvcg.2021.3114837,"Visual analytics,large language models,,,model evaluation,responsible AI,machine learning interpretability",,0.0,58.0,1921.0,,,evaluating large language;practitioners developing llms;feedback users highlights;facilitates depth;sourced,0.6193;0.1591;0.1571;0.0970;0.0280,"[np.int64(-1), -1, -1, -1, -1]",303;-1;-1;-1;-1,303,303
InfoVis,2016,Visualizing Social Media Content with SentenTree,10.1109/tvcg.2016.2598590,http://dx.doi.org/10.1109/TVCG.2016.2598590,621.0,630.0,J,"We introduce SentenTree, a novel technique for visualizing the content of unstructured social media text. SentenTree displays frequent sentence patterns abstracted from a corpus of social media posts. The technique employs design ideas from word clouds and the Word Tree, but overcomes a number of limitations of both those visualizations. SentenTree displays a node-link diagram where nodes are words and links indicate word co-occurrence within the same sentence. The spatial arrangement of nodes gives cues to the syntactic ordering of words while the size of nodes gives cues to their frequency of occurrence. SentenTree can help people gain a rapid understanding of key concepts and opinions in a large social media text collection. It is implemented as a lightweight application that runs in the browser.",Mengdie Hu;Krist Wongsuphasawat;John T. Stasko,Mengdie Hu;Krist Wongsuphasawat;John Stasko,Twitter Inc. and Georgia Institute of Technology;Twitter Inc.;Georgia Institute of Technology,10.1109/tvcg.2009.171;10.1109/tvcg.2008.172;10.1109/vast.2009.5333443;10.1109/infvis.1995.528686;10.1109/tvcg.2010.154;10.1109/vast.2012.6400485;10.1109/tvcg.2011.179;10.1109/tvcg.2010.194;10.1109/tvcg.2013.221;10.1109/tvcg.2006.156;10.1109/tvcg.2009.165;10.1109/vast.2011.6102488;10.1109/tvcg.2014.2346920;10.1109/tvcg.2015.2467991;10.1109/tvcg.2011.239;10.1109/tvcg.2009.171,text visualization;social media;natural language processing;word cloud;Twitter,58.0,43.0,46.0,2945.0,,,unstructured social media;sententree displays;number limitations visualizations;overcomes;application runs browser,0.5740;0.3668;0.2293;0.1115;0.0689,"[np.int64(-1), -1, -1, -1, -1]",73;-1;-1;-1;-1,73,73
InfoVis,1996,Data characterization for automatically visualizing heterogeneous information,10.1109/infvis.1996.559211,http://dx.doi.org/10.1109/INFVIS.1996.559211,13.0,,C,"Automated graphical generation systems should be able to design effective presentations for heterogeneous (quantitative and qualitative) information in static or interactive environments. When building such a system, it is important to thoroughly understand the presentation-related characteristics of domain-specific information. We define a data-analysis taxonomy that can be used to characterize heterogeneous information. In addition to capturing the presentation-related properties of data, our characterization takes into account the user's information-seeking goals and visual-interpretation preferences. We use automatically-generated examples from two different application domains to demonstrate the coverage of the proposed taxonomy and its utility for selecting effective graphical techniques.",Michelle X. Zhou;Steven Feiner,M.X. Zhou;S.K. Feiner,"Department of Computer Science, Columbia University, New York, NY, USA;Department of Computer Science, Columbia University, New York, NY, USA",10.1109/visual.1990.146375;10.1109/visual.1990.146375,,87.0,10.0,13.0,222.0,,,automated graphical generation;define data;characterize heterogeneous;utility selecting effective;different application domains,0.6314;0.3108;0.2897;0.1603;0.0490,"[np.int64(-1), -1, -1, -1, -1]",155;-1;-1;-1;-1,155,155
InfoVis,1996,Dual multiresolution HyperSlice for multivariate data visualization,10.1109/infvis.1996.559224,http://dx.doi.org/10.1109/INFVIS.1996.559224,74.0,,M,We present a new multiresolution visualization design which allows a user to control the physical data resolution as well as the logical display resolution of multivariate data. A system prototype is described which uses the HyperSlice representation. The notion of space projection in multivariate data is introduced. This process is coupled with wavelets to form a powerful tool for very large data visualization.,Pak Chung Wong;Andrew H. Crabb;R. Daniel Bergeron,Pak Chung Wong;A.H. Crabb;R.D. Bergeron,"Department of Computer Science, University of New Hampshire, Durham, NH, USA;Department of Computer Science, University of New Hampshire, Durham, NH, USA;Department of Computer Science, University of New Hampshire, Durham, NH, USA",0.1109/visual.1995.480811;10.1109/visual.1993.398859;10.1109/visual.1996.567800,,18.0,4.0,5.0,97.0,,,multiresolution visualization;hyperslice;representation notion space;data introduced process;logical,0.7436;0.2553;0.2137;0.1284;0.0410,"[np.int64(-1), -1, -1, -1, -1]",-1;-1;-1;-1;-1,,-1
InfoVis,2008,A Framework of Interaction Costs in Information Visualization,10.1109/tvcg.2008.109,http://dx.doi.org/10.1109/TVCG.2008.109,1149.0,1156.0,J,"Interaction cost is an important but poorly understood factor in visualization design. We propose a framework of interaction costs inspired by Normanpsilas Seven Stages of Action to facilitate study. From 484 papers, we collected 61 interaction-related usability problems reported in 32 user studies and placed them into our framework of seven costs: (1) Decision costs to form goals; (2) system-power costs to form system operations; (3) Multiple input mode costs to form physical sequences; (4) Physical-motion costs to execute sequences; (5) Visual-cluttering costs to perceive state; (6) View-change costs to interpret perception; (7) State-change costs to evaluate interpretation. We also suggested ways to narrow the gulfs of execution (2-4) and evaluation (5-7) based on collected reports. Our framework suggests a need to consider decision costs (1) as the gulf of goal formation.",Heidi Lam,Heidi Lam,"University of British Columbia, Canada",10.1109/infvis.2001.963289;10.1109/infvis.2003.1249020;10.1109/infvis.2005.1532151;10.1109/infvis.2004.21;10.1109/tvcg.2006.187;10.1109/infvis.2004.5;10.1109/tvcg.2007.70515;10.1109/tvcg.2006.120;10.1109/infvis.2005.1532133;10.1109/infvis.2004.19;10.1109/infvis.2005.1532126;10.1109/vast.2006.261426;10.1109/visual.1994.346302;10.1109/tvcg.2007.70589;10.1109/infvis.2005.1532132;10.1109/infvis.1998.729560;10.1109/tvcg.2007.70583,"Interaction, Information Visualization, Framework, Interface Evaluation",173.0,95.0,70.0,1790.0,HM,,interaction related usability;execute sequences visual;reports;costs gulf goal;inspired normanpsilas seven,0.6290;0.3090;0.1411;0.0949;0.0892,"[np.int64(-1), -1, -1, -1, -1]",79;-1;-1;-1;-1,79,79
Vis,2002,A model for the visualization exploration process,10.1109/visual.2002.1183791,http://dx.doi.org/10.1109/VISUAL.2002.1183791,323.0,330.0,C,"The current state of the art in visualization research places strong emphasis on different techniques to derive insight from disparate types of data. However, little work has investigated the visualization process itself. The information content of the visualization process - the results, history, and relationships between those results - is addressed by this work. A characterization of the visualization process is discussed, leading to a general model of the visualization exploration process. The model, based upon a new parameter derivation calculus, can be used for automated reporting, analysis, or visualized directly. An XML-based language for expressing visualization sessions using the model is also described. These sessions can then be shared and reused by collaborators. The model, along with the XML representation, provides an effective means to utilize information within the visualization process to further data exploration.",T. J. Jankun-Kelly;Kwan-Liu Ma;Michael Gertz 0001,T.J. Jankun-Kelly;Kwan-Liu Ma;M. Gertz,"Computer Science Department, University of California, Davis, CA, USA;Computer Science Department, University of California, Davis, CA, USA;Database and Information Systems Group, Computer Science Department, University of California, Davis, CA, USA",10.1109/visual.2002.1183816;10.1109/infvis.1998.729560;10.1109/visual.1999.809871;10.1109/visual.1995.480821;10.1109/visual.1993.398857;10.1109/visual.1992.235203;10.1109/visual.1995.480801;10.1109/visual.1994.346304;10.1109/visual.2002.1183816,"visualization process, visualization models, scientific and information visualization, collaboration, XML",97.0,27.0,23.0,439.0,,,visualization exploration;directly xml;parameter derivation;means;shared reused,0.7472;0.2710;0.1632;0.0992;0.0812,"[np.int64(-1), -1, -1, -1, -1]",212;-1;-1;-1;-1,212,212
VAST,2018,Analyzing the Noise Robustness of Deep Neural Networks,10.1109/vast.2018.8802509,http://dx.doi.org/10.1109/VAST.2018.8802509,60.0,71.0,C,"Deep neural networks (DNNs) are vulnerable to maliciously generated adversarial examples. These examples are intentionally designed by making imperceptible perturbations and often mislead a DNN into making an incorrect prediction. This phenomenon means that there is significant risk in applying DNNs to safety-critical applications, such as driverless cars. To address this issue, we present a visual analytics approach to explain the primary cause of the wrong predictions introduced by adversarial examples. The key is to analyze the datapaths of the adversarial examples and compare them with those of the normal examples. A datapath is a group of critical neurons and their connections. To this end, we formulate the datapath extraction as a subset selection problem and approximately solve it based on back-propagation. A multi-level visualization consisting of a segmented DAG (layer level), an Euler diagram (feature map level), and a heat map (neuron level), has been designed to help experts investigate datapaths from the high-level layers to the detailed neuron activations. Two case studies are conducted that demonstrate the promise of our approach in support of explaining the working mechanism of adversarial examples.",Mengchen Liu;Shixia Liu;Hang Su 0006;Kelei Cao;Jun Zhu 0001,Mengchen Liu;Shixia Liu;Hang Su;Kelei Cao;Jun Zhu,"School of Software, Tsinghua University;School of Software, Tsinghua University;Dept.of Comp.Sci.Tech., Tsinghua University;School of Software, Tsinghua University;Dept.of Comp.Sci.Tech., Tsinghua University",10.1109/tvcg.2015.2467618;10.1109/tvcg.2011.186;10.1109/tvcg.2016.2598496;10.1109/tvcg.2017.2744683;10.1109/tvcg.2014.2346431;10.1109/tvcg.2014.2346433;10.1109/tvcg.2017.2744199;10.1109/tvcg.2017.2744718;10.1109/tvcg.2017.2744938;10.1109/tvcg.2016.2598831;10.1109/tvcg.2013.196;10.1109/tvcg.2011.209;10.1109/tvcg.2017.2744358;10.1109/tvcg.2016.2598838;10.1109/tvcg.2010.210;10.1109/tvcg.2017.2744018;10.1109/tvcg.2011.183;10.1109/tvcg.2017.2744158;10.1109/visual.2005.1532820;10.1109/vast.2014.7042494;10.1109/tvcg.2017.2744878;10.1109/tvcg.2018.2865041;10.1109/vast.2017.8585721;10.1109/tvcg.2015.2467618,"Deep neural networks,robustness,adversarial examples,back propagation,multi-level visualization.",55.0,41.0,64.0,972.0,,,datapaths adversarial examples;euler diagram;support explaining working;solve based;normal,0.6600;0.1508;0.1412;0.0520;0.0316,"[np.int64(-1), -1, -1, -1, -1]",82;-1;-1;-1;-1,82,82
Vis,2022,ChartWalk: Navigating large collections of text notes in electronic health records for clinical chart review,10.1109/tvcg.2022.3209444,http://dx.doi.org/10.1109/TVCG.2022.3209444,1244.0,1254.0,J,"Before seeing a patient for the first time, healthcare workers will typically conduct a comprehensive clinical chart review of the patient's electronic health record (EHR). Within the diverse documentation pieces included there, text notes are among the most important and thoroughly perused segments for this task; and yet they are among the least supported medium in terms of content navigation and overview. In this work, we delve deeper into the task of clinical chart review from a data visualization perspective and propose a hybrid graphics+text approach via ChartWalk, an interactive tool to support the review of text notes in EHRs. We report on our iterative design process grounded in input provided by a diverse range of healthcare professionals, with steps including: (a) initial requirements distilled from interviews and the literature, (b) an interim evaluation to validate design decisions, and (c) a task-based qualitative evaluation of our final design. We contribute lessons learned to better support the design of tools not only for clinical chart reviews but also other healthcare-related tasks around medical text analysis.",Nicole Sultanum;Farooq Naeem;Michael Brudno;Fanny Chevalier,Nicole Sultanum;Farooq Naeem;Michael Brudno;Fanny Chevalier,"University of Toronto, Canada;Centre for Addiction and Mental Health (CAMH), Canada;University of Toronto, Canada;University of Toronto, Canada",10.1109/vast.2014.7042493;10.1109/tvcg.2015.2467757;10.1109/tvcg.2014.2346431;10.1109/vast.2010.5652922;10.1109/vast.2012.6400485;10.1109/tvcg.2014.2346743;10.1109/vast.2007.4389006;10.1109/tvcg.2015.2467759;10.1109/tvcg.2018.2864905;10.1109/vast.2014.7042496;10.1109/tvcg.2010.129;10.1109/tvcg.2014.2346677;10.1109/vast.2014.7042493,"Electronic Health Record (EHR),Text Visualization,Close+Distant Reading,Clinical Overview,Medicine",,10.0,67.0,1231.0,HM,,chart reviews healthcare;text notes important;interactive tool support;delve;process grounded input,0.6079;0.3798;0.3281;0.1854;-0.0233,"[np.int64(-1), -1, -1, -1, -1]",90;-1;-1;-1;-1,90,90
Vis,2023,Design Characterization for Black-and-White Textures in Visualization,10.1109/tvcg.2023.3326941,http://dx.doi.org/10.1109/TVCG.2023.3326941,1019.0,1029.0,J,"We investigate the use of 2D black-and-white textures for the visualization of categorical data and contribute a summary of texture attributes, and the results of three experiments that elicited design strategies as well as aesthetic and effectiveness measures. Black-and-white textures are useful, for instance, as a visual channel for categorical data on low-color displays, in 2D/3D print, to achieve the aesthetic of historic visualizations, or to retain the color hue channel for other visual mappings. We specifically study how to use what we call geometric and iconic textures. Geometric textures use patterns of repeated abstract geometric shapes, while iconic textures use repeated icons that may stand for data categories. We parameterized both types of textures and developed a tool for designers to create textures on simple charts by adjusting texture parameters. 30 visualization experts used our tool and designed 66 textured bar charts, pie charts, and maps. We then had 150 participants rate these designs for aesthetics. Finally, with the top-rated geometric and iconic textures, our perceptual assessment experiment with 150 participants revealed that textured charts perform about equally well as non-textured charts, and that there are some differences depending on the type of chart.",Tingying He;Yuanyang Zhong;Petra Isenberg;Tobias Isenberg 0001,Tingying He;Yuanyang Zhong;Petra Isenberg;Tobias Isenberg,"Université Paris-Saclay, CNRS, Inria, LISN, France;Tencent Technology (Shenzhen) Company Limited, China;Université Paris-Saclay, CNRS, Inria, LISN, France;Université Paris-Saclay, CNRS, Inria, LISN, France",0.1109/tvcg.2015.2467732;10.1109/tvcg.2013.234;10.1109/tvcg.2014.2346435;10.1109/tvcg.2022.3209390;10.1109/visual.1998.745292;10.1109/tvcg.2022.3209486,"Aesthetics,textures,icons,black and white,visualization,visual representations,categorical data,design,perception",,0.0,53.0,385.0,,X,textures visualization categorical;design strategies aesthetic;charts adjusting;measures black;achieve,0.7012;0.4656;0.3018;0.1935;-0.0272,"[np.int64(-1), -1, -1, -1, -1]",310;-1;-1;-1;-1,310,310
VAST,2015,The Visual Causality Analyst: An Interactive Interface for Causal Reasoning,10.1109/tvcg.2015.2467931,http://dx.doi.org/10.1109/TVCG.2015.2467931,230.0,239.0,J,"Uncovering the causal relations that exist among variables in multivariate datasets is one of the ultimate goals in data analytics. Causation is related to correlation but correlation does not imply causation. While a number of casual discovery algorithms have been devised that eliminate spurious correlations from a network, there are no guarantees that all of the inferred causations are indeed true. Hence, bringing a domain expert into the casual reasoning loop can be of great benefit in identifying erroneous casual relationships suggested by the discovery algorithm. To address this need we present the Visual Causal Analyst - a novel visual causal reasoning framework that allows users to apply their expertise, verify and edit causal links, and collaborate with the causal discovery algorithm to identify a valid causal network. Its interface consists of both an interactive 2D graph view and a numerical presentation of salient statistical parameters, such as regression coefficients, p-values, and others. Both help users in gaining a good understanding of the landscape of causal structures particularly when the number of variables is large. Our framework is also novel in that it can handle both numerical and categorical variables within one unified model and return plausible results. We demonstrate its use via a set of case studies using multiple practical datasets.",Jun Wang;Klaus Mueller 0001,Jun Wang;Klaus Mueller,"Computer Science Department, Stony Brook University, Stony Brook, NY;Computer Science Dept., SUNY, Korea and Computer Science Department, Stony Brook University, Stony Brook, NY",10.1109/infvis.2003.1249025;10.1109/tvcg.2007.70528;10.1109/tvcg.2012.225;10.1109/vast.2007.4388999;10.1109/infvis.2003.1249025,"Visual knowledge discovery, Causality, Hypothesis testing, Visual evidence, High-dimensional data",74.0,50.0,31.0,1965.0,,,visual causal analyst;studies using;regression coefficients values;plausible;casual relationships suggested,0.7570;0.1927;0.1305;0.0971;0.0661,"[np.int64(-1), -1, -1, -1, -1]",160;-1;-1;-1;-1,160,160
Vis,1996,Wavelets applied to lossless compression and progressive transmission of floating point data in 3-D curvilinear grids,10.1109/visual.1996.568138,http://dx.doi.org/10.1109/VISUAL.1996.568138,385.0,388.0,C,"A method of lossless compression using wavelets is presented that enables progressive transmission of computational fluid dynamics (CFD) data in PLOT3D format. The floating point data is first converted to double-precision floating point format to maintain adequate precision throughout the transform process. It is then transformed using Haar wavelets-four times in two spatial dimensions, twice in the third spatial dimension, and twice in time for a total compression factor of 64 times. The double precision format will maintain enough precision during the transform to keep the process lossless. Next, the transformed data is compressed using Huffman coding and transmitted progressively using spectral selection. This allows most of the information to be transmitted in the first pass. Details are transmitted in later passes which ultimately provide for lossless reconstruction of the original data.",Aaron Trott;Robert J. Moorhead;John McGinley,A. Trott;R. Moorhead;J. McGinley,"NSF Engineering Research Center for CFS, Mississippi State University, USA;NSF Engineering Research Center for CFS, Mississippi State University, USA;NSF Engineering Research Center for CFS, Mississippi State University, USA",10.1109/visual.1994.346332;10.1109/visual.1994.346332,,51.0,17.0,3.0,126.0,,,compression using wavelets;fluid dynamics cfd;format floating point;pass details transmitted;haar,0.6188;0.3784;0.2742;0.1385;0.1317,"[np.int64(-1), -1, -1, -1, -1]",99;-1;-1;-1;-1,99,99
Vis,2022,Relaxed Dot Plots: Faithful Visualization of Samples and Their Distribution,10.1109/tvcg.2022.3209429,http://dx.doi.org/10.1109/TVCG.2022.3209429,278.0,287.0,J,"We introduce relaxed dot plots as an improvement of nonlinear dot plots for unit visualization. Our plots produce more faithful data representations and reduce moiré effects. Their contour is based on a customized kernel frequency estimation to match the shape of the distribution of underlying data values. Previous nonlinear layouts introduce column-centric nonlinear scaling of dot diameters for visualization of high-dynamic-range data with high peaks. We provide a mathematical approach to convert that column-centric scaling to our smooth envelope shape. This formalism allows us to use linear, root, and logarithmic scaling to find ideal dot sizes. Our method iteratively relaxes the dot layout for more correct and aesthetically pleasing results. To achieve this, we modified Lloyd's algorithm with additional constraints and heuristics. We evaluate the layouts of relaxed dot plots against a previously existing nonlinear variant and show that our algorithm produces less error regarding the underlying data while establishing the blue noise property that works against moiré effects. Further, we analyze the readability of our relaxed plots in three crowd-sourced experiments. The results indicate that our proposed technique surpasses traditional dot plots.",Nils Rodrigues;Christoph Schulz 0001;Sören Döring;Daniel Baumgartner;Tim Krake;Daniel Weiskopf,Nils Rodrigues;Christoph Schulz;Sören Döring;Daniel Baumgartner;Tim Krake;Daniel Weiskopf,"University of Stuttgart, Visualization Research Center (VISUS), Germany;University of Stuttgart, Visualization Research Center (VISUS), Germany;University of Stuttgart, Germany;University of Stuttgart, Germany;University of Stuttgart, Visualization Research Center (VISUS), Germany;University of Stuttgart, Visualization Research Center (VISUS), Germany",10.1109/visual.2002.1183777;10.1109/tvcg.2017.2744018;10.1109/tvcg.2009.127;10.1109/tvcg.2011.227,"Dot plot,statistical graphics,Lloyd relaxation,layout,kernel frequency estimation",,0.0,33.0,1172.0,,,traditional dot plots;kernel frequency estimation;reduce moiré effects;high dynamic;logarithmic scaling ideal,0.6531;0.3029;0.2630;0.1755;0.1451,"[np.int64(-1), -1, -1, -1, -1]",152;-1;-1;-1;-1,152,152
Vis,1991,How shall we connect our software tools?,10.1109/visual.1991.175816,http://dx.doi.org/10.1109/VISUAL.1991.175816,292.0,296.0,C,"Software tools are traditionally connected using human-readable files, an approach that buys flexibility and understandability at some cost in performance relative to binary file formats. The possibility of using shared-memory functions to retain most of the existing style while leapfrogging the speed of reading binary files, at least in some environments and for some applications, is explored. Results of a benchmarking experiment confirm the benefits of this alternative.&lt;&lt;ETX&gt;&gt;",Eric Grosse,E. Grosse,"AT and T Bell Laboratories, Inc., Murray Hill, NJ, USA",,,1.0,0.0,4.0,41.0,,,shared memory functions;human readable files;software tools traditionally;retain existing style;cost,0.5206;0.4646;0.4592;0.1038;0.0366,"[np.int64(-1), -1, -1, -1, -1]",231;-1;-1;-1;-1,231,231
InfoVis,2016,VLAT: Development of a Visualization Literacy Assessment Test,10.1109/tvcg.2016.2598920,http://dx.doi.org/10.1109/TVCG.2016.2598920,551.0,560.0,J,"The Information Visualization community has begun to pay attention to visualization literacy; however, researchers still lack instruments for measuring the visualization literacy of users. In order to address this gap, we systematically developed a visualization literacy assessment test (VLAT), especially for non-expert users in data visualization, by following the established procedure of test development in Psychological and Educational Measurement: (1) Test Blueprint Construction, (2) Test Item Generation, (3) Content Validity Evaluation, (4) Test Tryout and Item Analysis, (5) Test Item Selection, and (6) Reliability Evaluation. The VLAT consists of 12 data visualizations and 53 multiple-choice test items that cover eight data visualization tasks. The test items in the VLAT were evaluated with respect to their essentialness by five domain experts in Information Visualization and Visual Analytics (average content validity ratio = 0.66). The VLAT was also tried out on a sample of 191 test takers and showed high reliability (reliability coefficient omega = 0.76). In addition, we demonstrated the relationship between users' visualization literacy and aptitude for learning an unfamiliar visualization and showed that they had a fairly high positive relationship (correlation coefficient = 0.64). Finally, we discuss evidence for the validity of the VLAT and potential research areas that are related to the instrument.",Sukwon Lee;Sung-Hee Kim;Bum Chul Kwon,Sukwon Lee;Sung-Hee Kim;Bum Chul Kwon,"School of Industrial Engineering, Purdue University, West Lafayette, IN, USA;Samsung Electronics Co., Ltd., Seoul, South Korea;IBM T.J. Watson Research Center, Yorktown Heights, NY, USA",10.1109/tvcg.2014.2346419;10.1109/tvcg.2014.2346481;10.1109/tvcg.2014.2346984;10.1109/visual.1991.175815;10.1109/tvcg.2007.70515;10.1109/tvcg.2015.2467195;10.1109/vast.2011.6102435;10.1109/infvis.2005.1532136;10.1109/tvcg.2013.124;10.1109/tvcg.2015.2467201;10.1109/tvcg.2014.2346419,Visualization Literacy;Assessment Test;Instrument;Measurement;Aptitude;Education,156.0,117.0,55.0,4550.0,,,measuring visualization literacy;users data;test item generation;evaluated respect essentialness;order address,0.8405;0.2486;0.0789;0.0049;-0.0706,"[np.int64(-1), -1, -1, -1, -1]",211;-1;-1;-1;-1,211,211
Vis,2010,Superquadric Glyphs for Symmetric Second-Order Tensors,10.1109/tvcg.2010.199,http://dx.doi.org/10.1109/TVCG.2010.199,1595.0,1604.0,J,"Symmetric second-order tensor fields play a central role in scientific and biomedical studies as well as in image analysis and feature-extraction methods. The utility of displaying tensor field samples has driven the development of visualization techniques that encode the tensor shape and orientation into the geometry of a tensor glyph. With some exceptions, these methods work only for positive-definite tensors (i.e. having positive eigenvalues, such as diffusion tensors). We expand the scope of tensor glyphs to all symmetric second-order tensors in two and three dimensions, gracefully and unambiguously depicting any combination of positive and negative eigenvalues. We generalize a previous method of superquadric glyphs for positive-definite tensors by drawing upon a larger portion of the superquadric shape space, supplemented with a coloring that indicates the tensor's quadratic form. We show that encoding arbitrary eigenvalue sign combinations requires design choices that differ fundamentally from those in previous work on traceless tensors (arising in the study of liquid crystals). Our method starts with a design of 2-D tensor glyphs guided by principles of symmetry and continuity, and creates 3-D glyphs that include the 2-D glyphs in their axis-aligned cross-sections. A key ingredient of our method is a novel way of mapping from the shape space of three-dimensional symmetric second-order tensors to the unit square. We apply our new glyphs to stress tensors from mechanics, geometry tensors and Hessians from image analysis, and rate-of-deformation tensors in computational fluid dynamics.",Thomas Schultz 0001;Gordon L. Kindlmann,Thomas Schultz;Gordon L. Kindlmann,"Computer Science Department, Computation Institute, University of Chicago, USA;Computer Science Department, Computation Institute, University of Chicago, USA",10.1109/visual.1999.809905;10.1109/tvcg.2006.134;10.1109/visual.1998.745294;10.1109/tvcg.2006.181;10.1109/visual.1991.175773;10.1109/tvcg.2009.184;10.1109/tvcg.2006.182;10.1109/tvcg.2009.177;10.1109/tvcg.2010.166;10.1109/visual.1993.398849;10.1109/visual.2003.1250414;10.1109/visual.1994.346326;10.1109/visual.1997.663929;10.1109/visual.2002.1183797;10.1109/visual.2003.1250376;10.1109/visual.2005.1532774;10.1109/visual.2004.80;10.1109/tvcg.2006.115;10.1109/visual.1999.809905,"Tensor Glyphs, Stress Tensors, Rate-of-Deformation Tensors, Geometry Tensors, Glyph Design",109.0,89.0,61.0,923.0,,,tensor shape;negative eigenvalues generalize;glyph exceptions methods;unambiguously;driven development,0.6665;0.2313;0.1820;0.1497;-0.0368,"[np.int64(-1), -1, -1, -1, -1]",17;-1;-1;-1;-1,17,17
InfoVis,2003,Visualization of Labeled Data Using Linear Transformation,10.1109/infvis.2003.1249017,http://doi.ieeecomputersociety.org/10.1109/INFVIS.2003.1249017,121.0,128.0,C,"We present a novel family of data-driven linear transformations, aimed at visualizing multivariate data in a low-dimensional space in a way that optimally preserves the structure of the data. The well-studied PCA and Fisher's LDA (linear discriminant analysis) are shown to be special members in this family of transformations, and we demonstrate how to generalize these two methods such as to enhance their performance. Furthermore, our technique is the only one, to the best of our knowledge, that reflects in the resulting embedding both the data coordinates and pairwise similarities and/or dissimilarities between the data elements. Even more so, when information on the clustering (labeling) decomposition of the data is known, this information can be integrated in the linear transformation, resulting in embeddings that clearly show the separation between the clusters, as well as their infrastructure. All this makes our technique very flexible and powerful, and lets us cope with kinds of data that other techniques fail to describe properly.",Yehuda Koren;Liran Carmel,Y. Koren;L. Carmel,"Dept. of Computer Science and Applied Mathematics, The Weizmann Institute of Science, Rehovot, Israel;Dept. of Computer Science and Applied Mathematics, The Weizmann Institute of Science, Rehovot, Israel",10.1109/infvis.2002.1173159;10.1109/infvis.2001.963275;10.1109/infvis.2002.1173161,"visualization, dimensionality-reduction, projection, principal component analysis, Fisher's linear discriminant analysis, eigenprojection, classification",89.0,33.0,9.0,242.0,,,visualizing multivariate data;lda linear discriminant;optimally preserves structure;clusters infrastructure;techniques fail properly,0.6285;0.5033;0.2483;0.0906;-0.0364,"[np.int64(-1), np.int64(-1), -1, -1, -1]",184;37;-1;-1;-1,37;184,184
VAST,2016,A Visual Analytics Approach for Understanding Reasons behind Snowballing and Comeback in MOBA Games,10.1109/tvcg.2016.2598415,http://dx.doi.org/10.1109/TVCG.2016.2598415,211.0,220.0,J,"To design a successful Multiplayer Online Battle Arena (MOBA) game, the ratio of snowballing and comeback occurrences to all matches played must be maintained at a certain level to ensure its fairness and engagement. Although it is easy to identify these two types of occurrences, game developers often find it difficult to determine their causes and triggers with so many game design choices and game parameters involved. In addition, the huge amounts of MOBA game data are often heterogeneous, multi-dimensional and highly dynamic in terms of space and time, which poses special challenges for analysts. In this paper, we present a visual analytics system to help game designers find key events and game parameters resulting in snowballing or comeback occurrences in MOBA game data. We follow a user-centered design process developing the system with game analysts and testing with real data of a trial version MOBA game from NetEase Inc. We apply novel visualization techniques in conjunction with well-established ones to depict the evolution of players' positions, status and the occurrences of events. Our system can reveal players' strategies and performance throughout a single match and suggest patterns, e.g., specific player' actions and game events, that have led to the final occurrences. We further demonstrate a workflow of leveraging human analyzed patterns to improve the scalability and generality of match data analysis. Finally, we validate the usability of our system by proving the identified patterns are representative in snowballing or comeback matches in a one-month-long MOBA tournament dataset.",Quan Li;Peng Xu;Yeukyin Chan;Yun Wang 0012;Zhipeng Wang;Huamin Qu;Xiaojuan Ma,Quan Li;Peng Xu;Yeuk Yin Chan;Yun Wang;Zhipeng Wang;Huamin Qu;Xiaojuan Ma,"Hong Kong University of Science and Technology;NetEase, Inc.;Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;China Academy of Art;Hong Kong University of Science and Technology;Hong Kong University of Science and Technology",10.1109/tvcg.2014.2346445;10.1109/visual.2004.120;10.1109/vast.2015.7347633;10.1109/vast.2014.7042477;10.1109/vast.2014.7042478;10.1109/tvcg.2013.192;10.1109/tvcg.2012.263;10.1109/tvcg.2014.2346445,Game play data visualization;visual knowledge discovery;visual knowledge representation;and game reconstruction,53.0,37.0,41.0,2749.0,,,game analysts;novel visualization techniques;comeback matches month;data follow user;led final occurrences,0.5607;0.3179;0.2658;0.1986;0.0782,"[np.int64(-1), -1, -1, -1, -1]",76;-1;-1;-1;-1,76,76
Vis,1996,Real-time incremental visualization of dynamic ultrasound volumes using parallel BSP trees,10.1109/visual.1996.568114,http://dx.doi.org/10.1109/VISUAL.1996.568114,235.0,240.0,C,"We present a method for producing real-time volume visualizations of continuously captured, arbitrarily-oriented 2D arrays (slices) of data. Our system constructs a 3D representation on-the-fly from incoming 2D ultrasound slices by modeling and rendering the slices as planar polygons with translucent surface textures. We use binary space partition (BSP) tree data structures to provide non-intersecting, visibility-ordered primitives for accurate opacity accumulation images. New in our system is a method of using parallel, time-shifted BSP trees to efficiently manage the continuously captured ultrasound data and to decrease the variability in image generation time between output frames. This technique is employed in a functioning real-time augmented reality system that a physician has used to examine human patients prior to breast biopsy procedures. We expect the technique can be used for real-time visualization of any 2D data being collected from a tracked sensor moving along an arbitrary path.",William F. Garrett;Henry Fuchs;Mary C. Whitton;Andrei State,W.F. Garrett;H. Fuchs;M.C. Whitton;A. State,"Department of Computer Science, University of North Carolina, Chapel Hill, USA;Department of Computer Science, University of North Carolina, Chapel Hill, USA;Department of Computer Science, University of North Carolina, Chapel Hill, USA;Department of Computer Science, University of North Carolina, Chapel Hill, USA",10.1109/visual.1991.175802;10.1109/visual.1994.346295;10.1109/visual.1991.175802,"Augmented reality, ultrasound echography, 3D medical imaging, BSP tree",119.0,10.0,24.0,137.0,,,2d ultrasound slices;visibility;tree data structures;textures use binary;functioning real time,0.6199;0.2877;0.2718;0.1754;0.1694,"[np.int64(-1), -1, -1, -1, -1]",132;-1;-1;-1;-1,132,132
VAST,2012,A case study: Tracking and visualizing the evolution of dark matter halos and groups of satellite halos in cosmology simulations,10.1109/vast.2012.6400532,http://dx.doi.org/10.1109/VAST.2012.6400532,243.0,244.0,M,"In this poster, we track the evolution of cosmic structures and higher level host structures in cosmological simulation as they interact with each other. The structures found in these simulations are made up of groups of dark matter tracer particles called satellite halos and groups of satellite halos called host halos. We implement a multilevel tracking model to track dark matter tracer particles, satellite halos and host halos to understand their behaviour and show how the different structures are formed over time. We also represent the evolution of halos in the form of merger trees for detailed analysis by cosmologists.",Jay Takle;Deborah Silver;Katrin Heitmann,Jay Takle;Deborah Silver;Katrin Heitmann,"Rutgers The State University of New Jersey, New Brunswick, NJ, US;Rutgers The State University of New Jersey, New Brunswick, NJ, US;Argonne National Laboratory, Argonne, IL, US",,,10.0,8.0,7.0,170.0,,,cosmic structures;form merger trees;halos host;multilevel tracking model;evolution,0.6431;0.3389;0.3303;0.2522;0.1387,"[np.int64(-1), -1, -1, -1, -1]",2;-1;-1;-1;-1,2,2
Vis,2010,Gradient Estimation Revitalized,10.1109/tvcg.2010.160,http://dx.doi.org/10.1109/TVCG.2010.160,1495.0,1504.0,J,"We investigate the use of a Fourier-domain derivative error kernel to quantify the error incurred while estimating the gradient of a function from scalar point samples on a regular lattice. We use the error kernel to show that gradient reconstruction quality is significantly enhanced merely by shifting the reconstruction kernel to the centers of the principal lattice directions. Additionally, we exploit the algebraic similarities between the scalar and derivative error kernels to design asymptotically optimal gradient estimation filters that can be factored into an infinite impulse response interpolation prefilter and a finite impulse response directional derivative filter. This leads to a significant performance gain both in terms of accuracy and computational efficiency. The interpolation prefilter provides an accurate scalar approximation and can be re-used to cheaply compute directional derivatives on-the-fly without the need to store gradients. We demonstrate the impact of our filters in the context of volume rendering of scalar data sampled on the Cartesian and Body-Centered Cubic lattices. Our results rival those obtained from other competitive gradient estimation methods while incurring no additional computational or storage overhead.",Usman R. Alim;Torsten Möller;Laurent Condat,Usman Alim;Torsten Moller;Laurent Condat,"Graphics, Usability, and Visualization GrUVi Laboratory, Simon Fraser University, Burnaby, BC, Canada;Graphics, Usability, and Visualization GrUVi Laboratory, Simon Fraser University, Burnaby, BC, Canada;CNRS-UCBN-ENSICAEN, GREYC, Caen, France",10.1109/visual.2001.964498;10.1109/visual.1994.346331;10.1109/visual.1997.663848;10.1109/visual.2004.65,"Derivative, Gradient, Reconstruction, Sampling, Lattice, Interpolation, Approximation, Frequency Error Kernel",26.0,9.0,37.0,576.0,,,gradient reconstruction;lattices results rival;use fourier;prefilter provides;cheaply,0.5350;0.2511;0.1982;0.1177;0.0440,"[np.int64(-1), -1, -1, -1, -1]",247;-1;-1;-1;-1,247,247
Vis,1998,Hierarchical volume analysis and visualization based on morphological operators,10.1109/visual.1998.745321,http://dx.doi.org/10.1109/VISUAL.1998.745321,335.0,341.0,C,"One common problem in the practical application of volume visualization is the proper choice of transfer functions in order to color different parts of the volume meaningfully. This interactive process can be very complicated and time consuming. An alternative to the adjustment of transfer functions is the application of segmentation algorithms. These algorithms are often dedicated to a limited range of data sets and tend to be very compute intensive. We propose a morphology based hierarchical analysis to estimate the optical properties of the volume to be rendered. This approach requires fewer parameters and incorporates also spatial information, but it is far less compute intensive than most of the segmentation methods. The hierarchical analysis is constructed in analogy to the wavelet analysis, except for the fact, that nonlinear filters are used in our case. These morphological operators have a lower distortional influence on the analyzed structures than the usual linear filters. A special decomposition of the morphological operators is discussed, which leads to an efficient implementation of this approach. This technique reduces the three dimensional analysis to a one dimensional computation, as it is done in tensor product based linear filters. The resulting decomposition may also be parallelized easily. We demonstrate the usefulness of the proposed technique by applying it to medical and technical data sets.",Christoph Lürig;Thomas Ertl,C. Lurig;T. Ertl,"Computer Graphics Group, Universität Erlangen Nürnberg, Germany;Computer Graphics Group, Universität Erlangen Nürnberg, Germany",,,19.0,5.0,20.0,60.0,,,volume visualization;morphology based hierarchical;filters special decomposition;optical properties;time consuming alternative,0.6390;0.4866;0.2518;0.2306;0.0312,"[np.int64(-1), -1, -1, -1, -1]",84;-1;-1;-1;-1,84,84
VAST,2013,Space Transformation for Understanding Group Movement,10.1109/tvcg.2013.193,http://dx.doi.org/10.1109/TVCG.2013.193,2169.0,2178.0,J,"We suggest a methodology for analyzing movement behaviors of individuals moving in a group. Group movement is analyzed at two levels of granularity: the group as a whole and the individuals it comprises. For analyzing the relative positions and movements of the individuals with respect to the rest of the group, we apply space transformation, in which the trajectories of the individuals are converted from geographical space to an abstract 'group space'. The group space reference system is defined by both the position of the group center, which is taken as the coordinate origin, and the direction of the group's movement. Based on the individuals' positions mapped onto the group space, we can compare the behaviors of different individuals, determine their roles and/or ranks within the groups, and, possibly, understand how group movement is organized. The utility of the methodology has been evaluated by applying it to a set of real data concerning movements of wild social animals and discussing the results with experts in animal ethology.",Natalia V. Andrienko;Gennady L. Andrienko;Louise Barrett;Marcus Dostie;S. Peter Henzi,Natalia Andrienko;Gennady Andrienko;Louise Barrett;Marcus Dostie;Peter Henzi,"Fraunhofer Institute IAIS, Germany;Fraunhofer Institute IAIS, Germany;University of Lethbridge and University of South Africa;University of Lethbridge and University of South Africa;University of Lethbridge and University of South Africa",10.1109/infvis.2005.1532142;10.1109/infvis.2004.27;10.1109/vast.2010.5653580;10.1109/infvis.2005.1532142,"Visual analytics, movement data, collective movement",68.0,48.0,36.0,935.0,,,group movement analyzed;experts animal ethology;roles ranks;space reference defined;different,0.7300;0.3482;0.1992;0.1284;0.0557,"[np.int64(-1), -1, -1, -1, -1]",223;-1;-1;-1;-1,223,223
Vis,2006,Isosurface Extraction and Spatial filtering using Persistent Octree (POT),10.1109/tvcg.2006.157,http://dx.doi.org/10.1109/TVCG.2006.157,1283.0,1290.0,J,"We propose a novel persistent octree (POT) indexing structure for accelerating isosurface extraction and spatial filtering from volumetric data. This data structure efficiently handles a wide range of visualization problems such as the generation of view-dependent isosurfaces, ray tracing, and isocontour slicing for high dimensional data. POT can be viewed as a hybrid data structure between the interval tree and the branch-on-need octree (BONO) in the sense that it achieves the asymptotic bound of the interval tree for identifying the active cells corresponding to an isosurface and is more efficient than BONO for handling spatial queries. We encode a compact octree for each isovalue. Each such octree contains only the corresponding active cells, in such a way that the combined structure has linear space. The inherent hierarchical structure associated with the active cells enables very fast filtering of the active cells based on spatial constraints. We demonstrate the effectiveness of our approach by performing view-dependent isosurfacing on a wide variety of volumetric data sets and 4D isocontour slicing on the time-varying Richtmyer-Meshkov instability dataset",Qingmin Shi;Joseph F. JáJá,Qingmin Shi;Joseph JaJa,"Institute for Advanced Computer Studies and the Department of Electrical and Computer Engineering, University of Maryland, College Park, USA;Institute for Advanced Computer Studies and the Department of Electrical and Computer Engineering, University of Maryland, College Park, USA",10.1109/visual.1998.745713;10.1109/visual.1991.175780;10.1109/visual.1998.745299;10.1109/visual.1996.568121;10.1109/visual.1999.809910;10.1109/visual.2002.1183810;10.1109/visual.1998.745298;10.1109/visual.1999.809879;10.1109/visual.2004.52;10.1109/visual.1998.745300;10.1109/visual.2003.1250373;10.1109/visual.1998.745713,"scientific visualization, isosurface extraction, indexing",29.0,12.0,30.0,274.0,,,accelerating isosurface extraction;interval tree branch;active cells based;data pot viewed;linear space inherent,0.6266;0.2921;0.1755;0.1241;-0.0059,"[np.int64(-1), -1, -1, -1, -1]",91;-1;-1;-1;-1,91,91
VAST,2013,MotionExplorer: Exploratory Search in Human Motion Capture Data Based on Hierarchical Aggregation,10.1109/tvcg.2013.178,http://dx.doi.org/10.1109/TVCG.2013.178,2257.0,2266.0,J,"We present MotionExplorer, an exploratory search and analysis system for sequences of human motion in large motion capture data collections. This special type of multivariate time series data is relevant in many research fields including medicine, sports and animation. Key tasks in working with motion data include analysis of motion states and transitions, and synthesis of motion vectors by interpolation and combination. In the practice of research and application of human motion data, challenges exist in providing visual summaries and drill-down functionality for handling large motion data collections. We find that this domain can benefit from appropriate visual retrieval and analysis support to handle these tasks in presence of large motion data. To address this need, we developed MotionExplorer together with domain experts as an exploratory search system based on interactive aggregation and visualization of motion states as a basis for data navigation, exploration, and search. Based on an overview-first type visualization, users are able to search for interesting sub-sequences of motion based on a query-by-example metaphor, and explore search results by details on demand. We developed MotionExplorer in close collaboration with the targeted users who are researchers working on human motion synthesis and analysis, including a summative field study. Additionally, we conducted a laboratory design study to substantially improve MotionExplorer towards an intuitive, usable and robust design. MotionExplorer enables the search in human motion capture data with only a few mouse clicks. The researchers unanimously confirm that the system can efficiently support their work.",Jürgen Bernard;Nils Wilhelm;Björn Krüger;Thorsten May;Tobias Schreck;Jörn Kohlhammer,Jürgen Bernard;Nils Wilhelm;Björn Krüger;Thorsten May;Tobias Schreck;Jörn Kohlhammer,"Fraunhofer Institute for Computer Graphics Research, Darmstadt, Germany;Fraunhofer Institute for Computer Graphics Research, Darmstadt, Germany;Institute of Computer Science, Universität Bonn, Germany;Fraunhofer Institute for Computer Graphics Research, Darmstadt, Germany;Data Analysis and Visualization Group, Universität Konstanz, Germany;Fraunhofer Institute for Computer Graphics Research, Darmstadt, Germany",10.1109/visual.1999.809865;10.1109/vast.2008.4677350;10.1109/tvcg.2006.120;10.1109/tvcg.2011.181;10.1109/tvcg.2011.188;10.1109/visual.1999.809865,"Visual analytics, exploratory search, multivariate time series, motion capture data, data aggregation, cluster glyph",109.0,69.0,44.0,2126.0,,,human motion data;metaphor explore;summaries drill functionality;laboratory design;large,0.6573;0.2241;0.1463;0.1415;-0.0028,"[np.int64(-1), -1, -1, -1, -1]",6;-1;-1;-1;-1,6,6
VAST,2017,Visual Causality Analysis Made Practical,10.1109/vast.2017.8585647,http://dx.doi.org/10.1109/VAST.2017.8585647,151.0,161.0,C,"Deriving the exact casual model that governs the relations between variables in a multidimensional dataset is difficult in practice. It is because causal inference algorithms by themselves typically cannot encode an adequate amount of domain knowledge to break all ties. Visual analytic approaches are considered a feasible alternative to fully automated methods. However, their application in real-world scenarios can be tedious. This paper focuses on these practical aspects of visual causality analysis. The most imperative of these aspects is posed by Simpson' Paradox. It implies the existence of multiple causal models differing in both structure and parameter depending on how the data is subdivided. We propose a comprehensive interface that engages human experts in identifying these subdivisions and allowing them to establish the corresponding causal models via a rich set of interactive facilities. Other features of our interface include: (1) a new causal network visualization that emphasizes the flow of causal dependencies, (2) a model scoring mechanism with visual hints for interactive model refinement, and (3) flexible approaches for handling heterogeneous data. Various real-world data examples are given.",Jun Wang;Klaus Mueller 0001,Jun Wang;Klaus Mueller,"Visual Analytics and Imaging Lab, Stony Brook University;Visual Analytics and Imaging Lab, Stony Brook University",10.1109/tvcg.2015.2467931;10.1109/tvcg.2012.225;10.1109/tvcg.2013.200;10.1109/tvcg.2016.2598797;10.1109/tvcg.2016.2598919;10.1109/tvcg.2016.2598543;10.1109/tvcg.2015.2467691;10.1109/tvcg.2015.2467931,"Visual knowledge discovery,Causality,Hypothesis testing,Visual evidence,High-dimensional data",39.0,30.0,49.0,794.0,,,visual causality analysis;simpson;model scoring mechanism;handling heterogeneous;deriving exact,0.7849;0.2984;0.1910;0.1536;0.0147,"[np.int64(-1), -1, -1, -1, -1]",160;-1;-1;-1;-1,160,160
InfoVis,2009,Scattering Points in Parallel Coordinates,10.1109/tvcg.2009.179,http://dx.doi.org/10.1109/TVCG.2009.179,1001.0,1008.0,J,"In this paper, we present a novel parallel coordinates design integrated with points (scattering points in parallel coordinates, SPPC), by taking advantage of both parallel coordinates and scatterplots. Different from most multiple views visualization frameworks involving parallel coordinates where each visualization type occupies an individual window, we convert two selected neighboring coordinate axes into a scatterplot directly. Multidimensional scaling is adopted to allow converting multiple axes into a single subplot. The transition between two visual types is designed in a seamless way. In our work, a series of interaction tools has been developed. Uniform brushing functionality is implemented to allow the user to perform data selection on both points and parallel coordinate polylines without explicitly switching tools. A GPU accelerated dimensional incremental multidimensional scaling (DIMDS) has been developed to significantly improve the system performance. Our case study shows that our scheme is more efficient than traditional multi-view methods in performing visual analysis tasks.",Xiaoru Yuan;Peihong Guo;He Xiao;Hong Zhou 0004;Huamin Qu,Xiaoru Yuan;Peihong Guo;He Xiao;Hong Zhou;Huamin Qu,"Key Laboratory of Machine Perception (Ministry of Education) and School of EECS, Peking University, Beijing, China;Key Laboratory of Machine Perception (Ministry of Education) and School of EECS, Peking University, Beijing, China;Key Laboratory of Machine Perception (Ministry of Education) and School of EECS, Peking University, Beijing, China;Department of Computer Science and Engineering, Hong Kong University of Science and Technology, Hong Kong, China;Department of Computer Science and Engineering, Hong Kong University of Science and Technology, Hong Kong, China",10.1109/tvcg.2008.119;10.1109/infvis.2005.1532139;10.1109/visual.1997.663867;10.1109/visual.1990.146402;10.1109/infvis.2005.1532141;10.1109/visual.1997.663916;10.1109/tvcg.2006.138;10.1109/visual.1997.663866;10.1109/visual.1996.567800;10.1109/infvis.2005.1532138;10.1109/infvis.2003.1249015;10.1109/visual.1996.567787;10.1109/infvis.1998.729559;10.1109/infvis.2003.1249008;10.1109/infvis.2002.1173157;10.1109/visual.1999.809866;10.1109/infvis.2003.1249023;10.1109/tvcg.2006.170;10.1109/infvis.2004.68;10.1109/infvis.2004.15;10.1109/tvcg.2008.153;10.1109/tvcg.2008.119,"Parallel Coordinates, Scatterplots, Information Visualization, Multidimensional Scaling",201.0,101.0,44.0,1923.0,,,parallel coordinates visualization;scattering;dimds developed significantly;perform data selection;explicitly switching tools,0.6951;0.1970;0.1581;0.1409;0.1252,"[np.int64(-1), -1, -1, -1, -1]",65;-1;-1;-1;-1,65,65
Vis,1994,Feature detection from vector quantities in a numerically simulated hypersonic flow field in combination with experimental flow visualization,10.1109/visual.1994.346329,http://dx.doi.org/10.1109/VISUAL.1994.346329,117.0,,C,"In computational fluid dynamics visualization is a frequently used tool for data evaluation, understanding of flow characteristics, and qualitative comparison to flow visualizations originating from experiments. Building on an existing visualization software system, that allows for a careful selection of state-of-the-art visualization techniques and some extensions, it became possible to present various features of the data in a single image. The visualizations show vortex position and rotation as well as skin-friction lines, experimental oil-flow traces, and shock-wave positions. By adding experimental flow visualization a comparison between numerical simulation and wind-tunnel flow becomes possible up to a high level of detail. Since some of the underlying algorithms are not yet described in detail in the visualization literature, some experiences gained from the implementation are illustrated.&lt;&lt;ETX&gt;&gt;",Hans-Georg Pagendarm;Birgit Walter,H.-G. Pagendarm;B. Walter,"DLR, German Aerospace Research Establishment (DLR), Gottingen, Germany;DLR, German Aerospace Research Establishment (DLR), Gottingen, Germany",10.1109/visual.1992.235225;10.1109/visual.1991.175789;10.1109/visual.1992.235225,,52.0,17.0,23.0,149.0,,,fluid dynamics visualization;underlying algorithms;etx gt gt;careful selection state;literature experiences gained,0.7763;0.1287;0.0378;-0.0063;-0.1058,"[np.int64(-1), -1, -1, -1, -1]",146;-1;-1;-1;-1,146,146
Vis,2002,Fast visualization of plane-like structures in voxel data,10.1109/visual.2002.1183753,http://dx.doi.org/10.1109/VISUAL.2002.1183753,29.0,36.0,C,"We present a robust, noise-resistant criterion characterizing plane-like skeletons in binary voxel objects. It is based on a distance map and the geodesic distance along the object's boundary. A parameter allows us to control the noise sensitivity. If needed, homotopy with the original object might be reconstructed in a second step, using an improved distance ordered thinning algorithm. The skeleton is analyzed to create a geometric representation for rendering. Plane-like parts are transformed into an triangulated surface not enclosing a volume by a suitable triangulation scheme. The resulting surfaces have lower triangle count than those created with standard methods and tend to maintain the original geometry, even after simplification with a high decimation rate. Our algorithm allows us to interactively render expressive images of complex 3D structures, emphasizing independently plane-like and rod-like structures. The methods are applied for visualization of the microstructure of bone biopsies.",Steffen Prohaska;Hans-Christian Hege,S. Prohaska;H.-C. Hege,"Department for Scientific Visualization, Zuse Institute Berlin, Germany;Department for Scientific Visualization, Zuse Institute Berlin, Germany",,"skeletonization, thinning, distance transform, triangulation, visualization",55.0,10.0,19.0,138.0,,,skeletons binary voxel;distance map geodesic;interactively render;scheme resulting surfaces;noise sensitivity needed,0.5956;0.2619;0.2059;0.1560;0.1528,"[np.int64(-1), -1, -1, -1, -1]",311;-1;-1;-1;-1,311,311
InfoVis,2017,Taking Word Clouds Apart: An Empirical Investigation of the Design Space for Keyword Summaries,10.1109/tvcg.2017.2746018,http://dx.doi.org/10.1109/TVCG.2017.2746018,657.0,666.0,J,"In this paper we present a set of four user studies aimed at exploring the visual design space of what we call keyword summaries: lists of words with associated quantitative values used to help people derive an intuition of what information a given document collection (or part of it) may contain. We seek to systematically study how different visual representations may affect people's performance in extracting information out of keyword summaries. To this purpose, we first create a design space of possible visual representations and compare the possible solutions in this design space through a variety of representative tasks and performance metrics. Other researchers have, in the past, studied some aspects of effectiveness with word clouds, however, the existing literature is somewhat scattered and do not seem to address the problem in a sufficiently systematic and holistic manner. The results of our studies showed a strong dependency on the tasks users are performing. In this paper we present details of our methodology, the results, as well as, guidelines on how to design effective keyword summaries based in our discoveries.",Cristian Felix;Steven Franconeri;Enrico Bertini,Cristian Felix;Steven Franconeri;Enrico Bertini,New York University;Northwestern University;New York University,10.1109/vast.2009.5333443;10.1109/tvcg.2016.2598447;10.1109/tvcg.2011.176;10.1109/tvcg.2010.194;10.1109/tvcg.2009.165;10.1109/tvcg.2009.171;10.1109/vast.2009.5333443,"Word Clouds,Tag Clouds,Text Visualization,Keyword Summaries",78.0,45.0,27.0,1266.0,,,information keyword summaries;design space;possible visual;quantitative values used;set user,0.6430;0.2912;0.1984;0.1917;-0.0702,"[np.int64(-1), -1, -1, -1, -1]",243;-1;-1;-1;-1,243,243
InfoVis,2016,Map LineUps: Effects of spatial structure on graphical inference,10.1109/tvcg.2016.2598862,http://dx.doi.org/10.1109/TVCG.2016.2598862,391.0,400.0,J,"Fundamental to the effective use of visualization as an analytic and descriptive tool is the assurance that presenting data visually provides the capability of making inferences from what we see. This paper explores two related approaches to quantifying the confidence we may have in making visual inferences from mapped geospatial data. We adapt Wickham et al.'s `Visual Line-up' method as a direct analogy with Null Hypothesis Significance Testing (NHST) and propose a new approach for generating more credible spatial null hypotheses. Rather than using as a spatial null hypothesis the unrealistic assumption of complete spatial randomness, we propose spatially autocorrelated simulations as alternative nulls. We conduct a set of crowdsourced experiments (n=361) to determine the just noticeable difference (JND) between pairs of choropleth maps of geographic units controlling for spatial autocorrelation (Moran's I statistic) and geometric configuration (variance in spatial unit area). Results indicate that people's abilities to perceive differences in spatial autocorrelation vary with baseline autocorrelation structure and the geometric configuration of geographic units. These results allow us, for the first time, to construct a visual equivalent of statistical power for geospatial data. Our JND results add to those provided in recent years by Klippel et al. (2011), Harrison et al. (2014) and Kay &amp;amp; Heer (2015) for correlation visualization. Importantly, they provide an empirical basis for an improved construction of visual line-ups for maps and the development of theory to inform geospatial tests of graphical inference.",Roger Beecham;Jason Dykes;Wouter Meulemans;Aidan Slingsby;Cagatay Turkay;Jo Wood,Roger Beecham;Jason Dykes;Wouter Meulemans;Aidan Slingsby;Cagatay Turkay;Jo Wood,"giCentre, City University London;giCentre, City University London;giCentre, City University London;giCentre, City University London;giCentre, City University London;giCentre, City University London",10.1109/tvcg.2015.2467671;10.1109/tvcg.2015.2469125;10.1109/tvcg.2014.2346979;10.1109/tvcg.2010.161;10.1109/tvcg.2015.2467671,Graphical inference;spatial autocorrelation;just noticeable difference;geovisualization;statistical significance,52.0,40.0,20.0,1383.0,HM,,geospatial tests graphical;equivalent statistical power;autocorrelation structure;unrealistic;heer,0.6941;0.1766;0.1679;0.1033;0.0598,"[np.int64(-1), -1, -1, -1, -1]",285;-1;-1;-1;-1,285,285
VAST,2017,Dynamic Influence Networks for Rule-Based Models,10.1109/tvcg.2017.2745280,http://dx.doi.org/10.1109/TVCG.2017.2745280,184.0,194.0,J,"We introduce the Dynamic Influence Network (DIN), a novel visual analytics technique for representing and analyzing rule-based models of protein-protein interaction networks. Rule-based modeling has proved instrumental in developing biological models that are concise, comprehensible, easily extensible, and that mitigate the combinatorial complexity of multi-state and multi-component biological molecules. Our technique visualizes the dynamics of these rules as they evolve over time. Using the data produced by KaSim, an open source stochastic simulator of rule-based models written in the Kappa language, DINs provide a node-link diagram that represents the influence that each rule has on the other rules. That is, rather than representing individual biological components or types, we instead represent the rules about them (as nodes) and the current influence of these rules (as links). Using our interactive DIN-Viz software tool, researchers are able to query this dynamic network to find meaningful patterns about biological processes, and to identify salient aspects of complex rule-based models. To evaluate the effectiveness of our approach, we investigate a simulation of a circadian clock model that illustrates the oscillatory behavior of the KaiC protein phosphorylation cycle.",Angus Graeme Forbes;Andrew Burks;Kristine Lee;Xing Li;Pierre Boutillier;Jean Krivine;Walter Fontana,Angus G. Forbes;Andrew Burks;Kristine Lee;Xing Li;Pierre Boutillier;Jean Krivine;Walter Fontana,"University of California, Santa Cruz;University of Illinois, Chicago;University of Illinois, Chicago;University of Illinois, Chicago;Harvard Medical School;Université Paris Diderot;Harvard Medical School",10.1109/tvcg.2011.185;10.1109/tvcg.2010.126;10.1109/tvcg.2013.198;10.1109/tvcg.2007.70528;10.1109/tvcg.2013.154;10.1109/tvcg.2012.189;10.1109/tvcg.2011.185,"Dynamic networks,biological data visualization,rule-based modeling,protein-protein interaction networks",21.0,21.0,67.0,666.0,,,protein interaction networks;visualizes dynamics;circadian clock;simulator rule;easily,0.6502;0.4457;0.1963;0.1267;0.0505,"[np.int64(-1), -1, -1, -1, -1]",21;-1;-1;-1;-1,21,21
Vis,1997,Visualization of height field data with physical models and texture photomapping,10.1109/visual.1997.663862,http://dx.doi.org/10.1109/VISUAL.1997.663862,89.0,94.0,C,"The paper discusses a unique way to visualize height field data-the use of solid fabricated parts with a photomapped texture to display scalar information. In this process, the data in a height field are turned into a 3D solid representation through solid freeform fabrication techniques, in this case laminated object manufacturing. Next, that object is used as a 3D ""photographic plate"" to allow a texture image representing scalar data to be permanently mapped onto it. The paper discusses this process and how it can be used in different visualization situations.",Dru Clark;Michael J. Bailey,D. Clark;M. Bailey,"University of California, San Diego, USA;University of California, San Diego, USA",10.1109/visual.1991.175814;10.1109/visual.1991.175814,"Computer graphics, object modeling, scientific visualization",13.0,2.0,15.0,56.0,,,fabricated parts photomapped;data height field;3d solid;texture display scalar;discusses unique way,0.5925;0.4268;0.4084;0.3738;0.0631,"[np.int64(-1), -1, -1, -1, -1]",292;-1;-1;-1;-1,292,292
VAST,2020,"VATLD: A Visual Analytics System to Assess, Understand and Improve Traffic Light Detection",10.1109/tvcg.2020.3030350,http://dx.doi.org/10.1109/TVCG.2020.3030350,261.0,271.0,J,"Traffic light detection is crucial for environment perception and decision-making in autonomous driving. State-of-the-art detectors are built upon deep Convolutional Neural Networks (CNNs) and have exhibited promising performance. However, one looming concern with CNN based detectors is how to thoroughly evaluate the performance of accuracy and robustness before they can be deployed to autonomous vehicles. In this work, we propose a visual analytics system, VATLD, equipped with a disentangled representation learning and semantic adversarial learning, to assess, understand, and improve the accuracy and robustness of traffic light detectors in autonomous driving applications. The disentangled representation learning extracts data semantics to augment human cognition with human-friendly visual summarization, and the semantic adversarial learning efficiently exposes interpretable robustness risks and enables minimal human interaction for actionable insights. We also demonstrate the effectiveness of various performance improvement strategies derived from actionable insights with our visual analytics system, VATLD, and illustrate some practical implications for safety-critical applications in autonomous driving.",Liang Gou;Lincan Zou;Nanxiang Li;Michael Hofmann 0010;Arvind Kumar Shekar;Axel Wendt;Liu Ren,Liang Gou;Lincan Zou;Nanxiang Li;Michael Hofmann;Arvind Kumar Shekar;Axel Wendt;Liu Ren,"Robert Bosch Research and Technology Center, USA;Robert Bosch Research and Technology Center, USA;Robert Bosch Research and Technology Center, USA;Robert Bosch GmbH, Germany;Robert Bosch GmbH, Germany;Robert Bosch GmbH, Germany;Robert Bosch Research and Technology Center, USA",10.1109/tvcg.2016.2598831;10.1109/tvcg.2018.2864812;10.1109/tvcg.2018.2864504;10.1109/tvcg.2017.2744683;10.1109/tvcg.2016.2598831,"Traffic light detection,representation learning,semantic adversarial learning,model diagnosing,autonomous driving",9.0,46.0,48.0,2554.0,BP,,cnn based detectors;disentangled;driving state;semantic;thoroughly evaluate performance,0.5768;0.3388;0.2302;0.1880;0.1081,"[np.int64(-1), -1, -1, -1, -1]",35;-1;-1;-1;-1,35,35
VAST,2014,Interactive Visual Analysis of Image-Centric Cohort Study Data,10.1109/tvcg.2014.2346591,http://dx.doi.org/10.1109/TVCG.2014.2346591,1673.0,1682.0,J,"Epidemiological population studies impose information about a set of subjects (a cohort) to characterize disease-specific risk factors. Cohort studies comprise heterogenous variables describing the medical condition as well as demographic and lifestyle factors and, more recently, medical image data. We propose an Interactive Visual Analysis (IVA) approach that enables epidemiologists to rapidly investigate the entire data pool for hypothesis validation and generation. We incorporate image data, which involves shape-based object detection and the derivation of attributes describing the object shape. The concurrent investigation of image-based and non-image data is realized in a web-based multiple coordinated view system, comprising standard views from information visualization and epidemiological data representations such as pivot tables. The views are equipped with brushing facilities and augmented by 3D shape renderings of the segmented objects, e.g., each bar in a histogram is overlaid with a mean shape of the associated subgroup of the cohort. We integrate an overview visualization, clustering of variables and object shape for data-driven subgroup definition and statistical key figures for measuring the association between variables. We demonstrate the IVA approach by validating and generating hypotheses related to lower back pain as part of a qualitative evaluation.",Paul Klemm;Steffen Oeltze-Jafra;Kai Lawonn;Katrin Hegenscheid;Henry Völzke;Bernhard Preim,Paul Klemm;Steffen Oeltze-Jafra;Kai Lawonn;Katrin Hegenscheid;Henry Völzke;Bernhard Preim,"Otto-von-Guericke University Magdeburg, Germany;Otto-von-Guericke University Magdeburg, Germany;Otto-von-Guericke University Magdeburg, Germany;Ernst-Moritz-Arndt University Greifswald, Germany;Ernst-Moritz-Arndt University Greifswald, Germany;Otto-von-Guericke University Magdeburg, Germany",10.1109/tvcg.2013.160;10.1109/tvcg.2011.185;10.1109/visual.2000.885739;10.1109/tvcg.2011.217;10.1109/tvcg.2007.70569;10.1109/tvcg.2013.160,"Interactive Visual Analysis, Epidemiology, Spine",58.0,36.0,44.0,999.0,,,information visualization epidemiological;shape associated subgroup;web based multiple;pool hypothesis validation;standard,0.6967;0.3016;0.1697;0.1342;0.0111,"[np.int64(-1), -1, -1, -1, -1]",273;-1;-1;-1;-1,273,273
Vis,2021,Perception! Immersion! Empowerment! Superpowers as Inspiration for Visualization,10.1109/tvcg.2021.3114844,http://dx.doi.org/10.1109/TVCG.2021.3114844,22.0,32.0,J,"We explore how the lens of fictional superpowers can help characterize how visualizations empower people and provide inspiration for new visualization systems. Researchers and practitioners often tout visualizations' ability to “make the invisible visible” and to “enhance cognitive abilities.” Meanwhile superhero comics and other modern fiction often depict characters with similarly fantastic abilities that allow them to see and interpret the world in ways that transcend traditional human perception. We investigate the intersection of these domains, and show how the language of superpowers can be used to characterize existing visualization systems and suggest opportunities for new and empowering ones. We introduce two frameworks: The first characterizes seven underlying mechanisms that form the basis for a variety of visual superpowers portrayed in fiction. The second identifies seven ways in which visualization tools and interfaces can instill a sense of empowerment in the people who use them. Building on these observations, we illustrate a diverse set of “visualization superpowers” and highlight opportunities for the visualization community to create new systems and interactions that empower new experiences with data Material and illustrations are available under CC-BY 4.0 at osf.io/8yhfz.",Wesley Willett;Bon Adriel Aseniero;Sheelagh Carpendale;Pierre Dragicevic;Yvonne Jansen;Lora Oehlberg;Petra Isenberg,Wesley Willett;Bon Adriel Aseniero;Sheelagh Carpendale;Pierre Dragicevic;Yvonne Jansen;Lora Oehlberg;Petra Isenberg,"University of Calgary, United States;Autodesk, United States;Simon Fraser Univ., Canada;Universite Paris-Saclay, CNRS. Inria. LISN, France;Sorbonne Universite, CNRS, ISIR, France;University of Calgary, United States;Universite Paris-Saclay, CNRS. Inria. LISN, France",10.1109/tvcg.2019.2934283;10.1109/tvcg.2008.137;10.1109/tvcg.2013.134;10.1109/tvcg.2006.146;10.1109/tvcg.2015.2467551;10.1109/tvcg.2018.2865152;10.1109/visual.2005.1532781;10.1109/tvcg.2016.2598608,"Visualization,superpowers,empowerment,vision,perception,cognition,fiction,situated visualization",6.0,20.0,103.0,2735.0,BP,,visualization superpowers;interpret;fictional;intersection domains;community create new,0.7989;0.2286;0.1928;0.0780;0.0262,"[np.int64(-1), -1, -1, -1, -1]",189;-1;-1;-1;-1,189,189
Vis,1996,Flow visualization for turbomachinery design,10.1109/visual.1996.568137,http://dx.doi.org/10.1109/VISUAL.1996.568137,381.0,384.0,C,"Visualization of CFD data for turbomachinery design poses some special requirements which are often not addressed by standard flow visualization systems. The authors discuss the issues involved with this particular application and its requirements with respect to flow visualization. Aiming at a feature-based visualization for this task, they examine various existing techniques to locate vortices. The specific flow conditions for turbomachines demonstrate limitations of current methods. Visualization of turbomachinery flow thus raises some challenges and research topics, particularly regarding feature extraction.",Martin Roth;Ronald Peikert,M. Roth;R. Peikert,"Swiss Center for Scientific Computing, ETH Zürich, Switzerland;Swiss Center for Scientific Computing, ETH Zürich, Switzerland",10.1109/visual.1991.175773;10.1109/visual.1991.175773,,89.0,26.0,9.0,275.0,BCS,,visualization turbomachinery flow;regarding feature extraction;design poses;limitations current;raises,0.8088;0.2571;0.0886;0.0336;-0.1006,"[np.int64(-1), -1, -1, -1, -1]",240;-1;-1;-1;-1,240,240
SciVis,2012,Interactive Volume Exploration of Petascale Microscopy Data Streams Using a Visualization-Driven Virtual Memory Approach,10.1109/tvcg.2012.240,http://dx.doi.org/10.1109/TVCG.2012.240,2285.0,2294.0,J,"This paper presents the first volume visualization system that scales to petascale volumes imaged as a continuous stream of high-resolution electron microscopy images. Our architecture scales to dense, anisotropic petascale volumes because it: (1) decouples construction of the 3D multi-resolution representation required for visualization from data acquisition, and (2) decouples sample access time during ray-casting from the size of the multi-resolution hierarchy. Our system is designed around a scalable multi-resolution virtual memory architecture that handles missing data naturally, does not pre-compute any 3D multi-resolution representation such as an octree, and can accept a constant stream of 2D image tiles from the microscopes. A novelty of our system design is that it is visualization-driven: we restrict most computations to the visible volume data. Leveraging the virtual memory architecture, missing data are detected during volume ray-casting as cache misses, which are propagated backwards for on-demand out-of-core processing. 3D blocks of volume data are only constructed from 2D microscope image tiles when they have actually been accessed during ray-casting. We extensively evaluate our system design choices with respect to scalability and performance, compare to previous best-of-breed systems, and illustrate the effectiveness of our system for real microscopy data from neuroscience.",Markus Hadwiger;Johanna Beyer;Won-Ki Jeong;Hanspeter Pfister,Markus Hadwiger;Johanna Beyer;Won-Ki Jeong;Hanspeter Pfister,"King Abdullah University for Science and Technology, Saudi Arabia;King Abdullah University for Science and Technology, Saudi Arabia;Ulsan National Institute of Science and Technology (UNIST), South Korea;School of Engineering and Applied Sciences, Harvard University, USA",10.1109/visual.1999.809908;10.1109/visual.2003.1250384;10.1109/tvcg.2009.161;10.1109/visual.1999.809908,"Petascale volume exploration, high-resolution microscopy, high-throughput imaging, neuroscience",102.0,65.0,31.0,1545.0,HM,,petascale volumes imaged;leveraging virtual memory;tiles;handles missing data;naturally does pre,0.5666;0.3218;0.1880;0.0609;0.0007,"[np.int64(-1), -1, -1, -1, -1]",132;-1;-1;-1;-1,132,132
Vis,2021,Human-in-the-loop Extraction of Interpretable Concepts in Deep Learning Models,10.1109/tvcg.2021.3114837,http://dx.doi.org/10.1109/TVCG.2021.3114837,780.0,790.0,J,"The interpretation of deep neural networks (DNNs) has become a key topic as more and more people apply them to solve various problems and making critical decisions. Concept-based explanations have recently become a popular approach for post-hoc interpretation of DNNs. However, identifying human-understandable visual concepts that affect model decisions is a challenging task that is not easily addressed with automatic approaches. We present a novel human-in-the-Ioop approach to generate user-defined concepts for model interpretation and diagnostics. Central to our proposal is the use of active learning, where human knowledge and feedback are combined to train a concept extractor with very little human labeling effort. We integrate this process into an interactive system, ConceptExtract. Through two case studies, we show how our approach helps analyze model behavior and extract human-friendly concepts for different machine learning tasks and datasets and how to use these concepts to understand the predictions, compare model performance and make suggestions for model refinement. Quantitative experiments show that our active learning approach can accurately extract meaningful visual concepts. More importantly, by identifying visual concepts that negatively affect model performance, we develop the corresponding data augmentation strategy that consistently improves model performance.",Zhenge Zhao;Panpan Xu;Carlos Scheidegger;Liu Ren,Zhenge Zhao;Panpan Xu;Carlos Scheidegger;Liu Ren,"University of Arizona, United States;Amazon AWS AI, United States;University of Arizona, United States;Bosch Research North America, United States",10.1109/tvcg.2011.185;10.1109/tvcg.2019.2934659;10.1109/tvcg.2011.185,"Visual Data Exploration,Deep Neural Network,Model Interpretation,Explainable AI",10.0,28.0,55.0,2004.0,,,interpretation deep neural;interactive conceptextract;helps;recently popular approach;generate user,0.5975;0.4486;0.1762;0.0454;0.0085,"[np.int64(-1), -1, -1, -1, -1]",213;-1;-1;-1;-1,213,213
VAST,2015,CiteRivers: Visual Analytics of Citation Patterns,10.1109/tvcg.2015.2467621,http://dx.doi.org/10.1109/TVCG.2015.2467621,190.0,199.0,J,"The exploration and analysis of scientific literature collections is an important task for effective knowledge management. Past interest in such document sets has spurred the development of numerous visualization approaches for their interactive analysis. They either focus on the textual content of publications, or on document metadata including authors and citations. Previously presented approaches for citation analysis aim primarily at the visualization of the structure of citation networks and their exploration. We extend the state-of-the-art by presenting an approach for the interactive visual analysis of the contents of scientific documents, and combine it with a new and flexible technique to analyze their citations. This technique facilitates user-steered aggregation of citations which are linked to the content of the citing publications using a highly interactive visualization approach. Through enriching the approach with additional interactive views of other important aspects of the data, we support the exploration of the dataset over time and enable users to analyze citation patterns, spot trends, and track long-term developments. We demonstrate the strengths of our approach through a use case and discuss it based on expert user feedback.",Florian Heimerl;Qi Han 0006;Steffen Koch 0001;Thomas Ertl,Florian Heimerl;Qi Han;Steffen Koch;Thomas Ertl,"Institute for Visualization and Interactive Systems (VIS), University of Stuttgart;Institute for Visualization and Interactive Systems (VIS), University of Stuttgart;Institute for Visualization and Interactive Systems (VIS), University of Stuttgart;Institute for Visualization and Interactive Systems (VIS), University of Stuttgart",10.1109/infvis.2004.77;10.1109/tvcg.2015.2467757;10.1109/tvcg.2008.166;10.1109/tvcg.2013.212;10.1109/vast.2009.5333443;10.1109/tvcg.2011.239;10.1109/tvcg.2012.252;10.1109/tvcg.2013.162;10.1109/tvcg.2012.277;10.1109/infvis.2004.45;10.1109/infvis.2005.1532150;10.1109/tvcg.2009.162;10.1109/tvcg.2009.171;10.1109/infvis.2005.1532122;10.1109/infvis.1995.528686;10.1109/tvcg.2014.2346920;10.1109/tvcg.2009.202;10.1109/infvis.2004.77,"scientific literature, visual document analysis, visual citation analysis, streamgraph, clustering",,73.0,53.0,2750.0,,,citation networks exploration;long term developments;user;art presenting approach;dataset time enable,0.7154;0.1535;0.0993;0.0892;0.0520,"[np.int64(-1), -1, -1, -1, -1]",280;-1;-1;-1;-1,280,280
VAST,2009,Timeline analysis of undercover activities VAST 2009 traffic mini challenge award: Good analytical technique,10.1109/vast.2009.5334460,http://dx.doi.org/10.1109/VAST.2009.5334460,,,M,"Our visualization tool for the VAST 2009 traffic mini challenge, Timeliner, visualizes badge and network traffic data together in a single timeline. The two views of per-employee and per-day with various filtering interactions enable users to analyze easily employees activities at a particular moment of interest as well as their general daily patterns. Using Timeliner, we present several hypotheses for the task at hand and their validation processes, which reveals various aspects of the data.",Jaegul Choo;Emily Fujimoto;Hanseung Lee;Pedro R. Walteros,Jaegul Choo;Emily Fujimoto;Hanseung Lee;Pedro R. Walteros,"Georgia Institute of Technology, Atlanta, GA, USA;Georgia Institute of Technology, Atlanta, GA, USA;Georgia Institute of Technology, Atlanta, GA, USA;Georgia Institute of Technology, Atlanta, GA, USA",,,0.0,0.0,0.0,141.0,,,traffic data;challenge timeliner visualizes;employee day various;single;hand validation processes,0.6380;0.5869;0.2635;0.0443;0.0137,"[np.int64(-1), np.int64(-1), -1, -1, -1]",69;157;-1;-1;-1,69;157,69
Vis,1996,"Time management, simultaneity and time-critical computation in interactive unsteady visualization environments",10.1109/visual.1996.568117,http://dx.doi.org/10.1109/VISUAL.1996.568117,255.0,261.0,C,"The paper describes time management and time critical computing for a near real time interactive unsteady visualization environment. Subtle issues regarding the flow of time are described, formalized and addressed. The resulting system correctly reflects time behavior while allowing the user to control the flow of time. The problem of time critical computation is discussed and a solution is presented. These time critical algorithms provide control over the frame rate of a visualization system, allowing interactive exploration.",Steve Bryson;Sandy Johan,S. Bryson;S. Johan,"NASA Ames Research Center, MRJ, Inc., USA and NASA Ames Research Center, Moffett Field, CA, USA;NASA Ames Research Center, USA",10.1109/visual.1995.485145;10.1109/visual.1995.485145,,91.0,13.0,12.0,98.0,,,interactive unsteady visualization;time management time;computing near real;control frame rate;subtle,0.5988;0.4248;0.3249;0.3227;0.1101,"[np.int64(-1), -1, -1, -1, -1]",-1;-1;-1;-1;-1,,-1
SciVis,2014,Stent Maps - Comparative Visualization for the Prediction of Adverse Events of Transcatheter Aortic Valve Implantations,10.1109/tvcg.2014.2346459,http://dx.doi.org/10.1109/TVCG.2014.2346459,2704.0,2713.0,J,"Transcatheter aortic valve implantation (TAVI) is a minimally-invasive method for the treatment of aortic valve stenosis in patients with high surgical risk. Despite the success of TAVI, side effects such as paravalvular leakages can occur postoperatively. The goal of this project is to quantitatively analyze the co-occurrence of this complication and several potential risk factors such as stent shape after implantation, implantation height, amount and distribution of calcifications, and contact forces between stent and surrounding structure. In this paper, we present a two-dimensional visualization (stent maps), which allows (1) to comprehensively display all these aspects from CT data and mechanical simulation results and (2) to compare different datasets to identify patterns that are typical for adverse effects. The area of a stent map represents the surface area of the implanted stent - virtually straightened and uncoiled. Several properties of interest, like radial forces or stent compression, are displayed in this stent map in a heatmap-like fashion. Important anatomical landmarks and calcifications are plotted to show their spatial relation to the stent and possible correlations with the color-coded parameters. To provide comparability, the maps of different patient datasets are spatially adjusted according to a corresponding anatomical landmark. Also, stent maps summarizing the characteristics of different populations (e.g. with or without side effects) can be generated. Up to this point several interesting patterns have been observed with our technique, which remained hidden when examining the raw CT data or 3D visualizations of the same data. One example are obvious radial force maxima between the right and non-coronary valve leaflet occurring mainly in cases without leakages. These observations confirm the usefulness of our approach and give starting points for new hypotheses and further analyses. Because of its reduced dimensionality, the stent map data is an appropriate input for statistical group evaluation and machine learning methods.",Silvia Born;Simon Harald Sündermann;Christoph Russ;Raoul Hopf;Carlos E. Ruiz;Volkmar Falk;Michael Gessat,Silvia Born;Simon H. Sündermann;Christoph Russ;Raoul Hopf;Carlos E. Ruiz;Volkmar Falk;Michael Gessat,"University of Zurich, Hybrid Laboratory for Cardiovascular Technologies, Switzerland;Division of Cardiovascular Surgery, University Hospital of Zurich, Switzerland;Swiss Federal Institute of Technology (ETH) Zurich, Computer Vision Laboratory, Switzerland;Swiss Federal Institute of Technology (ETH) Zurich, Institute of Mechanical Systems, Switzerland;Structural and Congenital Heart Division, Lenox Hill Hospital;Division of Cardiovascular Surgery, University Hospital of Zurich, Switzerland;University of Zurich, Computer Vision Laboratory, Switzerland",10.1109/tvcg.2009.169;10.1109/tvcg.2007.70550;10.1109/visual.2001.964540;10.1109/tvcg.2011.235;10.1109/tvcg.2013.139;10.1109/visual.2003.1250353;10.1109/tvcg.2009.169,"Comparative visualization, medical visualization, vessel flattening, transcatheter aortic valve implantation (TAVI)",14.0,9.0,31.0,704.0,,,visualization stent maps;tavi effects paravalvular;contact forces;populations;uncoiled properties,0.6806;0.3540;0.1709;0.0318;-0.0475,"[np.int64(-1), -1, -1, -1, -1]",133;-1;-1;-1;-1,133,133
InfoVis,2017,iTTVis: Interactive Visualization of Table Tennis Data,10.1109/tvcg.2017.2744218,http://dx.doi.org/10.1109/TVCG.2017.2744218,709.0,718.0,J,"The rapid development of information technology paved the way for the recording of fine-grained data, such as stroke techniques and stroke placements, during a table tennis match. This data recording creates opportunities to analyze and evaluate matches from new perspectives. Nevertheless, the increasingly complex data poses a significant challenge to make sense of and gain insights into. Analysts usually employ tedious and cumbersome methods which are limited to watching videos and reading statistical tables. However, existing sports visualization methods cannot be applied to visualizing table tennis competitions due to different competition rules and particular data attributes. In this work, we collaborate with data analysts to understand and characterize the sophisticated domain problem of analysis of table tennis data. We propose iTTVis, a novel interactive table tennis visualization system, which to our knowledge, is the first visual analysis system for analyzing and exploring table tennis data. iTTVis provides a holistic visualization of an entire match from three main perspectives, namely, time-oriented, statistical, and tactical analyses. The proposed system with several well-coordinated views not only supports correlation identification through statistics and pattern detection of tactics with a score timeline but also allows cross analysis to gain insights. Data analysts have obtained several new insights by using iTTVis. The effectiveness and usability of the proposed system are demonstrated with four case studies.",Yingcai Wu;Ji Lan;Xinhuan Shu;Chenyang Ji;Kejian Zhao;Jiachen Wang;Hui Zhang 0051,Yingcai Wu;Ji Lan;Xinhuan Shu;Chenyang Ji;Kejian Zhao;Jiachen Wang;Hui Zhang,"State Key Lab of CAD & CG, Zhejiang University;State Key Lab of CAD & CG, Zhejiang University;State Key Lab of CAD & CG, Zhejiang University;State Key Lab of CAD & CG, Zhejiang University;State Key Lab of CAD & CG, Zhejiang University;State Key Lab of CAD & CG, Zhejiang University;Department of Physical Education, Zhejiang University",10.1109/vast.2014.7042478;10.1109/vast.2014.7042477;10.1109/infvis.1996.559229;10.1109/tvcg.2011.208;10.1109/tvcg.2013.192;10.1109/tvcg.2012.263;10.1109/tvcg.2014.2346445;10.1109/tvcg.2012.213;10.1109/vast.2014.7042478,"Sports visualization,visual knowledge discovery,sports analytics,visual knowledge representation",63.0,67.0,35.0,2591.0,,,table tennis visualization;supports correlation identification;using ittvis;main perspectives time;recording fine,0.7759;0.3014;0.1839;0.1580;0.0284,"[np.int64(-1), -1, -1, -1, -1]",158;-1;-1;-1;-1,158,158
VAST,2019,VASSL: A Visual Analytics Toolkit for Social Spambot Labeling,10.1109/tvcg.2019.2934266,http://dx.doi.org/10.1109/TVCG.2019.2934266,874.0,883.0,J,"Social media platforms are filled with social spambots. Detecting these malicious accounts is essential, yet challenging, as they continually evolve to evade detection techniques. In this article, we present VASSL, a visual analytics system that assists in the process of detecting and labeling spambots. Our tool enhances the performance and scalability of manual labeling by providing multiple connected views and utilizing dimensionality reduction, sentiment analysis and topic modeling, enabling insights for the identification of spambots. The system allows users to select and analyze groups of accounts in an interactive manner, which enables the detection of spambots that may not be identified when examined individually. We present a user study to objectively evaluate the performance of VASSL users, as well as capturing subjective opinions about the usefulness and the ease of use of the tool.",Mosab Khayat;Morteza Karimzadeh;Jieqiong Zhao;David S. Ebert,Mosab Khayat;Morteza Karimzadeh;Jieqiong Zhao;David S. Ebert,Purdue University;University of Colorado Boulder;Purdue University;Purdue University,10.1109/tvcg.2015.2467196;10.1109/vast.2012.6400557;10.1109/vast.2016.7883510;10.1109/tvcg.2017.2745083;10.1109/tvcg.2017.2745080;10.1109/tvcg.2013.153;10.1109/tvcg.2014.2346920;10.1109/tvcg.2014.2346922;10.1109/tvcg.2015.2467196,"Spambot,Labeling,Detection,Visual Analytics,Social Media Annotation",15.0,16.0,46.0,830.0,,,social spambots detecting;visual analytics;allows users select;article;filled,0.6675;0.4356;0.1653;0.1396;0.1145,"[np.int64(-1), np.int64(-1), -1, -1, -1]",122;201;-1;-1;-1,122;201,122
Vis,1998,A higher-order method for finding vortex core lines,10.1109/visual.1998.745296,http://dx.doi.org/10.1109/VISUAL.1998.745296,143.0,150.0,C,"This paper presents a novel method to extract vortical structures from 3D CFD (computational fluid dynamics) vector fields automatically. It discusses the underlying theory and some aspects of the implementation. Making use of higher-order derivatives, the method is able to locate bent vortices. In order to structure the recognition procedure, we distinguish locating the core line from calculating attributes of strength and quality. Results are presented on several flow fields from the field of turbomachinery.",Martin Roth;Ronald Peikert,M. Roth;R. Peikert,"ETH Zurich, Swiss Center for Scientific Computing, Switzerland;ETH Zurich, Swiss Center for Scientific Computing, Switzerland",10.1109/visual.1996.568137;10.1109/visual.1997.663912;10.1109/visual.1995.480817;10.1109/visual.1991.175773;10.1109/visual.1997.663910;10.1109/visual.1994.346327;10.1109/visual.1996.567807;10.1109/visual.1997.663857;10.1109/visual.1993.398877;10.1109/visual.1997.663858;10.1109/visual.1996.568137,,216.0,73.0,26.0,496.0,,,extract vortical structures;field turbomachinery;line calculating;higher order derivatives;strength quality,0.7180;0.3338;0.1860;0.1515;0.0401,"[np.int64(-1), -1, -1, -1, -1]",-1;-1;-1;-1;-1,,-1
Vis,2005,Distributed data management for large volume visualization,10.1109/visual.2005.1532794,http://dx.doi.org/10.1109/VISUAL.2005.1532794,183.0,189.0,C,"We propose a distributed data management scheme for large data visualization that emphasizes efficient data sharing and access. To minimize data access time and support users with a variety of local computing capabilities, we introduce an adaptive data selection method based on an ""enhanced time-space partitioning"" (ETSP) tree that assists with effective visibility culling, as well as multiresolution data selection. By traversing the tree, our data management algorithm can quickly identify the visible regions of data, and, for each region, adaptively choose the lowest resolution satisfying user-specified error tolerances. Only necessary data elements are accessed and sent to the visualization pipeline. To further address the issue of sharing large-scale data among geographically distributed collaborative teams, we have designed an infrastructure for integrating our data management technique with a distributed data storage system provided by logistical networking (LoN). Data sets at different resolutions are generated and uploaded to LoN for wide-area access. We describe a parallel volume rendering system that verifies the effectiveness of our data storage, selection and access scheme.",Jinzhu Gao;Jian Huang 0007;C. Ryan Johnson;Scott Atchley;James Arthur Kohl,J. Gao;J. Huang;C.R. Johnson;S. Atchley,"Oak Ridge Nat. Lab., TN, USA;The Univ. of Tennessee, TN, USA;The Univ. of Tennessee, TN, USA;The Univ. of Tennessee, TN, USA;Oak Ridge Nat. Lab., TN, USA",10.1109/visual.2002.1183758;10.1109/visual.2002.1183757;10.1109/visual.1999.809910;10.1109/visual.1998.745300;10.1109/visual.2004.110;10.1109/visual.2004.112;10.1109/visual.1999.809879;10.1109/visual.2002.1183758,"large data visualization, distributed storage, logistical networking, visibility culling, volume rendering, multiresolution rendering",48.0,2.0,23.0,320.0,,,large data visualization;sharing access minimize;rendering verifies;capabilities introduce adaptive;uploaded lon,0.6483;0.1717;0.0969;0.0867;-0.0043,"[np.int64(-1), -1, -1, -1, -1]",190;-1;-1;-1;-1,190,190
Vis,2021,Interactive Visual Pattern Search on Graph Data via Graph Representation Learning,10.1109/tvcg.2021.3114857,http://dx.doi.org/10.1109/TVCG.2021.3114857,335.0,345.0,J,"Graphs are a ubiquitous data structure to model processes and relations in a wide range of domains. Examples include control-flow graphs in programs and semantic scene graphs in images. Identifying subgraph patterns in graphs is an important approach to understand their structural properties. We propose a visual analytics system GraphQ to support human-in-the-loop, example-based, subgraph pattern search in a database containing many individual graphs. To support fast, interactive queries, we use graph neural networks (GNNs) to encode a graph as fixed-length latent vector representation, and perform subgraph matching in the latent space. Due to the complexity of the problem, it is still difficult to obtain accurate one-to-one node correspondences in the matching results that are crucial for visualization and interpretation. We, therefore, propose a novel GNN for node-alignment called NeuroAlign, to facilitate easy validation and interpretation of the query results. GraphQ provides a visual query interface with a query editor and a multi-scale visualization of the results, as well as a user feedback mechanism for refining the results with additional constraints. We demonstrate GraphQ through two example usage scenarios: analyzing reusable subroutines in program workflows and semantic scene graph search in images. Quantitative experiments show that NeuroAlign achieves 19%-29% improvement in node-alignment accuracy compared to baseline GNN and provides up to 100× speedup compared to combinatorial algorithms. Our qualitative study with domain experts confirms the effectiveness for both usage scenarios.",Huan Song;Zeng Dai;Panpan Xu;Liu Ren,Huan Song;Zeng Dai;Panpan Xu;Liu Ren,"Robert Bosch Research and Technology Center, USA;ByteDance Inc., China;Amazon AWS AI, United States;Robert Bosch Research and Technology Center, USA",10.1109/tvcg.2011.185;10.1109/vast50239.2020.00010;10.1109/tvcg.2007.70582;10.1109/tvcg.2017.2743858;10.1109/tvcg.2019.2934396;10.1109/tvcg.2006.122;10.1109/tvcg.2017.2744898;10.1109/tvcg.2020.3030347;10.1109/tvcg.2017.2744843;10.1109/tvcg.2015.2468078;10.1109/tvcg.2014.2346441;10.1109/tvcg.2019.2934798;10.1109/tvcg.2020.3030440;10.1109/tvcg.2011.185,"Graph,Graph Neural Network,Representation Learning,Visual Query Interface",3.0,10.0,83.0,1397.0,,,use graph neural;program workflows semantic;alignment accuracy compared;search database containing;propose,0.6174;0.3310;0.2285;0.1576;-0.0055,"[np.int64(-1), -1, -1, -1, -1]",213;-1;-1;-1;-1,213,213
Vis,1990,Automatic illustration of 3D geometric models: surfaces,10.1109/visual.1990.146395,http://dx.doi.org/10.1109/VISUAL.1990.146395,307.0,,C,"The authors present techniques for automating the illustration of geometric models based on traditional hand illustration methods. A system based on the techniques of traditional illustrators for automatically generating illustrations of complex three-dimensional models is described. The system relies on a richer set of display primitives, which are also outlined. Algorithmic details for emphasizing significant model components are discussed, and some preliminary results are presented.&lt;&lt;ETX&gt;&gt;",Debra Dooley;Michael F. Cohen,D. Dooley;M.F. Cohen,"Department of Computer Sciences, University of Utah, Salt Lake, UT, USA;Department of Computer Sciences, University of Utah, Salt Lake, UT, USA",,,65.0,9.0,14.0,106.0,,,illustration geometric models;automatically generating;traditional hand;set display;emphasizing significant,0.7528;0.2640;0.2397;0.1216;0.1023,"[np.int64(-1), -1, -1, -1, -1]",89;-1;-1;-1;-1,89,89
InfoVis,1996,Techniques for non-linear magnification transformations,10.1109/infvis.1996.559214,http://dx.doi.org/10.1109/INFVIS.1996.559214,38.0,45.0,C,"This paper presents efficient methods for implementing general non-linear magnification transformations. Techniques are provided for: combining linear and non-linear magnifications, constraining the domain of magnifications, combining multiple transformations, and smoothly interpolating between magnified and normal views. In addition, piecewise linear methods are introduced which allow greater efficiency and expressiveness than their continuous counterparts.",Alan Keahey;Edward L. Robertson,T.A. Keahey;E.L. Robertson,"Department of Computer Science, Indiana University, Bloomington, IN, USA;Department of Computer Science, Indiana University, Bloomington, IN, USA",,,217.0,48.0,17.0,176.0,,,magnification transformations techniques;normal views addition;piecewise linear methods;general;expressiveness continuous,0.7888;0.2313;0.2163;0.0749;0.0323,"[np.int64(-1), -1, -1, -1, -1]",52;-1;-1;-1;-1,52,52
Vis,2023,Wizualization: A “Hard Magic” Visualization System for Immersive and Ubiquitous Analytics,10.1109/tvcg.2023.3326580,http://dx.doi.org/10.1109/TVCG.2023.3326580,507.0,517.0,J,"What if magic could be used as an effective metaphor to perform data visualization and analysis using speech and gestures while mobile and on-the-go? In this paper, we introduce Wizualization, a visual analytics system for eXtended Reality (XR) that enables an analyst to author and interact with visualizations using such a magic system through gestures, speech commands, and touch interaction. Wizualization is a rendering system for current XR headsets that comprises several components: a cross-device (or Arcane Focuses) infrastructure for signalling and view control (Weave), a code notebook (Spellbook), and a grammar of graphics for XR (Optomancy). The system offers users three modes of input: gestures, spoken commands, and materials. We demonstrate Wizualization and its components using a motivating scenario on collaborative data analysis of pandemic data across time and space.",Andrea Batch;Peter W. S. Butcher;Panagiotis D. Ritsos;Niklas Elmqvist,Andrea Batch;Peter W. S. Butcher;Panagiotis D. Ritsos;Niklas Elmqvist,"U.S. Bureau of Economic Analysis, Washington, D.C., United States;Bangor University, Bangor, United Kingdom;Bangor University, Bangor, United Kingdom;Aarhus University, Aarhus, Denmark",0.1109/tvcg.2017.2745941;10.1109/vast.2016.7883506;10.1109/tvcg.2019.2934803;10.1109/tvcg.2019.2934785;10.1109/tvcg.2019.2934415;10.1109/tvcg.2015.2468292;10.1109/tvcg.2012.204;10.1109/tvcg.2013.191;10.1109/tvcg.2013.225;10.1109/tvcg.2020.3030378;10.1109/tvcg.2016.2599030;10.1109/tvcg.2015.2467091;10.1109/tvcg.2015.2467153;10.1109/tvcg.2018.2865152;10.1109/tvcg.2021.3114844;10.1109/tvcg.2007.70515;10.1109/tvcg.2019.2934668;10.1109/tvcg.2020.3030367,"Immersive analytics,situated analytics,ubiquitous analytics,gestural interaction,voice interaction",,3.0,82.0,792.0,,,visualizations using magic;modes input gestures;pandemic;current xr headsets;analyst author,0.6763;0.3179;0.2281;0.1031;0.0939,"[np.int64(-1), -1, -1, -1, -1]",189;-1;-1;-1;-1,189,189
Vis,2004,Dual marching cubes,10.1109/visual.2004.28,http://dx.doi.org/10.1109/VISUAL.2004.28,489.0,496.0,C,"We present the definition and computational algorithms for a new class of surfaces which are dual to the isosurface produced by the widely used marching cubes (MC) algorithm. These new isosurfaces have the same separating properties as the MC surfaces but they are comprised of quad patches that tend to eliminate the common negative aspect of poorly shaped triangles of the MC isosurfaces. Based upon the concept of this new dual operator, we describe a simple, but rather effective iterative scheme for producing smooth separating surfaces for binary, enumerated volumes which are often produced by segmentation algorithms. Both the dual surface algorithm and the iterative smoothing scheme are easily implemented.",Gregory M. Nielson,G.M. Nielson,"Arizona State University, USA",10.1109/visual.2002.1183807;10.1109/visual.1991.175782,"Marching Cubes, isosurfaces, triangular mesh, dual graph, segmented data, smoothing",154.0,50.0,16.0,826.0,,,marching cubes;class surfaces;separating;dual operator;produced widely used,0.6504;0.3558;0.1812;0.0877;0.0669,"[np.int64(-1), -1, -1, -1, -1]",286;-1;-1;-1;-1,286,286
Vis,1997,Visualization of geometric algorithms in an electronic classroom,10.1109/visual.1997.663920,http://dx.doi.org/10.1109/VISUAL.1997.663920,455.0,458.0,C,"This paper investigates the visualization and animation of geometric computing in a distributed electronic classroom. We show how focusing in a well-defined domain makes it possible to develop a compact system that is accessible to even naive users. We present a conceptual model and a system, GASP-II (Geometric Animation System, Princeton, II), that realizes this model in the geometric domain. The system allows the presentation and interactive exploration of 3D geometric algorithms over a network.",Maria Shneerson;Ayellet Tal,M. Shneerson;A. Tal,"Department of Applied Mathematics, Weizmann Institute of Science, Rehovot, Israel;Department of Electrical Engineering, Technion-Israel Institute of Technology, Haifa, Israel",,"Algorithm animation, Visualization in Education, Geometric algorithms ",12.0,1.0,13.0,72.0,,,animation geometric computing;allows presentation interactive;classroom focusing defined;princeton ii;domain allows,0.7225;0.4598;0.1479;0.1477;0.0885,"[np.int64(-1), -1, -1, -1, -1]",286;-1;-1;-1;-1,286,286
SciVis,2015,Mining Graphs for Understanding Time-Varying Volumetric Data,10.1109/tvcg.2015.2468031,http://dx.doi.org/10.1109/TVCG.2015.2468031,965.0,974.0,J,"A notable recent trend in time-varying volumetric data analysis and visualization is to extract data relationships and represent them in a low-dimensional abstract graph view for visual understanding and making connections to the underlying data. Nevertheless, the ever-growing size and complexity of data demands novel techniques that go beyond standard brushing and linking to allow significant reduction of cognition overhead and interaction cost. In this paper, we present a mining approach that automatically extracts meaningful features from a graph-based representation for exploring time-varying volumetric data. This is achieved through the utilization of a series of graph analysis techniques including graph simplification, community detection, and visual recommendation. We investigate the most important transition relationships for time-varying data and evaluate our solution with several time-varying data sets of different sizes and characteristics. For gaining insights from the data, we show that our solution is more efficient and effective than simply asking users to extract relationships via standard interaction techniques, especially when the data set is large and the relationships are complex. We also collect expert feedback to confirm the usefulness of our approach.",Yi Gu;Chaoli Wang 0001;Tom Peterka;Robert L. Jacob;Seung Hyun Kim,Yi Gu;Chaoli Wang;Tom Peterka;Robert Jacob;Seung Hyun Kim,"Department Computer Science and Engineering, University of Notre Dame, Notre Dame, IN;Department Computer Science and Engineering, University of Notre Dame, Notre Dame, IN;Division of Mathematics and Computer Science, Argonne National Laboratory, Argonne, IL;Division of Mathematics and Computer Science, Argonne National Laboratory, Argonne, IL;Department of Mechanical and Aerospace Engineering, The Ohio State University, Columbus, OH",10.1109/tvcg.2009.122;10.1109/tvcg.2013.151;10.1109/tvcg.2011.246;10.1109/tvcg.2008.116;10.1109/visual.1999.809871;10.1109/tvcg.2006.165;10.1109/tvcg.2009.165;10.1109/tvcg.2006.159;10.1109/tvcg.2009.122,"Time-varying data visualization, graph simplification, community detection, visual recommendation",16.0,14.0,28.0,1272.0,,,community detection visual;time varying volumetric;important transition relationships;allow significant reduction;cost,0.5816;0.3961;0.2828;0.0833;-0.0459,"[np.int64(-1), -1, -1, -1, -1]",169;-1;-1;-1;-1,169,169
VAST,2011,Pexel and heatmap visual analysis of multidimensional gun/homicide data,10.1109/vast.2011.6102482,http://dx.doi.org/10.1109/VAST.2011.6102482,297.0,298.0,M,"We present a visual analysis tool for mining correlations in county-level, multidimensional gun/homicide data. The tool uses 2D pexels, heatmaps, linked-views, dynamic queries and details-on-demand to analyze annual county-level data on firearm homicide rates and gun availability, as well as various socio-demographic measures. A statistical significance filter was implemented as a visual means to validate exploratory hypotheses. Results from expert evaluations indicate that our methods outperform typical graphical techniques used by statisticians, such as bar graphs, scatterplots and residual plots, to show spatial and temporal relationships. Our visualization has the potential to convey the impact of gun availability on firearm homicides to the public health arena and the general public.",Scott D. Rothenberger;John E. Wenskovitch;G. Elisabeta Marai,Scott D. Rothenberger;John E. Wenskovitch;G. Elisabeta Marai,"Department of Statistics, University of Pittsburgh, USA;Department of Computer Science, University of Pittsburgh, USA;Department of Computer Science, University of Pittsburgh, USA",,,1.0,2.0,4.0,340.0,,,homicide data tool;2d pexels heatmaps;spatial temporal relationships;filter;methods outperform typical,0.5759;0.3706;0.3575;0.0944;0.0838,"[np.int64(-1), -1, -1, -1, -1]",125;-1;-1;-1;-1,125,125
SciVis,2017,Screen-Space Normal Distribution Function Caching for Consistent Multi-Resolution Rendering of Large Particle Data,10.1109/tvcg.2017.2743979,http://dx.doi.org/10.1109/TVCG.2017.2743979,944.0,953.0,J,"Molecular dynamics (MD) simulations are crucial to investigating important processes in physics and thermodynamics. The simulated atoms are usually visualized as hard spheres with Phong shading, where individual particles and their local density can be perceived well in close-up views. However, for large-scale simulations with 10 million particles or more, the visualization of large fields-of-view usually suffers from strong aliasing artifacts, because the mismatch between data size and output resolution leads to severe under-sampling of the geometry. Excessive super-sampling can alleviate this problem, but is prohibitively expensive. This paper presents a novel visualization method for large-scale particle data that addresses aliasing while enabling interactive high-quality rendering. We introduce the novel concept of screen-space normal distribution functions (S-NDFs) for particle data. S-NDFs represent the distribution of surface normals that map to a given pixel in screen space, which enables high-quality re-lighting without re-rendering particles. In order to facilitate interactive zooming, we cache S-NDFs in a screen-space mipmap (S-MIP). Together, these two concepts enable interactive, scale-consistent re-lighting and shading changes, as well as zooming, without having to re-sample the particle data. We show how our method facilitates the interactive exploration of real-world large-scale MD simulation data in different scenarios.",Mohamed Ibrahim;Patrick Wickenhauser;Peter Rautek;Guido Reina;Markus Hadwiger,Mohamed Ibrahim;Patrick Wickenhäuser;Peter Rautek;Guido Reina;Markus Hadwiger,"King Abdullah University of Science and Technology (KAUST), Saudi Arabia;Visualization Research Center (VISUS), University of Stuttgart, Germany;King Abdullah University of Science and Technology (KAUST), Saudi Arabia;Visualization Research Center (VISUS), University of Stuttgart, Germany;King Abdullah University of Science and Technology (KAUST), Saudi Arabia",10.1109/visual.2004.103;10.1109/tvcg.2009.142;10.1109/visual.2003.1250404;10.1109/tvcg.2014.2346324;10.1109/tvcg.2010.215;10.1109/tvcg.2016.2599041;10.1109/scivis.2015.7429492;10.1109/visual.2004.103,"Multiresolution Techniques,Point-Based Data,Glyph-based Techniques,Scalability Issues,Molecular Visualization",6.0,4.0,40.0,566.0,,,million particles visualization;cache ndfs;consistent lighting shading;aliasing enabling interactive;large,0.6486;0.2451;0.2133;0.1835;0.0562,"[np.int64(-1), -1, -1, -1, -1]",34;-1;-1;-1;-1,34,34
Vis,2004,Generating sub-resolution detail in images and volumes using constrained texture synthesis,10.1109/visual.2004.35,http://dx.doi.org/10.1109/VISUAL.2004.35,75.0,82.0,C,"A common deficiency of discretized datasets is that detail beyond the resolution of the dataset has been irrecoverably lost. This lack of detail becomes immediately apparent once one attempts to zoom into the dataset and only recovers blur. We describe a method that generates the missing detail from any available and plausible high-resolution data, using texture synthesis. Since the detail generation process is guided by the underlying image or volume data and is designed to fill in plausible detail in accordance with the coarse structure and properties of the zoomed-in neighborhood, we refer to our method as constrained texture synthesis. Regular zooms become ""semantic zooms"", where each level of detail stems from a data source attuned to that resolution. We demonstrate our approach by a medical application - the visualization of a human liver - but its principles readily apply to any scenario, as long as data at all resolutions are available. We first present a 2D viewing application, called the ""virtual microscope"", and then extend our technique to 3D volumetric viewing.",Lujin Wang;Klaus Mueller 0001,Lujin Wang;K. Mueller,"Center for Visual Computing, Computer Science, Stony Brook University, USA;Center for Visual Computing, Computer Science, Stony Brook University, USA",,"texture synthesis, semantic zoom",29.0,3.0,27.0,104.0,,,volumetric viewing;using texture synthesis;dataset recovers blur;readily apply;generates missing available,0.5751;0.5411;0.3079;0.1111;0.0997,"[np.int64(-1), np.int64(-1), -1, -1, -1]",84;55;-1;-1;-1,55;84,84
Vis,1997,Haar wavelets over triangular domains with applications to multiresolution models for flow over a sphere,10.1109/visual.1997.663871,http://dx.doi.org/10.1109/VISUAL.1997.663871,143.0,149.0,C,"Some new piecewise constant wavelets defined over nested triangulated domains are presented and applied to the problem of multiresolution analysis of flow over a spherical domain. These new, nearly orthogonal wavelets have advantages over the existing weaker biorthogonal wavelets. In the planar case of uniform areas, the wavelets converge to one of two fully orthogonal Haar wavelets. These new, fully orthogonal wavelets are proven to be the only possible wavelets of this type.",Gregory M. Nielson;Il-Hong Jung;Junwon Sung,G.M. Nielson;Il-Hong Jung;Junwon Sung,"Computer Science and Engineering, Arizona State University, Tempe, AZ, USA;Computer Science and Engineering, Arizona State University, Tempe, AZ, USA;Computer Science and Engineering, Arizona State University, Tempe, AZ, USA",,,88.0,26.0,3.0,156.0,,,biorthogonal wavelets planar;spherical domain new;piecewise constant;haar;existing weaker,0.6745;0.3765;0.1584;0.0878;-0.1268,"[np.int64(-1), -1, -1, -1, -1]",100;-1;-1;-1;-1,100,100
Vis,2023,Attribute-Aware RBFs: Interactive Visualization of Time Series Particle Volumes Using RT Core Range Queries,10.1109/tvcg.2023.3327366,http://dx.doi.org/10.1109/TVCG.2023.3327366,1150.0,1160.0,J,"Smoothed-particle hydrodynamics (SPH) is a mesh-free method used to simulate volumetric media in fluids, astrophysics, and solid mechanics. Visualizing these simulations is problematic because these datasets often contain millions, if not billions of particles carrying physical attributes and moving over time. Radial basis functions (RBFs) are used to model particles, and overlapping particles are interpolated to reconstruct a high-quality volumetric field; however, this interpolation process is expensive and makes interactive visualization difficult. Existing RBF interpolation schemes do not account for color-mapped attributes and are instead constrained to visualizing just the density field. To address these challenges, we exploit ray tracing cores in modern GPU architectures to accelerate scalar field reconstruction. We use a novel RBF interpolation scheme to integrate per-particle colors and densities, and leverage GPU-parallel tree construction and refitting to quickly update the tree as the simulation animates over time or when the user manipulates particle radii. We also propose a Hilbert reordering scheme to cluster particles together at the leaves of the tree to reduce tree memory consumption. Finally, we reduce the noise of volumetric shadows by adopting a spatially temporal blue noise sampling scheme. Our method can provide a more detailed and interactive view of these large, volumetric, time-series particle datasets than traditional methods, leading to new insights into these physics simulations.",Nate Morrical;Stefan Zellmann;Alper Sahistan;Patrick C. Shriwise;Valerio Pascucci,Nate Morrical;Stefan Zellmann;Alper Sahistan;Patrick Shriwise;Valerio Pascucci,"Scientific Computing and Imaging Institute, University of Utah, USA;University of Cologne, USA;Scientific Computing and Imaging Institute, University of Utah, USA;Argonne National Laboratory, USA;Scientific Computing and Imaging Institute, University of Utah, USA",0.1109/tvcg.2010.148;10.1109/tvcg.2009.142;10.1109/tvcg.2011.161;10.1109/tvcg.2023.3327366;10.1109/tvcg.2022.3209418;10.1109/tvcg.2007.70526;10.1109/tvcg.2021.3114869;10.1109/tvcg.2020.3030470,"Ray Tracing,Volume Rendering,Particle Volumes,Radial Basis Functions,Scientific Visualization",,1.0,48.0,402.0,,,smoothed particle hydrodynamics;ray tracing cores;tree memory consumption;color mapped;propose,0.5658;0.4596;0.2175;0.1949;0.0113,"[np.int64(-1), -1, -1, -1, -1]",38;-1;-1;-1;-1,38,38
Vis,2008,Estimating Crossing fibers: A Tensor Decomposition Approach,10.1109/tvcg.2008.128,http://dx.doi.org/10.1109/TVCG.2008.128,1635.0,1642.0,J,"Diffusion weighted magnetic resonance imaging is a unique tool for non-invasive investigation of major nerve fiber tracts. Since the popular diffusion tensor (DT-MRI) model is limited to voxels with a single fiber direction, a number of high angular resolution techniques have been proposed to provide information about more diverse fiber distributions. Two such approaches are Q-Ball imaging and spherical deconvolution, which produce orientation distribution functions (ODFs) on the sphere. For analysis and visualization, the maxima of these functions have been used as principal directions, even though the results are known to be biased in case of crossing fiber tracts. In this paper, we present a more reliable technique for extracting discrete orientations from continuous ODFs, which is based on decomposing their higher-order tensor representation into an isotropic component, several rank-1 terms, and a small residual. Comparing to ground truth in synthetic data shows that the novel method reduces bias and reliably reconstructs crossing fibers which are not resolved as individual maxima in the ODF We present results on both Q-Ball and spherical deconvolution data and demonstrate that the estimated directions allow for plausible fiber tracking in a real data set.",Thomas Schultz 0001;Hans-Peter Seidel,Thomas Schultz;Hans-Peter Seidel,"MPI Informatik, Saarbruecken, Germany;MPI Informatik, Saarbruecken, Germany",10.1109/visual.2005.1532773;10.1109/visual.2005.1532773,"DW-MRI, Q-Ball, spherical deconvolution, fiber tracking, higher-order tensor, tensor decomposition",157.0,95.0,42.0,796.0,BP,,tensor dt mri;discrete orientations continuous;allow plausible fiber;angular;distribution functions,0.5259;0.2296;0.1797;0.1052;0.0710,"[np.int64(-1), -1, -1, -1, -1]",44;-1;-1;-1;-1,44,44
Vis,1995,Vector plots for irregular grids,10.1109/visual.1995.480819,http://dx.doi.org/10.1109/VISUAL.1995.480819,248.0,,C,"A standard method for visualizing vector fields consists of drawing many small ""glyphs"" to represent the field. This paper extends the technique from regular to curvilinear and unstructured grids. In order to achieve a uniform density of vector glyphs on nonuniformly spaced grids, the paper describes two approaches to resampling the grid data. One of the methods, an element-based resampling, can be used to visualize vector fields at arbitrary surfaces within three-dimensional grids.",Don Dovey,D. Dovey,"Lawrence Livemore National Laboratory, USA",10.1109/visual.1993.398877;10.1109/visual.1994.346313;10.1109/visual.1994.346312;10.1109/visual.1993.398877,,67.0,12.0,13.0,95.0,,,visualizing vector fields;resampling grid;glyphs nonuniformly;represent;data methods element,0.7627;0.3229;0.1550;0.1159;0.0626,"[np.int64(-1), -1, -1, -1, -1]",140;-1;-1;-1;-1,140,140
InfoVis,2013,Information Visualization and Proxemics: Design Opportunities and Empirical findings,10.1109/tvcg.2013.166,http://dx.doi.org/10.1109/TVCG.2013.166,2386.0,2395.0,J,"People typically interact with information visualizations using a mouse. Their physical movement, orientation, and distance to visualizations are rarely used as input. We explore how to use such spatial relations among people and visualizations (i.e., proxemics) to drive interaction with visualizations, focusing here on the spatial relations between a single user and visualizations on a large display. We implement interaction techniques that zoom and pan, query and relate, and adapt visualizations based on tracking of users' position in relation to a large high-resolution display. Alternative prototypes are tested in three user studies and compared with baseline conditions that use a mouse. Our aim is to gain empirical data on the usefulness of a range of design possibilities and to generate more ideas. Among other things, the results show promise for changing zoom level or visual representation with the user's physical distance to a large display. We discuss possible benefits and potential issues to avoid when designing information visualizations that use proxemics.",Mikkel R. Jakobsen;Yonas Sahlemariam Haile;Søren Knudsen;Kasper Hornbæk,Mikkel R. Jakobsen;Yonas Sahlemariam Haile;Søren Knudsen;Kasper Hornbæk,"Kobenhavns Universitet, Kobenhavns, DK;Kobenhavns Universitet, Kobenhavns, DK;Kobenhavns Universitet, Kobenhavns, DK;Kobenhavns Universitet, Kobenhavns, DK",10.1109/tvcg.2006.184;10.1109/tvcg.2012.204;10.1109/tvcg.2012.251;10.1109/tvcg.2007.70577;10.1109/infvis.2005.1532136;10.1109/tvcg.2006.184,"Proxemics, information visualization, user study, large displays, user tracking, movement, orientation, distance",71.0,46.0,56.0,1633.0,,,visualizations using mouse;physical distance large;avoid designing information;people typically;promise changing,0.6799;0.2921;0.2824;0.1425;-0.0524,"[np.int64(-1), -1, -1, -1, -1]",262;-1;-1;-1;-1,262,262
VAST,2016,Designing Progressive and Interactive Analytics Processes for High-Dimensional Data Analysis,10.1109/tvcg.2016.2598470,http://dx.doi.org/10.1109/TVCG.2016.2598470,131.0,140.0,J,"In interactive data analysis processes, the dialogue between the human and the computer is the enabling mechanism that can lead to actionable observations about the phenomena being investigated. It is of paramount importance that this dialogue is not interrupted by slow computational mechanisms that do not consider any known temporal human-computer interaction characteristics that prioritize the perceptual and cognitive capabilities of the users. In cases where the analysis involves an integrated computational method, for instance to reduce the dimensionality of the data or to perform clustering, such non-optimal processes are often likely. To remedy this, progressive computations, where results are iteratively improved, are getting increasing interest in visual analytics. In this paper, we present techniques and design considerations to incorporate progressive methods within interactive analysis processes that involve high-dimensional data. We define methodologies to facilitate processes that adhere to the perceptual characteristics of users and describe how online algorithms can be incorporated within these. A set of design recommendations and according methods to support analysts in accomplishing high-dimensional data analysis tasks are then presented. Our arguments and decisions here are informed by observations gathered over a series of analysis sessions with analysts from finance. We document observations and recommendations from this study and present evidence on how our approach contribute to the efficiency and productivity of interactive visual analysis sessions involving high-dimensional data.",Cagatay Turkay;Erdem Kaya;Selim Balcisoy;Helwig Hauser,Cagatay Turkay;Erdem Kaya;Selim Balcisoy;Helwig Hauser,"City University, London, UK;Sabanci University, Turkey;Sabanci University, Turkey;University of Bergen, Norway",10.1109/tvcg.2007.70539;10.1109/vast.2008.4677361;10.1109/tvcg.2008.153;10.1109/tvcg.2014.2346481;10.1109/tvcg.2014.2346574;10.1109/tvcg.2007.70515;10.1109/tvcg.2012.213;10.1109/tvcg.2013.125;10.1109/tvcg.2012.256;10.1109/vast.2008.4677357;10.1109/tvcg.2015.2467613;10.1109/tvcg.2014.2346265;10.1109/tvcg.2011.178;10.1109/infvis.2005.1532136;10.1109/infvis.1996.559223;10.1109/tvcg.2011.229;10.1109/tvcg.2008.125;10.1109/tvcg.2007.70539,Progressive analytics;high dimensional data;iterative refinement;visual analytics,99.0,60.0,48.0,2495.0,,,interactive visual analysis;clustering non optimal;dialogue interrupted slow;capabilities users;known,0.7165;0.2121;0.1604;0.1453;0.0233,"[np.int64(-1), -1, -1, -1, -1]",318;-1;-1;-1;-1,318,318
InfoVis,2013,Visual Compression of Workflow Visualizations with Automated Detection of Macro Motifs,10.1109/tvcg.2013.225,http://dx.doi.org/10.1109/TVCG.2013.225,2576.0,2585.0,J,"This paper is concerned with the creation of 'macros' in workflow visualization as a support tool to increase the efficiency of data curation tasks. We propose computation of candidate macros based on their usage in large collections of workflows in data repositories. We describe an efficient algorithm for extracting macro motifs from workflow graphs. We discovered that the state transition information, used to identify macro candidates, characterizes the structural pattern of the macro and can be harnessed as part of the visual design of the corresponding macro glyph. This facilitates partial automation and consistency in glyph design applicable to a large set of macro glyphs. We tested this approach against a repository of biological data holding some 9,670 workflows and found that the algorithmically generated candidate macros are in keeping with domain expert expectations.",Eamonn Maguire;Philippe Rocca-Serra;Susanna-Assunta Sansone;Jim Davies;Min Chen 0001,Eamonn Maguire;Philippe Rocca-Serra;Susanna-Assunta Sansone;Jim Davies;Min Chen,"Oxford e-Research Centre, Department of Computer Science, University of Oxford, UK;Oxford e-Research Centre, University of Oxford, UK;Oxford e-Research Centre, University of Oxford, UK;Department of Computer Science, University of Oxford, UK;Oxford e-Research Centre, University of Oxford, UK",10.1109/tvcg.2007.70584;10.1109/infvis.2004.12;10.1109/tvcg.2006.147;10.1109/tvcg.2009.195;10.1109/tvcg.2012.271;10.1109/visual.1996.567752;10.1109/tvcg.2008.174;10.1109/tvcg.2006.166;10.1109/tvcg.2007.70584,"Workflow visualization, motif detection, glyph-based visualization, glyph generation, state-transition-based algorithm",33.0,20.0,42.0,642.0,,,macros workflow visualization;biological data;glyph;repositories efficient algorithm;keeping domain,0.6948;0.3144;0.2931;0.2312;-0.0555,"[np.int64(-1), -1, -1, -1, -1]",260;-1;-1;-1;-1,260,260
InfoVis,2008,Rapid Graph Layout Using Space filling Curves,10.1109/tvcg.2008.158,http://dx.doi.org/10.1109/TVCG.2008.158,1301.0,1308.0,J,"Network data frequently arises in a wide variety of fields, and node-link diagrams are a very natural and intuitive representation of such data. In order for a node-link diagram to be effective, the nodes must be arranged well on the screen. While many graph layout algorithms exist for this purpose, they often have limitations such as high computational complexity or node colocation. This paper proposes a new approach to graph layout through the use of space filling curves which is very fast and guarantees that there will be no nodes that are colocated. The resulting layout is also aesthetic and satisfies several criteria for graph layout effectiveness.",Chris Muelder;Kwan-Liu Ma,Chris Muelder;Kwan-Liu Ma,"University of California,슠Davis, Davis, CA, USA;University of California Davis, Davis, CA, USA",10.1109/infvis.2002.1173159;10.1109/infvis.2005.1532145;10.1109/infvis.2005.1532126;10.1109/infvis.2004.66;10.1109/tvcg.2007.70580;10.1109/infvis.2002.1173159," Information visualization, Graph layout, Space filling curves",99.0,44.0,34.0,1027.0,,,graph layout algorithms;filling curves;fields node link;intuitive representation;use,0.7376;0.2835;0.2337;0.1693;0.0058,"[np.int64(-1), -1, -1, -1, -1]",39;-1;-1;-1;-1,39,39
Vis,2007,Generalized Streak Lines: Analysis and Visualization of Boundary Induced Vortices,10.1109/tvcg.2007.70557,http://dx.doi.org/10.1109/TVCG.2007.70557,1735.0,1742.0,J,"We present a method to extract and visualize vortices that originate from bounding walls of three-dimensional time- dependent flows. These vortices can be detected using their footprint on the boundary, which consists of critical points in the wall shear stress vector field. In order to follow these critical points and detect their transformations, affected regions of the surface are parameterized. Thus, an existing singularity tracking algorithm devised for planar settings can be applied. The trajectories of the singularities are used as a basis for seeding particles. This leads to a new type of streak line visualization, in which particles are released from a moving source. These generalized streak lines visualize the particles that are ejected from the wall. We demonstrate the usefulness of our method on several transient fluid flow datasets from computational fluid dynamics simulations.",Alexander Wiebel;Xavier Tricoche;Dominic Schneider;Heike Jänicke;Gerik Scheuermann,Alexander Wiebel;Xavier Tricoche;Dominic Schneider;Heike Jaenicke;Gerik Scheuermann,"Image and Signal Processing Group, Universität Leipzig, Germany and Image and Signal Processing Group, Universi??t Leipzig;SCI Institute, CS Department, University of Utah, USA and CS Department, Purdue University, USA;Image and Signal Processing Group, Universität Leipzig, Germany and Image and Signal Processing Group, Universi??t Leipzig;;Image and Signal Processing Group, Universität Leipzig, Germany and Image and Signal Processing Group, Universi??t Leipzig",10.1109/visual.2004.107;10.1109/tvcg.2006.173;10.1109/tvcg.2006.199;10.1109/visual.1990.146359;10.1109/visual.2005.1532851;10.1109/visual.1999.809896;10.1109/visual.2004.107,"Skin friction, singularity tracking, vortex, generalized streak line, flow visualization, time-dependent vector fields",57.0,32.0,33.0,351.0,,,visualize vortices originate;type streak line;dimensional time dependent;ejected wall;usefulness method,0.7156;0.2659;0.2076;0.1993;0.0031,"[np.int64(-1), -1, -1, -1, -1]",142;-1;-1;-1;-1,142,142
SciVis,2015,Multiresolution visualization of digital earth data via hexagonal box-spline wavelets,10.1109/scivis.2015.7429508,http://dx.doi.org/10.1109/SciVis.2015.7429508,151.0,152.0,M,"Multiresolution analysis is an important tool for exploring large-scale data sets. Such analysis provides facilities to visualize data at different levels of detail while providing the advantages of efficient data compression and transmission. In this work, an approach is presented to apply multiresolution analysis to digital Earth data where each resolution describes data at a specific level of detail. Geospatial data at a fine level is taken as the input and a hierarchy of approximation and detail coefficients is built by applying a hexagonal discrete wavelet transform. Multiresolution filters are designed for hexagonal cells based on the three directional linear box spline which is natively supported by modern GPUs.",Mohammad Imrul Jubair;Usman R. Alim;Niklas Röber;John P. Clyne;Ali Mahdavi-Amiri;Faramarz Samavati,Mohammad Imrul Jubair;Usman Alim;Niklas Roeber;John Clyne;Ali Mahdavi-Amiri;Faramarz Samavati,"University of Calgary, Calgary, AB, CA;University of Calgary, Calgary, AB, CA;Deutsches Klimarechenzentrum GmbH, Hamburg, Hamburg, DE;University Corporation for Atmospheric Research;University of Calgary, Calgary, AB, CA;University of Calgary, Calgary, AB, CA",,,4.0,2.0,6.0,198.0,,,hexagonal discrete wavelet;apply multiresolution;earth data;spline natively supported;analysis important tool,0.5981;0.4282;0.3747;0.2474;0.1262,"[np.int64(-1), -1, -1, -1, -1]",100;-1;-1;-1;-1,100,100
SciVis,2015,Interstitial and Interlayer Ion Diffusion Geometry Extraction in Graphitic Nanosphere Battery Materials,10.1109/tvcg.2015.2467432,http://dx.doi.org/10.1109/TVCG.2015.2467432,916.0,925.0,J,"Large-scale molecular dynamics (MD) simulations are commonly used for simulating the synthesis and ion diffusion of battery materials. A good battery anode material is determined by its capacity to store ion or other diffusers. However, modeling of ion diffusion dynamics and transport properties at large length and long time scales would be impossible with current MD codes. To analyze the fundamental properties of these materials, therefore, we turn to geometric and topological analysis of their structure. In this paper, we apply a novel technique inspired by discrete Morse theory to the Delaunay triangulation of the simulated geometry of a thermally annealed carbon nanosphere. We utilize our computed structures to drive further geometric analysis to extract the interstitial diffusion structure as a single mesh. Our results provide a new approach to analyze the geometry of the simulated carbon nanosphere, and new insights into the role of carbon defect size and distribution in determining the charge capacity and charge dynamics of these carbon based battery materials.",Attila Gyulassy;Aaron Knoll;Kah Chun Lau;Bei Wang 0001;Peer-Timo Bremer;Michael E. Papka;Larry A. Curtiss;Valerio Pascucci,Attila Gyulassy;Aaron Knoll;Kah Chun Lau;Bei Wang;Peer-Timo Bremer;Michael E. Papka;Larry A. Curtiss;Valerio Pascucci,"SCI Institute, University of Utah;SCI Institute, University of Utah;Materials Science Division, Argonne National Laboratory;SCI Institute, University of Utah;Lawrence Livermore National Laboratory;Materials Science Division, Argonne National Laboratory;Materials Science Division, Argonne National Laboratory;SCI Institute, University of Utah",10.1109/visual.2005.1532795;10.1109/tvcg.2011.244;10.1109/tvcg.2014.2346403;10.1109/visual.2005.1532839;10.1109/tvcg.2011.259;10.1109/visual.2005.1532795,"materials science, morse-smale, topology, Delaunay, computational geometry",56.0,21.0,56.0,589.0,,,simulated carbon nanosphere;diffusion battery materials;theory delaunay triangulation;commonly;time scales impossible,0.5186;0.4761;0.3500;-0.0003;-0.0046,"[np.int64(-1), -1, -1, -1, -1]",214;-1;-1;-1;-1,214,214
InfoVis,2014,"Node, Node-Link, and Node-Link-Group Diagrams: An Evaluation",10.1109/tvcg.2014.2346422,http://dx.doi.org/10.1109/TVCG.2014.2346422,2231.0,2240.0,J,"Effectively showing the relationships between objects in a dataset is one of the main tasks in information visualization. Typically there is a well-defined notion of distance between pairs of objects, and traditional approaches such as principal component analysis or multi-dimensional scaling are used to place the objects as points in 2D space, so that similar objects are close to each other. In another typical setting, the dataset is visualized as a network graph, where related nodes are connected by links. More recently, datasets are also visualized as maps, where in addition to nodes and links, there is an explicit representation of groups and clusters. We consider these three Techniques, characterized by a progressive increase of the amount of encoded information: node diagrams, node-link diagrams and node-link-group diagrams. We assess these three types of diagrams with a controlled experiment that covers nine different tasks falling broadly in three categories: node-based tasks, network-based tasks and group-based tasks. Our findings indicate that adding links, or links and group representations, does not negatively impact performance (time and accuracy) of node-based tasks. Similarly, adding group representations does not negatively impact the performance of network-based tasks. Node-link-group diagrams outperform the others on group-based tasks. These conclusions contradict results in other studies, in similar but subtly different settings. Taken together, however, such results can have significant implications for the design of standard and domain snecific visualizations tools.",Bahador Saket;Paolo Simonetto;Stephen G. Kobourov;Katy Börner,Bahador Saket;Paolo Simonetto;Stephen Kobourov;Katy Börner,University of Arizona;University of Arizona;University of Arizona;Indiana University,10.1109/infvis.2003.1249011;10.1109/tvcg.2011.186;10.1109/tvcg.2008.155;10.1109/infvis.1995.528686;10.1109/tvcg.2007.70596;10.1109/tvcg.2009.122;10.1109/tvcg.2013.187;10.1109/tvcg.2013.124;10.1109/infvis.2003.1249011,"graphs, networks, maps, scatter plots",68.0,37.0,48.0,1380.0,,,information visualization;node link group;tasks similarly adding;does negatively impact;standard domain snecific,0.6692;0.3777;0.1559;0.0737;0.0723,"[np.int64(-1), -1, -1, -1, -1]",207;-1;-1;-1;-1,207,207
Vis,1997,Application-controlled demand paging for out-of-core visualization,10.1109/visual.1997.663888,http://dx.doi.org/10.1109/VISUAL.1997.663888,235.0,244.0,C,"In the area of scientific visualization, input data sets are often very large. In visualization of computational fluid dynamics (CFD) in particular, input data sets today can surpass 100 Gbytes, and are expected to scale with the ability of supercomputers to generate them. Some visualization tools already partition large data sets into segments, and load appropriate segments as they are needed. However, this does not remove the problem for two reasons: 1) there are data sets for which even the individual segments are too large for the largest graphics workstations, 2) many practitioners do not have access to workstations with the memory capacity required to load even a segment, especially since the state-of-the-art visualization tools tend to be developed by researchers with much more powerful machines. When the size of the data that must be accessed is larger than the size of memory, some form of virtual memory is simply required. This may be by segmentation, paging, or by paged segments. The authors demonstrate that complete reliance on operating system virtual memory for out-of-core visualization leads to egregious performance. They then describe a paged segment system that they have implemented, and explore the principles of memory management that can be employed by the application for out-of-core visualization. They show that application control over some of these can significantly improve performance. They show that sparse traversal can be exploited by loading only those data actually required.",Michael Cox;David A. Ellsworth,M. Cox;D. Ellsworth,"Microcomputer Research Laboratories, Intel Corporation, MRJ/NASA Ames Research Center, USA;MRJ/NASA Ames Research Center, USA",10.1109/visual.1994.346311;10.1109/visual.1990.146360;10.1109/visual.1993.398860;10.1109/visual.1994.346311,"computational fluid dynamics, visualization, out-of-core visualization",681.0,144.0,28.0,567.0,,,large visualization;virtual memory core;paging paged segments;cfd particular input;does remove problem,0.6407;0.4445;0.3461;0.1041;-0.0160,"[np.int64(-1), -1, -1, -1, -1]",190;-1;-1;-1;-1,190,190
Vis,2024,What Can Interactive Visualization Do for Participatory Budgeting in Chicago?,10.1109/tvcg.2024.3456343,http://dx.doi.org/10.1109/TVCG.2024.3456343,415.0,425.0,J,"Participatory budgeting (PB) is a democratic approach to allocating municipal spending that has been adopted in many places in recent years, including in Chicago. Current PB voting resembles a ballot where residents are asked which municipal projects, such as school improvements and road repairs, to fund with a limited budget. In this work, we ask how interactive visualization can benefit PB by conducting a design probe-based interview study (N=13) with policy workers and academics with expertise in PB, urban planning, and civic HCI. Our probe explores how graphical elicitation of voter preferences and a dashboard of voting statistics can be incorporated into a realistic PB tool. Through qualitative analysis, we find that visualization creates opportunities for city government to set expectations about budget constraints while also granting their constituents greater freedom to articulate a wider range of preferences. However, using visualization to provide transparency about PB requires efforts to mitigate potential access barriers and mistrust. We call for more visualization professionals to help build civic capacity by working in and studying political systems.",Alex Kale;Danni Liu;Maria Gabriela Ayala;Harper Schwab;Andrew McNutt,Alex Kale;Danni Liu;Maria Gabriela Ayala;Harper Schwab;Andrew McNutt,"University of Chicago, USA;University of Chicago, USA;University of Chicago, USA;University of Chicago, USA;University of Washington, USA",10.1109/tvcg.2014.2346984;10.1109/tvcg.2013.119;10.1109/tvcg.2017.2743898;10.1109/tvcg.2020.3029412;10.1109/tvcg.2023.3327385;10.1109/tvcg.2016.2598920;10.1109/tvcg.2018.2864913;10.1109/tvcg.2023.3326593,"Visualization,Preference elicitation,,,Digital democracy",,0.0,95.0,140.0,,,participatory budgeting;qualitative analysis visualization;resembles ballot;hci probe;years including chicago,0.6237;0.4531;0.2780;0.1032;0.1032,"[np.int64(-1), -1, -1, -1, -1]",70;-1;-1;-1;-1,70,70
Vis,2003,A novel interface for higher-dimensional classification of volume data,10.1109/visual.2003.1250413,http://dx.doi.org/10.1109/VISUAL.2003.1250413,505.0,512.0,C,"In the traditional volume visualization paradigm, the user specifies a transfer function that assigns each scalar value to a color and opacity by defining an opacity and a color map function. The transfer function has two limitations. First, the user must define curves based on histogram and value rather than seeing and working with the volume itself. Second, the transfer function is inflexible in classifying regions of interest, where values at a voxel such as intensity and gradient are used to differentiate material, not talking into account additional properties such as texture and position. We describe an intuitive user interface for specifying the classification functions that consists of the users painting directly on sample slices of the volume. These painted regions are used to automatically define high-dimensional classification functions that can be implemented in hardware for interactive rendering. The classification of the volume is iteratively improved as the user paints samples, allowing intuitive and efficient viewing of materials of interest.",Fan-Yin Tzeng;Eric B. Lum;Kwan-Liu Ma,Fan-Yin Tzeng;E.B. Lum;Kwan-Liu Ma,"Department of Computer Science, University of California Davis, USA;Department of Computer Science, University of California,슠Davis, USA;Department of Computer Science, University of California Davis, USA",10.1109/visual.1998.745319;10.1109/visual.2001.964519;10.1109/visual.1999.809932;10.1109/visual.1997.663875;10.1109/visual.1996.568113,"classification, graphics hardware, interactive visualization, multidimensional transfer function, neural network, user interface design, volume visualization",193.0,35.0,25.0,266.0,,,volume visualization paradigm;opacity color map;paints samples allowing;function transfer function;define,0.6981;0.4493;0.3069;0.0825;0.0673,"[np.int64(-1), -1, -1, -1, -1]",84;-1;-1;-1;-1,84,84
InfoVis,2019,ShapeWordle: Tailoring Wordles using Shape-aware Archimedean Spirals,10.1109/tvcg.2019.2934783,http://dx.doi.org/10.1109/TVCG.2019.2934783,991.0,1000.0,J,"We present a new technique to enable the creation of shape-bounded Wordles, we call ShapeWordle, in which we fit words to form a given shape. To guide word placement within a shape, we extend the traditional Archimedean spirals to be shape-aware by formulating the spirals in a differential form using the distance field of the shape. To handle non-convex shapes, we introduce a multi-centric Wordle layout method that segments the shape into parts for our shape-aware spirals to adaptively fill the space and generate word placements. In addition, we offer a set of editing interactions to facilitate the creation of semantically-meaningful Wordles. Lastly, we present three evaluations: a comprehensive comparison of our results against the state-of-the-art technique (WordArt), case studies with 14 users, and a gallery to showcase the coverage of our technique.",Yunhai Wang;Xiaowei Chu;Kaiyi Zhang 0003;Chen Bao;Xiaotong Li;Jian Zhang 0070;Chi-Wing Fu;Christophe Hurter;Bongshin Lee;Oliver Deussen,Yunhai Wang;Xiaowei Chu;Kaiyi Zhang;Chen Bao;Xiaotong Li;Jian Zhang;Chi-Wing Fu;Christophe Hurter;Oliver Deussen;Bongshin Lee,"Shandong University;Shandong University;Shandong University;Shandong University;Shandong University;CNIC, CAS;Chinese University of Hong Kong;ENAC, France;Konstanz University, Germany and Shenzhen VisuCA Key Lab, SIAT, China;Microsoft Research",10.1109/vast.2007.4389007;10.1109/vast.2009.5333443;10.1109/tvcg.2011.233;10.1109/tvcg.2017.2746018;10.1109/tvcg.2011.223;10.1109/tvcg.2010.175;10.1109/tvcg.2010.194;10.1109/infvis.2004.56;10.1109/tvcg.2009.171;10.1109/tvcg.2017.2745859;10.1109/infvis.2001.963273;10.1109/vast.2007.4389007,"Wordle,Archimedean spiral,shape",8.0,10.0,42.0,815.0,,,shape bounded wordles;formulating spirals differential;set editing interactions;state art;studies 14 users,0.5926;0.2803;0.1925;0.1503;0.0707,"[np.int64(-1), -1, -1, -1, -1]",27;-1;-1;-1;-1,27,27
Vis,2021,F2-Bubbles: Faithful Bubble Set Construction and Flexible Editing,10.1109/tvcg.2021.3114761,http://dx.doi.org/10.1109/TVCG.2021.3114761,422.0,432.0,J,"In this paper, we propose F2-Bubbles, a set overlay visualization technique that addresses overlapping artifacts and supports interactive editing with intelligent suggestions. The core of our method is a new, efficient set overlay construction algorithm that approximates the optimal set overlay by considering set elements and their non-set neighbors. Thanks to the efficiency of the algorithm, interactive editing is achieved, and with intelligent suggestions, users can easily and flexibly edit visualizations through direct manipulations with local adaptations. A quantitative comparison with state-of-the-art set visualization techniques and case studies demonstrate the effectiveness of our method and suggests that F2-Bubbles is a helpful technique for set visualization.",Yunhai Wang;Da Cheng;Zhirui Wang;Jian Zhang 0070;Liang Zhou 0001;Gaoqi He;Oliver Deussen,Yunhai Wang;Da Cheng;Zhirui Wang;Jian Zhang;Liang Zhou;Gaoqi He;Oliver Deussen,"Shandong University, China;Shandong University, China;Shandong University, China;CNIC, CAS, China;National Institute of Health Data Science, Peking University, China;East China Normal University, China;Konstanz University, Germany",10.1109/tvcg.2011.186;10.1109/tvcg.2013.184;10.1109/tvcg.2009.122;10.1109/tvcg.2012.252;10.1109/tvcg.2010.175;10.1109/tvcg.2014.2346248;10.1109/tvcg.2012.199;10.1109/infvis.2005.1532150;10.1109/tvcg.2014.2346249;10.1109/tvcg.2019.2934805;10.1109/tvcg.2012.262;10.1109/tvcg.2011.186,"Set visualization,Edge Crossing,Minimal Spanning Tree",2.0,2.0,47.0,691.0,,,set overlay visualization;artifacts supports;editing intelligent;propose f2 bubbles;construction,0.7254;0.2815;0.2255;0.1980;0.1065,"[np.int64(-1), -1, -1, -1, -1]",177;-1;-1;-1;-1,177,177
VAST,2011,Visualizing an information assurance risk taxonomy,10.1109/vast.2011.6102477,http://dx.doi.org/10.1109/VAST.2011.6102477,287.0,288.0,M,"The researchers explore the intersections between Information Assurance and Risk using visual analysis of text mining operations. The methodological approach involves searching for and extracting for analysis those abstracts and keywords groupings that relate to risk within a defined subset of scientific research journals. This analysis is conducted through a triangulated study incorporating visualizations produced using both Starlight and In-Spire visual analysis software. The results are definitional, showing current attitudes within the Information Assurance research community towards risk management strategies, while simultaneously demonstrating the value of visual analysis processes when engaging in sense making of a large body of knowledge.",Victoria L. Lemieux;Barbara Endicott-Popovsky;Karl Eckler;Thomas Dang;Adam Jansen,Victoria Lemieux;Barbara Endicott-Popovsky;Karl Eckler;Thomas Dang;Adam Jansen,"University of British Columbia, Canada;University of Washington, USA;University of Washington, USA;University of British Columbia, Canada;University of British Columbia, Canada",,,0.0,0.0,2.0,234.0,,,visual analysis text;information assurance risk;scientific research journals;starlight;making large body,0.5584;0.4975;0.3734;0.0647;-0.0407,"[np.int64(-1), -1, -1, -1, -1]",-1;-1;-1;-1;-1,,-1
VAST,2018,Clustrophile 2: Guided Visual Clustering Analysis,10.1109/tvcg.2018.2864477,http://dx.doi.org/10.1109/TVCG.2018.2864477,267.0,276.0,J,"Data clustering is a common unsupervised learning method frequently used in exploratory data analysis. However, identifying relevant structures in unlabeled, high-dimensional data is nontrivial, requiring iterative experimentation with clustering parameters as well as data features and instances. The number of possible clusterings for a typical dataset is vast, and navigating in this vast space is also challenging. The absence of ground-truth labels makes it impossible to define an optimal solution, thus requiring user judgment to establish what can be considered a satisfiable clustering result. Data scientists need adequate interactive tools to effectively explore and navigate the large clustering space so as to improve the effectiveness of exploratory clustering analysis. We introduce Clustrophile 2, a new interactive tool for guided clustering analysis. Clustrophile 2 guides users in clustering-based exploratory analysis, adapts user feedback to improve user guidance, facilitates the interpretation of clusters, and helps quickly reason about differences between clusterings. To this end, Clustrophile 2 contributes a novel feature, the Clustering Tour, to help users choose clustering parameters and assess the quality of different clustering results in relation to current analysis goals and user expectations. We evaluate Clustrophile 2 through a user study with 12 data scientists, who used our tool to explore and interpret sub-cohorts in a dataset of Parkinson's disease patients. Results suggest that Clustrophile 2 improves the speed and effectiveness of exploratory clustering analysis for both experts and non-experts.",Marco Cavallo;Çagatay Demiralp,Marco Cavallo;Çağatay Demiralp,IBM Research;MIT CSAIL & Fitnescity Labs,10.1109/tvcg.2011.188;10.1109/tvcg.2013.119;10.1109/tvcg.2012.219;10.1109/tvcg.2017.2745085;10.1109/tvcg.2010.138;10.1109/vast.2007.4388999;10.1109/tvcg.2012.207;10.1109/tvcg.2017.2744805;10.1109/vast.2008.4677350;10.1109/infvis.2004.3;10.1109/tvcg.2015.2467191;10.1109/tvcg.2011.188,"Clustering tour,Guided data analysis,Unsupervised learning,Exploratory data analysis,Interactive clustering analysis,Interpretability,Explainability,Visual data exploration recommendation,Dimensionality reduction,What-if analysis,Clustrophile",77.0,57.0,46.0,1801.0,,,exploratory clustering analysis;improve user guidance;parkinson disease patients;clustrophile improves speed;makes impossible define,0.6755;0.3571;0.2804;0.1180;-0.0119,"[np.int64(-1), -1, -1, -1, -1]",137;-1;-1;-1;-1,137,137
Vis,2021,AffectiveTDA: Using Topological Data Analysis to Improve Analysis and Explainability in Affective Computing,10.1109/tvcg.2021.3114784,http://dx.doi.org/10.1109/TVCG.2021.3114784,769.0,779.0,J,"We present an approach utilizing Topological Data Analysis to study the structure of face poses used in affective computing, i.e., the process of recognizing human emotion. The approach uses a conditional comparison of different emotions, both respective and irrespective of time, with multiple topological distance metrics, dimension reduction techniques, and face subsections (e.g., eyes, nose, mouth, etc.). The results confirm that our topology-based approach captures known patterns, distinctions between emotions, and distinctions between individuals, which is an important step towards more robust and explainable emotion recognition by machines.",Hamza Elhamdadi;Shaun J. Canavan;Paul Rosen 0001,Hamza Elhamdadi;Shaun Canavan;Paul Rosen,"University of Massachusetts, Amherst, USA;University of South Florida, USA;University of South Florida, USA",10.1109/tvcg.2017.2744321;10.1109/tvcg.2012.248;10.1109/tvcg.2019.2934802;10.1109/tvcg.2017.2743938;10.1109/tvcg.2011.177;10.1109/tvcg.2017.2744321,"Affective computing,topological data analysis,explainability,visualization",7.0,9.0,91.0,900.0,,,recognizing human emotion;structure face poses;metrics dimension reduction;multiple topological;irrespective time,0.6015;0.4031;0.3427;0.3284;0.0393,"[np.int64(-1), -1, -1, -1, -1]",23;-1;-1;-1;-1,23,23
Vis,2005,A feature-driven approach to locating optimal viewpoints for volume visualization,10.1109/visual.2005.1532834,http://dx.doi.org/10.1109/VISUAL.2005.1532834,495.0,502.0,C,"Optimal viewpoint selection is an important task because it considerably influences the amount of information contained in the 2D projected images of 3D objects, and thus dominates their first impressions from a psychological point of view. Although several methods have been proposed that calculate the optimal positions of viewpoints especially for 3D surface meshes, none has been done for solid objects such as volumes. This paper presents a new method of locating such optimal viewpoints when visualizing volumes using direct volume rendering. The major idea behind our method is to decompose an entire volume into a set of feature components, and then find a globally optimal viewpoint by finding a compromise between locally optimal viewpoints for the components. As the feature components, the method employs interval volumes and their combinations that characterize the topological transitions of isosurfaces according to the scalar field. Furthermore, opacity transfer functions are also utilized to assign different weights to the decomposed components so that users can emphasize features of specific interest in the volumes. Several examples of volume datasets together with their optimal positions of viewpoints are exhibited in order to demonstrate that the method can effectively guide naive users to find optimal projections of volumes.",Shigeo Takahashi;Issei Fujishiro;Yuriko Takeshima;Tomoyuki Nishita,S. Takahashi;I. Fujishiro;Y. Takeshima;T. Nishita,"University of Tokyo, Japan;University of Tohoku, Japan;Tohoku University;University of Tokyo, Japan",10.1109/visual.1995.480789;10.1109/visual.2004.96;10.1109/visual.2002.1183774;10.1109/visual.2005.1532833;10.1109/visual.1997.663875;10.1109/visual.2002.1183785,"viewpoint selection, viewpoint entropy, direct volume rendering, interval volumes, level-set graphs",234.0,29.0,34.0,566.0,,,viewpoints visualizing volumes;transitions isosurfaces;emphasize features specific;proposed calculate optimal;naive users,0.7616;0.2986;0.2297;0.1460;0.0701,"[np.int64(-1), -1, -1, -1, -1]",84;-1;-1;-1;-1,84,84
Vis,2007,Time Dependent Processing in a Parallel Pipeline Architecture,10.1109/tvcg.2007.70600,http://dx.doi.org/10.1109/TVCG.2007.70600,1376.0,1383.0,J,"Pipeline architectures provide a versatile and efficient mechanism for constructing visualizations, and they have been implemented in numerous libraries and applications over the past two decades. In addition to allowing developers and users to freely combine algorithms, visualization pipelines have proven to work well when streaming data and scale well on parallel distributed- memory computers. However, current pipeline visualization frameworks have a critical flaw: they are unable to manage time varying data. As data flows through the pipeline, each algorithm has access to only a single snapshot in time of the data. This prevents the implementation of algorithms that do any temporal processing such as particle tracing; plotting over time; or interpolation, fitting, or smoothing of time series data. As data acquisition technology improves, as simulation time-integration techniques become more complex, and as simulations save less frequently and regularly, the ability to analyze the time-behavior of data becomes more important. This paper describes a modification to the traditional pipeline architecture that allows it to accommodate temporal algorithms. Furthermore, the architecture allows temporal algorithms to be used in conjunction with algorithms expecting a single time snapshot, thus simplifying software design and allowing adoption into existing pipeline frameworks. Our architecture also continues to work well in parallel distributed-memory environments. We demonstrate our architecture by modifying the popular VTK framework and exposing the functionality to the ParaView application. We use this framework to apply time-dependent algorithms on large data with a parallel cluster computer and thereby exercise a functionality that previously did not exist.",John Biddiscombe;Berk Geveci;Ken Martin;Kenneth Moreland;David C. Thompson 0001,John Biddiscombe;Berk Geveci;Ken Martin;Kenneth Moreland;David Thompson,"Swiss National Supercomputing Centre, Switzerland;Kitware, Inc.;Kitware, Inc.;Sandia National Laboratories, USA;Sandia National Laboratories, USA",10.1109/visual.2005.1532793;10.1109/visual.1992.235219;10.1109/visual.2005.1532795;10.1109/visual.1991.175794;10.1109/visual.2004.55;10.1109/infvis.2000.885092;10.1109/visual.1995.480821;10.1109/visual.2005.1532793,"data-parallel visualization pipeline, time-varying data",57.0,21.0,25.0,568.0,,,pipeline visualization frameworks;cluster computer exercise;interpolation fitting smoothing;time behavior;access single snapshot,0.6600;0.2329;0.2003;0.1857;0.0987,"[np.int64(-1), -1, -1, -1, -1]",-1;-1;-1;-1;-1,,-1
InfoVis,2019,Design by Immersion: A Transdisciplinary Approach to Problem-Driven Visualizations,10.1109/tvcg.2019.2934790,http://dx.doi.org/10.1109/TVCG.2019.2934790,109.0,118.0,J,"While previous work exists on how to conduct and disseminate insights from problem-driven visualization projects and design studies, the literature does not address how to accomplish these goals in transdisciplinary teams in ways that advance all disciplines involved. In this paper we introduce and define a new methodological paradigm we call design by immersion, which provides an alternative perspective on problem-driven visualization work. Design by immersion embeds transdisciplinary experiences at the center of the visualization process by having visualization researchers participate in the work of the target domain (or domain experts participate in visualization research). Based on our own combined experiences of working on cross-disciplinary, problem-driven visualization projects, we present six case studies that expose the opportunities that design by immersion enables, including (1) exploring new domain-inspired visualization design spaces, (2) enriching domain understanding through personal experiences, and (3) building strong transdisciplinary relationships. Furthermore, we illustrate how the process of design by immersion opens up a diverse set of design activities that can be combined in different ways depending on the type of collaboration, project, and goals. Finally, we discuss the challenges and potential pitfalls of design by immersion.",Kyle Wm. Hall;Adam James Bradley;Uta Hinrichs;Samuel Huron;Jo Wood;Christopher Collins 0001;Sheelagh Carpendale,Kyle Wm. Hall;Adam J. Bradley;Uta Hinrichs;Samuel Huron;Jo Wood;Christopher Collins;Sheelagh Carpendale,"Temple University, Philadelphia, USA;Ontario Tech University, Oshawa, Canada;University of St Andrews, Fife, United Kingdom;Télécom Paristech, Université Paris-Saclay, Paris, France;University of London, London, United Kingdom;Ontario Tech University, Oshawa, Canada;University of Calgary, Calgary, Canada and Simon Fraser University, Burnaby, Canada",10.1109/tvcg.2009.122;10.1109/tvcg.2006.160;10.1109/tvcg.2015.2467452;10.1109/tvcg.2018.2865241;10.1109/tvcg.2014.2346325;10.1109/tvcg.2011.209;10.1109/tvcg.2014.2346331;10.1109/tvcg.2009.111;10.1109/tvcg.2015.2467271;10.1109/tvcg.2012.213;10.1109/tvcg.2014.2346323;10.1109/tvcg.2009.122,"Visualization,problem-driven,design studies,collaboration,methodology,framework",39.0,31.0,47.0,1450.0,,,visualization researchers participate;understanding personal;work target domain;combined different ways;define new,0.7280;0.1534;0.1448;0.0915;0.0491,"[np.int64(-1), -1, -1, -1, -1]",209;-1;-1;-1;-1,209,209
SciVis,2020,Visualization of Human Spine Biomechanics for Spinal Surgery,10.1109/tvcg.2020.3030388,http://dx.doi.org/10.1109/TVCG.2020.3030388,700.0,710.0,J,"We propose a visualization application, designed for the exploration of human spine simulation data. Our goal is to support research in biomechanical spine simulation and advance efforts to implement simulation-backed analysis in surgical applications. Biomechanical simulation is a state-of-the-art technique for analyzing load distributions of spinal structures. Through the inclusion of patient-specific data, such simulations may facilitate personalized treatment and customized surgical interventions. Difficulties in spine modelling and simulation can be partly attributed to poor result representation, which may also be a hindrance when introducing such techniques into a clinical environment. Comparisons of measurements across multiple similar anatomical structures and the integration of temporal data make commonly available diagrams and charts insufficient for an intuitive and systematic display of results. Therefore, we facilitate methods such as multiple coordinated views, abstraction and focus and context to display simulation outcomes in a dedicated tool. $\mathrm{By}$ linking the result data with patient-specific anatomy, we make relevant parameters tangible for clinicians. Furthermore, we introduce new concepts to show the directions of impact force vectors, which were not accessible before. We integrated our toolset into a spine segmentation and simulation pipeline and evaluated our methods with both surgeons and biomechanical researchers. When comparing our methods against standard representations that are currently in use, we found increases in accuracy and speed in data exploration tasks. $\mathrm{in}$ a qualitative review, domain experts deemed the tool highly useful when dealing with simulation result data, which typically combines time-dependent patient movement and the resulting force distributions on spinal structures.",Pepe Eulzer;Sabine Bauer 0001;Francis Kilian;Kai Lawonn,Pepe Eulzer;Sabine Bauer;Francis Kilian;Kai Lawonn,"University of Jena, Germany;University of Koblenz-Landau, Germany;Department of Spine Surgery, Cath. Clinic Koblenz-Montabaur, Germany;University of Jena, Germany",10.1109/tvcg.2014.2346448;10.1109/tvcg.2011.189;10.1109/tvcg.2009.184;10.1109/tvcg.2019.2934337;10.1109/tvcg.2015.2467198;10.1109/tvcg.2014.2346591;10.1109/tvcg.2015.2467961;10.1109/tvcg.2016.2598795;10.1109/tvcg.2008.155;10.1109/tvcg.2018.2864510;10.1109/tvcg.2015.2467435;10.1109/tvcg.2014.2346448,"Medical visualization,bioinformatics,coordinated views,focus and context,biomechanical simulation",5.0,6.0,63.0,792.0,,,biomechanical spine simulation;visualization application;customized surgical interventions;impact;insufficient intuitive systematic,0.6922;0.3857;0.3148;0.2299;0.0611,"[np.int64(-1), -1, -1, -1, -1]",33;-1;-1;-1;-1,33,33
Vis,2021,Visual Arrangements of Bar Charts Influence Comparisons in Viewer Takeaways,10.1109/tvcg.2021.3114823,http://dx.doi.org/10.1109/TVCG.2021.3114823,955.0,965.0,J,"Well-designed data visualizations can lead to more powerful and intuitive processing by a viewer. To help a viewer intuitively compare values to quickly generate key takeaways, visualization designers can manipulate how data values are arranged in a chart to afford particular comparisons. Using simple bar charts as a case study, we empirically tested the comparison affordances of four common arrangements: vertically juxtaposed, horizontally juxtaposed, overlaid, and stacked. We asked participants to type out what patterns they perceived in a chart and we coded their takeaways into types of comparisons. In a second study, we asked data visualization design experts to predict which arrangement they would use to afford each type of comparison and found both alignments and mismatches with our findings. These results provide concrete guidelines for how both human designers and automatic chart recommendation systems can make visualizations that help viewers extract the “right” takeaway.",Cindy Xiong;Vidya Setlur;Benjamin Bach;Eunyee Koh;Kylie Lin;Steven Franconeri,Cindy Xiong;Vidya Setlur;Benjamin Bach;Eunyee Koh;Kylie Lin;Steven Franconeri,"UMass Amherst, United States;Tableau Research, United States;University of Edinburgh, United Kingdom;Adobe Research, United States;Northwestern University, United States;Northwestern University, United States",10.1109/tvcg.2007.70556;10.1109/tvcg.2019.2934786;10.1109/tvcg.2016.2598920;10.1109/tvcg.2011.194;10.1109/tvcg.2007.70594;10.1109/tvcg.2019.2934801;10.1109/tvcg.2018.2864884;10.1109/tvcg.2017.2744198;10.1109/tvcg.2019.2934399;10.1109/tvcg.2007.70556,"Comparison,perception,visual grouping,bar charts,recommendation systems,natural language interaction",10.0,19.0,75.0,1415.0,,,visualizations help viewers;arrangements vertically;type comparison alignments;use afford;takeaway,0.6826;0.2794;0.1720;0.1437;0.1033,"[np.int64(-1), -1, -1, -1, -1]",211;-1;-1;-1;-1,211,211
Vis,2022,Dashboard Design Patterns,10.1109/tvcg.2022.3209448,http://dx.doi.org/10.1109/TVCG.2022.3209448,342.0,352.0,J,"This paper introduces design patterns for dashboards to inform dashboard design processes. Despite a growing number of public examples, case studies, and general guidelines there is surprisingly little design guidance for dashboards. Such guidance is necessary to inspire designs and discuss tradeoffs in, e.g., screenspace, interaction, or information shown. Based on a systematic review of 144 dashboards, we report on eight groups of design patterns that provide common solutions in dashboard design. We discuss combinations of these patterns in “dashboard genres” such as narrative, analytical, or embedded dashboard. We ran a 2-week dashboard design workshop with 23 participants of varying expertise working on their own data and dashboards. We discuss the application of patterns for the dashboard design processes, as well as general design tradeoffs and common challenges. Our work complements previous surveys and aims to support dashboard designers and researchers in co-creation, structured design decisions, as well as future user evaluations about dashboard design guidelines. Detailed pattern descriptions and workshop material can be found online: https://dashboarddesignpatterns.github.io",Benjamin Bach;Euan Freeman;Alfie Abdul-Rahman;Cagatay Turkay;Saiful Khan;Yulei Fan;Min Chen 0001,Benjamin Bach;Euan Freeman;Alfie Abdul-Rahman;Cagatay Turkay;Saiful Khan;Yulei Fan;Min Chen,"University of Edinburgh, Scotland;University of Glasgow, Scotland;King's College London, England;University of Warwick, England;University of Oxford, England;University of Oxford, England;University of Oxford, England",10.1109/visual.1991.175794;10.1109/infvis.1997.636792;10.1109/tvcg.2020.3030424;10.1109/tvcg.2016.2599338;10.1109/tvcg.2021.3114828;10.1109/tvcg.2018.2864903;10.1109/tvcg.2013.120;10.1109/tvcg.2010.179;10.1109/tvcg.2019.2934398;10.1109/visual.1991.175794,"Dashboards,Design Patterns,Data Visualization,Storytelling,Visual Analytics,Qualitative Evaluation,Education",,52.0,56.0,7746.0,HM,,dashboard designers researchers;processes despite growing;tradeoffs common;23;complements previous,0.7783;0.1014;0.0651;0.0056;-0.0103,"[np.int64(-1), -1, -1, -1, -1]",192;-1;-1;-1;-1,192,192
Vis,2001,A simple algorithm for surface denoising,10.1109/visual.2001.964500,http://dx.doi.org/10.1109/VISUAL.2001.964500,107.0,112.0,C,"We present a simple denoising technique for geometric data represented as a semiregular mesh, based on locally adaptive Wiener filtering. The degree of denoising is controlled by a single parameter (an estimate of the relative noise level) and the time required for denoising is independent of the magnitude of the estimate. The performance of the algorithm is sufficiently fast to allow interactive local denoising.",Jianbo Peng;Vasily Strela;Denis Zorin,Jianbo Peng;V. Strela;D. Zorin,"New York University, USA;New York University, USA;NYU MRL, New York, NY, USA",10.1109/visual.2000.885721;10.1109/visual.2000.885721,"Meshes, multiresolution surfaces, Gaussian scale mixture model, denoising",98.0,9.0,26.0,188.0,,,adaptive wiener filtering;denoising technique geometric;mesh based locally;allow;single,0.6126;0.5888;0.4059;0.0821;-0.0498,"[np.int64(-1), np.int64(-1), -1, -1, -1]",309;248;-1;-1;-1,248;309,309
VAST,2008,The Scalable Reasoning System: Lightweight visualization for distributed analytics,10.1109/vast.2008.4677366,http://dx.doi.org/10.1109/VAST.2008.4677366,131.0,138.0,C,"A central challenge in visual analytics is the creation of accessible, widely distributable analysis applications that bring the benefits of visual discovery to as broad a user base as possible. Moreover, to support the role of visualization in the knowledge creation process, it is advantageous to allow users to describe the reasoning strategies they employ while interacting with analytic environments. We introduce an application suite called the scalable reasoning system (SRS), which provides Web-based and mobile interfaces for visual analysis. The service-oriented analytic framework that underlies SRS provides a platform for deploying pervasive visual analytic environments across an enterprise. SRS represents a ldquolightweightrdquo approach to visual analytics whereby thin client analytic applications can be rapidly deployed in a platform-agnostic fashion. Client applications support multiple coordinated views while giving analysts the ability to record evidence, assumptions, hypotheses and other reasoning artifacts. We describe the capabilities of SRS in the context of a real-world deployment at a regional law enforcement organization.",William A. Pike;Joe Bruce;Bob Baddeley;Daniel M. Best;Lyndsey Franklin;Richard May 0001;Douglas M. Rice;Rick Riensche;Katarina Younkin,William A. Pike;Joe Bruce;Bob Baddeley;Daniel Best;Lyndsey Franklin;Richard May;Douglas M. Rice;Rick Riensche;Katarina Younkin,"Pacific Northwest National Laboratory, USA;Pacific Northwest National Laboratory, USA;Pacific Northwest National Laboratory, USA;Pacific Northwest National Laboratory, USA;Pacific Northwest National Laboratory, USA;Pacific Northwest National Laboratory, USA;Pacific Northwest National Laboratory, USA;Pacific Northwest National Laboratory, USA;Pacific Northwest National Laboratory, USA",10.1109/tvcg.2007.70577;10.1109/tvcg.2006.142;10.1109/vast.2007.4388996;10.1109/infvis.2005.1532133;10.1109/visual.1993.398874;10.1109/vast.2007.4389006;10.1109/vast.2007.4388991;10.1109/tvcg.2007.70577,"Web visualization, mobile visualization, analytic reasoning, law enforcement, multiple views",43.0,6.0,21.0,336.0,,,visual analytics;hypotheses;platform deploying;regional law;ldquolightweightrdquo approach,0.6887;0.1995;0.1572;0.1270;0.0796,"[np.int64(-1), -1, -1, -1, -1]",201;-1;-1;-1;-1,201,201
Vis,1992,Real virtual environment applications-now,10.1109/visual.1992.235184,http://dx.doi.org/10.1109/VISUAL.1992.235184,375.0,379.0,M,"Discusses efforts to develop virtual environment (VE) systems. The applications discussed are medical telesurgery, maintenance access, presence simulators, accounting visualizations, topographic visualizations and tools to assist developers in determining the value added of potential VE-based solutions.&lt;&lt;ETX&gt;&gt;",P.T. Breen,P.T. Breen,,,,,1.0,0.0,63.0,,,virtual environment;telesurgery maintenance;topographic visualizations;determining value added;lt lt,0.7408;0.3635;0.2836;0.1370;0.0284,"[np.int64(-1), -1, -1, -1, -1]",36;-1;-1;-1;-1,36,36
Vis,2008,Vectorized Radviz and Its Application to Multiple Cluster Datasets,10.1109/tvcg.2008.173,http://dx.doi.org/10.1109/TVCG.2008.173,1444.0,1427.0,J,"Radviz is a radial visualization with dimensions assigned to points called dimensional anchors (DAs) placed on the circumference of a circle. Records are assigned locations within the circle as a function of its relative attraction to each of the DAs. The DAs can be moved either interactively or algorithmically to reveal different meaningful patterns in the dataset. In this paper we describe Vectorized Radviz (VRV) which extends the number of dimensions through data flattening. We show how VRV increases the power of Radviz through these extra dimensions by enhancing the flexibility in the layout of the DAs. We apply VRV to the problem of analyzing the results of multiple clusterings of the same data set, called multiple cluster sets or cluster ensembles. We show how features of VRV help discern patterns across the multiple cluster sets. We use the Iris data set to explain VRV and a newt gene microarray data set used in studying limb regeneration to show its utility. We then discuss further applications of VRV.",John Sharko;Georges G. Grinstein;Kenneth A. Marx,John Sharko;Georges Grinstein;Kenneth A. Marx,"Department of Computer Science, University of Massachusetts, Lowell, USA;Department of Computer Science, University of Massachusetts, Lowell, USA;Department of Chemistry, University of Massachusetts, Lowell, USA",10.1109/infvis.2004.15;10.1109/visual.1997.663916;10.1109/infvis.1998.729559;10.1109/infvis.2004.15,"Visualization, Radviz, Vectorized Radviz, Clustering, Multiple Clustering, Cluster Ensembles, Flattening Datasets",107.0,62.0,29.0,970.0,,,radial visualization;gene microarray data;studying limb regeneration;anchors;extends number,0.6340;0.3113;0.2470;0.1127;0.0426,"[np.int64(-1), -1, -1, -1, -1]",252;-1;-1;-1;-1,252,252
InfoVis,2019,VisTA: Integrating Machine Intelligence with Visualization to Support the Investigation of Think-Aloud Sessions,10.1109/tvcg.2019.2934797,http://dx.doi.org/10.1109/TVCG.2019.2934797,343.0,352.0,J,"Think-aloud protocols are widely used by user experience (UX) practitioners in usability testing to uncover issues in user interface design. It is often arduous to analyze large amounts of recorded think-aloud sessions and few UX practitioners have an opportunity to get a second perspective during their analysis due to time and resource constraints. Inspired by the recent research that shows subtle verbalization and speech patterns tend to occur when users encounter usability problems, we take the first step to design and evaluate an intelligent visual analytics tool that leverages such patterns to identify usability problem encounters and present them to UX practitioners to assist their analysis. We first conducted and recorded think-aloud sessions, and then extracted textual and acoustic features from the recordings and trained machine learning (ML) models to detect problem encounters. Next, we iteratively designed and developed a visual analytics tool, VisTA, which enables dynamic investigation of think-aloud sessions with a timeline visualization of ML predictions and input features. We conducted a between-subjects laboratory study to compare three conditions, i.e., VisTA, VisTASimple (no visualization of the ML's input features), and Baseline (no ML information at all), with 30 UX professionals. The findings show that UX professionals identified more problem encounters when using VisTA than Baseline by leveraging the problem visualization as an overview, anticipations, and anchors as well as the feature visualization as a means to understand what ML considers and omits. Our findings also provide insights into how they treated ML, dealt with (dis)agreement with ML, and reviewed the videos (i.e., play, pause, and rewind).",Mingming Fan 0001;Ke Wu;Jian Zhao 0010;Yue Li;Winter Wei;Khai N. Truong,Mingming Fan;Ke Wu;Jian Zhao;Yue Li;Winter Wei;Khai N. Truong,University of Toronto and Rochester Institute of Technology;University of Toronto;University of Waterloo;University of Toronto;University of Toronto;University of Toronto,10.1109/tvcg.2015.2467871;10.1109/vast.2008.4677365;10.1109/tvcg.2008.137;10.1109/vast.2010.5653598;10.1109/tvcg.2016.2598543;10.1109/tvcg.2017.2745279;10.1109/tvcg.2015.2467871,"Think-aloud,visual analytics,machine intelligence,user study,usability problems,session review behavior,UX practices",10.0,11.0,45.0,1155.0,,,users encounter usability;visualization ml predictions;extracted textual acoustic;pause rewind;vista enables dynamic,0.5507;0.3697;0.2689;0.2070;0.1012,"[np.int64(-1), -1, -1, -1, -1]",79;-1;-1;-1;-1,79,79
Vis,1994,Visualizing data: is virtual reality the key?,10.1109/visual.1994.346286,http://dx.doi.org/10.1109/VISUAL.1994.346286,410.0,413.0,M,"A visualization goal is to simplify the analysis of large-quantity, numerical data by rendering the data as an image that can be intuitively manipulated. The question the article addresses is whether or not virtual reality techniques are the cure-all to the dilemma of visualizing increasing amounts of data. It determines the usefulness of techniques available today and in the near future that will ease the problem of visualizing complex data. In regards to visualization, the article discusses characteristics of virtual reality systems, data in three-dimensional environments, augmented reality, and virtual reality market opportunities.&lt;&lt;ETX&gt;&gt;",Linda M. Stone;Thomas Erickson;Benjamin B. Bederson;Peter Rothman;Raymond Muzzy,L.M. Stone;T. Erickson;B.B. Bederson;P. Rothman;R. Muzzy,"Loral Space and Range Systems, USA;Apple Computer, Inc., USA;University of New Mexico, USA;Avatar Partners, USA;LORAL Rolm Computer Systems, USA",,,3.0,1.0,22.0,133.0,,,visualizing complex data;environments augmented reality;article addresses virtual;techniques available today;future ease,0.6139;0.4263;0.2820;0.2299;0.1104,"[np.int64(-1), -1, -1, -1, -1]",199;-1;-1;-1;-1,199,199
InfoVis,2004,RecMap: Rectangular Map Approximations,10.1109/infvis.2004.57,http://dx.doi.org/10.1109/INFVIS.2004.57,33.0,40.0,C,"In many application domains, data is collected and referenced by its geospatial location. Nowadays, different kinds of maps are used to emphasize the spatial distribution of one or more geospatial attributes. The nature of geospatial statistical data is the highly nonuniform distribution in the real world data sets. This has several impacts on the resulting map visualizations. Classical area maps tend to highlight patterns in large areas, which may, however, be of low importance. Cartographers and geographers used cartograms or value-by-area maps to address this problem long before computers were available. Although many automatic techniques have been developed, most of the value-by-area cartograms are generated manually via human interaction. In this paper, we propose a novel visualization technique for geospatial data sets called RecMap. Our technique approximates a rectangular partition of the (rectangular) display area into a number of map regions preserving important geospatial constraints. It is a fully automatic technique with explicit user control over all exploration constraints within the exploration process. Experiments show that our technique produces visualizations of geospatial data sets, which enhance the discovery of global and local correlations, and demonstrate its performance in a variety of applications",Roland Heilmann;Daniel A. Keim;Christian Panse;Mike Sips,R. Heilmann;D.A. Keim;C. Panse;M. Sips,"Bayer Technology;University of Konstanz, Germany;University of Konstanz, Germany;University of Konstanz, Germany",10.1109/visual.1998.745303;10.1109/visual.1991.175815;10.1109/infvis.2002.1173144;10.1109/visual.1998.745303,"Geographic Visualization, Information Visualization, Database and Data Mining Visualization",122.0,32.0,13.0,576.0,,,visualizations geospatial data;approximates rectangular partition;constraints fully automatic;process experiments;low,0.7727;0.1388;0.1266;0.0338;-0.0475,"[np.int64(-1), -1, -1, -1, -1]",154;-1;-1;-1;-1,154,154
Vis,1995,A rule-based tool for assisting colormap selection,10.1109/visual.1995.480803,http://dx.doi.org/10.1109/VISUAL.1995.480803,118.0,,C,"The paper presents an interactive approach for guiding the user's select of colormaps in visualization. PRAVDAColor, implemented as a module in the IBM Visualization Data Explorer, provides the user a selection of appropriate colormaps given the data type and spatial frequency, the user's task, and properties of the human perceptual system.",Lawrence D. Bergman;Bernice E. Rogowitz;Lloyd Treinish,L.D. Bergman;B.E. Rogowitz;L.A. Treinish,"IBM Thomas J. Watson Research Center, Yorktown Heights, NY, USA;IBM Thomas J. Watson Research Center, Yorktown Heights, NY, USA;IBM Thomas J. Watson Research Center, Yorktown Heights, NY, USA",10.1109/visual.1995.480821;10.1109/visual.1993.398874;10.1109/visual.1995.480821,,329.0,92.0,24.0,1476.0,,,colormaps visualization;data explorer provides;interactive approach guiding;type spatial frequency;user select,0.7381;0.3564;0.3402;0.2246;0.1918,"[np.int64(-1), -1, -1, -1, -1]",131;-1;-1;-1;-1,131,131
InfoVis,2012,Interactive Level-of-Detail Rendering of Large Graphs,10.1109/tvcg.2012.238,http://dx.doi.org/10.1109/TVCG.2012.238,2486.0,2495.0,J,"We propose a technique that allows straight-line graph drawings to be rendered interactively with adjustable level of detail. The approach consists of a novel combination of edge cumulation with density-based node aggregation and is designed to exploit common graphics hardware for speed. It operates directly on graph data and does not require precomputed hierarchies or meshes. As proof of concept, we present an implementation that scales to graphs with millions of nodes and edges, and discuss several example applications.",Michael Zinsmaier;Ulrik Brandes;Oliver Deussen;Hendrik Strobelt,Michael Zinsmaier;Ulrik Brandes;Oliver Deussen;Hendrik Strobelt,"University of Konstanz, Germany;University of Konstanz, Germany;University of Konstanz, Germany;University of Konstanz, Germany",10.1109/infvis.2005.1532150;10.1109/tvcg.2006.120;10.1109/tvcg.2011.233;10.1109/tvcg.2008.135;10.1109/tvcg.2006.187;10.1109/tvcg.2006.147;10.1109/tvcg.2010.154;10.1109/infvis.2004.66,"Graph visualization, OpenGL, edge aggregation",123.0,72.0,28.0,1748.0,,,graph drawings rendered;millions nodes;cumulation density;require precomputed hierarchies;speed,0.6425;0.3836;0.2399;0.1275;0.0894,"[np.int64(-1), -1, -1, -1, -1]",143;-1;-1;-1;-1,143,143
VAST,2016,C2A: Crowd consensus analytics for virtual colonoscopy,10.1109/vast.2016.7883508,http://dx.doi.org/10.1109/VAST.2016.7883508,21.0,30.0,C,"We present a medical crowdsourcing visual analytics platform called C<sup>2</sup>A to visualize, classify and filter crowdsourced clinical data. More specifically, C<sup>2</sup>A is used to build consensus on a clinical diagnosis by visualizing crowd responses and filtering out anomalous activity. Crowdsourcing medical applications have recently shown promise where the non-expert users (the crowd) were able to achieve accuracy similar to the medical experts. This has the potential to reduce interpretation/reading time and possibly improve accuracy by building a consensus on the findings beforehand and letting the medical experts make the final diagnosis. In this paper, we focus on a virtual colonoscopy (VC) application with the clinical technicians as our target users, and the radiologists acting as consultants and classifying segments as benign or malignant. In particular, C<sup>2</sup>A is used to analyze and explore crowd responses on video segments, created from fly-throughs in the virtual colon. C<sup>2</sup>A provides several interactive visualization components to build crowd consensus on video segments, to detect anomalies in the crowd data and in the VC video segments, and finally, to improve the non-expert user's work quality and performance by A/B testing for the optimal crowdsourcing platform and application-specific parameters. Case studies and domain experts feedback demonstrate the effectiveness of our framework in improving workers' output quality, the potential to reduce the radiologists' interpretation time, and hence, the potential to improve the traditional clinical workflow by marking the majority of the video segments as benign based on the crowd consensus.",Ji Hwan Park;Saad Nadeem;Seyedkoosha Mirhosseini;Arie E. Kaufman,Ji Hwan Park;Saad Nadeem;Seyedkoosha Mirhosseini;Arie Kaufman,Stony Brook University;Stony Brook University;Stony Brook University;Stony Brook University,10.1109/tvcg.2015.2467196;10.1109/tvcg.2006.112;10.1109/tvcg.2009.171;10.1109/tvcg.2006.158;10.1109/vast.2015.7347631;10.1109/tvcg.2013.164;10.1109/tvcg.2015.2467555;10.1109/tvcg.2015.2467196,,0.0,8.0,39.0,303.0,,,medical crowdsourcing visual;virtual colon sup;filtering anomalous activity;platform application;time potential,0.6825;0.2116;0.2066;0.1779;0.0017,"[np.int64(-1), -1, -1, -1, -1]",313;-1;-1;-1;-1,313,313
Vis,2008,Box Spline Reconstruction On The Face-Centered Cubic Lattice,10.1109/tvcg.2008.115,http://dx.doi.org/10.1109/TVCG.2008.115,1523.0,1530.0,J,We introduce and analyze an efficient reconstruction algorithm for FCC-sampled data. The reconstruction is based on the 6-direction box spline that is naturally associated with the FCC lattice and shares the continuity and approximation order of the triquadratic B-spline. We observe less aliasing for generic level sets and derive special techniques to attain the higher evaluation efficiency promised by the lower degree and smaller stencil-size of the C1 6-direction box spline over the triquadratic B-spline.,Minho Kim;Alireza Entezari;Jörg Peters 0001,Minho Kim;Alireza Entezari;Jörg Peters,"CISE Department, University of Florida, USA;CISE Department, University of Florida, USA;CISE Department, University of Florida, USA",10.1109/visual.1994.346331;10.1109/tvcg.2007.70573;10.1109/visual.2001.964498;10.1109/visual.1993.398851;10.1109/visual.2005.1532811;10.1109/visual.2005.1532810;10.1109/visual.2004.65;10.1109/visual.1994.346331,"Volumetric data reconstruction, box spline, Face-Centered Cubic lattice",50.0,28.0,31.0,266.0,,,reconstruction algorithm fcc;spline naturally associated;approximation order triquadratic;lattice shares;higher,0.5474;0.3962;0.2700;0.1518;0.0693,"[np.int64(-1), -1, -1, -1, -1]",102;-1;-1;-1;-1,102,102
Vis,2001,Transport and anisotropic diffusion in time-dependent flow visualization,10.1109/visual.2001.964494,http://dx.doi.org/10.1109/VISUAL.2001.964494,61.0,68.0,C,"The visualization of time-dependent flow is an important and challenging topic in scientific visualization. Its aim is to represent transport phenomena governed by time-dependent vector fields in an intuitively understandable way, using images and animations. Here we pick up the recently presented anisotropic diffusion method, expand and generalize it to allow a multiscale visualization of long-term, complex transport problems. Instead of streamline type patterns generated by the original method now streakline patterns are generated and advected. This process obeys a nonlinear transport diffusion equation with typically dominant transport. Starting from some noisy initial image, the diffusion actually generates and enhances patterns which are then transported in the direction of the flow field. Simultaneously the image is again sharpened in the direction orthogonal to the flow field. A careful adjustment of the models parameters is derived to balance diffusion and transport effects in a reasonable way. Properties of the method can be discussed for the continuous model, which is solved by an efficient upwind finite element discretization. As characteristic for the class of multiscale image processing methods, we can in advance select a suitable scale for representing the flow field.",David Bürkle;Tobias Preußer;Martin Rumpf,D. Burkle;T. Preusser;M. Rumpf,"Institut für Angewandte Mathematik, University of Freiburg, Freiburg im Breisgau, Germany;Fachbereich Mathematik, Duisburg University, Duisburg, Germany;Fachbereich Mathematik, Duisburg University, Duisburg, Germany",10.1109/visual.1995.480817;10.1109/visual.1994.346312;10.1109/visual.1999.809894;10.1109/visual.1997.663898;10.1109/visual.1999.809904;10.1109/visual.1997.663912;10.1109/visual.1995.480817,"flow visualization, multiscale image processing, non-linear diffusion, transport diffusion, upwind method",35.0,5.0,20.0,127.0,,,presented anisotropic diffusion;allow multiscale visualization;streamline;using images animations;fields intuitively,0.6460;0.4242;0.2729;0.2558;0.1573,"[np.int64(-1), -1, -1, -1, -1]",41;-1;-1;-1;-1,41,41
Vis,1997,Fast oriented line integral convolution for vector field visualization via the Internet,10.1109/visual.1997.663897,http://dx.doi.org/10.1109/VISUAL.1997.663897,309.0,316.0,C,"Oriented line integral convolution (OLIC) illustrates flow fields by convolving a sparse texture with an anisotropic convolution kernel. The kernel is aligned to the underlying flow of the vector field. OLIC does not only show the direction of the flow but also its orientation. The paper presents fast rendering of oriented line integral convolution (FROLIC), which is approximately two orders of magnitude faster than OLIC. Costly convolution operations as done in OLIC are replaced in FROLIC by approximating a streamlet through a set of disks with varying intensity. The issue of overlapping streamlets is discussed. Two efficient animation techniques for animating FROLIC images are described. FROLIC has been implemented as a Java applet. This allows researchers from various disciplines (typically with inhomogenous hardware environments) to conveniently explore and investigate analytically defined 2D vector fields.",Rainer Wegenkittl;M. Eduard Gröller,R. Wegenkittl;E. Groller,"Institute of Computer Graphics, University of Technology, Vienna, Austria;Institute of Computer Graphics, University of Technology, Vienna, Austria",10.1109/visual.1995.480817;10.1109/visual.1994.346313;10.1109/visual.1993.398850;10.1109/visual.1996.567784;10.1109/visual.1993.398877;10.1109/visual.1994.346312;10.1109/visual.1995.480817,,108.0,19.0,18.0,340.0,,,illustrates flow fields;sparse texture anisotropic;integral convolution;defined 2d vector;faster olic costly,0.5983;0.2640;0.2546;0.1622;0.1510,"[np.int64(-1), -1, -1, -1, -1]",240;-1;-1;-1;-1,240,240
Vis,1993,Visualization of stratospheric ozone depletion and the polar vortex,10.1109/visual.1993.398899,http://dx.doi.org/10.1109/VISUAL.1993.398899,391.0,396.0,C,"Direct analysis of spacecraft observations of stratospheric ozone yields information about the morphology of annual austral depletion. Visual correlation of ozone with other atmospheric data illustrates the diurnal dynamics of the polar vortex and contributions from the upper troposphere, including the formation and breakup of the depletion region each spring. These data require care in their presentation to minimize the introduction of visualization artifacts that are erroneously interpreted as data features. Non-geographically registered data of differing mesh structures can be visually correlated via cartographic warping of underlying geometries without interpolation. Since this approach is independent of realization technique, it provides a framework for experimenting with different visualization strategies. This methodology preserves the fidelity of the original data sets in a coordinate system suitable for three-dimensional, dynamic examination of upper atmospheric phenomena.&lt;&lt;ETX&gt;&gt;",Lloyd Treinish,L.A. Treinish,"IBM Thomas J. Watson Research Center, Yorktown Heights, NY, USA",10.1109/visual.1992.235219;10.1109/visual.1992.235219,,17.0,1.0,10.0,86.0,,,atmospheric data illustrates;visualization strategies methodology;warping underlying geometries;including;registered,0.5736;0.3792;0.3690;-0.0001;-0.0002,"[np.int64(-1), -1, -1, -1, -1]",49;-1;-1;-1;-1,49,49
Vis,2003,Visualization of steep breaking waves and thin spray sheets around a ship,10.1109/visual.2003.1250419,http://dx.doi.org/10.1109/VISUAL.2003.1250419,555.0,559.0,C,"The simulation of breaking of waves, the formation of thin spray sheets, and the entertainment of air around the next generation of naval surface combatants is an ongoing 3-year Department of Defense (DoD) Challenge Project. The goal of this project is a validated computation capability to model the full hydrodynamics around a surface combatant including all of the processes that affect mission and performance. Visualization of these large-scale simulations is paramount to understanding the complex physics involved. These simulations produce enormous data sets with both surface and volumetric qualities. Wave breaking, spray sheets, and air entertainment can be visualized using isosurfaces of scalar data. Visualization of quantities such as the vorticity field also provides insight into the dynamics of droplet and bubble formation. This paper documents the techniques used, results obtained, and lessons learned from the visualization of the hydrodynamics of naval vessels.",Paul Adams;Douglas Dommermuth,P. Adams;D. Dommermuth,"ERDC MSRC, Science Applications International Corporation, USA;ERDC MSRC, Science Applications International Corporation, USA",10.1109/visual.1999.809891;10.1109/visual.2000.885704;10.1109/visual.2002.1183821;10.1109/visual.1997.663869;10.1109/visual.1999.809891,"isosurfaces, marching cubes, multilevel parallelism",8.0,1.0,17.0,138.0,,,visualization hydrodynamics naval;isosurfaces;breaking spray sheets;learned;including,0.7435;0.2544;0.2339;0.0212;0.0134,"[np.int64(-1), -1, -1, -1, -1]",240;-1;-1;-1;-1,240,240
InfoVis,2011,Flexible Linked Axes for Multivariate Data Visualization,10.1109/tvcg.2011.201,http://dx.doi.org/10.1109/TVCG.2011.201,2310.0,2316.0,J,"Multivariate data visualization is a classic topic, for which many solutions have been proposed, each with its own strengths and weaknesses. In standard solutions the structure of the visualization is fixed, we explore how to give the user more freedom to define visualizations. Our new approach is based on the usage of Flexible Linked Axes: The user is enabled to define a visualization by drawing and linking axes on a canvas. Each axis has an associated attribute and range, which can be adapted. Links between pairs of axes are used to show data in either scatter plot- or Parallel Coordinates Plot-style. Flexible Linked Axes enable users to define a wide variety of different visualizations. These include standard methods, such as scatter plot matrices, radar charts, and PCPs [11]; less well known approaches, such as Hyperboxes [1], TimeWheels [17], and many-to-many relational parallel coordinate displays [14]; and also custom visualizations, consisting of combinations of scatter plots and PCPs. Furthermore, our method allows users to define composite visualizations that automatically support brushing and linking. We have discussed our approach with ten prospective users, who found the concept easy to understand and highly promising.",Jarry H. T. Claessen;Jarke J. van Wijk,Jarry H.T. Claessen;Jarke J. van Wijk,"Eindhoven University of Technology, Netherlands;Eindhoven University of Technology, Netherlands",10.1109/infvis.2005.1532142;10.1109/infvis.2005.1532136;10.1109/infvis.2002.1173157;10.1109/tvcg.2006.138;10.1109/tvcg.2010.205;10.1109/tvcg.2006.170;10.1109/tvcg.2007.70521;10.1109/visual.1991.175790;10.1109/tvcg.2008.153;10.1109/infvis.2005.1532142,"Multivariate data, visualization, scatterplot, Parallel Coordinates Plot",188.0,102.0,21.0,3074.0,,,multivariate data visualization;adapted links pairs;pcps 11;brushing;enabled define,0.7632;0.1239;0.1201;0.0567;0.0248,"[np.int64(-1), -1, -1, -1, -1]",184;-1;-1;-1;-1,184,184
VAST,2012,Infographics at the Congressional Budget Office,10.1109/vast.2012.6400533,http://dx.doi.org/10.1109/VAST.2012.6400533,241.0,242.0,M,"The Congressional Budget Office (CBO) is an agency of the federal government with about 240 employees that provides the U.S. Congress with timely, nonpartisan analysis of important budgetary and economic issues. Recently, CBO began producing static infographics to present its headline stories and to provide information to the Congress in different ways.",Jonathan A. Schwabish,Jonathan A. Schwabish,Congressional Budget Office,,,1.0,0.0,2.0,226.0,,,budget office cbo;producing static infographics;240;present headline;stories provide,0.8090;0.1869;0.1004;0.0898;-0.0432,"[np.int64(-1), -1, -1, -1, -1]",70;-1;-1;-1;-1,70,70
Vis,2000,Fast visualization methods for comparing dynamics: a case study in combustion,10.1109/visual.2000.885725,http://dx.doi.org/10.1109/VISUAL.2000.885725,433.0,436.0,C,"Visualization can be an important tool for displaying, categorizing and digesting large quantities of inter-related information during laboratory and simulation experiments. Summary visualizations that compare and represent data sets in the context of a collection are particularly valuable. Applicable visualizations used in these settings must be fast (near real time) and should allow the addition of data sets as they are acquired without requiring rerendering of the visualization. This paper examines several visualization techniques for representing collections of data sets in a combustion experiment including spectral displays, tiling and geometric mappings of symmetry. The application provides insight into how such visualizations might be used in practical real-time settings to assist in exploration and in conducting parameter space surveys.",Kay A. Robbins;Michael Gorman,K.A. Robbins;M. Gorman,"Department of Physics, University of Houston, Houston, TX, USA;Division of Computer Science, University of Texas, San Antonio, San Antonio, TX, USA",10.1109/visual.1999.809882;10.1109/visual.1996.568117;10.1109/visual.1995.485141;10.1109/infvis.1999.801851;10.1109/visual.1999.809882,"realtime visualization, steering, symmetry, tiling, pattern formation, movies",3.0,0.0,10.0,55.0,,,experiments summary visualizations;combustion;represent;conducting parameter space;real time settings,0.6083;0.3536;0.0940;0.0901;0.0802,"[np.int64(-1), -1, -1, -1, -1]",320;-1;-1;-1;-1,320,320
Vis,2006,Out-of-Core Remeshing of Large Polygonal Meshes,10.1109/tvcg.2006.169,http://dx.doi.org/10.1109/TVCG.2006.169,1221.0,1228.0,J,"We propose an out-of-core method for creating semi-regular surface representations from large input surface meshes. Our approach is based on a streaming implementation of the MAPS remesher of Lee et al. Our remeshing procedure consists of two stages. First, a simplification process is used to obtain the base domain. During simplification, we maintain the mapping information between the input and the simplified meshes. The second stage of remeshing uses the mapping information to produce samples of the output semi-regular mesh. The out-of-core operation of our method is enabled by the synchronous streaming of a simplified mesh and the mapping information stored at the original vertices. The synchronicity of two streaming buffers is maintained using a specially designed write strategy for each buffer. Experimental results demonstrate the remeshing performance of the proposed method, as well as other applications that use the created mapping between the simplified and the original surface representations",Minsu Ahn;Igor Guskov;Seungyong Lee 0001,Minsu Ahn;Igor Guskov;Seungyong Lee,"Pohang University of Science and Technology, South Korea;University of Michigan, USA;Pohang University of Science and Technology, South Korea",10.1109/visual.2001.964503;10.1109/visual.2003.1250408;10.1109/visual.2005.1532800;10.1109/visual.1998.745282;10.1109/visual.2001.964532;10.1109/visual.2001.964503,"Out-of-core algorithm, semi-regular remeshing, shape compression",25.0,15.0,28.0,338.0,,,streaming simplified mesh;original surface representations;remeshing procedure;base domain simplification;using specially,0.6399;0.4768;0.3118;0.2074;0.0544,"[np.int64(-1), -1, -1, -1, -1]",235;-1;-1;-1;-1,235,235
Vis,2023,Action-Evaluator: A Visualization Approach for Player Action Evaluation in Soccer,10.1109/tvcg.2023.3326524,http://dx.doi.org/10.1109/TVCG.2023.3326524,880.0,890.0,J,"In soccer, player action evaluation provides a fine-grained method to analyze player performance and plays an important role in improving winning chances in future matches. However, previous studies on action evaluation only provide a score for each action, and hardly support inspecting and comparing player actions integrated with complex match context information such as team tactics and player locations. In this work, we collaborate with soccer analysts and coaches to characterize the domain problems of evaluating player performance based on action scores. We design a tailored visualization of soccer player actions that places the action choice together with the tactic it belongs to as well as the player locations in the same view. Based on the design, we introduce a visual analytics system, Action-Evaluator, to facilitate a comprehensive player action evaluation through player navigation, action investigation, and action explanation. With the system, analysts can find players to be analyzed efficiently, learn how they performed under various match situations, and obtain valuable insights to improve their action choices. The usefulness and effectiveness of this work are demonstrated by two case studies on a real-world dataset and an expert interview.",Anqi Cao;Xiao Xie;Mingxu Zhou;Hui Zhang 0051;Mingliang Xu 0001;Yingcai Wu,Anqi Cao;Xiao Xie;Mingxu Zhou;Hui Zhang;Mingliang Xu;Yingcai Wu,"State Key Lab of CAD&CG, Zhejiang University, China;Department of Sports Science, Zhejiang University, China;State Key Lab of CAD&CG, Zhejiang University, China;Department of Sports Science, Zhejiang University, China;Ministry of Education, School of Computer and Artificial Intelligence, Zhengzhou University, Engineering Research Center of Intelligent Swarm Systems, National Supercomputing Center, Zhengzhou, China;State Key Lab of CAD&CG, Zhejiang University, China",0.1109/vast.2014.7042478;10.1109/vast.2014.7042477;10.1109/tvcg.2013.192;10.1109/tvcg.2012.263;10.1109/tvcg.2019.2934243;10.1109/tvcg.2014.2346445;10.1109/tvcg.2017.2745181;10.1109/tvcg.2022.3209352;10.1109/tvcg.2022.3209452;10.1109/tvcg.2021.3114832;10.1109/tvcg.2022.3209373;10.1109/tvcg.2018.2865041;10.1109/tvcg.2020.3030359,"Soccer Visualization,Player Evaluation,Design Study",,0.0,65.0,761.0,,,visualization soccer;evaluator;context information team;previous studies action;hardly,0.7005;0.3230;0.2520;0.1883;0.0729,"[np.int64(-1), -1, -1, -1, -1]",158;-1;-1;-1;-1,158,158
Vis,2021,A Mixed-Initiative Approach to Reusing Infographic Charts,10.1109/tvcg.2021.3114856,http://dx.doi.org/10.1109/TVCG.2021.3114856,173.0,183.0,J,"Infographic bar charts have been widely adopted for communicating numerical information because of their attractiveness and memorability. However, these infographics are often created manually with general tools, such as PowerPoint and Adobe Illustrator, and merely composed of primitive visual elements, such as text blocks and shapes. With the absence of chart models, updating or reusing these infographics requires tedious and error-prone manual edits. In this paper, we propose a mixed-initiative approach to mitigate this pain point. On one hand, machines are adopted to perform precise and trivial operations, such as mapping numerical values to shape attributes and aligning shapes. On the other hand, we rely on humans to perform subjective and creative tasks, such as changing embellishments or approving the edits made by machines. We encapsulate our technique in a PowerPoint add-in prototype and demonstrate the effectiveness by applying our technique on a diverse set of infographic bar chart examples.",Weiwei Cui;Jinpeng Wang 0001;He Huang;Yun Wang 0012;Chin-Yew Lin;Haidong Zhang;Dongmei Zhang 0001,Weiwei Cui;Jinpeng Wang;He Huang;Yun Wang;Chin-Yew Lin;Haidong Zhang;Dongmei Zhang,"Microsoft Research Asia, China;Meituan, China;Microsoft Research Asia, China;Microsoft Research Asia, China;Microsoft Research Asia, China;Microsoft Research Asia, China;Microsoft Research Asia, China",10.1109/tvcg.2015.2467732;10.1109/tvcg.2019.2934810;10.1109/tvcg.2019.2934785;10.1109/tvcg.2019.2934431;10.1109/tvcg.2016.2598620;10.1109/tvcg.2020.3030360;10.1109/tvcg.2012.229;10.1109/tvcg.2017.2744320;10.1109/tvcg.2020.3030448;10.1109/tvcg.2014.2346291;10.1109/tvcg.2018.2865158;10.1109/tvcg.2020.3030403;10.1109/tvcg.2019.2934398;10.1109/tvcg.2020.3030423;10.1109/tvcg.2015.2467732,"Infographics,Reusable templates,Graphic design,Automatic visualization",4.0,13.0,48.0,1211.0,,,infographics requires tedious;point hand machines;adopted communicating numerical;approving edits;prone,0.6464;0.2950;0.2885;0.1265;0.0137,"[np.int64(-1), -1, -1, -1, -1]",317;-1;-1;-1;-1,317,317
InfoVis,2019,An Incremental Dimensionality Reduction Method for Visualizing Streaming Multidimensional Data,10.1109/tvcg.2019.2934433,http://dx.doi.org/10.1109/TVCG.2019.2934433,418.0,428.0,J,"Dimensionality reduction (DR) methods are commonly used for analyzing and visualizing multidimensional data. However, when data is a live streaming feed, conventional DR methods cannot be directly used because of their computational complexity and inability to preserve the projected data positions at previous time points. In addition, the problem becomes even more challenging when the dynamic data records have a varying number of dimensions as often found in real-world applications. This paper presents an incremental DR solution. We enhance an existing incremental PCA method in several ways to ensure its usability for visualizing streaming multidimensional data. First, we use geometric transformation and animation methods to help preserve a viewer's mental map when visualizing the incremental results. Second, to handle data dimension variants, we use an optimization method to estimate the projected data positions, and also convey the resulting uncertainty in the visualization. We demonstrate the effectiveness of our design with two case studies using real-world datasets.",Takanori Fujiwara;Jia-Kai Chou;Shilpika;Panpan Xu;Liu Ren;Kwan-Liu Ma,Takanori Fujiwara;Jia-Kai Chou;Shilpika Shilpika;Panpan Xu;Liu Ren;Kwan-Liu Ma,"University of California, Davis;University of California, Davis;University of California, Davis;Bosch Research North America;Bosch Research North America;University of California, Davis",10.1109/tvcg.2015.2467851;10.1109/tvcg.2013.186;10.1109/tvcg.2017.2744419;10.1109/tvcg.2017.2744318;10.1109/tvcg.2015.2467553;10.1109/tvcg.2014.2346578;10.1109/tvcg.2016.2598838;10.1109/tvcg.2016.2598495;10.1109/tvcg.2014.2346574;10.1109/tvcg.2016.2598470;10.1109/tvcg.2015.2468078;10.1109/infvis.2003.1249004;10.1109/infvis.2004.60;10.1109/tvcg.2016.2598664;10.1109/tvcg.2015.2467851,"Dimensionality reduction,principal component analysis,streaming data,uncertainty,visual analytics",52.0,53.0,73.0,1832.0,,,visualizing streaming multidimensional;incremental pca method;inability preserve projected;dr methods commonly;number,0.6709;0.4963;0.1611;0.0921;0.0798,"[np.int64(-1), -1, -1, -1, -1]",301;-1;-1;-1;-1,301,301
Vis,2023,Class-Constrained t-SNE: Combining Data Features and Class Probabilities,10.1109/tvcg.2023.3326600,http://dx.doi.org/10.1109/TVCG.2023.3326600,164.0,174.0,J,"Data features and class probabilities are two main perspectives when, e.g., evaluating model results and identifying problematic items. Class probabilities represent the likelihood that each instance belongs to a particular class, which can be produced by probabilistic classifiers or even human labeling with uncertainty. Since both perspectives are multi-dimensional data, dimensionality reduction (DR) techniques are commonly used to extract informative characteristics from them. However, existing methods either focus solely on the data feature perspective or rely on class probability estimates to guide the DR process. In contrast to previous work where separate views are linked to conduct the analysis, we propose a novel approach, class-constrained t-SNE, that combines data features and class probabilities in the same DR result. Specifically, we combine them by balancing two corresponding components in a cost function to optimize the positions of data points and iconic representation of classes – class landmarks. Furthermore, an interactive user-adjustable parameter balances these two components so that users can focus on the weighted perspectives of interest and also empowers a smooth visual transition between varying perspectives to preserve the mental map. We illustrate its application potential in model evaluation and visual-interactive labeling. A comparative analysis is performed to evaluate the DR results.",Linhao Meng;Stef van den Elzen;Nicola Pezzotti;Anna Vilanova,Linhao Meng;Stef van den Elzen;Nicola Pezzotti;Anna Vilanova,"Eindhoven University of Technology, Netherlands;Eindhoven University of Technology, Netherlands;Eindhoven University of Technology, Netherlands;Eindhoven University of Technology, Netherlands",0.1109/tvcg.2014.2346660;10.1109/tvcg.2017.2744818;10.1109/tvcg.2013.212;10.1109/vast.2010.5652443;10.1109/tvcg.2012.277;10.1109/visual.1997.663916;10.1109/vast.2012.6400492;10.1109/tvcg.2016.2598445;10.1109/tvcg.2018.2864843;10.1109/tvcg.2019.2934631;10.1109/tvcg.2011.212;10.1109/tvcg.2019.2934307;10.1109/tvcg.2016.2598828;10.1109/visual.2000.885740;10.1109/vast47406.2019.8986943;10.1109/tvcg.2018.2864499,"Dimensionality reduction,t-distributed stochastic neighbor embedding,constraint integration",,2.0,60.0,714.0,,,data dimensionality reduction;model evaluation visual;classes class;commonly used extract;components cost,0.5338;0.3885;0.2913;0.0658;0.0626,"[np.int64(-1), -1, -1, -1, -1]",42;-1;-1;-1;-1,42,42
VAST,2019,VIANA: Visual Interactive Annotation of Argumentation,10.1109/vast47406.2019.8986917,http://dx.doi.org/10.1109/VAST47406.2019.8986917,11.0,22.0,C,"Argumentation Mining addresses the challenging tasks of identifying boundaries of argumentative text fragments and extracting their relationships. Fully automated solutions do not reach satisfactory accuracy due to their insufficient incorporation of semantics and domain knowledge. Therefore, experts currently rely on time-consuming manual annotations. In this paper, we present a visual analytics system that augments the manual annotation process by automatically suggesting which text fragments to annotate next. The accuracy of those suggestions is improved over time by incorporating linguistic knowledge and language modeling to learn a measure of argument similarity from user interactions. Based on a long-term collaboration with domain experts, we identify and model five high-level analysis tasks. We enable close reading and note-taking, annotation of arguments, argument reconstruction, extraction of argument relations, and exploration of argument graphs. To avoid context switches, we transition between all views through seamless morphing, visually anchoring all text- and graph-based layers. We evaluate our system with a two-stage expert user study based on a corpus of presidential debates. The results show that experts prefer our system over existing solutions due to the speedup provided by the automatic suggestions and the tight integration between text and graph views.",Fabian Sperrle;Rita Sevastjanova;Rebecca Kehlbeck;Mennatallah El-Assady,Fabian Sperrle;Rita Sevastjanova;Rebecca Kehlbeck;Mennatallah El-Assady,University of Konstanz;University of Konstanz;University of Konstanz;University of Konstanz,10.1109/vast.2012.6400485;10.1109/tvcg.2006.156;10.1109/tvcg.2019.2934654;10.1109/tvcg.2017.2745080;10.1109/tvcg.2018.2864769;10.1109/tvcg.2015.2467531;10.1109/tvcg.2007.70539;10.1109/tvcg.2008.127;10.1109/tvcg.2014.2346677;10.1109/tvcg.2015.2467759;10.1109/tvcg.2012.262;10.1109/vast.2012.6400485,"Argumentation annotation,machine learning,user interaction,layered interfaces,semantic transitions",13.0,11.0,70.0,450.0,,,argumentation mining;present visual analytics;presidential;tight integration text;speedup provided automatic,0.7305;0.2966;0.1200;0.1154;-0.0133,"[np.int64(-1), -1, -1, -1, -1]",115;-1;-1;-1;-1,115,115
InfoVis,2011,Human-Centered Approaches in Geovisualization Design: Investigating Multiple Methods Through a Long-Term Case Study,10.1109/tvcg.2011.209,http://dx.doi.org/10.1109/TVCG.2011.209,2498.0,2507.0,J,"Working with three domain specialists we investigate human-centered approaches to geovisualization following an ISO13407 taxonomy covering context of use, requirements and early stages of design. Our case study, undertaken over three years, draws attention to repeating trends: that generic approaches fail to elicit adequate requirements for geovis application design; that the use of real data is key to understanding needs and possibilities; that trust and knowledge must be built and developed with collaborators. These processes take time but modified human-centred approaches can be effective. A scenario developed through contextual inquiry but supplemented with domain data and graphics is useful to geovis designers. Wireframe, paper and digital prototypes enable successful communication between specialist and geovis domains when incorporating real and interesting data, prompting exploratory behaviour and eliciting previously unconsidered requirements. Paper prototypes are particularly successful at eliciting suggestions, especially for novel visualization. Enabling specialists to explore their data freely with a digital prototype is as effective as using a structured task protocol and is easier to administer. Autoethnography has potential for framing the design process. We conclude that a common understanding of context of use, domain data and visualization possibilities are essential to successful geovis design and develop as this progresses. HC approaches can make a significant contribution here. However, modified approaches, applied with flexibility, are most promising. We advise early, collaborative engagement with data - through simple, transient visual artefacts supported by data sketches and existing designs - before moving to successively more sophisticated data wireframes and data prototypes.",David Lloyd 0002;Jason Dykes,David Lloyd;Jason Dykes,"GiCentre, City University London, UK;GiCentre, City University London, UK",10.1109/tvcg.2010.191;10.1109/tvcg.2009.174;10.1109/tvcg.2010.191,"Evaluation, geovisualization, context of use, requirements, field study, prototypes, sketching, design",138.0,86.0,70.0,2086.0,,,geovis design;early collaborative engagement;data key understanding;domains incorporating real;time modified human,0.6935;0.2765;0.1539;0.1144;0.0565,"[np.int64(-1), -1, -1, -1, -1]",83;-1;-1;-1;-1,83,83
InfoVis,2018,NLIZE: A Perturbation-Driven Visual Interrogation Tool for Analyzing and Interpreting Natural Language Inference Models,10.1109/tvcg.2018.2865230,http://dx.doi.org/10.1109/TVCG.2018.2865230,651.0,660.0,J,"With the recent advances in deep learning, neural network models have obtained state-of-the-art performances for many linguistic tasks in natural language processing. However, this rapid progress also brings enormous challenges. The opaque nature of a neural network model leads to hard-to-debug-systems and difficult-to-interpret mechanisms. Here, we introduce a visualization system that, through a tight yet flexible integration between visualization elements and the underlying model, allows a user to interrogate the model by perturbing the input, internal state, and prediction while observing changes in other parts of the pipeline. We use the natural language inference problem as an example to illustrate how a perturbation-driven paradigm can help domain experts assess the potential limitation of a model, probe its inner states, and interpret and form hypotheses about fundamental model mechanisms such as attention.",Shusen Liu 0001;Zhimin Li;Tao Li 0039;Vivek Srikumar;Valerio Pascucci;Peer-Timo Bremer,Shusen Liu;Zhimin Li;Tao Li;Vivek Srikumar;Valerio Pascucci;Peer-Timo Bremer,"Lawrence Livermore National Laboratory;SCI Institute, University of Utah;School of Computing, University of Utah;School of Computing, University of Utah;SCI Institute, University of Utah;Lawrence Livermore National Laboratory",10.1109/tvcg.2017.2744683;10.1109/tvcg.2017.2744718;10.1109/tvcg.2017.2744938;10.1109/tvcg.2016.2598831;10.1109/tvcg.2017.2745141;10.1109/tvcg.2017.2744358;10.1109/tvcg.2017.2744158;10.1109/visual.2005.1532820;10.1109/tvcg.2017.2744878;10.1109/tvcg.2017.2744683,"Natural Language Processing,Interpretable Machine Learning,Natural Language Inference,Attention Visualization",33.0,34.0,40.0,1297.0,,,model mechanisms attention;flexible integration visualization;leads hard debug;enormous;allows user,0.5223;0.2912;0.1939;0.1379;0.0224,"[np.int64(-1), -1, -1, -1, -1]",213;-1;-1;-1;-1,213,213
InfoVis,2011,Visual Thinking In Action: Visualizations As Used On Whiteboards,10.1109/tvcg.2011.251,http://dx.doi.org/10.1109/TVCG.2011.251,2508.0,2517.0,J,"While it is still most common for information visualization researchers to develop new visualizations from a data-or taskdriven perspective, there is growing interest in understanding the types of visualizations people create by themselves for personal use. As part of this recent direction, we have studied a large collection of whiteboards in a research institution, where people make active use of combinations of words, diagrams and various types of visuals to help them further their thought processes. Our goal is to arrive at a better understanding of the nature of visuals that are created spontaneously during brainstorming, thinking, communicating, and general problem solving on whiteboards. We use the qualitative approaches of open coding, interviewing, and affinity diagramming to explore the use of recognizable and novel visuals, and the interplay between visualization and diagrammatic elements with words, numbers and labels. We discuss the potential implications of our findings on information visualization design.",Jagoda Walny;Sheelagh Carpendale;Nathalie Henry Riche;Gina Venolia;Philip Fawcett,Jagoda Walny;Sheelagh Carpendale;Nathalie Henry Riche;Gina Venolia;Philip Fawcett,"University of Calgary, Canada;University of Calgary and Microsoft Research, Canada;Microsoft Research Limited, UK;Microsoft Research Limited, UK;Microsoft Research and University of Washington, USA",10.1109/tvcg.2010.144;10.1109/tvcg.2010.179;10.1109/tvcg.2006.156;10.1109/tvcg.2007.70535;10.1109/tvcg.2008.155;10.1109/infvis.2004.10;10.1109/infvis.2002.1173148;10.1109/visual.1991.175815;10.1109/tvcg.2010.164;10.1109/tvcg.2010.144,"Visualization, diagrams, whiteboards, observational study",89.0,60.0,51.0,1497.0,,,visualization researchers develop;whiteboards;potential implications;create personal use;help thought,0.6716;0.4567;0.1847;0.1324;0.1185,"[np.int64(-1), -1, -1, -1, -1]",209;-1;-1;-1;-1,209,209
InfoVis,2012,Design Study Methodology: Reflections from the Trenches and the Stacks,10.1109/tvcg.2012.213,http://dx.doi.org/10.1109/TVCG.2012.213,2431.0,2440.0,J,"Design studies are an increasingly popular form of problem-driven visualization research, yet there is little guidance available about how to do them effectively. In this paper we reflect on our combined experience of conducting twenty-one design studies, as well as reading and reviewing many more, and on an extensive literature review of other field work methods and methodologies. Based on this foundation we provide definitions, propose a methodological framework, and provide practical guidance for conducting design studies. We define a design study as a project in which visualization researchers analyze a specific real-world problem faced by domain experts, design a visualization system that supports solving this problem, validate the design, and reflect about lessons learned in order to refine visualization design guidelines. We characterize two axes - a task clarity axis from fuzzy to crisp and an information location axis from the domain expert's head to the computer - and use these axes to reason about design study contributions, their suitability, and uniqueness from other approaches. The proposed methodological framework consists of 9 stages: learn, winnow, cast, discover, design, implement, deploy, reflect, and write. For each stage we provide practical guidance and outline potential pitfalls. We also conducted an extensive literature survey of related methodological approaches that involve a significant amount of qualitative field work, and compare design study methodology to that of ethnography, grounded theory, and action research.",Michael Sedlmair;Miriah D. Meyer;Tamara Munzner,Michael Sedlmair;Miriah Meyer;Tamara Munzner,"University of British, Colombia;University of Utah, USA;University of British, Colombia",10.1109/infvis.1999.801869;10.1109/infvis.1996.559226;10.1109/tvcg.2008.117;10.1109/tvcg.2009.152;10.1109/tvcg.2010.206;10.1109/infvis.2005.1532136;10.1109/tvcg.2010.193;10.1109/vast.2011.6102443;10.1109/tvcg.2011.174;10.1109/vast.2007.4389008;10.1109/tvcg.2009.116;10.1109/tvcg.2011.192;10.1109/tvcg.2009.128;10.1109/infvis.2003.1249023;10.1109/tvcg.2009.167;10.1109/tvcg.2009.111;10.1109/tvcg.2011.209;10.1109/tvcg.2010.137;10.1109/infvis.1999.801869,"Design study, methodology, visualization, framework",828.0,513.0,95.0,11892.0,HM,,visualization researchers analyze;guidance conducting design;lessons learned;world;order refine,0.7232;0.1440;0.1291;0.0342;0.0310,"[np.int64(-1), -1, -1, -1, -1]",209;-1;-1;-1;-1,209,209
Vis,2011,Evaluation of Trend Localization with Multi-Variate Visualizations,10.1109/tvcg.2011.194,http://dx.doi.org/10.1109/TVCG.2011.194,2053.0,2062.0,J,"Multi-valued data sets are increasingly common, with the number of dimensions growing. A number of multi-variate visualization techniques have been presented to display such data. However, evaluating the utility of such techniques for general data sets remains difficult. Thus most techniques are studied on only one data set. Another criticism that could be levied against previous evaluations of multi-variate visualizations is that the task doesn't require the presence of multiple variables. At the same time, the taxonomy of tasks that users may perform visually is extensive. We designed a task, trend localization, that required comparison of multiple data values in a multi-variate visualization. We then conducted a user study with this task, evaluating five multivariate visualization techniques from the literature (Brush Strokes, Data-Driven Spots, Oriented Slivers, Color Blending, Dimensional Stacking) and juxtaposed grayscale maps. We report the results and discuss the implications for both the techniques and the task.",Mark A. Livingston;Jonathan W. Decker,Mark Livingston;Jonathan Decker,"Naval Research Laboratory, USA;Naval Research Laboratory, USA",10.1109/tvcg.2009.126;10.1109/visual.1998.745292;10.1109/visual.1990.146387;10.1109/visual.1990.146386;10.1109/tvcg.2007.70623;10.1109/visual.1991.175795;10.1109/visual.1999.809905;10.1109/visual.2003.1250362;10.1109/visual.1998.745294;10.1109/visual.2003.1250362,"User study, multi-variate visualization, visual task design, visual analytics",28.0,12.0,25.0,640.0,,,multi variate visualizations;increasingly common number;time taxonomy tasks;brush;localization,0.7657;0.1843;0.1511;0.1231;0.0487,"[np.int64(-1), -1, -1, -1, -1]",185;-1;-1;-1;-1,185,185
Vis,1990,A three-dimensional/stereoscopic display and model control system for Great Lakes forecasts,10.1109/visual.1990.146382,http://dx.doi.org/10.1109/VISUAL.1990.146382,194.0,,C,"A forecasting system for the Great Lakes in which the data generated by a three-dimensional numerical model is visualized by a 3-D/stereoscopic display module is discussed. The module consists of a control panel and a display window with the capability of interactively rendering the results. The event scheduling for scenario testing to steer the 3-D numerical model is achieved by a similar panel. These panels set up the simulation and control the data flow between the graphics workstation and supercomputer. Rendering methods, stereo imagery, and animation are incorporated to display the results. Interaction between the user, the workstation, and the supercomputer allows steering of the simulation and tracing of the simulation output. Distributed software for postprocessing and volume rendering are used to enhance the representation.&lt;&lt;ETX&gt;&gt;",Chieh-Cheng Yen;Keith W. Bedford;Jill Kempf;Robert E. Marshall,C.-C.J. Yen;K.W. Bedford;J.L. Kempf;R.E. Marshall,"Department of Civil Engineering, Ohio State Uinversity, USA;Department of Civil Engineering, Ohio State Uinversity, USA;The Ohio Supercomputer Graphics Project, Ohio Supercomputing Center;The Ohio Supercomputer Graphics Project, Ohio Supercomputing Center",,,11.0,4.0,12.0,54.0,,,forecasting great lakes;stereo imagery animation;simulation output;dimensional numerical;interaction user workstation,0.5932;0.3467;0.2987;0.2681;0.2321,"[np.int64(-1), -1, -1, -1, -1]",282;-1;-1;-1;-1,282,282
Vis,2000,Simplification of surface annotations,10.1109/visual.2000.885700,http://dx.doi.org/10.1109/VISUAL.2000.885700,235.0,242.0,C,"Geometric models are often annotated to provide additional information during visualization. Maps may be marked with rivers, roads or topographical information, and CAD data models may highlight the underlying mesh structure. While this additional information may be extremely useful, there is a rendering cost associated with it. Texture maps have often been used to convey this information at relatively low cost, but they suffer from blurring and pixelization at high magnification. We present a technique for simplifying surface annotations based on directed, asymmetric tolerance. By maintaining the annotations as geometry, as opposed to textures, we are able to simplify them while still maintaining the overall appearance of the model over a wide range of magnifications. Texture maps may still be used to provide low-resolution surface detail, such as color. We demonstrate a significant gain in rendering performance while retaining the original appearance of objects from many application domains.",Frank Suits;James T. Klosowski;William P. Horn;Gérard Lecina,F. Suits;J.T. Klosowski;W.P. Horn;G. Lecina,"IBM Thomas J. Watson Research Center, USA;IBM Thomas J. Watson Research Center, USA;Dassault Systèmes;IBM Thomas J. Watson Research Center, USA",10.1109/visual.1998.745285;10.1109/visual.1998.745285,"simplification, polygonal path, mesh, CAD/CAM,FEM, cartography",5.0,0.0,15.0,52.0,,,simplifying surface annotations;range magnifications texture;rendering performance retaining;application domains;opposed,0.5971;0.3623;0.3168;0.1101;-0.0024,"[np.int64(-1), -1, -1, -1, -1]",242;-1;-1;-1;-1,242,242
Vis,1994,Visualizing flow with quaternion frames,10.1109/visual.1994.346330,http://dx.doi.org/10.1109/VISUAL.1994.346330,108.0,,C,"Flow fields, geodesics, and deformed volumes are natural sources of families of space curves that can be characterized by intrinsic geometric properties such as curvature, torsion, and Frenet frames. By expressing a curve's moving Frenet coordinate frame as an equivalent unit quaternion, we reduce the number of components that must be displayed from nine with six constraints to four with one constraint. We can then assign a color to each curve point by dotting its quaternion frame with a 4D light vector, or we can plot the frame values separately as a curve in the three-sphere. As examples, we examine twisted volumes used in topology to construct knots and tangles, a spherical volume deformation known as the Dirac string trick, and streamlines of 3D vector flow fields.&lt;&lt;ETX&gt;&gt;",Andrew J. Hanson;Hui Ma,A.J. Hanson;Hui Ma,"Department of Computer Science, Indiana University, Bloomington, IN, USA;Department of Computer Science, Indiana University, Bloomington, IN, USA",10.1109/visual.1993.398869;10.1109/visual.1994.346324;10.1109/visual.1992.235211;10.1109/visual.1991.175821;10.1109/visual.1993.398869,,35.0,10.0,15.0,185.0,,,tangles spherical;4d light vector;curve moving frenet;known dirac;frame values separately,0.5487;0.3769;0.3366;0.1177;0.1168,"[np.int64(-1), -1, -1, -1, -1]",284;-1;-1;-1;-1,284,284
InfoVis,2019,SmartCube: An Adaptive Data Management Architecture for the Real-Time Visualization of Spatiotemporal Datasets,10.1109/tvcg.2019.2934434,http://dx.doi.org/10.1109/TVCG.2019.2934434,790.0,799.0,J,"Interactive visualization and exploration of large spatiotemporal data sets is difficult without carefully-designed data pre-processing and management tools. We propose a novel architecture for spatiotemporal data management. The architecture can dynamically update itself based on user queries. Datasets is stored in a tree-like structure to support memory sharing among cuboids in a logical structure of data cubes. An update mechanism is designed to create or remove cuboids on it, according to the analysis of the user queries, with the consideration of memory size limitation. Data structure is dynamically optimized according to different user queries. During a query process, user queries are recorded to predict the performance increment of the new cuboid. The creation or deletion of a cuboid is determined by performance increment. Experiment results show that our prototype system deliveries good performance towards user queries on different spatiotemporal datasets, which costing small memory size with comparable performance compared with other state-of-the-art algorithms.",Can Liu 0004;Cong Wu 0004;Hanning Shao;Xiaoru Yuan,Can Liu;Cong Wu;Hanning Shao;Xiaoru Yuan,"Key Laboratory of Machine Perception (Ministry of Education), School of EECS, Peking University;Key Laboratory of Machine Perception (Ministry of Education), School of EECS, Peking University;Key Laboratory of Machine Perception (Ministry of Education), School of EECS, Peking University;Key Laboratory of Machine Perception (Ministry of Education), School of EECS, Peking University and National Engineering Laboratory for Big Data Analysis and Application, Peking University",10.1109/tvcg.2014.2346418;10.1109/tvcg.2013.179;10.1109/tvcg.2014.2346452;10.1109/tvcg.2009.191;10.1109/tvcg.2016.2598624;10.1109/tvcg.2014.2346574;10.1109/infvis.2000.885086;10.1109/infvis.2002.1173141;10.1109/tvcg.2016.2598694;10.1109/tvcg.2017.2744059;10.1109/tvcg.2014.2346418,"data management,spatial-temporal data",17.0,7.0,36.0,1404.0,,,spatiotemporal data management;cuboid creation deletion;costing small memory;process user;different,0.7660;0.2102;0.1686;0.0656;-0.0161,"[np.int64(-1), -1, -1, -1, -1]",279;-1;-1;-1;-1,279,279
Vis,2005,Visualizing the tightening of knots,10.1109/visual.2005.1532844,http://dx.doi.org/10.1109/VISUAL.2005.1532844,575.0,582.0,C,"The study of physical models for knots has recently received much interest in the mathematics community. In this paper, we consider the ropelength model, which considers knots tied in an idealized rope. This model is interesting in pure mathematics, and has been applied to the study of a variety of problems in the natural sciences as well. Modeling and visualizing the tightening of knots in this idealized rope poses some interesting challenges in computer graphics. In particular, self-contact in a deformable rope model is a difficult problem which cannot be handled by standard techniques. In this paper, we describe a solution based on reformulating the contact problem and using constrained-gradient techniques from nonlinear optimization. The resulting animations reveal new properties of the tightening flow and provide new insights into the geometric structure of tight knots and links.",Jason Cantarella;Michael Piatek;Eric J. Rawdon,J. Cantarella;M. Piatek;E. Rawdon,"University of Georgia, USA;University of Washington, USA;Duquesne University",,"collision detection, contact, flexible models, tight knots, ideal knots, ropelength, nonlinear optimization, constrained least squares",22.0,3.0,41.0,131.0,,,deformable rope model;gradient techniques;graphics particular self;contact problem using;study,0.7386;0.3124;0.1310;0.0567;0.0067,"[np.int64(-1), -1, -1, -1, -1]",33;-1;-1;-1;-1,33,33
Vis,1995,Interval volume: a solid fitting technique for volumetric data display and analysis,10.1109/visual.1995.480807,http://dx.doi.org/10.1109/VISUAL.1995.480807,151.0,,C,"Proposes as a generalization of isosurfaces, the 'interval volume', which is a new type of geometric model representing 3D subvolumes with field values belonging to a closed interval. A dominant surface fitting algorithm called 'marching cubes' is extended to obtain a solid fitting algorithm, which extracts from a given volumetric dataset a high-resolution polyhedral solid data structure of the interval volume. Rendering methods for the interval volume and principal related operations are also presented. The effectiveness of this approach is illustrated with 4D simulated data from atomic collision research.",Issei Fujishiro;Yuji Maeda;Hiroshi Sato,I. Fujishiro;Y. Maeda;H. Sato,"Department of Information Sciences, Ochanomizu University, Tokyo, Japan;Doctoral Program in Engineering, University of Tsukuba, Baraki, Japan;Department of Information Sciences, Ochanomizu University, Tokyo, Japan",10.1109/visual.1991.175782;10.1109/visual.1992.235223;10.1109/visual.1994.346308;10.1109/visual.1991.175782,"Volume visualization, surface fitting, isosurface, Marching cubes, atomic collision",55.0,20.0,17.0,105.0,,,marching cubes;atomic collision research;volume new type;dataset;values belonging closed,0.5925;0.3235;0.2303;0.1013;0.0940,"[np.int64(-1), -1, -1, -1, -1]",286;-1;-1;-1;-1,286,286
InfoVis,2012,Organizing Search Results with a Reference Map,10.1109/tvcg.2012.250,http://dx.doi.org/10.1109/TVCG.2012.250,2546.0,2555.0,J,"We propose a method to highlight query hits in hierarchically clustered collections of interrelated items such as digital libraries or knowledge bases. The method is based on the idea that organizing search results similarly to their arrangement on a fixed reference map facilitates orientation and assessment by preserving a user's mental map. Here, the reference map is built from an MDS layout of the items in a Voronoi treemap representing their hierarchical clustering, and we use techniques from dynamic graph layout to align query results with the map. The approach is illustrated on an archive of newspaper articles.",Arlind Nocaj;Ulrik Brandes,Arlind Nocaj;Ulrik Brandes,University of Konstanz;University of Konstanz,10.1109/infvis.2005.1532128;10.1109/infvis.1997.636718;10.1109/tvcg.2006.147;10.1109/tvcg.2010.154;10.1109/tvcg.2009.176;10.1109/infvis.2005.1532128,"Search results, mental map, voronoi treemaps, dynamic graph layout, multidimensional scaling, edge bundling",40.0,20.0,46.0,773.0,,,organizing search;graph layout align;voronoi;fixed reference map;mds,0.5573;0.2673;0.2169;0.2078;0.1212,"[np.int64(-1), -1, -1, -1, -1]",243;-1;-1;-1;-1,243,243
Vis,2024,Visual Analysis of Multi-Outcome Causal Graphs,10.1109/tvcg.2024.3456346,http://dx.doi.org/10.1109/TVCG.2024.3456346,656.0,666.0,J,"We introduce a visual analysis method for multiple causal graphs with different outcome variables, namely, multi-outcome causal graphs. Multi-outcome causal graphs are important in healthcare for understanding multimorbidity and comorbidity. To support the visual analysis, we collaborated with medical experts to devise two comparative visualization techniques at different stages of the analysis process. First, a progressive visualization method is proposed for comparing multiple state-of-the-art causal discovery algorithms. The method can handle mixed-type datasets comprising both continuous and categorical variables and assist in the creation of a fine-tuned causal graph of a single o utcome. Second, a comparative graph layout technique and specialized visual encodings are devised for the quick comparison of multiple causal graphs. In our visual analysis approach, analysts start by building individual causal graphs for each outcome variable, and then, multi-outcome causal graphs are generated and visualized with our comparative technique for analyzing differences and commonalities of these causal graphs. Evaluation includes quantitative measurements on benchmark datasets, a case study with a medical expert, and expert user studies with real-world health research data.",Mengjie Fan;Jinlu Yu;Daniel Weiskopf;Nan Cao 0001;Huai-Yu Wang;Liang Zhou 0001,Mengjie Fan;Jinlu Yu;Daniel Weiskopf;Nan Cao;Huai-Yu Wang;Liang Zhou,"Institute of Medical Technology, Peking University Health Science Center, and the National Institute of Health Data Science (NIHDS), Peking University, China;Chalmers University of Technology and NIHDS, Peking University, China;Visualization Research Center (VISUS), University of Stuttgart, Germany;iDVx Lab, Tongji University, China;National Institute of Traditional Chinese Medicine Constitution and Preventive Treatment of Diseases, Beijing University of Chinese Medicine, China;NIHDS, Peking University, China",10.1109/tvcg.2015.2467618;10.1109/tvcg.2008.117;10.1109/tvcg.2021.3114875;10.1109/tvcg.2022.3209484;10.1109/tvcg.2017.2744199;10.1109/tvcg.2020.3030465;10.1109/tvcg.2021.3114779;10.1109/tvcg.2023.3327376;10.1109/tvcg.2009.111;10.1109/tvcg.2012.213;10.1109/tvcg.2012.237;10.1109/tvcg.2015.2467931;10.1109/vast.2017.8585647;10.1109/tvcg.2020.3028957,"Causal graph visualization and visual analysis,causal discovery,,,comparative visualization,visual analysis in medicine",,0.0,70.0,247.0,,,causal graphs visual;multimorbidity comorbidity;expert expert user;quantitative measurements benchmark;encodings,0.7562;0.4301;0.1700;0.1377;0.0324,"[np.int64(-1), -1, -1, -1, -1]",160;-1;-1;-1;-1,160,160
Vis,1997,Singularities in nonuniform tensor fields,10.1109/visual.1997.663857,http://dx.doi.org/10.1109/VISUAL.1997.663857,59.0,66.0,C,"Studies the topology of 2nd-order symmetric tensor fields. Degenerate points are basic constituents of tensor fields. From the set of degenerate points, an experienced researcher can reconstruct a whole tensor field. We address the conditions for the existence of degenerate points and, based on these conditions, we predict the distribution of degenerate points inside the field. Every tensor can be decomposed into a deviator and an isotropic tensor. A deviator determines the properties of a tensor field, while the isotropic part provides a uniform bias. Deviators can be 3D or locally 2D. The triple-degenerate points of a tensor field are associated with the singular points of its deviator and the double-degenerate points of a tensor field have singular local 2D deviators. This provides insights into the similarity of topological structure between 1st-order (or vectors) and 2nd-order tensors. Control functions are in charge of the occurrences of a singularity of a deviator. These singularities can further be linked to important physical properties of the underlying physical phenomena. For a deformation tensor in a stationary flow, the singularities of its deviator actually represent the area of the vortex core in the field; for a stress tensor, the singularities represent the area with no stress; for a Newtonian flow, compressible flow and incompressible flow as well as stress and deformation tensors share similar topological features due to the similarity of their deviators; for a viscous flow, removing the large, isotropic pressure contribution dramatically enhances the anisotropy due to viscosity.",Yingmei Lavin;Yuval Levy;Lambertus Hesselink,Yingmei Lavin;Y. Levy;L. Hesselink,"Department of Physics, University of Stanford, Stanford, CA, USA;Faculty of Aerospace Engineering, Technion-Israel Institute of Technology, Haifa, Israel;Department of Electrical Engineering, University of Stanford, Stanford, CA, USA",10.1109/visual.1992.235193;10.1109/visual.1992.235193,,38.0,6.0,12.0,97.0,,,tensor fields;incompressible flow stress;set degenerate points;topological structure 1st;predict distribution,0.6430;0.3374;0.2772;0.2391;0.0907,"[np.int64(-1), -1, -1, -1, -1]",17;-1;-1;-1;-1,17,17
InfoVis,2004,An Evaluation of Microarray Visualization Tools for Biological Insight,10.1109/infvis.2004.5,http://dx.doi.org/10.1109/INFVIS.2004.5,1.0,8.0,C,"High-throughput experiments such as gene expression microarrays in the life sciences result in large datasets. In response, a wide variety of visualization tools have been created to facilitate data analysis. Biologists often face a dilemma in choosing the best tool for their situation. The tool that works best for one biologist may not work well for another due to differences in the type of insight they seek from their data. A primary purpose of a visualization tool is to provide domain-relevant insight into the data. Ideally, any user wants maximum information in the least possible time. In this paper we identify several distinct characteristics of insight that enable us to recognize and quantify it. Based on this, we empirically evaluate five popular microarray visualization tools. Our conclusions can guide biologists in selecting the best tool for their data, and computer scientists in developing and evaluating visualizations",Purvi Saraiya;Chris North 0001;Karen Duca,P. Saraiya;C. North;K. Duca,"Department of Computer Science, Virginia Polytechnic Institute and State University, Blacksburg, VA, USA;Department of Computer Science, Virginia Polytechnic Institute and State University, Blacksburg, VA, USA;Virginia Bioinformatics Institute, Virginia Polytechnic Institute and State University, Blacksburg, VA, USA",10.1109/infvis.2001.963289;10.1109/infvis.2001.963289,"Data visualization, empirical evaluation, insight, high throughput experiments, microarray data, bioinformatics",164.0,44.0,31.0,727.0,,,microarray visualization tools;biologists face dilemma;empirically evaluate popular;data primary purpose;possible time,0.7697;0.2498;0.2211;0.1967;-0.0701,"[np.int64(-1), -1, -1, -1, -1]",116;-1;-1;-1;-1,116,116
InfoVis,2003,Exploring high-D spaces with multiform matrices and small multiples,10.1109/infvis.2003.1249006,http://dx.doi.org/10.1109/INFVIS.2003.1249006,31.0,38.0,C,"We introduce an approach to visual analysis of multivariate data that integrates several methods from information visualization, exploratory data analysis (EDA), and geovisualization. The approach leverages the component-based architecture implemented in GeoVISTA Studio to construct a flexible, multiview, tightly (but generically) coordinated, EDA toolkit. This toolkit builds upon traditional ideas behind both small multiples and scatterplot matrices in three fundamental ways. First, we develop a general, multiform, bivariate matrix and a complementary multiform, bivariate small multiple plot in which different bivariate representation forms can be used in combination. We demonstrate the flexibility of this approach with matrices and small multiples that depict multivariate data through combinations of: scatterplots, bivariate maps, and space-filling displays. Second, we apply a measure of conditional entropy to (a) identify variables from a high-dimensional data set that are likely to display interesting relationships and (b) generate a default order of these variables in the matrix or small multiple display. Third, we add conditioning, a kind of dynamic query/filtering in which supplementary (undisplayed) variables are used to constrain the view onto variables that are displayed. Conditioning allows the effects of one or more well understood variables to be removed form the analysis, making relationships among remaining variables easier to explore. We illustrate the individual and combined functionality enabled by this approach through application to analysis of cancer diagnosis and mortality data and their associated covariates and risk factors.",Alan M. MacEachren;Xiping Dai;Frank Hardisty;Diansheng Guo;Eugene Lengerich,A. MacEachren;D. Xiping;F. Hardisty;Diansheng Guo;G. Lengerich,"Department of Geography, The Pennsylvania State University, University Park, PA, USA;Dept. of Geogr., Pennsylvania State Univ., University Park, VA, USA;Department of Geography, The Pennsylvania State University, University Park, PA, USA;Department of Geography, The Pennsylvania State University, University Park, PA, USA;Department of Health Evaluation Sciences, The Pennsylvania State University, Hershey, PA, USA",10.1109/visual.1991.175815;10.1109/infvis.1998.729559,"geovisualization, EDA, scatterplot matrix,bivariate map, space-filling visualization, conditional entropy, small multiples, conditioning, GeoVISTA Studio ",130.0,32.0,49.0,532.0,,,visualization exploratory data;covariates risk factors;conditional entropy;matrices small multiples;second apply,0.7045;0.2492;0.1745;0.0914;0.0386,"[np.int64(-1), -1, -1, -1, -1]",202;-1;-1;-1;-1,202,202
Vis,2003,Psychophysical scaling of a cardiovascular information display,10.1109/visual.2003.1250352,http://dx.doi.org/10.1109/VISUAL.2003.1250352,35.0,42.0,C,"A new method was developed to increase the saliency of changing variables in a cardiovascular visualization for use by anesthesiologists in the operating room (OR). Clinically meaningful changes in patient physiology were identified and then mapped to the inherent psychophysical properties of the visualization. A long history of psychophysical research has provided an understanding of the parameters within which the human information processing system is able to detect changes in the size, shape and color of visual objects (Gescheider, 1976, Spence, 1990, and Baird, 1970). These detection thresholds are known as just noticeable differences (JNDs) which characterize the amount of change in an object's attribute that is recognizable 50% of the time. A prototype version of the display has been demonstrated to facilitate anesthesiologist's performance while reducing cognitive workload during simulated cardiac events (Agutter et al., 2002). In order to further improve the utility of the new cardiovascular visualization, the clinically relevant changes in cardiovascular variables are mapped to noticeable perceptual changes in the representational elements of the display. The results of the method described in this paper are used to merge information from the psychophysical properties of the cardiovascular visualization, with clinically relevant changes in the patient's cardiovascular physiology as measured by the clinical meaningfulness questionnaire. The result of this combination will create a visualization that is sensitive to changes in the cardiovascular health of the patient and communicates this information to the user in a meaningful, salient and intuitive manner.",Robert Albert;Noah Syroid;Yinqi Zhang;James Agutter;Frank Drews;David L. Strayer;George Hutchinson;Dwayne R. Westenskow,R. Albert;N. Syroid;Y. Zhang;J. Agutter;F. Drews;D. Strayer;G. Hutchinson;D. Westenskow,"Medvis-Applied Medical Visualizations Limited Liability Company, West Valley, UT, USA;Medvis-Applied Medical Visualizations Limited Liability Company, West Valley, UT, USA;Department of Anesthesiology, University of Utah, USA;Medvis-Applied Medical Visualizations Limited Liability Company, West Valley, UT, USA;Department of Psychology, University of Utah, USA;Department of Psychology, University of Utah, USA;General Electric Medical Systems, Milwaukee, WI, USA;Department of Anesthesiology, University of Utah, USA",10.1109/infvis.2001.963295;10.1109/infvis.2001.963295,"Psychophysical Scaling, Anesthesia, Patient Vital Sign Monitor",6.0,1.0,20.0,98.0,,,visualization use anesthesiologists;saliency changing;differences jnds characterize;meaningful;performance reducing,0.6947;0.3749;0.2134;0.1998;0.1445,"[np.int64(-1), -1, -1, -1, -1]",180;-1;-1;-1;-1,180,180
Vis,2021,Causal Support: Modeling Causal Inferences with Visualizations,10.1109/tvcg.2021.3114824,http://dx.doi.org/10.1109/TVCG.2021.3114824,1150.0,1160.0,J,"Analysts often make visual causal inferences about possible data-generating models. However, visual analytics (VA) software tends to leave these models implicit in the mind of the analyst, which casts doubt on the statistical validity of informal visual “insights”. We formally evaluate the quality of causal inferences from visualizations by adopting <i>causal support</i>—a Bayesian cognition model that learns the probability of alternative causal explanations given some data—as a normative benchmark for causal inferences. We contribute two experiments assessing how well crowdworkers can detect (1) a treatment effect and (2) a confounding relationship. We find that chart users' causal inferences tend to be insensitive to sample size such that they deviate from our normative benchmark. While interactively cross-filtering data in visualizations can improve sensitivity, on average users do not perform reliably better with common visualizations than they do with textual contingency tables. These experiments demonstrate the utility of causal support as an evaluation framework for inferences in VA and point to opportunities to make analysts' mental models more explicit in VA software.",Alex Kale;Yifan Wu 0005;Jessica Hullman,Alex Kale;Yifan Wu;Jessica Hullman,"University of Washington, USA;University of California at Berkeley, USA;Northwestern University, USA",10.1109/infvis.2003.1249025;10.1109/tvcg.2019.2934287;10.1109/tvcg.2020.3030465;10.1109/tvcg.2007.70528;10.1109/tvcg.2020.3030335;10.1109/tvcg.2015.2467758;10.1109/infvis.2000.885086;10.1109/tvcg.2015.2467931;10.1109/vast.2017.8585647;10.1109/tvcg.2020.3028957;10.1109/infvis.2003.1249025,"Causal inference,visualization,contingency tables,data cognition",5.0,14.0,61.0,1231.0,HM,,causal inferences visualizations;analyst casts doubt;assessing crowdworkers;common;explicit va software,0.7212;0.3288;0.3222;0.1011;0.0795,"[np.int64(-1), -1, -1, -1, -1]",160;-1;-1;-1;-1,160,160
InfoVis,2020,Staged Animation Strategies for Online Dynamic Networks,10.1109/tvcg.2020.3030385,http://dx.doi.org/10.1109/TVCG.2020.3030385,539.0,549.0,J,"Dynamic networks-networks that change over time-can be categorized into two types: offline dynamic networks, where all states of the network are known, and online dynamic networks, where only the past states of the network are known. Research on staging animated transitions in dynamic networks has focused more on offline data, where rendering strategies can take into account past and future states of the network. Rendering online dynamic networks is a more challenging problem since it requires a balance between timeliness for monitoring tasks-so that the animations do not lag too far behind the events-and clarity for comprehension tasks-to minimize simultaneous changes that may be difficult to follow. To illustrate the challenges placed by these requirements, we explore three strategies to stage animations for online dynamic networks: time-based, event-based, and a new hybrid approach that we introduce by combining the advantages of the first two. We illustrate the advantages and disadvantages of each strategy in representing low- and high-throughput data and conduct a user study involving monitoring and comprehension of dynamic networks. We also conduct a follow-up, think-aloud study combining monitoring and comprehension with experts in dynamic network visualization. Our findings show that animation staging strategies that emphasize comprehension do better for participant response times and accuracy. However, the notion of “comprehension” is not always clear when it comes to complex changes in highly dynamic networks, requiring some iteration in staging that the hybrid approach affords. Based on our results, we make recommendations for balancing event-based and time-based parameters for our hybrid approach.",Tarik Crnovrsanin;Shilpika;Senthil K. Chandrasegaran;Kwan-Liu Ma,Tarik Crnovrsanin;Shilpika;Senthil Chandrasegaran;Kwan-Liu Ma,"University of California, Davis;University of California, Davis;University of California, Davis;University of California, Davis",10.1109/infvis.2002.1173160;10.1109/tvcg.2011.226;10.1109/tvcg.2014.2346424;10.1109/infvis.2004.18;10.1109/tvcg.2007.70539;10.1109/tvcg.2006.193;10.1109/tvcg.2008.158,"Dynamic networks,graph visualization,animation,mental map,user study",7.0,9.0,48.0,593.0,,,dynamic network visualization;tasks animations lag;change time categorized;aloud study combining;offline,0.6471;0.3647;0.1858;0.1379;0.1308,"[np.int64(-1), -1, -1, -1, -1]",169;-1;-1;-1;-1,169,169
Vis,2002,QuadTIN: quadtree based triangulated irregular networks,10.1109/visual.2002.1183800,http://dx.doi.org/10.1109/VISUAL.2002.1183800,395.0,402.0,C,"Interactive visualization of large digital elevation models is of continuing interest in scientific visualization, GIS, and virtual reality applications. Taking advantage of the regular structure of grid digital elevation models, efficient hierarchical multiresolution triangulation and adaptive level-of-detail (LOD) rendering algorithms have been developed for interactive terrain visualization. Despite the higher triangle count, these approaches generally outperform mesh simplification methods that produce irregular triangulated network (TIN) based LOD representations. In this project we combine the advantage of a TIN based mesh simplification preprocess with high-performance quadtree based LOD triangulation and rendering at run-time. This approach, called QuadTIN, generates an efficient quadtree triangulation hierarchy over any irregular point set that may originate from irregular terrain sampling or from reducing oversampling in high-resolution grid digital elevation models.",Renato Pajarola;Marc Antonijuan;Roberto Lario,R. Pajarola;M. Antonijuan;R. Lario,"Computer Graphics Laboratory Information & Computer Science Department, University of California, Irvine, USA;School of Engineering, Multimedia Technology Integration Center School of Engineering;Departmento Arquitectura de Computadores y Automática Faculty de CC. Físicas, Universidad Complutense de Madrid, Spain",10.1109/visual.1997.663860;10.1109/visual.2001.964533;10.1109/visual.1998.745282;10.1109/visual.1998.745280;10.1109/visual.1997.663860,"multiresolution triangulation, real-time terrain visualization, triangulated irregular networks, level-of-detail",135.0,28.0,28.0,261.0,,,interactive terrain visualization;triangulated network;lod representations;simplification preprocess high;tin,0.6611;0.4100;0.2413;0.1533;0.0491,"[np.int64(-1), -1, -1, -1, -1]",77;-1;-1;-1;-1,77,77
VAST,2008,Spatio-temporal aggregation for visual analysis of movements,10.1109/vast.2008.4677356,http://dx.doi.org/10.1109/VAST.2008.4677356,51.0,58.0,C,"Data about movements of various objects are collected in growing amounts by means of current tracking technologies. Traditional approaches to visualization and interactive exploration of movement data cannot cope with data of such sizes. In this research paper we investigate the ways of using aggregation for visual analysis of movement data. We define aggregation methods suitable for movement data and find visualization and interaction techniques to represent results of aggregations and enable comprehensive exploration of the data. We consider two possible views of movement, traffic-oriented and trajectory-oriented. Each view requires different methods of analysis and of data aggregation. We illustrate our argument with example data resulting from tracking multiple cars in Milan and example analysis tasks from the domain of city traffic management.",Gennady L. Andrienko;Natalia V. Andrienko,Gennady Andrienko;Natalia Andrienko,"Fraunhofer Institute of Intelligent Analysis and Information Systems (IAIS), Sankt-Augustin, Germany;Fraunhofer Institute of Intelligent Analysis and Information Systems (IAIS), Sankt-Augustin, Germany",,"Movement data, spatio-temporal data, aggregation, scalable visualization, geovisualization",327.0,154.0,17.0,2149.0,,,movement data visualization;define aggregation;multiple cars milan;methods suitable;cope data sizes,0.7041;0.4373;0.2990;0.1191;0.0574,"[np.int64(-1), -1, -1, -1, -1]",222;-1;-1;-1;-1,222,222
InfoVis,2017,LSTMVis: A Tool for Visual Analysis of Hidden State Dynamics in Recurrent Neural Networks,10.1109/tvcg.2017.2744158,http://dx.doi.org/10.1109/TVCG.2017.2744158,667.0,676.0,J,"Recurrent neural networks, and in particular long short-term memory (LSTM) networks, are a remarkably effective tool for sequence modeling that learn a dense black-box hidden representation of their sequential input. Researchers interested in better understanding these models have studied the changes in hidden state representations over time and noticed some interpretable patterns but also significant noise. In this work, we present LSTMVis, a visual analysis tool for recurrent neural networks with a focus on understanding these hidden state dynamics. The tool allows users to select a hypothesis input range to focus on local state changes, to match these states changes to similar patterns in a large data set, and to align these results with structural annotations from their domain. We show several use cases of the tool for analyzing specific hidden state properties on dataset containing nesting, phrase structure, and chord progressions, and demonstrate how the tool can be used to isolate patterns for further statistical analysis. We characterize the domain, the different stakeholders, and their goals and tasks. Long-term usage data after putting the tool online revealed great interest in the machine learning community.",Hendrik Strobelt;Sebastian Gehrmann;Hanspeter Pfister;Alexander M. Rush,Hendrik Strobelt;Sebastian Gehrmann;Hanspeter Pfister;Alexander M. Rush,Harvard SEAS;Harvard SEAS;Harvard SEAS;Harvard SEAS,10.1109/tvcg.2016.2598831;10.1109/tvcg.2016.2598838;10.1109/visual.2005.1532820;10.1109/tvcg.2016.2598831,"Visualization,Machine Learning,Recurrent Neural Networks,LSTM",416.0,220.0,35.0,3330.0,,,recurrent neural networks;visual analysis tool;nesting;changes hidden;domain use,0.5999;0.2883;0.1596;0.1364;0.0053,"[np.int64(-1), -1, -1, -1, -1]",50;-1;-1;-1;-1,50,50
InfoVis,2000,Getting portals to behave,10.1109/infvis.2000.885087,http://dx.doi.org/10.1109/INFVIS.2000.885087,15.0,25.0,C,"Data visualization environments help users understand and analyze their data by permitting interactive browsing of graphical representations of the data. To further facilitate understanding and analysis, many visualization environments have special features known as portals, which are sub-windows of a data canvas. Portals provide a way to display multiple graphical representations simultaneously, in a nested fashion. This makes portals an extremely powerful and flexible paradigm for data visualization. Unfortunately, with this flexibility comes complexity. There are over a hundred possible ways each portal can be configured to exhibit different behaviors. Many of these behaviors are confusing and certain behaviors can be inappropriate for a particular setting. It is desirable to eliminate confusing and inappropriate behaviors. The authors construct a taxonomy of portal behaviors and give recommendations to help designers of visualization systems decide which behaviors are intuitive and appropriate for a particular setting. They apply these recommendations to an example setting that is fully visually programmable and analyze the resulting reduced set of behaviors. Finally, the authors consider a real visualization environment and demonstrate some problems associated with behaviors that do not follow their recommendations.",Chris Olston;Allison Woodruff,C. Olston;A. Woodruff,"Xerox-PARC;University of Stanford, USA",10.1109/infvis.1995.528688;10.1109/infvis.1995.528688,"Portals, Multiple Views, Data Visualization",11.0,5.0,16.0,91.0,,,data visualization environments;taxonomy portal behaviors;intuitive appropriate particular;nested;set behaviors finally,0.7176;0.4347;0.1678;0.0470;0.0117,"[np.int64(-1), -1, -1, -1, -1]",-1;-1;-1;-1;-1,,-1
VAST,2016,A Visual Analytics Approach for Categorical Joint Distribution Reconstruction from Marginal Projections,10.1109/tvcg.2016.2598479,http://dx.doi.org/10.1109/TVCG.2016.2598479,51.0,60.0,J,"Oftentimes multivariate data are not available as sets of equally multivariate tuples, but only as sets of projections into subspaces spanned by subsets of these attributes. For example, one may find data with five attributes stored in six tables of two attributes each, instead of a single table of five attributes. This prohibits the visualization of these data with standard high-dimensional methods, such as parallel coordinates or MDS, and there is hence the need to reconstruct the full multivariate (joint) distribution from these marginal ones. Most of the existing methods designed for this purpose use an iterative procedure to estimate the joint distribution. With insufficient marginal distributions and domain knowledge, they lead to results whose joint errors can be large. Moreover, enforcing smoothness for regularizations in the joint space is not applicable if the attributes are not numerical but categorical. We propose a visual analytics approach that integrates both anecdotal data and human experts to iteratively narrow down a large set of plausible solutions. The solution space is populated using a Monte Carlo procedure which uniformly samples the solution space. A level-of-detail high dimensional visualization system helps the user understand the patterns and the uncertainties. Constraints that narrow the solution space can then be added by the user interactively during the iterative exploration, and eventually a subset of solutions with narrow uncertainty intervals emerges.",Cong Xie;Wen Zhong;Klaus Mueller 0001,Cong Xie;Wen Zhong;Klaus Mueller,"Computer Science Department, Stony Brook University;Computer Science Department, Stony Brook University;Computer Science Department, Stony Brook University",10.1109/tvcg.2010.181;10.1109/tvcg.2013.190;10.1109/vast.2009.5332586;10.1109/tvcg.2015.2467552;10.1109/vast.2009.5332611;10.1109/tvcg.2010.183;10.1109/tvcg.2011.248;10.1109/tvcg.2010.181,Parallel Coordinates;Joint Distribution Reconstruction;Solution Space;High-dimensional Data;Multivariate Data,21.0,16.0,35.0,1136.0,HM,,visual analytics;reconstruct multivariate;carlo procedure uniformly;table attributes prohibits;plausible solutions solution,0.5697;0.4094;0.2058;0.1082;0.0737,"[np.int64(-1), -1, -1, -1, -1]",201;-1;-1;-1;-1,201,201
InfoVis,2001,An empirical comparison of three commercial information visualization systems,10.1109/infvis.2001.963289,http://dx.doi.org/10.1109/INFVIS.2001.963289,123.0,130.0,C,"An empirical comparison of three commercial information visualization systems on three different databases is presented. The systems use different paradigms for visualizing data. Tasks were selected to be ""ecologically relevant"", i.e. meaningful and interesting in the respec- tive domains. Users of one system turned out to solve problems significantly faster than users of the other two, while users of another system would supply significantly more correct answers. Reasons for these results and general observations about the studied systems are discussed.",Alfred Kobsa,A. Kobsa,"University of California, Irvine, USA",10.1109/infvis.1995.528688,,138.0,40.0,13.0,493.0,,,information visualization systems;ecologically relevant meaningful;comparison commercial;tive domains users;solve,0.7407;0.3304;0.1679;0.1166;0.0494,"[np.int64(-1), -1, -1, -1, -1]",206;-1;-1;-1;-1,206,206
SciVis,2019,The Effect of Data Transformations on Scalar Field Topological Analysis of High-Order FEM Solutions,10.1109/tvcg.2019.2934338,http://dx.doi.org/10.1109/TVCG.2019.2934338,162.0,172.0,J,"High-order finite element methods (HO-FEM) are gaining popularity in the simulation community due to their success in solving complex flow dynamics. There is an increasing need to analyze the data produced as output by these simulations. Simultaneously, topological analysis tools are emerging as powerful methods for investigating simulation data. However, most of the current approaches to topological analysis have had limited application to HO-FEM simulation data for two reasons. First, the current topological tools are designed for linear data (polynomial degree one), but the polynomial degree of the data output by these simulations is typically higher (routinely up to polynomial degree six). Second, the simulation data and derived quantities of the simulation data have discontinuities at element boundaries, and these discontinuities do not match the input requirements for the topological tools. One solution to both issues is to transform the high-order data to achieve low-order, continuous inputs for topological analysis. Nevertheless, there has been little work evaluating the possible transformation choices and their downstream effect on the topological analysis. We perform an empirical study to evaluate two commonly used data transformation methodologies along with the recently introduced L-SIAC filter for processing high-order simulation data. Our results show diverse behaviors are possible. We offer some guidance about how best to consider a pipeline of topological analysis of HO-FEM simulations with the currently available implementations of topological analysis.",Ashok Jallepalli;Joshua A. Levine;Robert M. Kirby,Ashok Jallepalli;Joshua A. Levine;Robert M. Kirby,"SCI Institute, University of Utah;Department of Computer Science, University of Arizona;SCI Institute, University of Utah",10.1109/tvcg.2014.2346403;10.1109/tvcg.2008.110;10.1109/tvcg.2015.2467432;10.1109/tvcg.2007.70603;10.1109/tvcg.2017.2744058;10.1109/tvcg.2011.249;10.1109/tvcg.2006.186;10.1109/tvcg.2014.2346332;10.1109/tvcg.2017.2743938;10.1109/tvcg.2009.163;10.1109/tvcg.2012.228;10.1109/visual.2004.113;10.1109/tvcg.2014.2346403,"High-Order Finite Element Methods,Filtering Techniques,Scalar Field Visualization,Topological Analysis",2.0,2.0,73.0,365.0,,,simulations simultaneously topological;finite element;transform high order;analysis tools emerging;siac,0.5538;0.3764;0.2684;0.2088;0.0730,"[np.int64(-1), -1, -1, -1, -1]",5;-1;-1;-1;-1,5,5
InfoVis,2007,Casual Information Visualization: Depictions of Data in Everyday Life,10.1109/tvcg.2007.70541,http://dx.doi.org/10.1109/TVCG.2007.70541,1145.0,1152.0,J,"Information visualization has often focused on providing deep insight for expert user populations and on techniques for amplifying cognition through complicated interactive visual models. This paper proposes a new subdomain for infovis research that complements the focus on analytic tasks and expert use. Instead of work-related and analytically driven infovis, we propose casual information visualization (or casual infovis) as a complement to more traditional infovis domains. Traditional infovis systems, techniques, and methods do not easily lend themselves to the broad range of user populations, from expert to novices, or from work tasks to more everyday situations. We propose definitions, perspectives, and research directions for further investigations of this emerging subfield. These perspectives build from ambient information visualization (Skog et al., 2003), social visualization, and also from artistic work that visualizes information (Viegas and Wattenberg, 2007). We seek to provide a perspective on infovis that integrates these research agendas under a coherent vocabulary and framework for design. We enumerate the following contributions. First, we demonstrate how blurry the boundary of infovis is by examining systems that exhibit many of the putative properties of infovis systems, but perhaps would not be considered so. Second, we explore the notion of insight and how, instead of a monolithic definition of insight, there may be multiple types, each with particular characteristics. Third, we discuss design challenges for systems intended for casual audiences. Finally we conclude with challenges for system evaluation in this emerging subfield.",Zachary Pousman;John T. Stasko;Michael Mateas,Zachary Pousman;John Stasko;Michael Mateas,"School of Interactive Computing and the GVU Center, Georgia Institute of Technology, USA;School of Interactive Computing and the GVU Center, Georgia Institute of Technology, USA;University of California, Santa Cruz, USA",10.1109/infvis.2005.1532126;10.1109/infvis.2004.8;10.1109/infvis.2003.1249031;10.1109/infvis.2004.59;10.1109/visual.1990.146375,"Casual information visualization, ambient infovis, social infovis, editorial, design, evaluation",501.0,275.0,42.0,5133.0,,,visualization casual infovis;challenges systems intended;wattenberg 2007 seek;monolithic definition;finally,0.7701;0.2454;0.0741;0.0155;0.0039,"[np.int64(-1), -1, -1, -1, -1]",273;-1;-1;-1;-1,273,273
Vis,2002,Christmas tree case study: computed tomography as a tool for mastering complex real world objects with applications in computer graphics,10.1109/visual.2002.1183812,http://dx.doi.org/10.1109/VISUAL.2002.1183812,489.0,492.0,C,"We report on using computed tomography (CT) as a model acquisition tool for complex objects in computer graphics. Unlike other modeling and scanning techniques the complexity of the object is irrelevant in CT, which naturally enables to model objects with, for example, concavities, holes, twists or fine surface details. Once the data is scanned, one can apply post-processing techniques for data enhancement, modification or presentation. For demonstration purposes we chose to scan a Christmas tree which exhibits high complexity which is difficult or even impossible to handle with other techniques. However, care has to be taken to achieve good scanning results with CT. Further, we illustrate post-processing by means of data segmentation and photorealistic as well as non-photorealistic surface and volume rendering techniques.",Armin Kanitsar;Thomas Theußl;Lukas Mroz;Milos Srámek;Anna Vilanova Bartrolí;Balázs Csébfalvi;Jirí Hladuvka;Dominik Fleischmann;Michael Knapp;Rainer Wegenkittl;Petr Felkel;Stefan Röttger;Stefan Guthe;Werner Purgathofer;M. Eduard Gröller,A. Kanitsar;P. Felkel;S. Rottger;S. Guthe;W. Purgathofer;M.E. Groller;T. Theussl;L. Mroz;M. Sramek;A.V. Bartroli;B. Csebfalvi;J. Hladuvka;D. Fleischmann;M. Knapp;R. Wegenkittl,"Institute of Computer Graphics and Algorithms, Vienna University of Technology, Austria and Technische Universitat Wien, Wien, Wien, AT;Inst. of Comput. Graphics & Algorithms, Vienna Univ. of Technol., Austria;Tiani Medgraph, Austria;Austrian Academy of Sciences, Vienna, Austria;Institute of Computer Graphics and Algorithms, Vienna University of Technology;Institute of Computer Graphics and Algorithms, Vienna University of Technology, Austria;Institute of Computer Graphics and Algorithms, Vienna University of Technology, Austria;Department of Radiology, University of Technology, Vienna, Austria and Department of Radiology, University of Vienna;Institute of Computer Graphics and Algorithms, University of Technology, Vienna, Austria and Austrian Academy of Sciences, Vienna, Austria;Tiani Medgraph, Austria;VRVis Research Center, Vienna, Austria;VIS University of Stuttgart, Germany;WSI/GRIS University of Tübingen, Germany;Institute of Computer Graphics and Algorithms, Vienna University of Technology, Austria;Institute of Computer Graphics and Algorithms, Vienna University of Technology, Austria",10.1109/visual.2001.964522;10.1109/visual.2001.964555;10.1109/visual.2001.964531;10.1109/visual.1994.346320;10.1109/visual.2001.964522,"modeling, computed tomography, volume visualization",27.0,6.0,14.0,160.0,,,objects computer graphics;ct naturally enables;chose scan christmas;report using computed;difficult impossible handle,0.5774;0.2980;0.2404;0.1722;0.0817,"[np.int64(-1), -1, -1, -1, -1]",297;-1;-1;-1;-1,297,297
InfoVis,2004,Metric-Based Network Exploration and Multiscale Scatterplot,10.1109/infvis.2004.47,http://dx.doi.org/10.1109/INFVIS.2004.47,135.0,142.0,C,"We describe an exploratory technique based on the direct interaction with a 2D modified scatterplot computed from two different metrics calculated over the elements of a network. The scatterplot is transformed into an image by applying standard image processing techniques resulting into blurring effects. Segmentation of the image allow to easily select patches on the image as a way to extract subnetworks. We were inspired by the work of Wattenberg and Fisher [M. Wattenberg et al. (2003)] showing that the blurring process builds into a multiscale perceptual scheme, making this type of interaction intuitive to the user. We explain how the exploration of the network can be guided by the visual analysis of the blurred scatterplot and by its possible interpretations",Yves Chiricota;Fabien Jourdan;Guy Melançon,Y. Chiricota;F. Jourdan;G. Melancon,"Université du Quàbec à Chicoutimi, Canada;LIRMM UMR CNRS 5506, Montpellier, France;LIRMM UMR CNRS 5506, Montpellier, France",10.1109/visual.1995.485139;10.1109/infvis.1999.801858;10.1109/infvis.1997.636791;10.1109/infvis.2003.1249005;10.1109/infvis.2003.1249011;10.1109/infvis.2000.885090;10.1109/visual.1995.485139,"Graph navigation, exploration, scatterplot, multiscale perceptual organization, clustering, filtering, blurring",18.0,6.0,24.0,271.0,,,network scatterplot;multiscale;interaction intuitive user;explain;blurring process builds,0.6365;0.3121;0.2556;0.1958;0.1512,"[np.int64(-1), -1, -1, -1, -1]",226;-1;-1;-1;-1,226,226
InfoVis,2007,"Visual Analysis of Network Traffic for Resource Planning, Interactive Monitoring, and Interpretation of Security Threats",10.1109/tvcg.2007.70522,http://dx.doi.org/10.1109/TVCG.2007.70522,1105.0,1112.0,J,"The Internet has become a wild place: malicious code is spread on personal computers across the world, deploying botnets ready to attack the network infrastructure. The vast number of security incidents and other anomalies overwhelms attempts at manual analysis, especially when monitoring service provider backbone links. We present an approach to interactive visualization with a case study indicating that interactive visualization can be applied to gain more insight into these large data sets. We superimpose a hierarchy on IP address space, and study the suitability of Treemap variants for each hierarchy level. Because viewing the whole IP hierarchy at once is not practical for most tasks, we evaluate layout stability when eliding large parts of the hierarchy, while maintaining the visibility and ordering of the data of interest.",Florian Mansmann;Daniel A. Keim;Stephen C. North;Brian Rexroad;Daniel Sheleheda,Florian Mansmann;Daniel A. Keim;Stephen C. North;Brian Rexroad;Daniel Sheleheda,"University of Konstanz, Germany;University of Konstanz, Germany;AT&T, USA;AT&T, USA;AT&T, USA",10.1109/vast.2006.261438;10.1109/infvis.2002.1173156;10.1109/infvis.2004.57;10.1109/visual.1991.175815;10.1109/vast.2006.261438,"Information visualization, network security, network monitoring, treemap",98.0,49.0,21.0,1155.0,,,viewing ip hierarchy;large data sets;malicious code spread;layout stability;practical,0.6385;0.2840;0.2674;0.2541;0.0601,"[np.int64(-1), -1, -1, -1, -1]",-1;-1;-1;-1;-1,,-1
Vis,2021,Where Can We Help? A Visual Analytics Approach to Diagnosing and Improving Semantic Segmentation of Movable Objects,10.1109/tvcg.2021.3114855,http://dx.doi.org/10.1109/TVCG.2021.3114855,1040.0,1050.0,J,"Semantic segmentation is a critical component in autonomous driving and has to be thoroughly evaluated due to safety concerns. Deep neural network (DNN) based semantic segmentation models are widely used in autonomous driving. However, it is challenging to evaluate DNN-based models due to their black-box-like nature, and it is even more difficult to assess model performance for crucial objects, such as lost cargos and pedestrians, in autonomous driving applications. In this work, we propose <i>VASS</i>, a <i><u>V</u></i>isual <i><u>A</u></i>nalytics approach to diagnosing and improving the accuracy and robustness of <i><u>S</u></i>emantic <i><u>S</u></i>egmentation models, especially for critical objects moving in various driving scenes. The key component of our approach is a context-aware spatial representation learning that extracts important spatial information of objects, such as position, size, and aspect ratio, with respect to given scene contexts. Based on this spatial representation, we first use it to create visual summarization to analyze models' performance. We then use it to guide the generation of adversarial examples to evaluate models' spatial robustness and obtain actionable insights. We demonstrate the effectiveness of <i>VASS</i> via two case studies of lost cargo detection and pedestrian detection in autonomous driving. For both cases, we show quantitative evaluation on the improvement of models' performance with actionable insights obtained from <i>VASS</i>.",Wenbin He;Lincan Zou;Arvind Kumar Shekar;Liang Gou;Liu Ren,Wenbin He;Lincan Zou;Arvind Kumar Shekar;Liang Gou;Liu Ren,"Robert Bosch Research and Technology Center, USA;Robert Bosch Research and Technology Center, USA;Robert Bosch GmbH, Germany;Robert Bosch Research and Technology Center, USA;Robert Bosch Research and Technology Center, USA",10.1109/tvcg.2014.2346660;10.1109/vast.2018.8802509;10.1109/tvcg.2020.3030350;10.1109/tvcg.2017.2744938;10.1109/tvcg.2016.2598831;10.1109/tvcg.2019.2934631;10.1109/tvcg.2018.2864812;10.1109/tvcg.2016.2598838;10.1109/tvcg.2016.2598828;10.1109/tvcg.2017.2744158;10.1109/tvcg.2018.2864504;10.1109/tvcg.2014.2346660,"Model diagnosis,semantic segmentation,spatial representation learning,adversarial learning,autonomous driving",11.0,26.0,52.0,1273.0,,,semantic segmentation critical;driving cases;robustness emantic;nalytics approach diagnosing;use create,0.5936;0.1786;0.1571;0.0438;0.0111,"[np.int64(-1), -1, -1, -1, -1]",35;-1;-1;-1;-1,35,35
InfoVis,2012,Compressed Adjacency Matrices: Untangling Gene Regulatory Networks,10.1109/tvcg.2012.208,http://dx.doi.org/10.1109/TVCG.2012.208,2457.0,2466.0,J,"We present a novel technique-Compressed Adjacency Matrices-for visualizing gene regulatory networks. These directed networks have strong structural characteristics: out-degrees with a scale-free distribution, in-degrees bound by a low maximum, and few and small cycles. Standard visualization techniques, such as node-link diagrams and adjacency matrices, are impeded by these network characteristics. The scale-free distribution of out-degrees causes a high number of intersecting edges in node-link diagrams. Adjacency matrices become space-inefficient due to the low in-degrees and the resulting sparse network. Compressed adjacency matrices, however, exploit these structural characteristics. By cutting open and rearranging an adjacency matrix, we achieve a compact and neatly-arranged visualization. Compressed adjacency matrices allow for easy detection of subnetworks with a specific structure, so-called motifs, which provide important knowledge about gene regulatory networks to domain experts. We summarize motifs commonly referred to in the literature, and relate them to network analysis tasks common to the visualization domain. We show that a user can easily find the important motifs in compressed adjacency matrices, and that this is hard in standard adjacency matrix and node-link diagrams. We also demonstrate that interaction techniques for standard adjacency matrices can be used for our compressed variant. These techniques include rearrangement clustering, highlighting, and filtering.",Kasper Dinkla;Michel A. Westenberg;Jarke J. van Wijk,Kasper Dinkla;Michel A. Westenberg;Jarke J. van Wijk,"Eindhoven University of Technology, Netherlands;Eindhoven University of Technology, Netherlands;Eindhoven University of Technology, Netherlands",10.1109/tvcg.2011.187;10.1109/tvcg.2006.160;10.1109/tvcg.2007.70582;10.1109/infvis.2004.1;10.1109/infvis.2005.1532126;10.1109/infvis.2004.46;10.1109/tvcg.2006.147;10.1109/tvcg.2008.141;10.1109/tvcg.2007.70556;10.1109/infvis.2004.5;10.1109/tvcg.2006.156;10.1109/tvcg.2010.159;10.1109/infvis.2003.1249030,"Network, gene regulation, scale-free, adjacency matrix",66.0,44.0,43.0,1035.0,,,visualizing gene regulatory;standard adjacency matrix;include rearrangement clustering;sparse network compressed;domain user,0.7497;0.4915;0.2978;0.2847;-0.0100,"[np.int64(-1), -1, -1, -1, -1]",117;-1;-1;-1;-1,117,117
Vis,2023,Mystique: Deconstructing SVG Charts for Layout Reuse,10.1109/tvcg.2023.3327354,http://dx.doi.org/10.1109/TVCG.2023.3327354,447.0,457.0,J,"To facilitate the reuse of existing charts, previous research has examined how to obtain a semantic understanding of a chart by deconstructing its visual representation into reusable components, such as encodings. However, existing deconstruction approaches primarily focus on chart styles, handling only basic layouts. In this paper, we investigate how to deconstruct chart layouts, focusing on rectangle-based ones, as they cover not only 17 chart types but also advanced layouts (e.g., small multiples, nested layouts). We develop an interactive tool, called Mystique, adopting a mixed-initiative approach to extract the axes and legend, and deconstruct a chart's layout into four semantic components: mark groups, spatial relationships, data encodings, and graphical constraints. Mystique employs a wizard interface that guides chart authors through a series of steps to specify how the deconstructed components map to their own data. On 150 rectangle-based SVG charts, Mystique achieves above 85% accuracy for axis and legend extraction and 96% accuracy for layout deconstruction. In a chart reproduction study, participants could easily reuse existing charts on new datasets. We discuss the current limitations of Mystique and future research directions.",Chen Chen 0080;Bongshin Lee;Yunhai Wang;Yunjeong Chang;Zhicheng Liu 0001,Chen Chen;Bongshin Lee;Yunhai Wang;Yunjeong Chang;Zhicheng Liu,"University of Maryland, College Park, Maryland, United States;Microsoft Research, Redmond, Washington, United States;Shandong University, Qingdao, China;University of Maryland, College Park, Maryland, United States;University of Maryland, College Park, Maryland, United States",0.1109/tvcg.2022.3209490;10.1109/tvcg.2011.185;10.1109/tvcg.2019.2934810;10.1109/tvcg.2021.3114856;10.1109/tvcg.2017.2744320;10.1109/tvcg.2018.2865158;10.1109/tvcg.2019.2934281;10.1109/tvcg.2016.2599030;10.1109/infvis.2001.963283;10.1109/tvcg.2019.2934538;10.1109/tvcg.2008.165;10.1109/tvcg.2021.3114877,"Chart layout,Reuse,Reverse-engineering,Deconstruction",,2.0,47.0,481.0,,,deconstruct chart layouts;develop interactive;reuse;encodings existing;85 accuracy,0.7129;0.3049;0.2696;0.0781;-0.0040,"[np.int64(-1), -1, -1, -1, -1]",-1;-1;-1;-1;-1,,-1
SciVis,2016,Hairy Slices: Evaluating the Perceptual Effectiveness of Cutting Plane Glyphs for 3D Vector Fields,10.1109/tvcg.2016.2598448,http://dx.doi.org/10.1109/TVCG.2016.2598448,990.0,999.0,J,"Three-dimensional vector fields are common datasets throughout the sciences. Visualizing these fields is inherently difficult due to issues such as visual clutter and self-occlusion. Cutting planes are often used to overcome these issues by presenting more manageable slices of data. The existing literature provides many techniques for visualizing the flow through these cutting planes; however, there is a lack of empirical studies focused on the underlying perceptual cues that make popular techniques successful. This paper presents a quantitative human factors study that evaluates static monoscopic depth and orientation cues in the context of cutting plane glyph designs for exploring and analyzing 3D flow fields. The goal of the study was to ascertain the relative effectiveness of various techniques for portraying the direction of flow through a cutting plane at a given point, and to identify the visual cues and combinations of cues involved, and how they contribute to accurate performance. It was found that increasing the dimensionality of line-based glyphs into tubular structures enhances their ability to convey orientation through shading, and that increasing their diameter intensifies this effect. These tube-based glyphs were also less sensitive to visual clutter issues at higher densities. Adding shadows to lines was also found to increase perception of flow direction. Implications of the experimental results are discussed and extrapolated into a number of guidelines for designing more perceptually effective glyphs for 3D vector field visualizations.",Andrew H. Stevens;Thomas Butkiewicz;Colin Ware,Andrew H. Stevens;Thomas Butkiewicz;Colin Ware,"The Center for Coastal and Ocean Mapping, The University of New Hampshire;The Center for Coastal and Ocean Mapping, The University of New Hampshire;The Center for Coastal and Ocean Mapping, The University of New Hampshire",10.1109/visual.1996.568139;10.1109/tvcg.2009.126;10.1109/visual.2005.1532859;10.1109/visual.2004.59;10.1109/visual.1991.175792;10.1109/tvcg.2012.216;10.1109/visual.1999.809918;10.1109/visual.1998.745317;10.1109/visual.2005.1532772;10.1109/tvcg.2009.138;10.1109/visual.1990.146360;10.1109/visual.1996.567777;10.1109/visual.1996.568139,Flow visualization;3D vector fields;Cutting planes;Glyphs;Perception;Evaluation;Human factors,2.0,1.0,47.0,774.0,,,visualizing flow cutting;convey orientation;performance increasing dimensionality;glyphs sensitive;lack empirical studies,0.6410;0.3375;0.1997;0.1178;0.0494,"[np.int64(-1), -1, -1, -1, -1]",138;-1;-1;-1;-1,138,138
VAST,2012,The User Puzzle---Explaining the Interaction with Visual Analytics Systems,10.1109/tvcg.2012.273,http://dx.doi.org/10.1109/TVCG.2012.273,2908.0,2916.0,J,"Visual analytics emphasizes the interplay between visualization, analytical procedures performed by computers and human perceptual and cognitive activities. Human reasoning is an important element in this context. There are several theories in psychology and HCI explaining open-ended and exploratory reasoning. Five of these theories (sensemaking theories, gestalt theories, distributed cognition, graph comprehension theories and skill-rule-knowledge models) are described in this paper. We discuss their relevance for visual analytics. In order to do this more systematically, we developed a schema of categories relevant for visual analytics research and evaluation. All these theories have strengths but also weaknesses in explaining interaction with visual analytics systems. A possibility to overcome the weaknesses would be to combine two or more of these theories.",Margit Pohl;Michael Smuc;Eva Mayr,Margit Pohl;Michael Smuc;Eva Mayr,"University of Technology, Vienna, Austria;Danube-University of Krems, Austria;Danube-University of Krems, Austria",10.1109/tvcg.2008.121;10.1109/tvcg.2007.70515;10.1109/vast.2010.5653598;10.1109/vast.2008.4677361;10.1109/vast.2011.6102445,"Cognitive theory, visual knowledge discovery, interaction design, reasoning, problem solving",50.0,29.0,65.0,1203.0,,,visual analytics research;reasoning;cognitive activities human;gestalt theories distributed;ended,0.6735;0.3113;0.2904;0.2739;-0.0336,"[np.int64(-1), -1, -1, -1, -1]",201;-1;-1;-1;-1,201,201
InfoVis,2000,Visualizing sequential patterns for text mining,10.1109/infvis.2000.885097,http://dx.doi.org/10.1109/INFVIS.2000.885097,105.0,111.0,C,"A sequential pattern in data mining is a finite series of elements such as A/spl rarr/B/spl rarr/C/spl rarr/D where A, B, C, and D are elements of the same domain. The mining of sequential patterns is designed to find patterns of discrete events that frequently happen in the same arrangement along a timeline. Like association and clustering, the mining of sequential patterns is among the most popular knowledge discovery techniques that apply statistical measures to extract useful information from large datasets. As out computers become more powerful, we are able to mine bigger datasets and obtain hundreds of thousands of sequential patterns in full detail. With this vast amount of data, we argue that neither data mining nor visualization by itself can manage the information and reflect the knowledge effectively. Subsequently, we apply visualization to augment data mining in a study of sequential patterns in large text corpora. The result shows that we can learn more and more quickly in an integrated visual data-mining environment.",Pak Chung Wong;Wendy Cowley;Harlan Foote;Elizabeth Jurrus;James J. Thomas,Pak Chung Wong;W. Cowley;H. Foote;E. Jurrus;J. Thomas,"Pacific Northwest National Laboratory, USA;Pacific Northwest National Laboratory, USA;Pacific Northwest National Laboratory, USA;Pacific Northwest National Laboratory, USA;Pacific Northwest National Laboratory, USA",10.1109/infvis.1998.729565;10.1109/infvis.1998.729570;10.1109/visual.1998.745302;10.1109/infvis.1995.528686;10.1109/infvis.1999.801866;10.1109/infvis.1997.636791;10.1109/visual.1990.146402;10.1109/infvis.1998.729565,,109.0,11.0,14.0,576.0,,,mining sequential patterns;apply visualization augment;corpora result shows;argue;rarr elements domain,0.7220;0.2447;0.2026;0.0970;0.0628,"[np.int64(-1), -1, -1, -1, -1]",127;-1;-1;-1;-1,127,127
VAST,2011,Interactive decision making using dissimilarity to visually represented prototypes,10.1109/vast.2011.6102451,http://dx.doi.org/10.1109/VAST.2011.6102451,141.0,149.0,C,"To make informed decisions, an expert has to reason with multi-dimensional, heterogeneous data and analysis results of these. Items in such datasets are typically represented by features. However, as argued in cognitive science, features do not yield an optimal space for human reasoning. In fact, humans tend to organize complex information in terms of prototypes or known cases rather than in absolute terms. When confronted with unknown data items, humans assess them in terms of similarity to these prototypical elements. Interestingly, an analogues similarity-to-prototype approach, where prototypes are taken from the data, has been successfully applied in machine learning. Combining such a machine learning approach with human prototypical reasoning in a Visual Analytics context requires to integrate similarity-based classification with interactive visualizations. To that end, the data prototypes should be visually represented to trigger direct associations to cases familiar to the domain experts. In this paper, we propose a set of highly interactive visualizations to explore data and classification results in terms of dissimilarities to visually represented prototypes. We argue that this approach not only supports human reasoning processes, but is also suitable to enhance understanding of heterogeneous data. The proposed framework is applied to a risk assessment case study in Forensic Psychiatry.",Malgorzata Migut;Jan C. van Gemert;Marcel Worring,M.A. Migut;J.C. van Gemert;M. Worring,"Intelligent Systems Laboratory Amsterdam, University of Amsterdam, Netherlands;Expertise Center Forensic Psychiatry, Utrecht, Netherlands;Intelligent Systems Laboratory Amsterdam, University of Amsterdam, Netherlands",10.1109/tvcg.2007.70515;10.1109/tvcg.2009.174;10.1109/tvcg.2009.199;10.1109/vast.2010.5652398;10.1109/visual.1994.346302;10.1109/infvis.1998.729559;10.1109/infvis.2000.885086;10.1109/tvcg.2007.70515,"dissimilarity based classication, dissimilarity based visualization, prototypes, interactive visualization, visual analytics",21.0,11.0,35.0,426.0,,,visualizations explore data;cases familiar;machine learning combining;fact humans tend;yield optimal space,0.5720;0.3262;0.2690;0.1954;-0.0024,"[np.int64(-1), -1, -1, -1, -1]",202;-1;-1;-1;-1,202,202
SciVis,2018,CoDDA: A Flexible Copula-based Distribution Driven Analysis Framework for Large-Scale Multivariate Data,10.1109/tvcg.2018.2864801,http://dx.doi.org/10.1109/TVCG.2018.2864801,1214.0,1224.0,J,"CoDDA (Copula-based Distribution Driven Analysis) is a flexible framework for large-scale multivariate datasets. A common strategy to deal with large-scale scientific simulation data is to partition the simulation domain and create statistical data summaries. Instead of storing the high-resolution raw data from the simulation, storing the compact statistical data summaries results in reduced storage overhead and alleviated I/O bottleneck. Such summaries, often represented in the form of statistical probability distributions, can serve various post-hoc analysis and visualization tasks. However, for multivariate simulation data using standard multivariate distributions for creating data summaries is not feasible. They are either storage inefficient or are computationally expensive to be estimated in simulation time (in situ) for large number of variables. In this work, using copula functions, we propose a flexible multivariate distribution-based data modeling and analysis framework that offers significant data reduction and can be used in an in situ environment. The framework also facilitates in storing the associated spatial information along with the multivariate distributions in an efficient representation. Using the proposed multivariate data summaries, we perform various multivariate post-hoc analyses like query-driven visualization and sampling-based visualization. We evaluate our proposed method on multiple real-world multivariate scientific datasets. To demonstrate the efficacy of our framework in an in situ environment, we apply it on a large-scale flow simulation.",Subhashis Hazarika;Soumya Dutta;Han-Wei Shen;Jen-Ping Chen,Subhashis Hazarika;Soumya Dutta;Han-Wei Shen;Jen-Ping Chen,"Ohio State University, Columbus, OH, US;Ohio State University, Columbus, OH, US;Ohio State University, Columbus, OH, US;Ohio State University, Columbus, OH, US",10.1109/tvcg.2015.2467958;10.1109/tvcg.2007.70519;10.1109/tvcg.2015.2467952;10.1109/tvcg.2016.2598604;10.1109/tvcg.2015.2467436;10.1109/tvcg.2015.2467204;10.1109/tvcg.2017.2744099;10.1109/tvcg.2007.70615;10.1109/vast.2015.7347634;10.1109/tvcg.2006.165;10.1109/tvcg.2015.2467411;10.1109/tvcg.2015.2467958,"In situ processing,Distribution-based,Multivariate,Query-driven,Copula",19.0,13.0,64.0,743.0,,,multivariate simulation data;scale flow;environment framework facilitates;feasible storage;significant,0.5853;0.2733;0.1293;0.0705;0.0088,"[np.int64(-1), -1, -1, -1, -1]",216;-1;-1;-1;-1,216,216
Vis,1990,Real-world applications of visualization solutions,10.1109/visual.1990.146417,http://dx.doi.org/10.1109/VISUAL.1990.146417,440.0,442.0,C,"Visual data analysis (VDA) is a visualization approach that combines vector and raster graphics to provide insights into various aspects of multidimensional datasets. VDA methods have found application in aerospace engineering research, VDA is being used to develop nondestructive evaluation testing techniques for graphite epoxy composites by providing insights into stress waves propagating through them. Visual data analysis was used to analyze stress wave propagation, determine the origin of an unexplained wave distortion, and create a theoretical model to eliminate the distortion utilizing mathematical modeling.&lt;&lt;ETX&gt;&gt;",David A. Prawel,D.A. Prawel,"Precision Visuals, Inc., Boulder, CO, USA",,,3.0,0.0,3.0,59.0,,,visual data analysis;nondestructive evaluation testing;stress wave propagation;graphite epoxy composites;aerospace,0.5782;0.4066;0.3924;0.3395;0.3182,"[np.int64(-1), -1, -1, -1, -1]",272;-1;-1;-1;-1,272,272
Vis,2003,Appearance-preserving view-dependent visualization,10.1109/visual.2003.1250409,http://dx.doi.org/10.1109/VISUAL.2003.1250409,473.0,480.0,C,"In this paper a new quadric-based view-dependent simplification scheme is presented. The scheme provides a method to connect mesh simplification controlled by a quadric error metric with a level-of-detail hierarchy that is accessed continuously and efficiently based on current view parameters. A variety of methods for determining the screen-space metric for the view calculation are implemented and evaluated, including an appearance-preserving method that has both geometry- and texture-preserving aspects. Results are presented and compared for a variety of models.",Justin Jang;William Ribarsky;Christopher D. Shaw;Peter Wonka,J. Jang;W. Ribarsky;C. Shaw;P. Wonka,"GVU Center, Georgia Institute of Technology, USA;GVU Center, Georgia Institute of Technology, USA;GVU Center, Georgia Institute of Technology, USA;GVU Center, Georgia Institute of Technology, USA",10.1109/visual.1998.745342;10.1109/visual.1999.809869;10.1109/visual.1998.745312;10.1109/visual.1999.809924;10.1109/visual.2002.1183760;10.1109/visual.1998.745342," view-dependent, level of detail, mesh simplification, appearance-preserving, multiresolution models",17.0,3.0,27.0,73.0,,,mesh simplification controlled;quadric error;current view;scheme provides method;compared,0.6561;0.2967;0.1418;0.1096;0.0700,"[np.int64(-1), -1, -1, -1, -1]",112;-1;-1;-1;-1,112,112
SciVis,2017,BASTet: Shareable and Reproducible Analysis and Visualization of Mass Spectrometry Imaging Data via OpenMSI,10.1109/tvcg.2017.2744479,http://dx.doi.org/10.1109/TVCG.2017.2744479,1025.0,1035.0,J,"Mass spectrometry imaging (MSI) is a transformative imaging method that supports the untargeted, quantitative measurement of the chemical composition and spatial heterogeneity of complex samples with broad applications in life sciences, bioenergy, and health. While MSI data can be routinely collected, its broad application is currently limited by the lack of easily accessible analysis methods that can process data of the size, volume, diversity, and complexity generated by MSI experiments. The development and application of cutting-edge analytical methods is a core driver in MSI research for new scientific discoveries, medical diagnostics, and commercial-innovation. However, the lack of means to share, apply, and reproduce analyses hinders the broad application, validation, and use of novel MSI analysis methods. To address this central challenge, we introduce the Berkeley Analysis and Storage Toolkit (BASTet), a novel framework for shareable and reproducible data analysis that supports standardized data and analysis interfaces, integrated data storage, data provenance, workflow management, and a broad set of integrated tools. Based on BASTet, we describe the extension of the OpenMSI mass spectrometry imaging science gateway to enable web-based sharing, reuse, analysis, and visualization of data analyses and derived data products. We demonstrate the application of BASTet and OpenMSI in practice to identify and compare characteristic substructures in the mouse brain based on their chemical composition measured via MSI.",Oliver Rübel;Benjamin P. Bowen,Oliver Rübel;Benjamin P. Bowen,"Computational Research Division, Lawrence Berkeley National Laboratory (LBNL);Environmental Genomics & Systems Biology Division, LBNL",10.1109/visual.2005.1532788;10.1109/tvcg.2011.185;10.1109/tvcg.2015.2467091;10.1109/visual.2005.1532788,"Mass spectrometry imaging,Data provenance,Visualization,Data management,Analysis Workflows,Data sharing",8.0,9.0,55.0,582.0,,,mass spectrometry imaging;mouse brain;shareable reproducible data;analyses hinders broad;enable web,0.5741;0.3380;0.3373;0.1751;0.0018,"[np.int64(-1), -1, -1, -1, -1]",288;-1;-1;-1;-1,288,288
InfoVis,2015,Reactive Vega: A Streaming Dataflow Architecture for Declarative Interactive Visualization,10.1109/tvcg.2015.2467091,http://dx.doi.org/10.1109/TVCG.2015.2467091,659.0,668.0,J,"We present Reactive Vega, a system architecture that provides the first robust and comprehensive treatment of declarative visual and interaction design for data visualization. Starting from a single declarative specification, Reactive Vega constructs a dataflow graph in which input data, scene graph elements, and interaction events are all treated as first-class streaming data sources. To support expressive interactive visualizations that may involve time-varying scalar, relational, or hierarchical data, Reactive Vega's dataflow graph can dynamically re-write itself at runtime by extending or pruning branches in a data-driven fashion. We discuss both compile- and run-time optimizations applied within Reactive Vega, and share the results of benchmark studies that indicate superior interactive performance to both D3 and the original, non-reactive Vega system.",Arvind Satyanarayan;Ryan Russell;Jane Hoffswell;Jeffrey Heer,Arvind Satyanarayan;Ryan Russell;Jane Hoffswell;Jeffrey Heer,Stanford University;University of Washington;University of Washington;University of Washington,10.1109/visual.1995.480821;10.1109/tvcg.2009.174;10.1109/tvcg.2011.185;10.1109/tvcg.2010.144;10.1109/tvcg.2014.2346250;10.1109/tvcg.2013.179;10.1109/tvcg.2010.177;10.1109/visual.1996.567752;10.1109/infvis.2000.885086;10.1109/infvis.2004.12;10.1109/tvcg.2015.2467191;10.1109/tvcg.2007.70515;10.1109/visual.1995.480821,"Information visualization, systems, toolkits, declarative specification, optimization, interaction, streaming data",267.0,186.0,41.0,2469.0,,,expressive interactive visualizations;vega share;pruning branches data;original non reactive;compile run,0.6339;0.2082;0.1657;0.0832;0.0415,"[np.int64(-1), -1, -1, -1, -1]",194;-1;-1;-1;-1,194,194
Vis,1995,Legibility enhancement for information visualisation,10.1109/visual.1995.480814,http://dx.doi.org/10.1109/VISUAL.1995.480814,209.0,,C,"Navigation in computer generated information spaces may be difficult, resulting in users getting ""lost in hyperspace"". This work aims to build on research from the area of city planning to try to solve this problem. We introduce the concepts of legibility and cognitive maps and the five features of urban landscape with which they are associated. Following this will be descriptions of techniques and algorithms which we have developed to allow these features to be introduced to three dimensional spaces for information visualisation. Next we describe a specific application of these techniques in the visualisation of the World Wide Web and conclude with a look at future development of the system.",Rob Ingram;Steve Benford,R. Ingram;S. Benford,"Department of Computer Science, University of Nottingham, Nottingham, UK;Department of Computer Science, University of Nottingham, Nottingham, UK",,,101.0,14.0,10.0,111.0,,,spaces information visualisation;legibility cognitive;wide web conclude;urban;developed allow features,0.6204;0.4024;0.2113;0.2085;0.1133,"[np.int64(-1), -1, -1, -1, -1]",-1;-1;-1;-1;-1,,-1
VAST,2010,A closer look at note taking in the co-located collaborative visual analytics process,10.1109/vast.2010.5652879,http://dx.doi.org/10.1109/VAST.2010.5652879,171.0,178.0,C,"This paper highlights the important role that record-keeping (i.e. taking notes and saving charts) plays in collaborative data analysis within the business domain. The discussion of record-keeping is based on observations from a user study in which co-located teams worked on collaborative visual analytics tasks using large interactive wall and tabletop displays. Part of our findings is a collaborative data analysis framework that encompasses note taking as one of the main activities. We observed that record-keeping was a critical activity within the analysis process. Based on our observations, we characterize notes according to their content, scope, and usage, and describe how they fit into a process of collaborative data analysis. We then discuss suggestions for the design of collaborative visual analytics tools.",Narges Mahyar;Ali Sarvghad;Melanie Tory,Narges Mahyar;Ali Sarvghad;Melanie Tory,"University of Victoria, Canada;University of Victoria, Canada;University of Victoria, Canada",10.1109/tvcg.2008.137;10.1109/vast.2008.4677358;10.1109/tvcg.2007.70568;10.1109/vast.2009.5333020;10.1109/vast.2008.4677365;10.1109/vast.2009.5333023;10.1109/tvcg.2007.70577;10.1109/tvcg.2008.137,"note taking, recording, collaboration, tabletop, wall display, history, provenance",24.0,9.0,33.0,453.0,,,collaborative visual analytics;taking notes saving;wall tabletop displays;observations characterize;role,0.7378;0.4376;0.2915;0.1808;0.0621,"[np.int64(-1), -1, -1, -1, -1]",193;-1;-1;-1;-1,193,193
Vis,2003,A visual exploration process for the analysis of Internet routing data,10.1109/visual.2003.1250415,http://dx.doi.org/10.1109/VISUAL.2003.1250415,523.0,530.0,C,"The Internet pervades many aspects of our lives and is becoming indispensable to critical functions in areas such as commerce, government, production and general information dissemination. To maintain the stability and efficiency of the Internet, every effort must be made to protect it against various forms of attacks, malicious users, and errors. A key component in the Internet security effort is the routine examination of Internet routing data, which unfortunately can be too large and complicated to browse directly. We have developed an interactive visualization process which proves to be very effective for the analysis of Internet routing data. In this application paper, we show how each step in the visualization process helps direct the analysis and glean insights from the data. These insights include the discovery of patterns, detection of faults and abnormal events, understanding of event correlations, formation of causation hypotheses, and classification of anomalies. We also discuss lessons learned in our visual analysis study.",Soon Tee Teoh;Kwan-Liu Ma;Shyhtsun Felix Wu,Soon Tee Teoh;Kwan-Liu Ma;S.F. Wu,"Department of Computer Science, University of California, Davis, USA;Department of Computer Science, University of California, Davis, USA;Department of Computer Science, University of California, Davis, USA",10.1109/visual.2002.1183816," information visualization, text visualization, network visualization , internet stability, homeland security",56.0,15.0,16.0,162.0,,,analysis internet routing;interactive visualization process;understanding event correlations;protect various forms;lessons learned visual,0.6709;0.4531;0.2664;0.1411;0.1241,"[np.int64(-1), -1, -1, -1, -1]",64;-1;-1;-1;-1,64,64
Vis,2022,Constrained Dynamic Mode Decomposition,10.1109/tvcg.2022.3209437,http://dx.doi.org/10.1109/TVCG.2022.3209437,182.0,192.0,J,"Frequency-based decomposition of time series data is used in many visualization applications. Most of these decomposition methods (such as Fourier transform or singular spectrum analysis) only provide interaction via pre- and post-processing, but no means to influence the core algorithm. A method that also belongs to this class is Dynamic Mode Decomposition (DMD), a spectral decomposition method that extracts spatio-temporal patterns from data. In this paper, we incorporate frequency-based constraints into DMD for an adaptive decomposition that leads to user-controllable visualizations, allowing analysts to include their knowledge into the process. To accomplish this, we derive an equivalent reformulation of DMD that implicitly provides access to the eigenvalues (and therefore to the frequencies) identified by DMD. By utilizing a constrained minimization problem customized to DMD, we can guarantee the existence of desired frequencies by minimal changes to DMD. We complement this core approach by additional techniques for constrained DMD to facilitate explorative visualization and investigation of time series data. With several examples, we demonstrate the usefulness of constrained DMD and compare it to conventional frequency-based decomposition methods.",Tim Krake;Daniel Klötzl;Bernhard Eberhardt;Daniel Weiskopf,Tim Krake;Daniel Klötzl;Bernhard Eberhardt;Daniel Weiskopf,"University of Stuttgart and Hochschule der Medien, Germany;University of Stuttgart, Germany;Hochschule der Medien, Germany;University of Stuttgart, Germany",10.1109/vast.2012.6400557;10.1109/infvis.1999.801851;10.1109/tvcg.2015.2467751;10.1109/infvis.2001.963273;10.1109/tvcg.2011.195;10.1109/vast.2012.6400557,"Dynamic Mode Decomposition,time series analysis,spectral decomposition,frequency-based constraints,human-in-the-loop",38.0,2.0,58.0,1406.0,,X,frequency based decomposition;user controllable visualizations;dynamic mode;constrained minimization problem;demonstrate,0.6058;0.4013;0.2875;0.1619;0.0743,"[np.int64(-1), -1, -1, -1, -1]",42;-1;-1;-1;-1,42,42
Vis,1996,History consideration in reconstructing polyhedral surfaces from parallel slices,10.1109/visual.1996.567804,http://dx.doi.org/10.1109/VISUAL.1996.567804,149.0,156.0,C,"We introduce an algorithm for reconstructing a solid model given a series of planar cross sections. The main contribution of this work is the use of knowledge obtained during the interpolation of neighboring layers while attempting to interpolate a particular layer. This knowledge is used to reconstruct a surface in which consecutive layers are connected smoothly. In most previous work, each layer is interpolated independently of what happened or will happen in the other layers. We also discuss various objective functions which aim to optimize the reconstruction, and present an evaluation of the different objective functions by using various criteria.",Gill Barequet;Daniel Shapiro;Ayellet Tal,G. Barequet;D. Shapiro;A. Tal,"Tel-Aviv University, Israel;Princeton University, USA;Weizmann Institute of Science, Israel",,"reconstruction, interpolation, triangulation",39.0,9.0,35.0,52.0,,,reconstructing solid model;obtained interpolation neighboring;planar cross;functions aim optimize;consecutive,0.7389;0.4563;0.2512;0.0775;0.0458,"[np.int64(-1), -1, -1, -1, -1]",247;-1;-1;-1;-1,247,247
Vis,2001,Point set surfaces,10.1109/visual.2001.964489,http://dx.doi.org/10.1109/VISUAL.2001.964489,21.0,28.0,C,"We advocate the use of point sets to represent shapes. We provide a definition of a smooth manifold surface from a set of points close to the original surface. The definition is based on local maps from differential geometry, which are approximated by the method of moving least squares (MLS). We present tools to increase or decrease the density of the points, thus, allowing an adjustment of the spacing among the points to control the fidelity of the representation. To display the point set surface, we introduce a novel point rendering technique. The idea is to evaluate the local maps according to the image resolution. This results in high quality shading effects and smooth silhouettes at interactive frame rates.",Marc Alexa;Johannes Behr;Daniel Cohen-Or;Shachar Fleishman;David Levin;Cláudio T. Silva,M. Alexa;J. Behr;D. Cohen-Or;S. Fleishman;D. Levin;C.T. Silva,"Technical University of Darmstadt, Germany;ZGDV Darmstadt, Germany;Tel-Aviv University, Israel;Tel-Aviv University, Israel;Tel-Aviv University, Israel;AT and T Laboratories, USA",10.1109/visual.1997.663930;10.1109/visual.1998.745327;10.1109/visual.1997.663930,"surface representation and reconstruction, moving least squares, point sample rendering, 3D acquisition",1090.0,259.0,46.0,1225.0,,,novel point rendering;definition smooth manifold;sets;decrease density;evaluate local,0.6722;0.3790;0.1106;0.1045;0.0786,"[np.int64(-1), -1, -1, -1, -1]",62;-1;-1;-1;-1,62,62
Vis,1995,Authenticity analysis of wavelet approximations in visualization,10.1109/visual.1995.480811,http://dx.doi.org/10.1109/VISUAL.1995.480811,184.0,,C,"Wavelet transforms include data decompositions and reconstructions. This paper is concerned with the authenticity issues of the data decomposition, particularly for data visualization. A total of six datasets are used to clarify the approximation characteristics of compactly supported orthogonal wavelets. We present an error tracking mechanism, which uses the available wavelet resources to measure the quality of the wavelet approximations.",Pak Chung Wong;R. Daniel Bergeron,Pak Chung Wong;R.D. Bergeron,"Department of Computer Science, University of New Hampshire, Durham, NH, USA;Department of Computer Science, University of New Hampshire, Durham, NH, USA",10.1109/visual.1994.346333;10.1109/visual.1994.346332;10.1109/visual.1992.235230;10.1109/visual.1994.346333,,26.0,6.0,19.0,51.0,,,wavelet transforms;visualization total datasets;authenticity issues data;particularly;clarify approximation,0.7092;0.3463;0.3149;0.1509;0.1386,"[np.int64(-1), -1, -1, -1, -1]",99;-1;-1;-1;-1,99,99
InfoVis,1998,The shape of Shakespeare: visualizing text using implicit surfaces,10.1109/infvis.1998.729568,http://dx.doi.org/10.1109/INFVIS.1998.729568,121.0,,C,"Information visualization focuses on the use of visual means for exploring non-visual information. While free-form text is a rich, common source of information, visualization of text is a challenging problem since text is inherently non-spatial. The paper explores the use of implicit surface models for visualizing text. The authors describe several techniques for text visualization that aid in understanding document content and document relationships. A simple method is defined for mapping document content to shape. By comparing the shapes of multiple documents, global content similarities and differences may be noted. In addition, they describe a visual clustering method in which documents are arranged in 3D based upon similarity scoring. Documents deemed closely related blend together as a single connected shape. Hence, a document corpus becomes a collection of shapes that reflect inter-document relationships. These techniques provide methods to visualize individual documents as well as corpus meta-data. They then combine the two techniques to produce transparent clusters enclosing individual document shapes. This provides a way to visualize both local and global contextual information. Finally, they elaborate on several potential applications of these methods.",Randall M. Rohrer;John L. Sibert;David S. Ebert,R.M. Rohrer;D.S. Ebert;J.L. Sibert,"Department of EECS, George Washington University, USA;CSEE Department, University of Maryland Baltimore County, USA;Department of EECS, George Washington University, USA",10.1109/infvis.1997.636761;10.1109/infvis.1997.636759;10.1109/infvis.1995.528686;10.1109/visual.1996.568110;10.1109/infvis.1996.559228;10.1109/infvis.1996.559220,"information visualization, text visualization, procedural visualization, implicit surface modeling, blobby models, document clustering, information retrieval, graphics, user interfaces",93.0,22.0,26.0,339.0,,,visualize individual documents;surface models;form text;data;inherently non,0.6394;0.2922;0.2402;0.2125;0.0477,"[np.int64(-1), -1, -1, -1, -1]",171;-1;-1;-1;-1,171,171
Vis,2004,Non-linear model fitting to parameterize diseased blood vessels,10.1109/visual.2004.72,http://dx.doi.org/10.1109/VISUAL.2004.72,393.0,400.0,C,"Accurate estimation of vessel parameters is a prerequisite for automated visualization and analysis of healthy and diseased blood vessels. The objective of this research is to estimate the dimensions of lower extremity arteries, imaged by computed tomography (CT). These parameters are required to get a good quality visualization of healthy as well as diseased arteries using a visualization technique such as curved planar reformation (CPR). The vessel is modeled using an elliptical or cylindrical structure with specific dimensions, orientation and blood vessel mean density. The model separates two homogeneous regions: its inner side represents a region of density for vessels, and its outer side a region for background. Taking into account the point spread function (PSF) of a CT scanner, a function is modeled with a Gaussian kernel, in order to smooth the vessel boundary in the model. A new strategy for vessel parameter estimation is presented. It stems from vessel model and model parameter optimization by a nonlinear optimization procedure, i.e., the Levenberg-Marquardt technique. The method provides center location, diameter and orientation of the vessel as well as blood and background mean density values. The method is tested on synthetic data and real patient data with encouraging results.",Alexandra La Cruz;Matús Straka;Arnold Köchl;Milos Srámek;M. Eduard Gröller;Dominik Fleischmann,A. La Cruz;M. Straka;A. Kochl;M. Sramek;E. Groller;D. Fleischmann,"University of Technology, Vienna, Austria;Austrian Academy of Sciences, Austria;Vienna University of Medicine, Austria;Austrian Academy of Sciences, Austria;University of Technology, Vienna, Austria;Stanford University Medical Center, USA",10.1109/visual.2001.964555,"Visualization, Segmentation, Blood Vessel Detection",29.0,5.0,11.0,141.0,,,vessel parameter estimation;curved planar reformation;gaussian kernel;region background;new strategy,0.6539;0.2990;0.2426;0.0856;-0.0360,"[np.int64(-1), -1, -1, -1, -1]",221;-1;-1;-1;-1,221,221
InfoVis,2005,A note on space-filling visualizations and space-filling curves,10.1109/infvis.2005.1532145,http://dx.doi.org/10.1109/INFVIS.2005.1532145,181.0,186.0,C,"A recent line of treemap research has focused on layout algorithms that optimize properties such as stability, preservation of ordering information, and aspect ratio of rectangles. No ideal treemap layout algorithm has been found, and so it is natural to explore layouts that produce nonrectangular regions. This note describes a connection between space-filling visualizations and the mathematics of space-filling curves, and uses that connection to characterize a family of layout algorithms which produce nonrectangular regions but enjoy geometric continuity under changes to the data and legibility even for highly unbalanced trees.",Martin Wattenberg,M. Wattenberg,"IBM Research, Israel",10.1109/infvis.2001.963283;10.1109/infvis.2002.1173152;10.1109/infvis.2001.963283,Hierarchy Visualization,129.0,25.0,15.0,902.0,,,treemap layout algorithm;nonrectangular regions;information aspect ratio;space;properties stability,0.8002;0.2876;0.2238;0.1643;-0.0110,"[np.int64(-1), -1, -1, -1, -1]",53;-1;-1;-1;-1,53,53
VAST,2011,Characterizing the intelligence analysis process: Informing visual analytics design through a longitudinal field study,10.1109/vast.2011.6102438,http://dx.doi.org/10.1109/VAST.2011.6102438,21.0,30.0,C,"While intelligence analysis has been a primary target domain for visual analytics system development, relatively little user and task analysis has been conducted within this area. Our research community's understanding of the work processes and practices of intelligence analysts is not deep enough to adequately address their needs. Without a better understanding of the analysts and their problems, we cannot build visual analytics systems that integrate well with their work processes and truly provide benefit to them. In order to close this knowledge gap, we conducted a longitudinal, observational field study of intelligence analysts in training within the intelligence program at Mercyhurst College. We observed three teams of analysts, each working on an intelligence problem for a ten-week period. Based upon study findings, we describe and characterize processes and methods of intelligence analysis that we observed, make clarifications regarding the processes and practices, and suggest design implications for visual analytics systems for intelligence analysis.",Youn ah Kang;John T. Stasko,Youn-ah Kang;John Stasko,"Georgia Institute of Technology;Georgia Institute of Technology, USA",10.1109/vast.2008.4677362;10.1109/visual.1992.235203;10.1109/vast.2008.4677358;10.1109/tvcg.2009.111;10.1109/vast.2007.4389006;10.1109/vast.2008.4677362,"Intelligence analysis, qualitatvie user study",117.0,52.0,31.0,1031.0,,,analysts working intelligence;problems build visual;relatively little user;week period based;truly,0.6976;0.2394;0.0787;0.0501;0.0297,"[np.int64(-1), -1, -1, -1, -1]",76;-1;-1;-1;-1,76,76
InfoVis,2012,Intelligent Graph Layout Using Many Users' Input,10.1109/tvcg.2012.236,http://dx.doi.org/10.1109/TVCG.2012.236,2699.0,2708.0,J,"In this paper, we propose a new strategy for graph drawing utilizing layouts of many sub-graphs supplied by a large group of people in a crowd sourcing manner. We developed an algorithm based on Laplacian constrained distance embedding to merge subgraphs submitted by different users, while attempting to maintain the topological information of the individual input layouts. To facilitate collection of layouts from many people, a light-weight interactive system has been designed to enable convenient dynamic viewing, modification and traversing between layouts. Compared with other existing graph layout algorithms, our approach can achieve more aesthetic and meaningful layouts with high user preference.",Xiaoru Yuan;Limei Che;Yifan Hu 0001;Xin Zhang,Xiaoru Yuan;Limei Che;Yifan Hu;Xin Zhang,"Key Laboratory of Machine Perception (Ministry of Education) and School of EECS, Center for Computational Science and Engineering, Peking University, China;Key Laboratory of Machine Perception (Ministry of Education) and School of EECS, Peking University, China;AT and T Laboratories, USA;Key Laboratory of Machine Perception (Ministry of Education) and School of EECS, Peking University, China",10.1109/tvcg.2008.155;10.1109/infvis.2005.1532130;10.1109/tvcg.2009.109;10.1109/tvcg.2007.70580;10.1109/tvcg.2008.155,"Graph layout, Laplacian matrix, force directed layout, stress model, merging, editing, crowd sourcing",41.0,28.0,33.0,753.0,,,graph layout algorithms;people crowd sourcing;laplacian constrained;interactive designed enable;meaningful,0.6619;0.4484;0.2033;0.1230;0.0184,"[np.int64(-1), -1, -1, -1, -1]",39;-1;-1;-1;-1,39,39
Vis,1994,Discretized Marching Cubes,10.1109/visual.1994.346308,http://dx.doi.org/10.1109/VISUAL.1994.346308,281.0,,C,"Since the introduction of standard techniques for isosurface extraction from volumetric datasets, one of the hardest problems has been to reduce the number of triangles (or polygons) generated. The paper presents an algorithm that considerably reduces the number of polygons generated by a Marching Cubes-like scheme (W. Lorensen and H. Cline, 1987) without excessively increasing the overall computational complexity. The algorithm assumes discretization of the dataset space and replaces cell edge interpolation by midpoint selection. Under these assumptions, the extracted surfaces are composed of polygons lying within a finite number of incidences, thus allowing simple merging of the output facets into large coplanar polygons. An experimental evaluation of the proposed approach on datasets related to biomedical imaging and chemical modelling is reported.&lt;&lt;ETX&gt;&gt;",Claudio Montani;Riccardo Scateni;Roberto Scopigno,C. Montani;R. Scateni;R. Scopigno,"IEI-Consiglio Nazionale delle Richerche, Pisa, Italy;Centro di Ricerca, Sviluppo e Studi Superiori Sardegna (CRSI), Cagliari, Italy;CNUCE-Consiglio Nazionale delle Ricerche, Pisa, Italy",10.1109/visual.1992.235223;10.1109/visual.1992.235223,,326.0,55.0,16.0,240.0,,,isosurface extraction volumetric;algorithm assumes discretization;polygons lying finite;datasets related biomedical;merging,0.7206;0.2637;0.2509;0.2260;0.0340,"[np.int64(-1), -1, -1, -1, -1]",229;-1;-1;-1;-1,229,229
Vis,1993,Visualizing results of transient flow simulations,10.1109/visual.1993.398896,http://dx.doi.org/10.1109/VISUAL.1993.398896,406.0,409.0,C,"This work briefly describes our approach to visualize results of transient flow simulations in the application areas of groundwater flow and pollutant transport as well as compressible fluid flow in engine parts. The simulations use finite element data structures and can have geometries which change over time. We designed a client-server model to handle the huge amount of data that can be obtained either directly from the simulation process or from files on disk. As standard visualization packages are not able to cope with transient unstructured data, we implemented streamlines, stream surfaces and particle systems as our main visualization methods. Our experiences and results with these techniques are discussed in this paper.&lt;&lt;ETX&gt;&gt;",Harald F. Mayer;Behnam Tabatabai,H.F. Mayer;B. Tabatabai,"Institute for Information Systems, Joanneum Research Forschungsgesellschaft GmbH, Graz, Austria;Institute for Information Systems, Joanneum Research Forschungsgesellschaft GmbH, Graz, Austria",10.1109/visual.1991.175771;10.1109/visual.1992.235211;10.1109/visual.1991.175771,,3.0,0.0,10.0,59.0,,,transient flow simulations;main visualization;groundwater flow pollutant;unstructured data;able,0.7088;0.2950;0.2761;0.2267;-0.0780,"[np.int64(-1), -1, -1, -1, -1]",47;-1;-1;-1;-1,47,47
Vis,2006,Diffusion Tensor Visualization with Glyph Packing,10.1109/tvcg.2006.134,http://dx.doi.org/10.1109/TVCG.2006.134,1329.0,1336.0,J,"A common goal of multivariate visualization is to enable data inspection at discrete points, while also illustrating larger-scale continuous structures. In diffusion tensor visualization, glyphs are typically used to meet the first goal, and methods such as texture synthesis or fiber tractography can address the second. We adapt particle systems originally developed for surface modeling and anisotropic mesh generation to enhance the utility of glyph-based tensor visualizations. By carefully distributing glyphs throughout the field (either on a slice, or in the volume) into a dense packing, using potential energy profiles shaped by the local tensor value, we remove undue visual emphasis of the regular sampling grid of the data, and the underlying continuous features become more apparent. The method is demonstrated on a DT-MRI scan of a patient with a brain tumor",Gordon L. Kindlmann;Carl-Fredrik Westin,Gordon Kindlmann;Carl-fredrik Westin,"Laboratory of Mathematics in Imaging, Department of Radiology, Brigham and Womens Hospital, Harvard Medical School, USA;Director of the Laboratory of Mathematics in Imaging, Department of Radiology, Brigham & Womens Hospital, Harvard Medical School, USA",10.1109/visual.2004.25;10.1109/visual.1998.745294;10.1109/visual.2004.80;10.1109/visual.2002.1183797;10.1109/visual.1995.485141;10.1109/visual.1999.809905;10.1109/visual.2003.1250379;10.1109/tvcg.2010.199;10.1109/visual.2004.25,"Diffusion tensor, glyphs, particle systems, anisotropic sampling, fiber tractography",157.0,78.0,50.0,1109.0,,,diffusion tensor visualization;glyphs field slice;packing using;enable data inspection;common goal,0.7689;0.2022;0.1479;0.0005;-0.0526,"[np.int64(-1), -1, -1, -1, -1]",289;-1;-1;-1;-1,289,289
SciVis,2020,Interactive Visual Study of Multiple Attributes Learning Model of X-Ray Scattering Images,10.1109/tvcg.2020.3030384,http://dx.doi.org/10.1109/TVCG.2020.3030384,1312.0,1321.0,J,"Existing interactive visualization tools for deep learning are mostly applied to the training, debugging, and refinement of neural network models working on natural images. However, visual analytics tools are lacking for the specific application of x-ray image classification with multiple structural attributes. In this paper, we present an interactive system for domain scientists to visually study the multiple attributes learning models applied to x-ray scattering images. It allows domain scientists to interactively explore this important type of scientific images in embedded spaces that are defined on the model prediction output, the actual labels, and the discovered feature space of neural networks. Users are allowed to flexibly select instance images, their clusters, and compare them regarding the specified visual representation of attributes. The exploration is guided by the manifestation of model performance related to mutual relationships among attributes, which often affect the learning accuracy and effectiveness. The system thus supports domain scientists to improve the training dataset and model, find questionable attributes labels, and identify outlier images or spurious data clusters. Case studies and scientists feedback demonstrate its functionalities and usefulness.",Xinyi Huang 0003;Suphanut Jamonnak;Ye Zhao 0003;Boyu Wang 0001;Minh Hoai;Kevin G. Yager;Wei Xu 0020,Xinyi Huang;Suphanut Jamonnak;Ye Zhao;Boyu Wang;Minh Hoai;Kevin Yager;Wei Xu,Kent State University;Kent State University;Kent State University;Stony Brook University;Stony Brook University;Brookhaven National Laboratory;Brookhaven National Laboratory,10.1109/tvcg.2017.2744718;10.1109/tvcg.2017.2744938;10.1109/tvcg.2016.2598831;10.1109/tvcg.2017.2744358;10.1109/tvcg.2016.2598838;10.1109/tvcg.2017.2744878;10.1109/tvcg.2018.2864500;10.1109/tvcg.2017.2744718,,4.0,5.0,41.0,541.0,,,visualization tools deep;attributes paper;ray scattering;prediction output actual;allowed,0.5703;0.2993;0.2052;0.1624;0.0301,"[np.int64(-1), -1, -1, -1, -1]",264;-1;-1;-1;-1,264,264
Vis,1995,IFS fractal interpolation for 2D and 3D visualization,10.1109/visual.1995.480798,http://dx.doi.org/10.1109/VISUAL.1995.480798,77.0,,C,"Reconstruction is used frequently in visualization of one, two, and three dimensional data. Data uncertainty is typically ignored, and a deficiency of many interpolation schemes is smoothing which may indicate features or characteristics of the data that are not there. The author investigates the use of iterated function systems (IFS's) for interpolation. He shows new derivations for fractal interpolation in two and three dimensional scalar data, and new point and polytope rendering algorithms with tremendous speed advantages over ray tracing. The interpolations may be used to give an indication of the uncertainty of the data, statistically represent the data at a variety of scales, allow tunability from the data, and may allow more accurate data analysis.",Craig M. Wittenbrink,C.M. Wittenbrink,"Computer Engineering & Information Sciences, University of California, Santa Cruz, Santa Cruz, CA, USA",0.1109/visual.1994.346285,,70.0,18.0,20.0,177.0,,,fractal interpolation;data uncertainty typically;used frequently visualization;iterated;advantages ray,0.7381;0.2790;0.2566;0.2038;0.0749,"[np.int64(-1), -1, -1, -1, -1]",101;-1;-1;-1;-1,101,101
InfoVis,2007,Visualizing the History of Living Spaces,10.1109/tvcg.2007.70621,http://dx.doi.org/10.1109/TVCG.2007.70621,1153.0,1160.0,J,"The technology available to building designers now makes it possible to monitor buildings on a very large scale. Video cameras and motion sensors are commonplace in practically every office space, and are slowly making their way into living spaces. The application of such technologies, in particular video cameras, while improving security, also violates privacy. On the other hand, motion sensors, while being privacy-conscious, typically do not provide enough information for a human operator to maintain the same degree of awareness about the space that can be achieved by using video cameras. We propose a novel approach in which we use a large number of simple motion sensors and a small set of video cameras to monitor a large office space. In our system we deployed 215 motion sensors and six video cameras to monitor the 3,000-square-meter office space occupied by 80 people for a period of about one year. The main problem in operating such systems is finding a way to present this highly multidimensional data, which includes both spatial and temporal components, to a human operator to allow browsing and searching recorded data in an efficient and intuitive way. In this paper we present our experiences and the solutions that we have developed in the course of our work on the system. We consider this work to be the first step in helping designers and managers of building systems gain access to information about occupants' behavior in the context of an entire building in a way that is only minimally intrusive to the occupants' privacy.",Yuri A. Ivanov;Christopher Richard Wren;Alexander Sorokin;Ishwinder Kaur,Yuri Ivanov;Christopher Wren;Alexander Sorokin;Ishwinder Kaur,"Mitsubishi Electric Research Laboratories, Inc., USA and Mitsubuishi Electric Research Labs;Mitsubishi Electric Research Laboratories, Inc., USA and Mitsubuishi Electric Research Labs;UIUC, USA;MIT Media Lab, USA",10.1109/infvis.2004.27;10.1109/infvis.2005.1532122;10.1109/infvis.2004.27,"Sensor networks, user interfaces, surveillance, timeline, spatio-temporal visualization",90.0,49.0,14.0,791.0,BP,,monitor buildings;privacy hand;allow browsing searching;multidimensional data includes;number simple motion,0.5874;0.2171;0.2098;0.1829;0.1677,"[np.int64(-1), -1, -1, -1, -1]",305;-1;-1;-1;-1,305,305
InfoVis,2016,Multi-Granular Trend Detection for Time-Series Analysis,10.1109/tvcg.2016.2598619,http://dx.doi.org/10.1109/TVCG.2016.2598619,661.0,670.0,J,"Time series (such as stock prices) and ensembles (such as model runs for weather forecasts) are two important types of one-dimensional time-varying data. Such data is readily available in large quantities but visual analysis of the raw data quickly becomes infeasible, even for moderately sized data sets. Trend detection is an effective way to simplify time-varying data and to summarize salient information for visual display and interactive analysis. We propose a geometric model for trend-detection in one-dimensional time-varying data, inspired by topological grouping structures for moving objects in two- or higher-dimensional space. Our model gives provable guarantees on the trends detected and uses three natural parameters: granularity, support-size, and duration. These parameters can be changed on-demand. Our system also supports a variety of selection brushes and a time-sweep to facilitate refined searches and interactive visualization of (sub-)trends. We explore different visual styles and interactions through which trends, their persistence, and evolution can be explored.",Arthur van Goethem;Frank Staals;Maarten Löffler;Jason Dykes;Bettina Speckmann,Goethem Arthur Van;Frank Staals;Maarten Löffler;Jason Dykes;Bettina Speckmann,"TU, Eindhoven;MADALGO, Aarhus University;Utrecht University;City University, London;TU, Eindhoven",10.1109/tvcg.2015.2467204;10.1109/tvcg.2010.181;10.1109/tvcg.2006.147;10.1109/tvcg.2014.2346448;10.1109/tvcg.2007.70558;10.1109/tvcg.2008.166;10.1109/tvcg.2008.125;10.1109/tvcg.2014.2346455;10.1109/tvcg.2015.2467204,Interactive Exploration;Trend Detection;Time Series,18.0,9.0,41.0,1372.0,,,visualization sub trends;brushes time;inspired topological;weather forecasts important;gives provable guarantees,0.6980;0.2568;0.2535;0.2159;0.0631,"[np.int64(-1), -1, -1, -1, -1]",162;-1;-1;-1;-1,162,162
Vis,1994,Visualization of an electric power transmission system,10.1109/visual.1994.346292,http://dx.doi.org/10.1109/VISUAL.1994.346292,379.0,,C,"Visualization techniques are applied to an electric power system transmission network to create a graphical picture of network power flows and voltages. A geographic data map is used. Apparent power flow is encoded as the width of an arrow, with direction from real power flow. Flows are superposed on flow limits. Contour plots and color coding failed for representing bus voltages. A two-color thermometer encoding worked well. The resulting visualization is a significant improvement over current user interface practice in the power industry.&lt;&lt;ETX&gt;&gt;",Pramod M. Mahadev;Richard D. Christie,P.M. Mahadev;R.D. Christie,"Department of Electrical Engineering, FT-10, University of Washington, Seattle, WA, USA;Department of Electrical Engineering, FT-10, University of Washington, Seattle, WA, USA",,,4.0,4.0,6.0,474.0,,,power flow flows;geographic data map;color thermometer encoding;failed representing bus;significant,0.6078;0.3449;0.2680;0.1812;0.0020,"[np.int64(-1), -1, -1, -1, -1]",277;-1;-1;-1;-1,277,277
InfoVis,1997,Managing multiple focal levels in Table Lens,10.1109/infvis.1997.636787,http://dx.doi.org/10.1109/INFVIS.1997.636787,59.0,63.0,C,"The Table Lens, focus+context visualization for large data tables, allows users to see 100 times as many data values as a spreadsheet in the same screen space in a manner that enables an extremely immediate form of exploratory data analysis. In the original Table Lens design, data are shown in the context area using graphical representations in a single pixel row. Scaling up the Table Lens technique beyond approximately 500 cases (rows) by 40 variables (columns) requires not showing every value individually and thus raises challenges for preserving the exploratory and navigational ease and power of the original design. We describe two design enhancements for introducing regions of less than a pixel row for each data value and discuss the issues raised by each.",Tichomir Tenev;Ramana Rao,T. Tenev;R. Rao,"Xerox Palo Alto Research Center, Inxight Software, Inc., Palo Alto, CA, USA;Xerox Palo Alto Research Center, Inxight Software, Inc., Palo Alto, CA, USA",,"Focus+Context, Fisheye, Information visualization, Table Lens",36.0,3.0,6.0,113.0,,,focus context visualization;spreadsheet screen;large data tables;value individually raises;power original design,0.6421;0.4517;0.4493;0.0821;0.0653,"[np.int64(-1), -1, -1, -1, -1]",-1;-1;-1;-1;-1,,-1
Vis,2021,Visualizing Uncertainty in Probabilistic Graphs with Network Hypothetical Outcome Plots (NetHOPs),10.1109/tvcg.2021.3114679,http://dx.doi.org/10.1109/TVCG.2021.3114679,443.0,453.0,J,"Probabilistic graphs are challenging to visualize using the traditional node-link diagram. Encoding edge probability using visual variables like width or fuzziness makes it difficult for users of static network visualizations to estimate network statistics like densities, isolates, path lengths, or clustering under uncertainty. We introduce Network Hypothetical Outcome Plots (NetHOPs), a visualization technique that animates a sequence of network realizations sampled from a network distribution defined by probabilistic edges. NetHOPs employ an aggregation and anchoring algorithm used in dynamic and longitudinal graph drawing to parameterize layout stability for uncertainty estimation. We present a community matching algorithm to enable visualizing the uncertainty of cluster membership and community occurrence. We describe the results of a study in which 51 network experts used NetHOPs to complete a set of common visual analysis tasks and reported how they perceived network structures and properties subject to uncertainty. Participants' estimates fell, on average, within 11% of the ground truth statistics, suggesting NetHOPs can be a reasonable approach for enabling network analysts to reason about multiple properties under uncertainty. Participants appeared to articulate the distribution of network statistics slightly more accurately when they could manipulate the layout anchoring and the animation speed. Based on these findings, we synthesize design recommendations for developing and using animated visualizations for probabilistic networks.",Dongping Zhang;Eytan Adar;Jessica Hullman,Dongping Zhang;Eytan Adar;Jessica Hullman,"Northwestern University, United States;University of Michigan, United States;Northwestern University, United States",10.1109/tvcg.2006.147;10.1109/tvcg.2017.2743898;10.1109/tvcg.2020.3030335;10.1109/tvcg.2018.2864909;10.1109/tvcg.2012.279;10.1109/tvcg.2016.2598919;10.1109/tvcg.2006.166;10.1109/tvcg.2013.232;10.1109/tvcg.2015.2467691;10.1109/tvcg.2011.227;10.1109/tvcg.2006.147,"Network,Uncertainty,Application",1.0,9.0,93.0,663.0,,,network visualizations;membership community occurrence;anchoring animation;properties subject uncertainty;average 11,0.7018;0.2561;0.2260;0.1852;0.0501,"[np.int64(-1), -1, -1, -1, -1]",169;-1;-1;-1;-1,169,169
Vis,2001,POP: A Hybrid Point and Polygon Rendering System for Large Data,10.1109/visual.2001.964492,http://doi.ieeecomputersociety.org/10.1109/VISUAL.2001.964492,45.0,52.0,C,"We introduce a simple but effective extension to the existing pure point rendering systems. Rather than using only points, we use both points and polygons to represent and render large mesh models. We start from triangles as leaf nodes and build up a hierarchical tree structure with intermediate nodes as points. During the rendering, the system determines whether to use a point (of a certain intermediate level node) or a triangle (of a leaf node) for display depending on the screen contribution of each node. While points are used to speedup the rendering of distant objects, triangles are used to ensure the quality of close objects. Our method can accelerate the rendering of large models, compromising little in image quality.",Baoquan Chen;Minh Xuan Nguye,Baoquan Chen;Minh Xuan Nguyen,"Department of Computer Science and Engineering, University of Minnesota at Twin Cities;Department of Computer Science and Engineering, University of Minnesota at Twin Cities",10.1109/visual.1998.745282;10.1109/visual.1998.745282,"Rendering system, Spatial data structures, Level of detail algorithms, hybrid rendering systems",157.0,21.0,33.0,80.0,,,point rendering systems;tree;models start;little image quality;introduce simple effective,0.6922;0.2508;0.1417;0.1401;0.0418,"[np.int64(-1), -1, -1, -1, -1]",62;-1;-1;-1;-1,62,62
Vis,2004,Rendering implicit flow volumes,10.1109/visual.2004.90,http://dx.doi.org/10.1109/VISUAL.2004.90,99.0,106.0,C,"Traditional flow volumes construct an explicit geometrical or parametrical representation from the vector field. The geometry is updated interactively and then rendered using an unstructured volume rendering technique. Unless a detailed refinement of the flow volume is specified for the interior, information inside the underlying flow volume is lost in the linear interpolation. These disadvantages can be avoided and/or alleviated using an implicit flow model. An implicit flow is a scalar field constructed such that any point in the field is associated with a termination surface using an advection operator on the flow. We present two techniques, a slice-based three-dimensional texture mapping and an interval volume segmentation coupled with a tetrahedron projection-based renderer, to render implicit stream flows. In the first method, the implicit flow representation is loaded as a 3D texture and manipulated using a dynamic texture operation that allows the flow to be investigated interactively. In our second method, a geometric flow volume is extracted from the implicit flow using a high dimensional isocontouring or interval volume routine. This provides a very detailed flow volume or set of flow volumes that can easily change topology, while retaining accurate characteristics within the flow volume. The advantages and disadvantages of these two techniques are compared with traditional explicit flow volumes.",Daqing Xue;Caixia Zhang;Roger Crawfis,D. Xue;C. Zhang;R. Crawfis,"Department of Computer Science and Engineering, The Ohio State University, USA;Department of Computer Science and Engineering, The Ohio State University and Ohio State University, Columbus, OH, US;Dept. of Comput. Sci. & Eng., Ohio State Univ., Columbus, OH, USA",10.1109/visual.2001.964519;10.1109/visual.1993.398846;10.1109/visual.2000.885688;10.1109/visual.1991.175789;10.1109/visual.2003.1250364;10.1109/visual.1992.235211;10.1109/visual.1996.567777;10.1109/visual.2000.885704;10.1109/visual.1999.809909;10.1109/visual.2003.1250376;10.1109/visual.2003.1250377;10.1109/visual.1993.398875;10.1109/visual.2003.1250378;10.1109/visual.1999.809892;10.1109/visual.1997.663886;10.1109/visual.1993.398877;10.1109/visual.1994.346315;10.1109/visual.1995.480807;10.1109/visual.2001.964519,"interval volume rendering, implicit stream flow, flow visualization, graphics hardware",33.0,5.0,35.0,182.0,,,unstructured volume rendering;stream flows;lost linear interpolation;techniques compared;associated termination,0.6622;0.4187;0.1154;0.1110;0.0250,"[np.int64(-1), -1, -1, -1, -1]",256;-1;-1;-1;-1,256,256
VAST,2013,Temporal Event Sequence Simplification,10.1109/tvcg.2013.200,http://dx.doi.org/10.1109/TVCG.2013.200,2227.0,2236.0,J,"Electronic Health Records (EHRs) have emerged as a cost-effective data source for conducting medical research. The difficulty in using EHRs for research purposes, however, is that both patient selection and record analysis must be conducted across very large, and typically very noisy datasets. Our previous work introduced EventFlow, a visualization tool that transforms an entire dataset of temporal event records into an aggregated display, allowing researchers to analyze population-level patterns and trends. As datasets become larger and more varied, however, it becomes increasingly difficult to provide a succinct, summarizing display. This paper presents a series of user-driven data simplifications that allow researchers to pare event records down to their core elements. Furthermore, we present a novel metric for measuring visual complexity, and a language for codifying disjoint strategies into an overarching simplification framework. These simplifications were used by real-world researchers to gain new and valuable insights from initially overwhelming datasets.",Megan Monroe;Rongjian Lan;Hanseung Lee;Catherine Plaisant;Ben Shneiderman,Megan Monroe;Rongjian Lan;Hanseung Lee;Catherine Plaisant;Ben Shneiderman,"University of Maryland, USA;University of Maryland, USA;University of Maryland, USA;University of Maryland, USA;University of Maryland, USA",10.1109/tvcg.2009.117;10.1109/tvcg.2012.213;10.1109/vast.2010.5652890,"Event sequences, simplification, electronic heath records, temporal query",318.0,199.0,33.0,2755.0,HM,,introduced eventflow visualization;data simplifications allow;ehrs emerged cost;medical research difficulty;electronic,0.5368;0.4818;0.2640;0.2579;0.1001,"[np.int64(-1), -1, -1, -1, -1]",301;-1;-1;-1;-1,301,301
VAST,2007,From Tasks to Tools: A Field Study in Collaborative Visual Analytics,10.1109/vast.2007.4389028,http://dx.doi.org/10.1109/VAST.2007.4389028,223.0,224.0,M,"This poster presents an exploratory field study of a VAST 2007 contest entry. We applied cognitive task analysis (CTA), grounded theory (GT), and activity theory (AT), to analysis of field notes and interviews from participants. Our results are described in the context of activity theory and sensemaking, two theoretical perspectives that we have found to be particularly useful in understanding analytic tasks.",Daniel Ha;Minjung Kim;Andrew Wade;William Chao;Kevin Ho;Linda T. Kaastra;Brian D. Fisher;John Dill,Daniel Ha;Minjung Kim;Andrew Wade;William O. Chao;Kevin Ho;Linda Kaastra;Brian Fisher;John Dill,"SIAT and University of British Columbia, MAGIC, Canada and Simon Fraser University, Canada;SIAT and University of British Columbia, MAGIC, Canada and Simon Fraser University, Canada;SIAT and University of British Columbia, MAGIC, Canada and Simon Fraser University, Canada;SIAT and University of British Columbia, MAGIC, Canada and Simon Fraser University, Canada;SIAT and University of British Columbia, MAGIC, Canada and Simon Fraser University, Canada;SIAT and University of British Columbia, MAGIC, Canada and Simon Fraser University, Canada;SIAT and University of British Columbia, MAGIC, Canada and Simon Fraser University, Canada;SIAT and University of British Columbia, MAGIC, Canada and Simon Fraser University, Canada",,,2.0,0.0,5.0,172.0,,,activity theory sensemaking;field notes interviews;contest entry;understanding analytic;cta grounded,0.6370;0.4652;0.2732;0.2500;0.1754,"[np.int64(-1), -1, -1, -1, -1]",86;-1;-1;-1;-1,86,86
SciVis,2014,Boundary Aware Reconstruction of Scalar Fields,10.1109/tvcg.2014.2346351,http://dx.doi.org/10.1109/TVCG.2014.2346351,2447.0,2455.0,J,"In visualization, the combined role of data reconstruction and its classification plays a crucial role. In this paper we propose a novel approach that improves classification of different materials and their boundaries by combining information from the classifiers at the reconstruction stage. Our approach estimates the targeted materials' local support before performing multiple material-specific reconstructions that prevent much of the misclassification traditionally associated with transitional regions and transfer function (TF) design. With respect to previously published methods our approach offers a number of improvements and advantages. For one, it does not rely on TFs acting on derivative expressions, therefore it is less sensitive to noisy data and the classification of a single material does not depend on specialized TF widgets or specifying regions in a multidimensional TF. Additionally, improved classification is attained without increasing TF dimensionality, which promotes scalability to multivariate data. These aspects are also key in maintaining low interaction complexity. The results are simple-to-achieve visualizations that better comply with the user's understanding of discrete features within the studied object.",Stefan Lindholm;Daniel Jönsson;Charles D. Hansen;Anders Ynnerman,Stefan Lindholm;Daniel Jönsson;Charles Hansen;Anders Ynnerman,"Department of Science and Technology, Linköping University;Department of Science and Technology, Linköping University;Scientific Computing and Imaging Institute, University of Utah;Department of Science and Technology, Linköping University",10.1109/tvcg.2007.70518;10.1109/tvcg.2008.186;10.1109/visual.2003.1250386;10.1109/visual.2005.1532807;10.1109/visual.1998.745311;10.1109/visual.2003.1250387;10.1109/tvcg.2007.70518,"Reconstruction, signal processing, kernel regression, volume rendering",12.0,9.0,27.0,484.0,,,material specific reconstructions;regions multidimensional;visualizations better comply;classification attained;transfer function tf,0.5786;0.3457;0.2534;0.2202;0.2193,"[np.int64(-1), -1, -1, -1, -1]",247;-1;-1;-1;-1,247,247
Vis,1998,Constrained optimal framings of curves and surfaces using quaternion Gauss maps,10.1109/visual.1998.745326,http://dx.doi.org/10.1109/VISUAL.1998.745326,375.0,382.0,C,"We propose a general paradigm for computing optimal coordinate frame fields that may be exploited to visualize curves and surfaces. Parallel transport framings, which work well for open curves, generally fail to have desirable properties for cyclic curves and for surfaces. We suggest that minimal quaternion measure provides an appropriate heuristic generalization of parallel transport. Our approach differs from minimal tangential acceleration approaches due to the addition of ""sliding ring"" constraints that fix one frame axis, but allow an axial rotational freedom whose value is varied in the optimization process. Our fundamental tool is the quaternion Gauss map, a generalization to quaternion space of the tangent map for curves and of the Gauss map for surfaces. The quaternion Gauss map takes 3D coordinate frame fields for curves and surfaces into corresponding curves and surfaces constrained to the space of possible orientations in quaternion space. Standard optimization tools provide application specific means of choosing optimal, e.g., length- or area-minimizing, quaternion frame fields in this constrained space.",Andrew J. Hanson,A.J. Hanson,"Computer Science Department, Indiana University, Bloomington, IN, USA",10.1109/visual.1994.346330;10.1109/visual.1997.663876;10.1109/visual.1994.346330,"Quaternions, Frames, Tubing, Curves, Surfaces",34.0,6.0,27.0,135.0,,,frame fields curves;area minimizing quaternion;map generalization;tools provide application;appropriate,0.6073;0.5310;0.2497;0.0780;0.0497,"[np.int64(-1), np.int64(-1), -1, -1, -1]",302;28;-1;-1;-1,28;302,302
InfoVis,2003,Compound brushing,10.1109/infvis.2003.1249024,http://dx.doi.org/10.1109/INFVIS.2003.1249024,181.0,188.0,C,"This paper proposes a conceptual model called compound brushing for modeling the brushing techniques used in dynamic data visualization. In this approach, brushing techniques are modeled as higraphs with five types of basic entities: data, selection, device, renderer, and transformation. Using this model, a flexible visual programming tool is designed not only to configure/control various common types of brushing techniques currently used in dynamic data visualization, but also to investigate new brushing techniques.",Hong Chen,Hong Chen,"Analytical Solutions Division, SAS Institute, Inc., USA",10.1109/visual.1995.485139;10.1109/infvis.2002.1173157;10.1109/infvis.2000.885092;10.1109/visual.1994.346302;10.1109/infvis.1996.559216;10.1109/visual.1995.485139,"brushing, selection, dynamic graphics, data visualization, higraph, visual programming, dynamic query",,0.0,17.0,252.0,,,visualization approach brushing;entities data selection;currently used dynamic;device renderer transformation;higraphs,0.7286;0.2867;0.2178;0.1914;0.1549,"[np.int64(-1), -1, -1, -1, -1]",323;-1;-1;-1;-1,323,323
SciVis,2012,A Data-Driven Approach to Hue-Preserving Color-Blending,10.1109/tvcg.2012.186,http://dx.doi.org/10.1109/TVCG.2012.186,2122.0,2129.0,J,"Color mapping and semitransparent layering play an important role in many visualization scenarios, such as information visualization and volume rendering. The combination of color and transparency is still dominated by standard alpha-compositing using the Porter-Duff over operator which can result in false colors with deceiving impact on the visualization. Other more advanced methods have also been proposed, but the problem is still far from being solved. Here we present an alternative to these existing methods specifically devised to avoid false colors and preserve visual depth ordering. Our approach is data driven and follows the recently formulated knowledge-assisted visualization (KAV) paradigm. Preference data, that have been gathered in web-based user surveys, are used to train a support-vector machine model for automatically predicting an optimized hue-preserving blending. We have applied the resulting model to both volume rendering and a specific information visualization technique, illustrative parallel coordinate plots. Comparative renderings show a significant improvement over previous approaches in the sense that false colors are completely removed and important properties such as depth ordering and blending vividness are better preserved. Due to the generality of the defined data-driven blending operator, it can be easily integrated also into other visualization frameworks.",Lars Kuehne;Joachim Giesen;Zhiyuan Zhang 0006;Sungsoo Ha;Klaus Mueller 0001,Lars Kühne;Joachim Giesen;Zhiyuan Zhang;Sungsoo Ha;Klaus Mueller,"Institute of Computer Science, Friedrich-Schiller-Universität Jena, Germany;Institute of Computer Science, Friedrich-Schiller-Universität Jena, Germany;Visual Analytics and Imaging Laboratory, Computer Science Department, Stony Brook University, USA;Visual Analytics and Imaging Laboratory, Computer Science Department, Stony Brook University, USA;Visual Analytics and Imaging Laboratory, Computer Science Department, Stony Brook University, USA",10.1109/tvcg.2009.150;10.1109/tvcg.2008.118;10.1109/tvcg.2007.70623;10.1109/tvcg.2012.234;10.1109/visual.2003.1250362;10.1109/tvcg.2009.150,"Color blending, hue preservation, knowledge-assisted visualization, volume rendering, parallel coordinates",19.0,14.0,24.0,674.0,,,knowledge assisted visualization;mapping semitransparent layering;color transparency dominated;resulting model volume;porter duff,0.5809;0.3523;0.3357;0.1622;0.0901,"[np.int64(-1), -1, -1, -1, -1]",274;-1;-1;-1;-1,274,274
InfoVis,2015,Vials: Visualizing Alternative Splicing of Genes,10.1109/tvcg.2015.2467911,http://dx.doi.org/10.1109/TVCG.2015.2467911,399.0,408.0,J,"Alternative splicing is a process by which the same DNA sequence is used to assemble different proteins, called protein isoforms. Alternative splicing works by selectively omitting some of the coding regions (exons) typically associated with a gene. Detection of alternative splicing is difficult and uses a combination of advanced data acquisition methods and statistical inference. Knowledge about the abundance of isoforms is important for understanding both normal processes and diseases and to eventually improve treatment through targeted therapies. The data, however, is complex and current visualizations for isoforms are neither perceptually efficient nor scalable. To remedy this, we developed Vials, a novel visual analysis tool that enables analysts to explore the various datasets that scientists use to make judgments about isoforms: the abundance of reads associated with the coding regions of the gene, evidence for junctions, i.e., edges connecting the coding regions, and predictions of isoform frequencies. Vials is scalable as it allows for the simultaneous analysis of many samples in multiple groups. Our tool thus enables experts to (a) identify patterns of isoform abundance in groups of samples and (b) evaluate the quality of the data. We demonstrate the value of our tool in case studies using publicly available datasets.",Hendrik Strobelt;Bilal Alsallakh;Joseph Botros;Brant Peterson;Mark Borowsky;Hanspeter Pfister;Alexander Lex,Hendrik Strobelt;Bilal Alsallakh;Joseph Botros;Brant Peterson;Mark Borowsky;Hanspeter Pfister;Alexander Lex,"Harvard University;Vienna University of Technology;Harvard University;Institute of BioMedical Research;Institute of BioMedical Research;Harvard University;Harvard University, University of Utah",10.1109/tvcg.2013.214;10.1109/tvcg.2013.223;10.1109/tvcg.2014.2346248;10.1109/tvcg.2013.214,"Biology visualization, protein isoforms, mRNA-seq, directed acyclic graphs, multivariate networks",15.0,20.0,30.0,1005.0,,,isoforms alternative splicing;visual analysis;targeted therapies data;using publicly;eventually,0.5529;0.3664;0.2864;0.0860;0.0222,"[np.int64(-1), -1, -1, -1, -1]",16;-1;-1;-1;-1,16,16
InfoVis,2017,What Would a Graph Look Like in this Layout? A Machine Learning Approach to Large Graph Visualization,10.1109/tvcg.2017.2743858,http://dx.doi.org/10.1109/TVCG.2017.2743858,478.0,488.0,J,"Using different methods for laying out a graph can lead to very different visual appearances, with which the viewer perceives different information. Selecting a “good” layout method is thus important for visualizing a graph. The selection can be highly subjective and dependent on the given task. A common approach to selecting a good layout is to use aesthetic criteria and visual inspection. However, fully calculating various layouts and their associated aesthetic metrics is computationally expensive. In this paper, we present a machine learning approach to large graph visualization based on computing the topological similarity of graphs using graph kernels. For a given graph, our approach can show what the graph would look like in different layouts and estimate their corresponding aesthetic metrics. An important contribution of our work is the development of a new framework to design graph kernels. Our experimental study shows that our estimation calculation is considerably faster than computing the actual layouts and their aesthetic metrics. Also, our graph kernels outperform the state-of-the-art ones in both time and accuracy. In addition, we conducted a user study to demonstrate that the topological similarity computed with our graph kernel matches perceptual similarity assessed by human users.",Oh-Hyun Kwon;Tarik Crnovrsanin;Kwan-Liu Ma,Oh-Hyun Kwon;Tarik Crnovrsanin;Kwan-Liu Ma,"University of California, Davis;University of California, Davis;University of California, Davis",10.1109/tvcg.2016.2598467;10.1109/tvcg.2007.70580;10.1109/tvcg.2015.2467451;10.1109/infvis.2002.1173159;10.1109/tvcg.2008.158;10.1109/tvcg.2008.155;10.1109/tvcg.2016.2598867;10.1109/tvcg.2016.2598467,"Graph visualization,graph layout,aesthetics,machine learning,graph kernel,graphlet",70.0,55.0,92.0,2529.0,,,similarity graphs;actual layouts aesthetic;kernel;study shows estimation;expensive paper present,0.5977;0.4174;0.2571;0.0165;-0.0037,"[np.int64(-1), -1, -1, -1, -1]",139;-1;-1;-1;-1,139,139
Vis,2010,Interactive Vector field Feature Identification,10.1109/tvcg.2010.170,http://dx.doi.org/10.1109/TVCG.2010.170,1560.0,1568.0,J,"We introduce a flexible technique for interactive exploration of vector field data through classification derived from user-specified feature templates. Our method is founded on the observation that, while similar features within the vector field may be spatially disparate, they share similar neighborhood characteristics. Users generate feature-based visualizations by interactively highlighting well-accepted and domain specific representative feature points. Feature exploration begins with the computation of attributes that describe the neighborhood of each sample within the input vector field. Compilation of these attributes forms a representation of the vector field samples in the attribute space. We project the attribute points onto the canonical 2D plane to enable interactive exploration of the vector field using a painting interface. The projection encodes the similarities between vector field points within the distances computed between their associated attribute points. The proposed method is performed at interactive rates for enhanced user experience and is completely flexible as showcased by the simultaneous identification of diverse feature types.",Joel Daniels II;Erik W. Anderson;Luis Gustavo Nonato;Cláudio T. Silva,Joel Daniels II;Erik W. Anderson;Luis Gustavo Nonato;Claudio T. Silva,"School of Computing and Scientific Computing and Imaging Institute, University of Utah, USA;School of Computing and Scientific Computing and Imaging Institute, University of Utah, USA;Instituto de Ciências Matemáticas e de Computação, Universidade de Sáo Paulo, Brazil;School of Computing and Scientific Computing and Imaging Institute, University of Utah, USA",10.1109/tvcg.2009.138;10.1109/visual.1993.398846;10.1109/tvcg.2007.70579;10.1109/visual.1991.175794;10.1109/visual.1998.745333;10.1109/visual.1992.235211;10.1109/tvcg.2008.116;10.1109/tvcg.2009.190;10.1109/visual.1999.809917;10.1109/visual.1997.663910;10.1109/visual.1998.745296;10.1109/visual.1991.175771;10.1109/visual.2000.885690;10.1109/visual.2000.885689;10.1109/tvcg.2009.138,"Vector field, data clustering, feature classification, high-dimensional data, user interaction",57.0,31.0,46.0,717.0,,,feature based visualizations;vector field using;points canonical 2d;experience completely;derived user specified,0.6299;0.4389;0.2090;0.1126;-0.0081,"[np.int64(-1), -1, -1, -1, -1]",274;-1;-1;-1;-1,274,274
VAST,2018,EmbeddingVis: A Visual Analytics Approach to Comparative Network Embedding Inspection,10.1109/vast.2018.8802454,http://dx.doi.org/10.1109/VAST.2018.8802454,48.0,59.0,C,"Constructing latent vector representation for nodes in a network through embedding models has shown its practicality in many graph analysis applications, such as node classification, clustering, and link prediction. However, despite the high efficiency and accuracy of learning an embedding model, people have little clue of what information about the original network is preserved in the embedding vectors. The abstractness of low-dimensional vector representation, stochastic nature of the construction process, and non-transparent hyper-parameters all obscure understanding of network embedding results. Visualization techniques have been introduced to facilitate embedding vector inspection, usually by projecting the embedding space to a two-dimensional display. Although the existing visualization methods allow simple examination of the structure of embedding space, they cannot support in-depth exploration of the embedding vectors. In this paper, we design an exploratory visual analytics system that supports the comparative visual interpretation of embedding vectors at the cluster, instance, and structural levels. To be more specific, it facilitates comparison of what and how node metrics are preserved across different embedding models and investigation of relationships between node metrics and selected embedding vectors. Several case studies confirm the efficacy of our system. Experts' feedback suggests that our approach indeed helps them better embrace the understanding of network embedding models.",Quan Li;Kristanto Sean Njotoprawiro;Hammad Haleem;Qiaoan Chen;Chris Yi;Xiaojuan Ma,Quan Li;Kristanto Sean Njotoprawiro;Hammad Haleem;Qiaoan Chen;Chris Yi;Xiaojuan Ma,"Department of Computer Science and Engineering, The Hong Kong University of Science and Technology, Hong Kong;Department of Computer Science and Engineering, The Hong Kong University of Science and Technology, Hong Kong;Department of Computer Science and Engineering, The Hong Kong University of Science and Technology, Hong Kong;WeChat, Tencent Technology (Shenzhen) Co., Ltd., Shenzhen, China;WeChat, Tencent Technology (Shenzhen) Co., Ltd., Shenzhen, China;Department of Computer Science and Engineering, The Hong Kong University of Science and Technology, Hong Kong",10.1109/tvcg.2007.70521;10.1109/tvcg.2013.173;10.1109/visual.1990.146402;10.1109/tvcg.2016.2598415;10.1109/tvcg.2017.2745141;10.1109/tvcg.2016.2598838;10.1109/tvcg.2015.2468151;10.1109/tvcg.2007.70521,"Human-centered computing,Visualization,Visualization application domains,Visual analytics,Human-centered computing,Visualization,Visualization design and evaluation methods",37.0,34.0,52.0,824.0,,,network embedding results;visual analytics;vectors abstractness;non transparent hyper;practicality,0.6648;0.4843;0.2603;0.0955;0.0498,"[np.int64(-1), np.int64(-1), -1, -1, -1]",32;201;-1;-1;-1,32;201,32
InfoVis,1997,Adaptive information visualization based on the user's multiple viewpoints - interactive 3D visualization of the WWW,10.1109/infvis.1997.636778,http://dx.doi.org/10.1109/INFVIS.1997.636778,25.0,28.0,C,"We introduce the adaptive information visualization method for hypermedia and the WWW based on the user's multiple viewpoints. We propose two graphical interfaces, the CVI and the RF-Cone. The CVI is the interface for interactive viewpoint selection. We can select a viewpoint reflecting our interests by using the CVI. According to the given viewpoint, the RF-Cone adaptively organizes the 3D representation of the hypermedia so that we can understand the semantic and structural relationship of the hypermedia and easily retrieve the information. Combining these methods, we have developed the WWW visualization system which can provide highly efficient navigation.",Teruhiko Teraoka;Minoru Maruyama,T. Teraoka;M. Maruyama,"Advanced Technology R&D Center, Mitsubishi Electric Corporation Limited, Amagasaki, Japan;Faculty of Engineering, Shinshu University, Nagano, Japan",0.1109/infvis.1995.528696,,29.0,2.0,10.0,160.0,,,www visualization;adaptively organizes 3d;multiple viewpoints propose;cone cvi;easily,0.7056;0.3996;0.1849;0.1574;0.0052,"[np.int64(-1), -1, -1, -1, -1]",178;-1;-1;-1;-1,178,178
SciVis,2015,Multi-field Pattern Matching based on Sparse Feature Sampling,10.1109/tvcg.2015.2467292,http://dx.doi.org/10.1109/TVCG.2015.2467292,807.0,816.0,J,"We present an approach to pattern matching in 3D multi-field scalar data. Existing pattern matching algorithms work on single scalar or vector fields only, yet many numerical simulations output multi-field data where only a joint analysis of multiple fields describes the underlying phenomenon fully. Our method takes this into account by bundling information from multiple fields into the description of a pattern. First, we extract a sparse set of features for each 3D scalar field using the 3D SIFT algorithm (Scale-Invariant Feature Transform). This allows for a memory-saving description of prominent features in the data with invariance to translation, rotation, and scaling. Second, the user defines a pattern as a set of SIFT features in multiple fields by e.g. brushing a region of interest. Third, we locate and rank matching patterns in the entire data set. Experiments show that our algorithm is efficient in terms of required memory and computational efforts.",Zhongjie Wang 0001;Hans-Peter Seidel;Tino Weinkauf,Zhongjie Wang;Hans-Peter Seidel;Tino Weinkauf,"MPI for Informatics, Saarbrücken, Germany;MPI for Informatics, Saarbrücken, Germany;KTH Royal Institute of Technology, Stockholm, Sweden",10.1109/visual.2003.1250372;10.1109/tvcg.2009.141;10.1109/tvcg.2006.165;10.1109/tvcg.2007.70579;10.1109/tvcg.2014.2346332;10.1109/tvcg.2011.236;10.1109/visual.2003.1250372,"Pattern matching, multi-field visualization",19.0,9.0,36.0,825.0,,,pattern matching 3d;fields describes underlying;rotation scaling second;memory saving;work single,0.6876;0.2441;0.1842;0.1358;-0.0166,"[np.int64(-1), -1, -1, -1, -1]",286;-1;-1;-1;-1,286,286
InfoVis,2012,Graphical Overlays: Using Layered Elements to Aid Chart Reading,10.1109/tvcg.2012.229,http://dx.doi.org/10.1109/TVCG.2012.229,2631.0,2638.0,J,"Reading a visualization can involve a number of tasks such as extracting, comparing or aggregating numerical values. Yet, most of the charts that are published in newspapers, reports, books, and on the Web only support a subset of these tasks. In this paper we introduce graphical overlays-visual elements that are layered onto charts to facilitate a larger set of chart reading tasks. These overlays directly support the lower-level perceptual and cognitive processes that viewers must perform to read a chart. We identify five main types of overlays that support these processes; the overlays can provide (1) reference structures such as gridlines, (2) highlights such as outlines around important marks, (3) redundant encodings such as numerical data labels, (4) summary statistics such as the mean or max and (5) annotations such as descriptive text for context. We then present an automated system that applies user-chosen graphical overlays to existing chart bitmaps. Our approach is based on the insight that generating most of these graphical overlays only requires knowing the properties of the visual marks and axes that encode the data, but does not require access to the underlying data values. Thus, our system analyzes the chart bitmap to extract only the properties necessary to generate the desired overlay. We also discuss techniques for generating interactive overlays that provide additional controls to viewers. We demonstrate several examples of each overlay type for bar, pie and line charts.",Nicholas Kong;Maneesh Agrawala,Nicholas Kong;Maneesh Agrawala,"Computer Science Division, University of California, Berkeley, USA;Computer Science Division, University of California, Berkeley, USA",10.1109/tvcg.2011.242;10.1109/visual.1991.175820;10.1109/tvcg.2009.122;10.1109/tvcg.2011.183;10.1109/tvcg.2011.242,"Visualization, overlays, graphical perception, graph comprehension",79.0,58.0,38.0,2049.0,,,chart bitmaps;overlays provide additional;techniques generating interactive;read;require access underlying,0.6422;0.3389;0.3214;0.1545;0.0397,"[np.int64(-1), -1, -1, -1, -1]",113;-1;-1;-1;-1,113,113
InfoVis,2010,OpinionSeer: Interactive Visualization of Hotel Customer Feedback,10.1109/tvcg.2010.183,http://dx.doi.org/10.1109/TVCG.2010.183,1109.0,1118.0,J,"The rapid development of Web technology has resulted in an increasing number of hotel customers sharing their opinions on the hotel services. Effective visual analysis of online customer opinions is needed, as it has a significant impact on building a successful business. In this paper, we present OpinionSeer, an interactive visualization system that could visually analyze a large collection of online hotel customer reviews. The system is built on a new visualization-centric opinion mining technique that considers uncertainty for faithfully modeling and analyzing customer opinions. A new visual representation is developed to convey customer opinions by augmenting well-established scatterplots and radial visualization. To provide multiple-level exploration, we introduce subjective logic to handle and organize subjective opinions with degrees of uncertainty. Several case studies illustrate the effectiveness and usefulness of OpinionSeer on analyzing relationships among multiple data dimensions and comparing opinions of different groups. Aside from data on hotel customer feedback, OpinionSeer could also be applied to visually analyze customer opinions on other products or services.",Yingcai Wu;Furu Wei;Shixia Liu;Norman Au;Weiwei Cui;Hong Zhou 0004;Huamin Qu,Yingcai Wu;Furu Wei;Shixia Liu;Norman Au;Weiwei Cui;Hong Zhou;Huamin Qu,"Department of Computer Science and Engineering, Hong Kong University of Science and Technology, Hong Kong, China;IBM China Research Laboratory, Beijing, China;IBM China Research Laboratory, Beijing, China;School of Hotel & Tourism Management, Hong Kong PolyTechnic University, Hong Kong, China;Department of Computer Science and Engineering, Hong Kong University of Science and Technology, Hong Kong, China;Shenzhen University, Shenzhen, China;Department of Computer Science and Engineering, Hong Kong University of Science and Technology, Hong Kong, China",10.1109/vast.2006.261431;10.1109/tvcg.2009.171;10.1109/vast.2009.5332611;10.1109/tvcg.2008.187;10.1109/vast.2009.5333919;10.1109/infvis.2002.1173151;10.1109/vast.2006.261431,"opinion visualization, radial visualization, uncertainty visualization",233.0,117.0,31.0,3364.0,,,opinionseer interactive visualization;increasing number hotel;case studies illustrate;uncertainty faithfully modeling;new,0.7115;0.2154;0.1419;0.1084;0.0642,"[np.int64(-1), -1, -1, -1, -1]",148;-1;-1;-1;-1,148,148
Vis,2023,Explore Your Network in Minutes: A Rapid Prototyping Toolkit for Understanding Neural Networks with Visual Analytics,10.1109/tvcg.2023.3326575,http://dx.doi.org/10.1109/TVCG.2023.3326575,683.0,693.0,J,"Neural networks attract significant attention in almost every field due to their widespread applications in various tasks. However, developers often struggle with debugging due to the black-box nature of neural networks. Visual analytics provides an intuitive way for developers to understand the hidden states and underlying complex transformations in neural networks. Existing visual analytics tools for neural networks have been demonstrated to be effective in providing useful hints for debugging certain network architectures. However, these approaches are often architecture-specific with strong assumptions of how the network should be understood. This limits their use when the network architecture or the exploration goal changes. In this paper, we present a general model and a programming toolkit, Neural Network Visualization Builder (NNVisBuilder), for prototyping visual analytics systems to understand neural networks. NNVisBuilder covers the common data transformation and interaction model involved in existing tools for exploring neural networks. It enables developers to customize a visual analytics interface for answering their specific questions about networks. NNVisBuilder is compatible with PyTorch so that developers can integrate the visualization code into their learning code seamlessly. We demonstrate the applicability by reproducing several existing visual analytics systems for networks with NNVisBuilder. The source code and some example cases can be found at https://github.com/sysuvis/NVB.",Shaoxuan Lai;Wanna Luan;Jun Tao 0002,Shaoxuan Lai;Wanna Luan;Jun Tao,"School of Computer Science and Engineering, Sun Yat-sen University, China;School of Computer Science and Engineering, Sun Yat-sen University, China;School of Computer Science and Engineering, Sun Yat-sen University, National Supercomputer Center, Guangzhou, China",0.1109/tvcg.2011.185;10.1109/tvcg.2020.3030342;10.1109/tvcg.2019.2934537;10.1109/tvcg.2020.3030453;10.1109/vast.2018.8802509;10.1109/tvcg.2016.2598831;10.1109/vast.2017.8585721;10.1109/tvcg.2016.2599030;10.1109/tvcg.2015.2467091;10.1109/tvcg.2018.2865044;10.1109/tvcg.2017.2744158;10.1109/visual.2005.1532820;10.1109/tvcg.2020.3030418,"Visualization model,toolkit,neural networks,visual diagnosis",,0.0,50.0,590.0,,,neural network visualization;nnvisbuilder compatible pytorch;enables developers;struggle debugging black;understood limits use,0.6728;0.3748;0.2172;0.1465;0.0624,"[np.int64(-1), -1, -1, -1, -1]",135;-1;-1;-1;-1,135,135
VAST,2010,Anomaly detection in GPS data based on visual analytics,10.1109/vast.2010.5652467,http://dx.doi.org/10.1109/VAST.2010.5652467,51.0,58.0,C,"Modern machine learning techniques provide robust approaches for data-driven modeling and critical information extraction, while human experts hold the advantage of possessing high-level intelligence and domain-specific expertise. We combine the power of the two for anomaly detection in GPS data by integrating them through a visualization and human-computer interaction interface. In this paper we introduce GPSvas (GPS Visual Analytics System), a system that detects anomalies in GPS data using the approach of visual analytics: a conditional random field (CRF) model is used as the machine learning component for anomaly detection in streaming GPS traces. A visualization component and an interactive user interface are built to visualize the data stream, display significant analysis results (i.e., anomalies or uncertain predications) and hidden information extracted by the anomaly detection model, which enable human experts to observe the real-time data behavior and gain insights into the data flow. Human experts further provide guidance to the machine learning model through the interaction tools; the learning model is then incrementally improved through an active learning procedure.",Zicheng Liao;Yizhou Yu;Baoquan Chen,Zicheng Liao;Yizhou Yu;Baoquan Chen,"University of Illinois, Urbana, USA;University of Illinois, Urbana, USA;Shenzhen Institutes of Advanced Technology, Chinese Academy and Sciences, China",10.1109/tvcg.2009.145;10.1109/tvcg.2009.145,,96.0,68.0,28.0,1843.0,,,anomaly detection gps;active learning;interface built visualize;field crf model;possessing high level,0.6838;0.2964;0.2414;0.2148;0.0985,"[np.int64(-1), -1, -1, -1, -1]",234;-1;-1;-1;-1,234,234
Vis,2001,Visualization and interaction techniques for the exploration of vascular structures,10.1109/visual.2001.964538,http://dx.doi.org/10.1109/VISUAL.2001.964538,395.0,402.0,C,"We describe a pipeline of image processing steps for deriving symbolic models of vascular structures from radiological data which reflect the branching pattern and diameter of vessels. For the visualization of these symbolic models, concatenated truncated cones are smoothly blended at branching points. We put emphasis on the quality of the visualizations which is achieved by anti-aliasing operations in different stages of the visualization. The methods presented are referred to as HQVV (high quality vessel visualization). Scalable techniques are provided to explore vascular structures of different orders of magnitude. The hierarchy as well as the diameter of the branches of vascular systems are used to restrict visualizations to relevant subtrees and to emphasize parts of vascular systems. Our research is inspired by clear visualizations in textbooks and is targeted toward medical education and therapy planning. We describe the application of vessel visualization techniques for liver surgery planning. For this application it is crucial to recognize the morphology and branching pattern of vascular systems as well as the basic spatial relations between vessels and other anatomic structures.",Horst K. Hahn;Bernhard Preim;Dirk Selle;Heinz-Otto Peitgen,H.K. Hahn;B. Preim;D. Selle;H.-O. Peitgen,"MeVis Center for Medical Diagnostic Systems and Visualization, Bremen, Germany;MeVis Center for Medical Diagnostic Systems and Visualization, Bremen, Germany;MeVis Center for Medical Diagnostic Systems and Visualization, Bremen, Germany;MeVis Center for Medical Diagnostic Systems and Visualization, Bremen, Germany",10.1109/visual.1997.663917,"vessel visualization, medical visualization, computer-assisted surgery",162.0,48.0,22.0,728.0,,,vessel visualization;liver surgery;planning application;concatenated truncated;relevant,0.7408;0.3021;0.1245;0.0525;-0.0014,"[np.int64(-1), -1, -1, -1, -1]",133;-1;-1;-1;-1,133,133
Vis,2022,The State of the Art in BGP Visualization Tools: A Mapping of Visualization Techniques to Cyberattack Types,10.1109/tvcg.2022.3209412,http://dx.doi.org/10.1109/TVCG.2022.3209412,1059.0,1069.0,J,"Internet routing is largely dependent on Border Gateway Protocol (BGP). However, BGP does not have any inherent authentication or integrity mechanisms that help make it secure. Effective security is challenging or infeasible to implement due to high costs, policy employment in these distributed systems, and unique routing behavior. Visualization tools provide an attractive alternative in lieu of traditional security approaches. Several BGP security visualization tools have been developed as a stop-gap in the face of ever-present BGP attacks. Even though the target users, tasks, and domain remain largely consistent across such tools, many diverse visualization designs have been proposed. The purpose of this study is to provide an initial formalization of methods and visualization techniques for BGP cybersecurity analysis. Using PRISMA guidelines, we provide a systematic review and survey of 29 BGP visualization tools with their tasks, implementation techniques, and attacks and anomalies that they were intended for. We focused on BGP visualization tools as the main inclusion criteria to best capture the visualization techniques used in this domain while excluding solely algorithmic solutions and other detection tools that do not involve user interaction or interpretation. We take the unique approach of connecting (1) the actual BGP attacks and anomalies used to validate existing tools with (2) the techniques employed to detect them. In this way, we contribute an analysis of which techniques can be used for each attack type. Furthermore, we can see the evolution of visualization solutions in this domain as new attack types are discovered. This systematic review provides the groundwork for future designers and researchers building visualization tools for providing BGP cybersecurity, including an understanding of the state-of-the-art in this space and an analysis of what techniques are appropriate for each attack type. Our novel security visualization survey methodology—connecting visualization techniques with appropriate attack types—may also assist future researchers conducting systematic reviews of security visualizations. All supplemental materials are available at https://osf.io/tupz6/.",Justin Raynor;Tarik Crnovrsanin;Sara Di Bartolomeo;Laura South;David Saffo;Cody Dunne,Justin Raynor;Tarik Crnovrsanin;Sara Di Bartolomeo;Laura South;David Saffo;Cody Dunne,"Northeastern University, USA;Northeastern University, USA;Northeastern University, USA;Northeastern University, USA;Northeastern University, USA;Northeastern University, USA",10.1109/tvcg.2006.185;10.1109/tvcg.2012.213;10.1109/visual.2002.1183816;10.1109/visual.2003.1250415;10.1109/tvcg.2006.185,"Visualization,Security,Routing,Systematics,Task analysis,Anomaly detection,Focusing",,3.0,82.0,917.0,,X,bgp security visualization;users tasks;used domain excluding;systematic reviews;infeasible implement high,0.8409;0.0824;0.0776;0.0516;0.0046,"[np.int64(-1), -1, -1, -1, -1]",166;-1;-1;-1;-1,166,166
VAST,2011,Automated measures for interpretable dimensionality reduction for visual classification: A user study,10.1109/vast.2011.6102474,http://dx.doi.org/10.1109/VAST.2011.6102474,281.0,282.0,M,"This paper studies the interpretability of transformations of labeled higher dimensional data into a 2D representation (scatterplots) for visual classification.&lt;sup&gt;1&lt;/sup&gt;In this context, the term interpretability has two components: the interpretability of the visualization (the image itself) and the interpretability of the visualization axes (the data transformation functions). We define a data transformation function as any linear or non-linear function of the original variables mapping the data into 1D. Even for a small dataset, the space of possible data transformations is beyond the limit of manual exploration, therefore it is important to develop automated techniques that capture both aspects of interpretability so that they can be used to guide the search process without human intervention. The goal of the search process is to find a smaller number of interpretable data transformations for the users to explore. We briefly discuss how we used such automated measures in an evolutionary computing based data dimensionality reduction application for visual analytics. In this paper, we present a two-part user study in which we separately investigated how humans rated the visualizations of labeled data and comprehensibility of mathematical expressions that could be used as data transformation functions. In the first part, we compared human perception with a number of automated measures from the machine learning and visual analytics literature. In the second part, we studied how various structural properties of an expression related to its interpretability.",Ilknur Icke;Andrew Rosenberg,Ilknur Icke;Andrew Rosenberg,"The Graduate Center, City University of New York, USA;The Graduate Center, City University of New York, USA and Queens College, City University of New York, USA",,,7.0,2.0,8.0,253.0,,,interpretability visualization axes;evolutionary computing based;1d small dataset;transformation function linear;define,0.7003;0.3490;0.2452;0.1498;0.0988,"[np.int64(-1), -1, -1, -1, -1]",271;-1;-1;-1;-1,271,271
Vis,2010,Scalable Multi-variate Analytics of Seismic and Satellite-based Observational Data,10.1109/tvcg.2010.192,http://dx.doi.org/10.1109/TVCG.2010.192,1413.0,1420.0,J,"Over the past few years, large human populations around the world have been affected by an increase in significant seismic activities. For both conducting basic scientific research and for setting critical government policies, it is crucial to be able to explore and understand seismic and geographical information obtained through all scientific instruments. In this work, we present a visual analytics system that enables explorative visualization of seismic data together with satellite-based observational data, and introduce a suite of visual analytical tools. Seismic and satellite data are integrated temporally and spatially. Users can select temporal ;and spatial ranges to zoom in on specific seismic events, as well as to inspect changes both during and after the events. Tools for designing high dimensional transfer functions have been developed to enable efficient and intuitive comprehension of the multi-modal data. Spread-sheet style comparisons are used for data drill-down as well as presentation. Comparisons between distinct seismic events are also provided for characterizing event-wise differences. Our system has been designed for scalability in terms of data size, complexity (i.e. number of modalities), and varying form factors of display environments.",Xiaoru Yuan;He Xiao;Hanqi Guo 0001;Peihong Guo;Wesley Kendall;Jian Huang 0007;Yongxian Zhang,Xiaoru Yuan;He Xiao;Hanqi Guo;Peihong Guo;Wesley Kendall;Jian Huang;Yongxian Zhang,"Key Laboratory of Machine Perception (Ministry of Education), and School of EECS, Peking University, China;Peking University, Beijing, Beijing, CN;Key Laboratory of Machine Perception (Ministry of Education), and School of EECS, Peking University, China;Key Laboratory of Machine Perception (Ministry of Education), and School of EECS, Peking University, China;Department of Electrical Engineering & Computer Science, University of Tennessee, USA;Key Laboratory of Machine Perception (Ministry of Education), and School of EECS, Peking University, China;China Earthquake Networks Center, China",10.1109/tvcg.2009.179;10.1109/visual.2003.1250412;10.1109/visual.1990.146402;10.1109/visual.2002.1183814;10.1109/tvcg.2008.170;10.1109/tvcg.2008.184;10.1109/tvcg.2009.179,"Earth Science Visualization, Multivariate Visualization, Seismic Data, Scalable Visualization",36.0,17.0,36.0,863.0,,,visualization seismic data;populations world affected;multi modal;size;functions developed enable,0.7594;0.2516;0.1439;0.0996;0.0297,"[np.int64(-1), -1, -1, -1, -1]",77;-1;-1;-1;-1,77,77
Vis,2006,Interactive Point-Based Rendering of Higher-Order Tetrahedral Data,10.1109/tvcg.2006.154,http://dx.doi.org/10.1109/TVCG.2006.154,1229.0,1236.0,J,"Computational simulations frequently generate solutions defined over very large tetrahedral volume meshes containing many millions of elements. Furthermore, such solutions may often be expressed using non-linear basis functions. Certain solution techniques, such as discontinuous Galerkin methods, may even produce non-conforming meshes. Such data is difficult to visualize interactively, as it is far too large to fit in memory and many common data reduction techniques, such as mesh simplification, cannot be applied to non-conforming meshes. We introduce a point-based visualization system for interactive rendering of large, potentially non-conforming, tetrahedral meshes. We propose methods for adaptively sampling points from non-linear solution data and for decimating points at run time to fit GPU memory limits. Because these are streaming processes, memory consumption is independent of the input size. We also present an order-independent point rendering method that can efficiently render volumes on the order of 20 million tetrahedra at interactive rates",Yuan Zhou 0012;Michael Garland,Yuan Zhou;Michael Garland,"Department of Computer Science, University of Illinois, Urbana-Champaign, USA;NVIDIA Corporation, USA",10.1109/visual.2003.1250406;10.1109/visual.2005.1532796;10.1109/visual.2005.1532776;10.1109/visual.2005.1532809;10.1109/visual.2003.1250404;10.1109/visual.2002.1183757;10.1109/visual.2002.1183771;10.1109/visual.2004.91;10.1109/visual.2003.1250390;10.1109/visual.1999.809868;10.1109/visual.2004.38;10.1109/visual.2003.1250384;10.1109/visual.2000.885683;10.1109/visual.2002.1183778;10.1109/visual.2005.1532808;10.1109/visual.2003.1250389;10.1109/visual.1995.480790;10.1109/visual.2004.81;10.1109/visual.2005.1532801;10.1109/visual.2004.102;10.1109/visual.2003.1250406,"Interactive large higher-order tetrahedral volume visualization, point-based visualization",47.0,21.0,35.0,248.0,,,tetrahedral volume meshes;adaptively sampling points;method efficiently render;millions elements;potentially non conforming,0.7002;0.2968;0.2529;0.2473;-0.0384,"[np.int64(-1), -1, -1, -1, -1]",286;-1;-1;-1;-1,286,286
VAST,2008,Collaborative synthesis of visual analytic results,10.1109/vast.2008.4677358,http://dx.doi.org/10.1109/VAST.2008.4677358,67.0,74.0,C,"Visual analytic tools allow analysts to generate large collections of useful analytical results. We anticipate that analysts in most real world situations will draw from these collections when working together to solve complicated problems. This indicates a need to understand how users synthesize multiple collections of results. This paper reports the results of collaborative synthesis experiments conducted with expert geographers and disease biologists. Ten participants were worked in pairs to complete a simulated real-world synthesis task using artifacts printed on cards on a large, paper-covered workspace. Experiment results indicate that groups use a number of different approaches to collaborative synthesis, and that they employ a variety of organizational metaphors to structure their information. It is further evident that establishing common ground and role assignment are critical aspects of collaborative synthesis. We conclude with a set of general design guidelines for collaborative synthesis support tools.",Anthony C. Robinson,Anthony C. Robinson,"GeoVISTA Center, Department of Geography, Pennsylvania State University, USA",10.1109/vast.2007.4389011;10.1109/tvcg.2007.70594;10.1109/tvcg.2007.70568;10.1109/vast.2007.4389011,"Movement data, spatio-temporal data, aggregation, scalable visualization, geovisualization",95.0,55.0,17.0,583.0,,,results collaborative synthesis;visual analytic tools;organizational metaphors structure;geographers;paper covered workspace,0.6201;0.5769;0.3632;0.2772;0.2261,"[np.int64(-1), np.int64(-1), -1, -1, -1]",72;200;-1;-1;-1,72;200,72
Vis,2022,A Visual Analytics System for Improving Attention-based Traffic Forecasting Models,10.1109/tvcg.2022.3209462,http://dx.doi.org/10.1109/TVCG.2022.3209462,1102.0,1112.0,J,"With deep learning (DL) outperforming conventional methods for different tasks, much effort has been devoted to utilizing DL in various domains. Researchers and developers in the traffic domain have also designed and improved DL models for forecasting tasks such as estimation of traffic speed and time of arrival. However, there exist many challenges in analyzing DL models due to the black-box property of DL models and complexity of traffic data (i.e., spatio-temporal dependencies). Collaborating with domain experts, we design a visual analytics system, AttnAnalyzer, that enables users to explore how DL models make predictions by allowing effective spatio-temporal dependency analysis. The system incorporates dynamic time warping (DTW) and Granger causality tests for computational spatio-temporal dependency analysis while providing map, table, line chart, and pixel views to assist user to perform dependency and model behavior analysis. For the evaluation, we present three case studies showing how AttnAnalyzer can effectively explore model behaviors and improve model performance in two different road networks. We also provide domain expert feedback.",Seungmin Jin;Hyunwook Lee;Cheonbok Park;Hyeshin Chu;Yunwon Tae;Jaegul Choo;Sungahn Ko,Seungmin Jin;Hyunwook Lee;Cheonbok Park;Hyeshin Chu;Yunwon Tae;Jaegul Choo;Sungahn Ko,"UNIST, South Korea;UNIST, South Korea;NAVER, South Korea;UNIST, South Korea;KAIST, South Korea;KAIST, South Korea;UNIST, South Korea",10.1109/vast47406.2019.8986948;10.1109/tvcg.2009.122;10.1109/tvcg.2020.3028976;10.1109/tvcg.2019.2934659;10.1109/tvcg.2017.2744718;10.1109/vast.2014.7042484;10.1109/tvcg.2017.2745085;10.1109/vast.2018.8802509;10.1109/tvcg.2016.2598831;10.1109/vast.2017.8585721;10.1109/tvcg.2014.2346578;10.1109/tvcg.2017.2744358;10.1109/tvcg.2018.2865044;10.1109/tvcg.2017.2744158;10.1109/tvcg.2018.2864504;10.1109/tvcg.2013.228;10.1109/tvcg.2019.2934619;10.1109/tvcg.2020.3030410;10.1109/tvcg.2018.2864500;10.1109/vast47406.2019.8986948,"Traffic Visualization,Deep Learning,Attention Model,Speed Prediction,Explainable Artificial Intelligence",,6.0,82.0,919.0,,,traffic data spatio;forecasting tasks;deep;pixel views assist;evaluation present case,0.5225;0.3060;0.1958;0.1598;0.0691,"[np.int64(-1), -1, -1, -1, -1]",69;-1;-1;-1;-1,69,69
Vis,2001,Circular incident edge lists: a data structure for rendering complex unstructured grids,10.1109/visual.2001.964511,http://dx.doi.org/10.1109/VISUAL.2001.964511,191.0,198.0,C,"We present the circular incident edge lists (CIEL), a new data structure and a high-performance algorithm for generating a series of iso-surfaces in a highly unstructured grid. Slicing-based volume rendering is also considered. The CIEL data structure represents all the combinatorial information of the grid, making it possible to optimize the classical propagation from local minima paradigm. The usual geometric structures are replaced by a more efficient combinatorial structure. An active edges list is maintained, and iteratively propagated from an iso-surface to the next one in a very efficient way. The intersected cells incident to each active edge are retrieved, and the intersection polygons are generated by circulating around their facets. This latter feature enables arbitrary irregular cells to be treated, such as those encountered in certain computational fluid dynamics (CFD) simulations. Since the CIEL data structure solely depends on the connections between the cells, it is possible to take into account dynamic changes in the geometry of the mesh and in property values, which only requires the sorted extrema list to be updated. Experiments have shown that our approach is significantly faster than classical methods. The major drawback of our method is its memory consumption, higher than most classical methods. However, experimental results show that it stays within a practical range.",Bruno Lévy 0001;Guillaume Caumon;Stéphane Conreaux;Xavier Cavin,B. Levy;G. Caumon;S. Conreaux;X. Cavin,"Loria, ISA Inria Lorraine, Vandoeuvre-les-Nancy, France;Loria, ISA Inria Lorraine, Vandoeuvre-les-Nancy, France;Loria, ISA Inria Lorraine, Vandoeuvre-les-Nancy, France;Loria, ISA Inria Lorraine, Vandoeuvre-les-Nancy, France",10.1109/visual.1996.567606;10.1109/visual.1996.567606,"Volume Rendering, Iso-Surfaces, Unstructured Grids, Combinatorial Topology",32.0,6.0,28.0,101.0,,,unstructured grid slicing;fluid dynamics cfd;extrema list;major drawback;incident active,0.6507;0.2272;0.1595;0.0778;0.0556,"[np.int64(-1), -1, -1, -1, -1]",109;-1;-1;-1;-1,109,109
Vis,2002,Geometric surface smoothing via anisotropic diffusion of normals,10.1109/visual.2002.1183766,http://dx.doi.org/10.1109/VISUAL.2002.1183766,125.0,132.0,C,"This paper introduces a method for smoothing complex, noisy surfaces, while preserving (and enhancing) sharp, geometric features. It has two main advantages over previous approaches to feature preserving surface smoothing. First is the use of level set surface models, which allows us to process very complex shapes of arbitrary and changing topology. This generality makes it well suited for processing surfaces that are derived directly from measured data. The second advantage is that the proposed method derives from a well-founded formulation, which is a natural generalization of anisotropic diffusion, as used in image processing. This formulation is based on the proposition that the generalization of image filtering entails filtering the normals of the surface, rather than processing the positions of points on a mesh.",Tolga Tasdizen;Ross T. Whitaker;Paul Burchard;Stanley J. Osher,T. Tasdizen;R. Whitaker;P. Burchard;S. Osher,"School of Computing, University of Utah, USA;School of Computing, University of Utah, USA;Department of Mathematics, UCLA, USA;Department of Mathematics, UCLA, USA",0.1109/visual.2000.885721,"anisotropic diffusion, surface fairing, geometric surface processing, intrinsic Laplacian of curvature, level sets",344.0,87.0,32.0,411.0,,,surface smoothing;allows process;proposition generalization;measured data second;derives founded,0.7647;0.0752;0.0748;0.0188;0.0145,"[np.int64(-1), -1, -1, -1, -1]",105;-1;-1;-1;-1,105,105
Vis,1994,Virtual reality performance for virtual geometry,10.1109/visual.1994.346324,http://dx.doi.org/10.1109/VISUAL.1994.346324,156.0,,C,"We describe the theoretical and practical visualization issues solved in the implementation of an interactive real-time four-dimensional geometry interface for the CAVE, an immersive virtual reality environment. While our specific task is to produce a ""virtual geometry"" experience by approximating physically correct rendering of manifolds embedded in four dimensions, the general principles exploited by our approach reflect requirements common to many immersive virtual reality applications, especially those involving volume rendering. Among the issues we address are the classification of rendering tasks, the specialized hardware support required to attain interactivity, specific techniques required to render 4D objects, and interactive methods appropriate for our 4D virtual world application.&lt;&lt;ETX&gt;&gt;",Robert A. Cross;Andrew J. Hanson,R.A. Cross;A.J. Hanson,"Department of Computer Science, Indiana University, Bloomington, IN, USA;Department of Computer Science, Indiana University, Bloomington, IN, USA",10.1109/visual.1994.346330;10.1109/visual.1993.398869;10.1109/visual.1991.175821;10.1109/visual.1992.235222;10.1109/visual.1994.346330,,22.0,6.0,20.0,122.0,,,4d virtual world;rendering tasks specialized;manifolds embedded;involving volume;methods appropriate,0.7128;0.3375;0.2999;0.2712;0.0323,"[np.int64(-1), -1, -1, -1, -1]",74;-1;-1;-1;-1,74,74
Vis,1996,A fast Gibbs sampler for synthesizing constrained fractals,10.1109/visual.1996.567598,http://dx.doi.org/10.1109/VISUAL.1996.567598,29.0,35.0,C,"It is well known that the spatial frequency spectra of membrane and thin-plate splines exhibit self-affine characteristics and hence behave as fractals. This behavior was exploited in generating the constrained fractal surfaces in the work of Szeliski and Terzopoulos (1989), which were generated by using a Gibbs sampler algorithm. The algorithm involves locally perturbing a constrained spline surface with white noise until the spline surface reaches an equilibrium state. In this paper, we introduce a very fast generalized Gibbs sampler that combines two novel techniques, namely a preconditioning technique in a wavelet basis for constraining the splines and a perturbation scheme in which, unlike the traditional Gibbs sampler, all sites (surface nodes) that do not share a common neighbor are updated simultaneously. In addition, we demonstrate the capability to generate arbitrary-order fractal surfaces without resorting to blending techniques. Using this fast Gibbs sampler algorithm, we demonstrate the synthesis of realistic terrain models from sparse elevation data.",Baba C. Vemuri;Chhandomay Mandal,B.C. Vemuri;C. Mandal,"Department of Computer and Information Sciences and Engineering, University of Florida, USA;Department of Computer and Information Sciences and Engineering, University of Florida, USA",0.1109/visual.1995.480798,,22.0,0.0,26.0,80.0,,,fractal surfaces resorting;generalized gibbs sampler;spline;generate arbitrary order;neighbor updated simultaneously,0.6155;0.3612;0.3239;0.2033;0.0161,"[np.int64(-1), -1, -1, -1, -1]",101;-1;-1;-1;-1,101,101
VAST,2009,Guided analysis of hurricane trends using statistical processes integrated with interactive parallel coordinates,10.1109/vast.2009.5332586,http://dx.doi.org/10.1109/VAST.2009.5332586,19.0,26.0,C,"This paper demonstrates the promise of augmenting interactive multivariate representations with information from statistical processes in the domain of weather data analysis. Statistical regression, correlation analysis, and descriptive statistical calculations are integrated via graphical indicators into an enhanced parallel coordinates system, called the Multidimensional Data eXplorer (MDX). These statistical indicators, which highlight significant associations in the data, are complemented with interactive visual analysis capabilities. The resulting system allows a smooth, interactive, and highly visual workflow. The system's utility is demonstrated with an extensive hurricane climate study that was conducted by a hurricane expert. In the study, the expert used a new data set of environmental weather data, composed of 28 independent variables, to predict annual hurricane activity. MDX shows the Atlantic Meridional Mode increases the explained variance of hurricane seasonal activity by 7-15% and removes less significant variables used in earlier studies. The findings and feedback from the expert (1) validate the utility of the data set for hurricane prediction, and (2) indicate that the integration of statistical processes with interactive parallel coordinates, as implemented in MDX, addresses both deficiencies in traditional weather data analysis and exhibits some of the expected benefits of visual data analysis.",Chad A. Steed;J. Edward Swan II;T. J. Jankun-Kelly;Patrick J. Fitzpatrick,Chad A. Steed;J. Edward Swan;T.J. Jankun-Kelly;Patrick J. Fitzpatrick,"Naval Research Laboratory, Inc., USA;Mississippi State University, USA;Mississippi State University, USA;Mississippi State University, USA",10.1109/tvcg.2007.70523;10.1109/infvis.2005.1532138;10.1109/vast.2006.261452;10.1109/infvis.2004.68;10.1109/visual.1995.485139;10.1109/infvis.2002.1173157;10.1109/visual.1999.809866;10.1109/tvcg.2006.170;10.1109/tvcg.2007.70523,"Climate study, multivariate data, correlation, regression, interaction, statistical analysis, visual analytics",34.0,25.0,32.0,361.0,,,hurricane climate study;explorer mdx statistical;highly visual workflow;parallel coordinates called;used earlier,0.5564;0.3403;0.3169;0.2765;0.0803,"[np.int64(-1), -1, -1, -1, -1]",48;-1;-1;-1;-1,48,48
Vis,2002,Sea of images,10.1109/visual.2002.1183792,http://dx.doi.org/10.1109/VISUAL.2002.1183792,331.0,338.0,C,"A long-standing research problem in computer graphics is to reproduce the visual experience of walking through a large photorealistic environment interactively. On one hand, traditional geometry-based rendering systems fall short of simulating the visual realism of a complex environment. On the other hand, image-based rendering systems have to date been unable to capture and store a sampled representation of a large environment with complex lighting and visibility effects. In this paper, we present a ""sea of images,"" a practical approach to dense sampling, storage, and reconstruction of the plenoptic function in large, complex indoor environments. We use a motorized cart to capture omnidirectional images every few inches on a eye-height plane throughout an environment. The captured images are compressed and stored in a multiresolution hierarchy suitable for real-time prefetching during an interactive walkthrough. Later, novel images are reconstructed for a simulated observer by resampling nearby captured images. Our system acquires 15,254 images over 1,050 square feet at an average image spacing of 1.5 inches. The average capture and processing time is 7 hours. We demonstrate realistic walkthroughs of real-world environments reproducing specular reflections and occlusion effects while rendering 15-25 frames per second.",Daniel G. Aliaga;Thomas A. Funkhouser;Dimah Yanovsky;Ingrid Carlbom,D.G. Aliaga;T. Funkhouser;D. Yanovsky;I. Carlbom,"Lucent Bell Laboratories, USA;Princeton University, USA;Harvard University, UK;Lucent Bell Laboratories, USA",10.1109/visual.1995.480797,"image-based rendering, capture, reconstruction, interactive, walkthrough",103.0,14.0,37.0,154.0,,,large photorealistic environment;plenoptic function;cart capture omnidirectional;experience walking;frames second,0.5893;0.3808;0.2485;0.2228;0.1816,"[np.int64(-1), -1, -1, -1, -1]",58;-1;-1;-1;-1,58,58
Vis,2023,The Rational Agent Benchmark for Data Visualization,10.1109/tvcg.2023.3326513,http://dx.doi.org/10.1109/TVCG.2023.3326513,338.0,347.0,J,"Understanding how helpful a visualization is from experimental results is difficult because the observed performance is confounded with aspects of the study design, such as how useful the information that is visualized is for the task. We develop a rational agent framework for designing and interpreting visualization experiments. Our framework conceives two experiments with the same setup: one with behavioral agents (human subjects), and the other one with a hypothetical rational agent. A visualization is evaluated by comparing the expected performance of behavioral agents to that of a rational agent under different assumptions. Using recent visualization decision studies from the literature, we demonstrate how the framework can be used to pre-experimentally evaluate the experiment design by bounding the expected improvement in performance from having access to visualizations, and post-experimentally to deconfound errors of information extraction from errors of optimization, among other analyses.",Yifan Wu 0005;Ziyang Guo;Michalis Mamakos;Jason D. Hartline;Jessica Hullman,Yifan Wu;Ziyang Guo;Michalis Mamakos;Jason Hartline;Jessica Hullman,"Northwestern University, USA;Northwestern University, USA;Northwestern University, USA;Northwestern University, USA;Northwestern University, USA",0.1109/tvcg.2021.3114813;10.1109/tvcg.2020.3030395;10.1109/tvcg.2019.2934287;10.1109/tvcg.2018.2864889;10.1109/tvcg.2013.126;10.1109/tvcg.2023.3326516;10.1109/tvcg.2020.3030335;10.1109/tvcg.2021.3114824;10.1109/tvcg.2020.3028984;10.1109/tvcg.2009.111;10.1109/visual.2005.1532781,"Evaluation,decision-making,rational agent,scoring rule",,2.0,33.0,434.0,,,visualization decision studies;hypothetical rational agent;experiment;bounding expected improvement;information extraction errors,0.6510;0.3692;0.2833;0.2345;0.1310,"[np.int64(-1), -1, -1, -1, -1]",211;-1;-1;-1;-1,211,211
VAST,2019,TopicSifter: Interactive Search Space Reduction through Targeted Topic Modeling,10.1109/vast47406.2019.8986922,http://dx.doi.org/10.1109/VAST47406.2019.8986922,35.0,45.0,C,"Topic modeling is commonly used to analyze and understand large document collections. However, in practice, users want to focus on specific aspects or “targets” rather than the entire corpus. For example, given a large collection of documents, users may want only a smaller subset which more closely aligns with their interests, tasks, and domains. In particular, our paper focuses on large-scale document retrieval with high recall where any missed relevant documents can be critical. A simple keyword matching search is generally not effective nor efficient as 1) it is difficult to find a list of keyword queries that can cover the documents of interest before exploring the dataset, 2) some documents may not contain the exact keywords of interest but may still be highly relevant, and 3) some words have multiple meanings, which would result in irrelevant documents included in the retrieved subset. In this paper, we present TopicSifter, a visual analytics system for interactive search space reduction. Our system utilizes targeted topic modeling based on nonnegative matrix factorization and allows users to give relevance feedback in order to refine their target and guide the topic modeling to the most relevant results.",Hannah Kim 0001;Dongjin Choi;Barry L. Drake;Alex Endert;Haesun Park,Hannah Kim;Dongjin Choi;Barry Drake;Alex Endert;Haesun Park,Georgia Institute of Technology;Georgia Institute of Technology;Georgia Tech Research Institute;Georgia Institute of Technology;Georgia Institute of Technology,10.1109/tvcg.2010.154;10.1109/tvcg.2013.212;10.1109/tvcg.2009.176;10.1109/tvcg.2014.2346433;10.1109/tvcg.2018.2864769;10.1109/infvis.2001.963287;10.1109/tvcg.2016.2598445;10.1109/tvcg.2012.260;10.1109/tvcg.2006.142;10.1109/tvcg.2010.154,"Human-centered computing,Visualization,Visualization application domains,Visual analytics,Information systems,Information retrieval,Users and interactive retrieval,Search interfaces",9.0,8.0,46.0,392.0,,,targeted topic modeling;visual analytics interactive;nonnegative matrix;space reduction utilizes;commonly,0.5841;0.3289;0.2561;0.2065;0.0892,"[np.int64(-1), -1, -1, -1, -1]",46;-1;-1;-1;-1,46,46
InfoVis,2006,Software Design Patterns for Information Visualization,10.1109/tvcg.2006.178,http://dx.doi.org/10.1109/TVCG.2006.178,853.0,860.0,J,"Despite a diversity of software architectures supporting information visualization, it is often difficult to identify, evaluate, and re-apply the design solutions implemented within such frameworks. One popular and effective approach for addressing such difficulties is to capture successful solutions in design patterns, abstract descriptions of interacting software components that can be customized to solve design problems within a particular context. Based upon a review of existing frameworks and our own experiences building visualization software, we present a series of design patterns for the domain of information visualization. We discuss the structure, context of use, and interrelations of patterns spanning data representation, graphics, and interaction. By representing design knowledge in a reusable form, these patterns can be used to facilitate software design, implementation, and evaluation, and improve developer education and communication",Jeffrey Heer;Maneesh Agrawala,Jeffrey Heer;Maneesh Agrawala,"Computer Science Division, University of California, Berkeley, USA;Computer Science Division, University of California, Berkeley, USA",10.1109/infvis.1998.729560;10.1109/infvis.2002.1173141;10.1109/infvis.2003.1249007;10.1109/infvis.2000.885086;10.1109/infvis.2004.12;10.1109/infvis.2004.64;10.1109/infvis.1998.729560,"Design patterns, information visualization, software engineering, object-oriented programming",293.0,117.0,23.0,4393.0,,,supporting information visualization;design patterns domain;improve developer education;popular;solve,0.7082;0.4523;0.2465;0.1583;-0.0666,"[np.int64(-1), -1, -1, -1, -1]",274;-1;-1;-1;-1,274,274
VAST,2007,Visual Analytics on Mobile Devices for Emergency Response,10.1109/vast.2007.4388994,http://dx.doi.org/10.1109/VAST.2007.4388994,35.0,42.0,C,"Using mobile devices for visualization provides a ubiquitous environment for accessing information and effective decision making. These visualizations are critical in satisfying the knowledge needs of operators in areas as diverse as education, business, law enforcement, protective services, medical services, scientific discovery, and homeland security. In this paper, we present an efficient and interactive mobile visual analytic system for increased situational awareness and decision making in emergency response and training situations. Our system provides visual analytics with locational scene data within a simple interface tailored to mobile device capabilities. In particular, we focus on processing and displaying sensor network data for first responders. To verify our system, we have used simulated data of The Station nightclub fire evacuation.",SungYe Kim;Yun Jang;Angela K. Mellema;David S. Ebert;Timothy W. Collins,Sung Ye Kim;Yun Jang;Angela Mellema;David S. Ebert;Timothy Collinss,"Purdue University Regional Visualization and Analytics Center (PURVAC), Purdue University, West Lafayette, IN, USA;Purdue University Regional Visualization and Analytics Center (PURVAC), Purdue University, West Lafayette, IN, USA;Purdue University Regional Visualization and Analytics Center (PURVAC), Purdue University, West Lafayette, IN, USA;Purdue University Regional Visualization and Analytics Center (PURVAC), Purdue University, West Lafayette, IN, USA;Purdue Homeland Security Institute (PHSI), Purdue University, West Lafayette, IN. e-mail:",10.1109/vast.2006.261434;10.1109/vast.2006.261434,"mobile visualization, visual analytics, emergency response",61.0,33.0,20.0,830.0,,,mobile visual analytic;increased situational awareness;sensor network data;station nightclub evacuation;verify,0.5524;0.4021;0.3300;0.2519;0.0852,"[np.int64(-1), -1, -1, -1, -1]",318;-1;-1;-1;-1,318,318
Vis,2003,Voxels on fire,10.1109/visual.2003.1250382,http://dx.doi.org/10.1109/VISUAL.2003.1250382,271.0,278.0,C,We introduce a method for the animation of fire propagation and the burning consumption of objects represented as volumetric data sets. Our method uses a volumetric fire propagation model based on an enhanced distance field. It can simulate the spreading of multiple fire fronts over a specified isosurface without actually having to create that isosurface. The distance field is generated from a specific shell volume that rapidly creates narrow spatial bands around the virtual surface of any given isovalue. The complete distance field is then obtained by propagation from the initial bands. At each step multiple fire fronts can evolve simultaneously on the volumetric object. The flames of the fire are constructed from streams of particles whose movement is regulated by a velocity field generated with the hardware-accelerated Lattice Boltzmann Model (LBM). The LBM provides a physically-based simulation of the air flow around the burning object. The object voxels and the splats associated with the flame particles are rendered in the same pipeline so that the volume data with its external and internal structures can be displayed along with the fire.,Ye Zhao 0004;Xiaoming Wei;Zhe Fan;Arie E. Kaufman;Hong Qin 0001,Ye Zhao;Xiaoming Wei;Zhe Fan;A. Kaufman;Hong Qin,"Center for Visual Computing and Department of Computer Science, Stony Brook University, Stony Brook, NY, USA;Center for Visual Computing and Department of Computer Science, Stony Brook University, Stony Brook, NY, USA;Center for Visual Computing and Department of Computer Science, Stony Brook University, Stony Brook, NY, USA;Center for Visual Computing and Department of Computer Science, Stony Brook University, Stony Brook, NY, USA;Center for Visual Computing and Department of Computer Science, Stony Brook University, Stony Brook, NY, USA",10.1109/visual.2002.1183779;10.1109/visual.1993.398879,"Fire Propagation, Distance Field, Lattice Boltzmann Model, Splatting, GPU Acceleration",3.0,4.0,34.0,219.0,,,volumetric object flames;hardware accelerated lattice;evolve simultaneously;uses;field generated specific,0.7340;0.3283;0.1111;0.0403;-0.0319,"[np.int64(-1), -1, -1, -1, -1]",256;-1;-1;-1;-1,256,256
Vis,1991,Visualizing causal effects in 4D space-time vector fields,10.1109/visual.1991.175770,http://dx.doi.org/10.1109/VISUAL.1991.175770,12.0,,C,"A method is presented for juxtaposing 4D space-time vector fields, of which one contains a source variable and the other the response field. Thresholding, ellipsoid fitting, and vortex line generation are used to reduce the amount of information and help analyze the relationship between two 3D vector variables evolving in time. The technique helps to highlight the topological relationship between the two in an effort to understand the causal connection. These concepts are applied to on-going research in evolving fluid dynamics problems.&lt;&lt;ETX&gt;&gt;",Deborah Silver;M. Gao;Norman Zabusky,D. Silver;M. Gao;N. Zabusky,"Department of Electrical and Computer Engineering & CAIP, Rutgers University, Piscataway, NJ, USA;Department of Electrical and Computer Engineering & CAIP, Rutgers University, Piscataway, NJ, USA;Department of Mech. and Aero. Engineering & CAIP, Rutgers University, Piscataway, NJ, USA",,,13.0,6.0,8.0,83.0,,,evolving fluid dynamics;thresholding ellipsoid fitting;space time vector;juxtaposing 4d;understand causal connection,0.5458;0.4154;0.3634;0.2524;0.1806,"[np.int64(-1), -1, -1, -1, -1]",307;-1;-1;-1;-1,307,307
Vis,2006,Visual Signatures in Video Visualization,10.1109/tvcg.2006.194,http://dx.doi.org/10.1109/TVCG.2006.194,1093.0,1100.0,J,"Video visualization is a computation process that extracts meaningful information from original video data sets and conveys the extracted information to users in appropriate visual representations. This paper presents a broad treatment of the subject, following a typical research pipeline involving concept formulation, system development, a path-finding user study, and a field trial with real application data. In particular, we have conducted a fundamental study on the visualization of motion events in videos. We have, for the first time, deployed flow visualization techniques in video visualization. We have compared the effectiveness of different abstract visual representations of videos. We have conducted a user study to examine whether users are able to learn to recognize visual signatures of motions, and to assist in the evaluation of different visualization techniques. We have applied our understanding and the developed techniques to a set of application video clips. Our study has demonstrated that video visualization is both technically feasible and cost-effective. It has provided the first set of evidence confirming that ordinary users can be accustomed to the visual features depicted in video visualizations, and can learn to recognize visual signatures of a variety of motion events",Min Chen 0001;Ralf Peter Botchen;Rudy Hashim;Daniel Weiskopf;Thomas Ertl;Ian M. Thornton,Min Chen;Ralf Botchen;Rudy Hashim;Daniel Weiskopf;Thomas Ertl;Ian Thornton,"Computer Science, Swansea University, UK;Visualization and Interactive Systems, University of Stuttgart, Germany;Computer Science, Swansea University, UK;GrUVi, Computing Science, Simon Fraser University, Canada;Visualization and Interactive Systems, University of Stuttgart, Germany;Computer Science and Psychology, Swansea University, UK",10.1109/visual.2003.1250401;10.1109/visual.1991.175792;10.1109/visual.1995.480819;10.1109/visual.2003.1250401,"Video visualization, volume visualization, flow visualization, human factors, user study, visual signatures, video processing, optical flow, GPU rendering",64.0,39.0,26.0,613.0,,,video visualization;events;deployed flow;ordinary users accustomed;different abstract,0.7138;0.1991;0.1961;0.1864;-0.0415,"[np.int64(-1), -1, -1, -1, -1]",258;-1;-1;-1;-1,258,258
Vis,2022,In Defence of Visual Analytics Systems: Replies to Critics,10.1109/tvcg.2022.3209360,http://dx.doi.org/10.1109/TVCG.2022.3209360,1026.0,1036.0,J,"The last decade has witnessed many visual analytics (VA) systems that make successful applications to wide-ranging domains like urban analytics and explainable AI. However, their research rigor and contributions have been extensively challenged within the visualization community. We come in defence of VA systems by contributing two interview studies for gathering critics and responses to those criticisms. First, we interview 24 researchers to collect criticisms the review comments on their VA work. Through an iterative coding and refinement process, the interview feedback is summarized into a list of 36 common criticisms. Second, we interview 17 researchers to validate our list and collect their responses, thereby discussing implications for defending and improving the scientific values and rigor of VA systems. We highlight that the presented knowledge is deep, extensive, but also imperfect, provocative, and controversial, and thus recommend reading with an inclusive and critical eye. We hope our work can provide thoughts and foundations for conducting VA research and spark discussions to promote the research field forward more rigorously and vibrantly.",Aoyu Wu;Dazhen Deng;Furui Cheng;Yingcai Wu;Shixia Liu;Huamin Qu,Aoyu Wu;Dazhen Deng;Furui Cheng;Yingcai Wu;Shixia Liu;Huamin Qu,"Hong Kong University of Science and Technology, China;State Key Lab of CAD&CG, Zhejiang University, China;Hong Kong University of Science and Technology, China;State Key Lab of CAD&CG, Zhejiang University, China;School of Software, Tsinghua University, China;Hong Kong University of Science and Technology, China",10.1109/tvcg.2020.3030338;10.1109/tvcg.2021.3114836;10.1109/tvcg.2021.3114797;10.1109/tvcg.2013.226;10.1109/tvcg.2021.3114810;10.1109/tvcg.2019.2934790;10.1109/tvcg.2021.3114855;10.1109/tvcg.2016.2598827;10.1109/tvcg.2013.126;10.1109/visual.2003.1250401;10.1109/tvcg.2019.2934264;10.1109/tvcg.2021.3114800;10.1109/tvcg.2017.2744319;10.1109/tvcg.2021.3114766;10.1109/tvcg.2018.2865022;10.1109/tvcg.2016.2598432;10.1109/tvcg.2019.2934593;10.1109/tvcg.2016.2598831;10.1109/tvcg.2021.3114789;10.1109/tvcg.2014.2346331;10.1109/tvcg.2019.2934539;10.1109/tvcg.2009.111;10.1109/tvcg.2021.3114827;10.1109/tvcg.2021.3114820;10.1109/tvcg.2021.3114858;10.1109/tvcg.2021.3114959;10.1109/tvcg.2021.3114812;10.1109/tvcg.2016.2598838;10.1109/tvcg.2013.120;10.1109/tvcg.2012.213;10.1109/tvcg.2020.3030396;10.1109/tvcg.2021.3114857;10.1109/tvcg.2021.3114878;10.1109/tvcg.2021.3114781;10.1109/tvcg.2021.3114787;10.1109/tvcg.2021.3114821;10.1109/tvcg.2021.3114840;10.1109/tvcg.2021.3114794;10.1109/tvcg.2021.3114790;10.1109/tvcg.2014.2346920;10.1109/tvcg.2018.2865041;10.1109/tvcg.2019.2934656;10.1109/tvcg.2020.3030338,"Visual Analytics,Theory,Qualitative Study,Design Study,Application,Theoretical and Empirical Research",,18.0,79.0,953.0,,,urban analytics explainable;comments va;decade witnessed;critical eye hope;validate list collect,0.6417;0.2829;0.1227;0.0704;0.0471,"[np.int64(-1), -1, -1, -1, -1]",237;-1;-1;-1;-1,237,237
Vis,2007,Listener-based Analysis of Surface Importance for Acoustic Metrics,10.1109/tvcg.2007.70575,http://dx.doi.org/10.1109/TVCG.2007.70575,1680.0,1687.0,J,"Acoustic quality in room acoustics is measured by well defined quantities, like definition, which can be derived from simulated impulse response filters or measured values. These take into account the intensity and phase shift of multiple reflections due to a wave front emanating from a sound source. Definition (D&lt;sub&gt;50&lt;/sub&gt;) and clarity (C&lt;sub&gt;50&lt;/sub&gt;) for example correspond to the fraction of the energy received in total to the energy received in the first 50 ms at a certain listener position. Unfortunately, the impulse response measured at a single point does not provide any information about the direction of reflections, and about the reflection surfaces which contribute to this measure. For the visualization of room acoustics, however, this information is very useful since it allows to discover regions with high contribution and provides insight into the influence of all reflecting surfaces to the quality measure. We use the phonon tracing method to calculate the contribution of the reflection surfaces to the impulse response for different listener positions. This data is used to compute importance values for the geometry taking a certain acoustic metric into account. To get a visual insight into the directional aspect, we map the importance to the reflecting surfaces of the geometry. This visualization indicates which parts of the surfaces need to be changed to enhance the chosen acoustic quality measure. We apply our method to the acoustic improvement of a lecture hall by means of enhancing the overall speech comprehensibility (clarity) and evaluate the results using glyphs to visualize the clarity (C&lt;sub&gt;50&lt;/sub&gt;) values at listener positions throughout the room.",Frank Michel 0001;Eduard Deines;Martin Hering-Bertram;Christoph Garth;Hans Hagen,Frank Michel;Eduard Deines;Martin Hering-Bertram;Christoph Garth;Hans Hagen,"IRTG Kaiserslautern, Germany;IRTG Kaiserslautern, Germany;Fraunhofer ITWM Kaiserslautern, Germany;The Institute for Data Analysis, University of Kaiserslautern, Germany and Visualization, University of California, Davis, USA;University of Kaiserslautern, Germany",10.1109/tvcg.2006.125;10.1109/visual.2005.1532790;10.1109/visual.1998.745338;10.1109/tvcg.2006.125,"Sound analytics, Applications of Visualization, Room Acoustics, Phonon Tracing, Acoustic Metric",7.0,4.0,26.0,190.0,,,visualization room acoustics;comprehensibility clarity;impulse response filters;compute importance;glyphs,0.7516;0.2352;0.2252;0.1246;0.1231,"[np.int64(-1), -1, -1, -1, -1]",30;-1;-1;-1;-1,30,30
InfoVis,2020,Palettailor: Discriminable Colorization for Categorical Data,10.1109/tvcg.2020.3030406,http://dx.doi.org/10.1109/TVCG.2020.3030406,475.0,484.0,J,"We present an integrated approach for creating and assigning color palettes to different visualizations such as multi-class scatterplots, line, and bar charts. While other methods separate the creation of colors from their assignment, our approach takes data characteristics into account to produce color palettes, which are then assigned in a way that fosters better visual discrimination of classes. To do so, we use a customized optimization based on simulated annealing to maximize the combination of three carefully designed color scoring functions: point distinctness, name difference, and color discrimination. We compare our approach to state-of-the-art palettes with a controlled user study for scatterplots and line charts, furthermore we performed a case study. Our results show that Palettailor, as a fully-automated approach, generates color palettes with a higher discrimination quality than existing approaches. The efficiency of our optimization allows us also to incorporate user modifications into the color selection process.",Kecheng Lu;Mi Feng;Xin Chen;Michael Sedlmair;Oliver Deussen;Dani Lischinski;Zhanglin Cheng;Yunhai Wang,Kecheng Lu;Mi Feng;Xin Chen;Michael Sedlmair;Oliver Deussen;Dani Lischinski;Zhanglin Cheng;Yunhai Wang,"Shandong University;Twitter Inc.;Shandong University;VISUS, University of Stuttgart, Germany;Shenzhen VisuCA Key Lab, SIAT, China and Konstanz University, Germany;Hebrew University, Jerusalem, Israel;Shenzhen VisuCA Key Lab, SIAT, China;Shandong University",10.1109/tvcg.2014.2346594;10.1109/tvcg.2016.2599214;10.1109/tvcg.2013.183;10.1109/tvcg.2016.2598918;10.1109/visual.1996.568118;10.1109/tvcg.2010.162;10.1109/tvcg.2009.113;10.1109/tvcg.2015.2467471;10.1109/tvcg.2008.118;10.1109/tvcg.2018.2864912;10.1109/tvcg.2014.2346594,"Color Palette,Discriminability,Multi-Class Scatterplot,Line Chart,Bar Chart",16.0,22.0,39.0,1014.0,,,user study scatterplots;separate creation colors;annealing maximize;class;allows incorporate,0.5711;0.4071;0.2884;0.1049;-0.0801,"[np.int64(-1), -1, -1, -1, -1]",151;-1;-1;-1;-1,151,151
Vis,1999,Simplified representation of vector fields,10.1109/visual.1999.809865,http://dx.doi.org/10.1109/VISUAL.1999.809865,35.0,507.0,C,"Vector field visualization remains a difficult task. Many local and global visualization methods for vector fields such as flow data exist, but they usually require extensive user experience on setting the visualization parameters in order to produce images communicating the desired insight. We present a visualization method that produces simplified but suggestive images of the vector field automatically, based on a hierarchical clustering of the input data. The resulting clusters are then visualized with straight or curved arrow icons. The presented method has a few parameters with which users can produce various simplified vector field visualizations that communicate different insights on the vector data.",Alexandru C. Telea;Jarke J. van Wijk,A. Telea;J.J. Van Wijk,"Department of Mathematics and Computer Science, Eindhovan University of Technology, Netherlands;Department of Mathematics and Computer Science, Eindhovan University of Technology, Netherlands",10.1109/visual.1995.480817;10.1109/visual.1994.346327;10.1109/visual.1991.175789;10.1109/visual.1995.480817,"Flow Visualization, Simplification, Clustering",215.0,73.0,14.0,442.0,,,vector field visualizations;automatically based hierarchical;global;user experience setting;usually,0.8014;0.1976;0.0476;0.0451;0.0028,"[np.int64(-1), -1, -1, -1, -1]",140;-1;-1;-1;-1,140,140
Vis,2000,Visualizing DIII-D Tokamak magnetic field lines,10.1109/visual.2000.885742,http://dx.doi.org/10.1109/VISUAL.2000.885742,501.0,504.0,C,"We demonstrate the use of a combination of perceptually effective techniques for visualizing magnetic field data from the DIII-D Tokamak. These techniques can be implemented to run very efficiently on machines with hardware support for OpenGL. Interactive speeds facilitate clear communication of magnetic field structure, enhancing fusion scientists' understanding of their data, and thereby accelerating their research.",Gregory L. Schussman;Kwan-Liu Ma;David P. Schissel;Todd Evans,G. Schussman;Kwan-Liu Ma;D. Schissel;T. Evans,"Center for Image Processing and Integrated Computing Department of Computer Science, University of California, Davis, CA, USA;General Atomics Court, San Diego, CA, USA;Center for Image Processing and Integrated Computing Department of Computer Science, University of California, Davis, CA, USA;General Atomics Court, San Diego, CA, USA",10.1109/visual.1996.567777;10.1109/visual.1996.567777,"graphics hardware, haloed lines, illuminated lines, interactive visualization, magnetic field, plasma physics, tokamak",20.0,5.0,8.0,164.0,,,techniques visualizing magnetic;diii tokamak;data accelerating research;hardware support opengl;use combination,0.5794;0.4547;0.2767;0.2476;0.0237,"[np.int64(-1), -1, -1, -1, -1]",153;-1;-1;-1;-1,153,153
VAST,2016,Visual analysis and coding of data-rich user behavior,10.1109/vast.2016.7883520,http://dx.doi.org/10.1109/VAST.2016.7883520,141.0,150.0,C,"Investigating user behavior involves abstracting low-level events to higher-level concepts. This requires an analyst to study individual user activities, assign codes which categorize behavior, and develop a consistent classification scheme. To better support this reasoning process of an analyst, we suggest a novel visual analytics approach which integrates rich user data including transcripts, videos, eye movement data, and interaction logs. Word-sized visualizations embedded into a tabular representation provide a space-efficient and detailed overview of user activities. An analyst assigns codes, grouped into code categories, as part of an interactive process. Filtering and searching helps to select specific activities and focus an analysis. A comparison visualization summarizes results of coding and reveals relationships between codes. Editing features support efficient assignment, refinement, and aggregation of codes. We demonstrate the practical applicability and usefulness of our approach in a case study and describe expert feedback.",Tanja Blascheck;Fabian Beck 0001;Sebastian Baltes;Thomas Ertl;Daniel Weiskopf,Tanja Blascheck;Fabian Beck;Sebastian Baltes;Thomas Ertl;Daniel Weiskopf,"University of Stuttgart, Germany;University of Stuttgart, Germany;University of Trier, Germany;University of Stuttgart, Germany;University of Stuttgart, Germany",10.1109/vast.2009.5333443;10.1109/visual.1990.146402;10.1109/tvcg.2011.226;10.1109/tvcg.2014.2346452;10.1109/tvcg.2008.137;10.1109/tvcg.2015.2467611;10.1109/tvcg.2015.2467757;10.1109/tvcg.2010.194;10.1109/tvcg.2014.2346677;10.1109/vast.2008.4677365;10.1109/tvcg.2013.124;10.1109/vast.2009.5333443,,22.0,17.0,58.0,681.0,,,visual analytics;activities assign codes;integrates rich user;logs word sized;better,0.6640;0.3301;0.1636;0.1433;0.0526,"[np.int64(-1), -1, -1, -1, -1]",201;-1;-1;-1;-1,201,201
InfoVis,2018,A Framework for Creative Visualization-Opportunities Workshops,10.1109/tvcg.2018.2865241,http://dx.doi.org/10.1109/TVCG.2018.2865241,748.0,758.0,J,"Applied visualization researchers often work closely with domain collaborators to explore new and useful applications of visualization. The early stages of collaborations are typically time consuming for all stakeholders as researchers piece together an understanding of domain challenges from disparate discussions and meetings. A number of recent projects, however, report on the use of creative visualization-opportunities (CVO) workshops to accelerate the early stages of applied work, eliciting a wealth of requirements in a few days of focused work. Yet, there is no established guidance for how to use such workshops effectively. In this paper, we present the results of a 2-year collaboration in which we analyzed the use of 17 workshops in 10 visualization contexts. Its primary contribution is a framework for CVO workshops that: 1) identifies a process model for using workshops; 2) describes a structure of what happens within effective workshops; 3) recommends 25 actionable guidelines for future workshops; and 4) presents an example workshop and workshop methods. The creation of this framework exemplifies the use of critical reflection to learn about visualization in practice from diverse studies and experience.",Ethan Kerzner;Sarah Goodwin;Jason Dykes;Sara Jones 0001;Miriah D. Meyer,Ethan Kerzner;Sarah Goodwin;Jason Dykes;Sara Jones;Miriah Meyer,"University of Utah, Salt Lake City, UT, US;Monash University, Clayton, VIC, AU;University of London, London, London, GB;University of London, London, London, GB;University of Utah, Salt Lake City, UT, US",10.1109/tvcg.2010.191;10.1109/tvcg.2013.145;10.1109/tvcg.2016.2598545;10.1109/tvcg.2016.2599338;10.1109/tvcg.2011.209;10.1109/tvcg.2017.2744459;10.1109/tvcg.2014.2346331;10.1109/tvcg.2009.111;10.1109/tvcg.2015.2467271;10.1109/tvcg.2016.2599030;10.1109/tvcg.2012.213;10.1109/tvcg.2013.132;10.1109/tvcg.2015.2467191;10.1109/tvcg.2010.191,"User-centered visualization design,design studies,creativity workshops,critically reflective practice",0.0,46.0,90.0,1657.0,,,applied visualization researchers;understanding domain;discussions meetings number;wealth requirements days;piece,0.7439;0.2250;0.1886;0.0530;-0.0160,"[np.int64(-1), -1, -1, -1, -1]",209;-1;-1;-1;-1,209,209
InfoVis,2015,A comparative study between RadViz and Star Coordinates,10.1109/tvcg.2015.2467324,http://dx.doi.org/10.1109/TVCG.2015.2467324,619.0,628.0,J,"RadViz and star coordinates are two of the most popular projection-based multivariate visualization techniques that arrange variables in radial layouts. Formally, the main difference between them consists of a nonlinear normalization step inherent in RadViz. In this paper we show that, although RadViz can be useful when analyzing sparse data, in general this design choice limits its applicability and introduces several drawbacks for exploratory data analysis. In particular, we observe that the normalization step introduces nonlinear distortions, can encumber outlier detection, prevents associating the plots with useful linear mappings, and impedes estimating original data attributes accurately. In addition, users have greater flexibility when choosing different layouts and views of the data in star coordinates. Therefore, we suggest that analysts and researchers should carefully consider whether RadViz's normalization step is beneficial regarding the data sets' characteristics and analysis tasks.",Manuel Rubio-Sánchez;Laura Raya;Francisco Diaz;Alberto Sánchez 0001,Manuel Rubio-Sánchez;Laura Raya;Francisco Díaz;Alberto Sanchez,URJC;U-tad;UPM;URJC and CCS,10.1109/vast.2010.5652433;10.1109/infvis.1998.729559;10.1109/visual.1997.663916;10.1109/tvcg.2013.182;10.1109/tvcg.2014.2346258;10.1109/tvcg.2008.173;10.1109/vast.2010.5652433,"RadViz, Star coordinates, Exploratory data analysis, Cluster analysis, Classification, Outlier detection",,53.0,45.0,1500.0,,,multivariate visualization;outlier detection prevents;inherent radviz paper;layouts views data;general,0.6250;0.2747;0.2602;0.1692;0.0529,"[np.int64(-1), -1, -1, -1, -1]",185;-1;-1;-1;-1,185,185
VAST,2009,Visualized subgraph search,10.1109/vast.2009.5333968,http://dx.doi.org/10.1109/VAST.2009.5333968,,,M,"We present a visually supported search and browsing system for network-type data, especially a novel module for subgraph search with a GUI to define subgraphs for queries. We describe how this prototype was applied for the Vast Challenge 2009, Flitter Mini Challenge.",Dóra Erdös;Zsolt Fekete;András Lukács,Dora Erdos;Zsolt Fekete;Andras Lukacs,"Computer and Automation Research Institute (MTA SZTAKI), Data Mining and Web Search Group, Hungarian Academy of Sciences (ATOMKI), Hungary;Computer and Automation Research Institute (MTA SZTAKI), Data Mining and Web Search Group, Hungarian Academy of Sciences (ATOMKI), Hungary;Computer and Automation Research Institute (MTA SZTAKI), Data Mining and Web Search Group, Hungarian Academy of Sciences (ATOMKI), Hungary",,,1.0,2.0,1.0,149.0,,,subgraph search gui;data especially;network type;flitter;present visually supported,0.6788;0.2927;0.2688;0.1861;0.1647,"[np.int64(-1), -1, -1, -1, -1]",249;-1;-1;-1;-1,249,249
Vis,2024,The Effect of Visual Aids on Reading Numeric Data Tables,10.1109/tvcg.2024.3456403,http://dx.doi.org/10.1109/TVCG.2024.3456403,995.0,1005.0,J,"Data tables are one of the most common ways in which people encounter data. Although mostly built with text and numbers, data tables have a spatial layout and often exhibit visual elements meant to facilitate their reading. Surprisingly, there is an empirical knowledge gap on how people read tables and how different visual aids affect people's reading of tables. In this work, we seek to address this vacuum through a controlled study. We asked participants to repeatedly perform four different tasks with four table representation conditions (plain tables, tables with zebra striping, tables with cell background color encoding cell value, and tables with in-cell bars with lengths encoding cell value). We analyzed completion time, error rate, gaze-tracking data, mouse movement and participant preferences. We found that color and bar encodings help for finding maximum values. For a more complex task (comparison of proportional differences) color and bar helped less than zebra striping. We also characterize typical human behavior for the four tasks. These findings inform the design of tables and research directions for improving presentation of data in tabular form.",Yongfeng Ji;Charles Perin;Miguel A. Nacenta,Yongfeng Ji;Charles Perin;Miguel A. Nacenta,"University of Victoria, Canada;University of Victoria, Canada;University of Victoria, Canada",10.1109/tvcg.2021.3114830;10.1109/tvcg.2014.2346248;10.1109/tvcg.2014.2346279,"Data Table,Visual Encoding,,,Visual Aid,Gaze Analysis,Zebra,Data Bars,Tabular Representations",,0.0,51.0,134.0,,,people read tables;data mouse;preferences color;encodings;repeatedly,0.6199;0.3594;0.2590;0.1648;0.0295,"[np.int64(-1), -1, -1, -1, -1]",88;-1;-1;-1;-1,88,88
Vis,1997,Extracting feature lines from 3D unstructured grids,10.1109/visual.1997.663894,http://dx.doi.org/10.1109/VISUAL.1997.663894,285.0,292.0,C,"The paper discusses techniques for extracting feature lines from three-dimensional unstructured grids. The twin objectives are to facilitate the interactive manipulation of these typically very large and dense meshes, and to clarify the visualization of the solution data that accompanies them. The authors describe the perceptual importance of specific viewpoint-dependent and view-independent features, discuss the relative advantages and disadvantages of several alternative algorithms for identifying these features (taking into consideration both local and global criteria), and demonstrate the results of these methods on a variety of different data sets.",Kwan-Liu Ma;Victoria Interrante,Kwan-Liu Ma;V. Interrante,"Institute for Computer Applications in Science and Engineering, NASA-Langley Research Center, Hampton, VA, USA;Institute for Computer Applications in Science and Engineering, NASA-Langley Research Center, Hampton, VA, USA",10.1109/visual.1995.480795;10.1109/visual.1995.480795,,51.0,0.0,26.0,76.0,,,extracting feature lines;dimensional unstructured grids;data accompanies authors;disadvantages alternative;local global,0.6143;0.5635;0.0129;0.0082;-0.0449,"[np.int64(-1), np.int64(-1), -1, -1, -1]",246;109;-1;-1;-1,109;246,246
Vis,1997,Visualization of rotation fields,10.1109/visual.1997.663929,http://dx.doi.org/10.1109/VISUAL.1997.663929,491.0,494.0,C,"We define a rotation field by extending the notion of a vector field to rotations. A vector field has a vector as a value at each point of its domain; a rotation field has a rotation as a value at each point of its domain. Rotation fields result from mapping the orientation error of tracking systems. We build upon previous methods for the visualization of vector fields, tensor fields and rotations at a point, to visualize a rotation field resulting from calibration of a commonly-used magnetic tracking system.",Mark A. Livingston,M.A. Livingston,"Department of Computer Science, University of North Carolina, Chapel Hill, USA",10.1109/visual.1992.235211;10.1109/visual.1994.346330;10.1109/visual.1992.235193;10.1109/visual.1992.235227;10.1109/visual.1994.346315;10.1109/visual.1991.175789;10.1109/visual.1993.398867;10.1109/visual.1994.346338;10.1109/visual.1993.398846;10.1109/visual.1992.235211,"Scientific visualization, tufts, streamlines, stream surfaces",11.0,5.0,22.0,83.0,,,rotation fields;methods visualization vector;error tracking;define;commonly,0.7123;0.3951;0.2393;0.0414;-0.0354,"[np.int64(-1), -1, -1, -1, -1]",40;-1;-1;-1;-1,40,40
InfoVis,2000,From metaphor to method: cartographic perspectives on information visualization,10.1109/infvis.2000.885095,http://dx.doi.org/10.1109/INFVIS.2000.885095,91.0,97.0,C,"By virtue of their spatio-cognitive abilities, humans are able to navigate through geographic space as well as meaningfully communicate geographic information represented in cartographic form. The current dominance of spatial metaphors in information visualization research is the result of the realization that those cognitive skills also have value in the exploration and analysis of non-geographic information. While mapping or landscape metaphors are routinely used in this field, there is a noticeable lack of consideration for existing cartographic expertise. This is especially apparent whenever problematic issues are encountered, such as graphic complexity or feature labeling. There are a number of areas in which a cartographic outlook could provide a valuable perspective. This paper discusses how geographic and cartographic notions may influence the design of visualizations for textual information spaces. Map projections, generalization, feature labeling and map design issues are discussed.",André Skupin,A. Skupin,"Department of Geography, University of New Orleans, USA",10.1109/infvis.1995.528686;10.1109/visual.1992.235198;10.1109/infvis.2000.885102;10.1109/infvis.1995.528686,,136.0,23.0,62.0,576.0,,,information represented cartographic;metaphors routinely used;outlook;abilities humans;apparent problematic issues,0.7344;0.3330;0.0939;0.0861;0.0851,"[np.int64(-1), -1, -1, -1, -1]",-1;-1;-1;-1;-1,,-1
SciVis,2014,Visualization of Brain Microstructure Through Spherical Harmonics Illumination of High Fidelity Spatio-Angular Fields,10.1109/tvcg.2014.2346411,http://dx.doi.org/10.1109/TVCG.2014.2346411,2516.0,2525.0,J,"Diffusion kurtosis imaging (DKI) is gaining rapid adoption in the medical imaging community due to its ability to measure the non-Gaussian property of water diffusion in biological tissues. Compared to traditional diffusion tensor imaging (DTI), DKI can provide additional details about the underlying microstructural characteristics of the neural tissues. It has shown promising results in studies on changes in gray matter and mild traumatic brain injury where DTI is often found to be inadequate. The DKI dataset, which has high-fidelity spatio-angular fields, is difficult to visualize. Glyph-based visualization techniques are commonly used for visualization of DTI datasets; however, due to the rapid changes in orientation, lighting, and occlusion, visually analyzing the much more higher fidelity DKI data is a challenge. In this paper, we provide a systematic way to manage, analyze, and visualize high-fidelity spatio-angular fields from DKI datasets, by using spherical harmonics lighting functions to facilitate insights into the brain microstructure.",Sujal Bista;Jiachen Zhuo;Rao P. Gullapalli;Amitabh Varshney,Sujal Bista;Jiachen Zhuo;Rao P. Gullapalli;Amitabh Varshney,"University of Maryland, College Park;University of Maryland School of Medicine at Baltimore;University of Maryland School of Medicine at Baltimore;University of Maryland, College Park",10.1109/tvcg.2013.172;10.1109/tvcg.2007.70602;10.1109/tvcg.2010.199;10.1109/tvcg.2012.231;10.1109/visual.1999.809886;10.1109/visual.2004.62;10.1109/tvcg.2008.162;10.1109/visual.2004.64;10.1109/visual.2004.5;10.1109/tvcg.2011.198;10.1109/tvcg.2008.148;10.1109/tvcg.2013.172,"Diffusion Kurtosis Imaging, Diffusion Tensor Imaging, Spatio-Angular Fields, Spherical Harmonics Fields, Tensor Fields",24.0,10.0,51.0,798.0,BP,,diffusion tensor imaging;glyph based visualization;using spherical;lighting functions;non,0.6946;0.3961;0.2948;0.1922;-0.0071,"[np.int64(-1), np.int64(-1), -1, -1, -1]",43;262;-1;-1;-1,43;262,43
Vis,2002,Efficient compression and rendering of multi-resolution meshes,10.1109/visual.2002.1183794,http://dx.doi.org/10.1109/VISUAL.2002.1183794,347.0,354.0,C,"We present a method to code the multiresolution structure of a 3D triangle mesh in a manner that allows progressive decoding and efficient rendering at a client machine. The code is based on a special ordering of the mesh vertices which has good locality and continuity properties, inducing a natural multiresolution structure. This ordering also incorporates information allowing efficient rendering of the mesh at all resolutions using the contemporary vertex buffer mechanism. The performance of our code is shown to be competitive with existing progressive mesh compression methods, while achieving superior rendering speed.",Zachi Karni;Alexander Bogomjakov;Craig Gotsman,Z. Karni;A. Bogomjakov;C. Gotsman,"Center for Graphics and Geometric Computing, The Faculty of Computer Science, Technion-Israel Institute of Technology, Israel;Center for Graphics and Geometric Computing, The Faculty of Computer Science, Technion-Israel Institute of Technology, Israel;Center for Graphics and Geometric Computing, The Faculty of Computer Science, Technion-Israel Institute of Technology, Israel",10.1109/vis.1999.10000;10.1109/visual.2000.885711;10.1109/visual.1999.809902,"progressive compression, wavelets, geometry coding, rendering",73.0,19.0,26.0,133.0,,,progressive mesh compression;3d triangle;client machine code;ordering;continuity properties,0.6960;0.4235;0.1230;0.0541;0.0061,"[np.int64(-1), -1, -1, -1, -1]",107;-1;-1;-1;-1,107,107
InfoVis,2012,Whisper: Tracing the Spatiotemporal Process of Information Diffusion in Real Time,10.1109/tvcg.2012.291,http://dx.doi.org/10.1109/TVCG.2012.291,2649.0,2658.0,J,"When and where is an idea dispersed? Social media, like Twitter, has been increasingly used for exchanging information, opinions and emotions about events that are happening across the world. Here we propose a novel visualization design, “Whisper”, for tracing the process of information diffusion in social media in real time. Our design highlights three major characteristics of diffusion processes in social media: the temporal trend, social-spatial extent, and community response of a topic of interest. Such social, spatiotemporal processes are conveyed based on a sunflower metaphor whose seeds are often dispersed far away. In Whisper, we summarize the collective responses of communities on a given topic based on how tweets were retweeted by groups of users, through representing the sentiments extracted from the tweets, and tracing the pathways of retweets on a spatial hierarchical layout. We use an efficient flux line-drawing algorithm to trace multiple pathways so the temporal and spatial patterns can be identified even for a bursty event. A focused diffusion series highlights key roles such as opinion leaders in the diffusion process. We demonstrate how our design facilitates the understanding of when and where a piece of information is dispersed and what are the social responses of the crowd, for large-scale events including political campaigns and natural disasters. Initial feedback from domain experts suggests promising use for today's information consumption and dispersion in the wild.",Nan Cao 0001;Yu-Ru Lin;Xiaohua Sun;David Lazer;Shixia Liu;Huamin Qu,Nan Cao;Yu-Ru Lin;Xiaohua Sun;David Lazer;Shixia Liu;Huamin Qu,"Hong Kong University of Science and Technology, Hong Kong, China;Northeastern University and Harvard University, USA;TongJi University, China;Northeastern University and Harvard University, USA;Microsoft Research Asia, China;Hong Kong University of Science and Technology, Hong Kong, China",10.1109/tvcg.2009.171;10.1109/tvcg.2006.147;10.1109/infvis.2000.885098;10.1109/tvcg.2006.202;10.1109/tvcg.2007.70535;10.1109/tvcg.2010.129;10.1109/tvcg.2008.125;10.1109/tvcg.2011.188;10.1109/tvcg.2009.171,"Information visualization, Information diffusion, Contagion, Social media, Microblogging, Spatiotemporal patterns",200.0,127.0,54.0,2813.0,,,diffusion social media;sunflower metaphor;flux line;time design highlights;whisper tracing process,0.6252;0.2895;0.1945;0.1910;0.1499,"[np.int64(-1), -1, -1, -1, -1]",73;-1;-1;-1;-1,73,73
VAST,2010,A radial visualization tool for depicting hierarchically structured video content,10.1109/vast.2010.5650177,http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=5650177,251.0,252.0,M,"The visual analysis of video content is an important research topic due to the huge amount of video data that is generated every day. Annotating this data will become a major problem since the amount of videos further increases. With this work we introduce a system that combines a visualization tool with automatic video segmentation techniques and a characteristic key-frame extraction. A summary of the content of a whole video in one view is realized. Furthermore, the user can interactively browse through the video via our visualization interface to get more detailed information. The system is adapted to two application scenarios and a third application is discussed for future work.",Tobias Ruppert;Jörn Kohlhammer,Tobias Ruppert;Jörn Kohlhammer,"Fraunhofer Institute of Computer Graphics Research (IGD), Darmstadt, Germany;Fraunhofer Institute of Computer Graphics Research (IGD), Darmstadt, Germany",,,2.0,2.0,3.0,170.0,,,automatic video segmentation;characteristic key frame;visualization interface detailed;content important research;generated day,0.6770;0.3693;0.3603;0.1481;0.0066,"[np.int64(-1), -1, -1, -1, -1]",242;-1;-1;-1;-1,242,242
Vis,1990,Interactive visualization of quaternion Julia sets,10.1109/visual.1990.146384,http://dx.doi.org/10.1109/VISUAL.1990.146384,209.0,,C,"The first half of a two-step quaternion Julia set visualization system is described. This step uses a quarternion square root function to adapt the classic inverse iteration algorithm to the quaternions. The augmented version produces a 3-D Julia set defined by a point cloud that can be interactively manipulated on a graphics workstation. Several cues are assigned to the point cloud to increase depth perception. Finally, a short theorem is proven that extends the domain of the inverse iteration method to a rotational family of quadratic quaternion Julia sets.&lt;&lt;ETX&gt;&gt;",John C. Hart;Louis H. Kauffman;Daniel J. Sandin,J.C. Hart;L.H. Kauffman;D.J. Sandim,"Electronic Visualization Laboratory, University of Illinois, Chicago, USA;Electronic Visualization Laboratory, University of Illinois, Chicago, USA;Electron. Visualization Lab., Illinois Univ., Chicago, IL, USA",,,32.0,6.0,11.0,128.0,,,quaternion julia sets;point cloud increase;graphics workstation cues;inverse iteration method;family,0.6908;0.3330;0.2343;0.2197;-0.0066,"[np.int64(-1), -1, -1, -1, -1]",28;-1;-1;-1;-1,28,28
InfoVis,2020,Visual Reasoning Strategies for Effect Size Judgments and Decisions,10.1109/tvcg.2020.3030335,http://dx.doi.org/10.1109/TVCG.2020.3030335,272.0,282.0,J,"Uncertainty visualizations often emphasize point estimates to support magnitude estimates or decisions through visual comparison. However, when design choices emphasize means, users may overlook uncertainty information and misinterpret visual distance as a proxy for effect size. We present findings from a mixed design experiment on Mechanical Turk which tests eight uncertainty visualization designs: 95% containment intervals, hypothetical outcome plots, densities, and quantile dotplots, each with and without means added. We find that adding means to uncertainty visualizations has small biasing effects on both magnitude estimation and decision-making, consistent with discounting uncertainty. We also see that visualization designs that support the least biased effect size estimation do not support the best decision-making, suggesting that a chart user's sense of effect size may not necessarily be identical when they use the same information for different tasks. In a qualitative analysis of users' strategy descriptions, we find that many users switch strategies and do not employ an optimal strategy when one exists. Uncertainty visualizations which are optimally designed in theory may not be the most effective in practice because of the ways that users satisfice with heuristics, suggesting opportunities to better understand visualization effectiveness by modeling sets of potential strategies.",Alex Kale;Matthew Kay 0001;Jessica Hullman,Alex Kale;Matthew Kay;Jessica Hullman,University of Washington;University of Michigan;Northwestern University,10.1109/tvcg.2014.2346298;10.1109/tvcg.2019.2934287;10.1109/tvcg.2019.2934786;10.1109/tvcg.2018.2864909;10.1109/tvcg.2014.2346298,"Uncertainty visualization,graphical perception,data cognition",47.0,61.0,62.0,1686.0,BP,,uncertainty visualizations emphasize;findings mixed design;effective practice ways;turk;size necessarily identical,0.7414;0.3772;0.1407;0.1073;0.0611,"[np.int64(-1), -1, -1, -1, -1]",159;-1;-1;-1;-1,159,159
VAST,2017,Progressive Learning of Topic Modeling Parameters: A Visual Analytics Framework,10.1109/tvcg.2017.2745080,http://dx.doi.org/10.1109/TVCG.2017.2745080,382.0,391.0,J,"Topic modeling algorithms are widely used to analyze the thematic composition of text corpora but remain difficult to interpret and adjust. Addressing these limitations, we present a modular visual analytics framework, tackling the understandability and adaptability of topic models through a user-driven reinforcement learning process which does not require a deep understanding of the underlying topic modeling algorithms. Given a document corpus, our approach initializes two algorithm configurations based on a parameter space analysis that enhances document separability. We abstract the model complexity in an interactive visual workspace for exploring the automatic matching results of two models, investigating topic summaries, analyzing parameter distributions, and reviewing documents. The main contribution of our work is an iterative decision-making technique in which users provide a document-based relevance feedback that allows the framework to converge to a user-endorsed topic distribution. We also report feedback from a two-stage study which shows that our technique results in topic model quality improvements on two independent measures.",Mennatallah El-Assady;Rita Sevastjanova;Fabian Sperrle;Daniel A. Keim;Christopher Collins 0001,Mennatallah El-Assady;Rita Sevastjanova;Fabian Sperrle;Daniel Keim;Christopher Collins,"University of Ontario Institute of Technology, Canada and University of Konstanz, Germany;University of Konstanz, Germany;University of Konstanz, Germany;University of Konstanz, Germany;University of Ontario Institute of Technology, Canada",10.1109/tvcg.2015.2467618;10.1109/vast.2014.7042493;10.1109/tvcg.2013.212;10.1109/vast.2009.5333443;10.1109/tvcg.2011.239;10.1109/tvcg.2014.2346433;10.1109/tvcg.2010.129;10.1109/vast.2011.6102461;10.1109/tvcg.2013.162;10.1109/tvcg.2013.126;10.1109/tvcg.2014.2346321;10.1109/tvcg.2015.2467618,"Topic Model Configuration,Reinforcement Learning,Feature Detection and Tracking,Iterative Optimization",78.0,49.0,43.0,2032.0,HM,,topic modeling;complexity interactive visual;users provide document;decision;adjust addressing limitations,0.6527;0.3022;0.1728;0.0461;0.0120,"[np.int64(-1), -1, -1, -1, -1]",46;-1;-1;-1;-1,46,46
Vis,2000,Immersive virtual reality for visualizing flow through an artery,10.1109/visual.2000.885731,http://dx.doi.org/10.1109/VISUAL.2000.885731,457.0,460.0,C,"We present an immersive system for exploring numerically simulated flow data through a model of a coronary artery graft. This tightly-coupled interdisciplinary project is aimed at understanding how to reduce the failure rate of these grafts. The visualization system provides a mechanism for exploring the effect of changes to the geometry, to the flow, and for exploring potential sources of future lesions. The system uses gestural and voice interactions exclusively, moving away from more traditional windows/icons/menus/point-and-click (WIMP) interfaces. We present an example session using the system and discuss our experiences developing, testing, and using it. We describe some of the interaction and rendering techniques that we experimented with and describe their level of success. Our experience suggests that systems like this are exciting to clinical researchers, but conclusive evidence of their value is not yet available.",Andrew S. Forsberg;David H. Laidlaw;Andries van Dam;Robert M. Kirby;George E. Karniadakis;Jonathan L. Elion,A.S. Forsberg;D.H. Laidlaw;A. Van Dam;R.M. Kirby;G.E. Kafniadakis;J.L. Elion,"Dept. of Comput. Sci., Brown Univ., Providence, RI, USA;Center for Fluid Mechanics Applied Math, Brown University, Providence, RI, USA;Computer Science, Brown University, Providence, RI, USA;Computer Science, Brown University, Providence, RI, USA;;Computer Science, Brown University, Providence, RI, USA",10.1109/visual.1991.175771;10.1109/visual.1991.175771,,49.0,11.0,17.0,115.0,,,interaction rendering techniques;coronary artery graft;flow exploring potential;point click wimp;conclusive evidence value,0.5453;0.3276;0.2181;0.1388;0.0236,"[np.int64(-1), -1, -1, -1, -1]",227;-1;-1;-1;-1,227,227
Vis,1992,A 3-D streamline tracking algorithm using dual stream functions,10.1109/visual.1992.235225,http://dx.doi.org/10.1109/VISUAL.1992.235225,62.0,68.0,C,"A methodology has been developed for constructing streamlines and particle paths in numerically generated fluid velocity fields. A graphical technique is used to convert the discretely defined flow within a cell into one represented by two three-dimensional stream functions. Streamlines are calculated by tracking constant values of each stream function, a process which corresponds to finding the intersection of two stream surfaces. The tracking process is mass conservative and does not use a time stepping method for integration, thus eliminating a computationally intensive part of traditional tracking algorithms. The method can be applied generally to any three-dimensional compressible or incompressible steady flow. Results presented compare the performance of the new method to the most commonly used scheme and show that calculation times can be reduced by an order of magnitude.&lt;&lt;ETX&gt;&gt;",David N. Kenwright;Gordon D. Mallison,D.N. Kenwright;G.D. Mallinson,"Department of Mechanical Engineering, University of Auckland, Auckland, New Zealand;Department of Mechanical Engineering, University of Auckland, Auckland, New Zealand",,,106.0,23.0,14.0,306.0,,,particle paths numerically;incompressible steady flow;performance new method;conservative does;used convert,0.6275;0.4349;0.1739;-0.0101;-0.0665,"[np.int64(-1), -1, -1, -1, -1]",38;-1;-1;-1;-1,38,38
Vis,1996,A haptic interaction method for volume visualization,10.1109/visual.1996.568108,http://dx.doi.org/10.1109/VISUAL.1996.568108,197.0,204.0,C,"Volume visualization techniques typically provide support for visual exploration of data, however additional information can be conveyed by allowing a user to see as well as feel virtual objects. We present a haptic interaction method that is suitable for both volume visualization and modeling applications. Point contact forces are computed directly from the volume data and are consistent with the isosurface and volume rendering methods, providing a strong correspondence between visual and haptic feedback. Virtual tools are simulated by applying three-dimensional filters to some properties of the data within the extent of the tool, and interactive visual feedback rates are obtained by using an accelerated ray casting method. This haptic interaction method was implemented using a PHANToM haptic interface.",Ricardo S. Avila;Lisa M. Sobierajski,R.S. Avila;L.M. Sobierajski,"GE Corporate Research and Development Center, Schenectady, NY, USA;GE Corporate Research and Development Center, Schenectady, NY, USA",10.1109/visual.1995.480792;10.1109/visual.1995.480792,,442.0,107.0,17.0,836.0,,,haptic interaction;isosurface volume rendering;exploration data additional;ray;computed directly,0.6529;0.4567;0.1779;0.1029;0.0983,"[np.int64(-1), -1, -1, -1, -1]",79;-1;-1;-1;-1,79,79
InfoVis,2009,code_swarm: A Design Study in Organic Software Visualization,10.1109/tvcg.2009.123,http://dx.doi.org/10.1109/TVCG.2009.123,1097.0,1104.0,J,"In May of 2008, we published online a series of software visualization videos using a method called code_swarm. Shortly thereafter, we made the code open source and its popularity took off. This paper is a study of our code swarm application, comprising its design, results and public response. We share our design methodology, including why we chose the organic information visualization technique, how we designed for both developers and a casual audience, and what lessons we learned from our experiment. We validate the results produced by code_swarm through a qualitative analysis and by gathering online user comments. Furthermore, we successfully released the code as open source, and the software community used it to visualize their own projects and shared their results as well. In the end, we believe code_swarm has positive implications for the future of organic information design and open source information visualization practice.",Michael Ogawa;Kwan-Liu Ma,Michael Ogawa;Kwan-Liu Ma,"VIDI Laboratory, University of California, Davis, USA;VIDI Laboratory, University of California, Davis, USA",10.1109/tvcg.2007.70541;10.1109/tvcg.2008.172;10.1109/infvis.2005.1532125;10.1109/infvis.2004.65;10.1109/infvis.2005.1532122;10.1109/tvcg.2007.70541,"Software visualization, organic information visualization, software development history and evolution",120.0,50.0,32.0,1056.0,,,software visualization;believe code_swarm positive;audience lessons learned;published online series;chose organic,0.6813;0.3371;0.2222;0.1817;0.1121,"[np.int64(-1), -1, -1, -1, -1]",196;-1;-1;-1;-1,196,196
Vis,2010,Supine and Prone Colon Registration Using Quasi-Conformal Mapping,10.1109/tvcg.2010.200,http://dx.doi.org/10.1109/TVCG.2010.200,1348.0,1357.0,J,"In virtual colonoscopy, CT scans are typically acquired with the patient in both supine (facing up) and prone (facing down) positions. The registration of these two scans is desirable so that the user can clarify situations or confirm polyp findings at a location in one scan with the same location in the other, thereby improving polyp detection rates and reducing false positives. However, this supine-prone registration is challenging because of the substantial distortions in the colon shape due to the patient's change in position. We present an efficient algorithm and framework for performing this registration through the use of conformal geometry to guarantee that the registration is a diffeomorphism (a one-to-one and onto mapping). The taeniae coli and colon flexures are automatically extracted for each supine and prone surface, employing the colon geometry. The two colon surfaces are then divided into several segments using the flexures, and each segment is cut along a taenia coli and conformally flattened to the rectangular domain using holomorphic differentials. The mean curvature is color encoded as texture images, from which feature points are automatically detected using graph cut segmentation, mathematic morphological operations, and principal component analysis. Corresponding feature points are found between supine and prone and are used to adjust the conformal flattening to be quasi-conformal, such that the features become aligned. We present multiple methods of visualizing our results, including 2D flattened rendering, corresponding 3D endoluminal views, and rendering of distortion measurements. We demonstrate the efficiency and efficacy of our registration method by illustrating matched views on both the 2D flattened colon images and in the 3D volume rendered colon endoluminal view. We analytically evaluate the correctness of the results by measuring the distance between features on the registered colons.",Wei Zeng 0002;Joseph Marino;Krishna Chaitanya Gurijala;Xianfeng Gu;Arie E. Kaufman,Wei Zeng;Joseph Marino;Krishna Chaitanya Gurijala;Xianfeng Gu;Arie Kaufman,"Computer Science Department, Stony Brook University, USA;Computer Science Department, Stony Brook University, USA;Computer Science Department, Stony Brook University, USA;Computer Science Department, Stony Brook University, USA;Computer Science Department, Stony Brook University, USA",10.1109/visual.2005.1532806;10.1109/tvcg.2006.112;10.1109/visual.2004.75;10.1109/tvcg.2006.158;10.1109/visual.2005.1532806,"Data registration, geometry-based techniques, medical visualization, mathematical foundations for visualization",95.0,63.0,39.0,826.0,,,colon images 3d;registration use conformal;differentials mean curvature;taeniae;rates reducing false,0.6685;0.3417;0.1948;0.0919;0.0021,"[np.int64(-1), -1, -1, -1, -1]",290;-1;-1;-1;-1,290,290
Vis,2000,Bicubic subdivision-surface wavelets for large-scale isosurface representation and visualization,10.1109/visual.2000.885720,http://doi.ieeecomputersociety.org/10.1109/VISUAL.2000.885720,389.0,396.0,C,"We introduce a new subdivision-surface wavelet transform for arbitrary two-manifolds with boundary that is the first to use simple lifting-style filtering operations with bicubic precision. We also describe a conversion process for re-mapping large-scale isosurfaces to have subdivision connectivity and fair parameterizations so that the new wavelet transform can be used for compression and visualization. The main idea enabling our wavelet transform is the circular symmetrization of the filters in irregular neighborhoods, which replaces the traditional separation of filters into two 1D passes. Our wavelet transform uses polygonal base meshes to represent surface topology, from which a Catmull-Clark-style subdivision hierarchy is generated. The details between these levels of resolution are quickly computed and compactly stored as wavelet coefficients. The isosurface conversion process begins with a contour triangulation computed using conventional techniques, which we subsequently simplify with a variant edge-collapse procedure, followed by an edge-removal process. This provides a coarse initial base mesh, which is subsequently refined, relaxed and attracted in phases to converge to the contour. The conversion is designed to produce smooth, untangled and minimally-skewed parameterizations which improves the subsequent compression after applying the transform. We have demonstrated our conversion and transform for an isosurface obtained from a high-resolution turbulent-mixing hydrodynamics simulation, showing the potential for compression and level-of-detail visualization.",Martin Bertram 0001;Mark A. Duchaineau;Bernd Hamann;Kenneth I. Joy,M. Bertram;M.A. Duchaineau;B. Hamann;K.I. Joy,"CASC, Lawrence Livermore Nat. Lab., CA, USA#University of California at Davis;CASC, Lawrence Livermore Nat. Lab., CA, USA;University of California at Davis;University of California at Davis",10.1109/visual.1994.346332;10.1109/visual.1997.663871;10.1109/visual.2000.885717,,114.0,29.0,0.0,30.0,,,subdivision surface wavelet;transform arbitrary manifolds;turbulent mixing hydrodynamics;subsequently simplify variant;compactly stored,0.6968;0.3327;0.2529;0.0707;0.0648,"[np.int64(-1), -1, -1, -1, -1]",248;-1;-1;-1;-1,248,248
Vis,1997,A comparison of normal estimation schemes,10.1109/visual.1997.663848,http://dx.doi.org/10.1109/VISUAL.1997.663848,19.0,26.0,C,"The task of reconstructing the derivative of a discrete function is essential for its shading and rendering as well as being widely used in image processing and analysis. We survey the possible methods for normal estimation in volume rendering and divide them into two classes based on the delivered numerical accuracy. The three members of the first class determine the normal in two steps by employing both interpolation and derivative filters. Among these is a new method which has never been realized. The members of the first class are all equally accurate. The second class has only one member and employs a continuous derivative filter obtained through the analytic derivation of an interpolation filter. We use the new method to analytically compare the accuracy of the first class with that of the second. As a result of our analysis we show that even inexpensive schemes can in fact be more accurate than high order methods. We describe the theoretical computational cost of applying the schemes in a volume rendering application and provide guidelines for helping one choose a scheme for estimating derivatives. In particular we find that the new method can be very inexpensive and can compete with the normal estimations which pre-shade and pre-classify the volume (M. Levoy, 1988).",Torsten Möller;Raghu Machiraju;Klaus Mueller 0001;Roni Yagel,T. Moller;R. Machiraju;K. Mueller;R. Yagel,"The Ohio State University, Columbus, Ohio;Mississippi State University, Mississippi;The Ohio State University, Columbus, Ohio;The Ohio State University, Columbus, Ohio",10.1109/visual.1994.346331;10.1109/visual.1994.346331,"interpolation filters, derivative filters, filter design, normal estimation, Taylor series expansion, efficient volume rendering",129.0,31.0,16.0,191.0,,,estimation volume rendering;reconstructing derivative discrete;shade pre classify;normal;cost applying,0.6356;0.3703;0.2391;0.1777;0.0496,"[np.int64(-1), -1, -1, -1, -1]",256;-1;-1;-1;-1,256,256
InfoVis,2015,TimeNotes: A Study on Effective Chart Visualization and Interaction Techniques for Time-Series Data,10.1109/tvcg.2015.2467751,http://dx.doi.org/10.1109/TVCG.2015.2467751,549.0,558.0,J,"Collecting sensor data results in large temporal data sets which need to be visualized, analyzed, and presented. One-dimensional time-series charts are used, but these present problems when screen resolution is small in comparison to the data. This can result in severe over-plotting, giving rise for the requirement to provide effective rendering and methods to allow interaction with the detailed data. Common solutions can be categorized as multi-scale representations, frequency based, and lens based interaction techniques. In this paper, we comparatively evaluate existing methods, such as Stack Zoom [15] and ChronoLenses [38], giving a graphical overview of each and classifying their ability to explore and interact with data. We propose new visualizations and other extensions to the existing approaches. We undertake and report an empirical study and a field study using these techniques.",James S. Walker;Rita Borgo;Mark W. Jones 0001,James Walker;Rita Borgo;Mark W. Jones,Swansea University;Swansea University;Swansea University,10.1109/tvcg.2009.181;10.1109/tvcg.2014.2346428;10.1109/infvis.2005.1532148;10.1109/tvcg.2011.160;10.1109/tvcg.2010.162;10.1109/tvcg.2010.193;10.1109/infvis.1999.801860;10.1109/tvcg.2011.195;10.1109/tvcg.2009.181,"Time-series Exploration, Focus+Context, Lens, Interaction Techniques",61.0,45.0,38.0,3502.0,,,time series charts;lens based interaction;explore;screen resolution small;common solutions,0.5381;0.3860;0.2640;0.1516;-0.0059,"[np.int64(-1), -1, -1, -1, -1]",163;-1;-1;-1;-1,163,163
VAST,2019,CourtTime: Generating Actionable Insights into Tennis Matches Using Visual Analytics,10.1109/tvcg.2019.2934243,http://dx.doi.org/10.1109/TVCG.2019.2934243,397.0,406.0,J,"Tennis players and coaches of all proficiency levels seek to understand and improve their play. Summary statistics alone are inadequate to provide the insights players need to improve their games. Spatio-temporal data capturing player and ball movements is likely to provide the actionable insights needed to identify player strengths, weaknesses, and strategies. To fully utilize this spatio-temporal data, we need to integrate it with domain-relevant context meta-data. In this paper, we propose CourtTime, a novel approach to perform data-driven visual analysis of individual tennis matches. Our visual approach introduces a novel visual metaphor, namely 1–D Space-Time Charts that enable the analysis of single points at a glance based on small multiples. We also employ user-driven sorting and clustering techniques and a layout technique that aligns the last few shots in a point to facilitate shot pattern discovery. We discuss the usefulness of CourtTime via an extensive case study and report on feedback from an amateur tennis player and three tennis coaches.",Tom Polk;Dominik Jäckle;Johannes Häußler;Jing Yang 0001,Tom Polk;Dominik Jäckle;Johannes Häußler;Jing Yang,University of Konstanz;University of Konstanz;University of Konstanz;University of North Carolina,10.1109/vast.2014.7042478;10.1109/infvis.1996.559229;10.1109/visual.2001.964496;10.1109/tvcg.2017.2744218;10.1109/tvcg.2012.263;10.1109/tvcg.2013.192;10.1109/tvcg.2014.2346445;10.1109/vast.2014.7042478,"Visual analytics,tennis analysis,sports analytics,spatio-temporal analysis",23.0,16.0,40.0,1377.0,,,tennis matches visual;user driven sorting;fully utilize spatio;meta data paper;time,0.6671;0.3313;0.2859;0.2177;0.1899,"[np.int64(-1), -1, -1, -1, -1]",158;-1;-1;-1;-1,158,158
VAST,2015,Visual scalability of spatial ensemble uncertainty,10.1109/vast.2015.7347671,http://dx.doi.org/10.1109/VAST.2015.7347671,187.0,188.0,M,"Weather Research and Forecasting (WRF) models simulate weather conditions by generating 2D numerical weather prediction ensemble members either through perturbing initial conditions or by changing different parameterization schemes, e.g., cumulus and microphysics schemes. These simulations are often used by weather analysts to analyze the nature of uncertainty attributed by these simulations to forecast weather conditions with good accuracy. The number of simulations used for forecasting is growing with the advent of increase in computing power. Hence, there is a need for providing better visual insights of uncertainty with growing number of ensemble members. We propose a geo visual analytical framework that uses visual analytics approach to resolve visual scalability of these ensemble members. Our approach naturally fits with the workflow of an analyst analyzing ensemble spatial uncertainty. Meteorologists evaluated our framework qualitatively and found it to be effective in acquiring insights of spatial uncertainty associated with multiple ensemble runs that are simulated using multiple parameterization schemes.",Sujan Anreddy;Song Zhang 0004;Andrew Mercer 0001;Jamie L. Dyer;J. Edward Swan II,Sujan Anreddy;Song Zhang;Andrew Mercer;Jamie Dyer;J. Edward Swan,Mississippi State University;Mississippi State University;Mississippi State University;Mississippi State University;Mississippi State University,0.1109/tvcg.2010.181,,1.0,1.0,6.0,177.0,,,spatial uncertainty meteorologists;visual analytics approach;number ensemble members;initial conditions changing;good,0.6240;0.4700;0.1982;-0.0158;-0.0294,"[np.int64(-1), -1, -1, -1, -1]",-1;-1;-1;-1;-1,,-1
SciVis,2020,Mode Surfaces of Symmetric Tensor Fields: Topological Analysis and Seamless Extraction,10.1109/tvcg.2020.3030431,http://dx.doi.org/10.1109/TVCG.2020.3030431,583.0,592.0,J,"Mode surfaces are the generalization of degenerate curves and neutral surfaces, which constitute 3D symmetric tensor field topology. Efficient analysis and visualization of mode surfaces can provide additional insight into not only degenerate curves and neutral surfaces, but also how these features transition into each other. Moreover, the geometry and topology of mode surfaces can help domain scientists better understand the tensor fields in their applications. Existing mode surface extraction methods can miss features in the surfaces. Moreover, the mode surfaces extracted from neighboring cells have gaps, which make their subsequent analysis difficult. In this paper, we provide novel analysis on the topological structures of mode surfaces, including a common parameterization of all mode surfaces of a tensor field using 2D asymmetric tensors. This allows us to not only better understand the structures in mode surfaces and their interactions with degenerate curves and neutral surfaces, but also develop an efficient algorithm to seamlessly extract mode surfaces, including neutral surfaces. The seamless mode surfaces enable efficient analysis of their geometric structures, such as the principal curvature directions. We apply our analysis and visualization to a number of solid mechanics data sets.",Botong Qu;Lawrence Roy;Yue Zhang 0009;Eugene Zhang,Botong Qu;Lawrence Roy;Yue Zhang;Eugene Zhang,"School of Electrical Engineering and Computer Science, Oregon State University;School of Electrical Engineering and Computer Science, Oregon State University;School of Electrical Engineering and Computer Science, Oregon State University;School of Electrical Engineering and Computer Science, Oregon State University",10.1109/visual.1994.346326;10.1109/tvcg.2019.2934314;10.1109/visual.2004.28;10.1109/tvcg.2011.170;10.1109/tvcg.2018.2864846;10.1109/tvcg.2018.2864768;10.1109/tvcg.2008.148;10.1109/visual.2004.105;10.1109/visual.2005.1532770,"Tensor field visualization,tensor field topology,traceless tensors,degenerate curve extraction,neutral surface extraction,mode surface extraction",4.0,5.0,40.0,280.0,,,mode surfaces tensor;field topology;asymmetric;number solid;subsequent analysis difficult,0.7290;0.2695;0.1699;0.1140;-0.0951,"[np.int64(-1), -1, -1, -1, -1]",17;-1;-1;-1;-1,17,17
InfoVis,2006,MatrixExplorer: a Dual-Representation System to Explore Social Networks,10.1109/tvcg.2006.160,http://dx.doi.org/10.1109/TVCG.2006.160,677.0,684.0,J,"MatrixExplorer is a network visualization system that uses two representations: node-link diagrams and matrices. Its design comes from a list of requirements formalized after several interviews and a participatory design session conducted with social science researchers. Although matrices are commonly used in social networks analysis, very few systems support the matrix-based representations to visualize and analyze networks. MatrixExplorer provides several novel features to support the exploration of social networks with a matrix-based representation, in addition to the standard interactive filtering and clustering functions. It provides tools to reorder (layout) matrices, to annotate and compare findings across different layouts and find consensus among several clusterings. MatrixExplorer also supports node-link diagram views which are familiar to most users and remain a convenient way to publish or communicate exploration results. Matrix and node-link representations are kept synchronized at all stages of the exploration process",Nathalie Henry;Jean-Daniel Fekete,Nathalie Henry;Jean-daniel Fekete,"INRIA Futurs/LRI and University of Sydney, France;INRIA-Futurs/LRI, France",10.1109/infvis.2004.64;10.1109/infvis.2004.64,"social networks visualization, node-link diagrams, matrix-based representations, exploratory process, matrix ordering, interactive clustering, consensus",402.0,184.0,35.0,1996.0,,,matrixexplorer network visualization;filtering clustering functions;compare findings different;list requirements formalized;participatory,0.7475;0.2584;0.1463;0.1120;0.1042,"[np.int64(-1), -1, -1, -1, -1]",169;-1;-1;-1;-1,169,169
Vis,2021,The Weighted Average Illusion: Biases in Perceived Mean Position in Scatterplots,10.1109/tvcg.2021.3114783,http://dx.doi.org/10.1109/TVCG.2021.3114783,987.0,997.0,J,"Scatterplots can encode a third dimension by using additional channels like size or color (e.g. bubble charts). We explore a potential misinterpretation of trivariate scatterplots, which we call the <i>weighted average illusion</i>, where locations of larger and darker points are given more weight toward x- and y-mean estimates. This systematic bias is sensitive to a designer's choice of size or lightness ranges mapped onto the data. In this paper, we quantify this bias against varying size/lightness ranges and data correlations. We discuss possible explanations for its cause by measuring attention given to individual data points using a vision science technique called the centroid method. Our work illustrates how ensemble processing mechanisms and mental shortcuts can significantly distort visual summaries of data, and can lead to misjudgments like the demonstrated weighted average illusion.",Matt-Heun Hong;Jessica K. Witt;Danielle Albers Szafir,Matt-Heun Hong;Jessica K. Witt;Danielle Albers Szafir,"ATLAS Institute, University of Colorado, Boulder, USA;Department of Psychology, Colorado State University, USA;ATLAS Institute, University of Colorado, Boulder, USA",10.1109/tvcg.2017.2745086;10.1109/tvcg.2014.2346978;10.1109/tvcg.2018.2865233;10.1109/tvcg.2013.183;10.1109/tvcg.2012.233;10.1109/tvcg.2012.233;10.1109/tvcg.2014.2346979;10.1109/tvcg.2017.2744184;10.1109/tvcg.2017.2744359;10.1109/tvcg.2019.2934208;10.1109/tvcg.2019.2934400;10.1109/tvcg.2017.2745086,"Human-Subjects Quantitative Studies,Perception & Cognition",5.0,10.0,96.0,689.0,,,scatterplots encode dimension;weighted average;bubble;mechanisms mental shortcuts;lead misjudgments,0.5886;0.2799;0.2492;0.2261;0.0727,"[np.int64(-1), -1, -1, -1, -1]",94;-1;-1;-1;-1,94,94
Vis,2003,Producing high-quality visualizations of large-scale simulation,10.1109/visual.2003.1250422,http://dx.doi.org/10.1109/VISUAL.2003.1250422,575.0,580.0,C,"This paper describes the work of a team of researchers in computer graphics, geometric computing, and civil engineering to produce a visualization of the September 2001 attack on the Pentagon. The immediate motivation for the project was to understand the behavior of the building under the impact. The longer term motivation was to establish a path for producing high-quality visualizations of large scale simulations. The first challenge was managing the enormous complexity of the scene to fit within the limits of state-of-the art simulation software systems and supercomputing resources. The second challenge was to integrate the simulation results into a high-quality visualization. To meet this challenge, we implemented a custom importer that simplifies and loads the massive simulation data in a commercial animation system. The surrounding scene is modeled using image-based techniques and is also imported in the animation system where the visualization is produced. A specific issue for us was to federate the simulation and the animation systems, both commercial systems not under our control and following internally different conceptualizations of geometry and animation. This had to be done such that scalability was achieved. The reusable link created between the two systems allows communicating the results to non-specialists and the public at large, as well as facilitating communication in teams with members having diverse technical backgrounds.",Voicu Popescu;Christoph M. Hoffmann;Sami Kilic;Mete A. Sözen;Scott Meador,V. Popescu;C. Hoffmann;S. Kilic;M. Sozen;S. Meador,"Purdue University, USA;CS, Purdue University, USA;CRI, Purdue University, USA;CE, Purdue University, USA;ITaP, Purdue University, USA",,,11.0,3.0,19.0,102.0,,,visualization september 2001;large scale simulations;techniques imported animation;non;longer term motivation,0.5919;0.4507;0.3391;0.0465;-0.0082,"[np.int64(-1), np.int64(-1), -1, -1, -1]",270;15;-1;-1;-1,15;270,270
Vis,2024,ProvenanceWidgets: A Library of UI Control Elements to Track and Dynamically Overlay Analytic Provenance,10.1109/tvcg.2024.3456144,http://dx.doi.org/10.1109/TVCG.2024.3456144,1235.0,1245.0,J,"We present ProvenanceWidgets, a Javascript library of UI control elements such as radio buttons, checkboxes, and dropdowns to track and dynamically overlay a user's analytic provenance. These in situ overlays not only save screen space but also minimize the amount of time and effort needed to access the same information from elsewhere in the UI. In this paper, we discuss how we design modular UI control elements to track how often and how recently a user interacts with them and design visual overlays showing an aggregated summary as well as a detailed temporal history. We demonstrate the capability of ProvenanceWidgets by recreating three prior widget libraries: (1) Scented Widgets, (2) Phosphor objects, and (3) Dynamic Query Widgets. We also evaluated its expressiveness and conducted case studies with visualization developers to evaluate its effectiveness. We find that ProvenanceWidgets enables developers to implement custom provenance-tracking applications effectively. ProvenanceWidgets is available as open-source software at https://github.com/ProvenanceWidgets to help application developers build custom provenance-based systems.",Arpit Narechania;Kaustubh Odak;Mennatallah El-Assady;Alex Endert,Arpit Narechania;Kaustubh Odak;Mennatallah El-Assady;Alex Endert,"Georgia Tech, USA;Georgia Tech, USA;ETH Zürich, Switzerland;Georgia Tech, USA",10.1109/visual.2005.1532788;10.1109/tvcg.2022.3209495;10.1109/tvcg.2016.2599058;10.1109/tvcg.2008.137;10.1109/tvcg.2014.2346452;10.1109/tvcg.2021.3114827;10.1109/tvcg.2021.3114820;10.1109/tvcg.2015.2467551;10.1109/tvcg.2016.2599030;10.1109/tvcg.2021.3114862;10.1109/tvcg.2007.70589,"Provenance,Analytic provenance,,,Visualization,UI controls,GUI elements,JavaScript library",,0.0,79.0,151.0,,X,provenancewidgets;javascript library;user interacts design;time;phosphor objects dynamic,0.7281;0.2902;0.2626;0.0853;0.0776,"[np.int64(-1), -1, -1, -1, -1]",291;-1;-1;-1;-1,291,291
InfoVis,2014,Origin-Destination Flow Data Smoothing and Mapping,10.1109/tvcg.2014.2346271,http://dx.doi.org/10.1109/TVCG.2014.2346271,2043.0,2052.0,J,"This paper presents a new approach to flow mapping that extracts inherent patterns from massive geographic mobility data and constructs effective visual representations of the data for the understanding of complex flow trends. This approach involves a new method for origin-destination flow density estimation and a new method for flow map generalization, which together can remove spurious data variance, normalize flows with control population, and detect high-level patterns that are not discernable with existing approaches. The approach achieves three main objectives in addressing the challenges for analyzing and mapping massive flow data. First, it removes the effect of size differences among spatial units via kernel-based density estimation, which produces a measurement of flow volume between each pair of origin and destination. Second, it extracts major flow patterns in massive flow data through a new flow sampling method, which filters out duplicate information in the smoothed flows. Third, it enables effective flow mapping and allows intuitive perception of flow patterns among origins and destinations without bundling or altering flow paths. The approach can work with both point-based flow data (such as taxi trips with GPS locations) and area-based flow data (such as county-to-county migration). Moreover, the approach can be used to detect and compare flow patterns at different scales or in relatively sparse flow datasets, such as migration for each age group. We evaluate and demonstrate the new approach with case studies of U.S. migration data and experiments with synthetic data.",Diansheng Guo;Xi Zhu 0002,Diansheng Guo;Xi Zhu,"Department of Geography, University of South Carolina;Department of Geography, University of South Carolina",10.1109/tvcg.2009.143;10.1109/tvcg.2008.135;10.1109/tvcg.2006.147;10.1109/tvcg.2006.193;10.1109/tvcg.2011.202;10.1109/infvis.2005.1532150;10.1109/tvcg.2011.181;10.1109/visual.2005.1532819;10.1109/tvcg.2009.143,"flow mapping, kernel smoothing, generalization, multi-resolution mapping, graph drawing, spatial data mining",155.0,108.0,45.0,2927.0,,,geographic mobility data;altering flow;scales relatively sparse;understanding complex;age,0.6322;0.2987;0.1738;0.1192;0.0325,"[np.int64(-1), -1, -1, -1, -1]",67;-1;-1;-1;-1,67,67
Vis,2010,FI3D: Direct-Touch Interaction for the Exploration of 3D Scientific Visualization Spaces,10.1109/tvcg.2010.157,http://dx.doi.org/10.1109/TVCG.2010.157,1613.0,1622.0,J,"We present the design and evaluation of FI3D, a direct-touch data exploration technique for 3D visualization spaces. The exploration of three-dimensional data is core to many tasks and domains involving scientific visualizations. Thus, effective data navigation techniques are essential to enable comprehension, understanding, and analysis of the information space. While evidence exists that touch can provide higher-bandwidth input, somesthetic information that is valuable when interacting with virtual worlds, and awareness when working in collaboration, scientific data exploration in 3D poses unique challenges to the development of effective data manipulations. We present a technique that provides touch interaction with 3D scientific data spaces in 7 DOF. This interaction does not require the presence of dedicated objects to constrain the mapping, a design decision important for many scientific datasets such as particle simulations in astronomy or physics. We report on an evaluation that compares the technique to conventional mouse-based interaction. Our results show that touch interaction is competitive in interaction speed for translation and integrated interaction, is easy to learn and use, and is preferred for exploration and wayfinding tasks. To further explore the applicability of our basic technique for other types of scientific visualizations we present a second case study, adjusting the interaction to the illustrative visualization of fiber tracts of the brain and the manipulation of cutting planes in this context.",Lingyun Yu 0001;Pjotr Svetachov;Petra Isenberg;Maarten H. Everts;Tobias Isenberg 0001,Lingyun Yu;Pjotr Svetachov;Petra Isenberg;Maarten H. Everts;Tobias Isenberg,"University of Groningam, Netherlands;University of Groningam, Netherlands;INRIA, France;University of Groningam, Netherlands;University of Groningam, Netherlands",10.1109/visual.2005.1532778;10.1109/tvcg.2007.70515;10.1109/visual.2004.30;10.1109/visual.2005.1532778,"Direct-touch interaction, wall displays, 3D navigation and exploration, evaluation, illustrative visualization",109.0,58.0,55.0,1485.0,,,3d visualization spaces;touch provide higher;fiber tracts brain;data manipulations;astronomy physics,0.6703;0.3125;0.2633;0.2368;0.1808,"[np.int64(-1), -1, -1, -1, -1]",110;-1;-1;-1;-1,110,110
Vis,2006,Extensions of the Zwart-Powell Box Spline for Volumetric Data Reconstruction on the Cartesian Lattice,10.1109/tvcg.2006.141,http://dx.doi.org/10.1109/TVCG.2006.141,1337.0,1344.0,J,"In this article we propose a box spline and its variants for reconstructing volumetric data sampled on the Cartesian lattice. In particular we present a tri-variate box spline reconstruction kernel that is superior to tensor product reconstruction schemes in terms of recovering the proper Cartesian spectrum of the underlying function. This box spline produces a C&lt;sup&gt;2&lt;/sup&gt; reconstruction that can be considered as a three dimensional extension of the well known Zwart-Powell element in 2D. While its smoothness and approximation power are equivalent to those of the tri-cubic B-spline, we illustrate the superiority of this reconstruction on functions sampled on the Cartesian lattice and contrast it to tensor product B-splines. Our construction is validated through a Fourier domain analysis of the reconstruction behavior of this box spline. Moreover, we present a stable method for evaluation of this box spline by means of a decomposition. Through a convolution, this decomposition reduces the problem to evaluation of a four directional box spline that we previously published in its explicit closed form",Alireza Entezari;Torsten Möller,Alireza Entezari;Torsten Moller,"School of Computing Science, Simon Fraser University, Canada;School of Computing Science, Simon Fraser University, Canada",10.1109/visual.1994.346331;10.1109/visual.1993.398851;10.1109/visual.2005.1532811;10.1109/visual.2004.65;10.1109/visual.1997.663848;10.1109/visual.1994.346331,"Volumetric data interpolation, reconstruction, box splines",41.0,23.0,27.0,272.0,,,spline reconstruction;fourier domain;tri variate box;zwart powell;tensor product,0.6931;0.2076;0.1815;0.1607;0.1439,"[np.int64(-1), -1, -1, -1, -1]",254;-1;-1;-1;-1,254,254
InfoVis,2014,DimpVis: Exploring Time-varying Information Visualizations by Direct Manipulation,10.1109/tvcg.2014.2346250,http://dx.doi.org/10.1109/TVCG.2014.2346250,2003.0,2012.0,J,"We introduce a new direct manipulation technique, DimpVis, for interacting with visual items in information visualizations to enable exploration of the time dimension. DimpVis is guided by visual hint paths which indicate how a selected data item changes through the time dimension in a visualization. Temporal navigation is controlled by manipulating any data item along its hint path. All other items are updated to reflect the new time. We demonstrate how the DimpVis technique can be designed to directly manipulate position, colour, and size in familiar visualizations such as bar charts and scatter plots, as a means for temporal navigation. We present results from a comparative evaluation, showing that the DimpVis technique was subjectively preferred and quantitatively competitive with the traditional time slider, and significantly faster than small multiples for a variety of tasks.",Brittany Kondo;Christopher Collins 0001,Brittany Kondo;Christopher Collins,University of Ontario Institute of Technology;University of Ontario Institute of Technology,10.1109/tvcg.2013.147;10.1109/tvcg.2012.204;10.1109/tvcg.2012.260;10.1109/tvcg.2008.175;10.1109/vast.2012.6400486;10.1109/tvcg.2012.265;10.1109/tvcg.2013.149;10.1109/infvis.2005.1532136;10.1109/tvcg.2011.185;10.1109/tvcg.2008.125;10.1109/tvcg.2011.195;10.1109/tvcg.2013.147,"Time navigation, direct manipulation, information visualization",71.0,40.0,33.0,1443.0,,,visualization temporal navigation;manipulating data item;dimpvis interacting;colour size familiar;designed directly,0.6740;0.2416;0.2107;0.1573;0.0539,"[np.int64(-1), -1, -1, -1, -1]",121;-1;-1;-1;-1,121,121
InfoVis,2002,Visualization schemas for flexible information visualization,10.1109/infvis.2002.1173142,http://dx.doi.org/10.1109/INFVIS.2002.1173142,15.0,22.0,C,"Relational databases provide significant flexibility to organize, store, and manipulate an infinite variety of complex data collections. This flexibility is enabled by the concept of relational data schemas, which allow data owners to easily design custom databases according to their unique needs. However, user interfaces and information visualizations for accessing and utilizing databases have not kept pace with this level of flexibility. This paper introduces the concept of visualization schemas, based on the Snap-Together Visualization model, which are analogous to relational data schemas. Visualization schemas enable users to rapidly construct customized multiple-view visualizations for databases in a similarly flexible fashion without programming. Since the design of appropriate visualizations for a given database depends on the data schema, visualization schemas are a natural analogy to the data schema concept.",Chris North 0001;Nathan Conklin;Varun Saini,C. North;N. Conklin;V. Saini,"Center for Human Computer Interaction Department of Computer Science, Virginia Polytechnic Institute and State University, Blacksburg, VA, USA;Center for Human Computer Interaction Department of Computer Science, Virginia Polytechnic Institute and State University, Blacksburg, VA, USA;Center for Human Computer Interaction Department of Computer Science, Virginia Polytechnic Institute and State University, Blacksburg, VA, USA",10.1109/infvis.1995.528688;10.1109/infvis.1997.636788;10.1109/infvis.1995.528688,,45.0,10.0,20.0,419.0,,,data schemas visualization;flexibility paper introduces;custom;enable users;kept pace level,0.7837;0.2010;0.1253;-0.0030;-0.0640,"[np.int64(-1), -1, -1, -1, -1]",198;-1;-1;-1;-1,198,198
InfoVis,2002,Graphical encoding for information visualization: an empirical study,10.1109/infvis.2002.1173146,http://dx.doi.org/10.1109/INFVIS.2002.1173146,43.0,50.0,C,"Research in several areas provides scientific guidance for use of graphical encoding to convey information in an information visualization display. By graphical encoding we mean the use of visual display elements such as icon color, shape, size, or position to convey information about objects represented by the icons. Literature offers inconclusive and often conflicting viewpoints, including the suggestion that the effectiveness of a graphical encoding depends on the type of data represented. Our empirical study suggests that the nature of the users' perceptual task is more indicative of the effectiveness of a graphical encoding than the type of data represented.",Lucy T. Nowell;Robert S. Schulman;Deborah Hix,L. Nowell;R. Schulman;D. Hix,"Battelle Pacific Northwest Laboratories, Richland, WA, USA;Department of Statistics, Virginia Technology, Blacksburg, VA, USA;Department of Computer Science, Virginia Technology, Blacksburg, VA, USA",,,83.0,11.0,31.0,813.0,,,information visualization display;elements icon color;encoding depends type;including;study suggests nature,0.7034;0.3011;0.1567;0.0529;0.0275,"[np.int64(-1), -1, -1, -1, -1]",273;-1;-1;-1;-1,273,273
InfoVis,2010,Visualization of Graph Products,10.1109/tvcg.2010.217,http://dx.doi.org/10.1109/TVCG.2010.217,1082.0,1089.0,J,"Graphs are a versatile structure and abstraction for binary relationships between objects. To gain insight into such relationships, their corresponding graph can be visualized. In the past, many classes of graphs have been defined, e.g. trees, planar graphs, directed acyclic graphs, and visualization algorithms were proposed for these classes. Although many graphs may only be classified as ""general"" graphs, they can contain substructures that belong to a certain class. Archambault proposed the TopoLayout framework: rather than draw any arbitrary graph using one method, split the graph into components that are homogeneous with respect to one graph class and then draw each component with an algorithm best suited for this class. Graph products constitute a class that arises frequently in graph theory, but for which no visualization algorithm has been proposed until now. In this paper, we present an algorithm for drawing graph products and the aesthetic criterion graph product's drawings are subject to. We show that the popular High-Dimensional Embedder approach applied to cartesian products already respects this aestetic criterion, but has disadvantages. We also present how our method is integrated as a new component into the TopoLayout framework. Our implementation is used for further research of graph products in a biological context.",Stefan Jänicke;Christian Heine 0002;Marc Hellmuth;Peter F. Stadler;Gerik Scheuermann,Stefan Janicke;Christian Heine;Marc Hellmuth;Peter F. Stadler;Gerik Scheuermann,"Image and Signal Processing Group, Institute for Computer Science, Universität Leipzig, Germany;Image and Signal Processing Group, Institute for Computer Science, Universität Leipzig, Germany;Bioinformatics Group, Department of Computer Science and Interdisciplinary Center for Bioinformatics, Universität Leipzig, Germany and Max Planck Institute for Mathematics in the Sciences, Germany;Max Planck Institute for Mathematics in the Sciences, Germany;Institute for Computer Science, University of Leipzig, Germany",10.1109/tvcg.2007.70580;10.1109/tvcg.2007.70580,"Graph drawing, graph products, TopoLayout",20.0,10.0,35.0,718.0,,,drawing graph products;high dimensional embedder;biological context;topolayout framework implementation;certain,0.6932;0.3298;0.2399;0.1916;0.0399,"[np.int64(-1), -1, -1, -1, -1]",143;-1;-1;-1;-1,143,143
Vis,1999,Progressive Compression of Arbitrary Triangular Meshes,10.1109/visual.1999.10189410,http://dx.doi.org/10.1109/VISUAL.1999.10189410,67.0,72.0,C,"In this paper we present a mesh compression method based on a multiresolution decomposition whose detail coefficients have a compact representation and thus smaller entropy than the original mesh. Given an arbitrary triangular mesh with an irregular connectivity, we use a hierarchical simplification scheme, which generates a multiresolution model. By reversing the process we define a hierarchical progressive refinement process, where a simple prediction plus a correction is used for inserting vertices to form a finer level. We show how the connectivity of an arbitrary triangulation can be encoded efficiently by a coloring technique, and recovered incrementally during the progressive reconstruction of the original mesh.",Daniel Cohen-Or;David Levin;Offir Remez,Daniel Cohen-Or;David Levin;Offir Remez,"Computer Science Department, School of Mathematical Sciences, Tel Aviv University, Tel Aviv, Israel;Computer Science Department, School of Mathematical Sciences, Tel Aviv University, Tel Aviv, Israel;Computer Science Department, School of Mathematical Sciences, Tel Aviv University, Tel Aviv, Israel",10.1109/visual.1996.568125,"compression, streaming, progressive meshes, simplification",250.0,20.0,0.0,15.0,,,mesh compression method;define hierarchical;decomposition coefficients;connectivity arbitrary;coloring,0.6995;0.1849;0.1728;0.1593;0.1404,"[np.int64(-1), -1, -1, -1, -1]",107;-1;-1;-1;-1,107,107
Vis,2010,Fast; Memory-Efficient Cell Location in Unstructured Grids for Visualization,10.1109/tvcg.2010.156,http://dx.doi.org/10.1109/TVCG.2010.156,1541.0,1550.0,J,"Applying certain visualization techniques to datasets described on unstructured grids requires the interpolation of variables of interest at arbitrary locations within the dataset's domain of definition. Typical solutions to the problem of finding the grid element enclosing a given interpolation point make use of a variety of spatial subdivision schemes. However, existing solutions are memory- intensive, do not scale well to large grids, or do not work reliably on grids describing complex geometries. In this paper, we propose a data structure and associated construction algorithm for fast cell location in unstructured grids, and apply it to the interpolation problem. Based on the concept of bounding interval hierarchies, the proposed approach is memory-efficient, fast and numerically robust. We examine the performance characteristics of the proposed approach and compare it to existing approaches using a number of benchmark problems related to vector field visualization. Furthermore, we demonstrate that our approach can successfully accommodate large datasets, and discuss application to visualization on both CPUs and GPUs.",Christoph Garth;Kenneth I. Joy,Christoph Garth;Kenneth I. Joy,"Institute of Data Analysis and Visualization, University of California, Davis, USA;Institute of Data Analysis and Visualization, University of California, Davis, USA",10.1109/tvcg.2008.163;10.1109/tvcg.2008.133;10.1109/visual.2005.1532795;10.1109/tvcg.2009.154;10.1109/tvcg.2008.163,"Unstructured grids, cell location, interpolation, vector field visualization",65.0,32.0,22.0,834.0,,,location unstructured grids;apply interpolation;vector field;number benchmark;definition,0.6550;0.3327;0.2682;0.1615;0.0488,"[np.int64(-1), -1, -1, -1, -1]",109;-1;-1;-1;-1,109,109
InfoVis,1997,H3: laying out large directed graphs in 3D hyperbolic space,10.1109/infvis.1997.636718,http://dx.doi.org/10.1109/INFVIS.1997.636718,2.0,10.0,C,"We present the H3 layout technique for drawing large directed graphs as node-link diagrams in 3D hyperbolic space. We can lay out much larger structures than can be handled using traditional techniques for drawing general graphs because we assume a hierarchical nature of the data. We impose a hierarchy on the graph by using domain-specific knowledge to find an appropriate spanning tree. Links which are not part of the spanning tree do not influence the layout but can be selectively drawn by user request. The volume of hyperbolic 3-space increases exponentially, as opposed to the familiar geometric increase of euclidean 3-space. We exploit this exponential amount of room by computing the layout according to the hyperbolic metric. We optimize the cone tree layout algorithm for 3D hyperbolic space by placing children on a hemisphere around the cone mouth instead of on its perimeter. Hyperbolic navigation affords a Focus+Context view of the structure with minimal visual clutter. We have successfully laid out hierarchies of over 20,000 nodes. Our implementation accommodates navigation through graphs too large to be rendered interactively by allowing the user to explicitly prune or expand subtrees.",Tamara Munzner,T. Munzner,"University of Stanford, Stanford, CA, USA",10.1109/infvis.1995.528691;10.1109/infvis.1995.528689;10.1109/infvis.1996.559218;10.1109/infvis.1995.528691,,492.0,100.0,29.0,824.0,,,layout according hyperbolic;navigation graphs;20 000 nodes;domain specific knowledge;rendered interactively allowing,0.5583;0.4750;0.2788;0.1616;0.1438,"[np.int64(-1), -1, -1, -1, -1]",-1;-1;-1;-1;-1,,-1
Vis,2001,Texture Hardware Assisted Rendering of Time-Varying Volume Data,10.1109/visual.2001.964520,http://doi.ieeecomputersociety.org/10.1109/VISUAL.2001.964520,263.0,270.0,C,"In this paper we present a hardware-assisted rendering technique coupled with a compression scheme for the interactive visual exploration of time-varying scalar volume data. A palette-based decoding technique and an adaptive bit allocation scheme are developed to fully utilize the texturing capability of a commodity 3-D graphics card. Using a single PC equipped with a modest amount of memory, a texture capable graphics card, and an inexpensive disk array, we are able to render hundreds of time steps of regularly gridded volume data (up to 45 millions voxels each time step) at interactive rates, permitting the visual exploration of large scientific data sets in both the temporal and spatial domain.",Eric B. Lum;Kwan-Liu Ma;John P. Clyne,E.B. Lum;Kwan-Liu Ma;J. Clyne,"CIPIC & Department of Computer Science, University of California, Davis;CIPIC & Department of Computer Science, University of California, Davis;National Center for Atmospheric Research",10.1109/visual.1999.809910;10.1109/visual.1994.346321;10.1109/visual.1995.480809;10.1109/visual.1994.346341;10.1109/visual.1999.809879;10.1109/visual.1999.809910,"Compression, high performance computing, out-of-core processing, PC, scientific visualization, texture hardware, time-varying data, transform encoding, volume rendering",129.0,42.0,23.0,35.0,,,hardware assisted rendering;compression scheme;volume data 45;exploration time varying;millions,0.5598;0.3955;0.3115;0.1801;0.0866,"[np.int64(-1), -1, -1, -1, -1]",61;-1;-1;-1;-1,61,61
VAST,2019,Facetto: Combining Unsupervised and Supervised Learning for Hierarchical Phenotype Analysis in Multi-Channel Image Data,10.1109/tvcg.2019.2934547,http://dx.doi.org/10.1109/TVCG.2019.2934547,227.0,237.0,J,"Facetto is a scalable visual analytics application that is used to discover single-cell phenotypes in high-dimensional multi-channel microscopy images of human tumors and tissues. Such images represent the cutting edge of digital histology and promise to revolutionize how diseases such as cancer are studied, diagnosed, and treated. Highly multiplexed tissue images are complex, comprising 109 or more pixels, 60-plus channels, and millions of individual cells. This makes manual analysis challenging and error-prone. Existing automated approaches are also inadequate, in large part, because they are unable to effectively exploit the deep knowledge of human tissue biology available to anatomic pathologists. To overcome these challenges, Facetto enables a semi-automated analysis of cell types and states. It integrates unsupervised and supervised learning into the image and feature exploration process and offers tools for analytical provenance. Experts can cluster the data to discover new types of cancer and immune cells and use clustering results to train a convolutional neural network that classifies new cells accordingly. Likewise, the output of classifiers can be clustered to discover aggregate patterns and phenotype subsets. We also introduce a new hierarchical approach to keep track of analysis steps and data subsets created by users; this assists in the identification of cell types. Users can build phenotype trees and interact with the resulting hierarchical structures of both high-dimensional feature and image spaces. We report on use-cases in which domain scientists explore various large-scale fluorescence imaging datasets. We demonstrate how Facetto assists users in steering the clustering and classification process, inspecting analysis results, and gaining new scientific insights into cancer biology.",Robert Krüger;Johanna Beyer;Won-Dong Jang;Nam Wook Kim;Artem Sokolov;Peter K. Sorger;Hanspeter Pfister,Robert Krueger;Johanna Beyer;Won-Dong Jang;Nam Wook Kim;Artem Sokolov;Peter K. Sorger;Hanspeter Pfister,"School of Engineering and Applied Sciences, Harvard University, Cambridge, USA and Laboratory of Systems Pharmacology, Harvard Medical School, Boston, USA;School of Engineering and Applied Sciences, Harvard University, Cambridge, USA;School of Engineering and Applied Sciences, Harvard University, Cambridge, USA;School of Engineering and Applied Sciences, Harvard University, Cambridge, USA;Laboratory of Systems Pharmacology, Harvard Medical School, Boston, USA;Laboratory of Systems Pharmacology, Harvard Medical School, Boston, USA;School of Engineering and Applied Sciences, Harvard University, Cambridge, USA",10.1109/tvcg.2013.186;10.1109/tvcg.2016.2598468;10.1109/vast.2010.5652443;10.1109/tvcg.2016.2598587;10.1109/vast.2007.4389013;10.1109/tvcg.2012.277;10.1109/tvcg.2012.258;10.1109/vast.2014.7042495;10.1109/tvcg.2013.125;10.1109/tvcg.2007.70569;10.1109/tvcg.2015.2467551;10.1109/tvcg.2017.2744805;10.1109/tvcg.2012.213;10.1109/tvcg.2017.2744158;10.1109/tvcg.2013.186,"Clustering,Classification,Visual Analysis,Multiplex Tissue Imaging,Digital Pathology,Cancer Systems Biology",32.0,41.0,70.0,1412.0,,,tissue images complex;users steering clustering;provenance experts;integrates unsupervised;single,0.6003;0.2358;0.1913;0.1681;0.0495,"[np.int64(-1), -1, -1, -1, -1]",63;-1;-1;-1;-1,63,63
Vis,2002,Scalable alignment of large-format multi-projector displays using camera homography trees,10.1109/visual.2002.1183793,http://dx.doi.org/10.1109/VISUAL.2002.1183793,339.0,346.0,C,"This paper presents a vision-based geometric alignment system for aligning the projectors in an arbitrarily large display wall. Existing algorithms typically rely on a single camera view and degrade in accuracy as the display resolution exceeds the camera resolution by several orders of magnitude. Naive approaches to integrating multiple zoomed camera views fail since small errors in aligning adjacent views propagate quickly over the display surface to create glaring discontinuities. Our algorithm builds and refines a camera homography tree to automatically register any number of uncalibrated camera images; the resulting system is both faster and significantly more accurate than competing approaches, reliably achieving alignment errors of 0.55 pixels on a 24-projector display in under 9 minutes. Detailed experiments compare our system to two recent display wall alignment algorithms, both on our 18 Megapixel display wall and in simulation. These results indicate that our approach achieves sub-pixel accuracy even on displays with hundreds of projectors.",Han Chen;Rahul Sukthankar;Grant Wallace;Kai Li 0001,Han Chen;R. Sukthankar;G. Wallace;Kai Li,"Computer Science, Princeton University, USA;HP Laboratories CRL, The Robotics Institute, CMU, USA;Computer Science, Princeton University, USA;Computer Science, Princeton University, USA",10.1109/visual.1999.809883;10.1109/visual.2001.964508;10.1109/visual.2000.885685;10.1109/visual.1999.809883,"large-format tiled projection display, display wall, camera-projector systems, camera-based registration and calibration, automatic alignment, scalability, simulation, evaluation",238.0,56.0,13.0,389.0,,,alignment aligning projectors;homography tree automatically;megapixel;wall simulation;hundreds,0.7219;0.3946;0.2478;0.1969;0.0307,"[np.int64(-1), -1, -1, -1, -1]",22;-1;-1;-1;-1,22,22
VAST,2009,Innovative filtering techniques and customized analytics tools,10.1109/vast.2009.5334300,http://dx.doi.org/10.1109/VAST.2009.5334300,,,M,"The VAST 2009 Challenge consisted of three heterogeneous synthetic data sets organized into separate mini-challenges with minimal correspondence information. The challenge task was the identification of a suspected data theft from cyber and real-world traces. The grand challenge required integrating the findings from the mini challenges into a plausible, consistent scenario. A mixture of linked, customized tools based on queryable models and rapid prototyping as well as generic analysis tools (developed in-house) helped us correctly solve all of the mini challenges. A collaborative analytic process was employed to reconstruct the scenario and to propose the correct steps for the reliable identification of the criminal organization based on activity traces of its members.",Harald Bosch;Julian Heinrich;Christoph Müller 0001;Benjamin Höferlin;Guido Reina;Markus Höferlin;Michael Wörner 0001;Steffen Koch 0001,Harald Bosch;Julian Heinrich;Christoph Muller;Benjamin Hoferlin;Guido Reina;Markus Hoferlin;Michael Worner;Steffen Koch,"Visualization and Interactive Systems Institute and Visualization Research Center, Universität Stuttgart, Germany;Visualization and Interactive Systems Institute and Visualization Research Center, Universität Stuttgart, Germany;Visualization and Interactive Systems Institute and Visualization Research Center, Universität Stuttgart, Germany;Visualization and Interactive Systems Institute and Visualization Research Center, Universität Stuttgart, Germany;Visualization and Interactive Systems Institute and Visualization Research Center, Universität Stuttgart, Germany;Visualization and Interactive Systems Institute and Visualization Research Center, Universität Stuttgart, Germany;Visualization and Interactive Systems Institute and Visualization Research Center, Universität Stuttgart, Germany;Visualization and Interactive Systems Institute and Visualization Research Center, Universität Stuttgart, Germany",0.1109/vast.2009.5333564;10.1109/vast.2009.5333911,,15.0,5.0,3.0,202.0,,,data theft cyber;queryable models rapid;collaborative analytic process;challenge consisted;synthetic,0.5380;0.3232;0.3115;0.2640;0.2098,"[np.int64(-1), -1, -1, -1, -1]",125;-1;-1;-1;-1,125,125
Vis,2001,Variational classification for visualization of 3D ultrasound data,10.1109/visual.2001.964539,http://dx.doi.org/10.1109/VISUAL.2001.964539,403.0,410.0,C,"We present a new technique for visualizing surfaces from 3D ultrasound data. 3D ultrasound datasets are typically fuzzy, contain a substantial amount of noise and speckle, and suffer from several other problems that make extraction of continuous and smooth surfaces extremely difficult. We propose a novel opacity classification algorithm for 3D ultrasound datasets, based on the variational principle. More specifically, we compute a volumetric opacity function that optimally satisfies a set of simultaneous requirements. One requirement makes the function attain nonzero values only in the vicinity of a user-specified value, resulting in soft shells of finite, approximately constant thickness around isosurfaces in the volume. Other requirements are designed to make the function smoother and less sensitive to noise and speckle. The computed opacity function lends itself well to explicit geometric surface extraction, as well as to direct volume rendering at interactive rates. We also describe a new splatting algorithm that is particularly well suited for displaying soft opacity shells. Several examples and comparisons are included to illustrate our approach and demonstrate its effectiveness on real 3D ultrasound datasets.",Raanan Fattal;Dani Lischinski,R. Fattal;D. Lischinski,"School of Computer Science and Engineering, Hebrew University of Jerusalem, Israel;School of Computer Science and Engineering, Hebrew University of Jerusalem, Israel",10.1109/visual.1993.398877;10.1109/visual.1997.663875;10.1109/visual.1993.398877,"3D ultrasound, classification, isosurface extraction, opacity function, splatting, the variational principle, volume rendering",75.0,4.0,21.0,251.0,,,surfaces 3d ultrasound;opacity;based variational principle;fuzzy contain substantial;designed,0.6795;0.4506;0.2465;0.1760;0.0232,"[np.int64(-1), -1, -1, -1, -1]",133;-1;-1;-1;-1,133,133
Vis,2023,Designing for Ambiguity in Visual Analytics: Lessons from Risk Assessment and Prediction,10.1109/tvcg.2023.3326571,http://dx.doi.org/10.1109/TVCG.2023.3326571,924.0,933.0,J,"Ambiguity is pervasive in the complex sensemaking domains of risk assessment and prediction but there remains little research on how to design visual analytics tools to accommodate it. We report on findings from a qualitative study based on a conceptual framework of sensemaking processes to investigate how both new visual analytics designs and existing tools, primarily data tables, support the cognitive work demanded in avalanche forecasting. While both systems yielded similar analytic outcomes we observed differences in ambiguous sensemaking and the analytic actions either afforded. Our findings challenge conventional visualization design guidance in both perceptual and interaction design, highlighting the need for data interfaces that encourage reflection, provoke alternative interpretations, and support the inherently ambiguous nature of sensemaking in this critical application. We review how different visual and interactive forms support or impede analytic processes and introduce “gisting” as a significant yet unexplored analytic action for visual analytics research. We conclude with design implications for enabling ambiguity in visual analytics tools to scaffold sensemaking in risk assessment.",Stanislaw Nowak;Lyn Bartram,Stan Nowak;Lyn Bartram,"Simon Fraser University, Canada;Simon Fraser University, Canada",0.1109/tvcg.2021.3114830;10.1109/tvcg.2013.124;10.1109/vast.2007.4389011;10.1109/tvcg.2017.2744684;10.1109/tvcg.2011.175;10.1109/tvcg.2022.3209451;10.1109/tvcg.2019.2934593;10.1109/tvcg.2018.2864913;10.1109/tvcg.2017.2745958,"Complex Systems,Risk Assessment,Sensemaking,Visualization Design",,0.0,66.0,367.0,,,ambiguity visual analytics;avalanche forecasting systems;qualitative study;tools accommodate;demanded,0.6443;0.3302;0.2785;0.1182;0.0049,"[np.int64(-1), -1, -1, -1, -1]",270;-1;-1;-1;-1,270,270
InfoVis,1997,On integrating visualization techniques for effective software exploration,10.1109/infvis.1997.636784,http://dx.doi.org/10.1109/INFVIS.1997.636784,38.0,45.0,C,"This paper describes the SHriMP visualization technique for seamlessly exploring software structure and browsing source code, with a focus on effectively assisting hybrid program comprehension strategies. The technique integrates both pan+zoom and fisheye-view visualization approaches for exploring a nested graph view of software structure. The fisheye-view approach handles multiple focal points, which are necessary when examining several subsystems and their mutual interconnections. Source code is presented by embedding code fragments within the nodes of the nested graph. Finer connections among these fragments are represented by a network that is navigated using a hypertext link-following metaphor. SHriMP combines this hypertext metaphor with animated panning and zooming motions over the nested graph to provide continuous orientation and contextual cues for the user. The SHriMP tool is being evaluated in several user studies. Observations of users performing program understanding tasks with the tool are discussed.",Margaret-Anne D. Storey;Kenny Wong;F. David Fracchia;Hausi A. Müller,M.-A.D. Storey;K. Wong;F.D. Fracchia;H.A. Muller,"Department of Computer Science, University of Victoria, Victoria, BC, Canada and School of Computing Science, Simon Fraser University, Burnaby, BC, Canada;Department of Computer Science, University of Victoria, Victoria, BC, Canada;School of Computing Science, Simon Fraser University, Burnaby, BC, Canada;Department of Computer Science, University of Victoria, Victoria, BC, Canada",10.1109/visual.1991.175815;10.1109/visual.1991.175815,"Nested graphs, pan and zoom, fisheye views, hypertext, mental map, software visualization, program understanding",155.0,13.0,31.0,331.0,,,software structure browsing;pan zoom fisheye;metaphor animated;understanding tasks;using hypertext link,0.6037;0.3288;0.2424;0.2203;0.1991,"[np.int64(-1), -1, -1, -1, -1]",287;-1;-1;-1;-1,287,287
Vis,2023,TimeSplines: Sketch-Based Authoring of Flexible and Idiosyncratic Timelines,10.1109/tvcg.2023.3326520,http://dx.doi.org/10.1109/TVCG.2023.3326520,34.0,44.0,J,"Timelines are essential for visually communicating chronological narratives and reflecting on the personal and cultural significance of historical events. Existing visualization tools tend to support conventional linear representations, but fail to capture personal idiosyncratic conceptualizations of time. In response, we built TimeSplines, a visualization authoring tool that allows people to sketch multiple free-form temporal axes and populate them with heterogeneous, time-oriented data via incremental and lazy data binding. Authors can bend, compress, and expand temporal axes to emphasize or de-emphasize intervals based on their personal importance; they can also annotate the axes with text and figurative elements to convey contextual information. The results of two user studies show how people appropriate the concepts in TimeSplines to express their own conceptualization of time, while our curated gallery of images demonstrates the expressive potential of our approach.",Anna Offenwanger;Matthew Brehmer;Fanny Chevalier;Theophanis Tsandilas,Anna Offenwanger;Matthew Brehmer;Fanny Chevalier;Theophanis Tsandilas,"Université Paris Saclay, CRNS, Inria, LISN, France;Tableau Research, USA;Departments of Computer Science and Statistical Sciences, University of Toronto, Canada;Université Paris Saclay, CRNS, Inria, LISN, France",0.1109/tvcg.2015.2467851;10.1109/tvcg.2016.2598609;10.1109/tvcg.2011.185;10.1109/tvcg.2016.2598876;10.1109/tvcg.2017.2744118;10.1109/tvcg.2013.191;10.1109/tvcg.2022.3209451;10.1109/tvcg.2013.200;10.1109/tvcg.2021.3114959;10.1109/tvcg.2017.2743918;10.1109/tvcg.2018.2865158;10.1109/tvcg.2019.2934281;10.1109/tvcg.2015.2467153;10.1109/tvcg.2012.212;10.1109/tvcg.2020.3030476;10.1109/infvis.1999.801851;10.1109/tvcg.2015.2467751;10.1109/tvcg.2018.2865076;10.1109/tvcg.2011.195,"Temporal Data,interaction design,communication / presentation,storytelling,sketch-based interface,lazy data binding",,2.0,79.0,1107.0,BP,,timelines essential visually;reflecting personal cultural;authors bend;user;incremental lazy data,0.7163;0.3409;0.2269;0.1710;0.1139,"[np.int64(-1), -1, -1, -1, -1]",157;-1;-1;-1;-1,157,157
InfoVis,2020,Scalability of Network Visualisation from a Cognitive Load Perspective,10.1109/tvcg.2020.3030459,http://dx.doi.org/10.1109/TVCG.2020.3030459,1677.0,1687.0,J,"Node-link diagrams are widely used to visualise networks. However, even the best network layout algorithms ultimately result in ‘hairball’ visualisations when the graph reaches a certain degree of complexity, requiring simplification through aggregation or interaction (such as filtering) to remain usable. Until now, there has been little data to indicate at what level of complexity node-link diagrams become ineffective or how visual complexity affects cognitive load. To this end, we conducted a controlled study to understand workload limits for a task that requires a detailed understanding of the network topology-finding the shortest path between two nodes. We tested performance on graphs with 25 to 175 nodes with varying density. We collected performance measures (accuracy and response time), subjective feedback, and physiological measures (EEG, pupil dilation, and heart rate variability). To the best of our knowledge this is the first network visualisation study to include physiological measures. Our results show that people have significant difficulty finding the shortest path in high density node-link diagrams with more than 50 nodes and even low density graphs with more than 100 nodes. From our collected EEG data we observe functional differences in brain activity between hard and easy tasks. We found that cognitive load increased up to certain level of difficulty after which it decreased, likely because participants had given up. We also explored the effects of global network layout features such as size or number of crossings, and features of the shortest path such as length or straightness on task difficulty. We found that global features generally had a greater impact than those of the shortest path.",Vahan Yoghourdjian;Yalong Yang 0001;Tim Dwyer;Lawrence Lee;Michael Wybrow;Kim Marriott,Vahan Yoghourdjian;Yalong Yang;Tim Dwyer;Lee Lawrence;Michael Wybrow;Kim Marriott,"Department of Human-Centred Computing, Faculty of Information Technology, Monash University, Melbourne, Australia;Department of Human-Centred Computing, Faculty of Information Technology, Monash University, Melbourne, Australia and School of Engineering and Applied Sciences, Harvard University, MA, USA;Department of Human-Centred Computing, Faculty of Information Technology, Monash University, Melbourne, Australia;Faculty of Business and Economics, Monash University, Melbourne, Australia;Department of Human-Centred Computing, Faculty of Information Technology, Monash University, Melbourne, Australia;Department of Human-Centred Computing, Faculty of Information Technology, Monash University, Melbourne, Australia",10.1109/infvis.2004.1,"Data Visualisation,Network Visualisation,Cognitive Load,EEG",19.0,27.0,67.0,980.0,,,network visualisation study;affects cognitive load;difficulty finding shortest;ultimately result hairball;filtering remain usable,0.6596;0.4478;0.2272;-0.0186;-0.0202,"[np.int64(-1), -1, -1, -1, -1]",169;-1;-1;-1;-1,169,169
InfoVis,2015,Suggested Interactivity: Seeking Perceived Affordances for Information Visualization,10.1109/tvcg.2015.2467201,http://dx.doi.org/10.1109/TVCG.2015.2467201,639.0,648.0,J,"In this article, we investigate methods for suggesting the interactivity of online visualizations embedded with text. We first assess the need for such methods by conducting three initial experiments on Amazon's Mechanical Turk. We then present a design space for Suggested Interactivity (i. e., visual cues used as perceived affordances-SI), based on a survey of 382 HTML5 and visualization websites. Finally, we assess the effectiveness of three SI cues we designed for suggesting the interactivity of bar charts embedded with text. Our results show that only one cue (SI3) was successful in inciting participants to interact with the visualizations, and we hypothesize this is because this particular cue provided feedforward.",Jeremy Boy;Louis Eveillard;Françoise Détienne;Jean-Daniel Fekete,Jeremy Boy;Louis Eveillard;Françoise Detienne;Jean-Daniel Fekete,EnsadLab and INRIA and Telecom ParisTech;EnsadLab;Telecom ParisTech;INRIA,10.1109/tvcg.2014.2346984;10.1109/tvcg.2013.134;10.1109/tvcg.2010.179;10.1109/infvis.2005.1532122;10.1109/tvcg.2014.2346984,"Suggested interactivity, perceived affordances, information visualization for the people, online visualization",69.0,41.0,55.0,1361.0,,,interact visualizations hypothesize;embedded text results;cue;need methods;amazon,0.6722;0.2734;0.1602;0.1196;0.0958,"[np.int64(-1), -1, -1, -1, -1]",-1;-1;-1;-1;-1,,-1
Vis,2009,Exploring the Millennium Run - Scalable Rendering of Large-Scale Cosmological Datasets,10.1109/tvcg.2009.142,http://dx.doi.org/10.1109/TVCG.2009.142,1251.0,1258.0,J,"In this paper we investigate scalability limitations in the visualization of large-scale particle-based cosmological simulations, and we present methods to reduce these limitations on current PC architectures. To minimize the amount of data to be streamed from disk to the graphics subsystem, we propose a visually continuous level-of-detail (LOD) particle representation based on a hierarchical quantization scheme for particle coordinates and rules for generating coarse particle distributions. Given the maximal world space error per level, our LOD selection technique guarantees a sub-pixel screen space error during rendering. A brick-based page-tree allows to further reduce the number of disk seek operations to be performed. Additional particle quantities like density, velocity dispersion, and radius are compressed at no visible loss using vector quantization of logarithmically encoded floating point values. By fine-grain view-frustum culling and presence acceleration in a geometry shader the required geometry throughput on the GPU can be significantly reduced. We validate the quality and scalability of our method by presenting visualizations of a particle-based cosmological dark-matter simulation exceeding 10 billion elements.",Roland Fraedrich;Jens Schneider 0002;Rüdiger Westermann,Roland Fraedrich;Jens Schneider;Rüdiger Westermann,"Computer Graphics and Visualization Group, Technische Universität München, Germany;Computer Graphics and Visualization Group, Technische Universität München, Germany;Computer Graphics and Visualization Group, Technische Universität München, Germany",10.1109/visual.2003.1250404;10.1109/visual.2002.1183824;10.1109/visual.2003.1250404;10.1109/visual.2005.1532795;10.1109/visual.2003.1250385;10.1109/tvcg.2006.176;10.1109/tvcg.2007.70530;10.1109/visual.1997.663888;10.1109/tvcg.2007.70526;10.1109/visual.2004.112;10.1109/tvcg.2006.155,"Particle Visualization, Scalability, Cosmology",72.0,39.0,26.0,660.0,,,cosmological simulations;presenting visualizations particle;sub pixel screen;based page tree;reduced validate,0.5742;0.4912;0.2366;0.2144;0.0377,"[np.int64(-1), -1, -1, -1, -1]",15;-1;-1;-1;-1,15,15
VAST,2014,Feedback-Driven Interactive Exploration of Large Multidimensional Data Supported by Visual Classifier,10.1109/vast.2014.7042480,http://dx.doi.org/10.1109/VAST.2014.7042480,43.0,52.0,C,"The extraction of relevant and meaningful information from multivariate or high-dimensional data is a challenging problem. One reason for this is that the number of possible representations, which might contain relevant information, grows exponentially with the amount of data dimensions. Also, not all views from a possibly large view space, are potentially relevant to a given analysis task or user. Focus+Context or Semantic Zoom Interfaces can help to some extent to efficiently search for interesting views or data segments, yet they show scalability problems for very large data sets. Accordingly, users are confronted with the problem of identifying interesting views, yet the manual exploration of the entire view space becomes ineffective or even infeasible. While certain quality metrics have been proposed recently to identify potentially interesting views, these often are defined in a heuristic way and do not take into account the application or user context. We introduce a framework for a feedback-driven view exploration, inspired by relevance feedback approaches used in Information Retrieval. Our basic idea is that users iteratively express their notion of interestingness when presented with candidate views. From that expression, a model representing the user's preferences, is trained and used to recommend further interesting view candidates. A decision support system monitors the exploration process and assesses the relevance-driven search process for convergence and stability. We present an instantiation of our framework for exploration of Scatter Plot Spaces based on visual features. We demonstrate the effectiveness of this implementation by a case study on two real-world datasets. We also discuss our framework in light of design alternatives and point out its usefulness for development of user- and context-dependent visual exploration systems.",Michael Behrisch 0001;Fatih Korkmaz;Lin Shao 0001;Tobias Schreck,Michael Behrisch;Fatih Korkmaz;Lin Shao;Tobias Schreck,"Universität Konstanz, Germany;Universität Konstanz, Germany;Universität Konstanz, Germany;Universität Konstanz, Germany",10.1109/infvis.2005.1532142;10.1109/tvcg.2012.277;10.1109/tvcg.2010.184;10.1109/vast.2012.6400486;10.1109/vast.2007.4389001;10.1109/tvcg.2013.160;10.1109/vast.2012.6400488;10.1109/infvis.2005.1532142,"View Space Exploration Framework, Interesting View Problem, Relevance Feedback, User Preference Model",69.0,51.0,37.0,1018.0,,,view exploration;candidates decision support;exponentially data dimensions;relevant;convergence stability,0.6775;0.2478;0.2131;0.1304;0.0611,"[np.int64(-1), -1, -1, -1, -1]",-1;-1;-1;-1;-1,,-1
Vis,2011,Towards Robust Topology of Sparsely Sampled Data,10.1109/tvcg.2011.245,http://dx.doi.org/10.1109/TVCG.2011.245,1852.0,1861.0,J,"Sparse, irregular sampling is becoming a necessity for reconstructing large and high-dimensional signals. However, the analysis of this type of data remains a challenge. One issue is the robust selection of neighborhoods - a crucial part of analytic tools such as topological decomposition, clustering and gradient estimation. When extracting the topology of sparsely sampled data, common neighborhood strategies such as k-nearest neighbors may lead to inaccurate results, either due to missing neighborhood connections, which introduce false extrema, or due to spurious connections, which conceal true extrema. Other neighborhoods, such as the Delaunay triangulation, are costly to compute and store even in relatively low dimensions. In this paper, we address these issues. We present two new types of neighborhood graphs: a variation on and a generalization of empty region graphs, which considerably improve the robustness of neighborhood-based analysis tools, such as topological decomposition. Our findings suggest that these neighborhood graphs lead to more accurate topological representations of low- and high- dimensional data sets at relatively low cost, both in terms of storage and computation time. We describe the implications of our work in the analysis and visualization of scalar functions, and provide general strategies for computing and applying our neighborhood graphs towards robust data analysis.",Carlos D. Correa;Peter Lindstrom 0001,Carlos Correa;Peter Lindstrom,"Center for Applied Scientific Computing (CASC), Lawrence Livermore National Laboratory, USA;Center for Applied Scientific Computing (CASC), Lawrence Livermore National Laboratory, USA",10.1109/visual.2005.1532839;10.1109/tvcg.2010.213;10.1109/tvcg.2011.244;10.1109/vast.2010.5652940;10.1109/visual.1999.809932,"Neighborhood graphs, topology, sparsely sampled data",44.0,17.0,54.0,745.0,BP,,topological decomposition clustering;visualization scalar functions;sampling necessity;robust;extrema spurious,0.6112;0.3442;0.2448;0.1906;0.0291,"[np.int64(-1), -1, -1, -1, -1]",283;-1;-1;-1;-1,283,283
InfoVis,2018,Evaluating ‘Graphical Perception’ with CNNs,10.1109/tvcg.2018.2865138,http://dx.doi.org/10.1109/TVCG.2018.2865138,641.0,650.0,J,"Convolutional neural networks can successfully perform many computer vision tasks on images. For visualization, how do CNNs perform when applied to graphical perception tasks? We investigate this question by reproducing Cleveland and McGill's seminal 1984 experiments, which measured human perception efficiency of different visual encodings and defined elementary perceptual tasks for visualization. We measure the graphical perceptual capabilities of four network architectures on five different visualization tasks and compare to existing and new human performance baselines. While under limited circumstances CNNs are able to meet or outperform human task performance, we find that CNNs are not currently a good model for human graphical perception. We present the results of these experiments to foster the understanding of how CNNs succeed and fail when applied to data visualizations.",Daniel Haehn;James Tompkin 0001;Hanspeter Pfister,Daniel Haehn;James Tompkin;Hanspeter Pfister,Harvard University;Brown University;Harvard University,10.1109/tvcg.2014.2346979;10.1109/tvcg.2014.2346320;10.1109/tvcg.2014.2346979,"Machine Perception,Graphical Perception,Deep Learning,Convolutional Neural Networks",42.0,36.0,50.0,1367.0,,,visualization cnns perform;reproducing cleveland mcgill;fail applied data;tasks compare existing;defined,0.7354;0.1509;0.1092;0.0589;0.0422,"[np.int64(-1), -1, -1, -1, -1]",135;-1;-1;-1;-1,135,135
InfoVis,2012,Different Strokes for Different Folks: Visual Presentation Design between Disciplines,10.1109/tvcg.2012.214,http://dx.doi.org/10.1109/TVCG.2012.214,2411.0,2420.0,J,"We present an ethnographic study of design differences in visual presentations between academic disciplines. Characterizing design conventions between users and data domains is an important step in developing hypotheses, tools, and design guidelines for information visualization. In this paper, disciplines are compared at a coarse scale between four groups of fields: social, natural, and formal sciences; and the humanities. Two commonplace presentation types were analyzed: electronic slideshows and whiteboard “chalk talks”. We found design differences in slideshows using two methods - coding and comparing manually-selected features, like charts and diagrams, and an image-based analysis using PCA called eigenslides. In whiteboard talks with controlled topics, we observed design behaviors, including using representations and formalisms from a participant's own discipline, that suggest authors might benefit from novel assistive tools for designing presentations. Based on these findings, we discuss opportunities for visualization ethnography and human-centered authoring tools for visual information.",Steven R. Gomez;Radu Jianu;Caroline Ziemkiewicz;Hua Guo;David H. Laidlaw,Steven R. Gomez;Radu Jianu;Caroline Ziemkiewicz;Hua Guo;David Laidlaw,"Brown University, USA;Brown University, USA;Brown University, USA;Brown University, USA;Brown University, USA",10.1109/tvcg.2011.251;10.1109/tvcg.2010.177;10.1109/tvcg.2010.179;10.1109/tvcg.2011.255;10.1109/tvcg.2011.251,"Presentations, information visualization, design, visual analysis",15.0,7.0,18.0,802.0,,,visualization paper disciplines;whiteboard talks controlled;slideshows using;called eigenslides;natural,0.6927;0.3290;0.2860;0.0691;0.0008,"[np.int64(-1), -1, -1, -1, -1]",267;-1;-1;-1;-1,267,267
InfoVis,2009,MizBee: A Multiscale Synteny Browser,10.1109/tvcg.2009.167,http://dx.doi.org/10.1109/TVCG.2009.167,897.0,904.0,J,"In the field of comparative genomics, scientists seek to answer questions about evolution and genomic function by comparing the genomes of species to find regions of shared sequences. Conserve dsyntenic blocks are an important biological data abstraction for indicating regions of shared sequences. The goal of this work is to show multiple types of relationships at multiple scales in a way that is visually comprehensible in accordance with known perceptual principles. We present a task analysis for this domain where the fundamental questions asked by biologists can be understood by a characterization of relationships into the four types of proximity/location, size, orientation, and similarity/strength, and the four scales of genome, chromosome, block, and genomic feature. We also propose a new taxonomy of the design space for visually encoding conservation data. We present MizBee, a multiscale synteny browser with the unique property of providing interactive side-by-side views of the data across the range of scales supporting exploration of all of these relationship types. We conclude with case studies from two biologists who used MizBee to augment their previous automatic analysis work flow, providing anecdotal evidence about the efficacy of the system for the visualization of syntenic data, the analysis of conservation relationships, and the communication of scientific insights.",Miriah D. Meyer;Tamara Munzner;Hanspeter Pfister,Miriah Meyer;Tamara Munzner;Hanspeter Pfister,"Harvard University, USA;University of British Columbia, Canada;Harvard University, USA",10.1109/infvis.2005.1532134;10.1109/tvcg.2006.147;10.1109/infvis.2005.1532134,"Information visualization, design study, bioinformatics, synteny",210.0,122.0,23.0,2064.0,HM,,comparing genomes species;abstraction indicating regions;conserve dsyntenic;scales way;anecdotal evidence efficacy,0.5718;0.3368;0.2112;0.1845;-0.0080,"[np.int64(-1), -1, -1, -1, -1]",16;-1;-1;-1;-1,16,16
VAST,2019,Origraph: Interactive Network Wrangling,10.1109/vast47406.2019.8986909,http://dx.doi.org/10.1109/VAST47406.2019.8986909,81.0,92.0,C,"Networks are a natural way of thinking about many datasets. The data on which a network is based, however, is rarely collected in a form that suits the analysis process, making it necessary to create and reshape networks. Data wrangling is widely acknowledged to be a critical part of the data analysis pipeline, yet interactive network wrangling has received little attention in the visualization research community. In this paper, we discuss a set of operations that are important for wrangling network datasets and introduce a visual data wrangling tool, Origraph, that enables analysts to apply these operations to their datasets. Key operations include creating a network from source data such as tables, reshaping a network by introducing new node or edge classes, filtering nodes or edges, and deriving new node or edge attributes. Our tool, Origraph, enables analysts to execute these operations with little to no programming, and to immediately visualize the results. Origraph provides views to investigate the network model, a sample of the network, and node and edge attributes. In addition, we introduce interfaces designed to aid analysts in specifying arguments for sensible network wrangling operations. We demonstrate the usefulness of Origraph in two Use Cases: first, we investigate gender bias in the film industry, and then the influence of money on the political support for the war in Yemen.",Alex Bigelow;Carolina Nobre;Miriah Meyer;Alexander Lex,Alex Bigelow;Carolina Nobre;Miriah Meyer;Alexander Lex,University of Utah;University of Utah;University of Utah;University of Utah,10.1109/vast.2006.261429;10.1109/vast.2011.6102441;10.1109/vast.2011.6102441;10.1109/tvcg.2014.2346248;10.1109/tvcg.2013.154;10.1109/vast.2011.6102440;10.1109/tvcg.2009.111;10.1109/tvcg.2009.116;10.1109/tvcg.2018.2865149;10.1109/tvcg.2017.2744843;10.1109/vast.2010.5652520;10.1109/vast.2006.261429,"Graph visualization,Data abstraction,Data wrangling,Human-centered computing [Information visualization],[Human-centered computing]: Visualization systems and tools,Information systems [Graph-based database models]",19.0,15.0,67.0,492.0,,,wrangling network datasets;visualize results;investigate gender bias;tool origraph enables;support war yemen,0.5736;0.4041;0.3256;0.1850;0.1268,"[np.int64(-1), -1, -1, -1, -1]",32;-1;-1;-1;-1,32,32
InfoVis,2004,Clutter Reduction in Multi-Dimensional Data Visualization Using Dimension Reordering,10.1109/infvis.2004.15,http://dx.doi.org/10.1109/INFVIS.2004.15,89.0,96.0,C,"Visual clutter denotes a disordered collection of graphical entities in information visualization. Clutter can obscure the structure present in the data. Even in a small dataset, clutter can make it hard for the viewer to find patterns, relationships and structure. In this paper, we define visual clutter as any aspect of the visualization that interferes with the viewer's understanding of the data, and present the concept of clutter-based dimension reordering. Dimension order is an attribute that can significantly affect a visualization's expressiveness. By varying the dimension order in a display, it is possible to reduce clutter without reducing information content or modifying the data in any way. Clutter reduction is a display-dependent task. In this paper, we follow a three-step procedure for four different visualization techniques. For each display technique, first, we determine what constitutes clutter in terms of display properties; then we design a metric to measure visual clutter in this display; finally we search for an order that minimizes the clutter in a display",Wei Peng;Matthew O. Ward;Elke A. Rundensteiner,Wei Peng;M.O. Ward;E.A. Rundensteiner,"Computer Science Department, Worcester Polytechnic Institute, Worcester, MA, USA;Computer Science Department, Worcester Polytechnic Institute, Worcester, MA, USA;Computer Science Department, Worcester Polytechnic Institute, Worcester, MA, USA",10.1109/infvis.2003.1249015;10.1109/visual.1996.567800;10.1109/visual.1990.146386;10.1109/infvis.1998.729559;10.1109/visual.1999.809866;10.1109/infvis.1996.559215;10.1109/infvis.2000.885086,"Multidimensional visualization, dimension order, visual clutter, visual structure",412.0,101.0,27.0,2110.0,,,information visualization clutter;dimension order attribute;significantly affect;define;follow step procedure,0.7957;0.3399;0.1172;0.0525;0.0308,"[np.int64(-1), -1, -1, -1, -1]",273;-1;-1;-1;-1,273,273
VAST,2009,Comparing two interface tools in performing visual analytics tasks,10.1109/vast.2009.5333469,http://dx.doi.org/10.1109/VAST.2009.5333469,219.0,220.0,M,"In visual analytics, menu systems are commonly adopted as supporting tools because of the complex nature of data. However, it is still unknown how much the interaction implicit to the interface impacts the performance of visual analysis. To show the effectiveness of two interface tools, one a floating text-based menu (Floating Menu) and the other a more interactive iconic tool (Interactive-Icon), we evaluated the use and human performance of both tools within one highly interactive visual analytics system. We asked participants to answer similarly constructed, straightforward questions in a genomic visualization, first with one tool, and then the other. During task performance we tracked completion times, task errors, and captured coarse-grained interactive behaviors. Based on the participants accuracy, speed, behaviors and post-task qualitative feedback, we observed that although the Interactive-Icon tool supports continuous interactions, task-oriented user evaluation did not find a significant difference between the two tools because there is a familiarity effect on the performance of solving the task questions with using Floating-Menu interface tool.",Dong Hyun Jeong;Tera Marie Green;William Ribarsky;Remco Chang,Dong Hyun Jeong;Tera Marie Green;William Ribarsky;Remco Chang,"Charlotte Visualization Center, UNC-Charlotte, USA;School of Interactive Arts and Technology, Simon Fraser University, Canada;Charlotte Visualization Center, UNC-Charlotte, USA;Charlotte Visualization Center, UNC-Charlotte, USA",0.1109/vast.2008.4677361,,0.0,1.0,3.0,241.0,,,interactive visual analytics;using floating menu;task errors;did significant difference;commonly adopted,0.6592;0.2773;0.1547;0.1480;0.1420,"[np.int64(-1), -1, -1, -1, -1]",201;-1;-1;-1;-1,201,201
VAST,2020,A Visual Analytics Framework for Reviewing Multivariate Time-Series Data with Dimensionality Reduction,10.1109/tvcg.2020.3028889,http://dx.doi.org/10.1109/TVCG.2020.3028889,1601.0,1611.0,J,"Data-driven problem solving in many real-world applications involves analysis of time-dependent multivariate data, for which dimensionality reduction (DR) methods are often used to uncover the intrinsic structure and features of the data. However, DR is usually applied to a subset of data that is either single-time-point multivariate or univariate time-series, resulting in the need to manually examine and correlate the DR results out of different data subsets. When the number of dimensions is large either in terms of the number of time points or attributes, this manual task becomes too tedious and infeasible. In this paper, we present MulTiDR, a new DR framework that enables processing of time-dependent multivariate data as a whole to provide a comprehensive overview of the data. With the framework, we employ DR in two steps. When treating the instances, time points, and attributes of the data as a 3D array, the first DR step reduces the three axes of the array to two, and the second DR step visualizes the data in a lower-dimensional space. In addition, by coupling with a contrastive learning method and interactive visualizations, our framework enhances analysts' ability to interpret DR results. We demonstrate the effectiveness of our framework with four case studies using real-world datasets.",Takanori Fujiwara;Shilpika;Naohisa Sakamoto;Jorji Nonaka;Keiji Yamamoto;Kwan-Liu Ma,Takanori Fujiwara;Shilpika;Naohisa Sakamoto;Jorji Nonaka;Keiji Yamamoto;Kwan-Liu Ma,"University of California, Davis;University of California, Davis;Kobe University;RIKEN R-CCS;RIKEN R-CCS;University of California, Davis",10.1109/tvcg.2015.2467851;10.1109/tvcg.2011.185;10.1109/tvcg.2017.2744419;10.1109/tvcg.2019.2934433;10.1109/tvcg.2019.2934251;10.1109/tvcg.2015.2467553;10.1109/tvcg.2018.2865018;10.1109/tvcg.2016.2598495;10.1109/tvcg.2016.2598470;10.1109/tvcg.2015.2468078;10.1109/tvcg.2015.2468111;10.1109/tvcg.2016.2598664;10.1109/tvcg.2015.2467851,"Multivariate time-series,tensor,data cube,dimensionality reduction,interpretability,visual analytics",30.0,31.0,59.0,2052.0,,,data dimensionality reduction;time point multivariate;visualizations framework;case studies;series resulting need,0.5895;0.4052;0.3469;0.1028;0.0284,"[np.int64(-1), -1, -1, -1, -1]",42;-1;-1;-1;-1,42,42
Vis,2022,ECoalVis: Visual Analysis of Control Strategies in Coal-fired Power Plants,10.1109/tvcg.2022.3209430,http://dx.doi.org/10.1109/TVCG.2022.3209430,1091.0,1101.0,J,"Improving the efficiency of coal-fired power plants has numerous benefits. The control strategy is one of the major factors affecting such efficiency. However, due to the complex and dynamic environment inside the power plants, it is hard to extract and evaluate control strategies and their cascading impact across massive sensors. Existing manual and data-driven approaches cannot well support the analysis of control strategies because these approaches are time-consuming and do not scale with the complexity of the power plant systems. Three challenges were identified: a) interactive extraction of control strategies from large-scale dynamic sensor data, b) intuitive visual representation of cascading impact among the sensors in a complex power plant system, and c) time-lag-aware analysis of the impact of control strategies on electricity generation efficiency. By collaborating with energy domain experts, we addressed these challenges with ECoalVis, a novel interactive system for experts to visually analyze the control strategies of coal-fired power plants extracted from historical sensor data. The effectiveness of the proposed system is evaluated with two usage scenarios on a real-world historical dataset and received positive feedback from experts.",Shuhan Liu;Di Weng;Yuan Tian;Zikun Deng;Haoran Xu 0003;Xiangyu Zhu;Honglei Yin;Xianyuan Zhan;Yingcai Wu,Shuhan Liu;Di Weng;Yuan Tian;Zikun Deng;Haoran Xu;Xiangyu Zhu;Honglei Yin;Xianyuan Zhan;Yingcai Wu,"State Key Lab of CAD&CG, Zhejiang University, Hangzhou, China;Microsoft Research Asia, Beijing, China;State Key Lab of CAD&CG, Zhejiang University, Hangzhou, China;State Key Lab of CAD&CG, Zhejiang University, Hangzhou, China;JD iCity, JD Technology, Beijing, China;Institute for AI Industry Research (AIR), Tsinghua University, Beijing, China;JD iCity, JD Technology, Beijing, China;Institute for AI Industry Research (AIR), Tsinghua University, Beijing, China;State Key Lab of CAD&CG, Zhejiang University, Hangzhou, China",10.1109/tvcg.2015.2467851;10.1109/tvcg.2021.3114792;10.1109/tvcg.2017.2745083;10.1109/tvcg.2021.3114875;10.1109/vast.2006.261421;10.1109/tvcg.2013.173;10.1109/tvcg.2017.2745105;10.1109/tvcg.2014.2346454;10.1109/tvcg.2015.2467622;10.1109/tvcg.2018.2864886;10.1109/tvcg.2009.200;10.1109/tvcg.2012.213;10.1109/tvcg.2019.2934275;10.1109/tvcg.2021.3114878;10.1109/tvcg.2009.117;10.1109/vast.2009.5332595;10.1109/tvcg.2016.2598664;10.1109/tvcg.2021.3114877;10.1109/tvcg.2022.3209360;10.1109/tvcg.2015.2467851,"Power plant visual analytics,energy data visualization,spatiotemporal visualization,smart factory",,3.0,71.0,1146.0,,,power plant systems;data intuitive visual;extracted historical sensor;time lag;domain experts addressed,0.5029;0.4209;0.2851;0.2070;0.2049,"[np.int64(-1), -1, -1, -1, -1]",71;-1;-1;-1;-1,71,71
Vis,2000,Interior/exterior classification of polygonal models,10.1109/visual.2000.885723,http://doi.ieeecomputersociety.org/10.1109/VISUAL.2000.885723,415.0,422.0,C,"We present an algorithm for automatically classifying the interior and exterior parts of a polygonal model. The need for visualizing the interiors of objects frequently arises in medical visualization and CAD modeling. The goal of such visualizations is to display the model in a way that the human observer can easily understand the relationship between the different parts of the surface. While there exist excellent methods for visualizing surfaces that are inside one another (nested surfaces), the determination of which parts of the surface are interior is currently done manually. Our automatic method for interior classification takes a sampling approach using a collection of direction vectors. Polygons are said to be interior to the model if they are not visible in any of these viewing directions from a point outside the model. Once we have identified polygons as being inside or outside the model, these can be textured or have different opacities applied to them so that the whole model can be rendered in a more comprehensible manner. An additional consideration for some models is that they may have holes or tunnels running through them that are connected to the exterior surface. Although an external observer can see into these holes, it is often desirable to mark the walls of such tunnels as being part of the interior of a model. In order to allow this modified classification of the interior, we use morphological operators to close all the holes of the model. An input model is used together with its closed version to provide a better classification of the portions of the original model.",Fakir S. Nooruddin;Greg Turk,F.S. Nooruddin;G. Turk,"Georgia Institute of Technology, Atlanta, GA, US;Georgia Institute of Technology, Atlanta, GA, US",10.1109/visual.1997.663909;10.1109/visual.1995.480795;10.1109/visual.1996.568111,"Visibility, Surface Classification, Rendering,Interior Surfaces",28.0,7.0,0.0,40.0,,,visualizing interiors objects;use morphological operators;allow modified classification;takes sampling approach;running connected,0.6756;0.3417;0.1610;0.1006;0.0157,"[np.int64(-1), -1, -1, -1, -1]",-1;-1;-1;-1;-1,,-1
Vis,1997,Vortex identification-applications in aerodynamics: a case study,10.1109/visual.1997.663910,http://dx.doi.org/10.1109/VISUAL.1997.663910,413.0,416.0,C,"An eigenvector method for vortex identification has been applied to recent numerical and experimental studies in external flow aerodynamics. It is shown to be an effective way to extract and visualize features such as vortex cores, spiral vortex breakdowns, vortex bursting, and vortex diffusion. Several problems are reported and illustrated. These include: disjointed line segments, detecting non-vortical flow features, and vortex core displacement. Future research and applications are discussed, such as using vortex cores to guide automatic grid refinement.",David N. Kenwright;Robert Haimes,D. Kenwright;R. Haimes,"MRJ Technology Solutions Inc., NASA Ames Research Center, USA;Massachusetts Institute of Technology, USA",10.1109/visual.1996.568137;10.1109/visual.1994.346327;10.1109/visual.1991.175773;10.1109/visual.1996.568137,,74.0,18.0,16.0,309.0,BCS,,vortex identification applied;eigenvector;automatic grid refinement;experimental studies;include,0.7144;0.2958;0.2870;0.0304;-0.0894,"[np.int64(-1), -1, -1, -1, -1]",141;-1;-1;-1;-1,141,141
SciVis,2013,Uncertainty Quantification in Linear Interpolation for Isosurface Extraction,10.1109/tvcg.2013.208,http://dx.doi.org/10.1109/TVCG.2013.208,2723.0,2732.0,J,"We present a study of linear interpolation when applied to uncertain data. Linear interpolation is a key step for isosurface extraction algorithms, and the uncertainties in the data lead to non-linear variations in the geometry of the extracted isosurface. We present an approach for deriving the probability density function of a random variable modeling the positional uncertainty in the isosurface extraction. When the uncertainty is quantified by a uniform distribution, our approach provides a closed-form characterization of the mentioned random variable. This allows us to derive, in closed form, the expected value as well as the variance of the level-crossing position. While the former quantity is used for constructing a stable isosurface for uncertain data, the latter is used for visualizing the positional uncertainties in the expected isosurface level crossings on the underlying grid.",Tushar M. Athawale;Alireza Entezari,Tushar Athawale;Alireza Entezari,"Department of Computer and Information Science and Engineering, University of Florida, USA;Department of Computer and Information Science and Engineering, University of Florida, USA",10.1109/visual.2005.1532853;10.1109/tvcg.2007.70602;10.1109/visual.1991.175782;10.1109/tvcg.2007.70518;10.1109/tvcg.2012.249;10.1109/visual.1994.346331;10.1109/visual.1996.568116;10.1109/tvcg.2009.194;10.1109/tvcg.2011.203;10.1109/visual.2005.1532853,"Uncertainty quantification, linear interpolation, isosurface extraction, marching cubes",43.0,38.0,36.0,1053.0,,,uncertainty isosurface extraction;crossing position;probability density function;non;characterization mentioned,0.8334;0.1327;0.1246;0.0455;0.0288,"[np.int64(-1), -1, -1, -1, -1]",229;-1;-1;-1;-1,229,229
Vis,2004,Vorticity based flow analysis and visualization for Pelton turbine design optimization,10.1109/visual.2004.128,http://dx.doi.org/10.1109/VISUAL.2004.128,179.0,186.0,C,"Vorticity is the quantity used to describe the creation, transformation and extinction of vortices. It is present not only in vortices but also in shear flow. Especially in ducted flows, most of the overall vorticity is usually contained in the boundary layer. When a vortex develops from the boundary layer, this can be described by transport of vorticity. For a better understanding of a flow it is therefore of interest to examine vorticity in all of its different roles. The goal of this application study was not primarily the visualization of vortices but of vorticity distribution and its role in vortex phenomena. The underlying industrial case is a design optimization for a Pelton turbine. An important industrial objective is to improve the quality of the water jets driving the runner. Jet quality is affected mostly by vortices originating in the distributor ring. For a better understanding of this interrelation, it is crucial to not only visualize these vortices but also to analyze the mechanisms of their creation. We used various techniques for the visualization of vorticity, including field lines and modified isosurfaces. For field line based visualization, we extended the image-guided streamline placement algorithm of Turk and Banks to data-guided field line placement on three-dimensional unstructured grids.",Filip Sadlo;Ronald Peikert;Etienne Parkinson,F. Sadlo;R. Peikert;E. Parkinson,"Comput. Sci. Dept., Eidgenossische Tech. Hochschule, Zurich, Switzerland;Comput. Sci. Dept., Eidgenossische Tech. Hochschule, Zurich, Switzerland; VA Tech Hydro",10.1109/visual.2003.1250372;10.1109/visual.1996.567807;10.1109/visual.1998.745317;10.1109/visual.1992.235211;10.1109/visual.2000.885690;10.1109/visual.1998.745295;10.1109/visual.1994.346327;10.1109/visual.2001.964506;10.1109/visual.1999.809896;10.1109/visual.1999.809907;10.1109/visual.2002.1183789;10.1109/visual.2003.1250372,"flow visualization, feature extraction, line placement",53.0,17.0,33.0,507.0,,,visualization vortices vorticity;isosurfaces field line;jets driving runner;industrial objective improve;usually,0.7290;0.2755;0.1619;0.1520;-0.0334,"[np.int64(-1), -1, -1, -1, -1]",142;-1;-1;-1;-1,142,142
InfoVis,2016,cite2vec: Citation-Driven Document Exploration via Word Embeddings,10.1109/tvcg.2016.2598667,http://dx.doi.org/10.1109/TVCG.2016.2598667,691.0,700.0,J,"Effectively exploring and browsing document collections is a fundamental problem in visualization. Traditionally, document visualization is based on a data model that represents each document as the set of its comprised words, effectively characterizing what the document is. In this paper we take an alternative perspective: motivated by the manner in which users search documents in the research process, we aim to visualize documents via their usage, or how documents tend to be used. We present a new visualization scheme - cite2vec - that allows the user to dynamically explore and browse documents via how other documents use them, information that we capture through citation contexts in a document collection. Starting from a usage-oriented word-document 2D projection, the user can dynamically steer document projections by prescribing semantic concepts, both in the form of phrase/document compositions and document:phrase analogies, enabling the exploration and comparison of documents by their use. The user interactions are enabled by a joint representation of words and documents in a common high-dimensional embedding space where user-specified concepts correspond to linear operations of word and document vectors. Our case studies, centered around a large document corpus of computer vision research papers, highlight the potential for usage-based document visualization.",Matthew Berger;Katherine McDonough;Lee M. Seversky,Matthew Berger;Katherine McDonough;Lee M. Seversky,Air Force Research Laboratory;Northeastern University;Air Force Research Laboratory,10.1109/tvcg.2014.2346431;10.1109/vast.2011.6102461;10.1109/tvcg.2011.220;10.1109/tvcg.2015.2467451;10.1109/tvcg.2010.207;10.1109/tvcg.2014.2346978;10.1109/tvcg.2015.2467757;10.1109/vast.2009.5333428;10.1109/tvcg.2013.212;10.1109/tvcg.2015.2467621;10.1109/vast.2014.7042493;10.1109/tvcg.2013.162;10.1109/tvcg.2009.202;10.1109/tvcg.2008.138;10.1109/tvcg.2014.2346431,word embeddings;document visualization,85.0,57.0,44.0,2306.0,,,visualize documents;cite2vec allows user;user dynamically steer;phrase;projections prescribing,0.6613;0.3124;0.1531;0.1174;0.1012,"[np.int64(-1), -1, -1, -1, -1]",171;-1;-1;-1;-1,171,171
VAST,2010,Real-time aggregation of Wikipedia data for visual analytics,10.1109/vast.2010.5652896,http://dx.doi.org/10.1109/VAST.2010.5652896,147.0,154.0,C,"Wikipedia has been built to gather encyclopedic knowledge using a collaborative social process that has proved its effectiveness. However, the workload required for raising the quality and increasing the coverage of Wikipedia is exhausting the community. Based on several participatory design sessions with active Wikipedia contributors (a.k.a. Wikipedians), we have collected a set of measures related to Wikipedia activity that, if available and visualized effectively, could spare a lot of monitoring time to these Wikipedians, allowing them to focus on quality and coverage of Wikipedia instead of spending their time navigating heavily to track vandals and copyright infringements. However, most of these measures cannot be computed on the fly using the available Wikipedia API. Therefore, we have designed an open architecture called WikiReactive to compute incrementally and maintain several aggregated measures on the French Wikipedia. This aggregated data is available as a Web Service and can be used to overlay information on Wikipedia articles through Wikipedia Skins or for new services for Wikipedians or people studying Wikipedia. This article describes the architecture, its performance and some of its uses.",Nadia Boukhelifa;Fanny Chevalier;Jean-Daniel Fekete,Nadia Boukhelifa;Fanny Chevalier;Jean-Daniel Fekete,"Microsoft Research-INRIA Joint Centre, France;Microsoft Research-INRIA Joint Centre, France;INRIA, France",,,21.0,10.0,23.0,480.0,,,wikipedia api designed;collaborative social process;track vandals copyright;aggregated measures french;exhausting,0.6910;0.3503;0.2830;0.1930;0.0721,"[np.int64(-1), -1, -1, -1, -1]",244;-1;-1;-1;-1,244,244
VAST,2012,SocialNetSense: Supporting sensemaking of social and structural features in networks with interactive visualization,10.1109/vast.2012.6400558,http://dx.doi.org/10.1109/VAST.2012.6400558,133.0,142.0,C,"Increasingly, social network datasets contain social attribute information about actors and their relationship. Analyzing such network with social attributes requires making sense of not only its structural features, but also the relationship between social features in attributes and network structures. Existing social network analysis tools are usually weak in supporting complex analytical tasks involving both structural and social features, and often overlook users' needs for sensemaking tools that help to gather, synthesize, and organize information of these features. To address these challenges, we propose a sensemaking framework of social-network visual analytics in this paper. This framework considers both bottom-up processes, which are about constructing new understandings based on collected information, and top-down processes, which concern using prior knowledge to guide information collection, in analyzing social networks from both social and structural perspectives. The framework also emphasizes the externalization of sensemaking processes through interactive visualization. Guided by the framework, we develop a system, SocialNetSense, to support the sensemaking in visual analytics of social networks with social attributes. The example of using our system to analyze a scholar collaboration network shows that our approach can help users gain insight into social networks both structurally and socially, and enhance their process awareness in visual analytics.",Liang Gou;Xiaolong (Luke) Zhang;Airong Luo;Patricia F. Anderson,Liang Gou;Xiaolong Zhang;Airong Luo;Patricia F. Anderson,The Pennsylvania State University;The Pennsylvania State University;University of Michigan;University of Michigan,10.1109/infvis.1999.801853;10.1109/tvcg.2011.247;10.1109/infvis.2005.1532126;10.1109/visual.2005.1532788;10.1109/tvcg.2007.70582;10.1109/tvcg.2006.192;10.1109/vast.2009.5333020;10.1109/vast.2011.6102440;10.1109/vast.2006.261426;10.1109/infvis.2004.2;10.1109/tvcg.2008.137;10.1109/tvcg.2006.166;10.1109/tvcg.2006.160;10.1109/vast.2008.4677365;10.1109/tvcg.2006.147;10.1109/vast.2007.4389006;10.1109/infvis.1999.801853,"Social network, visualization, sensemaking, visual analytics, SocialNetSense",19.0,1.0,48.0,727.0,,,network visual analytics;socially enhance process;scholar;making sense;concern using,0.6996;0.2784;0.2040;0.1315;0.0984,"[np.int64(-1), -1, -1, -1, -1]",169;-1;-1;-1;-1,169,169
Vis,2004,Vector Wavelet Thresholding for Vector Field Denoising,10.1109/visual.2004.108,http://dx.doi.org/10.1109/VISUAL.2004.108,25.0,25.0,M,"Noise reduction is an important preprocessing step for many visualization techniques that make use of feature extraction. We propose a method for denoising 2-D vector fields that are corrupted by additive noise. The method is based on the vector wavelet transform and wavelet coefficient thresholding. We compare our wavelet-based denoising method with Gaussian filtering, and test the effect of these methods on the signal-to-noise ratio (SNR) of the vector fields before and after denoising. We also study the effect on relevant details for visualization, such as vortex measures. The results show that for low SNR, Gaussian filtering with large kernels has a somewhat higher performance than the wavelet-based method in terms of SNR. For larger SNR, the wavelet-based method outperforms Gaussian filtering. This is mostly due to the fact that Gaussian filtering tends to remove small details, which are preserved by the wavelet-based method.",Michel A. Westenberg;Thomas Ertl,M.A. Westenberg;T. Ertl,"Institute for Visualization and Interactive Systems, University of Stuttgart, Stuttgart, Germany;Institute for Visualization and Interactive Systems, University of Stuttgart, Stuttgart, Germany",,,3.0,2.0,7.0,82.0,,,vector fields denoising;larger snr wavelet;preprocessing step visualization;details preserved;compare,0.6808;0.4118;0.2955;0.1083;0.0311,"[np.int64(-1), -1, -1, -1, -1]",8;-1;-1;-1;-1,8,8
Vis,1998,Real-time techniques for 3D flow visualization,10.1109/visual.1998.745317,http://dx.doi.org/10.1109/VISUAL.1998.745317,305.0,312.0,C,"Visualization of three-dimensional steady flow has to overcome a lot of problems to be effective. Among them are occlusion of distant details, lack of directional and depth hints and occlusion. We present methods which address these problems for real-time graphic representations applicable in virtual environments. We use dashtubes, i.e., animated, opacity-mapped streamlines, as a visualization icon for 3D-flow visualization. We present a texture mapping technique to keep the level of texture detail along a streamline nearly constant even when the velocity of the flow varies considerably. An algorithm is described which distributes the dashtubes evenly in space. We apply magic lenses and magic boxes as interaction techniques for investigating densely filled areas without overwhelming the observer with visual detail. Implementation details of these methods and their integration in our virtual environment conclude the paper.",Anton L. Fuhrmann;M. Eduard Gröller,A. Fuhrmann;E. Groller,Vienna University of Technology;Vienna University of Technology,10.1109/visual.1994.346312;10.1109/visual.1997.663897;10.1109/visual.1997.663921;10.1109/visual.1991.175771;10.1109/visual.1997.663912;10.1109/visual.1993.398877;10.1109/visual.1994.346312,"virtual environments, flow visualization, texturing, interaction, magic lens, focussing",151.0,26.0,22.0,328.0,,,3d flow visualization;dashtubes animated opacity;virtual environments use;apply magic;varies,0.6741;0.4255;0.2601;0.2153;0.0537,"[np.int64(-1), -1, -1, -1, -1]",145;-1;-1;-1;-1,145,145
Vis,2000,A topology simplification method for 2D vector fields,10.1109/visual.2000.885716,http://dx.doi.org/10.1109/VISUAL.2000.885716,359.0,366.0,C,"Topology analysis of plane, turbulent vector fields results in visual clutter caused by critical points indicating vortices of finer and finer scales. A simplification can be achieved by merging critical points within a prescribed radius into higher order critical points. After building clusters containing the singularities to merge, the method generates a piecewise linear representation of the vector field in each cluster containing only one (higher order) singularity. Any visualization method can be applied to the result after this process. Using different maximal distances for the critical points to be merged results in a hierarchy of simplified vector fields that can be used for analysis on different scales.",Xavier Tricoche;Gerik Scheuermann;Hans Hagen,X. Tricoche;G. Scheuermann;H. Hagen,"Department of Computer Science, University of Kaiserslautern, Kaiserslautern, Germany;Department of Computer Science, University of Kaiserslautern, Kaiserslautern, Germany;Department of Computer Science, University of Kaiserslautern, Kaiserslautern, Germany",10.1109/visual.1999.809863;10.1109/visual.1998.745318;10.1109/visual.1991.175773;10.1109/visual.1999.809907;10.1109/visual.1997.663858;10.1109/visual.1999.809863,"vector field topology, flow visualization, clustering,simplification",176.0,55.0,12.0,256.0,,,turbulent vector fields;singularity visualization method;building clusters containing;points;using different maximal,0.6730;0.5624;0.2167;0.0455;0.0211,"[np.int64(-1), np.int64(-1), -1, -1, -1]",40;153;-1;-1;-1,40;153,40
Vis,2021,TacticFlow: Visual Analytics of Ever-Changing Tactics in Racket Sports,10.1109/tvcg.2021.3114832,http://dx.doi.org/10.1109/TVCG.2021.3114832,835.0,845.0,J,"Event sequence mining is often used to summarize patterns from hundreds of sequences but faces special challenges when handling racket sports data. In racket sports (e.g., tennis and badminton), a player hitting the ball is considered a multivariate event consisting of multiple attributes (e.g., hit technique and ball position). A rally (i.e., a series of consecutive hits beginning with one player serving the ball and ending with one player winning a point) thereby can be viewed as a multivariate event sequence. Mining frequent patterns and depicting how patterns change over time is instructive and meaningful to players who want to learn more short-term competitive strategies (i.e., tactics) that encompass multiple hits. However, players in racket sports usually change their tactics rapidly according to the opponent's reaction, resulting in ever-changing tactic progression. In this work, we introduce a tailored visualization system built on a novel multivariate sequence pattern mining algorithm to facilitate explorative identification and analysis of various tactics and tactic progression. The algorithm can mine multiple non-overlapping multivariate patterns from hundreds of sequences effectively. Based on the mined results, we propose a glyph-based Sankey diagram to visualize the ever-changing tactic progression and support interactive data exploration. Through two case studies with four domain experts in tennis and badminton, we demonstrate that our system can effectively obtain insights about tactic progression in most racket sports. We further discuss the strengths and the limitations of our system based on domain experts' feedback.",Jiang Wu;Dongyu Liu;Ziyang Guo;Qingyang Xu;Yingcai Wu,Jiang Wu;Dongyu Liu;Ziyang Guo;Qingyang Xu;Yingcai Wu,"State Key Lab of CAD&CG, Zhejiang University, China;Massachusetts Institute of Technology, United States;State Key Lab of CAD&CG, Zhejiang University, China;State Key Lab of CAD&CG, Zhejiang University, China;State Key Lab of CAD&CG, Zhejiang University, China",10.1109/tvcg.2017.2745278;10.1109/tvcg.2017.2745083;10.1109/tvcg.2021.3114861;10.1109/tvcg.2019.2934670;10.1109/tvcg.2020.3030442;10.1109/tvcg.2014.2346682;10.1109/tvcg.2018.2864885;10.1109/tvcg.2017.2745320;10.1109/tvcg.2020.3030465;10.1109/tvcg.2011.179;10.1109/tvcg.2016.2598831;10.1109/tvcg.2013.200;10.1109/tvcg.2013.192;10.1109/tvcg.2019.2934243;10.1109/tvcg.2016.2598591;10.1109/vast50239.2020.00009;10.1109/tvcg.2017.2744218;10.1109/tvcg.2020.3030359;10.1109/tvcg.2020.3030392;10.1109/tvcg.2020.3030458;10.1109/tvcg.2019.2934630;10.1109/tvcg.2017.2745278,"Sports Analytics,Multivariate Event Sequence,Sequential Pattern Mining,Progression Analysis",12.0,33.0,67.0,1792.0,,,event sequence mining;visualize changing tactic;handling racket;overlapping multivariate;propose glyph based,0.5559;0.4749;0.3015;0.1933;0.1893,"[np.int64(-1), -1, -1, -1, -1]",127;-1;-1;-1;-1,127,127
Vis,1999,Volume rendering based interactive navigation within the human colon,10.1109/visual.1999.809914,http://dx.doi.org/10.1109/VISUAL.1999.809914,397.0,549.0,C,"We present an interactive navigation system for virtual colonoscopy, which is based solely on high performance volume rendering. Previous colonic navigation systems have employed either a surface rendering or a Z-buffer-assisted volume rendering method that depends on the surface rendering results. Our method is a fast direct volume rendering technique that exploits distance information stored in the potential field of the camera control model, and is parallelized on a multiprocessor. Experiments have been conducted on both a simulated pipe and patients' data sets acquired with a CT scanner.",Ming Wan;Qingyu Tang;Arie E. Kaufman;Zhengrong Liang;Mark Wax,M. Wan;Q. Tang;A. Kaufman;Z. Liang;M. Wax,"Center for Visual Computing (CVC)and Departments of Computer Science and Radiology, State University of New York, Stony Brook, Stony Brook, NY, USA;Center for Visual Computing (CVC)and Departments of Computer Science and Radiology, State University of New York, Stony Brook, Stony Brook, NY, USA;Center for Visual Computing (CVC)and Departments of Computer Science and Radiology, State University of New York, Stony Brook, Stony Brook, NY, USA;Center for Visual Computing (CVC)and Departments of Computer Science and Radiology, State University of New York, Stony Brook, Stony Brook, NY, USA;Center for Visual Computing (CVC)and Departments of Computer Science and Radiology, State University of New York, Stony Brook, Stony Brook, NY, USA",10.1109/visual.1999.809911;10.1109/visual.1997.663915;10.1109/visual.1998.745713;10.1109/visual.1993.398852;10.1109/visual.1999.809900;10.1109/visual.1999.809911,,92.0,24.0,17.0,115.0,,,navigation virtual colonoscopy;performance volume rendering;multiprocessor;potential field;model,0.7299;0.4812;0.1826;0.1451;0.0355,"[np.int64(-1), -1, -1, -1, -1]",4;-1;-1;-1;-1,4,4
Vis,1994,Wavelet-based volume morphing,10.1109/visual.1994.346333,http://dx.doi.org/10.1109/VISUAL.1994.346333,85.0,,C,"This paper presents a technique for performing volume morphing between two volumetric datasets in the wavelet domain. The idea is to decompose the volumetric datasets into a set of frequency bands, apply smooth interpolation to each band, and reconstruct to form the morphed model. In addition, a technique for establishing a suitable correspondence among object voxels is presented. The combination of these two techniques results in a smooth transition between the two datasets and produces morphed volume with fewer high frequency distortions than those obtained from spatial domain volume morphing.&lt;&lt;ETX&gt;&gt;",Taosong He;Sidney W. Wang;Arie E. Kaufman,Taosong He;S. Wang;A. Kaufman,"Department of Computer Science, State University of New York, Stony Brook, Stony Brook, NY, USA;Department of Computer Science, State University of New York, Stony Brook, Stony Brook, NY, USA;Department of Computer Science, State University of New York, Stony Brook, Stony Brook, NY, USA",10.1109/visual.1993.398854;10.1109/visual.1993.398854,,199.0,21.0,9.0,96.0,,,morphing volumetric datasets;wavelet domain;technique performing;fewer high frequency;idea,0.7691;0.4224;0.0758;0.0199;0.0125,"[np.int64(-1), -1, -1, -1, -1]",312;-1;-1;-1;-1,312,312
Vis,2024,VADIS: A Visual Analytics Pipeline for Dynamic Document Representation and Information-Seeking,10.1109/tvcg.2024.3456339,http://dx.doi.org/10.1109/TVCG.2024.3456339,1312.0,1321.0,J,"In the biomedical domain, visualizing the document embeddings of an extensive corpus has been widely used in information-seeking tasks. However, three key challenges with existing visualizations make it difficult for clinicians to find information efficiently. First, the document embeddings used in these visualizations are generated statically by pretrained language models, which cannot adapt to the user's evolving interest. Second, existing document visualization techniques cannot effectively display how the documents are relevant to users' interest, making it difficult for users to identify the most pertinent information. Third, existing embedding generation and visualization processes suffer from a lack of interpretability, making it difficult to understand, trust and use the result for decision-making. In this paper, we present a novel visual analytics pipeline for user-driven document representation and iterative information seeking (VADIS). VADIS introduces a prompt-based attention model (PAM) that generates dynamic document embedding and document relevance adjusted to the user's query. To effectively visualize these two pieces of information, we design a new document map that leverages a circular grid layout to display documents based on both their relevance to the query and the semantic similarity. Additionally, to improve the interpretability, we introduce a corpus-level attention visualization method to improve the user's understanding of the model focus and to enable the users to identify potential oversight. This visualization, in turn, empowers users to refine, update and introduce new queries, thereby facilitating a dynamic and iterative information-seeking experience. We evaluated VADIS quantitatively and qualitatively on a real-world dataset of biomedical research papers to demonstrate its effectiveness.",Rui Qiu;Yamei Tu;Po-Yin Yen;Han-Wei Shen,Rui Qiu;Yamei Tu;Po-Yin Yen;Han-Wei Shen,"Ohio Sate University, USA;Ohio Sate University, USA;Washington University School of Medicine, USA;Ohio Sate University, USA",10.1109/tvcg.2015.2467621;10.1109/tvcg.2016.2598827;10.1109/tvcg.2021.3114820,"Attention visualization,dynamic document representation,,,document visualization,biomedical information seeking",,0.0,42.0,505.0,BP,,visualizing document embeddings;based relevance query;biomedical domain;focus enable users;update,0.6613;0.2735;0.2362;0.1270;0.0103,"[np.int64(-1), -1, -1, -1, -1]",296;-1;-1;-1;-1,296,296
VAST,2009,MassVis: Visual analysis of protein complexes using mass spectrometry,10.1109/vast.2009.5333895,http://dx.doi.org/10.1109/VAST.2009.5333895,163.0,170.0,C,"Protein complexes are formed when two or more proteins non-covalently interact to form a larger three dimensional structure with specific biological function. Understanding the composition of such complexes is vital to understanding cell biology at the molecular level. MassVis is a visual analysis tool designed to assist the interpretation of data from a new workflow for detecting the composition of such protein complexes in biological samples. The data generated by the laboratory workflow naturally lends itself to a scatter plot visualization. However, characteristics of this data give rise to some unique aspects not typical of a standard scatter plot. We are able to take the output from tandem mass spectrometry and render the data in such a way that it mimics more traditional two-dimensional gel techniques and at the same time reveals the correlated behavior indicative of protein complexes. By computationally measuring these correlated patterns in the data, membership in putative complexes can be inferred. User interactions are provided to support both an interactive discovery mode as well as an unsupervised clustering of likely complexes. The specific analysis tasks led us to design a unique arrangement of item selection and coordinated detail views in order to simultaneously view different aspects of the selected item.",Robert Kincaid;Kurt Dejgaard,Robert Kincaid;Kurt Dejgaard,"Agilent Laboratories;McGill University, Canada",10.1109/visual.2005.1532827;10.1109/visual.2005.1532828;10.1109/vast.2007.4389006,"information visualization, visual analysis, correlation analysis, mass spectrometry, proteomics, interactome",7.0,8.0,27.0,267.0,,,protein complexes computationally;standard scatter plot;laboratory workflow naturally;item selection coordinated;vital understanding,0.6231;0.3060;0.2242;0.2147;0.1101,"[np.int64(-1), -1, -1, -1, -1]",119;-1;-1;-1;-1,119,119
VAST,2012,Visualising variations in household energy consumption,10.1109/vast.2012.6400545,http://dx.doi.org/10.1109/VAST.2012.6400545,217.0,218.0,M,"There is limited understanding of the relationship between neighbourhoods, demographic characteristics and domestic energy consumption habits. We report upon research that combines datasets relating to household energy use with geodemographics to enable better understanding of UK energy user types. A novel interactive interface is planned to evaluate the performance of specifically created energy-based data classifications. The research aims to help local governments and the energy industry in targeting households and populations for new energy saving schemes and in improving efforts to promote sustainable energy consumption. The new classifications may also stimulate consumption awareness amongst domestic users. This poster reports on initial visual findings and describes the research methodology, data sources and future visualisation requirements.",Sarah Goodwin;Jason Dykes,Sarah Goodwin;Jason Dykes,"giCentre, City University London, UK;giCentre, City University London, UK",0.1109/tvcg.2011.196;10.1109/tvcg.2011.197,,11.0,3.0,10.0,488.0,,,uk energy user;relationship neighbourhoods demographic;classifications research aims;use geodemographics enable;sources future visualisation,0.6165;0.3483;0.3110;0.2104;0.1621,"[np.int64(-1), -1, -1, -1, -1]",71;-1;-1;-1;-1,71,71
InfoVis,1995,Case study: fishing for information on the Internet,10.1109/infvis.1995.528693,http://dx.doi.org/10.1109/INFVIS.1995.528693,105.0,111.0,C,"As the Internet continues to grow, the amount of accessible information becomes increasingly vast. Search tools exist that allow users to find relevant information. However, a search can often produce such a large amount of data that it becomes hard to ferret out the most appropriate and highest quality information. In addition, some search tools lose valuable information when displaying the results to the user. The paper describes a search visualization tool, called FISH, for viewing hierarchically structured information and managing information overload. FISH (Forager for the Information Super Highway) allows users to visualize the results of search requests across large document spaces in a way that preserves the structure of the information space. FISH displays the returned documents as rectangles, using a combination of order, indentation, size, and color to denote document hierarchy, the score of the documents with respect to the search, and other data attributes. In addition, the user can navigate through the document space for in-depth probing and refinement.",R. Mitchell;David S. Day;Lynette Hirschman,R. Mitchell;D. Day;L. Hirschman,"MITRE Corporation, Bedford, MA, USA;MITRE Corporation, Bedford, MA, USA;MITRE Corporation, Bedford, MA, USA",10.1109/visual.1991.175815;10.1109/visual.1991.175815,,16.0,4.0,4.0,98.0,,,search visualization;managing information overload;documents rectangles using;order indentation size;highway allows,0.6719;0.4449;0.3624;0.1473;-0.0035,"[np.int64(-1), -1, -1, -1, -1]",178;-1;-1;-1;-1,178,178
VAST,2009,Evaluating visual analytics systems for investigative analysis: Deriving design principles from a case study,10.1109/vast.2009.5333878,http://dx.doi.org/10.1109/VAST.2009.5333878,139.0,146.0,C,"Despite the growing number of systems providing visual analytic support for investigative analysis, few empirical studies of the potential benefits of such systems have been conducted, particularly controlled, comparative evaluations. Determining how such systems foster insight and sensemaking is important for their continued growth and study, however. Furthermore, studies that identify how people use such systems and why they benefit (or not) can help inform the design of new systems in this area. We conducted an evaluation of the visual analytics system Jigsaw employed in a small investigative sensemaking exercise, and we compared its use to three other more traditional methods of analysis. Sixteen participants performed a simulated intelligence analysis task under one of the four conditions. Experimental results suggest that Jigsaw assisted participants to analyze the data and identify an embedded threat. We describe different analysis strategies used by study participants and how computational support (or the lack thereof) influenced the strategies. We then illustrate several characteristics of the sensemaking process identified in the study and provide design implications for investigative analysis tools based thereon. We conclude with recommendations for metrics and techniques for evaluating other visual analytics investigative analysis tools.",Youn ah Kang;Carsten Görg;John T. Stasko,Youn-ah Kang;Carsten Gorg;John Stasko,"School of Interactive Computing & GVU Center, Georgia Institute of Technology, USA;School of Interactive Computing & GVU Center, Georgia Institute of Technology, USA;School of Interactive Computing & GVU Center, Georgia Institute of Technology, USA",10.1109/vast.2008.4677362;10.1109/vast.2008.4677360;10.1109/vast.2006.261416;10.1109/vast.2007.4389006;10.1109/vast.2008.4677358;10.1109/vast.2008.4677362,,111.0,52.0,17.0,1065.0,,,investigative sensemaking;visual analytic support;exercise compared use;number systems;thereon,0.6989;0.5991;0.1065;0.0663;-0.0006,"[np.int64(-1), np.int64(-1), -1, -1, -1]",86;200;-1;-1;-1,86;200,86
