Conference,Year,Title,DOI,Link,FirstPage,LastPage,PaperType,Abstract,AuthorNames-Deduped,AuthorNames,AuthorAffiliation,InternalReferences,AuthorKeywords,AminerCitationCount,CitationCount_CrossRef,PubsCited_CrossRef,Downloads_Xplore,Award,GraphicsReplicabilityStamp,Keywords,RelevanceScore,KeywordClusters,RefinedKeywordClusters,AllClusters,DominantCluster,Area
VAST,2006,Pixnostics: Towards Measuring the Value of Visualization,10.1109/vast.2006.261423,http://dx.doi.org/10.1109/VAST.2006.261423,199.0,206.0,C,"During the last two decades a wide variety of advanced methods for the visual exploration of large data sets have been proposed. For most of these techniques user interaction has become a crucial element, since there are many situations in which a user or an analyst has to select the right parameter settings from among many or select a subset of the available attribute space for the visualization process, in order to construct valuable visualizations that provide insight, into the data and reveal interesting patterns. The right choice of input parameters is often essential, since suboptimal parameter settings or the investigation of irrelevant data dimensions make the exploration process more time consuming and may result in wrong conclusions. In this paper we propose a novel method for automatically determining meaningful parameter- and attribute settings based on the information content of the resulting visualizations. Our technique called Pixnostics, in analogy to Scagnostics (Wilkinson et al., 2005), automatically analyses pixel images resulting from diverse parameter mappings and ranks them according to the potential value for the user. This allows a more effective and more efficient visual data analysis process, since the attribute/parameter space is reduced to meaningful selections and thus the analyst obtains faster insight into the data. Real world applications are provided to show the benefit of the proposed approach",Jörn Schneidewind;Mike Sips;Daniel A. Keim,Jorn Schneidewind;Mike Sips;Daniel A. Keim,"University of Konstanz, Germany;University of Stanford, USA;University of Konstanz, Germany",10.1109/infvis.2005.1532145;10.1109/infvis.2005.1532142;10.1109/visual.2005.1532782;10.1109/visual.2005.1532781;10.1109/infvis.2000.885092;10.1109/infvis.2005.1532145,"Visual Data Exploration, Visualization technique,Visual Analytics",63.0,35.0,24.0,684.0,,,construct valuable visualizations;parameter attribute settings;called pixnostics;select subset;2005 automatically,0.6616;0.2800;0.2359;0.1310;0.0510,"[np.int64(-1), -1, -1, -1, -1]",102;-1;-1;-1;-1,102,102,Visualization Value Assessment
VAST,2015,Interactive semi-automatic categorization for spinel group minerals,10.1109/vast.2015.7347676,http://dx.doi.org/10.1109/VAST.2015.7347676,197.0,198.0,M,"Spinel group minerals are excellent indicators of geological environments (tectonic settings). In 2001, Barnes and Roeder defined a set of contours corresponding to compositional fields for spinel group minerals. Geologists typically use this contours to estimate the tectonic environment where a particular spinel composition could have been formed. This task is prone to errors and requires tedious manual comparison of overlapping diagrams. We introduce a semi-automatic, interactive detection of tectonic settings for an arbitrary dataset based on the Barnes and Roeder contours. The new approach integrates the mentioned contours and includes a novel interaction called contour brush. The new methodology is integrated in the Spinel Explorer system and it improves the scientist's workflow significantly.",Maria Luján Ganuza;Maria Florencia Gargiulo;Gabriela Ferracutti;Silvia Mabel Castro;Ernesto A. Bjerg;M. Eduard Gröller;Kresimir Matkovic,María Luján Ganuza;Florencia Gargiulo;Gabriela Ferracutti;Silvia Castro;Ernesto Bjerg;Eduard Gröller;Krešimir Matković,"UNS, VyGLab;INGEOSUR CONICET;INGEOSUR CONICET;UNS, VyGLab;INGEOSUR CONICET;TU Wien;VRVis",0.1109/tvcg.2014.2346754,,5.0,2.0,5.0,106.0,,,interactive detection tectonic;compositional fields spinel;settings arbitrary dataset;group;prone errors,0.6692;0.3364;0.1164;0.0436;0.0330,"[np.int64(-1), -1, -1, -1, -1]",72;-1;-1;-1;-1,72,72,Ridge Extraction Techniques
Vis,1994,Visualization in medicine: VIRTUAL reality or ACTUAL reality ?,10.1109/visual.1994.346288,http://dx.doi.org/10.1109/VISUAL.1994.346288,396.0,399.0,M,Discusses and debates the role played by 3D visualization in medicine as a set of methods and techniques for displaying 3D spatial information related to the anatomy and the physiology of the human body.&lt;&lt;ETX&gt;&gt;,Christian Roux;Jean-Louis Coatrieux;Jean-Louis Dillenseger;Elliot K. Fishman;Murray H. Loew;Hans-Peter Meinzer;Justin D. Pearlman,C. Roux;J.L. Coatrieux;J.-L. Dillenseger;E.K. Fishman;M. Loew;H.-P. Meinzer;J.D. Pearlman,"Département Image et Traitement de l'Information, Ecole Nationale Supérieure des TéIécommunications, Brest, France;Labratoire Tiaitement du Signal et de l'Image, Université de Rennes 1, Rennes, France;University of Rennes I, France;Johns Hopkins School of Medicine, USA;Washington University, USA;German Cancer Center Heidelberg, Germany;Harvard Medical School, USA",,,3.0,1.0,3.0,96.0,,,3d visualization medicine;body;methods techniques displaying;lt etx;debates role,0.8177;0.2443;0.2170;0.0906;0.0320,"[np.int64(-1), -1, -1, -1, -1]",38;-1;-1;-1;-1,38,38,3D Medical Visualization
InfoVis,2014,Attribute Signatures: Dynamic Visual Summaries for Analyzing Multivariate Geographical Data,10.1109/tvcg.2014.2346265,http://dx.doi.org/10.1109/TVCG.2014.2346265,2033.0,2042.0,J,"The visual analysis of geographically referenced datasets with a large number of attributes is challenging due to the fact that the characteristics of the attributes are highly dependent upon the locations at which they are focussed, and the scale and time at which they are measured. Specialized interactive visual methods are required to help analysts in understanding the characteristics of the attributes when these multiple aspects are considered concurrently. Here, we develop attribute signatures-interactively crafted graphics that show the geographic variability of statistics of attributes through which the extent of dependency between the attributes and geography can be visually explored. We compute a number of statistical measures, which can also account for variations in time and scale, and use them as a basis for our visualizations. We then employ different graphical configurations to show and compare both continuous and discrete variation of location and scale. Our methods allow variation in multiple statistical summaries of multiple attributes to be considered concurrently and geographically, as evidenced by examples in which the census geography of London and the wider UK are explored.",Cagatay Turkay;Aidan Slingsby;Helwig Hauser;Jo Wood;Jason Dykes,Cagatay Turkay;Aidan Slingsby;Helwig Hauser;Jo Wood;Jason Dykes,"Dep. of Computer Science at City University London, UK;Dep. of Computer Science at City University London, UK;Department of Informatics at University of Bergen, Bergen, Norway;Dep. of Computer Science at City University London, UK;Dep. of Computer Science at City University London, UK",10.1109/tvcg.2013.173;10.1109/tvcg.2011.178;10.1109/tvcg.2013.226;10.1109/tvcg.2011.197;10.1109/tvcg.2007.70558;10.1109/tvcg.2008.149;10.1109/infvis.2004.12;10.1109/tvcg.2012.256;10.1109/tvcg.2007.70574;10.1109/vast.2008.4677350;10.1109/tvcg.2008.125;10.1109/tvcg.2013.122;10.1109/tvcg.2013.173,"Visual analytics, multi-variate data, geographic information, geovisualization, interactive data analysis",65.0,39.0,54.0,1343.0,,,visual analysis geographically;statistical measures account;referenced datasets large;concurrently develop attribute;different,0.7344;0.2434;0.2329;0.1353;0.0790,"[np.int64(-1), -1, -1, -1, -1]",89;-1;-1;-1;-1,89,89,Geographical Visualization
SciVis,2020,Polyphorm: Structural Analysis of Cosmological Datasets via Interactive Physarum Polycephalum Visualization,10.1109/tvcg.2020.3030407,http://dx.doi.org/10.1109/TVCG.2020.3030407,806.0,816.0,J,"This paper introduces Polyphorm, an interactive visualization and model fitting tool that provides a novel approach for investigating cosmological datasets. Through a fast computational simulation method inspired by the behavior of Physarum polycephalum, an unicellular slime mold organism that efficiently forages for nutrients, astrophysicists are able to extrapolate from sparse datasets, such as galaxy maps archived in the Sloan Digital Sky Survey, and then use these extrapolations to inform analyses of a wide range of other data, such as spectroscopic observations captured by the Hubble Space Telescope. Researchers can interactively update the simulation by adjusting model parameters, and then investigate the resulting visual output to form hypotheses about the data. We describe details of Polyphorm's simulation model and its interaction and visualization modalities, and we evaluate Polyphorm through three scientific use cases that demonstrate the effectiveness of our approach.",Oskar Elek;Joseph N. Burchett;J. Xavier Prochaska;Angus G. Forbes,Oskar Elek;Joseph N. Burchett;J. Xavier Prochaska;Angus G. Forbes,"Dept. of Computational Media, University of California, Santa Cruz;Dept. of Astronomy and Astrophysics, University of California, Santa Cruz;Dept. of Astronomy and Astrophysics, University of California, Santa Cruz;Dept. of Computational Media, University of California, Santa Cruz",10.1109/tvcg.2019.2934259;10.1109/tvcg.2019.2934259,"Astrophysics visualization,agent-based modeling,intergalactic media,Physarum polycephalum,Cosmic Web",13.0,10.0,79.0,530.0,,,investigating cosmological datasets;polyphorm interactive visualization;mold organism efficiently;interactively update;cases,0.6864;0.4737;0.2242;0.0722;-0.0446,"[np.int64(-1), -1, -1, -1, -1]",10;-1;-1;-1;-1,10,10,Cosmological Research
VAST,2017,Clustering Trajectories by Relevant Parts for Air Traffic Analysis,10.1109/tvcg.2017.2744322,http://dx.doi.org/10.1109/TVCG.2017.2744322,34.0,44.0,J,"Clustering of trajectories of moving objects by similarity is an important technique in movement analysis. Existing distance functions assess the similarity between trajectories based on properties of the trajectory points or segments. The properties may include the spatial positions, times, and thematic attributes. There may be a need to focus the analysis on certain parts of trajectories, i.e., points and segments that have particular properties. According to the analysis focus, the analyst may need to cluster trajectories by similarity of their relevant parts only. Throughout the analysis process, the focus may change, and different parts of trajectories may become relevant. We propose an analytical workflow in which interactive filtering tools are used to attach relevance flags to elements of trajectories, clustering is done using a distance function that ignores irrelevant elements, and the resulting clusters are summarized for further analysis. We demonstrate how this workflow can be useful for different analysis tasks in three case studies with real data from the domain of air traffic. We propose a suite of generic techniques and visualization guidelines to support movement data analysis by means of relevance-aware trajectory clustering.",Gennady L. Andrienko;Natalia V. Andrienko;Georg Fuchs;Jose Manuel Cordero Garcia,Gennady Andrienko;Natalia Andrienko;Georg Fuchs;Jose Manuel Cordero Garcia,"Fraunhofer IAIS, City University, London;Fraunhofer IAIS, City University, London;Fraunhofer Institute IAIS;CRIDA (Reference Center for Research, Development and Innovation in ATM)",10.1109/vast.2009.5332584;10.1109/tvcg.2013.193;10.1109/tvcg.2011.233;10.1109/tvcg.2015.2468292;10.1109/vast.2008.4677350;10.1109/vast.2009.5332584,"Visual analytics,movement data analysis,trajectory clustering,air traffic",90.0,62.0,53.0,2561.0,,,trajectories clustering using;important technique movement;relevance flags;workflow interactive;air,0.7251;0.2497;0.1665;0.1544;0.1401,"[np.int64(-1), -1, -1, -1, -1]",6;-1;-1;-1;-1,6,6,Geospatial Data Analysis
Vis,1996,Volume Thinning for Automatic Isosurface Propagation,10.1109/visual.1996.568123,http://doi.ieeecomputersociety.org/10.1109/VISUAL.1996.568123,303.0,310.0,C,"An isosurface can be efficiently generated by visiting adjacent intersected cells in order, as if the isosurface were propagating itself. We previously proposed an extrema graph method (T. Itoh and K. Koyamada, 1995), which generates a graph connecting extremum points. The isosurface propagation starts from some of the intersected cells that are found both by visiting the cells through which arcs of the graph pass and by visiting the cells on the boundary of a volume. We propose an efficient method of searching for cells intersected by an isosurface. This method generates a volumetric skeleton. consisting of cells, like an extrema graph, by applying a thinning algorithm used in the image recognition area. Since it preserves the topological features of the volume and the connectivity of the extremum points, it necessarily intersects every isosurface. The method is more efficient than the extrema graph method, since it does not require that cells on the boundary be visited.",Takayuki Itoh;Yasushi Yamaguchi 0001;Koji Koyamada,T. Itoh;Y. Yamaguchi;K. Koyamada,"Tokyo Research Laboratory, IBM Japan;Graduate School of Arts and Sciences, The University of Tokyo;Tokyo Research Laboratory, IBM Japan",10.1109/visual.1991.175780,,73.0,22.0,0.0,28.0,,,cells order isosurface;recognition area preserves;generates graph connecting;volume;method searching,0.5701;0.4382;0.3050;0.2427;0.2146,"[np.int64(-1), -1, -1, -1, -1]",126;-1;-1;-1;-1,126,126,Geometric Mesh Processing
Vis,2008,Sinus Endoscopy - Application of Advanced GPU Volume Rendering for Virtual Endoscopy,10.1109/tvcg.2008.161,http://dx.doi.org/10.1109/TVCG.2008.161,1491.0,1498.0,J,"For difficult cases in endoscopic sinus surgery, a careful planning of the intervention is necessary. Due to the reduced field of view during the intervention, the surgeons have less information about the surrounding structures in the working area compared to open surgery. Virtual endoscopy enables the visualization of the operating field and additional information, such as risk structures (e.g., optical nerve and skull base) and target structures to be removed (e.g., mucosal swelling). The Sinus Endoscopy system provides the functional range of a virtual endoscopic system with special focus on a realistic representation. Furthermore, by using direct volume rendering, we avoid time-consuming segmentation steps for the use of individual patient datasets. However, the image quality of the endoscopic view can be adjusted in a way that a standard computer with a modern standard graphics card achieves interactive frame rates with low CPU utilization. Thereby, characteristics of the endoscopic view are systematically used for the optimization of the volume rendering speed. The system design was based on a careful analysis of the endoscopic sinus surgery and the resulting needs for computer support. As a small standalone application it can be instantly used for surgical planning and patient education. First results of a clinical evaluation with ENT surgeons were employed to fine-tune the user interface, in particular to reduce the number of controls by using appropriate default values wherever possible. The system was used for preoperative planning in 102 cases, provides useful information for intervention planning (e.g., anatomic variations of the Rec. Frontalis), and closely resembles the intraoperative situation.",Arno Krüger;Christoph Kubisch;Gero Strauß;Bernhard Preim,Arno Krueger;Christoph Kubisch;Bernhard Preim;Gero Strauss,"Department of Simulation and Graphics, Otto-von-Guericke-University of Magdeburg, Germany;Department of Simulation and Graphics, Otto-von-Guericke-University of Magdeburg, Germany;ENT Department, University Hospital of Leipzig;Department of Simulation and Graphics, Otto-von-Guericke-University of Magdeburg, Germany",10.1109/visual.2003.1250370;10.1109/visual.2003.1250384;10.1109/visual.2004.98;10.1109/visual.2003.1250370,"medical visualization, sinus surgery, operation planning, virtual endoscopy, volume rendering",57.0,35.0,22.0,593.0,,,surgery virtual endoscopy;swelling sinus;provides useful information;frame rates;using appropriate default,0.6810;0.3314;0.1187;0.0552;0.0181,"[np.int64(-1), -1, -1, -1, -1]",27;-1;-1;-1;-1,27,27,Virtual Endoscopy Techniques
InfoVis,2006,Measuring Data Abstraction Quality in Multiresolution Visualizations,10.1109/tvcg.2006.161,http://dx.doi.org/10.1109/TVCG.2006.161,709.0,716.0,J,"Data abstraction techniques are widely used in multiresolution visualization systems to reduce visual clutter and facilitate analysis from overview to detail. However, analysts are usually unaware of how well the abstracted data represent the original dataset, which can impact the reliability of results gleaned from the abstractions. In this paper, we define two data abstraction quality measures for computing the degree to which the abstraction conveys the original dataset: the histogram difference measure and the nearest neighbor measure. They have been integrated within XmdvTool, a public-domain multiresolution visualization system for multivariate data analysis that supports sampling as well as clustering to simplify data. Several interactive operations are provided, including adjusting the data abstraction level, changing selected regions, and setting the acceptable data abstraction quality level. Conducting these operations, analysts can select an optimal data abstraction level. Also, analysts can compare different abstraction methods using the measures to see how well relative data density and outliers are maintained, and then select an abstraction method that meets the requirement of their analytic tasks",Qingguang Cui;Matthew O. Ward;Elke A. Rundensteiner;Jing Yang 0001,Qingguang Cui;Matthew Ward;Elke Rundensteiner;Jing Yang,"Worcester Polytechnic Institute, Worcester, MA, USA;Worcester Polytechnic Institute, Worcester, MA, USA;Worcester Polytechnic Institute, Worcester, MA, USA;University of North Carolina, Charlotte, Charlotte, NC, USA",10.1109/infvis.2004.19;10.1109/visual.2005.1532819;10.1109/infvis.2004.15;10.1109/visual.1995.485139;10.1109/infvis.2000.885088;10.1109/infvis.2004.19,"Metrics, Clustering, Sampling, Multiresolution Visualization",128.0,68.0,28.0,977.0,,,visualization multivariate data;nearest neighbor;unaware abstracted;impact reliability results;regions setting acceptable,0.5716;0.1777;0.1415;0.1315;0.1158,"[np.int64(-1), -1, -1, -1, -1]",93;-1;-1;-1;-1,93,93,Multivariate Data Visualization
Vis,1999,Spiraling Edge: fast surface reconstruction from partially organized sample points,10.1109/visual.1999.809903,http://dx.doi.org/10.1109/VISUAL.1999.809903,317.0,538.0,C,"Many applications produce three-dimensional points that must be further processed to generate a surface. Surface reconstruction algorithms that start with a set of unorganized points are extremely time-consuming. Sometimes however, points are generated such that there is additional information available to the reconstruction algorithm. We present Spiraling Edge, a specialized algorithm for surface reconstruction that is three orders of magnitude faster than algorithms for the general case. In addition to sample point locations, our algorithm starts with normal information and knowledge of each point's neighbors. Our algorithm produces a localized approximation to the surface by creating a star-shaped triangulation between a point and a subset of its nearest neighbors. This surface patch is extended by locally triangulating each of the points along the edge of the patch. As each edge point is triangulated, it is removed from the edge and new edge points along the patch's edge are inserted in its place. The updated edge spirals out over the surface until the edge encounters a surface boundary and stops growing in that direction, or until the edge reduces to a small hole that is filled by the final triangle.",Patricia Crossno;Edward Angel,P. Crossno;E. Angel,"Sandia National Laboratories, USA;University of New Mexico, USA",10.1109/visual.1997.663930;10.1109/visual.1998.745286;10.1109/visual.1997.663930,"Surface reconstruction, advancing front, triangulation",37.0,8.0,6.0,87.0,,,algorithm surface reconstruction;spirals;information knowledge point;patch extended locally;extremely time,0.6886;0.2777;0.1489;0.1463;-0.0510,"[np.int64(-1), -1, -1, -1, -1]",76;-1;-1;-1;-1,76,76,Surface Reconstruction Techniques
Vis,2021,Revisiting Dimensionality Reduction Techniques for Visual Cluster Analysis: An Empirical Study,10.1109/tvcg.2021.3114694,http://dx.doi.org/10.1109/TVCG.2021.3114694,529.0,539.0,J,"Dimensionality Reduction (DR) techniques can generate 2D projections and enable visual exploration of cluster structures of high-dimensional datasets. However, different DR techniques would yield various patterns, which significantly affect the performance of visual cluster analysis tasks. We present the results of a user study that investigates the influence of different DR techniques on visual cluster analysis. Our study focuses on the most concerned property types, namely the linearity and locality, and evaluates twelve representative DR techniques that cover the concerned properties. Four controlled experiments were conducted to evaluate how the DR techniques facilitate the tasks of 1) cluster identification, 2) membership identification, 3) distance comparison, and 4) density comparison, respectively. We also evaluated users' subjective preference of the DR techniques regarding the quality of projected clusters. The results show that: 1) Non-linear and Local techniques are preferred in cluster identification and membership identification; 2) Linear techniques perform better than non-linear techniques in density comparison; 3) UMAP (Uniform Manifold Approximation and Projection) and t-SNE (t-Distributed Stochastic Neighbor Embedding) perform the best in cluster identification and membership identification; 4) NMF (Nonnegative Matrix Factorization) has competitive performance in distance comparison; 5) t-SNLE (t-Distributed Stochastic Neighbor Linear Embedding) has competitive performance in density comparison.",Jiazhi Xia;Yuchen Zhang;Jie Song;Yang Chen;Yunhai Wang;Shixia Liu,Jiazhi Xia;Yuchen Zhang;Jie Song;Yang Chen;Yunhai Wang;Shixia Liu,"School of Computer Science and Engineering, Central South University, China;School of Computer Science and Engineering, Central South University, China;School of Computer Science and Engineering, Central South University, China;I4 data, United States;School of Computer Science and Technology, Shandong University, China;School of Software, Tsinghua University, China",10.1109/tvcg.2015.2467552;10.1109/tvcg.2011.220;10.1109/infvis.2003.1249017;10.1109/tvcg.2016.2598831;10.1109/tvcg.2017.2745258;10.1109/vast47406.2019.8986943;10.1109/tvcg.2020.3030432;10.1109/tvcg.2019.2934660;10.1109/tvcg.2018.2865020;10.1109/tvcg.2015.2467552,"Dimensionality reduction,visual cluster analysis,perception-based evaluation",17.0,39.0,61.0,1783.0,,,visual cluster analysis;linearity locality evaluates;significantly affect performance;identification nmf nonnegative;property types,0.7279;0.2847;0.0893;0.0846;0.0654,"[np.int64(-1), -1, -1, -1, -1]",85;-1;-1;-1;-1,85,85,Cluster Visualization
InfoVis,2008,HiPP: A Novel Hierarchical Point Placement Strategy and its Application to the Exploration of Document Collections,10.1109/tvcg.2008.138,http://dx.doi.org/10.1109/TVCG.2008.138,1229.0,1236.0,J,"Point placement strategies aim at mapping data points represented in higher dimensions to bi-dimensional spaces and are frequently used to visualize relationships amongst data instances. They have been valuable tools for analysis and exploration of data sets of various kinds. Many conventional techniques, however, do not behave well when the number of dimensions is high, such as in the case of documents collections. Later approaches handle that shortcoming, but may cause too much clutter to allow flexible exploration to take place. In this work we present a novel hierarchical point placement technique that is capable of dealing with these problems. While good grouping and separation of data with high similarity is maintained without increasing computation cost, its hierarchical structure lends itself both to exploration in various levels of detail and to handling data in subsets, improving analysis capability and also allowing manipulation of larger data sets.",Fernando Vieira Paulovich;Rosane Minghim,Fernando V. Paulovich;Rosane Minghim,"ICMC, Instituto de Ciências Matemáticas e de Computaçãao, University of São Paulo, Sao Paulo, Brazil;ICMC, Instituto de Ciências Matemáticas e de Computaçãao, University of São Paulo, Sao Paulo, Brazil",10.1109/visual.1999.809866;10.1109/visual.1991.175815;10.1109/vast.2007.4389002;10.1109/visual.1996.567787,"Text and document visualization, hierarchical multidimensional visualization, visual knowledge discovery, high-dimensional data",118.0,62.0,24.0,836.0,,,hierarchical point placement;documents collections;bi dimensional spaces;data;increasing computation cost,0.6046;0.4158;0.3215;0.2702;0.1649,"[np.int64(-1), -1, -1, -1, -1]",56;-1;-1;-1;-1,56,56,Treemap Visualization
Vis,2011,Vortex Visualization in Ultra Low Reynolds Number Insect Flight,10.1109/tvcg.2011.260,http://dx.doi.org/10.1109/TVCG.2011.260,2071.0,2079.0,J,"We present the visual analysis of a biologically inspired CFD simulation of the deformable flapping wings of a dragonfly as it takes off and begins to maneuver, using vortex detection and integration-based flow lines. The additional seed placement and perceptual challenges introduced by having multiple dynamically deforming objects in the highly unsteady 3D flow domain are addressed. A brief overview of the high speed photogrammetry setup used to capture the dragonfly takeoff, parametric surfaces used for wing reconstruction, CFD solver and underlying flapping flight theory is presented to clarify the importance of several unsteady flight mechanisms, such as the leading edge vortex, that are captured visually. A novel interactive seed placement method is used to simplify the generation of seed curves that stay in the vicinity of relevant flow phenomena as they move with the flapping wings. This method allows a user to define and evaluate the quality of a seed's trajectory over time while working with a single time step. The seed curves are then used to place particles, streamlines and generalized streak lines. The novel concept of flowing seeds is also introduced in order to add visual context about the instantaneous vector fields surrounding smoothly animate streak lines. Tests show this method to be particularly effective at visually capturing vortices that move quickly or that exist for a very brief period of time. In addition, an automatic camera animation method is used to address occlusion issues caused when animating the immersed wing boundaries alongside many geometric flow lines. Each visualization method is presented at multiple time steps during the up-stroke and down-stroke to highlight the formation, attachment and shedding of the leading edge vortices in pairs of wings. Also, the visualizations show evidence of wake capture at stroke reversal which suggests the existence of previously unknown unsteady lift generation mechanisms that are unique to quad wing insects.",Christopher Koehler;Thomas Wischgoll;Haibo Dong;Zachary Gaston,Christopher Koehler;Thomas Wischgoll;Haibo Dong;Zachary Gaston,"College of Engineering and Computer Science, Wright State University, USA;College of Engineering and Computer Science, Wright State University, USA;College of Mechanical and Materials Engineering, Wright State University, USA;College of Mechanical and Materials Engineering, Wright State University, USA",10.1109/visual.2002.1183789;10.1109/visual.2005.1532830;10.1109/tvcg.2007.70557;10.1109/visual.2005.1532831;10.1109/tvcg.2008.163;10.1109/tvcg.2010.169;10.1109/visual.2005.1532848;10.1109/visual.2005.1532850;10.1109/tvcg.2010.212;10.1109/visual.2000.885690;10.1109/tvcg.2010.198;10.1109/visual.2004.113;10.1109/visual.1998.745296;10.1109/tvcg.2007.70595;10.1109/tvcg.2009.190;10.1109/tvcg.2008.133;10.1109/tvcg.2006.199;10.1109/visual.2002.1183821;10.1109/tvcg.2007.70545;10.1109/tvcg.2010.166;10.1109/tvcg.2006.201;10.1109/visual.2002.1183789,"Flow visualization, flowing seed points, streak lines, streamlines, insect flight, vortex visualization, unsteady flow",42.0,31.0,47.0,1318.0,,,wings visualizations;reconstruction cfd solver;caused animating immersed;detection integration based;simplify generation seed,0.6005;0.3056;0.1888;0.1145;0.0880,"[np.int64(-1), -1, -1, -1, -1]",66;-1;-1;-1;-1,66,66,Aerospace Visualizations
Vis,2021,MultiVision: Designing Analytical Dashboards with Deep Learning Based Recommendation,10.1109/tvcg.2021.3114826,http://dx.doi.org/10.1109/TVCG.2021.3114826,162.0,172.0,J,"We contribute a deep-learning-based method that assists in designing analytical dashboards for analyzing a data table. Given a data table, data workers usually need to experience a tedious and time-consuming process to select meaningful combinations of data columns for creating charts. This process is further complicated by the needs of creating dashboards composed of multiple views that unveil different perspectives of data. Existing automated approaches for recommending multiple-view visualizations mainly build on manually crafted design rules, producing sub-optimal or irrelevant suggestions. To address this gap, we present a deep learning approach for selecting data columns and recommending multiple charts. More importantly, we integrate the deep learning models into a mixed-initiative system. Our model could make recommendations given optional user-input selections of data columns. The model, in turn, learns from provenance data of authoring logs in an offline manner. We compare our deep learning model with existing methods for visualization recommendation and conduct a user study to evaluate the usefulness of the system.",Aoyu Wu;Yun Wang 0012;Mengyu Zhou;Xinyi He;Haidong Zhang;Huamin Qu;Dongmei Zhang 0001,Aoyu Wu;Yun Wang;Mengyu Zhou;Xinyi He;Haidong Zhang;Huamin Qu;Dongmei Zhang,"Hong Kong University of Science and Technology, Hong Kong and Microsoft Research Area, United States;Microsoft Research Area, United States;Microsoft Research Area, United States;Microsoft Research Area, United States;Microsoft Research Area, United States;Hong Kong University of Science and Technology, Hong Kong;Microsoft Research Area, United States",10.1109/tvcg.2020.3030338;10.1109/tvcg.2019.2934810;10.1109/tvcg.2019.2934332;10.1109/tvcg.2018.2865138;10.1109/tvcg.2013.119;10.1109/tvcg.2016.2598620;10.1109/tvcg.2017.2744019;10.1109/tvcg.2018.2865235;10.1109/tvcg.2007.70594;10.1109/tvcg.2020.3030430;10.1109/tvcg.2018.2865240;10.1109/tvcg.2020.3030387;10.1109/tvcg.2017.2744198;10.1109/tvcg.2014.2346291;10.1109/tvcg.2018.2865158;10.1109/tvcg.2018.2864903;10.1109/tvcg.2016.2599030;10.1109/tvcg.2020.3030403;10.1109/tvcg.2020.3030396;10.1109/tvcg.2018.2865145;10.1109/tvcg.2017.2744843;10.1109/tvcg.2019.2934798;10.1109/tvcg.2019.2934398;10.1109/tvcg.2015.2467191;10.1109/tvcg.2020.3030423,"Visualization Recommendation,Deep Learning,Multiple-View,Dashboard,Mixed-Initiative,Visualization Provenance",14.0,31.0,73.0,1788.0,,,dashboards analyzing data;present deep learning;select meaningful combinations;manually crafted;irrelevant,0.5685;0.3128;0.2108;0.1375;0.0307,"[np.int64(-1), -1, -1, -1, -1]",108;-1;-1;-1;-1,108,108,Visual Analytics
Vis,2001,Chromatin decondensation: case study of tracking features in confocal data,10.1109/visual.2001.964546,http://dx.doi.org/10.1109/VISUAL.2001.964546,441.0,444.0,C,"In this case study we discuss an interactive feature tracking system and its use for the analysis of chromatin decondensation. Features are described as points in a multidimensional attribute space. Distances between points are used as a measure for feature correspondence. Users can interactively experiment with the correspondence measure in order to gain insight in chromatin movement. In addition, by defining time as an attribute, tracking problems related to noisy confocal data can be circumvented.",Wim C. de Leeuw;Robert van Liere,W. de Leeuw;R. van Liere,"Center of Mathematics and Computer Science, Amsterdam, Netherlands;Center of Mathematics and Computer Science, Amsterdam, Netherlands",10.1109/visual.2000.885735,"feature tracking, multidimensional visualization, biomedical imaging",13.0,3.0,8.0,63.0,,,insight chromatin movement;measure feature correspondence;users interactively;noisy confocal;addition defining time,0.6764;0.3660;0.2113;0.1903;0.0508,"[np.int64(-1), -1, -1, -1, -1]",23;-1;-1;-1;-1,23,23,Chromatin Visualization
InfoVis,2017,Skeleton-Based Scagnostics,10.1109/tvcg.2017.2744339,http://dx.doi.org/10.1109/TVCG.2017.2744339,542.0,552.0,J,"Scatterplot matrices (SPLOMs) are widely used for exploring multidimensional data. Scatterplot diagnostics (scagnostics) approaches measure characteristics of scatterplots to automatically find potentially interesting plots, thereby making SPLOMs more scalable with the dimension count. While statistical measures such as regression lines can capture orientation, and graph-theoretic scagnostics measures can capture shape, there is no scatterplot characterization measure that uses both descriptors. Based on well-known results in shape analysis, we propose a scagnostics approach that captures both scatterplot shape and orientation using skeletons (or medial axes). Our representation can handle complex spatial distributions, helps discovery of principal trends in a multiscale way, scales visually well with the number of samples, is robust to noise, and is automatic and fast to compute. We define skeleton-based similarity metrics for the visual exploration and analysis of SPLOMs. We perform a user study to measure the human perception of scatterplot similarity and compare the outcome to our results as well as to graph-based scagnostics and other visual quality metrics. Our skeleton-based metrics outperform previously defined measures both in terms of closeness to perceptually-based similarity and computation time efficiency.",José Matute;Alexandru C. Telea;Lars Linsen,José Matute;Alexandru C. Telea;Lars Linsen,"Institute of Computer Science, University of Münster, Germany;Johann Bernoulli Institute for Mathematics and Computer Science, University of Groningen, Groningen, The Netherlands;Institute of Computer Science, University of Münster, Germany",10.1109/vast.2011.6102437;10.1109/tvcg.2011.233;10.1109/tvcg.2010.213;10.1109/tvcg.2011.223;10.1109/tvcg.2011.220;10.1109/vast.2008.4677367;10.1109/vast.2009.5332628;10.1109/vast.2011.6102437,"Multidimensional Data (primary keyword),High-Dimensional Data",30.0,22.0,65.0,729.0,,,perception scatterplot similarity;define skeleton;sploms widely used;representation handle complex;perform,0.6837;0.2581;0.2043;0.1282;0.0343,"[np.int64(-1), -1, -1, -1, -1]",130;-1;-1;-1;-1,130,130,Visual Perception Analysis
Vis,1997,Two-phase perspective ray casting for interactive volume navigation,10.1109/visual.1997.663878,http://dx.doi.org/10.1109/VISUAL.1997.663878,183.0,189.0,C,"Volume navigation is the interactive exploration of volume data sets by ""flying"" the view point through the data, producing a volume rendered view at each frame. The authors present an inexpensive perspective volume navigation method designed to run on a PC platform with accelerated 3D graphics hardware. They compute perspective projections at each frame, allow trilinear interpolation of sample points, and render both gray scale and RGB volumes by volumetric compositing. The implementation handles arbitrarily large volumes, by dynamically swapping data within the local depth-limited frustum into main memory as the viewpoint moves through the volume. They describe a new ray casting algorithm that takes advantage of the coherence inherent in adjacent frames to generate a sequence of approximate animated frames much faster than they could be computed individually. They also take advantage of the 3D graphics acceleration hardware to offload much of the alpha blending and resampling from the CPU.",Martin L. Brady;Kenneth K. Jung;H. T. Nguyen;Thinh P. Q. Nguyen,M. Brady;K. Jung;H.T. Nguyen;T. Nguyen,"Microcomputer Research Laboratories, Intel Corporation, USA;Microcomputer Research Laboratories, Intel Corporation, USA;;Microcomputer Research Laboratories, Intel Corporation, USA",10.1109/visual.1994.346340;10.1109/visual.1995.485154;10.1109/visual.1996.567603;10.1109/visual.1994.346340,"Volume navigation, volume rendering, 3D medical imaging, scientific visualization, texture mapping",67.0,9.0,18.0,130.0,,,volumetric compositing implementation;animated frames;faster;limited frustum main;data local,0.6213;0.3354;0.1005;0.0993;0.0544,"[np.int64(-1), -1, -1, -1, -1]",52;-1;-1;-1;-1,52,52,Volume Rendering Techniques
Vis,2005,Particle and texture based spatiotemporal visualization of time-dependent vector fields,10.1109/visual.2005.1532852,http://dx.doi.org/10.1109/VISUAL.2005.1532852,639.0,646.0,C,"We propose a hybrid particle and texture based approach for the visualization of time-dependent vector fields. The underlying space-time framework builds a dense vector field representation in a two-step process: 1) particle-based forward integration of trajectories in spacetime for temporal coherence, and 2) texture-based convolution along another set of paths through the spacetime for spatially correlated patterns. Particle density is controlled by stochastically injecting and removing particles, taking into account the divergence of the vector field. Alternatively, a uniform density can be maintained by placing exactly one particle in each cell of a uniform grid, which leads to particle-in-cell forward advection. Moreover, we discuss strategies of previous visualization methods for unsteady flow and show how they address issues of spatiotemporal coherence and dense visual representations. We demonstrate how our framework is capable of realizing several of these strategies. Finally, we present an efficient GPU implementation that facilitates an interactive visualization of unsteady 2D flow on Shader Model 3 compliant graphics hardware.",Daniel Weiskopf;Frederik Schramm;Gordon Erlebacher;Thomas Ertl,D. Weiskopf;F. Schramm;G. Erlebacher;T. Ertl,"Institute of Visualization and Interactive Systems, University of Stuttgart, Germany and Graphics, Usability and Visualization (GrUVi) Laboratory, Simon Fraser University, Canada;Institute of Visualization and Interactive Systems, University of Stuttgart, Germany;School of Computational Science and Information Technology, Florida State University, USA;Institute of Visualization and Interactive Systems, University of Stuttgart, Germany",10.1109/visual.2003.1250377;10.1109/visual.2003.1250363;10.1109/visual.2003.1250361;10.1109/visual.2000.885689;10.1109/visual.2003.1250402;10.1109/visual.2003.1250364;10.1109/visual.2003.1250377,"Unsteady flow visualization, visualization framework, LIC, texture advection, particle systems, GPU methods",36.0,7.0,31.0,259.0,,,particle texture based;visualization unsteady;spacetime temporal coherence;gpu implementation facilitates;account divergence,0.5397;0.3726;0.3573;0.3134;0.1209,"[np.int64(-1), -1, -1, -1, -1]",20;-1;-1;-1;-1,20,20,Particle Flow Analysis
Vis,2023,Let the Chart Spark: Embedding Semantic Context into Chart with Text-to-Image Generative Model,10.1109/tvcg.2023.3326913,http://dx.doi.org/10.1109/TVCG.2023.3326913,284.0,294.0,J,"Pictorial visualization seamlessly integrates data and semantic context into visual representation, conveying complex information in an engaging and informative manner. Extensive studies have been devoted to developing authoring tools to simplify the creation of pictorial visualizations. However, mainstream works follow a retrieving-and-editing pipeline that heavily relies on retrieved visual elements from a dedicated corpus, which often compromise data integrity. Text-guided generation methods are emerging, but may have limited applicability due to their predefined entities. In this work, we propose ChartSpark, a novel system that embeds semantic context into chart based on text-to-image generative models. ChartSpark generates pictorial visualizations conditioned on both semantic context conveyed in textual inputs and data information embedded in plain charts. The method is generic for both foreground and background pictorial generation, satisfying the design practices identified from empirical research into existing pictorial visualizations. We further develop an interactive visual interface that integrates a text analyzer, editing module, and evaluation module to enable users to generate, modify, and assess pictorial visualizations. We experimentally demonstrate the usability of our tool, and conclude with a discussion of the potential of using text-to-image generative models combined with an interactive interface for visualization design.",Shishi Xiao;Suizi Huang;Yue Lin;Yilin Ye;Wei Zeng 0004,Shishi Xiao;Suizi Huang;Yue Lin;Yilin Ye;Wei Zeng,"Hong Kong University of Science and Technology (Guangzhou), Guangzhou, China;Hong Kong University of Science and Technology (Guangzhou), Guangzhou, China;Hong Kong University of Science and Technology (Guangzhou), Guangzhou, China;Hong Kong University of Science and Technology (Guangzhou), Guangzhou, China;Hong Kong University of Science and Technology (Guangzhou), Guangzhou, China",0.1109/tvcg.2012.197;10.1109/tvcg.2015.2467732;10.1109/tvcg.2013.234;10.1109/tvcg.2019.2934810;10.1109/tvcg.2019.2934785;10.1109/tvcg.2011.175;10.1109/tvcg.2016.2598620;10.1109/tvcg.2012.221;10.1109/tvcg.2020.3030448;10.1109/tvcg.2022.3209486;10.1109/tvcg.2022.3209357;10.1109/tvcg.2019.2934398;10.1109/tvcg.2022.3209447,"pictorial visualization,generative model,authoring tool",,5.0,61.0,1226.0,,,generates pictorial visualizations;data semantic context;editing module evaluation;dedicated corpus compromise;simplify,0.6739;0.3490;0.1645;0.1555;0.0430,"[np.int64(-1), -1, -1, -1, -1]",146;-1;-1;-1;-1,146,146,Visualization Techniques
VAST,2011,How locus of control influences compatibility with visualization style,10.1109/vast.2011.6102445,http://dx.doi.org/10.1109/VAST.2011.6102445,81.0,90.0,C,"Existing research suggests that individual personality differences are correlated with a user's speed and accuracy in solving problems with different types of complex visualization systems. In this paper, we extend this research by isolating factors in personality traits as well as in the visualizations that could have contributed to the observed correlation. We focus on a personality trait known as “locus of control,” which represents a person's tendency to see themselves as controlled by or in control of external events. To isolate variables of the visualization design, we control extraneous factors such as color, interaction, and labeling, and specifically focus on the overall layout style of the visualizations. We conduct a user study with four visualizations that gradually shift from an indentation metaphor to a containment metaphor and compare the participants' speed, accuracy, and preference with their locus of control. Our findings demonstrate that there is indeed a correlation between the two: participants with an internal locus of control perform more poorly with visualizations that employ a containment metaphor, while those with an external locus of control perform well with such visualizations. We discuss a possible explanation for this relationship based in cognitive psychology and propose that these results can be used to better understand how people use visualizations and how to adapt visual analytics design to an individual user's needs.",Caroline Ziemkiewicz;R. Jordan Crouser;Ashley Rye Yauilla;Sara L. Su;William Ribarsky;Remco Chang,Caroline Ziemkiewicz;R. Jordan Crouser;Ashley Rye Yauilla;Sara L. Su;William Ribarsky;Remco Chang,"Brown University, USA;Tufts University, USA;Winthrop University, USA;Tufts University, USA;UNC-Charlotte, USA;Tufts University, USA",10.1109/vast.2010.5653587;10.1109/tvcg.2008.171;10.1109/tvcg.2008.121;10.1109/vast.2010.5653587,,70.0,40.0,31.0,509.0,HM,,user study visualizations;personality trait;indentation metaphor;speed accuracy solving;control extraneous,0.6874;0.2593;0.2516;0.1096;0.0234,"[np.int64(-1), -1, -1, -1, -1]",137;-1;-1;-1;-1,137,137,Visualization Research Studies
Vis,1999,Visual debugging of visualization software: a case study for particle systems,10.1109/visual.1999.809919,http://dx.doi.org/10.1109/VISUAL.1999.809919,417.0,554.0,C,"Visualization systems are complex dynamic software systems. Debugging such systems is difficult using conventional debuggers because the programmer must try to imagine the three-dimensional geometry based on a list of positions and attributes. In addition, the programmer must be able to mentally animate changes in those positions and attributes to grasp dynamic behaviors within the algorithm. We show that representing geometry, attributes, and relationships graphically permits visual pattern recognition skills to be applied to the debugging problem. The particular application is a particle system used for isosurface extraction from volumetric data. Coloring particles based on individual attributes is especially helpful when these colorings are viewed as animations over successive iterations in the program. Although we describe a particular application, the types of tools that we discuss can be applied to a variety of problems.",Patricia Crossno;Edward Angel,P. Crossno;E. Angel,"Sandia National Laboratories, USA;University of New Mexico, USA",10.1109/visual.1996.568120;10.1109/visual.1997.663930;10.1109/visual.1996.568120,,17.0,7.0,17.0,111.0,,,visualization systems;using conventional debuggers;particle used isosurface;animate changes positions;able,0.5637;0.3595;0.2617;0.1512;-0.0170,"[np.int64(-1), -1, -1, -1, -1]",109;-1;-1;-1;-1,109,109,Visualization Technologies
Vis,2023,ExTreeM: Scalable Augmented Merge Tree Computation via Extremum Graphs,10.1109/tvcg.2023.3326526,http://dx.doi.org/10.1109/TVCG.2023.3326526,1085.0,1094.0,J,"Over the last decade merge trees have been proven to support a plethora of visualization and analysis tasks since they effectively abstract complex datasets. This paper describes the ExTreeM-Algorithm: A scalable algorithm for the computation of merge trees via extremum graphs. The core idea of ExTreeM is to first derive the extremum graph $\mathcal{G}$ of an input scalar field $f$ defined on a cell complex $\mathcal{K}$, and subsequently compute the unaugmented merge tree of $f$ on $\mathcal{G}$ instead of $\mathcal{K}$; which are equivalent. Any merge tree algorithm can be carried out significantly faster on $\mathcal{G}$, since $\mathcal{K}$ in general contains substantially more cells than $\mathcal{G}$. To further speed up computation, ExTreeM includes a tailored procedure to derive merge trees of extremum graphs. The computation of the fully augmented merge tree, i.e., a merge tree domain segmentation of $\mathcal{K}$, can then be performed in an optional post-processing step. All steps of ExTreeM consist of procedures with high parallel efficiency, and we provide a formal proof of its correctness. Our experiments, performed on publicly available datasets, report a speedup of up to one order of magnitude over the state-of-the-art algorithms included in the TTK and VTK-m software libraries, while also requiring significantly less memory and exhibiting excellent scaling behavior.",Jonas Lukasczyk;Michael Will;Florian Wetzels;Gunther H. Weber;Christoph Garth,Jonas Lukasczyk;Michael Will;Florian Wetzels;Gunther H. Weber;Christoph Garth,"RPTU Kaiserslautern-Landau, Germany;RPTU Kaiserslautern-Landau, Germany;RPTU Kaiserslautern-Landau, Germany;Lawrence Berkeley National Lab., USA;RPTU Kaiserslautern-Landau, Germany",0.1109/tvcg.2019.2934257;10.1109/tvcg.2017.2743938,"Scalar field topology,merge trees,persistence pairs,high performance computing",,0.0,41.0,334.0,,,computation merge trees;domain segmentation;extremum graph;contains substantially cells;scalar field,0.6246;0.3878;0.3239;0.1739;0.1321,"[np.int64(-1), -1, -1, -1, -1]",9;-1;-1;-1;-1,9,9,Tree Visualization Techniques
InfoVis,2012,PivotPaths: Strolling through Faceted Information Spaces,10.1109/tvcg.2012.252,http://dx.doi.org/10.1109/TVCG.2012.252,2709.0,2718.0,J,"We present PivotPaths, an interactive visualization for exploring faceted information resources. During both work and leisure, we increasingly interact with information spaces that contain multiple facets and relations, such as authors, keywords, and citations of academic publications, or actors and genres of movies. To navigate these interlinked resources today, one typically selects items from facet lists resulting in abrupt changes from one subset of data to another. While filtering is useful to retrieve results matching specific criteria, it can be difficult to see how facets and items relate and to comprehend the effect of filter operations. In contrast, the PivotPaths interface exposes faceted relations as visual paths in arrangements that invite the viewer to `take a stroll' through an information space. PivotPaths supports pivot operations as lightweight interaction techniques that trigger gradual transitions between views. We designed the interface to allow for casual traversal of large collections in an aesthetically pleasing manner that encourages exploration and serendipitous discoveries. This paper shares the findings from our iterative design-and-evaluation process that included semi-structured interviews and a two-week deployment of PivotPaths applied to a large database of academic publications.",Marian Dörk;Nathalie Henry Riche;Gonzalo A. Ramos;Susan T. Dumais,Marian Dörk;Nathalie Henry Riche;Gonzalo Ramos;Susan Dumais,"University of Calgary, Canada;Microsoft, USA;Microsoft, USA;Microsoft, USA",10.1109/vast.2009.5333443;10.1109/tvcg.2010.154;10.1109/vast.2006.261426;10.1109/vast.2007.4389006;10.1109/vast.2008.4677370;10.1109/tvcg.2007.70539;10.1109/tvcg.2008.175;10.1109/tvcg.2009.108;10.1109/vast.2009.5333443,"Information visualization, interactivity, node-link diagrams, animation, information seeking, exploratory search",217.0,126.0,24.0,1637.0,,,exploring faceted information;lightweight interaction techniques;pivotpaths applied large;work leisure increasingly;invite,0.6254;0.2994;0.2773;0.1799;-0.1157,"[np.int64(-1), -1, -1, -1, -1]",146;-1;-1;-1;-1,146,146,Visualization Techniques
Vis,2023,Average Estimates in Line Graphs Are Biased Toward Areas of Higher Variability,10.1109/tvcg.2023.3326589,http://dx.doi.org/10.1109/TVCG.2023.3326589,306.0,315.0,J,"We investigate variability overweighting, a previously undocumented bias in line graphs, where estimates of average value are biased toward areas of higher variability in that line. We found this effect across two preregistered experiments with 140 and 420 participants. These experiments also show that the bias is reduced when using a dot encoding of the same series. We can model the bias with the average of the data series and the average of the points drawn along the line. This bias might arise because higher variability leads to stronger weighting in the average calculation, either due to the longer line segments (even though those segments contain the same number of data values) or line segments with higher variability being otherwise more visually salient. Understanding and predicting this bias is important for visualization design guidelines, recommendation systems, and tool builders, as the bias can adversely affect estimates of averages and trends.",Dominik Moritz;Lace M. K. Padilla;Francis Nguyen;Steven L. Franconeri,Dominik Moritz;Lace M. Padilla;Francis Nguyen;Steven L. Franconeri,"Carnegie Mellon University, USA;Northeastern University, USA;Northwestern University, USA;UBC, Canada",0.1109/infvis.2005.1532136;10.1109/tvcg.2018.2865077;10.1109/tvcg.2009.131;10.1109/tvcg.2021.3114783;10.1109/tvcg.2010.162;10.1109/tvcg.2021.3114684;10.1109/tvcg.2019.2934784;10.1109/tvcg.2019.2934400;10.1109/tvcg.2021.3114865,"bias,lines graph,ensemble perception,average",,2.0,34.0,440.0,HM,,bias important visualization;series average;using dot encoding;systems tool builders;longer,0.5901;0.3591;0.0936;0.0786;0.0677,"[np.int64(-1), -1, -1, -1, -1]",135;-1;-1;-1;-1,135,135,Comparative Visualization Bias
Vis,2024,Motion-Based Visual Encoding Can Improve Performance on Perceptual Tasks with Dynamic Time Series,10.1109/tvcg.2024.3456405,http://dx.doi.org/10.1109/TVCG.2024.3456405,163.0,173.0,J,"Dynamic data visualizations can convey large amounts of information over time, such as using motion to depict changes in data values for multiple entities. Such dynamic displays put a demand on our visual processing capacities, yet our perception of motion is limited. Several techniques have been shown to improve the processing of dynamic displays. Staging the animation to sequentially show steps in a transition and tracing object movement by displaying trajectory histories can improve processing by reducing the cognitive load. In this paper, We examine the effectiveness of staging and tracing in dynamic displays. We showed participants animated line charts depicting the movements of lines and asked them to identify the line with the highest mean and variance. We manipulated the animation to display the lines with or without staging, tracing and history, and compared the results to a static chart as a control. Results showed that tracing and staging are preferred by participants, and improve their performance in mean and variance tasks respectively. They also preferred display time 3 times shorter when staging is used. Also, encoding animation speed with mean and variance in congruent tasks is associated with higher accuracy. These findings help inform real-world best practices for building dynamic displays. The supplementary materials can be found at https://osf.io/8c95v/",Songwen Hu;Ouxun Jiang;Jeffrey Riedmiller;Cindy Xiong Bearfield,Songwen Hu;Ouxun Jiang;Jeffrey Riedmiller;Cindy Xiong Bearfield,"Georgia Tech., USA;Northwestern University, USA;Dolby Laboratories, USA;Georgia Tech., USA",10.1109/infvis.1999.801854;10.1109/tvcg.2019.2934397;10.1109/tvcg.2019.2934288;10.1109/tvcg.2014.2346424;10.1109/vast.2012.6400552;10.1109/tvcg.2020.3029413;10.1109/tvcg.2007.70539;10.1109/tvcg.2018.2864909;10.1109/tvcg.2013.191;10.1109/tvcg.2018.2865193;10.1109/tvcg.2008.125;10.1109/tvcg.2018.2865147;10.1109/tvcg.2020.3030418;10.1109/infvis.2001.963279;10.1109/tvcg.2022.3209369,"Animation,Dynamic Displays,,,Perception,Motion,Analytic Tasks",,0.0,56.0,130.0,,,animated line charts;processing reducing cognitive;tracing staging preferred;highest mean variance;materials https,0.6243;0.3407;0.1860;0.0798;0.0170,"[np.int64(-1), -1, -1, -1, -1]",53;-1;-1;-1;-1,53,53,Dynamic Data Visualizations
Vis,2024,Defogger: A Visual Analysis Approach for Data Exploration of Sensitive Data Protected by Differential Privacy,10.1109/tvcg.2024.3456304,http://dx.doi.org/10.1109/TVCG.2024.3456304,448.0,458.0,J,"Differential privacy ensures the security of individual privacy but poses challenges to data exploration processes because the limited privacy budget incapacitates the flexibility of exploration and the noisy feedback of data requests leads to confusing uncertainty. In this study, we take the lead in describing corresponding exploration scenarios, including underlying requirements and available exploration strategies. To facilitate practical applications, we propose a visual analysis approach to the formulation of exploration strategies. Our approach applies a reinforcement learning model to provide diverse suggestions for exploration strategies according to the exploration intent of users. A novel visual design for representing uncertainty in correlation patterns is integrated into our prototype system to support the proposed approach. Finally, we implemented a user study and two case studies. The results of these studies verified that our approach can help develop strategies that satisfy the exploration intent of users.",Xumeng Wang;Shuangcheng Jiao;Chris Bryan,Xumeng Wang;Shuangcheng Jiao;Chris Bryan,"DISSec, Nankai University, China;DISSec, Nankai University, China;SCAI, Arizona State University, USA",10.1109/tvcg.2018.2865040;10.1109/tvcg.2013.124;10.1109/tvcg.2015.2467199;10.1109/tvcg.2017.2743959;10.1109/tvcg.2018.2864889;10.1109/tvcg.2023.3327195;10.1109/tvcg.2018.2865027;10.1109/tvcg.2023.3326929;10.1109/tvcg.2009.114;10.1109/vast50239.2020.00006;10.1109/tvcg.2017.2745139;10.1109/tvcg.2015.2467191;10.1109/tvcg.2020.3030369;10.1109/tvcg.2022.3209391,"Differential privacy,Visual data analysis,,,Data exploration,Visualization for uncertainty illustration",,0.0,44.0,176.0,,,data exploration;privacy budget incapacitates;representing uncertainty correlation;intent users novel;available,0.6115;0.4134;0.2617;0.2232;-0.0658,"[np.int64(-1), -1, -1, -1, -1]",146;-1;-1;-1;-1,146,146,Visualization Techniques
Vis,2024,SimpleSets: Capturing Categorical Point Patterns with Simple Shapes,10.1109/tvcg.2024.3456168,http://dx.doi.org/10.1109/TVCG.2024.3456168,262.0,271.0,J,"Points of interest on a map such as restaurants, hotels, or subway stations, give rise to categorical point data: data that have a fixed location and one or more categorical attributes. Consequently, recent years have seen various set visualization approaches that visually connect points of the same category to support users in understanding the spatial distribution of categories. Existing methods use complex and often highly irregular shapes to connect points of the same category, leading to high cognitive load for the user. In this paper we introduce SimpleSets, which uses simple shapes to enclose categorical point patterns, thereby providing a clean overview of the data distribution. SimpleSets is designed to visualize sets of points with a single categorical attribute; as a result, the point patterns enclosed by SimpleSets form a partition of the data. We give formal definitions of point patterns that correspond to simple shapes and describe an algorithm that partitions categorical points into few such patterns. Our second contribution is a rendering algorithm that transforms a given partition into a clean set of shapes resulting in an aesthetically pleasing set visualization. Our algorithm pays particular attention to resolving intersections between nearby shapes in a consistent manner. We compare SimpleSets to the state-of-the-art set visualizations using standard datasets from the literature.",Steven van den Broek;Wouter Meulemans;Bettina Speckmann,Steven van den Broek;Wouter Meulemans;Bettina Speckmann,"TU Eindhoven, the Netherlands;TU Eindhoven, the Netherlands;TU Eindhoven, the Netherlands",10.1109/tvcg.2011.186;10.1109/tvcg.2009.122;10.1109/infvis.2005.1532126;10.1109/tvcg.2010.210;10.1109/tvcg.2006.122;10.1109/tvcg.2021.3114761,"Set visualization,geographic visualization,,,algorithms",,0.0,32.0,156.0,,X,pleasing set visualization;map restaurants;category support users;irregular;definitions,0.6297;0.4239;0.1491;0.1442;0.0990,"[np.int64(-1), -1, -1, -1, -1]",92;-1;-1;-1;-1,92,92,Set Visualization
Vis,2011,Visualization of AMR Data With Multi-Level Dual-Mesh Interpolation,10.1109/tvcg.2011.252,http://dx.doi.org/10.1109/TVCG.2011.252,1862.0,1871.0,J,"We present a new technique for providing interpolation within cell-centered Adaptive Mesh Refinement (AMR) data that achieves C&lt;sup&gt;0&lt;/sup&gt; continuity throughout the 3D domain. Our technique improves on earlier work in that it does not require that adjacent patches differ by at most one refinement level. Our approach takes the dual of each mesh patch and generates ""stitching cells"" on the fly to fill the gaps between dual meshes. We demonstrate applications of our technique with data from Enzo, an AMR cosmological structure formation simulation code. We show ray-cast visualizations that include contributions from particle data (dark matter and stars, also output by Enzo) and gridded hydrodynamic data. We also show results from isosurface studies, including surfaces in regions where adjacent patches differ by more than one refinement level.",Patrick J. Moran;David A. Ellsworth,Patrick Moran;David Ellsworth,"NASA Ames Research Center, USA;Computer Sciences Corporation, NASA Ames, USA",10.1109/visual.1991.175782;10.1109/tvcg.2009.149;10.1109/visual.2002.1183820;10.1109/visual.1991.175782,"Adaptive mesh refinement, AMR, Enzo, interpolation, ray casting, isosurfaces, dual meshes, stitching cells",17.0,14.0,22.0,576.0,,,adaptive mesh refinement;amr cosmological;cast visualizations include;gaps;cell centered,0.6673;0.3243;0.2032;0.1550;0.1151,"[np.int64(-1), -1, -1, -1, -1]",78;-1;-1;-1;-1,78,78,Mesh Refinement Techniques
Vis,2024,Curio: A Dataflow-Based Framework for Collaborative Urban Visual Analytics,10.1109/tvcg.2024.3456353,http://dx.doi.org/10.1109/TVCG.2024.3456353,1224.0,1234.0,J,"Over the past decade, several urban visual analytics systems and tools have been proposed to tackle a host of challenges faced by cities, in areas as diverse as transportation, weather, and real estate. Many of these tools have been designed through collaborations with urban experts, aiming to distill intricate urban analysis workflows into interactive visualizations and interfaces. However, the design, implementation, and practical use of these tools still rely on siloed approaches, resulting in bespoke systems that are difficult to reproduce and extend. At the design level, these tools undervalue rich data workflows from urban experts, typically treating them only as data providers and evaluators. At the implementation level, they lack interoperability with other technical frameworks. At the practical use level, they tend to be narrowly focused on specific fields, inadvertently creating barriers to cross-domain collaboration. To address these gaps, we present Curio, a framework for collaborative urban visual analytics. Curio uses a dataflow model with multiple abstraction levels (code, grammar, GUI elements) to facilitate collaboration across the design and implementation of visual analytics components. The framework allows experts to intertwine data preprocessing, management, and visualization stages while tracking the provenance of code and visualizations. In collaboration with urban experts, we evaluate Curio through a diverse set of usage scenarios targeting urban accessibility, urban microclimate, and sunlight access. These scenarios use different types of data and domain methodologies to illustrate Curio's flexibility in tackling pressing societal challenges. Curio is available at urbantk.org/curio.",Gustavo Moreira;Maryam Hosseini;Carolina Veiga Ferreira de Souza;Lucas Alexandre;Nicola Colaninno;Daniel de Oliveira 0001;Nivan Ferreira;Marcos Lage;Fabio Miranda 0001,Gustavo Moreira;Maryam Hosseini;Carolina Veiga;Lucas Alexandre;Nicola Colaninno;Daniel de Oliveira;Nivan Ferreira;Marcos Lage;Fabio Miranda,"University of Illinois, USA;University of California, Berkeley, and the Massachusetts Institute of Technology, USA;University of Illinois Urbana-Champaign, USA;Universidade Federal Fluminense, Brazil;Politecnico di Milano, Italy;Universidade Federal Fluminense, Brazil;Universidade Federal de Pernambuco, Brazil;Universidade Federal Fluminense, Brazil;University of Illinois, USA",10.1109/tvcg.2018.2865040;10.1109/tvcg.2017.2743990;10.1109/visual.2005.1532788;10.1109/tvcg.2019.2934670;10.1109/vast.2015.7347636;10.1109/tvcg.2013.226;10.1109/tvcg.2021.3114876;10.1109/tvcg.2016.2598585;10.1109/tvcg.2023.3326598;10.1109/tvcg.2022.3209474;10.1109/tvcg.2016.2599030;10.1109/tvcg.2017.2743938;10.1109/tvcg.2022.3209360;10.1109/tvcg.2016.2598497,"Urban analytics,urban data,,,spatial data,dataflow,provenance,visualization framework,visualization system",,0.0,75.0,171.0,,,urban visual analytics;bespoke systems difficult;microclimate sunlight;curio flexibility tackling;specific fields inadvertently,0.7834;0.1591;0.1220;0.0119;-0.0103,"[np.int64(-1), -1, -1, -1, -1]",89;-1;-1;-1;-1,89,89,Geographical Visualization
Vis,2022,MosaicSets: Embedding Set Systems into Grid Graphs,10.1109/tvcg.2022.3209485,http://dx.doi.org/10.1109/TVCG.2022.3209485,875.0,885.0,J,"Visualizing sets of elements and their relations is an important research area in information visualization. In this paper, we present MosaicSets: a novel approach to create Euler-like diagrams from non-spatial set systems such that each element occupies one cell of a regular hexagonal or square grid. The main challenge is to find an assignment of the elements to the grid cells such that each set constitutes a contiguous region. As use case, we consider the research groups of a university faculty as elements, and the departments and joint research projects as sets. We aim at finding a suitable mapping between the research groups and the grid cells such that the department structure forms a base map layout. Our objectives are to optimize both the compactness of the entirety of all cells and of each set by itself. We show that computing the mapping is NP-hard. However, using integer linear programming we can solve real-world instances optimally within a few seconds. Moreover, we propose a relaxation of the contiguity requirement to visualize otherwise non-embeddable set systems. We present and discuss different rendering styles for the set overlays. Based on a case study with real-world data, our evaluation comprises quantitative measures as well as expert interviews.",Peter Rottmann;Markus Wallinger;Annika Bonerath;Sven Gedicke;Martin Nöllenburg;Jan-Henrik Haunert,Peter Rottmann;Markus Wallinger;Annika Bonerath;Sven Gedicke;Martin Nöllenburg;Jan-Henrik Haunert,"Geoinformation Group of the University of Bonn, Germany;Algorithms and Complexity Group of the Technical University of Vienna, Austria;Geoinformation Group of the University of Bonn, Germany;Geoinformation Group of the University of Bonn, Germany;Algorithms and Complexity Group of the Technical University of Vienna, Austria;Geoinformation Group of the University of Bonn, Germany",10.1109/tvcg.2011.186;10.1109/tvcg.2009.122;10.1109/tvcg.2020.3030475;10.1109/tvcg.2021.3114834;10.1109/tvcg.2014.2346248;10.1109/tvcg.2016.2598542;10.1109/tvcg.2020.3028953;10.1109/tvcg.2012.199;10.1109/tvcg.2010.210;10.1109/tvcg.2014.2346249;10.1109/tvcg.2008.165;10.1109/tvcg.2011.186,"Set Visualization,Euler Diagram,Integer Linear Programming,Hypergraph",,4.0,66.0,504.0,,,visualizing sets;layout objectives optimize;base map;groups university faculty;integer linear,0.6362;0.3083;0.2748;0.2368;0.0502,"[np.int64(-1), -1, -1, -1, -1]",92;-1;-1;-1;-1,92,92,Set Visualization
VAST,2016,Supporting visual exploration for multiple users in large display environments,10.1109/vast.2016.7883506,http://dx.doi.org/10.1109/VAST.2016.7883506,1.0,10.0,C,"We present a design space exploration of interaction techniques for supporting multiple collaborators exploring data on a shared large display. Our proposed solution is based on users controlling individual lenses using both explicit gestures as well as proxemics: the spatial relations between people and physical artifacts such as their distance, orientation, and movement. We discuss different design considerations for implicit and explicit interactions through the lens, and evaluate the user experience to find a balance between the implicit and explicit interaction styles. Our findings indicate that users favor implicit interaction through proxemics for navigation and collaboration, but prefer using explicit mid-air gestures to perform actions that are perceived to be direct, such as terminating a lens composition. Based on these results, we propose a hybrid technique utilizing both proxemics and mid-air gestures, along with examples applying this technique to other datasets. Finally, we performed a usability evaluation of the hybrid technique and observed user performance improvements in the presence of both implicit and explicit interaction styles.",Sriram Karthik Badam;Fereshteh Amini;Niklas Elmqvist;Pourang Irani,Sriram Karthik Badam;Fereshteh Amini;Niklas Elmqvist;Pourang Irani,"University of Maryland, College Park, MD, USA;University of Manitoba, Winnipeg, MB, Canada;University of Maryland, College Park, MD, USA;University of Manitoba, Winnipeg, MB, Canada",10.1109/tvcg.2013.166;10.1109/tvcg.2009.162;10.1109/tvcg.2013.163;10.1109/tvcg.2011.185;10.1109/tvcg.2013.166,,34.0,27.0,41.0,885.0,,,interaction techniques supporting;distance orientation;terminating lens;proxemics mid air;shared large,0.6070;0.2646;0.1772;0.1621;0.1538,"[np.int64(-1), -1, -1, -1, -1]",34;-1;-1;-1;-1,34,34,Gesture Interaction Techniques
Vis,2024,Visual Support for the Loop Grafting Workflow on Proteins,10.1109/tvcg.2024.3456401,http://dx.doi.org/10.1109/TVCG.2024.3456401,580.0,590.0,J,"In understanding and redesigning the function of proteins in modern biochemistry, protein engineers are increasingly focusing on exploring regions in proteins called loops. Analyzing various characteristics of these regions helps the experts design the transfer of the desired function from one protein to another. This process is denoted as loop grafting. We designed a set of interactive visualizations that provide experts with visual support through all the loop grafting pipeline steps. The workflow is divided into several phases, reflecting the steps of the pipeline. Each phase is supported by a specific set of abstracted 2D visual representations of proteins and their loops that are interactively linked with the 3D View of proteins. By sequentially passing through the individual phases, the user shapes the list of loops that are potential candidates for loop grafting. Finally, the actual in-silico insertion of the loop candidates from one protein to the other is performed, and the results are visually presented to the user. In this way, the fully computational rational design of proteins and their loops results in newly designed protein structures that can be further assembled and tested through in-vitro experiments. We showcase the contribution of our visual support design on a real case scenario changing the enantiomer selectivity of the engineered enzyme. Moreover, we provide the readers with the experts' feedback.",Filip Opálený;Pavol Ulbrich;Joan Planas-Iglesias;Jan Byska;Jan Stourac;David Bednár;Katarína Furmanová;Barbora Kozlíková,Filip Opálený;Pavol Ulbrich;Joan Planas-Iglesias;Jan Byška;Jan Štourač;David Bednář;Katarína Furmanová;Barbora Kozlíková,"Department of Visual Computing, Faculty of Informatics, Masaryk University, Brno, Czech Republic;Department of Visual Computing, Faculty of Informatics, Masaryk University, Brno, Czech Republic;Department of Experimental Biology and RECETOX, Loschmidt Laboratories, Faculty of Science, Masaryk University, Brno, Czech Republic;Department of Visual Computing, Faculty of Informatics, Masaryk University, Brno, Czech Republic;Department of Experimental Biology and RECETOX, Loschmidt Laboratories, Faculty of Science, Masaryk University, Brno, Czech Republic;Department of Experimental Biology and RECETOX, Loschmidt Laboratories, Faculty of Science, Masaryk University, Brno, Czech Republic;Department of Visual Computing, Faculty of Informatics, Masaryk University, Brno, Czech Republic;Department of Visual Computing, Faculty of Informatics, Masaryk University, Brno, Czech Republic",10.1109/tvcg.2016.2598544;10.1109/tvcg.2009.111;10.1109/tvcg.2020.3030438;10.1109/tvcg.2012.213;10.1109/tvcg.2022.3209434,"Protein visualization,protein engineering,,,loop grafting,abstract views",,0.0,59.0,127.0,HM,,design proteins loops;interactive visualizations provide;grafting;actual;divided phases reflecting,0.6395;0.4680;0.2552;0.0055;-0.0389,"[np.int64(-1), -1, -1, -1, -1]",41;-1;-1;-1;-1,41,41,Protein Structure Design
Vis,1995,Interval set: a volume rendering technique generalizing isosurface extraction,10.1109/visual.1995.480789,http://dx.doi.org/10.1109/VISUAL.1995.480789,3.0,,C,"A scalar volume V={(x,f(x))|x/spl isin/R} is described by a function f(x) defined over some region R of the three dimensional space. The paper presents a simple technique for rendering interval sets of the form I/sub g/(a,b)={(x,f(x))|a/spl les/g(x)/spl les/b}, where a and b are either real numbers of infinities. We describe an algorithm for triangulating interval sets as /spl alpha/ shapes, which can be accurately and efficiently rendered as surfaces or semi transparent clouds. On the theoretical side, interval sets provide an unified approach to isosurface extraction and direct volume rendering. On the practical side, interval sets add flexibility to scalar volume visualization-we may choose to, for example, have an interactive, high quality display of the volume surrounding or ""inside"" an isosurface when such display for the entire volume is too expensive to produce.",Baining Guo,Baining Guo,"Department of Computer Science, University of Toronto, Toronto, ONT, Canada",,,57.0,8.0,22.0,100.0,,,volume visualization;infinities algorithm triangulating;approach isosurface extraction;theoretical interval sets;unified,0.6629;0.4109;0.4096;0.3593;0.0388,"[np.int64(-1), -1, -1, -1, -1]",54;-1;-1;-1;-1,54,54,Volume Visualization Techniques
Vis,2006,Feature Aligned Volume Manipulation for Illustration and Visualization,10.1109/tvcg.2006.144,http://dx.doi.org/10.1109/TVCG.2006.144,1069.0,1076.0,J,"In this paper we describe a GPU-based technique for creating illustrative visualization through interactive manipulation of volumetric models. It is partly inspired by medical illustrations, where it is common to depict cuts and deformation in order to provide a better understanding of anatomical and biological structures or surgical processes, and partly motivated by the need for a real-time solution that supports the specification and visualization of such illustrative manipulation. We propose two new feature aligned techniques, namely surface alignment and segment alignment, and compare them with the axis-aligned techniques which were reported in previous work on volume manipulation. We also present a mechanism for defining features using texture volumes, and methods for computing correct normals for the deformed volume in respect to different alignments. We describe a GPU-based implementation to achieve real-time performance of the techniques and a collection of manipulation operators including peelers, retractors, pliers and dilators which are adaptations of the metaphors and tools used in surgical procedures and medical illustrations. Our approach is directly applicable in medical and biological illustration, and we demonstrate how it works as an interactive tool for focus+context visualization, as well as a generic technique for volume graphics",Carlos D. Correa;Deborah Silver;Min Chen 0001,Carlos Correa;Deborah Silver;Min Chen,"Department of Electrical and Computer Engineering, State University of New Jersey, Rutgers, USA;Department of Electrical and Computer Engineering, State University of New Jersey, Rutgers, USA;Department of Computer Science, University of Wales, Swansea, UK",10.1109/visual.2003.1250400;10.1109/visual.2000.885694;10.1109/visual.2003.1250400,"Illustrative visualization, Illustrative manipulation, GPU computing, volume rendering, volume deformation, computerassisted medical illustration",125.0,61.0,25.0,708.0,,,interactive manipulation volumetric;paper gpu;common depict cuts;medical biological;different alignments,0.6684;0.3553;0.3234;0.1470;0.0573,"[np.int64(-1), -1, -1, -1, -1]",-1;-1;-1;-1;-1,,-1,Interactive 3D Visualization
Vis,1995,On enhancing the speed of splatting with indexing,10.1109/visual.1995.480797,http://dx.doi.org/10.1109/VISUAL.1995.480797,69.0,,C,"Splatting is an object space direct volume rendering algorithm that produces images of high quality, but is computationally expensive like many other volume rendering algorithms. The paper presents a new technique that enhances the speed of splatting without trading off image quality. This new method reduces rendering time by employing a simple indexing mechanism which allows to visit and splat only the voxels of interest. It is shown that this algorithm is suitable for the dynamic situation in which viewing parameters and opacity transfer functions change interactively. We report experimental results on several test data sets of useful site and complexity, and discuss the cost/benefit trade off of our method.",Insung Ihm;Rae Kyoung Lee,Insung Ihm;Rae Kyoung Lee,"Department of Computer Science, Sogang University, Seoul, South Korea;Department of Computer Science, Sogang University, Seoul, South Korea",10.1109/visual.1990.146377;10.1109/visual.1990.146377,,40.0,3.0,13.0,48.0,,,volume rendering algorithms;splat;indexing mechanism allows;change interactively;test data sets,0.7297;0.2959;0.1286;0.0515;0.0459,"[np.int64(-1), -1, -1, -1, -1]",52;-1;-1;-1;-1,52,52,Volume Rendering Techniques
Vis,1999,Visualizing gridded datasets with large number of missing values,10.1109/visual.1999.809916,http://dx.doi.org/10.1109/VISUAL.1999.809916,405.0,551.0,C,"Much of the research in scientific visualization has focused on complete sets of gridded data. The paper presents our experience dealing with gridded data sets with a large number of missing or invalid data, and some of our experiments in addressing the shortcomings of standard off-the-shelf visualization algorithms. In particular, we discuss the options in modifying known algorithms to adjust to the specifics of sparse datasets, and provide a new technique to smooth out the side-effects of the operations. We apply our findings to data acquired from NEXRAD (NEXt generation RADars) weather radars, which usually have no more than 3 to 4 percent of all possible cell points filled.",Suzana Djurcilov;Alex Pang,S. Djurcilov;A. Pang,"Computer Science Department, University of California, Santa Cruz, USA;Computer Science Department, University of California, Santa Cruz, USA",10.1109/visual.1996.568145;10.1109/visual.1996.568145,,23.0,11.0,12.0,91.0,,,gridded data sets;nexrad generation radars;smooth effects operations;usually percent;missing invalid,0.6045;0.3215;0.0936;0.0649;0.0598,"[np.int64(-1), -1, -1, -1, -1]",4;-1;-1;-1;-1,4,4,Spatial Data Structures
VAST,2016,NameClarifier: A Visual Analytics System for Author Name Disambiguation,10.1109/tvcg.2016.2598465,http://dx.doi.org/10.1109/TVCG.2016.2598465,141.0,150.0,J,"In this paper, we present a novel visual analytics system called NameClarifier to interactively disambiguate author names in publications by keeping humans in the loop. Specifically, NameClarifier quantifies and visualizes the similarities between ambiguous names and those that have been confirmed in digital libraries. The similarities are calculated using three key factors, namely, co-authorships, publication venues, and temporal information. Our system estimates all possible allocations, and then provides visual cues to users to help them validate every ambiguous case. By looping users in the disambiguation process, our system can achieve more reliable results than general data mining models for highly ambiguous cases. In addition, once an ambiguous case is resolved, the result is instantly added back to our system and serves as additional cues for all the remaining unidentified names. In this way, we open up the black box in traditional disambiguation processes, and help intuitively and comprehensively explain why the corresponding classifications should hold. We conducted two use cases and an expert review to demonstrate the effectiveness of NameClarifier.",Qiaomu Shen;Tongshuang Wu;Haiyan Yang;Yanhong Wu;Huamin Qu;Weiwei Cui,Qiaomu Shen;Tongshuang Wu;Haiyan Yang;Yanhong Wu;Huamin Qu;Weiwei Cui,Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Microsoft Research,10.1109/tvcg.2012.252;10.1109/tvcg.2011.188;10.1109/vast.2006.261429;10.1109/tvcg.2012.252,Name disambiguation;analytical reasoning,47.0,26.0,41.0,1681.0,,,interactively disambiguate author;novel visual analytics;libraries similarities;cases addition;humans loop specifically,0.6837;0.3352;0.3076;0.1292;0.1121,"[np.int64(-1), -1, -1, -1, -1]",28;-1;-1;-1;-1,28,28,Natural Language Processing
VAST,2011,Exploring agent-based simulations using temporal graphs,10.1109/vast.2011.6102469,http://dx.doi.org/10.1109/VAST.2011.6102469,271.0,272.0,M,"Agent-based simulation has become a key technique for modeling and simulating dynamic, complicated behaviors in social and behavioral sciences. Lacking the appropriate tools and support, it is difficult for social scientists to thoroughly analyze the results of these simulations. In this work, we capture the complex relationships between discrete simulation states by visualizing the data as a temporal graph. In collaboration with expert analysts, we identify two graph structures which capture important relationships between pivotal states in the simulation and their inevitable outcomes. Finally, we demonstrate the utility of these structures in the interactive analysis of a large-scale social science simulation of political power in present-day Thailand.",R. Jordan Crouser;Jeremy G. Freeman;Remco Chang,R. Jordan Crouser;Jeremy G. Freeman;Remco Chang,"Tufts University, USA;Tufts University, USA;Tufts University, USA",0.1109/infvis.2005.1532126,,0.0,0.0,8.0,163.0,,,simulation political power;identify graph;day thailand;thoroughly analyze results;support difficult social,0.6789;0.2714;0.1644;0.1467;0.0936,"[np.int64(-1), -1, -1, -1, -1]",1;-1;-1;-1;-1,1,1,Simulation Modeling
Vis,2007,Visualization of Cosmological Particle-Based Datasets,10.1109/tvcg.2007.70526,http://dx.doi.org/10.1109/TVCG.2007.70526,1712.0,1718.0,J,"We describe our visualization process for a particle-based simulation of the formation of the first stars and their impact on cosmic history. The dataset consists of several hundred time-steps of point simulation data, with each time-step containing approximately two million point particles. For each time-step, we interpolate the point data onto a regular grid using a method taken from the radiance estimate of photon mapping [21]. We import the resulting regular grid representation into ParaView [24], with which we extract isosurfaces across multiple variables. Our images provide insights into the evolution of the early universe, tracing the cosmic transition from an initially homogeneous state to one of increasing complexity. Specifically, our visualizations capture the build-up of regions of ionized gas around the first stars, their evolution, and their complex interactions with the surrounding matter. These observations will guide the upcoming James Webb Space Telescope, the key astronomy mission of the next decade.",Paul A. Navrátil;Jarrett Johnson;Volker Bromm,Paul Navratil;Jarrett Johnson;Volker Bromm,"Texas Advanced Computing Center, University of Texas at Austin;Department of Astronomy, University of Technology, Austin, USA and Department of Astronomy, University of Texas at Austin;Department of Astronomy, University of Technology, Austin, USA and Department of Astronomy, University of Texas at Austin",10.1109/visual.2004.52;10.1109/visual.2004.29;10.1109/visual.2004.52,"Interpolation, Isosurface, Astronomy, Cosmology",51.0,23.0,41.0,403.0,,,early universe tracing;grid representation paraview;isosurfaces;james webb;homogeneous state increasing,0.6233;0.2497;0.2129;0.1076;0.0266,"[np.int64(-1), -1, -1, -1, -1]",10;-1;-1;-1;-1,10,10,Cosmological Research
InfoVis,2012,Visualizing Flow of Uncertainty through Analytical Processes,10.1109/tvcg.2012.285,http://dx.doi.org/10.1109/TVCG.2012.285,2526.0,2535.0,J,"Uncertainty can arise in any stage of a visual analytics process, especially in data-intensive applications with a sequence of data transformations. Additionally, throughout the process of multidimensional, multivariate data analysis, uncertainty due to data transformation and integration may split, merge, increase, or decrease. This dynamic characteristic along with other features of uncertainty pose a great challenge to effective uncertainty-aware visualization. This paper presents a new framework for modeling uncertainty and characterizing the evolution of the uncertainty information through analytical processes. Based on the framework, we have designed a visual metaphor called uncertainty flow to visually and intuitively summarize how uncertainty information propagates over the whole analysis pipeline. Our system allows analysts to interact with and analyze the uncertainty information at different levels of detail. Three experiments were conducted to demonstrate the effectiveness and intuitiveness of our design.",Yingcai Wu;Guo-Xun Yuan;Kwan-Liu Ma,Yingcai Wu;Guo-Xun Yuan;Kwan-Liu Ma,"University of California, Davis, USA;University of California,슠Davis, USA;University of California, Davis, USA",10.1109/tvcg.2008.137;10.1109/tvcg.2011.178;10.1109/infvis.2004.2;10.1109/infvis.2002.1173145;10.1109/visual.1993.398857;10.1109/vast.2009.5332611;10.1109/tvcg.2010.183;10.1109/tvcg.2009.114;10.1109/tvcg.2011.197;10.1109/tvcg.2010.176,"Uncertainty visualization, uncertainty quantification, uncertainty propagation, error ellipsoids, uncertainty fusion",69.0,43.0,46.0,1098.0,,,uncertainty aware visualization;analysts interact;transformations additionally process;sequence data;called,0.7671;0.3211;0.2009;0.1445;0.0247,"[np.int64(-1), -1, -1, -1, -1]",73;-1;-1;-1;-1,73,73,Uncertainty Visualization
VAST,2019,GPGPU Linear Complexity t-SNE Optimization,10.1109/tvcg.2019.2934307,http://dx.doi.org/10.1109/TVCG.2019.2934307,1172.0,1181.0,J,"In recent years the t-distributed Stochastic Neighbor Embedding (t-SNE) algorithm has become one of the most used and insightful techniques for exploratory data analysis of high-dimensional data. It reveals clusters of high-dimensional data points at different scales while only requiring minimal tuning of its parameters. However, the computational complexity of the algorithm limits its application to relatively small datasets. To address this problem, several evolutions of t-SNE have been developed in recent years, mainly focusing on the scalability of the similarity computations between data points. However, these contributions are insufficient to achieve interactive rates when visualizing the evolution of the t-SNE embedding for large datasets. In this work, we present a novel approach to the minimization of the t-SNE objective function that heavily relies on graphics hardware and has linear computational complexity. Our technique decreases the computational cost of running t-SNE on datasets by orders of magnitude and retains or improves on the accuracy of past approximated techniques. We propose to approximate the repulsive forces between data points by splatting kernel textures for each data point. This approximation allows us to reformulate the t-SNE minimization problem as a series of tensor operations that can be efficiently executed on the graphics card. An efficient implementation of our technique is integrated and available for use in the widely used Google TensorFlow.js, and an open-source C++ library.",Nicola Pezzotti;Julian Thijssen;Alexander Mordvintsev;Thomas Höllt;Baldur van Lew;Boudewijn P. F. Lelieveldt;Elmar Eisemann;Anna Vilanova,Nicola Pezzotti;Julian Thijssen;Alexander Mordvintsev;Thomas Höllt;Baldur Van Lew;Boudewijn P.F. Lelieveldt;Elmar Eisemann;Anna Vilanova,"Google AI, Zürich, Switzerland and Delft University of Technology, Delft, The Netherlands;Delft University of Technology, Delft, The Netherlands;Google AI, Zürich, Switzerland;Delft University of Technology, Delft, The Netherlands and Leiden University Medical Center, Leiden, The Netherlands;Leiden University Medical Center, Leiden, The Netherlands;Delft University of Technology, Delft, The Netherlands and Leiden University Medical Center, Leiden, The Netherlands;Delft University of Technology, Delft, The Netherlands;Delft University of Technology, Delft, The Netherlands",10.1109/tvcg.2017.2744318;10.1109/tvcg.2017.2744718;10.1109/tvcg.2017.2745141;10.1109/tvcg.2017.2744358;10.1109/tvcg.2014.2346574,"High Dimensional Data,Dimensionality Reduction,Progressive Visual Analytics,Approximate Computation,GPGPU",59.0,45.0,45.0,1185.0,,,stochastic neighbor embedding;visualizing evolution;tensorflow js open;repulsive forces;graphics card efficient,0.6117;0.3444;0.2563;0.2062;0.1546,"[np.int64(-1), -1, -1, -1, -1]",24;-1;-1;-1;-1,24,24,Embedding Techniques
VAST,2012,Visual analytics methods for categoric spatio-temporal data,10.1109/vast.2012.6400553,http://dx.doi.org/10.1109/VAST.2012.6400553,183.0,192.0,C,"We focus on visual analysis of space- and time-referenced categorical data, which describe possible states of spatial (geographical) objects or locations and their changes over time. The analysis of these data is difficult as there are only limited possibilities to analyze the three aspects (location, time and category) simultaneously. We present a new approach which interactively combines (a) visualization of categorical changes over time; (b) various spatial data displays; (c) computational techniques for task-oriented selection of time steps. They provide an expressive visualization with regard to either the overall evolution over time or unusual changes. We apply our approach on two use cases demonstrating its usefulness for a wide variety of tasks. We analyze data from movement tracking and meteorologic areas. Using our approach, expected events could be detected and new insights were gained.",Tatiana von Landesberger;Sebastian Bremm;Natalia V. Andrienko;Gennady L. Andrienko;Maria Tekusova,T. von Landesberger;Sebastian Bremm;Natalia Andrienko;Gennady Andrienko;Mária Tekušová,"TU Darmstadt, Darmstadt, Germany;TU Darmstadt, Darmstadt, Germany;Fraunhofer IAIS, Bonn, Germany;Fraunhofer IAIS, Bonn, Germany;SHMU, Bratislava, Slovakia",10.1109/tvcg.2011.174;10.1109/tvcg.2009.117;10.1109/tvcg.2009.181;10.1109/infvis.2000.885098;10.1109/tvcg.2010.138;10.1109/vast.2010.5652530;10.1109/infvis.2004.27;10.1109/infvis.2005.1532152;10.1109/infvis.2001.963281;10.1109/tvcg.2008.165;10.1109/tvcg.2009.153;10.1109/tvcg.2011.174,,100.0,43.0,43.0,1416.0,,,visualization categorical changes;task oriented selection;location time;meteorologic areas using;expected events,0.6561;0.3065;0.2926;0.2926;0.1431,"[np.int64(-1), -1, -1, -1, -1]",136;-1;-1;-1;-1,136,136,Trend Visualization Techniques
Vis,2024,DimBridge: Interactive Explanation of Visual Patterns in Dimensionality Reductions with Predicate Logic,10.1109/tvcg.2024.3456391,http://dx.doi.org/10.1109/TVCG.2024.3456391,207.0,217.0,J,"Dimensionality reduction techniques are widely used for visualizing high-dimensional data. However, support for interpreting patterns of dimension reduction results in the context of the original data space is often insufficient. Consequently, users may struggle to extract insights from the projections. In this paper, we introduce DimBridge, a visual analytics tool that allows users to interact with visual patterns in a projection and retrieve corresponding data patterns. DimBridge supports several interactions, allowing users to perform various analyses, from contrasting multiple clusters to explaining complex latent structures. Leveraging first-order predicate logic, DimBridge identifies subspaces in the original dimensions relevant to a queried pattern and provides an interface for users to visualize and interact with them. We demonstrate how DimBridge can help users overcome the challenges associated with interpreting visual patterns in projections.",Brian Montambault;Gabriel Appleby;Jen Rogers;Camelia D. Brumar;Mingwei Li;Remco Chang,Brian Montambault;Gabriel Appleby;Jen Rogers;Camelia D. Brumar;Mingwei Li;Remco Chang,"Tufts University, USA;Tufts University, USA;Tufts University, USA;Tufts University, USA;Tufts University, USA;Tufts University, USA",10.1109/tvcg.2011.229;10.1109/tvcg.2018.2864477;10.1109/vast.2012.6400489;10.1109/tvcg.2019.2934251;10.1109/tvcg.2021.3114807;10.1109/vast.2008.4677352;10.1109/infvis.2002.1173157;10.1109/tvcg.2017.2745085;10.1109/visual.1990.146386;10.1109/tvcg.2022.3209382;10.1109/visual.1995.485139;10.1109/tvcg.2018.2864812;10.1109/tvcg.2013.153;10.1109/tvcg.2021.3114870;10.1109/tvcg.2017.2744843;10.1109/tvcg.2015.2467717;10.1109/vast.2012.6400488;10.1109/tvcg.2017.2745258;10.1109/infvis.2005.1532142;10.1109/tvcg.2022.3209423;10.1109/vast.2006.261436,"Predicates,Dimensionality Reduction,,,Explainable Machine Learning",,0.0,95.0,220.0,,,visualizing high dimensional;multiple clusters explaining;logic dimbridge identifies;reduction results;support,0.6151;0.4332;0.3196;0.1879;0.1271,"[np.int64(-1), -1, -1, -1, -1]",93;-1;-1;-1;-1,93,93,Multivariate Data Visualization
Vis,2003,Interactive view-dependent rendering with conservative occlusion culling in complex environments,10.1109/visual.2003.1250368,http://dx.doi.org/10.1109/VISUAL.2003.1250368,163.0,170.0,C,"This paper presents an algorithm combining view-dependent rendering and conservative occlusion culling for interactive display of complex environments. A vertex hierarchy of the entire scene is decomposed into a cluster hierarchy through a novel clustering and partitioning algorithm. The cluster hierarchy is then used for view-frustum and occlusion culling. Using hardware accelerated occlusion queries and frame-to-frame coherence, a potentially visible set of clusters is computed. An active vertex front and face list is computed from the visible clusters and rendered using vertex arrays. The integrated algorithm has been implemented on a Pentium IV PC with a NVIDIA GeForce 4 graphics card and applied in two complex environments composed of millions of triangles. The resulting system can render these environments at interactive rates with little loss in image quality and minimal popping artifacts.",Sung-Eui Yoon;Brian Salomon;Dinesh Manocha,Sung-Eui Yoon;B. Salomon;D. Manocha,"University of North Carolina, Chapel Hill, USA;University of North Carolina, Chapel Hill, USA;University of North Carolina, Chapel Hill, USA",10.1109/visual.2002.1183760;10.1109/visual.2001.964534;10.1109/visual.2002.1183796;10.1109/visual.2002.1183760,"Interactive Display, View-Dependent Rendering, Occlusion Culling, Level of Detail, Multiresolution Hierarchies",56.0,6.0,40.0,118.0,,,hardware accelerated occlusion;display complex environments;cluster hierarchy used;scene;list computed,0.6035;0.4821;0.2570;0.1520;0.0705,"[np.int64(-1), -1, -1, -1, -1]",43;-1;-1;-1;-1,43,43,Illustrative Rendering Techniques
Vis,2008,Generation of Accurate Integral Surfaces in Time-Dependent Vector fields,10.1109/tvcg.2008.133,http://dx.doi.org/10.1109/TVCG.2008.133,1404.0,1411.0,J,"We present a novel approach for the direct computation of integral surfaces in time-dependent vector fields. As opposed to previous work, which we analyze in detail, our approach is based on a separation of integral surface computation into two stages: surface approximation and generation of a graphical representation. This allows us to overcome several limitations of existing techniques. We first describe an algorithm for surface integration that approximates a series of time lines using iterative refinement and computes a skeleton of the integral surface. In a second step, we generate a well-conditioned triangulation. Our approach allows a highly accurate treatment of very large time-varying vector fields in an efficient, streaming fashion. We examine the properties of the presented methods on several example datasets and perform a numerical study of its correctness and accuracy. Finally, we investigate some visualization aspects of integral surfaces.",Christoph Garth;Han Krishnan;Xavier Tricoche;Tom Tricoche;Kenneth I. Joy,Christoph Garth;Han Krishnan;Xavier Tricoche;Tom Tricoche;Kenneth I. Joy,"Institute of Data Analysis and Visualization, University of California, Davis, USA;Institute of Data Analysis and Visualization, University of California, Davis, USA;Computer Science Dept., Purdue University, USA;Geometric Algorithms Group, University of Kaiserslautern;Institute of Data Analysis and Visualization, University of California, Davis, USA",10.1109/visual.1993.398875;10.1109/visual.2001.964506;10.1109/visual.2004.28;10.1109/visual.1992.235211;10.1109/visual.1992.235226;10.1109/visual.1993.398875,"3D vector field visualization, flow visualization, time-varying and time-series visualization, surface extraction",103.0,51.0,18.0,376.0,,,integral surfaces time;triangulation;streaming fashion;fields opposed;approximates series,0.5838;0.3497;0.1337;0.1040;0.0339,"[np.int64(-1), -1, -1, -1, -1]",123;-1;-1;-1;-1,123,123,Surface Reconstruction
Vis,2000,Two-level volume rendering - fusing MIP and DVR,10.1109/visual.2000.885697,http://dx.doi.org/10.1109/VISUAL.2000.885697,211.0,218.0,C,"Presents a two-level approach for fusing direct volume rendering (DVR) and maximum-intensity projection (MIP) within a joint rendering method. Different structures within the data set are rendered locally by either MIP or DVR on an object-by-object basis. Globally, all the results of subsequent object renderings are combined in a merging step (usually compositing in our case). This allows us to selectively choose the most suitable technique for depicting each object within the data, while keeping the amount of information contained in the image at a reasonable level. This is especially useful when inner structures should be visualized together with semi-transparent outer parts, similar to the focus-and-context approach known from information visualization. We also present an implementation of our approach which allows us to explore volumetric data using two-level rendering at interactive frame rates.",Helwig Hauser;Lukas Mroz;Gian Italo Bischi;M. Eduard Gröller,H. Hauser;L. Mroz;G.-I. Bischi;M.E. Groller,"VRVis Center Vienna, Austria;University of Technology, Vienna, Austria;University of Urbino, Italy;University of Technology, Vienna, Austria",10.1109/visual.1998.745311;10.1109/visual.1999.809887;10.1109/visual.1996.568113;10.1109/visual.2000.885697;10.1109/visual.1998.745311,"visualization, volume rendering, dynamical systems,medical applications",81.0,12.0,20.0,173.0,,,direct volume rendering;object basis globally;explore;combined;keeping information,0.7287;0.2026;0.1436;0.1119;0.1087,"[np.int64(-1), -1, -1, -1, -1]",52;-1;-1;-1;-1,52,52,Volume Rendering Techniques
Vis,2023,VISPUR: Visual Aids for Identifying and Interpreting Spurious Associations in Data-Driven Decisions,10.1109/tvcg.2023.3326587,http://dx.doi.org/10.1109/TVCG.2023.3326587,219.0,229.0,J,"Big data and machine learning tools have jointly empowered humans in making data-driven decisions. However, many of them capture empirical associations that might be spurious due to confounding factors and subgroup heterogeneity. The famous Simpson's paradox is such a phenomenon where aggregated and subgroup-level associations contradict with each other, causing cognitive confusions and difficulty in making adequate interpretations and decisions. Existing tools provide little insights for humans to locate, reason about, and prevent pitfalls of spurious association in practice. We propose VISPUR, a visual analytic system that provides a causal analysis framework and a human-centric workflow for tackling spurious associations. These include a CONFOUNDER DASHBOARD, which can automatically identify possible confounding factors, and a SUBGROUP VIEWER, which allows for the visualization and comparison of diverse subgroup patterns that likely or potentially result in a misinterpretation of causality. Additionally, we propose a REASONING STORYBOARD, which uses a flow-based approach to illustrate paradoxical phenomena, as well as an interactive DECISION DIAGNOSIS panel that helps ensure accountable decision-making. Through an expert interview and a controlled user experiment, our qualitative and quantitative results demonstrate that the proposed “de-paradox” workflow and the designed visual analytic system are effective in helping human users to identify and understand spurious associations, as well as to make accountable causal decisions.",Xian Teng;Yongsu Ahn;Yu-Ru Lin,Xian Teng;Yongsu Ahn;Yu-Ru Lin,"University of Pittsburgh, USA;University of Pittsburgh, USA;University of Pittsburgh, USA",0.1109/tvcg.2019.2934262;10.1109/tvcg.2014.2346297;10.1109/vast.2018.8802486;10.1109/vast47406.2019.8986948;10.1109/tvcg.2020.3030342;10.1109/tvcg.2018.2865043;10.1109/tvcg.2020.3030465;10.1109/tvcg.2021.3114824;10.1109/tvcg.2017.2745085;10.1109/infvis.2005.1532152;10.1109/tvcg.2015.2467931;10.1109/vast.2017.8585647;10.1109/tvcg.2019.2934619;10.1109/tvcg.2020.3028957,"Causal Analysis,Simpson's Paradox,Spurious Associations,Machine Learning,Decision Making",,0.0,76.0,426.0,,,associations spurious confounding;visualization comparison diverse;factors subgroup;dashboard automatically;uses,0.5565;0.3643;0.1866;0.1326;0.1200,"[np.int64(-1), -1, -1, -1, -1]",25;-1;-1;-1;-1,25,25,Data Interpretation Challenges
Vis,2005,Multimodal exploration of the fourth dimension,10.1109/visual.2005.1532804,http://dx.doi.org/10.1109/VISUAL.2005.1532804,263.0,270.0,C,"We present a multimodal paradigm for exploring topological surfaces embedded in four dimensions; we exploit haptic methods in particular to overcome the intrinsic limitations of 3D graphics images and 3D physical models. The basic problem is that, just as 2D shadows of 3D curves lose structure where lines cross, 3D graphics projections of smooth 4D topological surfaces are interrupted where one surface intersects another. Furthermore, if one attempts to trace real knotted ropes or a plastic models of self-intersecting surfaces with a fingertip, one inevitably collides with parts of the physical artifact. In this work, we exploit the free motion of a computer-based haptic probe to support a continuous motion that follows the local continuity of the object being explored. For our principal test case of 4D-embedded surfaces projected to 3D, this permits us to follow the full local continuity of the surface as though in fact we were touching an actual 4D object. We exploit additional sensory cues to provide supplementary or redundant information. For example, we can use audio tags to note the relative 4D depth of illusory 3D surface intersections produced by projection from 4D, as well as providing automated refinement of the tactile exploration path to eliminate jitter and snagging, resulting in a much cleaner exploratory motion than a bare uncorrected motion. Visual enhancements provide still further improvement to the feedback: by opening a view-direction-defined cutaway into the interior of the 3D surface projection, we allow the viewer to keep the haptic probe continuously in view as it traverses any touchable part of the object. Finally, we extend the static tactile exploration framework using a dynamic mode that links each stylus motion to a change in orientation that creates at each instant a maximal-area screen projection of a neighborhood of the current point of interest. This minimizes 4D distortion and permits true metric sizes to be deduced locally at any point. All these methods combine to reveal the full richness of the complex spatial relationships of the target shapes, and to overcome many expected perceptual limitations in 4D visualization.",Andrew J. Hanson;Hui Zhang 0006,A.J. Hanson;H. Zhang,"Computer Science Department, Indiana University, USA;Computer Science Department, Indiana University, USA",10.1109/visual.1995.480804;10.1109/visual.1995.480804," multimodal, haptics, visualization",21.0,5.0,31.0,170.0,,,touching actual 4d;paradigm exploring topological;eliminate jitter snagging;attempts trace;provide supplementary redundant,0.6277;0.3054;0.0972;0.0809;-0.0137,"[np.int64(-1), -1, -1, -1, -1]",114;-1;-1;-1;-1,114,114,4D/3D Visualization
Vis,2001,"Semi-immersive space mission design and visualization: case study of the ""Terrestrial Planet Finder"" mission",10.1109/visual.2001.964562,http://dx.doi.org/10.1109/VISUAL.2001.964562,501.0,504.0,C,"The paper addresses visualization issues of the Terrestrial Planet Finder Mission (C.A. Beichman et al., 1999). The goal of this mission is to search for chemical signatures of life in distant solar systems using five satellites flying in formation to simulate a large telescope. To design and visually verify such a delicate mission, one has to analyze and interact with many different 3D spacecraft trajectories, which is often difficult in 2D. We employ a novel trajectory design approach using invariant manifold theory, which is best understood and utilized in an immersive setting. The visualization also addresses multi-scale issues related to the vast differences in distance, velocity, and time at different phases of the mission. Additionally, the parameterization and coordinate frames used for numerical simulations may not be suitable for direct visualization. Relative motion presents a more serious problem where the patterns of the trajectories can only be viewed in particular rotating frames. Some of these problems are greatly relieved by using interactive, animated stereo 3D visualization in a semi-immersive environment such as a Responsive Workbench. Others were solved using standard techniques such as a stratify approach with multiple windows to address the multiscale issues, re-parameterizations of trajectories and associated 2D manifolds and relative motion of the camera to ""evoke"" the desired patterns.",Ken Museth;Alan H. Barr;Martin W. Lo,K. Museth;A. Barr;M.W. Lo,"Computer Science Department, California Institute of Technology, Pasadena, CA, USA;Computer Science Department, California Institute of Technology, Pasadena, CA, USA;Jet Propulsion Laboratory and Computer Science Department, California Institute of Technology, Pasadena, CA",,,13.0,3.0,7.0,122.0,,,3d spacecraft trajectories;chemical signatures life;camera evoke desired;responsive workbench;stratify,0.6054;0.2041;0.1688;0.1521;0.0789,"[np.int64(-1), -1, -1, -1, -1]",119;-1;-1;-1;-1,119,119,Spacecraft Trajectory Analysis
InfoVis,2020,Table Scraps: An Actionable Framework for Multi-Table Data Wrangling From An Artifact Study of Computational Journalism,10.1109/tvcg.2020.3030462,http://dx.doi.org/10.1109/TVCG.2020.3030462,957.0,966.0,J,"For the many journalists who use data and computation to report the news, data wrangling is an integral part of their work. Despite an abundance of literature on data wrangling in the context of enterprise data analysis, little is known about the specific operations, processes, and pain points journalists encounter while performing this tedious, time-consuming task. To better understand the needs of this user group, we conduct a technical observation study of 50 public repositories of data and analysis code authored by 33 professional journalists at 26 news organizations. We develop two detailed and cross-cutting taxonomies of data wrangling in computational journalism, for actions and for processes. We observe the extensive use of multiple tables, a notable gap in previous wrangling analyses. We develop a concise, actionable framework for general multi-table data wrangling that includes wrangling operations documented in our taxonomy that are without clear parallels in other work. This framework, the first to incorporate tables as first-class objects, will support future interactive wrangling tools for both computational journalism and general-purpose use. We assess the generative and descriptive power of our framework through discussion of its relationship to our set of taxonomies.",Stephen Kasica;Charles Berret;Tamara Munzner,Stephen Kasica;Charles Berret;Tamara Munzner,"Department of Computer Science, University of British Columbia;University of British Columbia, School of Journalism, Writing, and Media;Department of Computer Science, University of British Columbia",10.1109/vast47406.2019.8986909;10.1109/vast.2011.6102441;10.1109/tvcg.2012.219;10.1109/tvcg.2019.2934593;10.1109/vast.2011.6102440;10.1109/tvcg.2019.2934539;10.1109/tvcg.2015.2467551;10.1109/infvis.2000.885086;10.1109/vast47406.2019.8986909,"Computational journalism,Data journalism,Data wrangling",20.0,17.0,55.0,800.0,,,journalists use data;framework incorporate tables;operations processes pain;taxonomy clear parallels;26,0.6592;0.2414;0.1863;0.0989;0.0118,"[np.int64(-1), -1, -1, -1, -1]",51;-1;-1;-1;-1,51,51,Data Journalism
Vis,1994,Nonpolygonal isosurface rendering for large volume datasets,10.1109/visual.1994.346306,http://dx.doi.org/10.1109/VISUAL.1994.346306,293.0,,C,"Surface-based rendering techniques, particularly those that extract a polygonal approximation of an isosurface, are widely used in volume visualization. As dataset size increases though, the computational demands of these methods can overwhelm typically available computing resources. Recent work on accelerating such techniques has focused on preprocessing the volume data or postprocessing the extracted polygonization. The algorithm presented, concentrates instead on streamlining the surface extraction process itself so as to accelerate the rendering of large volumes. The technique shortens the conventional isosurface visualization pipeline by eliminating the intermediate polygonization. We compute the contribution of the isosurface within a volume cell to the resulting image directly from a simplified numerical description of the cell/surface intersection. The approach also reduces the work in the remaining stages of the visualization process. By quantizing the volume data, we exploit precomputed and cached data at key processing steps to improve rendering efficiency. The resulting implementation provides comparatively fast renderings with reasonable image quality.&lt;&lt;ETX&gt;&gt;",James W. Durkin;John F. Hughes,J.W. Durkin;J.F. Hughes,"Cornell University, Ithaca, NY, USA;Computer Science Department, Brown University, Providence, RI, USA",,,27.0,2.0,12.0,53.0,,,volume visualization;comparatively fast renderings;conventional isosurface;postprocessing extracted polygonization;exploit precomputed cached,0.6695;0.4283;0.4127;0.4008;0.0458,"[np.int64(-1), -1, -1, -1, -1]",54;-1;-1;-1;-1,54,54,Volume Visualization Techniques
Vis,2023,Interactive Design and Optics-Based Visualization of Arbitrary Non-Euclidean Kaleidoscopic Orbifolds,10.1109/tvcg.2023.3326927,http://dx.doi.org/10.1109/TVCG.2023.3326927,1292.0,1301.0,J,"Orbifolds are a modern mathematical concept that arises in the research of hyperbolic geometry with applications in computer graphics and visualization. In this paper, we make use of rooms with mirrors as the visual metaphor for orbifolds. Given any arbitrary two-dimensional kaleidoscopic orbifold, we provide an algorithm to construct a Euclidean, spherical, or hyperbolic polygon to match the orbifold. This polygon is then used to create a room for which the polygon serves as the floor and the ceiling. With our system that implements Möbius transformations, the user can interactively edit the scene and see the reflections of the edited objects. To correctly visualize non-Euclidean orbifolds, we adapt the rendering algorithms to account for the geodesics in these spaces, which light rays follow. Our interactive orbifold design system allows the user to create arbitrary two-dimensional kaleidoscopic orbifolds. In addition, our mirror-based orbifold visualization approach has the potential of helping our users gain insight on the orbifold, including its orbifold notation as well as its universal cover, which can also be the spherical space and the hyperbolic space.",Jinta Zheng;Eugene Zhang;Yue Zhang 0009,Jinta Zheng;Eugene Zhang;Yue Zhang,"Oregon State University, USA;Oregon State University, USA;Oregon State University, USA",0.1109/tvcg.2020.3030431;10.1109/tvcg.2017.2744038;10.1109/tvcg.2018.2864768,"Kaleidoscopic Orbifolds,Orbifold Visualization,Math Visualization,Orbifold Construction,Spherical Geometry,Hyperbolic Geometry",,0.0,36.0,214.0,,,based orbifold visualization;hyperbolic space;polygon serves floor;scene reflections edited;given arbitrary,0.7131;0.4431;0.3597;0.3065;0.0703,"[np.int64(-1), -1, -1, -1, -1]",125;-1;-1;-1;-1,125,125,Celestial Visualization
InfoVis,1999,Evaluating a visualisation of image similarity as a tool for image browsing,10.1109/infvis.1999.801855,http://dx.doi.org/10.1109/INFVIS.1999.801855,36.0,,C,"A similarity metric based on the low-level content of images can be used to create a visualisation in which visually similar images are displayed close to each other. We are carrying out a series of experiments to evaluate the usefulness of this type of visualisation as an image browsing aid. The initial experiment, described, considered whether people would find a given photograph more quickly in a visualisation than in a randomly arranged grid of images. The results show that the subjects were faster with the visualisation, although in post-experiment interviews many of them said that they preferred the clarity and regularity of the grid. We describe an algorithm with which the best aspects of the two layout types can be combined.",Kerry Rodden;Wojciech Basalaj;David Sinclair;Kenneth R. Wood,K. Rodden;W. Basalaj;D. Sinclair;K. Wood,"Computer Laboratory, University of Cambridge, Cambridge, UK;Computer Laboratory, University of Cambridge, Cambridge, UK;AT and T Laboratories, Cambridge, UK;AT and T Laboratories, Cambridge, UK",0.1109/infvis.1999.801855,,113.0,25.0,17.0,236.0,,,visually similar images;best aspects layout;regularity grid algorithm;low level;carrying series,0.6448;0.3190;0.2895;0.0338;0.0122,"[np.int64(-1), -1, -1, -1, -1]",14;-1;-1;-1;-1,14,14,Image Dataset Comparison
InfoVis,2008,Particle-based labeling: Fast point-feature labeling without obscuring other visual features,10.1109/tvcg.2008.152,http://dx.doi.org/10.1109/TVCG.2008.152,1237.0,1244.0,J,"In many information visualization techniques, labels are an essential part to communicate the visualized data. To preserve the expressiveness of the visual representation, a placed label should neither occlude other labels nor visual representatives (e.g., icons, lines) that communicate crucial information. Optimal, non-overlapping labeling is an NP-hard problem. Thus, only a few approaches achieve a fast non-overlapping labeling in highly interactive scenarios like information visualization. These approaches generally target the point-feature label placement (PFLP) problem, solving only label-label conflicts. This paper presents a new, fast, solid and flexible 2D labeling approach for the PFLP problem that additionally respects other visual elements and the visual extent of labeled features. The results (number of placed labels, processing time) of our particle-based method compare favorably to those of existing techniques. Although the esthetic quality of non-real-time approaches may not be achieved with our method, it complies with practical demands and thus supports the interactive exploration of information spaces. In contrast to the known adjacent techniques, the flexibility of our technique enables labeling of dense point clouds by the use of non-occluding distant labels. Our approach is independent of the underlying visualization technique, which enables us to demonstrate the application of our labeling method within different information visualization scenarios.",Martin Luboschik;Heidrun Schumann;Hilko Cords,Martin Luboschik;Heidrun Schumann;Hilko Cords,"University of Rostock, Germany;University of Rostock, Germany;University of Rostock, Germany",10.1109/tvcg.2006.136;10.1109/tvcg.2006.136;10.1109/visual.2005.1532856,"Interactive labeling, dynamic labeling, automatic label placement, occlusion-free, information visualization",88.0,50.0,23.0,786.0,,,information visualization;labeling dense point;particle;placement pflp problem;hard,0.5756;0.4783;0.2606;0.2045;0.0631,"[np.int64(-1), -1, -1, -1, -1]",98;-1;-1;-1;-1,98,98,Information Visualization
Vis,1997,Isosurface extraction using particle systems,10.1109/visual.1997.663930,http://dx.doi.org/10.1109/VISUAL.1997.663930,495.0,498.0,C,"Presents a new approach to isosurface extraction from volume data using particle systems. Particle behavior is dynamic and can be based on laws of physics or artificial rules. For isosurface extraction, we program particles to be attracted towards a specific surface value while simultaneously repelling adjacent particles. The repulsive forces are based on the curvature of the surface at that location. A birth-death process results in a denser concentration of particles in areas of high curvature and sparser populations in areas of lower curvature. The overall level of detail is controlled through a scaling factor that increases or decreases the repulsive forces of the particles. Once particles reach equilibrium, their locations are used as vertices in generating a triangular mesh of the surface. The advantages of our approach include: vertex densities are based on surface features rather than on the sampling rate of the volume; a single scaling factor simplifies level-of-detail control; and meshing is efficient because it uses neighbor information that has already been generated during the force calculations.",Patricia Crossno;Edward Angel,P. Crossno;E. Angel,"Department of Computer Science, University of New Mexico, USA;Department of Computer Science, University of New Mexico, USA",10.1109/visual.1993.398880;10.1109/visual.1993.398880,,101.0,24.0,9.0,136.0,,,densities based surface;repulsive forces particles;extraction program;vertices generating triangular;simultaneously,0.6053;0.2874;0.2475;0.1584;-0.0444,"[np.int64(-1), -1, -1, -1, -1]",124;-1;-1;-1;-1,124,124,Volumetric Surface Visualization
VAST,2015,VA2: A Visual Analytics Approach for Evaluating Visual Analytics Applications,10.1109/tvcg.2015.2467871,http://dx.doi.org/10.1109/TVCG.2015.2467871,61.0,70.0,J,"Evaluation has become a fundamental part of visualization research and researchers have employed many approaches from the field of human-computer interaction like measures of task performance, thinking aloud protocols, and analysis of interaction logs. Recently, eye tracking has also become popular to analyze visual strategies of users in this context. This has added another modality and more data, which requires special visualization techniques to analyze this data. However, only few approaches exist that aim at an integrated analysis of multiple concurrent evaluation procedures. The variety, complexity, and sheer amount of such coupled multi-source data streams require a visual analytics approach. Our approach provides a highly interactive visualization environment to display and analyze thinking aloud, interaction, and eye movement data in close relation. Automatic pattern finding algorithms allow an efficient exploratory search and support the reasoning process to derive common eye-interaction-thinking patterns between participants. In addition, our tool equips researchers with mechanisms for searching and verifying expected usage patterns. We apply our approach to a user study involving a visual analytics application and we discuss insights gained from this joint analysis. We anticipate our approach to be applicable to other combinations of evaluation techniques and a broad class of visualization applications.",Tanja Blascheck;Markus John;Kuno Kurzhals;Steffen Koch 0001;Thomas Ertl,Tanja Blascheck;Markus John;Kuno Kurzhals;Steffen Koch;Thomas Ertl,"Institute for Visualization and Interactive Systems (VIS), University of Stuttgart, Germany;Institute for Visualization and Interactive Systems (VIS), University of Stuttgart, Germany;Visualization Research Center, University of Stuttgart, Germany;Institute for Visualization and Interactive Systems (VIS), University of Stuttgart, Germany;Institute for Visualization and Interactive Systems (VIS), University of Stuttgart, Germany",10.1109/tvcg.2012.276;10.1109/tvcg.2013.124;10.1109/vast.2008.4677361;10.1109/vast.2009.5333878;10.1109/tvcg.2014.2346677;10.1109/vast.2010.5653598;10.1109/tvcg.2012.273;10.1109/visual.2005.1532837;10.1109/tvcg.2012.276,"visual analytics, qualitative evaluation, thinking aloud, interaction logs, eye tracking, time series data",,69.0,53.0,2679.0,HM,,visual analytics;thinking aloud protocols;recently eye;research researchers employed;derive common,0.6403;0.3537;0.2193;0.0892;0.0679,"[np.int64(-1), -1, -1, -1, -1]",108;-1;-1;-1;-1,108,108,Visual Analytics
VAST,2020,Diagnosing Concept Drift with Visual Analytics,10.1109/vast50239.2020.00007,http://dx.doi.org/10.1109/VAST50239.2020.00007,12.0,23.0,C,"Concept drift is a phenomenon in which the distribution of a data stream changes over time in unforeseen ways, causing prediction models built on historical data to become inaccurate. While a variety of automated methods have been developed to identify when concept drift occurs, there is limited support for analysts who need to understand and correct their models when drift is detected. In this paper, we present a visual analytics method, DriftVis, to support model builders and analysts in the identification and correction of concept drift in streaming data. DriftVis combines a distribution-based drift detection method with a streaming scatterplot to support the analysis of drift caused by the distribution changes of data streams and to explore the impact of these changes on the model’s accuracy. A quantitative experiment and two case studies on weather prediction and text classification have been conducted to demonstrate our proposed tool and illustrate how visual analytics can be used to support the detection, examination, and correction of concept drift.",Weikai Yang;Zhen Li 0044;Mengchen Liu;Yafeng Lu;Kelei Cao;Ross Maciejewski;Shixia Liu,Weikai Yang;Zhen Li;Mengchen Liu;Yafeng Lu;Kelei Cao;Ross Maciejewski;Shixia Liu,"School of Software, BNRist, Tsinghua University;School of Software, BNRist, Tsinghua University;Microsoft;Bloomberg L.P.;School of Software, BNRist, Tsinghua University;Computer Science, Arizona State University;School of Software, BNRist, Tsinghua University",10.1109/tvcg.2018.2864499;10.1109/tvcg.2017.2744878;10.1109/tvcg.2019.2934619;10.1109/vast50239.2020.00006;10.1109/tvcg.2018.2864504;10.1109/visual.2005.1532820;10.1109/tvcg.2017.2744158;10.1109/tvcg.2018.2865044;10.1109/tvcg.2018.2864838;10.1109/tvcg.2016.2598828;10.1109/tvcg.2016.2598838;10.1109/tvcg.2017.2744358;10.1109/tvcg.2019.2934267;10.1109/tvcg.2018.2864812;10.1109/vast.2017.8585721;10.1109/tvcg.2019.2934631;10.1109/tvcg.2016.2598831;10.1109/tvcg.2017.2744938;10.1109/vast.2018.8802509;10.1109/tvcg.2018.2865027;10.1109/tvcg.2018.2864500;10.1109/tvcg.2019.2934659;10.1109/tvcg.2018.2865043;10.1109/tvcg.2013.212;10.1109/tvcg.2017.2744683;10.1109/tvcg.2018.2864499,"Concept drift,streaming data,change detection,scatterplot,t-SNE.",16.0,21.0,76.0,1097.0,,,identify concept drift;weather prediction text;scatterplot support;model builders;correction,0.7139;0.3175;0.3137;0.1109;0.0434,"[np.int64(-1), -1, -1, -1, -1]",112;-1;-1;-1;-1,112,112,Temporal Feature Analysis
Vis,1996,The Design and Implementation of an Object-Oriented Toolkit for 3D Graphics and Visualization,10.1109/visual.1996.567752,http://doi.ieeecomputersociety.org/10.1109/VISUAL.1996.567752,93.0,100.0,C,"The Visualization Toolkit (vtk) is a freely available C++ class library for 3D graphics and visualization. We describe core characteristics of the toolkit. This includes a description of object oriented models for graphics and visualization; methods for synchronizing system execution; a summary of data representation schemes; the role of C++; issues in portability across PC and Unix systems; and how we automatically wrap the C++ class library with interpreted languages such as Java and Tcl. We also demonstrate the capabilities of the system for scalar, vector, tensor, and other visualization techniques.",William J. Schroeder;Ken Martin;William E. Lorensen,W.J. Schroeder;K.M. Martin;W.E. Lorensen,"GE Corp. Res. & Dev., USA;;",10.1109/visual.1993.398878;10.1109/visual.1994.346303;10.1109/visual.1992.235205;10.1109/visual.1995.480821,,402.0,95.0,0.0,150.0,TT,,3d graphics visualization;toolkit includes description;scalar;issues portability pc;methods synchronizing execution,0.6884;0.2728;0.1634;0.0733;0.0722,"[np.int64(-1), -1, -1, -1, -1]",82;-1;-1;-1;-1,82,82,3D/4D Visualization
Vis,2001,Wavelet representation of contour sets,10.1109/visual.2001.964525,http://dx.doi.org/10.1109/VISUAL.2001.964525,303.0,310.0,C,"We present a new wavelet compression and multiresolution modeling approach for sets of contours (level sets). In contrast to previous wavelet schemes, our algorithm creates a parametrization of a scalar field induced by its contours and compactly stores this parametrization rather than function values sampled on a regular grid. Our representation is based on hierarchical polygon meshes with subdivision connectivity whose vertices are transformed into wavelet coefficients. From this sparse set of coefficients, every set of contours can be efficiently reconstructed at multiple levels of resolution. When applying lossy compression, introducing high quantization errors, our method preserves contour topology, in contrast to compression methods applied to the corresponding field function. We provide numerical results for scalar fields defined on planar domains. Our approach generalizes to volumetric domains, time-varying contours, and level sets of vector fields.",Martin Bertram 0001;Daniel E. Laney;Mark A. Duchaineau;Charles D. Hansen;Bernd Hamann;Kenneth I. Joy,M. Bertram;D.E. Laney;M.A. Duchaineau;C.D. Hansen;B. Hamann;K.I. Joy,"Department of Computer Science, University of Kaiserslautern, Kaiserslautern, Germany and SCI Institute, University of Utah, Salt Lake, UT, USA;Center for Applied Scientific Computing CASC, Lawrence Livemore National Laboratory, Livermore, CA, USA;Center for Applied Scientific Computing CASC, Lawrence Livemore National Laboratory, Livermore, CA, USA;Center for Image Processing and Integrated Computing CIPIC Department of Computer Science, University of California, Davis, CA, USA;SCI Institute, University of Utah, Salt Lake, UT, USA;Center for Image Processing and Integrated Computing CIPIC Department of Computer Science, University of California, Davis, CA, USA",10.1109/visual.1994.346332;10.1109/visual.2000.885720;10.1109/visual.2000.885716;10.1109/visual.2000.885705;10.1109/visual.1994.346332,"Contours, Geometry Compression, Iso-surfaces, Level Sets, Multiresolution Methods, Wavelets",14.0,3.0,21.0,90.0,,,wavelet compression multiresolution;contours efficiently;fields defined planar;lossy;sets,0.5814;0.5136;0.1971;0.0804;0.0121,"[np.int64(-1), np.int64(-1), -1, -1, -1]",22;126;-1;-1;-1,22;126,22,Wavelet Techniques
Vis,2001,Case study: medical Web service for the automatic 3D documentation for neuroradiological diagnosis,10.1109/visual.2001.964542,http://dx.doi.org/10.1109/VISUAL.2001.964542,425.0,428.0,C,"The case study presents a medical Web service for the automatic analysis of CTA (computer tomography angiography) datasets. It aims at the detection and evaluation of intracranial aneurysms which are malformations of cerebral blood vessels. To obtain a standardized 3D visualization, digital videos are automatically generated. The time-consuming video production caused by the manual delineation of structures, software based volume rendering, and the interactive definition of an optimized camera path is considerably improved with a fully automatic strategy. Therefore, a previously suggested approach (C. Rezk-Salama, 2000) is applied which uses an optimized transfer function as a template and automatically adapts it to an individual dataset. Furthermore, we introduce hardware-accelerated morphologic filtering in order to detect the location of mid-size and giant aneurysms. The actual generation of the video is finally integrated into a hardware accelerated off-screen rendering process based on 3D texture mapping, ensuring fast visualization of high quality. Overall, clinical routine can be considerably assisted by providing a Web based service combining automatic detection and standardized visualization.",Sabine Iserhardt-Bauer;Peter Hastreiter;Thomas Ertl;K. Eberhardt;Bernd Tomandl,S. Iserhardt-Bauer;P. Hastreiter;T. Ertl;K. Eberhardt;B. Tomandl,"Visualization and Interactive Systems Group, University of Stuttgart, Germany;Neurocenter, University of Erlangen Nuremberg, Germany;Visualization and Interactive Systems Group, University of Stuttgart, Germany;Division of Neuroradiology, University of Erlangen Nuremberg, Germany;Division of Neuroradiology, University of Erlangen Nuremberg, Germany",10.1109/visual.2000.885729;10.1109/visual.2000.885729,"Medical visualization, segmentation, automatic web service, video generation",15.0,2.0,11.0,128.0,,,computer tomography angiography;based 3d texture;video production caused;based service combining;definition,0.5708;0.4086;0.1848;0.0836;0.0123,"[np.int64(-1), -1, -1, -1, -1]",33;-1;-1;-1;-1,33,33,Medical Imaging Analysis
VAST,2014,Transforming Scagnostics to Reveal Hidden Features,10.1109/tvcg.2014.2346572,http://dx.doi.org/10.1109/TVCG.2014.2346572,1624.0,1632.0,J,"Scagnostics (Scatterplot Diagnostics) were developed by Wilkinson et al. based on an idea of Paul and John Tukey, in order to discern meaningful patterns in large collections of scatterplots. The Tukeys' original idea was intended to overcome the impediments involved in examining large scatterplot matrices (multiplicity of plots and lack of detail). Wilkinson's implementation enabled for the first time scagnostics computations on many points as well as many plots. Unfortunately, scagnostics are sensitive to scale transformations. We illustrate the extent of this sensitivity and show how it is possible to pair statistical transformations with scagnostics to enable discovery of hidden structures in data that are not discernible in untransformed visualizations.",Dang Tuan Nhon;Leland Wilkinson,Tuan Nhon Dang;Leland Wilkinson,"Department of Computer Science, University of Illinois at Chicago;Department of Computer Science, University of Illinois at Chicago",10.1109/tvcg.2006.163;10.1109/infvis.2005.1532142;10.1109/tvcg.2013.187;10.1109/tvcg.2011.167;10.1109/vast.2006.261423;10.1109/tvcg.2010.184;10.1109/vast.2011.6102437;10.1109/vast.2007.4389006;10.1109/tvcg.2006.163,"Scagnostics, Scatterplot matrix, Transformation, High-Dimensional Visual Analytics",46.0,26.0,44.0,783.0,,,scatterplot diagnostics developed;sensitive scale transformations;patterns large collections;multiplicity;al,0.6910;0.4130;0.2866;0.1130;0.0049,"[np.int64(-1), -1, -1, -1, -1]",68;-1;-1;-1;-1,68,68,Scatterplot Visualization
Vis,1995,"Defining, computing, and visualizing molecular interfaces",10.1109/visual.1995.480793,http://dx.doi.org/10.1109/VISUAL.1995.480793,36.0,,C,"A parallel, analytic approach for defining and computing the inter and intra molecular interfaces in three dimensions is described. The molecular interface surfaces are derived from approximations to the power diagrams over the participating molecular units. For a given molecular interface our approach can generate a family of interface surfaces parametrized by /spl alpha/ and /spl beta/, where /spl alpha/ is the radius of the solvent molecule (also known as the probe radius) and /spl beta/ is the interface radius that defines the size of the molecular interface. Molecular interface surfaces provide biochemists with a powerful tool to study surface complementarity and to efficiently characterize the interactions during a protein substrate docking. The complexity of our algorithm for molecular environments is O(nk log/sup 2/ k), where n is the number of atoms in the participating molecular units and k is the average number of neighboring atoms-a constant, given /spl alpha/ and /spl beta/.",Amitabh Varshney;Frederick P. Brooks Jr.;David C. Richardson;William V. Wright;Dinesh Manocha,A. Varshney;F.P. Brooks;D.C. Richardson;W.V. Wright;D. Manocha,"Department of Computer Science, State University of New York, Stony Brook, Stony Brook, NY, USA;Department of Computer Science, University of North Carolina, Chapel Hill, Chapel Hill, NC, USA;Department of Biochemistry, Duke University Medical Center, Durham, NC, USA;Department of Computer Science, University of North Carolina, Chapel Hill, Chapel Hill, NC, USA;Department of Computer Science, University of North Carolina, Chapel Hill, Chapel Hill, NC, USA",10.1109/visual.1993.398878;10.1109/visual.1993.398878,,45.0,7.0,19.0,91.0,,,molecular interface approach;docking complexity algorithm;parallel;environments nk;log sup number,0.7336;0.3866;0.0905;0.0317;-0.0299,"[np.int64(-1), -1, -1, -1, -1]",115;-1;-1;-1;-1,115,115,Structural Connectivity Analysis
Vis,1997,The multilevel finite element method for adaptive mesh optimization and visualization of volume data,10.1109/visual.1997.663907,http://dx.doi.org/10.1109/VISUAL.1997.663907,387.0,394.0,C,"Multilevel representations and mesh reduction techniques have been used for accelerating the processing and the rendering of large datasets representing scalar- or vector-valued functions defined on complex 2D or 3D meshes. We present a method based on finite element approximations which combines these two approaches in a new and unique way that is conceptually simple and theoretically sound. The main idea is to consider mesh reduction as an approximation problem in appropriate finite element spaces. Starting with a very coarse triangulation of the functional domain, a hierarchy of highly non-uniform tetrahedral (or triangular in 2D) meshes is generated adaptively by local refinement. This process is driven by controlling the local error of the piecewise linear finite element approximation of the function on each mesh element. A reliable and efficient computation of the global approximation error and a multilevel preconditioned conjugate gradient solver are the key components of the implementation. In order to analyze the properties and advantages of the adaptively generated tetrahedral meshes, we implemented two volume visualization algorithms: an iso-surface extractor and a ray-caster. Both algorithms, while conceptually simple, show significant speedups over conventional methods delivering comparable rendering quality from adaptively compressed datasets.",Roberto Grosso;Christoph Lürig;Thomas Ertl,R. Grosso;C. Lurig;T. Ertl,"Computer Graphics Group, Universität Erlangen Nürnberg, Germany;Computer Graphics Group, Universität Erlangen Nürnberg, Germany;Computer Graphics Group, Universität Erlangen Nürnberg, Germany",10.1109/visual.1996.568127;10.1109/visual.1996.568124;10.1109/visual.1995.480805;10.1109/visual.1996.568121;10.1109/visual.1993.398852;10.1109/visual.1995.480806;10.1109/visual.1996.567606;10.1109/visual.1996.568127,,133.0,38.0,32.0,281.0,,,mesh reduction techniques;multilevel representations;tetrahedral triangular 2d;scalar vector valued;approximation error,0.6374;0.3242;0.3191;0.1507;0.1277,"[np.int64(-1), -1, -1, -1, -1]",79;-1;-1;-1;-1,79,79,Mesh Simplification Techniques
Vis,2009,Multimodal Vessel Visualization of Mouse Aorta PET/CT Scans,10.1109/tvcg.2009.169,http://dx.doi.org/10.1109/TVCG.2009.169,1515.0,1522.0,J,"In this paper, we present a visualization system for the visual analysis of PET/CT scans of aortic arches of mice. The system has been designed in close collaboration between researchers from the areas of visualization and molecular imaging with the objective to get deeper insights into the structural and molecular processes which take place during plaque development. Understanding the development of plaques might lead to a better and earlier diagnosis of cardiovascular diseases, which are still the main cause of death in the western world. After motivating our approach, we will briefly describe the multimodal data acquisition process before explaining the visualization techniques used. The main goal is to develop a system which supports visual comparison of the data of different species. Therefore, we have chosen a linked multi-view approach, which amongst others integrates a specialized straightened multipath curved planar reformation and a multimodal vessel flattening technique. We have applied the visualization concepts to multiple data sets, and we will present the results of this investigation.",Timo Ropinski;Sven Hermann;Rainer Reich;Michael Schäfers 0001;Klaus H. Hinrichs,Timo Ropinski;Sven Hermann;Rainer Reich;Michael Schafers;Klaus Hinrichs,"Visualization and Computer Graphics Research Group (VisCG), University of Münster, Germany;University of Münster, Germany;Visualization and Computer Graphics Research Group (VisCG), University of Münster, Germany;European Institute of Molecular Imaging, Germany;Visualization and Computer Graphics Research Group (VisCG), University of Münster, Germany",10.1109/visual.2003.1250353;10.1109/visual.1992.235203;10.1109/tvcg.2007.70576;10.1109/visual.2004.104;10.1109/visual.2003.1250384;10.1109/visual.2001.964538;10.1109/tvcg.2007.70560;10.1109/visual.2002.1183754;10.1109/visual.2003.1250396;10.1109/visual.2003.1250353,"Vessel visualization, plaque growth, multipath CPR, vessel flattening",42.0,22.0,36.0,501.0,,,multimodal vessel flattening;visual comparison data;plaques lead better;arches mice;development understanding development,0.6502;0.3413;0.2385;0.2274;0.0214,"[np.int64(-1), -1, -1, -1, -1]",38;-1;-1;-1;-1,38,38,3D Medical Visualization
Vis,2007,Topological Visualization of Brain Diffusion MRI Data,10.1109/tvcg.2007.70602,http://dx.doi.org/10.1109/TVCG.2007.70602,1496.0,1503.0,J,"Topological methods give concise and expressive visual representations of flow fields. The present work suggests a comparable method for the visualization of human brain diffusion MRI data. We explore existing techniques for the topological analysis of generic tensor fields, but find them inappropriate for diffusion MRI data. Thus, we propose a novel approach that considers the asymptotic behavior of a probabilistic fiber tracking method and define analogs of the basic concepts of flow topology, like critical points, basins, and faces, with interpretations in terms of brain anatomy. The resulting features are fuzzy, reflecting the uncertainty inherent in any connectivity estimate from diffusion imaging. We describe an algorithm to extract the new type of features, demonstrate its robustness under noise, and present results for two regions in a diffusion MRI dataset to illustrate that the method allows a meaningful visual analysis of probabilistic fiber tracking results.",Thomas Schultz 0001;Holger Theisel;Hans-Peter Seidel,Thomas Schultz;Holger Theisel;Hans-Peter Seidel,"MPI Informatik Saarbrücken, Saarbruecken, Germany;BieGraph Group, Bielefeld University, Germany;MPI Informatik Saarbrücken, Saarbruecken, Germany",10.1109/visual.1999.809894;10.1109/visual.2005.1532777;10.1109/visual.2005.1532841;10.1109/visual.1994.346326;10.1109/visual.2005.1532778;10.1109/visual.1994.346326;10.1109/visual.1999.809894,"Diffusion tensor, probabilistic fiber tracking, tensor topology, uncertainty visualization",64.0,42.0,32.0,477.0,,,brain diffusion mri;existing techniques topological;tensor fields;probabilistic fiber;define analogs,0.6290;0.4574;0.4072;0.3331;0.0629,"[np.int64(-1), -1, -1, -1, -1]",39;-1;-1;-1;-1,39,39,Diffusion MRI Analysis
InfoVis,2020,Rainbows Revisited: Modeling Effective Colormap Design for Graphical Inference,10.1109/tvcg.2020.3030439,http://dx.doi.org/10.1109/TVCG.2020.3030439,1032.0,1042.0,J,"Color mapping is a foundational technique for visualizing scalar data. Prior literature offers guidelines for effective colormap design, such as emphasizing luminance variation while limiting changes in hue. However, empirical studies of color are largely focused on perceptual tasks. This narrow focus inhibits our understanding of how generalizable these guidelines are, particularly to tasks like visual inference that require synthesis and judgement across multiple percepts. Furthermore, the emphasis on traditional ramp designs (e.g., sequential or diverging) may sideline other key metrics or design strategies. We study how a cognitive metric-color name variation-impacts people's ability to make model-based judgments. In two graphical inference experiments, participants saw a series of color-coded scalar fields sampled from different models and assessed the relationships between these models. Contrary to conventional guidelines, participants were more accurate when viewing colormaps that cross a variety of uniquely nameable colors. We modeled participants' performance using this metric and found that it provides a better fit to the experimental data than do existing design principles. Our findings indicate cognitive advantages for colorful maps like rainbow, which exhibit high color categorization, despite their traditionally undesirable perceptual properties. We also found no evidence that color categorization would lead observers to infer false data features. Our results provide empirically grounded metrics for predicting a colormap's performance and suggest alternative guidelines for designing new quantitative colormaps to support inference. The data and materials for this paper are available at: https://osf.io/tck2r/",Khairi Reda;Danielle Albers Szafir,Khairi Reda;Danielle Albers Szafir,"University of Colorado, Boulder;University-Purdue University, Indianapolis",10.1109/visual.1995.480803;10.1109/tvcg.2011.192;10.1109/tvcg.2017.2743978;10.1109/tvcg.2016.2598918;10.1109/tvcg.2012.230;10.1109/tvcg.2014.2346325;10.1109/tvcg.2016.2599106;10.1109/visual.2001.964510;10.1109/tvcg.2015.2467471;10.1109/tvcg.2019.2934284;10.1109/tvcg.2017.2744359;10.1109/tvcg.2010.161;10.1109/visual.1995.480803,"Color,perception,graphical inference,scalar data",18.0,29.0,68.0,1151.0,,,cognitive metric color;variety uniquely nameable;traditional ramp designs;scalar fields sampled;series,0.6480;0.2149;0.1770;0.0889;0.0410,"[np.int64(-1), -1, -1, -1, -1]",29;-1;-1;-1;-1,29,29,Colormap Interpretation
Vis,1994,"Visualization and geographic information system integration: what are the needs and the requirements, if any?",10.1109/visual.1994.346284,http://dx.doi.org/10.1109/VISUAL.1994.346284,400.0,403.0,M,"Addresses the needs and requirements of integrating visualization and geographic information system technologies. There are three levels of integration methods: rudimentary, operational and functional. The rudimentary approach uses the minimum amount of data sharing and exchange between these two technologies. The operational level attempts to provide consistency of the data while removing redundancies between the two technologies. The functional form attempts to provide transparent communication between these respective software environments. At this level, the user only needs to request information and the integrated system retrieves or generates the information depending upon the request. This paper examines the role and impact of these three levels of integration. Stepping further into the future, the paper also questions the long-term survival of these separate disciplines.&lt;&lt;ETX&gt;&gt;",Theresa-Marie Rhyne;William Ivey;Loey Knapp;Peter Kochevar;Tom Mace,T.M. Rhyne;W. Ivey;L. Knapp;P. Kochevar;T. Mace,"Martin Marietta, U. S. EPA Visualization Center;SAS Institute, Inc.;IBM and University of Colorado, USA;DEC, San Diego Supercomputing Center;Scientific Computing Branch, U.S. EPA",,,29.0,2.0,3.0,112.0,,,integrating visualization geographic;technologies levels;minimum data sharing;retrieves generates;paper questions long,0.8077;0.2526;0.1851;-0.0067;-0.0702,"[np.int64(-1), -1, -1, -1, -1]",132;-1;-1;-1;-1,132,132,Geographic Visualization Techniques
InfoVis,2011,"Angular Histograms: Frequency-Based Visualizations for Large, High Dimensional Data",10.1109/tvcg.2011.166,http://dx.doi.org/10.1109/TVCG.2011.166,2572.0,2580.0,J,"Parallel coordinates is a popular and well-known multivariate data visualization technique. However, one of their inherent limitations has to do with the rendering of very large data sets. This often causes an overplotting problem and the goal of the visual information seeking mantra is hampered because of a cluttered overview and non-interactive update rates. In this paper, we propose two novel solutions, namely, angular histograms and attribute curves. These techniques are frequency-based approaches to large, high-dimensional data visualization. They are able to convey both the density of underlying polylines and their slopes. Angular histogram and attribute curves offer an intuitive way for the user to explore the clustering, linear correlations and outliers in large data sets without the over-plotting and clutter problems associated with traditional parallel coordinates. We demonstrate the results on a wide variety of data sets including real-world, high-dimensional biological data. Finally, we compare our methods with the other popular frequency-based algorithms.",Zhao Geng;Zhenmin Peng;Robert S. Laramee;Jonathan C. Roberts;Rick Walker,Zhao Geng;ZhenMin Peng;Robert S.Laramee;Jonathan C. Roberts;Rick Walker,"Visual Computing Group, Swansea University, UK;Visual Computing Group, Swansea University, UK;Swansea University, UK;Bangor University, UK;Visual Computing Group, Swansea University, UK",10.1109/infvis.2002.1173157;10.1109/infvis.2004.68;10.1109/tvcg.2006.138;10.1109/tvcg.2007.70535;10.1109/visual.1999.809866;10.1109/infvis.1996.559216;10.1109/visual.1990.146402;10.1109/tvcg.2010.184;10.1109/infvis.2005.1532138;10.1109/tvcg.2006.170;10.1109/tvcg.2008.131;10.1109/infvis.2002.1173157,"Parallel Coordinates, Angular Histogram, Attribute Curves",77.0,33.0,28.0,1702.0,,,multivariate data visualization;polylines slopes angular;frequency;causes overplotting;non interactive update,0.6891;0.3585;0.1235;0.0522;0.0134,"[np.int64(-1), -1, -1, -1, -1]",93;-1;-1;-1;-1,93,93,Multivariate Data Visualization
Vis,2010,VDVR: Verifiable Volume Visualization of Projection-Based Data,10.1109/tvcg.2010.211,http://dx.doi.org/10.1109/TVCG.2010.211,1515.0,1524.0,J,"Practical volume visualization pipelines are never without compromises and errors. A delicate and often-studied component is the interpolation of off-grid samples, where aliasing can lead to misleading artifacts and blurring, potentially hiding fine details of critical importance. The verifiable visualization framework we describe aims to account for these errors directly in the volume generation stage, and we specifically target volumetric data obtained via computed tomography (CT) reconstruction. In this case the raw data are the X-ray projections obtained from the scanner and the volume data generation process is the CT algorithm. Our framework informs the CT reconstruction process of the specific filter intended for interpolation in the subsequent visualization process, and this in turn ensures an accurate interpolation there at a set tolerance. Here, we focus on fast trilinear interpolation in conjunction with an octree-type mixed resolution volume representation without T-junctions. Efficient rendering is achieved by a space-efficient and locality-optimized representation, which can straightforwardly exploit fast fixed-function pipelines on GPUs.",Ziyi Zheng;Wei Xu 0020;Klaus Mueller 0001,Ziyi Zheng;Wei Xu;Klaus Mueller,"Center of Visual Computing, Stony Brook University, USA;Center of Visual Computing, Stony Brook University, USA;Center of Visual Computing, Stony Brook University, USA",10.1109/visual.1999.809908;10.1109/visual.1991.175805;10.1109/tvcg.2009.194;10.1109/tvcg.2006.141;10.1109/visual.1994.346331;10.1109/visual.2004.70;10.1109/tvcg.2009.149;10.1109/visual.1999.809908,"Direct volume rendering, computed tomography, filtered back-projection, verifiable visualization ",13.0,5.0,36.0,338.0,,,practical volume visualization;tomography ct reconstruction;filter intended interpolation;function pipelines gpus;exploit fast fixed,0.6427;0.4924;0.2875;0.2786;-0.0133,"[np.int64(-1), -1, -1, -1, -1]",54;-1;-1;-1;-1,54,54,Volume Visualization Techniques
Vis,1991,Designing a distributed scientific visualization tool,10.1109/visual.1991.175835,http://dx.doi.org/10.1109/VISUAL.1991.175835,383.0,386.0,C,"The benefits of using a distributed scientific visualization tool in the field of acoustic modeling are demonstrated. A user-friendly interface was developed under SunView. A Remote Procedure Call was used for transparent data transfer between a CRAY X-MP/28 and Sun 4 workstation. PV-WAVE, a high-level graphics package, was used to visualize the results.&lt;&lt;ETX&gt;&gt;",L. van der Sluis,L.V. Sluis,"Technology Applications, Inc.",,,1.0,0.0,4.0,42.0,,,acoustic modeling demonstrated;scientific visualization tool;sunview remote procedure;benefits using distributed;28 sun,0.6136;0.5654;0.2888;0.1511;-0.0143,"[np.int64(-1), np.int64(-1), -1, -1, -1]",19;84;-1;-1;-1,19;84,19,Sound Propagation Modeling
InfoVis,2004,Building Highly-Coordinated Visualizations in Improvise,10.1109/infvis.2004.12,http://dx.doi.org/10.1109/INFVIS.2004.12,159.0,166.0,C,"Improvise is a fully-implemented system in which users build and browse multiview visualizations interactively using a simple shared-object coordination mechanism coupled with a flexible, expression-based visual abstraction language. By coupling visual abstraction with coordination, users gain precise control over how navigation and selection in the visualization affects the appearance of data in individual views. As a result, it is practical to build visualizations with more views and richer coordination in Improvise than in other visualization systems. Building and browsing activities are integrated in a single, live user interface that lets users alter visualizations quickly and incrementally during data exploration",Chris E. Weaver,C. Weaver,"Computer Science Department, University of Wisconsin, Madison, USA",10.1109/infvis.2002.1173141;10.1109/infvis.2000.885086;10.1109/infvis.2002.1173141,"coordinated queries, coordination, exploratory visualization, multiple views, visual abstraction language",320.0,101.0,23.0,1026.0,,,visualizations interactively;build browse multiview;coordination mechanism coupled;expression;single live user,0.7397;0.4057;0.1154;0.0917;-0.0153,"[np.int64(-1), -1, -1, -1, -1]",110;-1;-1;-1;-1,110,110,Interactive Visualization
Vis,2008,Visualizing Particle/Flow Structure Interactions in the Small Bronchial Tubes,10.1109/tvcg.2008.183,http://dx.doi.org/10.1109/TVCG.2008.183,1412.0,1427.0,J,"Particle deposition in the small bronchial tubes (generations six through twelve) is strongly influenced by the vortex-dominated secondary flows that are induced by axial curvature of the tubes. In this paper, we employ particle destination maps in conjunction with two-dimensional, finite-time Lyapunov exponent maps to illustrate how the trajectories of finite-mass particles are influenced by the presence of vortices. We consider two three-generation bronchial tube models: a planar, asymmetric geometry and a non-planar, asymmetric geometry. Our visualizations demonstrate that these techniques, coupled with judiciously seeded particle trajectories, are effective tools for studying particle/flow structure interactions.",Bela Soni;David S. Thompson;Raghu Machiraju,Bela Soni;David Thompson;Raghu Machiraju,"Graduate Research Assistant at the Computational Simulation and Design Center, Mississippi State University, USA;Department of Aerospace Engineering, Mississippi State University, USA;Department of Computer Science and Engineering, Ohio State Uinversity, USA",10.1109/tvcg.2007.70551;10.1109/tvcg.2007.70554;10.1109/tvcg.2007.70551,"FTLE, particle trajectory, visualization, bronchial tube",27.0,17.0,30.0,335.0,,,studying particle flow;generation bronchial tube;lyapunov exponent maps;geometry non planar;judiciously,0.5979;0.4257;0.2888;0.0252;0.0074,"[np.int64(-1), -1, -1, -1, -1]",20;-1;-1;-1;-1,20,20,Particle Flow Analysis
VAST,2015,"The Role of Uncertainty, Awareness, and Trust in Visual Analytics",10.1109/tvcg.2015.2467591,http://dx.doi.org/10.1109/TVCG.2015.2467591,240.0,249.0,J,"Visual analytics supports humans in generating knowledge from large and often complex datasets. Evidence is collected, collated and cross-linked with our existing knowledge. In the process, a myriad of analytical and visualisation techniques are employed to generate a visual representation of the data. These often introduce their own uncertainties, in addition to the ones inherent in the data, and these propagated and compounded uncertainties can result in impaired decision making. The user's confidence or trust in the results depends on the extent of user's awareness of the underlying uncertainties generated on the system side. This paper unpacks the uncertainties that propagate through visual analytics systems, illustrates how human's perceptual and cognitive biases influence the user's awareness of such uncertainties, and how this affects the user's trust building. The knowledge generation model for visual analytics is used to provide a terminology and framework to discuss the consequences of these aspects in knowledge construction and though examples, machine uncertainty is compared to human trust measures with provenance. Furthermore, guidelines for the design of uncertainty-aware systems are presented that can aid the user in better decision making.",Dominik Sacha;Hansi Senaratne;Bum Chul Kwon;Geoffrey P. Ellis;Daniel A. Keim,Dominik Sacha;Hansi Senaratne;Bum Chul Kwon;Geoffrey Ellis;Daniel A. Keim,"Data Analysis and Visualisation Group, University of Konstanz;Data Analysis and Visualisation Group, University of Konstanz;Data Analysis and Visualisation Group, University of Konstanz;Data Analysis and Visualisation Group, University of Konstanz;Data Analysis and Visualisation Group, University of Konstanz",10.1109/tvcg.2014.2346575;10.1109/visual.2000.885679;10.1109/vast.2008.4677385;10.1109/vast.2009.5332611;10.1109/tvcg.2012.260;10.1109/vast.2011.6102473;10.1109/vast.2009.5333020;10.1109/vast.2011.6102435;10.1109/tvcg.2012.279;10.1109/tvcg.2014.2346481;10.1109/vast.2006.261416;10.1109/tvcg.2014.2346575,"Visual Analytics, Knowledge Generation, Uncertainty Measures and Propagation, Trust Building, Human Factors",261.0,180.0,83.0,4217.0,,,visual analytics systems;trust building knowledge;uncertainties result impaired;employed generate;terminology,0.5819;0.3769;0.3494;0.1029;0.0850,"[np.int64(-1), -1, -1, -1, -1]",108;-1;-1;-1;-1,108,108,Visual Analytics
InfoVis,2020,Responsive Matrix Cells: A Focus+Context Approach for Exploring and Editing Multivariate Graphs,10.1109/tvcg.2020.3030371,http://dx.doi.org/10.1109/TVCG.2020.3030371,1644.0,1654.0,J,"Matrix visualizations are a useful tool to provide a general overview of a graph's structure. For multivariate graphs, a remaining challenge is to cope with the attributes that are associated with nodes and edges. Addressing this challenge, we propose responsive matrix cells as a focus+context approach for embedding additional interactive views into a matrix. Responsive matrix cells are local zoomable regions of interest that provide auxiliary data exploration and editing facilities for multivariate graphs. They behave responsively by adapting their visual contents to the cell location, the available display space, and the user task. Responsive matrix cells enable users to reveal details about the graph, compare node and edge attributes, and edit data values directly in a matrix without resorting to external views or tools. We report the general design considerations for responsive matrix cells covering the visual and interactive means necessary to support a seamless data exploration and editing. Responsive matrix cells have been implemented in a web-based prototype based on which we demonstrate the utility of our approach. We describe a walk-through for the use case of analyzing a graph of soccer players and report on insights from a preliminary user feedback session.",Tom Horak;Philip Berger;Heidrun Schumann;Raimund Dachselt;Christian Tominski,Tom Horak;Philip Berger;Heidrun Schumann;Raimund Dachselt;Christian Tominski,"Interactive Media Lab, Technische Universitat Dresden;Inst. for Visual & Analytic Computing, University of Rostock;Inst. for Visual & Analytic Computing, University of Rostock;Interactive Media Lab, Technische Universitat Dresden;Inst. for Visual & Analytic Computing, University of Rostock",10.1109/tvcg.2006.120;10.1109/tvcg.2017.2743990;10.1109/tvcg.2014.2346575;10.1109/tvcg.2011.213;10.1109/tvcg.2007.70582;10.1109/infvis.2004.2;10.1109/tvcg.2008.109;10.1109/tvcg.2018.2865151;10.1109/infvis.2002.1173149;10.1109/tvcg.2009.151;10.1109/tvcg.2018.2865149;10.1109/tvcg.2014.2346279;10.1109/tvcg.2017.2745219;10.1109/tvcg.2014.2346441;10.1109/tvcg.2015.2467202;10.1109/tvcg.2006.120,"Multivariate graph visualization,matrix visualization,focus+context,embedded visualizations,responsive visualization,graph editing",7.0,14.0,83.0,1479.0,,,matrix visualizations;node edge attributes;editing responsive;soccer players report;contents cell,0.6361;0.3167;0.2746;0.1788;0.1482,"[np.int64(-1), -1, -1, -1, -1]",95;-1;-1;-1;-1,95,95,Table-Based Visualizations
Vis,1990,Personal visualization system: applications in research and engineering,10.1109/visual.1990.146418,http://dx.doi.org/10.1109/VISUAL.1990.146418,443.0,,C,"The authors describe an innovative personal visualization system and its application to several research and engineering problems. The system bridges both hardware and software components to permit a user to graphically describe a visualization problem to the computer; thereby reducing program development time to a few hours. Low-cost visualization is achieved using PC-based software that can either be executed on a PC or drive graphic workstations for high-resolution displays. In either case, supercomputer computation rates are available for the visualization process. On PCs this is done with one or more PiP plug in cards, each of which is capable of 100 million floating point operations per second. On workstations this is done with the QUEN array processor. Applications mentioned include: ocean wave imaging; characterizing superconductors; and solar sail visualization.&lt;&lt;ETX&gt;&gt;",Quentin E. Dolecek;K. Moorjani;B. F. Kim;D. G. Tilley;Thomas S. Denney Jr.,Q.E. Dolecek;K. Moorjani;B.F. Kim;D.G. Tilley;T.S. Denney,"Applied Physics Laboratory, Johns Hopkins University, Laurel, MD, USA;Applied Physics Laboratory, Johns Hopkins University, Laurel, MD, USA;Applied Physics Laboratory, Johns Hopkins University, Laurel, MD, USA;Applied Physics Laboratory, Johns Hopkins University, Laurel, MD, USA;Applied Physics Laboratory, Johns Hopkins University, Laurel, MD, USA",,,0.0,0.0,9.0,54.0,,,solar sail visualization;resolution displays;characterizing superconductors;software executed pc;authors innovative personal,0.6115;0.2156;0.1910;0.1628;0.0885,"[np.int64(-1), -1, -1, -1, -1]",66;-1;-1;-1;-1,66,66,Aerospace Visualizations
Vis,2000,New techniques for topologically correct surface reconstruction,10.1109/visual.2000.885718,http://dx.doi.org/10.1109/VISUAL.2000.885718,373.0,380.0,C,"We present a novel approach to surface reconstruction based on the Delaunay complex. First we give a simple and fast algorithm that picks locally a surface at each vertex. For that, we introduce the concept of /spl lambda/-intervals. It turns out that for smooth regions of the surface this method works very well and at difficult parts of the surface yields an output well-suited for postprocessing. As a postprocessing step we propose a topological clean up and a new technique based on linear programming in order to establish a topologically correct surface. These techniques should be useful also for many other reconstruction schemes.",Udo Adamy;Joachim Giesen;Matthias John 0003,U. Adamy;J. Giesen;M. John,"Institute of Theoretical Computer Science, Zurich, Switzerland;Institute of Theoretical Computer Science, Switzerland;Institute of Theoretical Computer Science, Switzerland",10.1109/visual.1998.745286;10.1109/visual.1998.745286,"surface reconstruction, gabriel graph, linear programming, topology",65.0,12.0,18.0,85.0,,,reconstruction based delaunay;topologically correct surface;complex simple;postprocessing postprocessing step;picks,0.7101;0.4721;0.1995;0.0687;0.0191,"[np.int64(-1), -1, -1, -1, -1]",75;-1;-1;-1;-1,75,75,Surface Reconstruction Techniques
Vis,2011,Interactive Multiscale Tensor Reconstruction for Multiresolution Volume Visualization,10.1109/tvcg.2011.214,http://dx.doi.org/10.1109/TVCG.2011.214,2135.0,2143.0,J,"Large scale and structurally complex volume datasets from high-resolution 3D imaging devices or computational simulations pose a number of technical challenges for interactive visual analysis. In this paper, we present the first integration of a multiscale volume representation based on tensor approximation within a GPU-accelerated out-of-core multiresolution rendering framework. Specific contributions include (a) a hierarchical brick-tensor decomposition approach for pre-processing large volume data, (b) a GPU accelerated tensor reconstruction implementation exploiting CUDA capabilities, and (c) an effective tensor-specific quantization strategy for reducing data transfer bandwidth and out-of-core memory footprint. Our multiscale representation allows for the extraction, analysis and display of structural features at variable spatial scales, while adaptive level-of-detail rendering methods make it possible to interactively explore large datasets within a constrained memory footprint. The quality and performance of our prototype system is evaluated on large structurally complex datasets, including gigabyte-sized micro-tomographic volumes.",Susanne K. Suter;José Antonio Iglesias Guitián;Fabio Marton;Marco Agus;Andreas Elsener;Christoph P. E. Zollikofer;Meenakshisundaram Gopi;Enrico Gobbetti;Renato Pajarola,Susanne K. Suter;Jose A. Iglesias Guitian;Fabio Marton;Marco Agus;Andreas Elsener;Christoph P.E. Zollikofer;M. Gopi;Enrico Gobbetti;Renato Pajarola,"University of Zurich, Switzerland;CRS4, Italy;CRS4, Italy;CRS4, Italy;University of Zurich, Switzerland;University of Zurich, Switzerland;University of California, Irvine, USA;CRS4, Italy;University of Zurich, Switzerland",10.1109/visual.2002.1183757;10.1109/visual.1997.663900;10.1109/tvcg.2007.70516;10.1109/visual.1998.745311;10.1109/tvcg.2006.146;10.1109/visual.2003.1250385;10.1109/visual.2002.1183757,"GPU/CUDA, multiscale, tensor reconstruction, interactive volume visualization, multiresolution rendering",63.0,39.0,28.0,838.0,,,volume data gpu;scale structurally complex;specific quantization strategy;including;prototype evaluated,0.6273;0.3216;0.1969;-0.0108;-0.0184,"[np.int64(-1), -1, -1, -1, -1]",111;-1;-1;-1;-1,111,111,3D Data Processing
InfoVis,2004,Value and Relation Display for Interactive Exploration of High Dimensional Datasets,10.1109/infvis.2004.71,http://dx.doi.org/10.1109/INFVIS.2004.71,73.0,80.0,C,"Traditional multidimensional visualization techniques, such as glyphs, parallel coordinates and scatterplot matrices, suffer from clutter at the display level and difficult user navigation among dimensions when visualizing high dimensional datasets. In this paper, we propose a new multidimensional visualization technique named a value and relation (VaR) display, together with a rich set of navigation and selection tools, for interactive exploration of datasets with up to hundreds of dimensions. By explicitly conveying the relationships among the dimensions of a high dimensional dataset, the VaR display helps users grasp the associations among dimensions. By using pixel-oriented techniques to present values of the data items in a condensed manner, the VaR display reveals data patterns in the dataset using as little screen space as possible. The navigation and selection tools enable users to interactively reduce clutter, navigate within the dimension space, and examine data value details within context effectively and efficiently. The VaR display scales well to datasets with large numbers of data items by employing sampling and texture mapping. A case study on a real dataset, as well as the VaR displays of multiple real datasets throughout the paper, reveals how our proposed approach helps users interactively explore high dimensional datasets with large numbers of data items",Jing Yang 0001;Anilkumar Patro;Shiping Huang;Nishant K. Mehta;Matthew O. Ward;Elke A. Rundensteiner,Jing Yang;A. Patro;Shiping Huang;N. Mehta;M.O. Ward;E.A. Rundensteiner,"Computer Science Department, Worcester Polytechnic Institute, Worcester, MA, USA;Computer Science Department, Worcester Polytechnic Institute, Worcester, MA, USA;Computer Science Department, Worcester Polytechnic Institute, Worcester, MA, USA;Computer Science Department, Worcester Polytechnic Institute, Worcester, MA, USA;Computer Science Department, Worcester Polytechnic Institute, Worcester, MA, USA;Computer Science Department, Worcester Polytechnic Institute, Worcester, MA, USA",10.1109/infvis.1998.729559;10.1109/infvis.2003.1249015;10.1109/visual.1994.346302;10.1109/infvis.2003.1249014;10.1109/infvis.1995.528686;10.1109/visual.1995.485140;10.1109/infvis.1998.729559,"Multi-dimensional visualization, pixel-oriented, multi-dimensional scaling, high dimensional datasets",85.0,18.0,24.0,517.0,,,traditional multidimensional visualization;display reveals data;named value relation;helps users;set,0.7105;0.3073;0.2377;0.2026;0.0241,"[np.int64(-1), -1, -1, -1, -1]",93;-1;-1;-1;-1,93,93,Multivariate Data Visualization
Vis,2002,Case study: Visualizing ocean flow vertical motions using Lagrangian-Eulerian time surfaces,10.1109/visual.2002.1183822,http://dx.doi.org/10.1109/VISUAL.2002.1183822,529.0,532.0,C,"Ocean model simulations commonly assume the ocean is hydrostatic, resulting in near zero vertical motion. The vertical motion found is typically associated with the variations of the thermocline depth over time, which are mainly a result of the development and movement of ocean fronts, eddies, and internal waves. A new technique, extended from Lagrangian-Eulerian Advection, is presented to help understand the variation of vertical motion associated with the change in thermocline depth over time. A time surface is correctly deformed in a single direction according to the flow. The evolution of the time surface is computed via a mixture of Eulerian and Lagrangian techniques. The dominant horizontal motion is textured onto the surface using texture advection, while both the horizontal and vertical motions are used to displace the surface. The resulting surface is shaded for enhanced contrast. Timings indicate that the overhead over standard 2D texture advection is no more than 12%.",Josh Grant;Gordon Erlebacher;James F. O'Brien,J. Grant;G. Erlebacher;J. O'Brien,"Center for Ocean-Atmospheric Prediction Studies, Florida State University, USA;School of Computational Science and Information Technology, Florida State University, USA;Center for Ocean-Atmospheric Prediction Studies, Florida State University, USA",10.1109/visual.1999.809895;10.1109/visual.2001.964493;10.1109/visual.2000.885688;10.1109/visual.1996.568149;10.1109/visual.1999.809895,"unsteady vector fields, time surfaces, ocean currents, vertical velocity",18.0,5.0,16.0,122.0,,,ocean model simulations;horizontal motion textured;associated change thermocline;eulerian lagrangian techniques;evolution time,0.5942;0.5057;0.3400;0.2878;0.1801,"[np.int64(-1), np.int64(-1), -1, -1, -1]",113;140;-1;-1;-1,113;140,113,Marine Simulation Studies
InfoVis,2014,Activity Sculptures: Exploring the Impact of Physical Visualizations on Running Activity,10.1109/tvcg.2014.2352953,http://dx.doi.org/10.1109/TVCG.2014.2352953,2201.0,2210.0,J,"Data sculptures are a promising type of visualizations in which data is given a physical form. In the past, they have mostly been used for artistic, communicative or educational purposes, and designers of data sculptures argue that in such situations, physical visualizations can be more enriching than pixel-based visualizations. We present the design of Activity Sculptures: data sculptures of running activity. In a three-week field study we investigated the impact of the sculptures on 14 participants' running activity, the personal and social behaviors generated by the sculptures, as well as participants' experiences when receiving these individual physical tokens generated from the specific data of their runs. The physical rewards generated curiosity and personal experimentation but also social dynamics such as discussion on runs or envy/competition. We argue that such passive (or calm) visualizations can complement nudging and other mechanisms of persuasion with a more playful and reflective look at ones' activity.",Simon Stusak;Aurélien Tabard;Franziska Sauka;Rohit Ashok Khot;Andreas Butz,Simon Stusak;Aurélien Tabard;Franziska Sauka;Rohit Ashok Khot;Andreas Butz,"University of Munich (LMU);Université de Lyon & CNRS, Université Lyon 1, LIRIS, UMR5205, France;University of Munich (LMU);Exertion Games Lab, RMIT University;University of Munich (LMU)",10.1109/tvcg.2007.70541;10.1109/infvis.2003.1249031;10.1109/tvcg.2013.134;10.1109/tvcg.2007.70541,"Physical Visualizations, Activity Sculptures, Physical Activity, Data Sculptures, Behavioral Change",122.0,67.0,41.0,1566.0,,,activity sculptures;individual physical tokens;specific data runs;argue;past used,0.6085;0.1899;0.1848;0.1780;0.1123,"[np.int64(-1), -1, -1, -1, -1]",142;-1;-1;-1;-1,142,142,Mathematical Art
Vis,2000,Geometric compression for interactive transmission,10.1109/visual.2000.885711,http://dx.doi.org/10.1109/VISUAL.2000.885711,319.0,326.0,C,"The compression of geometric structures is a relatively new field of data compression. Since about 1995, several articles have dealt with the coding of meshes, using for most of them the following approach: the vertices of the mesh are coded in an order that partially contains the topology of the mesh. In the same time, some simple rules attempt to predict the position of each vertex from the positions of its neighbors that have been previously coded. We describe a compression algorithm whose principle is completely different: the coding order of the vertices is used to compress their coordinates, and then the topology of the mesh is reconstructed from the vertices. This algorithm achieves compression ratios that are slightly better than those of the currently available algorithms, and moreover, it allows progressive and interactive transmission of the meshes.",Olivier Devillers;Pierre-Marie Gandoin,O. Devillers;P.-M. Gandoin,"INRIA, Sophia-Antipolis, France;INRIA, Sophia-Antipolis, France",10.1109/visual.1997.663902;10.1109/visual.1999.809902;10.1109/vis.1999.10000;10.1109/visual.1997.663902,"geometry, compression, coding, interactivity, mesh, reconstruction, terrain models",187.0,76.0,18.0,339.0,,,compression geometric structures;mesh coded order;articles dealt coding;attempt predict position;completely different,0.6875;0.5249;0.1711;0.0919;-0.0491,"[np.int64(-1), np.int64(-1), -1, -1, -1]",70;126;-1;-1;-1,70;126,70,3D Geometry Compression
Vis,2024,Sportify: Question Answering with Embedded Visualizations and Personified Narratives for Sports Video,10.1109/tvcg.2024.3456332,http://dx.doi.org/10.1109/TVCG.2024.3456332,12.0,22.0,J,"As basketball's popularity surges, fans often find themselves confused and overwhelmed by the rapid game pace and complexity. Basketball tactics, involving a complex series of actions, require substantial knowledge to be fully understood. This complexity leads to a need for additional information and explanation, which can distract fans from the game. To tackle these challenges, we present Sportify, a Visual Question Answering system that integrates narratives and embedded visualization for demystifying basketball tactical questions, aiding fans in understanding various game aspects. We propose three novel action visualizations (i.e., Pass, Cut, and Screen) to demonstrate critical action sequences. To explain the reasoning and logic behind players' actions, we leverage a large-language model (LLM) to generate narratives. We adopt a storytelling approach for complex scenarios from both first and third-person perspectives, integrating action visualizations. We evaluated Sportify with basketball fans to investigate its impact on understanding of tactics, and how different personal perspectives of narratives impact the understanding of complex tactic with action visualizations. Our evaluation with basketball fans demonstrates Sportify's capability to deepen tactical insights and amplify the viewing experience. Furthermore, third-person narration assists people in getting in-depth game explanations while first-person narration enhances fans' game engagement.",Chunggi Lee;Tica Lin;Hanspeter Pfister;Zhu-Tian Chen,Chunggi Lee;Tica Lin;Hanspeter Pfister;Chen Zhu-Tian,"John A. Paulson School of Engineering and Applied Sciences, Harvard University, Cambridge, MA, USA;John A. Paulson School of Engineering and Applied Sciences, Harvard University, Cambridge, MA, USA;John A. Paulson School of Engineering and Applied Sciences, Harvard University, Cambridge, MA, USA;CSE department, University of Minnesota, Minneapolis, MN, USA",10.1109/tvcg.2020.3030358;10.1109/tvcg.2021.3114861;10.1109/vast.2014.7042478;10.1109/tvcg.2023.3326910;10.1109/tvcg.2023.3327161;10.1109/tvcg.2022.3209353;10.1109/tvcg.2013.192;10.1109/tvcg.2010.179;10.1109/tvcg.2023.3327197;10.1109/tvcg.2017.2745181;10.1109/tvcg.2019.2934630;10.1109/tvcg.2016.2598608;10.1109/tvcg.2022.3209373;10.1109/tvcg.2021.3114806,"Embedded Visualization,Narrative and storytelling,,,Basketball tactic,Question-answering (QA) system",,0.0,67.0,387.0,,,visualization demystifying basketball;answering integrates narratives;large language model;sportify capability;complex series actions,0.6367;0.4268;0.3013;0.1476;0.0899,"[np.int64(-1), -1, -1, -1, -1]",88;-1;-1;-1;-1,88,88,Sports Data Visualization
Vis,2001,Nonmanifold subdivision,10.1109/visual.2001.964528,http://dx.doi.org/10.1109/VISUAL.2001.964528,325.0,332.0,C,"Commonly-used subdivision schemes require manifold control meshes and produce manifold surfaces. However, it is often necessary to model nonmanifold surfaces, such as several surface patches meeting at a common boundary. In this paper, we describe a subdivision algorithm that makes it possible to model nonmanifold surfaces. Any triangle mesh, subject only to the restriction that no two vertices of any triangle coincide, can serve as an input to the algorithm. Resulting surfaces consist of collections of manifold patches joined along nonmanifold curves and vertices. If desired, constraints may be imposed on the tangent planes of manifold patches sharing a curve or a vertex. The algorithm is an extension of a well-known Loop subdivision scheme, and uses techniques developed for piecewise smooth surfaces.",Lexing Ying;Denis Zorin,Lexing Ying;D. Zorin,"New York University, USA;New York University, USA",10.1109/visual.1999.809870,"Subdivision surfaces, Nonmanifold surfaces, Geometric modeling",,3.0,17.0,88.0,,,manifold control meshes;subdivision scheme uses;surfaces triangle;piecewise;common,0.6513;0.4492;0.3928;0.2378;-0.0296,"[np.int64(-1), -1, -1, -1, -1]",-1;-1;-1;-1;-1,,-1,Interactive 3D Visualization
VAST,2015,MobilityGraphs: Visual Analysis of Mass Mobility Dynamics via Spatio-Temporal Graphs and Clustering,10.1109/tvcg.2015.2468111,http://dx.doi.org/10.1109/TVCG.2015.2468111,11.0,20.0,J,"Learning more about people mobility is an important task for official decision makers and urban planners. Mobility data sets characterize the variation of the presence of people in different places over time as well as movements (or flows) of people between the places. The analysis of mobility data is challenging due to the need to analyze and compare spatial situations (i.e., presence and flows of people at certain time moments) and to gain an understanding of the spatio-temporal changes (variations of situations over time). Traditional flow visualizations usually fail due to massive clutter. Modern approaches offer limited support for investigating the complex variation of the movements over longer time periods. We propose a visual analytics methodology that solves these issues by combined spatial and temporal simplifications. We have developed a graph-based method, called MobilityGraphs, which reveals movement patterns that were occluded in flow maps. Our method enables the visual representation of the spatio-temporal variation of movements for long time series of spatial situations originally containing a large number of intersecting flows. The interactive system supports data exploration from various perspectives and at various levels of detail by interactive setting of clustering parameters. The feasibility our approach was tested on aggregated mobility data derived from a set of geolocated Twitter posts within the Greater London city area and mobile phone call data records in Abidjan, Ivory Coast. We could show that MobilityGraphs support the identification of regular daily and weekly movement patterns of resident population.",Tatiana von Landesberger;Felix Brodkorb;Philipp Roskosch;Natalia V. Andrienko;Gennady L. Andrienko;Andreas Kerren,Tatiana von Landesberger;Felix Brodkorb;Philipp Roskosch;Natalia Andrienko;Gennady Andrienko;Andreas Kerren,"Technical University of Darmstadt, Germany;Technical University of Darmstadt, Germany;Technical University of Darmstadt, Germany;Fraunhofer IAIS, City University, London, UK;Fraunhofer IAIS, City University, London, UK;Fraunhofer IAIS, City University, London, UK",10.1109/tvcg.2011.202;10.1109/tvcg.2011.226;10.1109/tvcg.2011.233;10.1109/infvis.2004.18;10.1109/tvcg.2009.143;10.1109/tvcg.2014.2346271;10.1109/tvcg.2008.125;10.1109/tvcg.2014.2346441;10.1109/infvis.1999.801851;10.1109/vast.2012.6400553;10.1109/vast.2009.5333893;10.1109/infvis.2005.1532150;10.1109/tvcg.2011.202,"Visual analytics, movement data, networks, graphs, temporal aggregation, spatial aggregation, flows, clustering",211.0,159.0,56.0,4670.0,,,analysis mobility data;traditional flow visualizations;simplifications;method enables visual;different,0.6385;0.4922;0.1218;0.0676;0.0297,"[np.int64(-1), -1, -1, -1, -1]",6;-1;-1;-1;-1,6,6,Geospatial Data Analysis
InfoVis,2001,"2D vs 3D, implications on spatial memory",10.1109/infvis.2001.963291,http://dx.doi.org/10.1109/INFVIS.2001.963291,139.0,145.0,C,"Since the introduction of graphical user interfaces (GUI) and two-dimensional (2D) displays, the concept of space has entered the information technology (IT) domain. Interactions with computers were re-encoded in terms of fidelity to the interactions with real environment and consequently in terms of fitness to cognitive and spatial abilities. A further step in this direction was the creation of three-dimensional (3D) displays which have amplified the fidelity of digital representations. However, there are no systematic results evaluating the extent to which 3D displays better support cognitive spatial abilities. The aim of this research is to empirically investigate spatial memory performance across different instances of 2D and 3D displays. Two experiments were performed. The displays used in the experimental situation represented hierarchical information structures. The results of the test show that the 3D display does improve performances in the designed spatial memory task.",Monica Tavanti;Mats Lind,M. Tavanti;M. Lind,"Department of Information Science, University of Uppsala, Sweden;Department of Information Science, University of Uppsala, Sweden",,,203.0,64.0,11.0,1036.0,,,support cognitive spatial;3d displays experiments;information technology domain;performance different;consequently terms,0.6517;0.5365;0.2360;0.1848;0.0253,"[np.int64(-1), np.int64(-1), -1, -1, -1]",143;114;-1;-1;-1,114;143,143,Immersive Spatial Support
VAST,2009,Combining automated analysis and visualization techniques for effective exploration of high-dimensional data,10.1109/vast.2009.5332628,http://dx.doi.org/10.1109/VAST.2009.5332628,59.0,66.0,C,"Visual exploration of multivariate data typically requires projection onto lower-dimensional representations. The number of possible representations grows rapidly with the number of dimensions, and manual exploration quickly becomes ineffective or even unfeasible. This paper proposes automatic analysis methods to extract potentially relevant visual structures from a set of candidate visualizations. Based on features, the visualizations are ranked in accordance with a specified user task. The user is provided with a manageable number of potentially useful candidate visualizations, which can be used as a starting point for interactive data analysis. This can effectively ease the task of finding truly useful visualizations and potentially speed up the data exploration task. In this paper, we present ranking measures for class-based as well as non class-based Scatterplots and Parallel Coordinates visualizations. The proposed analysis methods are evaluated on different datasets.",Andrada Tatu;Georgia Albuquerque;Martin Eisemann;Jörn Schneidewind;Holger Theisel;Marcus A. Magnor;Daniel A. Keim,Andrada Tatu;Georgia Albuquerque;Martin Eisemann;Jorn Schneidewind;Holger Theisel;Marcus Magnork;Daniel Keim,"University of Konstanz, Germany;TU Braunschweig, Germany;TU Braunschweig, Germany;Telefonica o2 Business Intelligence Center, Germany;University of Magdeburg, Germany;Technische Universitat Braunschweig, Braunschweig, Niedersachsen, DE;University of Konstanz, Germany",10.1109/infvis.2005.1532142;10.1109/infvis.1998.729559;10.1109/infvis.2003.1249017;10.1109/visual.1994.346302;10.1109/vast.2006.261423;10.1109/infvis.2005.1532142,,119.0,98.0,25.0,1325.0,,,visual exploration multivariate;class based;number dimensions manual;lower;ineffective unfeasible paper,0.7083;0.1922;0.1920;0.0384;0.0343,"[np.int64(-1), -1, -1, -1, -1]",93;-1;-1;-1;-1,93,93,Multivariate Data Visualization
VAST,2014,Visual Analytics for Complex Engineering Systems: Hybrid Visual Steering of Simulation Ensembles,10.1109/tvcg.2014.2346744,http://dx.doi.org/10.1109/TVCG.2014.2346744,1803.0,1812.0,J,"In this paper we propose a novel approach to hybrid visual steering of simulation ensembles. A simulation ensemble is a collection of simulation runs of the same simulation model using different sets of control parameters. Complex engineering systems have very large parameter spaces so a naïve sampling can result in prohibitively large simulation ensembles. Interactive steering of simulation ensembles provides the means to select relevant points in a multi-dimensional parameter space (design of experiment). Interactive steering efficiently reduces the number of simulation runs needed by coupling simulation and visualization and allowing a user to request new simulations on the fly. As system complexity grows, a pure interactive solution is not always sufficient. The new approach of hybrid steering combines interactive visual steering with automatic optimization. Hybrid steering allows a domain expert to interactively (in a visualization) select data points in an iterative manner, approximate the values in a continuous region of the simulation space (by regression) and automatically find the “best” points in this continuous region based on the specified constraints and objectives (by optimization). We argue that with the full spectrum of optimization options, the steering process can be improved substantially. We describe an integrated system consisting of a simulation, a visualization, and an optimization component. We also describe typical tasks and propose an interactive analysis workflow for complex engineering systems. We demonstrate our approach on a case study from automotive industry, the optimization of a hydraulic circuit in a high pressure common rail Diesel injection system.",Kresimir Matkovic;Denis Gracanin;Rainer Splechtna;Mario Jelovic;Benedikt Stehno;Helwig Hauser;Werner Purgathofer,Kreŝimir Matković;Denis Gračanin;Rainer Splechtna;Mario Jelović;Benedikt Stehno;Helwig Hauser;Werner Purgathofer,"VRVis Research Center, Vienna, Austria;Virginia Tech, Blacksburg, VA, USA;VRVis Research Center, Vienna, Austria;AVL-AST Zagreb, Croatia;VRVis Research Center, Vienna, Austria;University of Bergen, Norway;Vienna University of Technology, Austria",10.1109/tvcg.2010.223;10.1109/tvcg.2012.280;10.1109/tvcg.2008.145;10.1109/tvcg.2009.110;10.1109/tvcg.2010.171;10.1109/vast.2009.5333081;10.1109/vast.2010.5651694;10.1109/tvcg.2010.223,"Interactive Visual Analysis, Integrated Design Environment, Simulation, Visual Steering, Automatic Optimization",31.0,25.0,42.0,946.0,,,simulation visualization optimization;steering automatic;domain expert;pressure common rail;argue spectrum,0.6506;0.2198;0.1953;0.1457;-0.0060,"[np.int64(-1), -1, -1, -1, -1]",146;-1;-1;-1;-1,146,146,Visualization Techniques
Vis,2023,A Local Iterative Approach for the Extraction of 2D Manifolds from Strongly Curved and Folded Thin-Layer Structures,10.1109/tvcg.2023.3327403,http://dx.doi.org/10.1109/TVCG.2023.3327403,1260.0,1270.0,J,"Ridge surfaces represent important features for the analysis of 3-dimensional (3D) datasets in diverse applications and are often derived from varying underlying data including flow fields, geological fault data, and point data, but they can also be present in the original scalar images acquired using a plethora of imaging techniques. Our work is motivated by the analysis of image data acquired using micro-computed tomography ($\mu\text{CT}$) of ancient, rolled and folded thin-layer structures such as papyrus, parchment, and paper as well as silver and lead sheets. From these documents we know that they are 2-dimensional (2D) in nature. Hence, we are particularly interested in reconstructing 2D manifolds that approximate the document's structure. The image data from which we want to reconstruct the 2D manifolds are often very noisy and represent folded, densely-layered structures with many artifacts, such as ruptures or layer splitting and merging. Previous ridge-surface extraction methods fail to extract the desired 2D manifold for such challenging data. We have therefore developed a novel method to extract 2D manifolds. The proposed method uses a local fast marching scheme in combination with a separation of the region covered by fast marching into two sub-regions. The 2D manifold of interest is then extracted as the surface separating the two sub-regions. The local scheme can be applied for both automatic propagation as well as interactive analysis. We demonstrate the applicability and robustness of our method on both artificial data as well as real-world data including folded silver and papyrus sheets.",Nicolas Klenert;Verena Lepper;Daniel Baum,Nicolas Klenert;Verena Lepper;Daniel Baum,"Zuse Institute Berlin, Germany;Agyptisches Museum und Papyrussammlung, Germany;Zuse Institute Berlin, Germany",0.1109/tvcg.2009.177;10.1109/tvcg.2007.70554,"Ridge surface,crease surface,2D manifold extraction,fast marching,virtual unfolding,historical documents",,0.0,42.0,226.0,,,ridge surface extraction;ruptures layer;fast marching sub;ancient;sheets documents,0.6400;0.2615;0.1886;0.1355;0.1352,"[np.int64(-1), -1, -1, -1, -1]",72;-1;-1;-1;-1,72,72,Ridge Extraction Techniques
Vis,2002,Computing singularities of 3D vector fields with geometric algebra,10.1109/visual.2002.1183786,http://dx.doi.org/10.1109/VISUAL.2002.1183786,283.0,289.0,C,"Critical points of a vector field are key to their characterization. Their positions as well as their indexes are crucial for understanding vector fields. Considerable work exists in 2D, but less is available for 3D or higher dimensions. Geometric algebra is a derivative of Clifford algebra that not only enables a succinct definition of the index of a critical point in higher dimension; it also provides insight and computational pathways for calculating the index. We describe the problems in terms of geometric algebra and present an octree based solution using the algebra for finding critical points and their index in a 3D vector field.",Stephen Mann;Alyn P. Rockwood,S. Mann;A. Rockwood,"School of Computer Science, University of Waterloo, Waterloo, ONT, Canada;Department of Math and Computer Science, Colorado Schml of Mines, Golden, CO, USA",10.1109/visual.1997.663858;10.1109/visual.1997.663871,"Geometric Algebra, 3D Vector Fields, Singularities",59.0,18.0,20.0,232.0,,,vector fields;algebra present octree;definition index critical;clifford;insight computational pathways,0.5804;0.4378;0.2139;0.1653;0.1156,"[np.int64(-1), -1, -1, -1, -1]",60;-1;-1;-1;-1,60,60,Vector Field Visualization
VAST,2010,Interactive visual analysis of multiobjective optimizations,10.1109/vast.2010.5651694,http://dx.doi.org/10.1109/VAST.2010.5651694,215.0,216.0,M,"Optimization problems are typically addressed by purely automatic approaches. For multi-objective problems, however, a single best solution often does not exist. In this case, it is necessary to analyze trade-offs between many conflicting goals within a given application context. This poster describes an approach that tightly integrates automatic algorithms for multi-objective optimization and interactive multivariate visualizations. Ad-hoc selections support a flexible definition of input data for subsequent algorithms. These algorithms in turn represent their result as derived data attributes that can be assigned to visualizations or be used as a basis for further selections (e.g., to constrain the result set). This enables a guided search that still involves the knowledge of domain experts. We describe our approach in the context of multi-run simulation data from the application domain of car engine design.",Wolfgang Berger;Harald Piringer,Wolfgang Berger;Harald Piringer,"VRVis Research Center, Vienna, Austria;VRVis Research Center, Vienna, Austria",0.1109/vast.2009.5333081;10.1109/tvcg.2009.110,,8.0,9.0,7.0,309.0,,,objective optimization interactive;multivariate visualizations;car engine;offs conflicting;represent,0.5803;0.4629;0.2608;0.0555;0.0079,"[np.int64(-1), -1, -1, -1, -1]",3;-1;-1;-1;-1,3,3,Multi-Objective Optimization
Vis,1999,Time-critical Multiresolution Scene Rendering,10.1109/visual.1999.809876,http://doi.ieeecomputersociety.org/10.1109/VISUAL.1999.809876,123.0,130.0,C,"We describe a framework for time-critical rendering of graphics scenes composed of a large number of objects having complex geometric descriptions. Our technique relies upon a scene description in which objects are represented as multiresolution meshes. We perform a constrained optimization at each frame to choose the resolution of each potentially visible object that generates the best quality image while meeting timing constraints. The technique provides smooth level-of-detail control and aims at guaranteeing a uniform, bounded frame rate even for widely changing viewing conditions. The optimization algorithm is independent from the particular data structure used to represent multiresolution meshes. The only requirements are the ability to represent a mesh with an arbitrary number of triangles and to traverse a mesh structure at an arbitrary resolution in a short predictable time. A data structure satisfying these criteria is described and experimental results are discussed.",Enrico Gobbetti;Eric Bouvier,E. Gobbetti;E. Bouvier,"Center for Adv. Studies, Cagliari, Italy;Center for Adv. Studies, Cagliari, Italy",10.1109/visual.1996.568126;10.1109/visual.1998.745282,"multiresolution modeling,level of detail,adaptive rendering, time-critical graphics",77.0,15.0,0.0,26.0,,,represented multiresolution meshes;meeting timing constraints;visible object generates;traverse;large number,0.6247;0.2184;0.2034;0.1737;0.1172,"[np.int64(-1), -1, -1, -1, -1]",61;-1;-1;-1;-1,61,61,Geometric Data Representation
VAST,2006,Visual Analysis of Conflicting Opinions,10.1109/vast.2006.261431,http://dx.doi.org/10.1109/VAST.2006.261431,59.0,66.0,C,"Understanding the nature and dynamics of conflicting opinions is a profound and challenging issue. In this paper we address several aspects of the issue through a study of more than 3,000 Amazon customer reviews of the controversial bestseller The Da Vinci Code, including 1,738 positive and 918 negative reviews. The study is motivated by critical questions such as: what are the differences between positive and negative reviews? What is the origin of a particular opinion? How do these opinions change over time? To what extent can differentiating features be identified from unstructured text? How accurately can these features predict the category of a review? We first analyze terminology variations in these reviews in terms of syntactic, semantic, and statistic associations identified by TermWatch and use term variation patterns to depict underlying topics. We then select the most predictive terms based on log likelihood tests and demonstrate that this small set of terms classifies over 70% of the conflicting reviews correctly. This feature selection process reduces the dimensionality of the feature space from more than 20,000 dimensions to a couple of hundreds. We utilize automatically generated decision trees to facilitate the understanding of conflicting opinions in terms of these highly predictive terms. This study also uses a number of visualization and modeling tools to identify not only what positive and negative reviews have in common, but also they differ and evolve over time",Chaomei Chen;Fidelia Ibekwe-Sanjuan;Eric SanJuan;Chris E. Weaver,Chaomei Chen;Fidelia Ibekwe-SanJuan;Eric SanJuan;Chris Weaver,"Drexel University, USA;Universite de Lyon, France;Universite d''Avignon, France;Pennsylvania State University, USA",10.1109/infvis.2002.1173155,"Visual Analytics, Intelligence analysis, Problemsolving environments, Visual Knowledge Discovery",105.0,53.0,21.0,732.0,,,customer reviews controversial;associations identified termwatch;vinci code including;number visualization;change time,0.5519;0.3176;0.2654;0.1870;0.0368,"[np.int64(-1), -1, -1, -1, -1]",25;-1;-1;-1;-1,25,25,Data Interpretation Challenges
VAST,2018,ForVizor: Visualizing Spatio-Temporal Team Formations in Soccer,10.1109/tvcg.2018.2865041,http://dx.doi.org/10.1109/TVCG.2018.2865041,65.0,75.0,J,"Regarded as a high-level tactic in soccer, a team formation assigns players different tasks and indicates their active regions on the pitch, thereby influencing the team performance significantly. Analysis of formations in soccer has become particularly indispensable for soccer analysts. However, formations of a team are intrinsically time-varying and contain inherent spatial information. The spatio-temporal nature of formations and other characteristics of soccer data, such as multivariate features, make analysis of formations in soccer a challenging problem. In this study, we closely worked with domain experts to characterize domain problems of formation analysis in soccer and formulated several design goals. We design a novel spatio-temporal visual representation of changes in team formation, allowing analysts to visually analyze the evolution of formations and track the spatial flow of players within formations over time. Based on the new design, we further design and develop ForVizor, a visual analytics system, which empowers users to track the spatio-temporal changes in formation and understand how and why such changes occur. With ForVizor, domain experts conduct formation analysis of two games. Analysis results with insights and useful feedback are summarized in two case studies.",Yingcai Wu;Xiao Xie;Jiachen Wang;Dazhen Deng;Hongye Liang;Hui Zhang 0051;Shoubin Cheng;Wei Chen 0001,Yingcai Wu;Xiao Xie;Jiachen Wang;Dazhen Deng;Hongye Liang;Hui Zhang;Shoubin Cheng;Wei Chen,"State Key Lab of CAD&CG, Zhejiang University;State Key Lab of CAD&CG, Zhejiang University;State Key Lab of CAD&CG, Zhejiang University;State Key Lab of CAD&CG, Zhejiang University;State Key Lab of CAD&CG, Zhejiang University;Department of Sport Science, Zhejiang University;Department of Sport Science, Zhejiang University;State Key Lab of CAD&CG, Zhejiang University",10.1109/vast.2008.4677356;10.1109/tvcg.2011.239;10.1109/tvcg.2014.2346433;10.1109/vast.2014.7042477;10.1109/tvcg.2018.2865018;10.1109/tvcg.2016.2598831;10.1109/tvcg.2013.192;10.1109/tvcg.2014.2346445;10.1109/tvcg.2017.2745181;10.1109/tvcg.2017.2744218;10.1109/vast.2008.4677356,"Soccer data,formation analysis,spatio-temporal visualization",79.0,82.0,48.0,2778.0,,,formation analysis soccer;temporal visual representation;analytics empowers users;forvizor domain;regions pitch influencing,0.6550;0.3629;0.3330;0.1266;0.1250,"[np.int64(-1), -1, -1, -1, -1]",49;-1;-1;-1;-1,49,49,Soccer Formation Analysis
VAST,2016,Visualizing Dimension Coverage to Support Exploratory Analysis,10.1109/tvcg.2016.2598466,http://dx.doi.org/10.1109/TVCG.2016.2598466,21.0,30.0,J,"Data analysis involves constantly formulating and testing new hypotheses and questions about data. When dealing with a new dataset, especially one with many dimensions, it can be cumbersome for the analyst to clearly remember which aspects of the data have been investigated (i.e., visually examined for patterns, trends, outliers etc.) and which combinations have not. Yet this information is critical to help the analyst formulate new questions that they have not already answered. We observe that for tabular data, questions are typically comprised of varying combinations of data dimensions (e.g., what are the trends of Sales and Profit for different Regions?). We propose representing analysis history from the angle of dimension coverage (i.e., which data dimensions have been investigated and in which combinations). We use scented widgets to incorporate dimension coverage of the analysts' past work into interaction widgets of a visualization tool. We demonstrate how this approach can assist analysts with the question formation process. Our approach extends the concept of scented widgets to reveal aspects of one's own analysis history, and offers a different perspective on one's past work than typical visualization history tools. Results of our empirical study showed that participants with access to embedded dimension coverage information relied on this information when formulating questions, asked more questions about the data, generated more top-level findings, and showed greater breadth of their analysis without sacrificing depth.",Ali Sarvghad;Melanie Tory;Narges Mahyar,Ali Sarvghad;Melanie Tory;Narges Mahyar,University of Victoria;Tableau Research;University of British Columbia,10.1109/tvcg.2015.2467191;10.1109/tvcg.2006.120;10.1109/infvis.1999.801862;10.1109/infvis.2000.885086;10.1109/visual.2005.1532788;10.1109/tvcg.2014.2346452;10.1109/vast.2009.5333020;10.1109/infvis.2001.963289;10.1109/tvcg.2008.137;10.1109/tvcg.2015.2467611;10.1109/visual.1993.398857;10.1109/tvcg.2007.70589;10.1109/tvcg.2013.167;10.1109/tvcg.2008.109;10.1109/tvcg.2015.2467191,Dimension coverage;Tabular data;History;Empirical laboratory study;Exploratory data analysis;Scented widgets,35.0,27.0,33.0,1201.0,,,visualization history tools;dimension coverage analysts;formulating questions asked;extends concept scented;typical,0.5611;0.3797;0.3108;0.2549;0.0647,"[np.int64(-1), -1, -1, -1, -1]",146;-1;-1;-1;-1,146,146,Visualization Techniques
SciVis,2018,Dynamic Volume Lines: Visual Comparison of 3D Volumes through Space-filling Curves,10.1109/tvcg.2018.2864510,http://dx.doi.org/10.1109/TVCG.2018.2864510,1040.0,1049.0,J,"The comparison of many members of an ensemble is difficult, tedious, and error-prone, which is aggravated by often just subtle differences. In this paper, we introduce Dynamic Volume Lines for the interactive visual analysis and comparison of sets of 3D volumes. Each volume is linearized along a Hilbert space-filling curve into a 1D Hilbert line plot, which depicts the intensities over the Hilbert indices. We present a nonlinear scaling of these 1D Hilbert line plots based on the intensity variations in the ensemble of 3D volumes, which enables a more effective use of the available screen space. The nonlinear scaling builds the basis for our interactive visualization techniques. An interactive histogram heatmap of the intensity frequencies serves as overview visualization. When zooming in, the frequencies are replaced by detailed 1D Hilbert line plots and optional functional boxplots. To focus on important regions of the volume ensemble, nonlinear scaling is incorporated into the plots. An interactive scaling widget depicts the local ensemble variations. Our brushing and linking interface reveals, for example, regions with a high ensemble variation by showing the affected voxels in a 3D spatial view. We show the applicability of our concepts using two case studies on ensembles of 3D volumes resulting from tomographic reconstruction. In the first case study, we evaluate an artificial specimen from simulated industrial 3D X-ray computed tomography (XCT). In the second case study, a real-world XCT foam specimen is investigated. Our results show that Dynamic Volume Lines can identify regions with high local intensity variations, allowing the user to draw conclusions, for example, about the choice of reconstruction parameters. Furthermore, it is possible to detect ring artifacts in reconstructions volumes.",Johannes Weissenbock;Bernhard Fröhler;M. Eduard Gröller;Johann Kastner;Christoph Heinzl,Johannes Weissenböck;Bernhard Fröhler;Eduard Gröller;Johann Kastner;Christoph Heinzl,"University of Applied Sciences Upper Austria, Wels, Austria;University of Applied Sciences Upper Austria, Wels, Austria;Technische Universitat Wien, Wien, Wien, AT;University of Applied Sciences Upper Austria, Wels, Austria;University of Applied Sciences Upper Austria, Wels, Austria",10.1109/tvcg.2014.2346448;10.1109/vast.2015.7347634;10.1109/tvcg.2009.155;10.1109/tvcg.2014.2346455;10.1109/visual.2005.1532847;10.1109/tvcg.2013.213;10.1109/vast.2014.7042491;10.1109/tvcg.2014.2346321;10.1109/vast.2016.7883516;10.1109/tvcg.2013.143;10.1109/tvcg.2014.2346448,"Ensemble data,comparative visualization,visual analysis,Hilbert curve,nonlinear scaling,X-ray computed tomography",29.0,20.0,43.0,955.0,,,volume lines interactive;linearized hilbert space;scaling builds;just subtle differences;choice reconstruction,0.6298;0.1895;0.1475;0.0962;0.0952,"[np.int64(-1), -1, -1, -1, -1]",128;-1;-1;-1;-1,128,128,3D Volume Visualization
VAST,2013,Visual Analysis of Topic Competition on Social Media,10.1109/tvcg.2013.221,http://dx.doi.org/10.1109/TVCG.2013.221,2012.0,2021.0,J,"How do various topics compete for public attention when they are spreading on social media? What roles do opinion leaders play in the rise and fall of competitiveness of various topics? In this study, we propose an expanded topic competition model to characterize the competition for public attention on multiple topics promoted by various opinion leaders on social media. To allow an intuitive understanding of the estimated measures, we present a timeline visualization through a metaphoric interpretation of the results. The visual design features both topical and social aspects of the information diffusion process by compositing ThemeRiver with storyline style visualization. ThemeRiver shows the increase and decrease of competitiveness of each topic. Opinion leaders are drawn as threads that converge or diverge with regard to their roles in influencing the public agenda change over time. To validate the effectiveness of the visual analysis techniques, we report the insights gained on two collections of Tweets: the 2012 United States presidential election and the Occupy Wall Street movement.",Panpan Xu;Yingcai Wu;Enxun Wei;Tai-Quan Peng;Shixia Liu;Jonathan J. H. Zhu;Huamin Qu,Panpan Xu;Yingcai Wu;Enxun Wei;Tai-Quan Peng;Shixia Liu;Jonathan J.H. Zhu;Huamin Qu,"Hong Kong University of Science and Technology, Hong Kong, China;Microsoft Research, Asia, Russia;Shanghai Jiao Tong University, China;Nanyang Technological University, Singapore;Microsoft Research, Asia, Russia;City University of Hong Kong, Hong Kong, China;Hong Kong University of Science and Technology, Hong Kong, China",10.1109/tvcg.2008.166;10.1109/tvcg.2011.239;10.1109/tvcg.2012.253;10.1109/tvcg.2012.225;10.1109/vast.2009.5333437;10.1109/tvcg.2010.194;10.1109/tvcg.2012.291;10.1109/vast.2010.5652931;10.1109/tvcg.2013.196;10.1109/infvis.2001.963273;10.1109/tvcg.2012.212;10.1109/vast.2010.5652922;10.1109/tvcg.2010.129;10.1109/infvis.1999.801851;10.1109/tvcg.2008.166,"Social media visuaization, topic competition, information diffusion, information propagation, agenda-setting",153.0,90.0,50.0,4604.0,,,topic competition model;visualization metaphoric interpretation;wall street movement;drawn threads converge;united states presidential,0.5876;0.3672;0.3335;0.2520;0.1711,"[np.int64(-1), -1, -1, -1, -1]",15;-1;-1;-1;-1,15,15,Topic Competition Dynamics
Vis,1997,Building and traversing a surface at variable resolution,10.1109/visual.1997.663865,http://dx.doi.org/10.1109/VISUAL.1997.663865,103.0,110.0,C,"The authors consider the multi-triangulation, a general model for representing surfaces at variable resolution based on triangle meshes. They analyse characteristics of the model that make it effective for supporting basic operations such as extraction of a surface approximation, and point location. An interruptible algorithm for extracting a representation at a resolution variable over the surface is presented. Different heuristics for building the model are considered and compared. Results on both the construction and the extraction algorithm are presented.",Leila De Floriani;Paola Magillo;Enrico Puppo,L. De Fioriani;P. Magillo;E. Puppo,"Dipt. di Inf. e Sci. dell'Inf., Genoa Univ., Italy;Dipartimento di Informatica e Scienze dellInformazione, Universita di Genova, Genoa, Italy;Consiglio Nazionale delle Ricerche, Istituto per la Matematica Applicata del CNR, Genoa, Italy",,,163.0,26.0,21.0,79.0,,,based triangle meshes;representation resolution variable;location interruptible;building;compared,0.6977;0.2590;0.1870;0.0971;0.0333,"[np.int64(-1), -1, -1, -1, -1]",77;-1;-1;-1;-1,77,77,Mesh Geometry Techniques
SciVis,2015,Real-time Uncertainty Visualization for B-Mode Ultrasound,10.1109/scivis.2015.7429489,http://dx.doi.org/10.1109/SciVis.2015.7429489,33.0,40.0,C,"B-mode ultrasound is a very well established imaging modality and is widely used in many of today's clinical routines. However, acquiring good images and interpreting them correctly is a challenging task due to the complex ultrasound image formation process depending on a large number of parameters. To facilitate ultrasound acquisitions, we introduce a novel framework for real-time uncertainty visualization in B-mode images. We compute real-time per-pixel ultrasound Confidence Maps, which we fuse with the original ultrasound image in order to provide the user with an interactive feedback on the quality and credibility of the image. In addition to a standard color overlay mode, primarily intended for educational purposes, we propose two perceptional visualization schemes to be used in clinical practice. Our mapping of uncertainty to chroma uses the perceptionally uniform L*a*b* color space to ensure that the perceived brightness of B-mode ultrasound remains the same. The alternative mapping of uncertainty to fuzziness keeps the B-mode image in its original grayscale domain and locally blurs or sharpens the image based on the uncertainty distribution. An elaborate evaluation of our system and user studies on both medical students and expert sonographers demonstrate the usefulness of our proposed technique. In particular for ultrasound novices, such as medical students, our technique yields powerful visual cues to evaluate the image quality and thereby learn the ultrasound image formation process. Furthermore, seeing the distribution of uncertainty adjust to the transducer positioning in real-time, provides also expert clinicians with a strong visual feedback on their actions. This helps them to optimize the acoustic window and can improve the general clinical value of ultrasound.",Christian Schulte zu Berge;Denis Declara;Christoph Hennersperger;Maximilian Baust;Nassir Navab,Christian Schulte Zu Berge;Denis Declara;Christoph Hennersperger;Maximilian Baust;Nassir Navab,;;;;,10.1109/visual.2001.964550;10.1109/tvcg.2006.134;10.1109/tvcg.2007.70518;10.1109/tvcg.2012.279;10.1109/tvcg.2009.114;10.1109/visual.2001.964550,"Ultrasound, Uncertainty Visualization, Confidence Maps, Real-time",2.0,3.0,23.0,436.0,,,ultrasound confidence maps;color overlay mode;blurs sharpens image;improve general clinical;task,0.6866;0.3184;0.2482;0.1806;0.0559,"[np.int64(-1), -1, -1, -1, -1]",116;-1;-1;-1;-1,116,116,Uncertainty Visualization
InfoVis,2013,Selecting the Aspect Ratio of a Scatter Plot Based on Its Delaunay Triangulation,10.1109/tvcg.2013.187,http://dx.doi.org/10.1109/TVCG.2013.187,2326.0,2335.0,J,"Scatter plots are diagrams that visualize two-dimensional data as sets of points in the plane. They allow users to detect correlations and clusters in the data. Whether or not a user can accomplish these tasks highly depends on the aspect ratio selected for the plot, i.e., the ratio between the horizontal and the vertical extent of the diagram. We argue that an aspect ratio is good if the Delaunay triangulation of the scatter plot at this aspect ratio has some nice geometric property, e.g., a large minimum angle or a small total edge length. More precisely, we consider the following optimization problem. Given a set Q of points in the plane, find a scale factor s such that scaling the x-coordinates of the points in Q by s and the y-coordinates by 1=s yields a point set P(s) that optimizes a property of the Delaunay triangulation of P(s), over all choices of s. We present an algorithm that solves this problem efficiently and demonstrate its usefulness on real-world instances. Moreover, we discuss an empirical test in which we asked 64 participants to choose the aspect ratios of 18 scatter plots. We tested six different quality measures that our algorithm can optimize. In conclusion, minimizing the total edge length and minimizing what we call the 'uncompactness' of the triangles of the Delaunay triangulation yielded the aspect ratios that were most similar to those chosen by the participants in the test.",Martin Fink 0001;Jan-Henrik Haunert;Joachim Spoerhase;Alexander Wolff 0001,Martin Fink;Jan-Henrik Haunert;Joachim Spoerhase;Alexander Wolff,"Lehrstuhl I, Institut für Informatik, Universität Würzburg, Germany;Lehrstuhl I, Institut für Informatik, Universität Würzburg, Germany;Lehrstuhl I, Institut für Informatik, Universität Würzburg, Germany;Lehrstuhl I, Institut für Informatik, Universität Würzburg, Germany",10.1109/tvcg.2006.163;10.1109/tvcg.2012.196;10.1109/tvcg.2011.167;10.1109/tvcg.2006.163,"Scatter plot, aspect ratio, Delaunay triangulation",35.0,24.0,28.0,727.0,,,delaunay triangulation scatter;choose aspect ratios;clusters data;efficiently demonstrate usefulness;allow,0.6072;0.3702;0.3686;0.1983;-0.0029,"[np.int64(-1), -1, -1, -1, -1]",126;-1;-1;-1;-1,126,126,Geometric Mesh Processing
VAST,2012,The spatiotemporal multivariate hypercube for discovery of patterns in event data,10.1109/vast.2012.6400536,http://dx.doi.org/10.1109/VAST.2012.6400536,235.0,236.0,M,"Event data can hold valuable decision making information, yet detecting interesting patterns in this type of data is not an easy task because the data is usually rich and contains spatial, temporal as well as multivariate dimensions. Research into visual analytics tools to support the discovery of patterns in event data often focuses on the spatiotemporal or spatiomultivariate dimension of the data only. Few research efforts focus on all three dimensions in one framework. An integral view on all three dimensions is, however, required to unlock the full potential of event datasets. In this poster, we present an event visualization, transition, and interaction framework that enables an integral view on all dimensions of spatiotemporal multivariate event data. The framework is built around the notion that the event data space can be considered a spatiotemporal multivariate hypercube. Results of a case study we performed suggest that a visual analytics tool based on the proposed framework is indeed capable to support users in the discovery of multidimensional spatiotemporal multivariate patterns in event data.",Fred Olislagers;Marcel Worring,Fred Olislagers;Marcel Worring,"Intelligent Systems Lab Amsterdam, University of Amsterdam, The Netherlands;Intelligent Systems Lab Amsterdam, University of Amsterdam, The Netherlands",,,3.0,1.0,3.0,206.0,,,event visualization;spatiomultivariate dimension data;framework built notion;study performed suggest;unlock,0.7077;0.4763;0.0467;0.0456;-0.0202,"[np.int64(-1), -1, -1, -1, -1]",65;-1;-1;-1;-1,65,65,Event Visualization
InfoVis,2010,Declarative Language Design for Interactive Visualization,10.1109/tvcg.2010.144,http://dx.doi.org/10.1109/TVCG.2010.144,1149.0,1156.0,J,"We investigate the design of declarative, domain-specific languages for constructing interactive visualizations. By separating specification from execution, declarative languages can simplify development, enable unobtrusive optimization, and support retargeting across platforms. We describe the design of the Protovis specification language and its implementation within an object-oriented, statically-typed programming language (Java). We demonstrate how to support rich visualizations without requiring a toolkit-specific data model and extend Protovis to enable declarative specification of animated transitions. To support cross-platform deployment, we introduce rendering and event-handling infrastructures decoupled from the runtime platform, letting designers retarget visualization specifications (e.g., from desktop to mobile phone) with reduced effort. We also explore optimizations such as runtime compilation of visualization specifications, parallelized execution, and hardware-accelerated rendering. We present benchmark studies measuring the performance gains provided by these optimizations and compare performance to existing Java-based visualization tools, demonstrating scalability improvements exceeding an order of magnitude.",Jeffrey Heer;Michael Bostock,Jeffrey Heer;Michael Bostock,"Computer Science Department, University of Stanford, Stanford, CA, USA;Computer Science Department, University of Stanford, Stanford, CA, USA",10.1109/tvcg.2009.174;10.1109/tvcg.2006.178;10.1109/infvis.2004.12;10.1109/tvcg.2007.70577;10.1109/tvcg.2009.128;10.1109/visual.1992.235219;10.1109/tvcg.2009.191;10.1109/tvcg.2009.110;10.1109/tvcg.2007.70539;10.1109/infvis.2004.64;10.1109/infvis.2000.885086;10.1109/tvcg.2009.174,"Information visualization, user interfaces, toolkits, domain specific languages, declarative languages, optimization",151.0,82.0,25.0,1485.0,HM,,visualization specifications;animated transitions;languages simplify development;decoupled runtime;retarget,0.6372;0.4034;0.3889;0.2261;0.0498,"[np.int64(-1), -1, -1, -1, -1]",103;-1;-1;-1;-1,103,103,Visualization Design
Vis,2009,Interactive Visual Analysis of Complex Scientific Data as Families of Data Surfaces,10.1109/tvcg.2009.155,http://dx.doi.org/10.1109/TVCG.2009.155,1351.0,1358.0,J,"The widespread use of computational simulation in science and engineering provides challenging research opportunities. Multiple independent variables are considered and large and complex data are computed, especially in the case of multi-run simulation. Classical visualization techniques deal well with 2D or 3D data and also with time-dependent data. Additional independent dimensions, however, provide interesting new challenges. We present an advanced visual analysis approach that enables a thorough investigation of families of data surfaces, i.e., datasets, with respect to pairs of independent dimensions. While it is almost trivial to visualize one such data surface, the visual exploration and analysis of many such data surfaces is a grand challenge, stressing the users' perception and cognition. We propose an approach that integrates projections and aggregations of the data surfaces at different levels (one scalar aggregate per surface, a 1D profile per surface, or the surface as such). We demonstrate the necessity for a flexible visual analysis system that integrates many different (linked) views for making sense of this highly complex data. To demonstrate its usefulness, we exemplify our approach in the context of a meteorological multi-run simulation data case and in the context of the engineering domain, where our collaborators are working with the simulation of elastohydrodynamic (EHD) lubrication bearing in the automotive industry.",Kresimir Matkovic;Denis Gracanin;Borislav Klarin;Helwig Hauser,Kresimir Matkovic;Denis Gracanin;Borislav Klarin;Helwig Hauser,"VRVis Research Center Vienna, Austria;Virginia Technology, USA;AVL AST, Zagreb, Croatia;University of Bergen, Norway",10.1109/visual.1997.663867;10.1109/tvcg.2008.145;10.1109/infvis.2001.963273;10.1109/tvcg.2006.170;10.1109/visual.1997.663867,"Interactive visual analysis, family of surfaces, coordinated multiple views, multidimensional multivariate data",60.0,34.0,23.0,784.0,,,visualize data surface;lubrication bearing automotive;multi run simulation;engineering provides challenging;especially,0.6697;0.2883;0.2655;0.2253;0.0169,"[np.int64(-1), -1, -1, -1, -1]",146;-1;-1;-1;-1,146,146,Visualization Techniques
InfoVis,2008,Effectiveness of Animation in Trend Visualization,10.1109/tvcg.2008.125,http://dx.doi.org/10.1109/TVCG.2008.125,1325.0,1332.0,J,"Animation has been used to show trends in multi-dimensional data. This technique has recently gained new prominence for presentations, most notably with Gapminder Trendalyzer. In Trendalyzer, animation together with interesting data and an engaging presenter helps the audience understand the results of an analysis of the data. It is less clear whether trend animation is effective for analysis. This paper proposes two alternative trend visualizations that use static depictions of trends: one which shows traces of all trends overlaid simultaneously in one display and a second that uses a small multiples display to show the trend traces side-by-side. The paper evaluates the three visualizations for both analysis and presentation. Results indicate that trend animation can be challenging to use even for presentations; while it is the fastest technique for presentation and participants find it enjoyable and exciting, it does lead to many participant errors. Animation is the least effective form for analysis; both static depictions of trends are significantly faster than animation, and the small multiples display is more accurate.",George G. Robertson;Roland Fernandez;Danyel Fisher;Bongshin Lee;John T. Stasko,George Robertson;Roland Fernandez;Danyel Fisher;Bongshin Lee;John Stasko,Microsoft Research;Microsoft Research;Microsoft Research;Microsoft Research;Georgia Institute of Technology,10.1109/infvis.1999.801854;10.1109/tvcg.2007.70539,"Information visualization, animation, trends, design, experiment",480.0,259.0,21.0,4273.0,TT,,trend visualizations;faster animation small;overlaid simultaneously display;presenter helps audience;paper proposes alternative,0.7835;0.3073;0.2422;0.1804;0.0312,"[np.int64(-1), -1, -1, -1, -1]",136;-1;-1;-1;-1,136,136,Trend Visualization Techniques
Vis,2005,Understanding visualization through spatial ability differences,10.1109/visual.2005.1532836,http://dx.doi.org/10.1109/VISUAL.2005.1532836,511.0,518.0,C,"Little is known about the cognitive abilities which influence the comprehension of scientific and information visualizations and what properties of the visualization affect comprehension. Our goal in this paper is to understand what makes visualizations difficult. We address this goal by examining the spatial ability differences in a diverse population selected for spatial ability variance. For example, how is, spatial ability related to visualization comprehension? What makes a particular visualization difficult or time intensive for specific groups of subjects? In this paper, we present the results of an experiment designed to answer these questions. Fifty-six subjects were tested on a basic visualization task and given standard paper tests of spatial abilities. An equal number of males and females were recruited in this study in order to increase spatial ability variance. Our results show that high spatial ability is correlated with accuracy on our three-dimensional visualization test, but not with time. High spatial ability subjects also had less difficulty with object complexity and the hidden properties of an object.",Maria C. Velez;Deborah Silver;Marilyn Tremaine,M.C. Velez;D. Silver;M. Tremaine,"Center for Advanced Information Processing Rutgers, State University of New Jersey, USA;Center for Advanced Information Processing Rutgers, State University of New Jersey, USA;Center for Advanced Information Processing Rutgers, State University of New Jersey, USA",10.1109/infvis.2003.1249022;10.1109/visual.2003.1250396,"Gender differences, orthogonal projections, spatial ability, standardized testing",199.0,21.0,36.0,1041.0,,,visualization comprehension makes;ability correlated accuracy;population selected spatial;standard paper tests;difficult time,0.6827;0.2801;0.2793;0.1748;0.0938,"[np.int64(-1), -1, -1, -1, -1]",94;-1;-1;-1;-1,94,94,Visualization Literacy
SciVis,2017,Multiscale Visualization and Scale-Adaptive Modification of DNA Nanostructures,10.1109/tvcg.2017.2743981,http://dx.doi.org/10.1109/TVCG.2017.2743981,1014.0,1024.0,J,"We present an approach to represent DNA nanostructures in varying forms of semantic abstraction, describe ways to smoothly transition between them, and thus create a continuous multiscale visualization and interaction space for applications in DNA nanotechnology. This new way of observing, interacting with, and creating DNA nanostructures enables domain experts to approach their work in any of the semantic abstraction levels, supporting both low-level manipulations and high-level visualization and modifications. Our approach allows them to deal with the increasingly complex DNA objects that they are designing, to improve their features, and to add novel functions in a way that no existing single-scale approach offers today. For this purpose we collaborated with DNA nanotechnology experts to design a set of ten semantic scales. These scales take the DNA's chemical and structural behavior into account and depict it from atoms to the targeted architecture with increasing levels of abstraction. To create coherence between the discrete scales, we seamlessly transition between them in a well-defined manner. We use special encodings to allow experts to estimate the nanoscale object's stability. We also add scale-adaptive interactions that facilitate the intuitive modification of complex structures at multiple scales. We demonstrate the applicability of our approach on an experimental use case. Moreover, feedback from our collaborating domain experts confirmed an increased time efficiency and certainty for analysis and modification tasks on complex DNA structures. Our method thus offers exciting new opportunities with promising applications in medicine and biotechnology.",Haichao Miao;Elisa De Llano;Johannes Sorger;Yasaman Ahmadi;Tadija Kekic;Tobias Isenberg 0001;M. Eduard Gröller;Ivan Barisic;Ivan Viola,Haichao Miao;Elisa De Llano;Johannes Sorger;Yasaman Ahmadi;Tadija Kekic;Tobias Isenberg;M. Eduard Gröller;Ivan Barišić;Ivan Viola,"Austrian Institute of Technology and TU Wien, Austria;Austrian Institute of Technology;TU Wien, Austria;Austrian Institute of Technology;Austrian Institute of Technology;Université Paris-Saclay, France;VRVis Research Center, Austria and TU Wien, Austria;Austrian Institute of Technology;Austrian Institute of Technology and TU Wien, Austria",10.1109/visual.2004.103;10.1109/tvcg.2007.70578;10.1109/tvcg.2009.168;10.1109/tvcg.2013.126;10.1109/tvcg.2009.111,"Nano,nanotechnology,assembly,multiscale,abstraction,DNA,origami,scale-adaptive modification",23.0,21.0,54.0,1015.0,,,represent dna nanostructures;work semantic abstraction;scales seamlessly transition;experimental use;single,0.7316;0.2776;0.2300;0.0832;-0.0213,"[np.int64(-1), -1, -1, -1, -1]",45;-1;-1;-1;-1,45,45,DNA Representation
Vis,2002,A radial focus+context visualization for multi-dimensional functions,10.1109/visual.2002.1183806,http://dx.doi.org/10.1109/VISUAL.2002.1183806,443.0,450.0,C,"The analysis of multidimensional functions is important in many engineering disciplines, and poses a major problem as the number of dimensions increases. Previous visualization approaches focus on representing three or fewer dimensions at a time. This paper presents a new focus+context visualization that provides an integrated overview of an entire multidimensional function space, with uniform treatment of all dimensions. The overview is displayed with respect to a user-controlled polar focal point in the function's parameter space. Function value patterns are viewed along rays that emanate from the focal point in all directions in the parameter space, and represented radially around the focal point in the visualization. Data near the focal point receives proportionally more screen space than distant data. This approach scales smoothly from two dimensions to 10-20, with a 1000 pixel range on each dimension.",Sanjini Jayaraman;Chris North 0001,S. Jayaraman;C. North,"Center for Human Computer Interaction, Department of Computer Science, Virginia Polytechnic Institute and State University, Blacksburg, VA, USA;Center for Human Computer Interaction, Department of Computer Science, Virginia Polytechnic Institute and State University, Blacksburg, VA, USA",10.1109/infvis.1997.636793;10.1109/infvis.1995.528688;10.1109/visual.1993.398859;10.1109/infvis.1998.729558;10.1109/infvis.1997.636793,"visualization, multidimensional functions",27.0,8.0,11.0,146.0,,,focus context visualization;entire multidimensional function;user controlled polar;proportionally;10 20 1000,0.6944;0.3623;0.2096;0.1233;0.0720,"[np.int64(-1), -1, -1, -1, -1]",62;-1;-1;-1;-1,62,62,Interactive Visualization Tools
VAST,2017,Supporting Handoff in Asynchronous Collaborative Sensemaking Using Knowledge-Transfer Graphs,10.1109/tvcg.2017.2745279,http://dx.doi.org/10.1109/TVCG.2017.2745279,340.0,350.0,J,"During asynchronous collaborative analysis, handoff of partial findings is challenging because externalizations produced by analysts may not adequately communicate their investigative process. To address this challenge, we developed techniques to automatically capture and help encode tacit aspects of the investigative process based on an analyst's interactions, and streamline explicit authoring of handoff annotations. We designed our techniques to mediate awareness of analysis coverage, support explicit communication of progress and uncertainty with annotation, and implicit communication through playback of investigation histories. To evaluate our techniques, we developed an interactive visual analysis system, KTGraph, that supports an asynchronous investigative document analysis task. We conducted a two-phase user study to characterize a set of handoff strategies and to compare investigative performance with and without our techniques. The results suggest that our techniques promote the use of more effective handoff strategies, help increase an awareness of prior investigative process and insights, as well as improve final investigative outcomes.",Jian Zhao 0010;Michael Glueck;Petra Isenberg;Fanny Chevalier;Azam Khan,Jian Zhao;Michael Glueck;Petra Isenberg;Fanny Chevalier;Azam Khan,FX Palo Alto Laboratory;Autodesk Research;Inria;Inria;Autodesk Research,10.1109/vast.2007.4389009;10.1109/vast.2011.6102447;10.1109/vast.2010.5652932;10.1109/vast.2006.261420;10.1109/vast.2007.4389011;10.1109/tvcg.2008.137;10.1109/tvcg.2007.70568;10.1109/vast.2009.5333020;10.1109/vast.2009.5333878;10.1109/vast.2011.6102438;10.1109/vast.2006.261415;10.1109/tvcg.2014.2346573;10.1109/tvcg.2015.2467551;10.1109/vast.2008.4677358;10.1109/tvcg.2016.2598466;10.1109/vast.2007.4389006;10.1109/tvcg.2007.70577;10.1109/tvcg.2007.70589;10.1109/tvcg.2016.2598543;10.1109/vast.2007.4389009,"Collaboration,sensemaking,handoff,handover,structured externalizations,interactive visual analysis",63.0,41.0,55.0,1372.0,HM,,asynchronous collaborative analysis;investigative process address;handoff strategies help;visual;capture help encode,0.6236;0.4040;0.2333;0.2283;0.1042,"[np.int64(-1), -1, -1, -1, -1]",64;-1;-1;-1;-1,64,64,Collaborative Data Analysis
Vis,2002,Evaluation of a multimodal interface for 3D terrain visualization,10.1109/visual.2002.1183802,http://dx.doi.org/10.1109/VISUAL.2002.1183802,411.0,418.0,C,"Novel speech and/or gesture interfaces are candidates for use in future mobile or ubiquitous applications. This paper describes an evaluation of various interfaces for visual navigation of a whole Earth 3D terrain model. A mouse driven interface, a speech interface, a gesture interface, and a multimodal speech and gesture interface were used to navigate to targets placed at various points on the Earth. This study measured each participant's recall of target identity, order, and location as a measure of cognitive load. Timing information as well as a variety of subjective measures including discomfort and user preference were taken. While the familiar and mature mouse interface scored best by most measures, the speech interface also performed well. The gesture and multimodal interface suffered from weaknesses in the gesture modality. Weaknesses in the speech and multimodal modalities are identified and areas for improvement are discussed.",David M. Krum;Olugbenga Omoteso;William Ribarsky;Thad Starner;Larry F. Hodges,D.M. Krum;O. Omoteso;W. Ribarsky;T. Starner;L.F. Hodges,"College of Computing, Georgia Institute of Technology, GVU Center, Atlanta, GA, USA;College of Computing, Georgia Institute of Technology, GVU Center, Atlanta, GA, USA;College of Computing, Georgia Institute of Technology, GVU Center, Atlanta, GA, USA;College of Computing, Georgia Institute of Technology, GVU Center, Atlanta, GA, USA;College of Computing, Georgia Institute of Technology, GVU Center, Atlanta, GA, USA",,"multimodal interaction, evaluation, navigation, speech recognition, gesture recognition, virtual reality, mobile visualization, GIS",32.0,5.0,15.0,175.0,,,gesture interfaces;used navigate;earth 3d terrain;participant recall target;load timing,0.5964;0.3681;0.3312;0.1355;0.0647,"[np.int64(-1), -1, -1, -1, -1]",34;-1;-1;-1;-1,34,34,Gesture Interaction Techniques
InfoVis,2018,Looks Good To Me: Visualizations As Sanity Checks,10.1109/tvcg.2018.2864907,http://dx.doi.org/10.1109/TVCG.2018.2864907,830.0,839.0,J,"Famous examples such as Anscombe's Quartet highlight that one of the core benefits of visualizations is allowing people to discover visual patterns that might otherwise be hidden by summary statistics. This visual inspection is particularly important in exploratory data analysis, where analysts can use visualizations such as histograms and dot plots to identify data quality issues. Yet, these visualizations are driven by parameters such as histogram bin size or mark opacity that have a great deal of impact on the final visual appearance of the chart, but are rarely optimized to make important features visible. In this paper, we show that data flaws have varying impact on the visual features of visualizations, and that the adversarial or merely uncritical setting of design parameters of visualizations can obscure the visual signatures of these flaws. Drawing on the framework of Algebraic Visualization Design, we present the results of a crowdsourced study showing that common visualization types can appear to reasonably summarize distributional data while hiding large and important flaws such as missing data and extraneous modes. We make use of these results to propose additional best practices for visualizations of distributions for data quality tasks.",Michael Correll;Mingwei Li;Gordon L. Kindlmann;Carlos Scheidegger,Michael Correll;Mingwei Li;Gordon Kindlmann;Carlos Scheidegger,Tableau Research;University of Arizona;University of Chicago;University of Arizona,10.1109/tvcg.2016.2598862;10.1109/tvcg.2011.185;10.1109/tvcg.2014.2346298;10.1109/vast.2016.7883519;10.1109/tvcg.2016.2598618;10.1109/tvcg.2014.2346978;10.1109/tvcg.2014.2346979;10.1109/tvcg.2012.230;10.1109/tvcg.2014.2346325;10.1109/tvcg.2016.2599030;10.1109/tvcg.2017.2744359;10.1109/tvcg.2015.2469125;10.1109/tvcg.2010.161;10.1109/tvcg.2015.2467191;10.1109/tvcg.2016.2598862,"Graphical perception,data quality,univariate visualizations",52.0,47.0,51.0,1426.0,,,quality issues visualizations;adversarial merely uncritical;histogram bin;make use results;deal,0.6983;0.2991;0.2753;0.0362;-0.0260,"[np.int64(-1), -1, -1, -1, -1]",100;-1;-1;-1;-1,100,100,Visualization Quality
VAST,2014,DIA2: Web-based Cyberinfrastructure for Visual Analysis of Funding Portfolios,10.1109/tvcg.2014.2346747,http://dx.doi.org/10.1109/TVCG.2014.2346747,1823.0,1832.0,J,"We present a design study of the Deep Insights Anywhere, Anytime (DIA2) platform, a web-based visual analytics system that allows program managers and academic staff at the U.S. National Science Foundation to search, view, and analyze their research funding portfolio. The goal of this system is to facilitate users' understanding of both past and currently active research awards in order to make more informed decisions of their future funding. This user group is characterized by high domain expertise yet not necessarily high literacy in visualization and visual analytics-they are essentially casual experts-and thus require careful visual and information design, including adhering to user experience standards, providing a self-instructive interface, and progressively refining visualizations to minimize complexity. We discuss the challenges of designing a system for casual experts and highlight how we addressed this issue by modeling the organizational structure and workflows of the NSF within our system. We discuss each stage of the design process, starting with formative interviews, prototypes, and finally live deployments and evaluation with stakeholders.",Krishna P. C. Madhavan;Niklas Elmqvist;Mihaela Vorvoreanu;Xin Chen;Yuet Ling Wong;Hanjun Xian;Zhihua Dong;Aditya Johri,Krishna Madhavan;Niklas Elmqvist;Mihaela Vorvoreanu;Xin Chen;Yuetling Wong;Hanjun Xian;Zhihua Dong;Aditya Johri,Purdue University;Purdue University;Purdue University;Purdue University;Purdue University;Microsoft Corporation;Microsoft Corporation;George Mason University,10.1109/tvcg.2007.70541;10.1109/tvcg.2011.174;10.1109/tvcg.2010.177;10.1109/tvcg.2012.255;10.1109/tvcg.2009.123;10.1109/tvcg.2013.223;10.1109/infvis.2001.963283;10.1109/tvcg.2012.213;10.1109/vast.2008.4677361;10.1109/tvcg.2007.70541,"visual analytics, portfolio mining, web-based visualization, casual visualization, design study",30.0,16.0,40.0,1540.0,,,visualization visual analytics;research funding portfolio;expertise necessarily high;workflows nsf discuss;national,0.5746;0.3450;0.3208;0.2833;0.0544,"[np.int64(-1), -1, -1, -1, -1]",108;-1;-1;-1;-1,108,108,Visual Analytics
Vis,2021,Augmenting Sports Videos with VisCommentator,10.1109/tvcg.2021.3114806,http://dx.doi.org/10.1109/TVCG.2021.3114806,824.0,834.0,J,"Visualizing data in sports videos is gaining traction in sports analytics, given its ability to communicate insights and explicate player strategies engagingly. However, augmenting sports videos with such data visualizations is challenging, especially for sports analysts, as it requires considerable expertise in video editing. To ease the creation process, we present a design space that characterizes augmented sports videos at an element-level <i>(what the constituents are)</i> and clip-level <i>(how those constituents are organized)</i>. We do so by systematically reviewing 233 examples of augmented sports videos collected from TV channels, teams, and leagues. The design space guides selection of data insights and visualizations for various purposes. Informed by the design space and close collaboration with domain experts, we design VisCommentator, a fast prototyping tool, to eases the creation of augmented table tennis videos by leveraging machine learning-based data extractors and design space-based visualization recommendations. With VisCommentator, sports analysts can create an augmented video by <i>selecting the data</i> to visualize instead of manually <i>drawing the graphical marks</i>. Our system can be generalized to other racket sports <i>(e.g</i>., tennis, badminton) once the underlying datasets and models are available. A user study with seven domain experts shows high satisfaction with our system, confirms that the participants can reproduce augmented sports videos in a short period, and provides insightful implications into future improvements and opportunities.",Zhutian Chen;Shuainan Ye;Xiangtong Chu;Haijun Xia;Hui Zhang 0051;Huamin Qu;Yingcai Wu,Zhutian Chen;Shuainan Ye;Xiangtong Chu;Haijun Xia;Hui Zhang;Huamin Qu;Yingcai Wu,"Department of Cognitive Science and Design Lab, State Key Lab of CAD & CG, Zhejiang University and Hong Kong University of Science and Technology, University of California, San Diego, United States;State Key Lab of CAD & CG, Zhejiang University, China;State Key Lab of CAD & CG, Zhejiang University, China;Department of Cognitive Science and Design Lab, University of California, San Diego, United States;Department of Sport Science, Zhejiang University, China;Hong Kong University of Science and Technology, Hong Kong;State Key Lab of CAD & CG, Zhejiang University, China",10.1109/tvcg.2016.2598647;10.1109/tvcg.2019.2934810;10.1109/tvcg.2014.2346250;10.1109/tvcg.2018.2865240;10.1109/tvcg.2010.179;10.1109/tvcg.2020.3030403;10.1109/tvcg.2017.2745181;10.1109/tvcg.2019.2934398;10.1109/tvcg.2015.2467191;10.1109/tvcg.2017.2744218;10.1109/tvcg.2020.3028957;10.1109/tvcg.2020.3030359;10.1109/tvcg.2020.3030392;10.1109/tvcg.2019.2934656;10.1109/tvcg.2020.3030458,"Augmented Sports Videos,Video-based Visualization,Sports visualization,Intelligent Design Tool,Storytelling",19.0,42.0,62.0,2151.0,HM,,visualizing data sports;video editing ease;insightful implications future;element;design space close,0.7605;0.3853;0.1952;0.1452;0.1355,"[np.int64(-1), -1, -1, -1, -1]",88;-1;-1;-1;-1,88,88,Sports Data Visualization
Vis,1998,Visualizing diffusion tensor images of the mouse spinal cord,10.1109/visual.1998.745294,http://dx.doi.org/10.1109/VISUAL.1998.745294,127.0,134.0,C,"Within biological systems, water molecules undergo continuous stochastic Brownian motion. The diffusion rate can give clues to the structure of the underlying tissues. In some tissues, the rate is anisotropic. Diffusion-rate images can be calculated from diffusion-weighted MRI. A 2D diffusion tensor image (DTI) and an associated anatomical scalar field define seven values at each spatial location. We present two new methods for visually representing DTIs. The first method displays an array of ellipsoids, where the shape of each ellipsoid represents one tensor value. The ellipsoids are all normalized to approximately the same size so that they can be displayed simultaneously in context. The second method uses concepts from oil painting to represent the seven-valued data with multiple layers of varying brush strokes. Both methods successfully display most or all of the information in DTIs and provide exploratory methods for understanding them. The ellipsoid method has a simpler interpretation and explanation than the painting-motivated method; the painting-motivated method displays more of the information and is easier to read quantatively. We demonstrate the methods on images of the mouse spinal cord. The visualizations show significant differences between spinal cords from mice suffering from experimental allergic encephalomyelitis and spinal cords from wild-type mice. The differences are consistent with differences shown histologically and suggest that our new non-invasive imaging methodology and visualization of the results could have early diagnostic value for neurodegenerative diseases.",David H. Laidlaw;Eric T. Ahrens;David Kremers;Matthew J. Avalos;Russell E. Jacobs;Carol Readhead,D.H. Laidlaw;E.T. Ahrens;D. Kremers;M.J. Avalos;R.E. Jacobs;C. Readhead,"California Institute of Technology, Pasadena, CA, USA;California Institute of Technology, Pasadena, CA, USA;California Institute of Technology, Pasadena, CA, USA;California Institute of Technology, Pasadena, CA, USA;California Institute of Technology, Pasadena, CA, USA;Cedars Sinai Medical Center, Los Angeles, CA, USA",10.1109/visual.1992.235201;10.1109/visual.1992.235201,"multi-valued visualization, tensor field visualization,oil painting",223.0,63.0,26.0,287.0,,,diffusion tensor image;histologically suggest new;ellipsoids shape;simpler interpretation explanation;cords mice suffering,0.6835;0.2179;0.2178;0.1688;0.1257,"[np.int64(-1), -1, -1, -1, -1]",39;-1;-1;-1;-1,39,39,Diffusion MRI Analysis
Vis,2004,Surface reconstruction of noisy and defective data sets,10.1109/visual.2004.101,http://dx.doi.org/10.1109/VISUAL.2004.101,259.0,266.0,C,"We present a novel surface reconstruction algorithm that can recover high-quality surfaces from noisy and defective data sets without any normal or orientation information. A set of new techniques is introduced to afford extra noise tolerability, robust orientation alignment, reliable outlier removal, and satisfactory feature recovery. In our algorithm, sample points are first organized by an octree. The points are then clustered into a set of monolithically singly-oriented groups. The inside/outside orientation of each group is determined through a robust voting algorithm. We locally fit an implicit quadric surface in each octree cell. The locally fitted implicit surfaces are then blended to produce a signed distance field using the modified Shepard's method. We develop sophisticated iterative fitting algorithms to afford improved noise tolerance both in topology recognition and geometry accuracy. Furthermore, this iterative fitting algorithm, coupled with a local model selection scheme, provides a reliable sharp feature recovery mechanism even in the presence of bad input.",Hui Xie 0001;Kevin T. McDonnell;Hong Qin 0001,H. Xie;K.T. McDonnell;H. Qin,"Computer Science Department, State University of New York at Stony Brook, NY;Computer Science Department, State University of New York at Stony Brook, Stony Brook, NY, USA;Computer Science Department, State University of New York at Stony Brook, Stony Brook, NY, USA",10.1109/visual.2003.1250359;10.1109/visual.2003.1250359,"Computer Graphics, Surface Reconstruction, Surface Representation, MPU implicits, Modified Shepard's Method",106.0,39.0,27.0,475.0,,,surface reconstruction;octree cell locally;alignment reliable;outlier;using modified shepard,0.6800;0.2833;0.2343;0.2067;0.1219,"[np.int64(-1), -1, -1, -1, -1]",76;-1;-1;-1;-1,76,76,Surface Reconstruction Techniques
SciVis,2016,Topological Analysis of Inertial Dynamics,10.1109/tvcg.2016.2599018,http://dx.doi.org/10.1109/TVCG.2016.2599018,950.0,959.0,J,"Traditional vector field visualization has a close focus on velocity, and is typically constrained to the dynamics of massless particles. In this paper, we present a novel approach to the analysis of the force-induced dynamics of inertial particles. These forces can arise from acceleration fields such as gravitation, but also be dependent on the particle dynamics itself, as in the case of magnetism. Compared to massless particles, the velocity of an inertial particle is not determined solely by its position and time in a vector field. In contrast, its initial velocity can be arbitrary and impacts the dynamics over its entire lifetime. This leads to a four-dimensional problem for 2D setups, and a six-dimensional problem for the 3D case. Our approach avoids this increase in dimensionality and tackles the visualization by an integrated topological analysis approach. We demonstrate the utility of our approach using a synthetic time-dependent acceleration field, a system of magnetic dipoles, and N-body systems both in 2D and 3D.",Antoni Sagristà;Stefan Jordan;Andreas Just;Fabio Dias 0001;Luis Gustavo Nonato;Filip Sadlo,Antoni Sagristà;Stefan Jordan;Andreas Just;Fabio Dias;Luis Gustavo Nonato;Filip Sadlo,"Heidelberg University, Germany;Heidelberg University, Germany;ZAH, Heidelberg University, Germany;Universidade de Såo Paulo, Såo Carlos, Brazil;Universidade de Såo Paulo, Såo Carlos, Brazil;Heidelberg University, Germany",10.1109/visual.1993.398859;10.1109/tvcg.2014.2346415;10.1109/visual.1990.146386;10.1109/visual.1993.398859,Visualization of inertial dynamics;N-body systems;magnetism;acceleration,15.0,12.0,30.0,448.0,,,vector field visualization;induced dynamics inertial;massless particles;topological;entire lifetime,0.6084;0.4318;0.3073;0.2460;0.0203,"[np.int64(-1), -1, -1, -1, -1]",127;-1;-1;-1;-1,127,127,Field Visualization
InfoVis,2019,Why Authors Don't Visualize Uncertainty,10.1109/tvcg.2019.2934287,http://dx.doi.org/10.1109/TVCG.2019.2934287,130.0,139.0,J,"Clear presentation of uncertainty is an exception rather than rule in media articles, data-driven reports, and consumer applications, despite proposed techniques for communicating sources of uncertainty in data. This work considers, Why do so many visualization authors choose not to visualize uncertainty? I contribute a detailed characterization of practices, associations, and attitudes related to uncertainty communication among visualization authors, derived from the results of surveying 90 authors who regularly create visualizations for others as part of their work, and interviewing thirteen influential visualization designers. My results highlight challenges that authors face and expose assumptions and inconsistencies in beliefs about the role of uncertainty in visualization. In particular, a clear contradiction arises between authors' acknowledgment of the value of depicting uncertainty and the norm of omitting direct depiction of uncertainty. To help explain this contradiction, I present a rhetorical model of uncertainty omission in visualization-based communication. I also adapt a formal statistical model of how viewers judge the strength of a signal in a visualization to visualization-based communication, to argue that uncertainty communication necessarily reduces degrees of freedom in viewers' statistical inferences. I conclude with recommendations for how visualization research on uncertainty communication could better serve practitioners' current needs and values while deepening understanding of assumptions that reinforce uncertainty omission.",Jessica Hullman,Jessica Hullman,Northwestern University,10.1109/tvcg.2016.2598862;10.1109/tvcg.2011.255;10.1109/tvcg.2018.2864889;10.1109/tvcg.2018.2864909;10.1109/tvcg.2010.161;10.1109/tvcg.2014.2346298;10.1109/tvcg.2016.2598862,"Uncertainty visualization,graphical statistical inference,visualization rhetoric",97.0,87.0,55.0,2598.0,,,visualization research uncertainty;rule media articles;better;serve practitioners;necessarily reduces degrees,0.7483;0.1476;0.1162;0.0599;0.0291,"[np.int64(-1), -1, -1, -1, -1]",102;-1;-1;-1;-1,102,102,Visualization Value Assessment
InfoVis,2010,Pargnostics: Screen-Space Metrics for Parallel Coordinates,10.1109/tvcg.2010.184,http://dx.doi.org/10.1109/TVCG.2010.184,1017.0,1026.0,J,"Interactive visualization requires the translation of data into a screen space of limited resolution. While currently ignored by most visualization models, this translation entails a loss of information and the introduction of a number of artifacts that can be useful, (e.g., aggregation, structures) or distracting (e.g., over-plotting, clutter) for the analysis. This phenomenon is observed in parallel coordinates, where overlapping lines between adjacent axes form distinct patterns, representing the relation between variables they connect. However, even for a small number of dimensions, the challenge is to effectively convey the relationships for all combinations of dimensions. The size of the dataset and a large number of dimensions only add to the complexity of this problem. To address these issues, we propose Pargnostics, parallel coordinates diagnostics, a model based on screen-space metrics that quantify the different visual structures. Pargnostics metrics are calculated for pairs of axes and take into account the resolution of the display as well as potential axis inversions. Metrics include the number of line crossings, crossing angles, convergence, overplotting, etc. To construct a visualization view, the user can pick from a ranked display showing pairs of coordinate axes and the structures between them, or examine all possible combinations of axes at once in a matrix display. Picking the best axes layout is an NP-complete problem in general, but we provide a way of automatically optimizing the display according to the user's preferences based on our metrics and model.",Aritra Dasgupta;Robert Kosara,Aritra Dasgupta;Robert Kosara,"UNC-Charlotte, USA;UNC-Charlotte, USA",10.1109/infvis.2005.1532142;10.1109/tvcg.2006.138;10.1109/visual.1990.146402;10.1109/vast.2006.261423;10.1109/vast.2009.5332628;10.1109/infvis.2005.1532136;10.1109/infvis.1998.729559;10.1109/infvis.1997.636793;10.1109/infvis.2005.1532142,"Parallel coordinates, metrics, display optimization, visualization models",163.0,102.0,32.0,1207.0,,,interactive visualization requires;axes matrix;overlapping lines;inversions metrics;resolution currently ignored,0.6396;0.3388;0.3335;0.1644;0.1606,"[np.int64(-1), -1, -1, -1, -1]",110;-1;-1;-1;-1,110,110,Interactive Visualization
VAST,2017,Analyzing the Training Processes of Deep Generative Models,10.1109/tvcg.2017.2744938,http://dx.doi.org/10.1109/TVCG.2017.2744938,77.0,87.0,J,"Among the many types of deep models, deep generative models (DGMs) provide a solution to the important problem of unsupervised and semi-supervised learning. However, training DGMs requires more skill, experience, and know-how because their training is more complex than other types of deep models such as convolutional neural networks (CNNs). We develop a visual analytics approach for better understanding and diagnosing the training process of a DGM. To help experts understand the overall training process, we first extract a large amount of time series data that represents training dynamics (e.g., activation changes over time). A blue-noise polyline sampling scheme is then introduced to select time series samples, which can both preserve outliers and reduce visual clutter. To further investigate the root cause of a failed training process, we propose a credit assignment algorithm that indicates how other neurons contribute to the output of the neuron causing the training failure. Two case studies are conducted with machine learning experts to demonstrate how our approach helps understand and diagnose the training processes of DGMs. We also show how our approach can be directly used to analyze other types of deep models, such as CNNs.",Mengchen Liu;Jiaxin Shi;Kelei Cao;Jun Zhu 0001;Shixia Liu,Mengchen Liu;Jiaxin Shi;Kelei Cao;Jun Zhu;Shixia Liu,"Tsinghua University, National Engineering Lab for Big Data Software;Tsinghua University;Tsinghua University, National Engineering Lab for Big Data Software;Tsinghua University;Tsinghua University, National Engineering Lab for Big Data Software",10.1109/tvcg.2016.2598496;10.1109/tvcg.2014.2346594;10.1109/tvcg.2010.131;10.1109/tvcg.2011.239;10.1109/tvcg.2016.2598831;10.1109/tvcg.2016.2598797;10.1109/tvcg.2016.2598838;10.1109/tvcg.2016.2598829;10.1109/visual.2005.1532820;10.1109/vast.2016.7883511;10.1109/tvcg.2016.2598664;10.1109/tvcg.2010.132;10.1109/tvcg.2016.2598496,"deep learning,deep generative models,blue noise sampling,credit assignment",134.0,116.0,55.0,3126.0,,,deep generative;visual analytics;large time series;understanding diagnosing;blue noise polyline,0.6353;0.3519;0.2768;0.2458;0.2218,"[np.int64(-1), np.int64(-1), -1, -1, -1]",13;108;-1;-1;-1,13;108,13,Advanced Machine Learning
VAST,2014,The Spinel Explorer - Interactive Visual Analysis of Spinel Group Minerals,10.1109/tvcg.2014.2346754,http://dx.doi.org/10.1109/TVCG.2014.2346754,1913.0,1922.0,J,"Geologists usually deal with rocks that are up to several thousand million years old. They try to reconstruct the tectonic settings where these rocks were formed and the history of events that affected them through the geological time. The spinel group minerals provide useful information regarding the geological environment in which the host rocks were formed. They constitute excellent indicators of geological environments (tectonic settings) and are of invaluable help in the search for mineral deposits of economic interest. The current workflow requires the scientists to work with different applications to analyze spine data. They do use specific diagrams, but these are usually not interactive. The current workflow hinders domain experts to fully exploit the potentials of tediously and expensively collected data. In this paper, we introduce the Spinel Explorer-an interactive visual analysis application for spinel group minerals. The design of the Spinel Explorer and of the newly introduced interactions is a result of a careful study of geologists' tasks. The Spinel Explorer includes most of the diagrams commonly used for analyzing spinel group minerals, including 2D binary plots, ternary plots, and 3D Spinel prism plots. Besides specific plots, conventional information visualization views are also integrated in the Spinel Explorer. All views are interactive and linked. The Spinel Explorer supports conventional statistics commonly used in spinel minerals exploration. The statistics views and different data derivation techniques are fully integrated in the system. Besides the Spinel Explorer as newly proposed interactive exploration system, we also describe the identified analysis tasks, and propose a new workflow. We evaluate the Spinel Explorer using real-life data from two locations in Argentina: the Frontal Cordillera in Central Andes and Patagonia. We describe the new findings of the geologists which would have been much more difficult to achieve using the current workflow only. Very positive feedback from geologists confirms the usefulness of the Spinel Explorer.",Maria Luján Ganuza;Gabriela Ferracutti;Maria Florencia Gargiulo;Silvia Mabel Castro;Ernesto A. Bjerg;M. Eduard Gröller;Kresimir Matkovic,María Luján Ganuza;Gabriela Ferracutti;María Florencia Gargiulo;Silvia Mabel Castro;Ernesto Bjerg;Eduard Gröller;Krešimir Matković,"VyGLab Research Laboratory at the Universidad Nacional del Sur, Bahía Blanca, Argentina;Departamento de Geología, Universidad Nacional del Sur, Bahía Blanca, Argentina;Departamento de Geología, Universidad Nacional del Sur, Bahía Blanca, Argentina;VyGLab Research Laboratory at the Universidad Nacional del Sur, Bahía Blanca, Argentina;Departamento de Geología, Universidad Nacional del Sur, Bahía Blanca, Argentina;Vienna University of Technology, Austria;VRVis Research Center, Vienna, Austria",10.1109/infvis.2000.885086;10.1109/tvcg.2009.155;10.1109/visual.1995.485139,"Interactive visual analysis, visualization in earth/space/ and environmental sciences, coordinated and multiple views, design studies",21.0,12.0,29.0,664.0,,,spinel minerals exploration;explorer supports;interactive current workflow;statistics views different;hinders domain,0.6622;0.1978;0.1891;0.1877;-0.0340,"[np.int64(-1), -1, -1, -1, -1]",-1;-1;-1;-1;-1,,-1,Interactive 3D Visualization
InfoVis,2007,NodeTrix: a Hybrid Visualization of Social Networks,10.1109/tvcg.2007.70582,http://dx.doi.org/10.1109/TVCG.2007.70582,1302.0,1309.0,J,"The need to visualize large social networks is growing as hardware capabilities make analyzing large networks feasible and many new data sets become available. Unfortunately, the visualizations in existing systems do not satisfactorily resolve the basic dilemma of being readable both for the global structure of the network and also for detailed analysis of local communities. To address this problem, we present NodeTrix, a hybrid representation for networks that combines the advantages of two traditional representations: node-link diagrams are used to show the global structure of a network, while arbitrary portions of the network can be shown as adjacency matrices to better support the analysis of communities. A key contribution is a set of interaction techniques. These allow analysts to create a NodeTrix visualization by dragging selections to and from node-link and matrix forms, and to flexibly manipulate the NodeTrix representation to explore the dataset and create meaningful summary visualizations of their findings. Finally, we present a case study applying NodeTrix to the analysis of the InfoVis 2004 coauthorship dataset to illustrate the capabilities of NodeTrix as both an exploration tool and an effective means of communicating results.",Nathalie Henry;Jean-Daniel Fekete;Michael J. McGuffin,Nathalie Henry;Jean-Daniel Fekete;Michael J. McGuffin,"University of Sydney, Australia and INRIA Futurs, University of Paris-Sud 11, France;INRIA Futurs and Laboratory RI UMR CNRS 5800, France;Ontario Cancer Institute, University of Toronto, Canada",10.1109/tvcg.2006.160;10.1109/vast.2006.261426;10.1109/infvis.2005.1532126;10.1109/infvis.2004.46;10.1109/tvcg.2006.193;10.1109/infvis.2005.1532129;10.1109/tvcg.2006.166;10.1109/tvcg.2006.147;10.1109/infvis.2004.64;10.1109/infvis.2003.1249011;10.1109/tvcg.2006.160,"Network visualization, Matrix visualization, Hybrid visualization, Aggregation, Interaction",675.0,383.0,35.0,4341.0,,,visualize large social;capabilities nodetrix;matrix forms;unfortunately;dragging selections,0.6996;0.2556;0.1249;0.0841;0.0737,"[np.int64(-1), -1, -1, -1, -1]",87;-1;-1;-1;-1,87,87,Social Network Visualization
InfoVis,2016,Gaussian Cubes: Real-Time Modeling for Visual Exploration of Large Multidimensional Datasets,10.1109/tvcg.2016.2598694,http://dx.doi.org/10.1109/TVCG.2016.2598694,681.0,690.0,J,"Recently proposed techniques have finally made it possible for analysts to interactively explore very large datasets in real time. However powerful, the class of analyses these systems enable is somewhat limited: specifically, one can only quickly obtain plots such as histograms and heatmaps. In this paper, we contribute Gaussian Cubes, which significantly improves on state-of-the-art systems by providing interactive modeling capabilities, which include but are not limited to linear least squares and principal components analysis (PCA). The fundamental insight in Gaussian Cubes is that instead of precomputing counts of many data subsets (as state-of-the-art systems do), Gaussian Cubes precomputes the best multivariate Gaussian for the respective data subsets. As an example, Gaussian Cubes can fit hundreds of models over millions of data points in well under a second, enabling novel types of visual exploration of such large datasets. We present three case studies that highlight the visualization and analysis capabilities in Gaussian Cubes, using earthquake safety simulations, astronomical catalogs, and transportation statistics. The dataset sizes range around one hundred million elements and 5 to 10 dimensions. We present extensive performance results, a discussion of the limitations in Gaussian Cubes, and future research directions.",Zhe Wang;Nivan Ferreira;Youhao Wei;Aarthy Sankari Bhaskar;Carlos Scheidegger,Zhe Wang;Nivan Ferreira;Youhao Wei;Aarthy Sankari Bhaskar;Carlos Scheidegger,University of Arizona;Universidade Federal de Pernambuco;University of Arizona;University of Arizona;University of Arizona,10.1109/vast.2008.4677357;10.1109/infvis.2000.885086;10.1109/tvcg.2013.179;10.1109/tvcg.2014.2346452;10.1109/tvcg.2009.129;10.1109/tvcg.2013.141;10.1109/tvcg.2014.2346325;10.1109/vast.2012.6400490,data cubes;Data modeling;dimensionality reduction;interactive visualization,61.0,37.0,45.0,1167.0,,,gaussian cubes precomputes;studies highlight visualization;astronomical catalogs transportation;earthquake;enable somewhat limited,0.5705;0.3616;0.2544;0.1783;-0.0009,"[np.int64(-1), -1, -1, -1, -1]",-1;-1;-1;-1;-1,,-1,Interactive 3D Visualization
InfoVis,2010,The FlowVizMenu and Parallel Scatterplot Matrix: Hybrid Multidimensional Visualizations for Network Exploration,10.1109/tvcg.2010.205,http://dx.doi.org/10.1109/TVCG.2010.205,1100.0,1108.0,J,"A standard approach for visualizing multivariate networks is to use one or more multidimensional views (for example, scatterplots) for selecting nodes by various metrics, possibly coordinated with a node-link view of the network. In this paper, we present three novel approaches for achieving a tighter integration of these views through hybrid techniques for multidimensional visualization, graph selection and layout. First, we present the FlowVizMenu, a radial menu containing a scatterplot that can be popped up transiently and manipulated with rapid, fluid gestures to select and modify the axes of its scatterplot. Second, the FlowVizMenu can be used to steer an attribute-driven layout of the network, causing certain nodes of a node-link diagram to move toward their corresponding positions in a scatterplot while others can be positioned manually or by force-directed layout. Third, we describe a novel hybrid approach that combines a scatterplot matrix (SPLOM) and parallel coordinates called the Parallel Scatterplot Matrix (P-SPLOM), which can be used to visualize and select features within the network. We also describe a novel arrangement of scatterplots called the Scatterplot Staircase (SPLOS) that requires less space than a traditional scatterplot matrix. Initial user feedback is reported.",Christophe Viau;Michael J. McGuffin;Yves Chiricota;Igor Jurisica,Christophe Viau;Michael J. McGuffin;Yves Chiricota;Igor Jurisica,"École de technologie supérieure, Montreal, Canada;École de technologie supérieure, Montreal, Canada;Université du Quàbec à Chicoutimi, Chicoutimi, Canada;Ontario Cancer Institute, PMH UHN, Toronto, Canada",10.1109/tvcg.2009.151;10.1109/infvis.2005.1532142;10.1109/tvcg.2007.70523;10.1109/tvcg.2009.179;10.1109/vast.2009.5332586;10.1109/infvis.2005.1532141;10.1109/tvcg.2006.187;10.1109/infvis.2004.47;10.1109/tvcg.2007.70521;10.1109/infvis.2003.1249011;10.1109/tvcg.2008.153;10.1109/tvcg.2009.151,"Interactive graph drawing, network layout, attribute-driven layout, parallel coordinates, scatterplot matrix, radial menu",104.0,67.0,39.0,1480.0,,,visualizing multivariate networks;driven layout;gestures select modify;certain nodes node;standard,0.7594;0.2834;0.2561;0.2016;-0.0079,"[np.int64(-1), -1, -1, -1, -1]",87;-1;-1;-1;-1,87,87,Social Network Visualization
VAST,2020,A Visual Analytics Approach for Ecosystem Dynamics based on Empirical Dynamic Modeling,10.1109/tvcg.2020.3028956,http://dx.doi.org/10.1109/TVCG.2020.3028956,506.0,516.0,J,"An important approach for scientific inquiry across many disciplines involves using observational time series data to understand the relationships between key variables to gain mechanistic insights into the underlying rules that govern the given system. In real systems, such as those found in ecology, the relationships between time series variables are generally not static; instead, these relationships are dynamical and change in a nonlinear or state-dependent manner. To further understand such systems, we investigate integrating methods that appropriately characterize these dynamics (i.e., methods that measure interactions as they change with time-varying system states) with visualization techniques that can help analyze the behavior of the system. Here, we focus on empirical dynamic modeling (EDM) as a state-of-the-art method that specifically identifies causal variables and measures changing state-dependent relationships between time series variables. Instead of using approaches centered on parametric equations, EDM is an equation-free approach that studies systems based on their dynamic attractors. We propose a visual analytics system to support the identification and mechanistic interpretation of system states using an EDM-constructed dynamic graph. This work, as detailed in four analysis tasks and demonstrated with a GUI, provides a novel synthesis of EDM and visualization techniques such as brush-link visualization and visual summarization to interpret dynamic graphs representing ecosystem dynamics. We applied our proposed system to ecological simulation data and real data from a marine mesocosm study as two key use cases. Our case studies show that our visual analytics tools support the identification and interpretation of the system state by the user, and enable us to discover both confirmatory and new findings in ecosystem dynamics. Overall, we demonstrated that our system can facilitate an understanding of how systems function beyond the intuitive analysis of high-dimensional information based on specific domain knowledge.",Hiroaki Natsukawa;Ethan R. Deyle;Gerald M. Pao;Koji Koyamada;George Sugihara,Hiroaki Natsukawa;Ethan R. Deyle;Gerald M. Pao;Koji Koyamada;George Sugihara,"Kyoto University;Boston University and Scripps Institution of Oceanography, University of California, San Diego;Salk Institution for Biological Sciences;Kyoto University;Scripps Institution of Oceanography, University of California, San Diego",10.1109/tvcg.2009.181;10.1109/tvcg.2019.2934251;10.1109/tvcg.2013.198;10.1109/tvcg.2006.192;10.1109/tvcg.2015.2468078;10.1109/tvcg.2017.2745258;10.1109/tvcg.2009.181,"Visual analytics,empirical dynamic modeling,dynamic network,exploratory data analysis",4.0,7.0,58.0,1153.0,,,representing ecosystem dynamics;mechanistic insights underlying;techniques brush;enable discover confirmatory;case,0.6974;0.3436;0.1183;0.0408;-0.0517,"[np.int64(-1), -1, -1, -1, -1]",2;-1;-1;-1;-1,2,2,Ecosystem Simulation Tools
Vis,1996,Case Study: Visual access for landscape event based temporal data,10.1109/visual.1996.568148,http://dx.doi.org/10.1109/VISUAL.1996.568148,425.0,428.0,C,As ecological awareness increases there has been a shift towards more integrated forest management. Accurate modeling of future states of forested landscapes will allow better planning for safeguarding our forest resource for future generations. We present an initial exploration into providing visual access to information generated by SELES (Spatially Explicit Landscape Event Simulator). We explore the application of our visual access distortion technique to a block of temporal data created from a sequence of landscape event based information. This type of access extends the possibilities of visual exploration for temporal and spatial interrelations in a data set.,M. Sheelagh T. Carpendale;Andrew Fall;David J. Cowperthwaite;Joseph Fall;F. David Fracchia,M. Sheelagh T. Carpendale;A. Fall;D.J. Cowperthwaite;J. Fall;F.D. Fracchia,"Simon Fraser University, Burnaby, BC, CA;Simon Fraser University, Burnaby, BC, CA;Simon Fraser University, Burnaby, BC, CA;Simon Fraser University, Burnaby, BC, CA;Simon Fraser University, Burnaby, BC, CA",,"distortion viewing, 3D interaction, information visualization, temporal data",12.0,4.0,4.0,90.0,,,landscape event simulator;safeguarding forest resource;interrelations data;access extends possibilities;seles,0.5539;0.3467;0.2581;0.2084;0.0528,"[np.int64(-1), -1, -1, -1, -1]",2;-1;-1;-1;-1,2,2,Ecosystem Simulation Tools
VAST,2007,VAST 2007 Contest - Blue Iguanodon,10.1109/vast.2007.4389032,http://dx.doi.org/10.1109/VAST.2007.4389032,231.0,232.0,M,Visual analytics experts realize that one effective way to push the field forward and to develop metrics for measuring the performance of various visual analytics components is to hold an annual competition. The second visual analytics science and technology (VAST) contest was held in conjunction with the 2007 IEEE VAST symposium. In this contest participants were to use visual analytic tools to explore a large heterogeneous data collection to construct a scenario and find evidence buried in the data of illegal and terrorist activities that were occurring. A synthetic data set was made available as well as tasks. In this paper we describe some of the advances we have made from the first competition held in 2006.,Georges G. Grinstein;Catherine Plaisant;Sharon J. Laskowski;Theresa A. O'Connell;Jean Scholtz;Mark A. Whiting,Georges Grinstein;Catherine Plaisant;Sharon Laskowski;Theresa O'Connell;Jean Scholtz;Mark Whiting,"University of Massachusetts, Lowell, USA;National Institute for Standards and Technology, USA;National Institute for Standards and Technology, USA;Pacific Northwest National Laboratory, USA;Pacific Northwest National Laboratory, USA;University of Maryland, USA",,,17.0,10.0,6.0,121.0,,,visual analytics science;scenario evidence buried;illegal terrorist;hold annual competition;set available tasks,0.7134;0.2577;0.2463;0.1454;-0.0093,"[np.int64(-1), -1, -1, -1, -1]",108;-1;-1;-1;-1,108,108,Visual Analytics
SciVis,2020,ChemVA: Interactive Visual Analysis of Chemical Compound Similarity in Virtual Screening,10.1109/tvcg.2020.3030438,http://dx.doi.org/10.1109/TVCG.2020.3030438,891.0,901.0,J,"In the modern drug discovery process, medicinal chemists deal with the complexity of analysis of large ensembles of candidate molecules. Computational tools, such as dimensionality reduction (DR) and classification, are commonly used to efficiently process the multidimensional space of features. These underlying calculations often hinder interpretability of results and prevent experts from assessing the impact of individual molecular features on the resulting representations. To provide a solution for scrutinizing such complex data, we introduce ChemVA, an interactive application for the visual exploration of large molecular ensembles and their features. Our tool consists of multiple coordinated views: Hexagonal view, Detail view, 3D view, Table view, and a newly proposed Difference view designed for the comparison of DR projections. These views display DR projections combined with biological activity, selected molecular features, and confidence scores for each of these projections. This conjunction of views allows the user to drill down through the dataset and to efficiently select candidate compounds. Our approach was evaluated on two case studies of finding structurally similar ligands with similar binding affinity to a target protein, as well as on an external qualitative evaluation. The results suggest that our system allows effective visual inspection and comparison of different high-dimensional molecular representations. Furthermore, ChemVA assists in the identification of candidate compounds while providing information on the certainty behind different molecular representations.",María Virginia Sabando;Pavol Ulbrich;Matias Nicolás Selzer;Jan Byska;Jan Mican;Ignacio Ponzoni;Axel J. Soto;Maria Luján Ganuza;Barbora Kozlíková,María Virginia Sabando;Pavol Ulbrich;Matías Selzer;Jan Byška;Jan Mičan;Ignacio Ponzoni;Axel J. Soto;María Luján Ganuza;Barbora Kozlíková,"Department of Computer Science and Engineering, Universidad Nacional del Sur, Institute for Computer Science and Engineering (UNS-CONICET), Bahía, Blanca, Argentina and Department of Computer Science and Engineering, Universidad Nacional del Sur, VyGLab Research Laboratory (UNS-CICPBA), Institute for Computer Science and Engineering (UNS-CONICET), Bahía, Blanca, Argentina;Faculty of Informatics, Masaryk University, Brno, Czech Republic;Department of Computer Science and Engineering, Universidad Nacional del Sur, Institute for Computer Science and Engineering (UNS-CONICET), Bahía, Blanca, Argentina and Department of Computer Science and Engineering, Universidad Nacional del Sur, VyGLab Research Laboratory (UNS-CICPBA), Institute for Computer Science and Engineering (UNS-CONICET), Bahía, Blanca, Argentina;Faculty of Informatics, Masaryk University, Brno, Czech Republic;Department of Experimental Biology and RECETOX, Loschmidt Laboratories, Faculty of Medicine Masaryk University, Brno, Czech Republic;Department of Computer Science and Engineering, Universidad Nacional del Sur, Institute for Computer Science and Engineering (UNS-CONICET), Bahía, Blanca, Argentina and Department of Computer Science and Engineering, Universidad Nacional del Sur, VyGLab Research Laboratory (UNS-CICPBA), Institute for Computer Science and Engineering (UNS-CONICET), Bahía, Blanca, Argentina;Department of Computer Science and Engineering, Universidad Nacional del Sur, Institute for Computer Science and Engineering (UNS-CONICET), Bahía, Blanca, Argentina and Department of Computer Science and Engineering, Universidad Nacional del Sur, VyGLab Research Laboratory (UNS-CICPBA), Institute for Computer Science and Engineering (UNS-CONICET), Bahía, Blanca, Argentina;Department of Computer Science and Engineering, Universidad Nacional del Sur, Institute for Computer Science and Engineering (UNS-CONICET), Bahía, Blanca, Argentina and Department of Computer Science and Engineering, Universidad Nacional del Sur, VyGLab Research Laboratory (UNS-CICPBA), Institute for Computer Science and Engineering (UNS-CONICET), Bahía, Blanca, Argentina;Faculty of Informatics, Masaryk University, Brno, Czech Republic",10.1109/tvcg.2019.2934209;10.1109/tvcg.2011.185;10.1109/tvcg.2013.173;10.1109/tvcg.2016.2598495;10.1109/tvcg.2013.153;10.1109/tvcg.2019.2934209,"Virtual screening,visual analysis,dimensionality reduction,coordinated views,cheminformatics",4.0,9.0,79.0,665.0,,,candidate molecules computational;hinder interpretability results;projections views display;user drill dataset;qualitative,0.5921;0.2879;0.2414;0.1289;0.1061,"[np.int64(-1), -1, -1, -1, -1]",41;-1;-1;-1;-1,41,41,Protein Structure Design
Vis,2008,Interactive Visualization and Analysis of Transitional Flow,10.1109/tvcg.2008.146,http://dx.doi.org/10.1109/TVCG.2008.146,1420.0,1427.0,J,"A stand-alone visualization application has been developed by a multi-disciplinary, collaborative team with the sole purpose of creating an interactive exploration environment allowing turbulent flow researchers to experiment and validate hypotheses using visualization. This system has specific optimizations made in data management, caching computations, and visualization allowing for the interactive exploration of datasets on the order of 1TB in size. Using this application, the user (co-author Calo) is able to interactively visualize and analyze all regions of a transitional flow volume, including the laminar, transitional and fully turbulent regions. The underlying goal of the visualizations produced from these transitional flow simulations is to localize turbulent spots in the laminar region of the boundary layer, determine under which conditions they form, and follow their evolution. The initiation of turbulent spots, which ultimately lead to full turbulence, was located via a proposed feature detection condition and verified by experimental results. The conditions under which these turbulent spots form and coalesce are validated and presented.",Gregory P. Johnson;Victor M. Calo;Kelly P. Gaither,"Gregory P. Johnson,;Victor M. Calo;Kelly P. Gaither","Texas Advanced Computing Center, The University of Texas, Austin;Texas Advanced Computing Center, University of Technology, Austin, USA and Institute for Computational and Engineering Sciences, The University of Texas, Austin;Texas Advanced Computing Center, University of Technology, Austin, USA and Texas Advanced Computing Center, The University of Texas, Austin",10.1109/visual.2005.1532792;10.1109/visual.1993.398850;10.1109/visual.2005.1532794;10.1109/visual.1991.175818;10.1109/visual.2004.55;10.1109/visual.2004.54,"Applications of Visualization, Flow Visualization, Transitional Flow, Turbulence",11.0,8.0,31.0,323.0,,,turbulent flow researchers;interactively visualize;laminar region boundary;follow evolution initiation;localize,0.7199;0.2904;0.2775;0.0792;-0.1823,"[np.int64(-1), -1, -1, -1, -1]",17;-1;-1;-1;-1,17,17,Turbulent Flow Simulation
Vis,2007,Querying and Creating Visualizations by Analogy,10.1109/tvcg.2007.70584,http://dx.doi.org/10.1109/TVCG.2007.70584,1560.0,1567.0,J,"While there have been advances in visualization systems, particularly in multi-view visualizations and visual exploration, the process of building visualizations remains a major bottleneck in data exploration. We show that provenance metadata collected during the creation of pipelines can be reused to suggest similar content in related visualizations and guide semi-automated changes. We introduce the idea of query-by-example in the context of an ensemble of visualizations, and the use of analogies as first-class operations in a system to guide scalable interactions. We describe an implementation of these techniques in VisTrails, a publicly-available, open-source system.",Carlos Eduardo Scheidegger;Huy T. Vo;David Koop;Juliana Freire;Cláudio T. Silva,Carlos Scheidegger;Huy Vo;David Koop;Juliana Freire;Claudio Silva,"Scientific Computing and Imaging (SCI) Institute, University of Utah, USA;Scientific Computing and Imaging (SCI) Institute, University of Utah, USA;Scientific Computing and Imaging (SCI) Institute, University of Utah, USA;School of Computing, University of Utah, USA;Scientific Computing and Imaging (SCI) Institute, University of Utah, USA",10.1109/visual.2005.1532781;10.1109/infvis.2004.2;10.1109/visual.2004.112;10.1109/visual.2005.1532788;10.1109/visual.2005.1532795;10.1109/visual.2005.1532781,"visualization systems, query-by-example, analogy",160.0,70.0,31.0,594.0,BP,,building visualizations;provenance metadata;pipelines reused;suggest similar content;particularly,0.6312;0.4755;0.2436;0.2272;0.0794,"[np.int64(-1), -1, -1, -1, -1]",106;-1;-1;-1;-1,106,106,Visualization Development
VAST,2016,VisFlow - Web-based Visualization Framework for Tabular Data with a Subset Flow Model,10.1109/tvcg.2016.2598497,http://dx.doi.org/10.1109/TVCG.2016.2598497,251.0,260.0,J,"Data flow systems allow the user to design a flow diagram that specifies the relations between system components which process, filter or visually present the data. Visualization systems may benefit from user-defined data flows as an analysis typically consists of rendering multiple plots on demand and performing different types of interactive queries across coordinated views. In this paper, we propose VisFlow, a web-based visualization framework for tabular data that employs a specific type of data flow model called the subset flow model. VisFlow focuses on interactive queries within the data flow, overcoming the limitation of interactivity from past computational data flow systems. In particular, VisFlow applies embedded visualizations and supports interactive selections, brushing and linking within a visualization-oriented data flow. The model requires all data transmitted by the flow to be a data item subset (i.e. groups of table rows) of some original input table, so that rendering properties can be assigned to the subset unambiguously for tracking and comparison. VisFlow features the analysis flexibility of a flow diagram, and at the same time reduces the diagram complexity and improves usability. We demonstrate the capability of VisFlow on two case studies with domain experts on real-world datasets showing that VisFlow is capable of accomplishing a considerable set of visualization and analysis tasks. The VisFlow system is available as open source on GitHub.",Bowen Yu 0004;Cláudio T. Silva,Bowen Yu;Cláudio T. Silva,New York University;New York University,10.1109/tvcg.2009.195;10.1109/infvis.2004.12;10.1109/vast.2011.6102440;10.1109/infvis.1998.729560;10.1109/tvcg.2014.2346260;10.1109/infvis.2005.1532136;10.1109/tvcg.2011.225;10.1109/infvis.2003.1249013;10.1109/visual.2005.1532788;10.1109/tvcg.2014.2346753;10.1109/tvcg.2011.185;10.1109/tvcg.2014.2346291;10.1109/tvcg.2009.195,Visualization framework;data flow;subset flow model;tabular data,45.0,43.0,47.0,2370.0,,,data visualization;framework tabular;model visflow focuses;subset groups;limitation interactivity past,0.6549;0.2790;0.2140;0.1909;0.1538,"[np.int64(-1), -1, -1, -1, -1]",97;-1;-1;-1;-1,97,97,Data Visualization
Vis,2002,NASA's great zooms: a case study,10.1109/visual.2002.1183825,http://dx.doi.org/10.1109/VISUAL.2002.1183825,541.0,544.0,C,"This paper examines a series of NASA outreach visualizations created using several layers of remote sensing satellite data ranging from 4-kilometers per pixel to I-meter per pixel. The viewer is taken on a seamless, cloud free journey from a global view of the Earth down to ground level where buildings, streets, and cars are visible. The visualizations were produced using a procedural shader that takes advantage of accurate georegistration and color matching between images. The shader accurately and efficiently maps the data sets to geometry allowing for animations with few perceptual transitions among data sets. We developed a pipeline to facilitate the production of over twenty zoom visualizations. Millions of people have seen these visualizations through national and international media coverage.",Gregory W. Shirah;Horace Mitchell,G.W. Shirah;H.G. Mitchell,"Scientific Visualization Studio, NASA Goddard Space Flight Center, USA;Scientific Visualization Studio, NASA Goddard Space Flight Center, USA",,"visualization, remote sensing, renderman, shader, georegistration, color matching",0.0,0.0,11.0,120.0,,,nasa outreach visualizations;animations perceptual transitions;images shader accurately;level buildings streets;takes advantage,0.6192;0.3521;0.3128;0.1819;0.0875,"[np.int64(-1), -1, -1, -1, -1]",86;-1;-1;-1;-1,86,86,Scientific Visualization Presentations
InfoVis,2006,Visualization of Barrier Tree Sequences,10.1109/tvcg.2006.196,http://dx.doi.org/10.1109/TVCG.2006.196,781.0,788.0,J,"Dynamical models that explain the formation of spatial structures of RNA molecules have reached a complexity that requires novel visualization methods that help to analyze the validity of these models. We focus on the visualization of so-called folding landscapes of a growing RNA molecule. Folding landscapes describe the energy of a molecule as a function of its spatial configuration; thus they are huge and high dimensional. Their most salient features, however, are encapsulated by their so-called barrier tree that reflects the local minima and their connecting saddle points. For each length of the growing RNA chain there exists a folding landscape. We visualize the sequence of folding landscapes by an animation of the corresponding barrier trees. To generate the animation, we adapt the foresight layout with tolerance algorithm for general dynamic graph layout problems. Since it is very general, we give a detailed description of each phase: constructing a supergraph for the trees, layout of that supergraph using a modified DOT algorithm, and presentation techniques for the final animation",Christian Heine 0002;Gerik Scheuermann;Christoph Flamm;Ivo L. Hofacker;Peter F. Stadler,Christian Heine;Gerik Scheuermann;Christoph Flamm;Ivo L. Hofacker;Peter F. Stadler,"Image and Signal Processing Group, Department of Computer Science, University of Leipzig, Germany;Image and Signal Processing Group, Department of Computer Science, University of Leipzig, Germany;Bioinformatics Group, Department of Computer Science, University of Leipzig, Germany;Department of Theoretical Chemistry and Structural Biology, University of Vienna, Germany;Bioinformatics Group, Department of Computer Science, University of Leipzig, Germany",10.1109/infvis.2004.18;10.1109/infvis.2004.18,"Graph drawing, dynamic graph, RNA folding, energy landscape, fitness landscape, barrier tree",22.0,13.0,25.0,347.0,,,visualize sequence folding;spatial configuration huge;energy molecule function;tolerance algorithm general;tree,0.6288;0.3042;0.2203;0.1596;0.1468,"[np.int64(-1), -1, -1, -1, -1]",26;-1;-1;-1;-1,26,26,Biological Sequence Visualization
InfoVis,2020,A Bayesian cognition approach for belief updating of correlation judgement through uncertainty visualizations,10.1109/tvcg.2020.3029412,http://dx.doi.org/10.1109/TVCG.2020.3029412,978.0,988.0,J,"Understanding correlation judgement is important to designing effective visualizations of bivariate data. Prior work on correlation perception has not considered how factors including prior beliefs and uncertainty representation impact such judgements. The present work focuses on the impact of uncertainty communication when judging bivariate visualizations. Specifically, we model how users update their beliefs about variable relationships after seeing a scatterplot with and without uncertainty representation. To model and evaluate the belief updating, we present three studies. Study 1 focuses on a proposed “Line + Cone” visual elicitation method for capturing users' beliefs in an accurate and intuitive fashion. The findings reveal that our proposed method of belief solicitation reduces complexity and accurately captures the users' uncertainty about a range of bivariate relationships. Study 2 leverages the “Line + Cone” elicitation method to measure belief updating on the relationship between different sets of variables when seeing correlation visualization with and without uncertainty representation. We compare changes in users beliefs to the predictions of Bayesian cognitive models which provide normative benchmarks for how users should update their prior beliefs about a relationship in light of observed data. The findings from Study 2 revealed that one of the visualization conditions with uncertainty communication led to users being slightly more confident about their judgement compared to visualization without uncertainty information. Study 3 builds on findings from Study 2 and explores differences in belief update when the bivariate visualization is congruent or incongruent with users' prior belief. Our results highlight the effects of incorporating uncertainty representation, and the potential of measuring belief updating on correlation judgement with Bayesian cognitive models.",Alireza Karduni;Douglas Markant;Ryan Wesslen;Wenwen Dou,Alireza Karduni;Douglas Markant;Ryan Wesslen;Wenwen Dou,"University of North Carolina, Charlotte;University of North Carolina, Charlotte;University of North Carolina, Charlotte;University of North Carolina, Charlotte",10.1109/tvcg.2014.2346979;10.1109/tvcg.2019.2934287;10.1109/tvcg.2017.2743898;10.1109/tvcg.2018.2864889;10.1109/tvcg.2018.2864909;10.1109/tvcg.2015.2467671;10.1109/tvcg.2017.2745240;10.1109/tvcg.2010.177;10.1109/tvcg.2012.279;10.1109/tvcg.2012.199;10.1109/tvcg.2015.2467758;10.1109/tvcg.2013.153;10.1109/tvcg.2014.2346979,"Information visualization,Bayesian modeling,uncertainty visualizations,correlations,belief elicitation",22.0,14.0,59.0,911.0,,,correlation visualization uncertainty;models provide normative;different sets variables;incongruent;users update,0.6619;0.2804;0.1482;0.1320;0.0604,"[np.int64(-1), -1, -1, -1, -1]",73;-1;-1;-1;-1,73,73,Uncertainty Visualization
InfoVis,2007,VisLink: Revealing Relationships Amongst Visualizations,10.1109/tvcg.2007.70521,http://dx.doi.org/10.1109/TVCG.2007.70521,1192.0,1199.0,J,"We present VisLink, a method by which visualizations and the relationships between them can be interactively explored. VisLink readily generalizes to support multiple visualizations, empowers inter-representational queries, and enables the reuse of the spatial variables, thus supporting efficient information encoding and providing for powerful visualization bridging. Our approach uses multiple 2D layouts, drawing each one in its own plane. These planes can then be placed and re-positioned in 3D space: side by side, in parallel, or in chosen placements that provide favoured views. Relationships, connections, and patterns between visualizations can be revealed and explored using a variety of interaction techniques including spreading activation and search filters.",Christopher Collins 0001;Sheelagh Carpendale,Christopher Collins;Sheelagh Carpendale,"Computer Science Department, Univeristy of Toronto, Canada;Computer Science Department, University of Calgary, Canada",10.1109/visual.2003.1250400;10.1109/visual.1990.146402;10.1109/tvcg.2006.166;10.1109/visual.1991.175815;10.1109/infvis.2003.1249008;10.1109/infvis.2001.963279;10.1109/tvcg.2006.147;10.1109/visual.2003.1250400,"Graph visualization, node-link diagrams, structural comparison, hierarchies, 3D visualization, edge aggregation",275.0,139.0,22.0,1646.0,,,multiple visualizations empowers;vislink;positioned 3d space;search;including,0.7315;0.3305;0.2779;0.1259;0.0999,"[np.int64(-1), -1, -1, -1, -1]",138;-1;-1;-1;-1,138,138,Innovative Visualization Design
VAST,2006,Exploring Large-Scale Video News via Interactive Visualization,10.1109/vast.2006.261433,http://dx.doi.org/10.1109/VAST.2006.261433,75.0,82.0,C,"In this paper, we have developed a novel visualization framework to enable more effective visual analysis of large-scale news videos, where keyframes and keywords are automatically extracted from news video clips and visually represented according to their interestingness measurement to help audiences rind news stories of interest at first glance. A computational approach is also developed to quantify the interestingness measurement of video clips. Our experimental results have shown that our techniques for intelligent news video analysis have the capacity to enable more effective visualization of large-scale news videos. Our news video visualization system is very useful for security applications and for general audiences to quickly find news topics of interest from among many channels",Hangzai Luo;Jianping Fan 0001;Jing Yang 0001;William Ribarsky;Shin'ichi Satoh 0001,Hangzai Luo;Jianping Fan;Jing Yang;William Ribarsky;Shin'ichi Satoh,"Department of Computer Science, UNC-Charlotte, Charlotte, NC, USA;Department of Computer Science, UNC-Charlotte, Charlotte, NC, USA;Department of Computer Science, UNC-Charlotte, Charlotte, NC, USA;Department of Computer Science, UNC-Charlotte, Charlotte, NC, USA;National Institute of Informatics (NII), Tokyo, Japan",10.1109/infvis.1998.729570;10.1109/infvis.2003.1249019;10.1109/visual.1991.175815;10.1109/infvis.1998.729570,"News Visualization, Semantic Video Classification",36.0,23.0,25.0,390.0,,,news video visualization;according interestingness;keywords automatically extracted;computational approach developed;capacity enable,0.7307;0.3640;0.2743;0.1352;-0.0199,"[np.int64(-1), -1, -1, -1, -1]",71;-1;-1;-1;-1,71,71,Video Visualization
VAST,2015,Evolution inspector: Interactive visual analysis for evolutionary molecular design,10.1109/vast.2015.7347687,http://dx.doi.org/10.1109/VAST.2015.7347687,219.0,220.0,M,"De novo design is a computational-chemistry method, where a computer program utilizes an optimization method, in our case an evolutionary algorithm, to design compounds with desired chemical properties. The optimization is performed with respect to a quantity called fitness, defined by the chemists. We present a tool that connects interactive visual analysis and evolutionary algorithm-based molecular design. We employ linked views to communicate different aspects of the data: the statistical distribution of molecule fitness, connections between individual molecules during the evolution and 3D molecular structure. The application is already used by chemists to explore and analyze the results of their evolution experiments and has proved to be highly useful.",Veronika Soltészová;Marco Foscato;Sondre H. Eliasson;Vidar R. Jensen,Veronika Solteszova;Marco Foscato;Sondre H. Eliasson;Vidar R. Jensen,"Christian Michelsen Research, Bergen, Norway;Department of Chemistry, University of Bergen, Norway;Department of Chemistry, University of Bergen, Norway;Department of Chemistry, University of Bergen, Norway",0.1109/tvcg.2007.70535,,0.0,1.0,10.0,137.0,,,molecular design;evolution 3d;interactive visual analysis;called fitness defined;linked,0.6966;0.2911;0.2575;0.1502;0.0422,"[np.int64(-1), -1, -1, -1, -1]",41;-1;-1;-1;-1,41,41,Protein Structure Design
VAST,2014,Vismate: Interactive Visual Analysis of Station-Based Observation Data on Climate Changes,10.1109/vast.2014.7042489,http://dx.doi.org/10.1109/VAST.2014.7042489,133.0,142.0,C,"We present a new approach to visualizing the climate data of multi-dimensional, time-series, and geo-related characteristics. Our approach integrates three new highly interrelated visualization techniques, and uses the same input data types as in the traditional model-based analysis methods. As the main visualization view, Global Radial Map is used to identify the overall state of climate changes and provide users with a compact and intuitive view for analyzing spatial and temporal patterns at the same time. Other two visualization techniques, providing complementary views, are specialized in analysing time trend and detecting abnormal cases, which are two important analysis tasks in any climate change study. Case studies and expert reviews have been conducted, through which the effectiveness and scalability of the proposed approach has been confirmed.",Jie Li 0006;Kang Zhang 0001;Zhao-Peng Meng,Jie Li;Kang Zhang;Zhao-Peng Meng,"School of Computer Science and Technology, National Ocean Technology Center, Tianjin, China;Department of Computer Science, The University of Texas, Dallas, USA;School of Computer Software, Tianjin University, China",10.1109/vast.2012.6400491;10.1109/tvcg.2010.194;10.1109/infvis.2000.885098;10.1109/tvcg.2007.70523;10.1109/tvcg.2009.199;10.1109/tvcg.2010.183;10.1109/vast.2012.6400553;10.1109/tvcg.2010.180;10.1109/tvcg.2009.197;10.1109/tvcg.2008.187;10.1109/tvcg.2012.284;10.1109/vast.2012.6400491,"climate changes, spatiotemporal visualization, station-based observation data, radial layout, visual analytics",44.0,18.0,54.0,760.0,,,visualizing climate data;radial;compact intuitive;abnormal cases important;proposed approach confirmed,0.8036;0.1524;0.0719;0.0440;0.0041,"[np.int64(-1), -1, -1, -1, -1]",146;-1;-1;-1;-1,146,146,Visualization Techniques
Vis,2023,Adaptive Assessment of Visualization Literacy,10.1109/tvcg.2023.3327165,http://dx.doi.org/10.1109/TVCG.2023.3327165,628.0,637.0,J,"Visualization literacy is an essential skill for accurately interpreting data to inform critical decisions. Consequently, it is vital to understand the evolution of this ability and devise targeted interventions to enhance it, requiring concise and repeatable assessments of visualization literacy for individuals. However, current assessments, such as the Visualization Literacy Assessment Test (vlat), are time-consuming due to their fixed, lengthy format. To address this limitation, we develop two streamlined computerized adaptive tests (cats) for visualization literacy, a-vlat and a-calvi, which measure the same set of skills as their original versions in half the number of questions. Specifically, we (1) employ item response theory (IRT) and non-psychometric constraints to construct adaptive versions of the assessments, (2) finalize the configurations of adaptation through simulation, (3) refine the composition of test items of a-calvi via a qualitative study, and (4) demonstrate the test-retest reliability (ICC: 0.98 and 0.98) and convergent validity (correlation: 0.81 and 0.66) of both CATS via four online studies. We discuss practical recommendations for using our CATS and opportunities for further customization to leverage the full potential of adaptive assessments. All supplemental materials are available at https://osf.io/a6258/.",Yuan Cui;Lily W. Ge;Yiren Ding;Fumeng Yang;Lane Harrison;Matthew Kay 0001,Yuan Cui;Lily W. Ge;Yiren Ding;Fumeng Yang;Lane Harrison;Matthew Kay,"Northwestern University, USA;Northwestern University, USA;Worcester Polytechnic Institute, USA;Northwestern University, USA;Worcester Polytechnic Institute, USA;Northwestern University, USA",0.1109/tvcg.2014.2346984;10.1109/tvcg.2016.2598920,"Visualization literacy,computerized adaptive testing,item response theory",,1.0,33.0,521.0,,,assessments visualization literacy;leverage potential adaptive;irt non;convergent validity;lengthy format address,0.7585;0.1419;0.1090;0.0266;-0.0747,"[np.int64(-1), -1, -1, -1, -1]",94;-1;-1;-1;-1,94,94,Visualization Literacy
InfoVis,2020,Implicit Multidimensional Projection of Local Subspaces,10.1109/tvcg.2020.3030368,http://dx.doi.org/10.1109/TVCG.2020.3030368,1558.0,1568.0,J,"We propose a visualization method to understand the effect of multidimensional projection on local subspaces, using implicit function differentiation. Here, we understand the local subspace as the multidimensional local neighborhood of data points. Existing methods focus on the projection of multidimensional data points, and the neighborhood information is ignored. Our method is able to analyze the shape and directional information of the local subspace to gain more insights into the global structure of the data through the perception of local structures. Local subspaces are fitted by multidimensional ellipses that are spanned by basis vectors. An accurate and efficient vector transformation method is proposed based on analytical differentiation of multidimensional projections formulated as implicit functions. The results are visualized as glyphs and analyzed using a full set of specifically-designed interactions supported in our efficient web-based visualization tool. The usefulness of our method is demonstrated using various multi- and high-dimensional benchmark datasets. Our implicit differentiation vector transformation is evaluated through numerical comparisons; the overall method is evaluated through exploration examples and use cases.",Rongzheng Bian;Yumeng Xue;Liang Zhou 0001;Jian Zhang 0070;Baoquan Chen;Daniel Weiskopf;Yunhai Wang,Rongzheng Bian;Yumeng Xue;Liang Zhou;Jian Zhang;Baoquan Chen;Daniel Weiskopf;Yunhai Wang,"Shandong University, Qingdao;Shandong University, Qingdao;University of Utah;CNIC, CAS;Peking University;University of Stuttgart;Shandong University, Qingdao",10.1109/vast.2012.6400488;10.1109/tvcg.2015.2467717;10.1109/tvcg.2013.153;10.1109/tvcg.2016.2598495;10.1109/tvcg.2019.2934811;10.1109/tvcg.2011.220;10.1109/tvcg.2018.2865194;10.1109/tvcg.2007.70535;10.1109/vast.2010.5652460;10.1109/vast.2012.6400488,"High-dimensional data visualization,dimensionality reduction,local linear subspaces,user interaction",7.0,4.0,51.0,830.0,,,differentiation multidimensional projections;visualization tool usefulness;ellipses;understand local;ignored method able,0.6228;0.3539;0.2404;0.2315;-0.0581,"[np.int64(-1), -1, -1, -1, -1]",141;-1;-1;-1;-1,141,141,Advanced Rendering Techniques
Vis,1999,DELTA's Virtual Physics Laboratory: a comprehensive learning platform on physics and astronomy,10.1109/visual.1999.809920,http://dx.doi.org/10.1109/VISUAL.1999.809920,421.0,423.0,C,"Perhaps the most effective instrument to simplify and to clarify the comprehension of any complex mathematical or scientific theory is through visualisation. Moreover using interactivity and 3D real time representations, one can easily explore and hence learn quickly in the virtual environments. The concept of virtual and safe laboratories has vast potentials in education. With the aid of computer simulations and 3D visualisations, many dangerous or cumbersome experiments may be implemented in the virtual environments, with rather small effort. Nonetheless visualisation alone is of little use if the respective simulation is not scientifically accurate. Hence a rigorous combination of precise computation as well as sophisticated visualisation, presented through some intuitive user interface is required to realise a virtual laboratory for education. We introduce Delta's Virtual Physics Laboratory, comprising a wide range of applications in the field of physics and astronomy, which can be implemented and used as an interactive learning tool on the World Wide Web.",Sepideh Chakaveh;Udo Zlender;Detlef Skaley;Konstantinos Fostiropoulos;Dieter Breitschwerdt,S. Chakaveh;U. Zlender;D. Skaley;K. Fostiropoulos;D. Breitschwerdt,"GMD Forschungszentrum Informationtechnik GmBH, German National Research Centre for Information Technology, IMK-DELTA, Saint Augustine, USA;GMD Forschungszentrum Informationtechnik GmBH, German National Research Centre for Information Technology, IMK-DELTA, Saint Augustine, USA;GMD Forschungszentrum Informationtechnik GmBH, German National Research Centre for Information Technology, IMK-DELTA, Saint Augustine, USA;;Max Planck Institut für Extraterrestrische Physik, Munich, Germany and Department of Physics & Astronomy, University of Heidelberg, Germany",,,,4.0,6.0,104.0,,,virtual physics laboratory;visualisation presented intuitive;astronomy;combination precise computation;nonetheless,0.7756;0.3729;0.3248;0.0794;0.0102,"[np.int64(-1), -1, -1, -1, -1]",17;-1;-1;-1;-1,17,17,Turbulent Flow Simulation
Vis,2024,DiffFit: Visually-Guided Differentiable Fitting of Molecule Structures to a Cryo-EM Map,10.1109/tvcg.2024.3456404,http://dx.doi.org/10.1109/TVCG.2024.3456404,558.0,568.0,J,"We introduce DiffFit, a differentiable algorithm for fitting protein atomistic structures into an experimental reconstructed Cryo-Electron Microscopy (cryo-EM) volume map. In structural biology, this process is necessary to semi-automatically composite large mesoscale models of complex protein assemblies and complete cellular structures that are based on measured cryo-EM data. The current approaches require manual fitting in three dimensions to start, resulting in approximately aligned structures followed by an automated fine-tuning of the alignment. The DiffFit approach enables domain scientists to fit new structures automatically and visualize the results for inspection and interactive revision. The fitting begins with differentiable three-dimensional (3D) rigid transformations of the protein atom coordinates followed by sampling the density values at the atom coordinates from the target cryo-EM volume. To ensure a meaningful correlation between the sampled densities and the protein structure, we proposed a novel loss function based on a multi-resolution volume-array approach and the exploitation of the negative space. This loss function serves as a critical metric for assessing the fitting quality, ensuring the fitting accuracy and an improved visualization of the results. We assessed the placement quality of DiffFit with several large, realistic datasets and found it to be superior to that of previous methods. We further evaluated our method in two use cases: automating the integration of known composite structures into larger protein complexes and facilitating the fitting of predicted protein domains into volume densities to aid researchers in identifying unknown proteins. We implemented our algorithm as an open-source plugin (github.com/nanovis/DiffFit) in ChimeraX, a leading visualization software in the field. All supplemental materials are available at osf. io/5tx4q.",Deng Luo;Zainab Alsuwaykit;Dawar Khan;Ondrej Strnad;Tobias Isenberg 0001;Ivan Viola,Deng Luo;Zainab Alsuwaykit;Dawar Khan;Ondřej Strnad;Tobias Isenberg;Ivan Viola,"Visual Computing Center at King Abdullah University of Science and Technology (KAUST), Saudi Arabia;Visual Computing Center at King Abdullah University of Science and Technology (KAUST), Saudi Arabia;Visual Computing Center at King Abdullah University of Science and Technology (KAUST), Saudi Arabia;Visual Computing Center at King Abdullah University of Science and Technology (KAUST), Saudi Arabia;Université Paris-Saclay, CNRS, Inria, LISN, France;Visual Computing Center at King Abdullah University of Science and Technology (KAUST), Saudi Arabia",10.1109/tvcg.2018.2864851;10.1109/tvcg.2020.3030415;10.1109/vast.2014.7042491;10.1109/tvcg.2015.2467293;10.1109/tvcg.2022.3209411,"Scalar field data,algorithms,genomics,cryo-EM,application-motivated visualization,process/workflow design,life sciences,health,medicine,biology,structural biology,bioinformatics",,0.0,52.0,308.0,,X,fitting protein atomistic;reconstructed cryo;leading visualization;necessary;differentiable dimensional,0.6115;0.3870;0.2166;0.0255;0.0219,"[np.int64(-1), -1, -1, -1, -1]",41;-1;-1;-1;-1,41,41,Protein Structure Design
Vis,2002,Efficient simplification of point-sampled surfaces,10.1109/visual.2002.1183771,http://dx.doi.org/10.1109/VISUAL.2002.1183771,163.0,170.0,C,"We introduce, analyze and quantitatively compare a number of surface simplification methods for point-sampled geometry. We have implemented incremental and hierarchical clustering, iterative simplification, and particle simulation algorithms to create approximations of point-based models with lower sampling density. All these methods work directly on the point cloud, requiring no intermediate tesselation. We show how local variation estimation and quadric error metrics can be employed to diminish the approximation error and concentrate more samples in regions of high curvature. To compare the quality of the simplified surfaces, we have designed a new method for computing numerical and visual error estimates for point-sampled surfaces. Our algorithms are fast, easy to implement, and create high-quality surface approximations, clearly demonstrating the effectiveness of point-based surface simplification.",Mark Pauly;Markus H. Gross;Leif Kobbelt,M. Pauly;M. Gross;L.P. Kobbelt,"ETH Zurich, Switzerland;ETH Zurich, Switzerland;RWTH Aachen, Germany",10.1109/visual.2001.964503;10.1109/visual.1999.809896;10.1109/visual.2001.964502;10.1109/visual.2001.964489;10.1109/visual.2000.885722;10.1109/visual.2001.964503,,1370.0,340.0,32.0,4117.0,,,based surface simplification;particle simulation;error concentrate samples;point;local,0.6769;0.3500;0.1362;0.1139;0.0937,"[np.int64(-1), -1, -1, -1, -1]",76;-1;-1;-1;-1,76,76,Surface Reconstruction Techniques
Vis,1990,Applying space subdivision techniques to volume rendering,10.1109/visual.1990.146377,http://dx.doi.org/10.1109/VISUAL.1990.146377,150.0,,C,"The authors present a ray-tracing algorithm for volume rendering designed to work efficiently when the data of interest is distributed sparsely through the volume. A simple preprocessing step identifies the voxels representing features of interest. Frequently this set of voxels, arbitrarily distributed in three-dimensional space, is a small fraction of the original voxel grid. A median-cut space partitioning scheme, combined with bounding volumes to prune void spaces in the resulting search structure, is used to store the voxels of interest in a k-d tree. The k-d tree is used as a data structure. The tree is then efficiently ray-traced to render the voxel data. The k-d tree is view independent, and can be used for animation sequences involving changes in positions of the viewer or positions of lights. This search structure has been applied to render voxel data from MRI, CAT scan, and electron density distributions.&lt;&lt;ETX&gt;&gt;",Kalpathi R. Subramanian;Donald S. Fussell,K.R. Subramanian;D.S. Fussell,"Department of Computer Sciences, University of Texas, Austin, Austin, TX, USA;Department of Computer Sciences, University of Texas, Austin, Austin, TX, USA",,,139.0,20.0,21.0,163.0,,,volume rendering designed;tree used data;scan electron;independent used animation;authors,0.6821;0.2581;0.1895;0.1199;0.0323,"[np.int64(-1), -1, -1, -1, -1]",52;-1;-1;-1;-1,52,52,Volume Rendering Techniques
SciVis,2017,Instant Construction and Visualization of Crowded Biological Environments,10.1109/tvcg.2017.2744258,http://dx.doi.org/10.1109/TVCG.2017.2744258,862.0,872.0,J,"We present the first approach to integrative structural modeling of the biological mesoscale within an interactive visual environment. These complex models can comprise up to millions of molecules with defined atomic structures, locations, and interactions. Their construction has previously been attempted only within a non-visual and non-interactive environment. Our solution unites the modeling and visualization aspect, enabling interactive construction of atomic resolution mesoscale models of large portions of a cell. We present a novel set of GPU algorithms that build the basis for the rapid construction of complex biological structures. These structures consist of multiple membrane-enclosed compartments including both soluble molecules and fibrous structures. The compartments are defined using volume voxelization of triangulated meshes. For membranes, we present an extension of the Wang Tile concept that populates the bilayer with individual lipids. Soluble molecules are populated within compartments distributed according to a Halton sequence. Fibrous structures, such as RNA or actin filaments, are created by self-avoiding random walks. Resulting overlaps of molecules are resolved by a forced-based system. Our approach opens new possibilities to the world of interactive construction of cellular compartments. We demonstrate its effectiveness by showcasing scenes of different scale and complexity that comprise blood plasma, mycoplasma, and HIV.",Tobias Klein;Ludovic Autin;Barbora Kozlíková;David S. Goodsell;Arthur J. Olson;M. Eduard Gröller;Ivan Viola,Tobias Klein;Ludovic Autin;Barbora Kozlíková;David S. Goodsell;Arthur Olson;M. Eduard Gröller;Ivan Viola,"TU Wien, Austria;The Scripps Research Institute, California, USA;Masaryk University, Brno, Czech Republic;The Scripps Research Institute, California, USA;The Scripps Research Institute, California, USA;TU Wien, VRVis Research Center, Austria;TU Wien, Austria",,"Interactive modeling,population,biological data,interactive visualization",37.0,35.0,49.0,1043.0,HM,,biological mesoscale interactive;gpu algorithms;plasma mycoplasma hiv;effectiveness showcasing scenes;build,0.6177;0.4216;0.1083;0.1040;0.0590,"[np.int64(-1), -1, -1, -1, -1]",-1;-1;-1;-1;-1,,-1,Interactive 3D Visualization
InfoVis,2020,Modeling the Influence of Visual Density on Cluster Perception in Scatterplots Using Topology,10.1109/tvcg.2020.3030365,http://dx.doi.org/10.1109/TVCG.2020.3030365,1829.0,1839.0,J,"Scatterplots are used for a variety of visual analytics tasks, including cluster identification, and the visual encodings used on a scatterplot play a deciding role on the level of visual separation of clusters. For visualization designers, optimizing the visual encodings is crucial to maximizing the clarity of data. This requires accurately modeling human perception of cluster separation, which remains challenging. We present a multi-stage user study focusing on four factors-distribution size of clusters, number of points, size of points, and opacity of points-that influence cluster identification in scatterplots. From these parameters, we have constructed two models, a distance-based model, and a density-based model, using the merge tree data structure from Topological Data Analysis. Our analysis demonstrates that these factors play an important role in the number of clusters perceived, and it verifies that the distance-based and density-based models can reasonably estimate the number of clusters a user observes. Finally, we demonstrate how these models can be used to optimize visual encodings on real-world data.",Ghulam Jilani Quadri;Paul Rosen 0001,Ghulam Jilani Quadri;Paul Rosen,University of South Florida;University of South Florida,10.1109/vast.2014.7042493;10.1109/infvis.2005.1532136;10.1109/tvcg.2014.2346594;10.1109/tvcg.2019.2934541;10.1109/tvcg.2018.2864907;10.1109/tvcg.2014.2346572;10.1109/tvcg.2007.70535;10.1109/tvcg.2013.183;10.1109/tvcg.2014.2346983;10.1109/tvcg.2014.2346979;10.1109/tvcg.2019.2934799;10.1109/tvcg.2017.2744339;10.1109/tvcg.2017.2744184;10.1109/tvcg.2017.2744359;10.1109/infvis.2005.1532142;10.1109/vast.2014.7042493,"Scatterplot,clustering,perception,empirical evaluation,visual encoding,crowdsourcing,topological data analysis",5.0,16.0,88.0,737.0,,,clusters visualization;opacity points influence;encodings;models reasonably estimate;play important,0.7490;0.1676;0.1076;0.0878;0.0398,"[np.int64(-1), -1, -1, -1, -1]",85;-1;-1;-1;-1,85,85,Cluster Visualization
Vis,1990,A procedural interface for volume rendering,10.1109/visual.1990.146362,http://dx.doi.org/10.1109/VISUAL.1990.146362,36.0,,C,"The author presents a simple, procedural interface for volume rendering. The interface is built on three types of objects: volumes, which contain the data to be visualized, environments, which set up viewing and lighting, and image objects, which convert results to a user-definable format. A volume is rendered against a particular environment with the results sent to an image object for conversion. By defining volume qualities such as color, opacity, and gradient in terms of user-definable transfer functions, the rendering process is made independent of the data set's underlying representation.&lt;&lt;ETX&gt;&gt;",James L. Montine,J.L. Montine,"Alliant Computer Systems Corporation, Littleton, MA, USA",,,18.0,3.0,9.0,71.0,,,volume rendering interface;lighting image objects;procedural;defining;convert results user,0.8052;0.3039;0.2655;0.0681;0.0542,"[np.int64(-1), -1, -1, -1, -1]",52;-1;-1;-1;-1,52,52,Volume Rendering Techniques
Vis,2022,FlowNL: Asking the Flow Data in Natural Languages,10.1109/tvcg.2022.3209453,http://dx.doi.org/10.1109/TVCG.2022.3209453,1200.0,1210.0,J,"Flow visualization is essentially a tool to answer domain experts' questions about flow fields using rendered images. Static flow visualization approaches require domain experts to raise their questions to visualization experts, who develop specific techniques to extract and visualize the flow structures of interest. Interactive visualization approaches allow domain experts to ask the system directly through the visual analytic interface, which provides flexibility to support various tasks. However, in practice, the visual analytic interface may require extra learning effort, which often discourages domain experts and limits its usage in real-world scenarios. In this paper, we propose FlowNL, a novel interactive system with a natural language interface. FlowNL allows users to manipulate the flow visualization system using plain English, which greatly reduces the learning effort. We develop a natural language parser to interpret user intention and translate textual input into a declarative language. We design the declarative language as an intermediate layer between the natural language and the programming language specifically for flow visualization. The declarative language provides selection and composition rules to derive relatively complicated flow structures from primitive objects that encode various kinds of information about scalar fields, flow patterns, regions of interest, connectivities, etc. We demonstrate the effectiveness of FlowNL using multiple usage scenarios and an empirical evaluation.",Jieying Huang;Yang Xi;Junnan Hu;Jun Tao 0002,Jieying Huang;Yang Xi;Junnan Hu;Jun Tao,"School of Computer Science and Engineering, Sun Yat-sen University, China;School of Computer Science and Engineering, Sun Yat-sen University, China;School of Computer Science and Engineering, Sun Yat-sen University, China;Southern Marine Science and Engineering Guangdong Laboratory (Zhuhai), School of Computer Science and Engineering, Sun Yat-sen University, National Supercomputer Center in Guangzhou, China",10.1109/tvcg.2019.2934310;10.1109/tvcg.2011.185;10.1109/visual.2005.1532856;10.1109/tvcg.2014.2346322;10.1109/tvcg.2019.2934785;10.1109/tvcg.2017.2744684;10.1109/tvcg.2013.121;10.1109/tvcg.2018.2864806;10.1109/tvcg.2013.189;10.1109/tvcg.2019.2934537;10.1109/tvcg.2020.3030453;10.1109/tvcg.2021.3114848;10.1109/tvcg.2020.3030378;10.1109/tvcg.2020.3030378;10.1109/tvcg.2019.2934367;10.1109/tvcg.2014.2346318;10.1109/visual.2004.128;10.1109/tvcg.2016.2599030;10.1109/tvcg.2015.2467091;10.1109/tvcg.2017.2745219;10.1109/visual.2003.1250376;10.1109/vast47406.2019.8986918;10.1109/tvcg.2018.2864841;10.1109/tvcg.2010.131;10.1109/visual.2005.1532831;10.1109/tvcg.2019.2934668;10.1109/tvcg.2019.2934310,"Flow visualization,natural language interface,interactive exploration,declarative grammar",,7.0,59.0,956.0,,,flow visualization declarative;translate textual input;using rendered images;experts raise;require domain,0.7705;0.2371;0.1520;0.1073;0.0361,"[np.int64(-1), -1, -1, -1, -1]",63;-1;-1;-1;-1,63,63,Flow Visualization Techniques
Vis,2008,AD-Frustum: Adaptive Frustum Tracing for Interactive Sound Propagation,10.1109/tvcg.2008.111,http://dx.doi.org/10.1109/TVCG.2008.111,1707.0,1722.0,J,"We present an interactive algorithm to compute sound propagation paths for transmission, specular reflection and edge diffraction in complex scenes. Our formulation uses an adaptive frustum representation that is automatically sub-divided to accurately compute intersections with the scene primitives. We describe a simple and fast algorithm to approximate the visible surface for each frustum and generate new frusta based on specular reflection and edge diffraction. Our approach is applicable to all triangulated models and we demonstrate its performance on architectural and outdoor models with tens or hundreds of thousands of triangles and moving objects. In practice, our algorithm can perform geometric sound propagation in complex scenes at 4-20 frames per second on a multi-core PC.",Anish Chandak;Christian Lauterbach;Micah T. Taylor;Zhimin Ren;Dinesh Manocha,Anish Chandak;Christian Lauterbach;Micah Taylor;Zhimin Ren;Dinesh Manocha,"University of North Carolina at Chapel Hill, Chapel Hill, NC, US;University of North Carolina at Chapel Hill, Chapel Hill, NC, US;University of North Carolina at Chapel Hill, Chapel Hill, NC, US;University of North Carolina at Chapel Hill, Chapel Hill, NC, US;University of North Carolina at Chapel Hill, Chapel Hill, NC, US",10.1109/tvcg.2007.70575;10.1109/tvcg.2006.125;10.1109/visual.2005.1532790;10.1109/tvcg.2008.111;10.1109/tvcg.2007.70567;10.1109/tvcg.2007.70575,"Sound propagation, interactive system, auralization",122.0,58.0,43.0,465.0,,,geometric sound propagation;intersections scene primitives;demonstrate performance architectural;frusta;tens hundreds thousands,0.6170;0.3631;0.2319;0.2022;0.0274,"[np.int64(-1), -1, -1, -1, -1]",19;-1;-1;-1;-1,19,19,Sound Propagation Modeling
Vis,2023,Perception of Line Attributes for Visualization,10.1109/tvcg.2023.3326523,http://dx.doi.org/10.1109/TVCG.2023.3326523,1041.0,1051.0,J,"Line attributes such as width and dashing are commonly used to encode information. However, many questions on the perception of line attributes remain, such as how many levels of attribute variation can be distinguished or which line attributes are the preferred choices for which tasks. We conducted three studies to develop guidelines for using stylized lines to encode scalar data. In our first study, participants drew stylized lines to encode uncertainty information. Uncertainty is usually visualized alongside other data. Therefore, alternative visual channels are important for the visualization of uncertainty. Additionally, uncertainty—e.g., in weather forecasts—is a familiar topic to most people. Thus, we picked it for our visualization scenarios in study 1. We used the results of our study to determine the most common line attributes for drawing uncertainty: Dashing, luminance, wave amplitude, and width. While those line attributes were especially common for drawing uncertainty, they are also commonly used in other areas. In studies 2 and 3, we investigated the discriminability of the line attributes determined in study 1. Studies 2 and 3 did not require specific application areas; thus, their results apply to visualizing any scalar data in line attributes. We evaluated the just-noticeable differences (JND) and derived recommendations for perceptually distinct line levels. We found that participants could discriminate considerably more levels for the line attribute width than for wave amplitude, dashing, or luminance.",Anna Sterzik;Nils Lichtenberg;Jana Wilms;Michael Krone;Douglas W. Cunningham;Kai Lawonn,Anna Sterzik;Nils Lichtenberg;Jana Wilms;Michael Krone;Douglas W. Cunningham;Kai Lawonn,"University of Jena, Germany;University of Tübingen, Germany;University of Jena, Germany;University of Tübingen, Germany;Brandenburg University of Technology, Germany;University of Jena, Germany",0.1109/tvcg.2012.220;10.1109/tvcg.2017.2743959;10.1109/tvcg.2015.2467671;10.1109/tvcg.2012.279;10.1109/tvcg.2015.2467591;10.1109/tvcg.2016.2598826;10.1109/tvcg.2023.3326574,"Line Drawings,Line Stylization,Perceptual Evaluation,Uncertainty Visualization",,1.0,48.0,326.0,,,lines encode uncertainty;visualization scenarios study;drew stylized;attributes preferred choices;require specific application,0.6815;0.4231;0.3610;0.2596;-0.0785,"[np.int64(-1), -1, -1, -1, -1]",36;-1;-1;-1;-1,36,36,Uncertainty Visualization
InfoVis,2000,A scalable framework for information visualization,10.1109/infvis.2000.885088,http://dx.doi.org/10.1109/INFVIS.2000.885088,27.0,36.0,C,"The paper describes major concepts of a scalable information visualization framework. We assume that the exploration of heterogeneous information spaces at arbitrary levels of detail requires a suitable preprocessing of information quantities, the combination of different graphical interfaces and the illustration of the frame of reference of given information sets. The innovative features of our system include: dynamic hierarchy computation and user controlled refinement of those hierarchies for preprocessing unstructured information spaces; a new Focus+Context technique for visualizing complex hierarchy graphs; a new paradigm for visualizing information structures within their frame of reference; and a new graphical interface that utilizes textual similarities to arrange objects of high dimensional information space in 3-dimensional visualization space.",Matthias Kreuseler;Norma López;Heidrun Schumann,M. Kreuseler;N. Lopez;H. Schumann,"Department of Computer Science, University of Rostock, Rostock, Germany;Department of Computer Science, University of Rostock, Rostock, Germany;Department of Computer Science, University of Rostock, Rostock, Germany",10.1109/visual.1990.146402;10.1109/infvis.1997.636759;10.1109/visual.1996.567745;10.1109/visual.1997.663916;10.1109/infvis.1995.528686;10.1109/infvis.1995.528691;10.1109/infvis.1998.729555;10.1109/visual.1991.175815;10.1109/infvis.1998.729559,,114.0,23.0,25.0,534.0,,,visualizing information structures;new focus context;user controlled;suitable preprocessing information;assume,0.7851;0.2440;0.1524;0.1400;-0.0171,"[np.int64(-1), -1, -1, -1, -1]",134;-1;-1;-1;-1,134,134,Information Visualization
Vis,2001,User-centric viewpoint computation for haptic exploration and manipulation,10.1109/visual.2001.964526,http://dx.doi.org/10.1109/VISUAL.2001.964526,311.0,318.0,C,"We present several techniques for user-centric viewing of the virtual objects or datasets under haptic exploration and manipulation. Depending on the type of tasks performed by the user, our algorithms compute automatic placement of the user viewpoint to navigate through the scene, to display the near-optimal views, and to reposition the viewpoint for haptic visualization. This is accomplished by conjecturing the user's intent based on the user's actions, the object geometry, and intra- and inter-object occlusion relationships. These algorithms have been implemented and interfaced with both a 3-DOF and a 6-DOF PHANToM arms. We demonstrate their application on haptic exploration and visualization of a complex structure, as well as multiresolution modeling and 3D painting with a haptic interface.",Miguel A. Otaduy;Ming C. Lin,M.A. Otaduy;M.C. Lin,"Department of Computer Science, University of North Carolina, Chapel Hill, USA;Department of Computer Science, University of North Carolina, Chapel Hill, USA",10.1109/visual.2000.885686;10.1109/visual.1996.568108;10.1109/visual.2000.885686,,22.0,10.0,33.0,102.0,,,viewpoint haptic visualization;user actions object;dof dof phantom;multiresolution;algorithms compute automatic,0.7477;0.2361;0.1876;0.1765;0.1116,"[np.int64(-1), -1, -1, -1, -1]",69;-1;-1;-1;-1,69,69,3D Navigation Interfaces
Vis,2021,STNet: An End-to-End Generative Framework for Synthesizing Spatiotemporal Super-Resolution Volumes,10.1109/tvcg.2021.3114815,http://dx.doi.org/10.1109/TVCG.2021.3114815,270.0,280.0,J,"We present STNet, an end-to-end generative framework that synthesizes spatiotemporal super-resolution volumes with high fidelity for time-varying data. STNet includes two modules: a generator and a spatiotemporal discriminator. The input to the generator is two low-resolution volumes at both ends, and the output is the intermediate and the two-ending spatiotemporal super-resolution volumes. The spatiotemporal discriminator, leveraging convolutional long short-term memory, accepts a spatiotemporal super-resolution sequence as input and predicts a conditional score for each volume based on its spatial (the volume itself) and temporal (the previous volumes) information. We propose an unsupervised pre-training stage using cycle loss to improve the generalization of STNet. Once trained, STNet can generate spatiotemporal super-resolution volumes from low-resolution ones, offering scientists an option to save data storage (i.e., sparsely sampling the simulation output in both spatial and temporal dimensions). We compare STNet with the baseline bicubic+linear interpolation, two deep learning solutions (<inline-formula><tex-math notation=""LaTeX"">$\mathsf{SSR}+\mathsf{TSF}$</tex-math><alternatives><graphic orientation=""portrait"" position=""float"" xlink:href=""28tvcg01-han-3114815-eqinline-1-small.tif"" xmlns:xlink=""http://www.w3.org/1999/xlink""/></alternatives></inline-formula>, STD), and a state-of-the-art tensor compression solution (TTHRESH) to show the effectiveness of STNet.",Jun Han 0010;Hao Zheng 0006;Danny Z. Chen;Chaoli Wang 0001,Jun Han;Hao Zheng;Danny Z. Chen;Chaoli Wang,"Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, USA;Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, USA;Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, USA;Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, USA",10.1109/tvcg.2019.2934332;10.1109/tvcg.2020.3030344;10.1109/tvcg.2019.2934255;10.1109/tvcg.2020.3030346;10.1109/tvcg.2019.2934312;10.1109/tvcg.2006.143;10.1109/tvcg.2019.2934375;10.1109/tvcg.2019.2934332,"Time-varying data,generative adversarial network,spatiotemporal super-resolution",15.0,30.0,65.0,1183.0,,,spatiotemporal super resolution;stnet generate;volumes information;cycle loss;input predicts conditional,0.5764;0.2813;0.2548;0.2193;0.1659,"[np.int64(-1), -1, -1, -1, -1]",118;-1;-1;-1;-1,118,118,Advanced Image Techniques
VAST,2013,Interactive Exploration of Implicit and Explicit Relations in Faceted Datasets,10.1109/tvcg.2013.167,http://dx.doi.org/10.1109/TVCG.2013.167,2080.0,2089.0,J,"Many datasets, such as scientific literature collections, contain multiple heterogeneous facets which derive implicit relations, as well as explicit relational references between data items. The exploration of this data is challenging not only because of large data scales but also the complexity of resource structures and semantics. In this paper, we present PivotSlice, an interactive visualization technique which provides efficient faceted browsing as well as flexible capabilities to discover data relationships. With the metaphor of direct manipulation, PivotSlice allows the user to visually and logically construct a series of dynamic queries over the data, based on a multi-focus and multi-scale tabular view that subdivides the entire dataset into several meaningful parts with customized semantics. PivotSlice further facilitates the visual exploration and sensemaking process through features including live search and integration of online data, graphical interaction histories and smoothly animated visual state transitions. We evaluated PivotSlice through a qualitative lab study with university researchers and report the findings from our observations and interviews. We also demonstrate the effectiveness of PivotSlice using a scenario of exploring a repository of information visualization literature.",Jian Zhao 0010;Christopher Collins 0001;Fanny Chevalier;Ravin Balakrishnan,Jian Zhao;Christopher Collins;Fanny Chevalier;Ravin Balakrishnan,"University of Toronto, Canada;Institute of Technology, University of Ontario, Canada;University of Toronto, Toronto, ON, CA;University of Toronto, Canada",10.1109/tvcg.2008.137;10.1109/vast.2011.6102440;10.1109/tvcg.2011.213;10.1109/tvcg.2010.154;10.1109/vast.2006.261426;10.1109/infvis.2005.1532136;10.1109/tvcg.2010.205;10.1109/tvcg.2012.252;10.1109/tvcg.2006.166;10.1109/infvis.2000.885086;10.1109/tvcg.2009.108;10.1109/infvis.2004.64;10.1109/tvcg.2008.137,"Faceted browsing, network exploration, dynamic query, interaction, information visualization, visual analytics",120.0,76.0,39.0,1487.0,,,information visualization literature;evaluated pivotslice;implicit relations;study university;allows,0.6158;0.2549;0.2241;0.1012;0.0227,"[np.int64(-1), -1, -1, -1, -1]",98;-1;-1;-1;-1,98,98,Information Visualization
InfoVis,2004,Information Visualization Research: Citation and Co-Citation Highlights,10.1109/infvis.2004.38,http://dx.doi.org/10.1109/INFVIS.2004.38,,,M,An overview of the entry is given. The techniques used to prepare the InfoVis contest entry are outlined. The strengths and weaknesses are briefly discussed.,Chaomei Chen,Chaomei Chen,"Drexel University, USA",,,5.0,0.0,4.0,146.0,,,prepare infovis contest;entry outlined;overview;weaknesses briefly discussed;used,0.8292;0.3665;0.2941;0.2512;0.1218,"[np.int64(-1), -1, -1, -1, -1]",51;-1;-1;-1;-1,51,51,Data Journalism
Vis,2002,Geometric verification of swirling features in flow fields,10.1109/visual.2002.1183789,http://dx.doi.org/10.1109/VISUAL.2002.1183789,307.0,314.0,C,"In this paper, we present a verification algorithm for swirling features in flow fields, based on the geometry of streamlines. The features of interest in this case are vortices. Without a formal definition, existing detection algorithms lack the ability to accurately identify these features, and the current method for verifying the accuracy of their results is by human visual inspection. Our verification algorithm addresses this issue by automating the visual inspection process. It is based on identifying the swirling streamlines that surround the candidate vortex cores. We apply our algorithm to both numerically simulated and procedurally generated datasets to illustrate the efficacy of our approach.",Ming Jiang 0005;Raghu Machiraju;David S. Thompson,Ming Jiang;R. Machiraju;D. Thompson,"Ohio State Uinversity, USA;Ohio State Uinversity, USA;Mississippi State University, USA",10.1109/visual.1999.809896;10.1109/visual.1998.745333;10.1109/visual.1998.745296;10.1109/visual.1993.398877;10.1109/visual.1999.809896,"feature verification, vortex detection, flow field visualization",76.0,22.0,19.0,190.0,,,based identifying swirling;inspection verification;features case;definition;addresses issue automating,0.6849;0.3272;0.0763;0.0204;-0.0038,"[np.int64(-1), -1, -1, -1, -1]",21;-1;-1;-1;-1,21,21,Vortex Identification
VAST,2007,Visual Analysis of Dynamic Networks with Geological Clustering,10.1109/vast.2007.4389027,http://dx.doi.org/10.1109/VAST.2007.4389027,221.0,222.0,M,"Many dynamic networks have associated geological information. Here we present two complementing visual analysis methods for such networks. The first one provides an overview with summerized information while the second one presents a more detailed view. The geological information is encoded in the network layout, which is designed to help maintain user's mental map. We also combined visualization with social network analysis to facilitate knowledge discovery, especially to understand network changes in the context overall evolution. Both methods are applied to the ""History of the FIFA World Cup Competition"" data set.",Adel Ahmed;Xiaoyan Fu;Seok-Hee Hong 0001;Quan Hoang Nguyen 0001;Kai Xu 0003,Adel Ahmed;Xiaoyan Fu;Seok-Hee Hong;Quan Hoang Nguyen;Kai Xu,"School of Information Technologies, University of Sydney, Australia and NICTA, Australia;NICTA, Australia;School of Information Technologies, University of Sydney, Australia;School of Computer Sciences and Engineering, University of New South Wales, Australia;NICTA, Australia",0.1109/tvcg.2006.166;10.1109/tvcg.2006.122,,3.0,1.0,7.0,194.0,,,visualization social network;geological information;fifa;evolution methods applied;changes context overall,0.6821;0.4418;0.1423;0.1017;0.0929,"[np.int64(-1), -1, -1, -1, -1]",87;-1;-1;-1;-1,87,87,Social Network Visualization
InfoVis,2011,DICON: Interactive Visual Analysis of Multidimensional Clusters,10.1109/tvcg.2011.188,http://dx.doi.org/10.1109/TVCG.2011.188,2581.0,2590.0,J,"Clustering as a fundamental data analysis technique has been widely used in many analytic applications. However, it is often difficult for users to understand and evaluate multidimensional clustering results, especially the quality of clusters and their semantics. For large and complex data, high-level statistical information about the clusters is often needed for users to evaluate cluster quality while a detailed display of multidimensional attributes of the data is necessary to understand the meaning of clusters. In this paper, we introduce DICON, an icon-based cluster visualization that embeds statistical information into a multi-attribute display to facilitate cluster interpretation, evaluation, and comparison. We design a treemap-like icon to represent a multidimensional cluster, and the quality of the cluster can be conveniently evaluated with the embedded statistical information. We further develop a novel layout algorithm which can generate similar icons for similar clusters, making comparisons of clusters easier. User interaction and clutter reduction are integrated into the system to help users more effectively analyze and refine clustering results for large datasets. We demonstrate the power of DICON through a user study and a case study in the healthcare domain. Our evaluation shows the benefits of the technique, especially in support of complex multidimensional cluster analysis.",Nan Cao 0001;David Gotz;Jimeng Sun 0001;Huamin Qu,Nan Cao;David Gotz;Jimeng Sun;Huamin Qu,"Department of Computer Science and Engineering, Hong Kong University of Science and Technology, Hong Kong, China;IBM Thomas J. Watson Research Center, USA;IBM Thomas J. Watson Research Center, USA;Department of Computer Science and Engineering, Hong Kong University of Science and Technology, Hong Kong, China",10.1109/infvis.2005.1532128;10.1109/tvcg.2006.147;10.1109/tvcg.2009.179;10.1109/visual.1995.485141;10.1109/tvcg.2007.70582;10.1109/visual.1990.146402;10.1109/vast.2009.5332628;10.1109/infvis.2001.963283;10.1109/infvis.1998.729559;10.1109/tvcg.2010.216;10.1109/visual.1999.809866;10.1109/tvcg.2008.153;10.1109/tvcg.2008.165;10.1109/tvcg.2009.153;10.1109/infvis.2005.1532128,"Visual Analysis, Clustering, Information Visualization",155.0,93.0,40.0,2696.0,,,cluster visualization;introduce dicon icon;applications difficult users;conveniently evaluated embedded;healthcare domain,0.7219;0.2777;0.1504;0.1362;0.1267,"[np.int64(-1), -1, -1, -1, -1]",85;-1;-1;-1;-1,85,85,Cluster Visualization
SciVis,2020,A Fluid Flow Data Set for Machine Learning and its Application to Neural Flow Map Interpolation,10.1109/tvcg.2020.3028947,http://dx.doi.org/10.1109/TVCG.2020.3028947,1279.0,1289.0,J,"In recent years, deep learning has opened countless research opportunities across many different disciplines. At present, visualization is mainly applied to explore and explain neural networks. Its counterpart-the application of deep learning to visualization problems-requires us to share data more openly in order to enable more scientists to engage in data-driven research. In this paper, we construct a large fluid flow data set and apply it to a deep learning problem in scientific visualization. Parameterized by the Reynolds number, the data set contains a wide spectrum of laminar and turbulent fluid flow regimes. The full data set was simulated on a high-performance compute cluster and contains 8000 time-dependent 2D vector fields, accumulating to more than 16 TB in size. Using our public fluid data set, we trained deep convolutional neural networks in order to set a benchmark for an improved post-hoc Lagrangian fluid flow analysis. In in-situ settings, flow maps are exported and interpolated in order to assess the transport characteristics of time-dependent fluids. Using deep learning, we improve the accuracy of flow map interpolations, allowing a more precise flow analysis at a reduced memory IO footprint.",Jakob Jakob;Markus Gross 0001;Tobias Günther,Jakob Jakob;Markus Gross;Tobias Günther,"ETH Zurich, Switzerland;ETH Zurich, Switzerland;ETH Zurich, Switzerland",10.1109/tvcg.2013.128;10.1109/tvcg.2019.2934332;10.1109/tvcg.2007.70551;10.1109/tvcg.2019.2934255;10.1109/tvcg.2019.2934312;10.1109/tvcg.2019.2934335;10.1109/tvcg.2007.70554;10.1109/tvcg.2013.128,"Scientific visualization,deep learning,flow maps",24.0,24.0,73.0,1932.0,,,deep learning visualization;fluid flow regimes;8000 time dependent;public;set contains,0.5911;0.4421;0.1663;0.0506;-0.0378,"[np.int64(-1), -1, -1, -1, -1]",42;-1;-1;-1;-1,42,42,Neural Visualization Techniques
Vis,2002,Probabilistic surfaces: point based primitives to show surface uncertainty,10.1109/visual.2002.1183769,http://dx.doi.org/10.1109/VISUAL.2002.1183769,147.0,153.0,C,"Efficient and informative visualization of surfaces with uncertainties is an important topic with many applications in science and engineering. Examples include environmental pollution borderline identification, identification of the limits of an oil basin, or discrimination between contaminated and healthy tissue in medicine. This paper presents an approach for such visualization using points as display primitives. The approach is to render each polygon as a collection of points and to displace each point from the surface in the direction of the surface normal by an amount proportional to some random number multiplied by the uncertainty level at that point. This approach can be used in combination with other techniques such as pseudo-coloring and shading to give rise to efficient and revealing visualizations. The method is used to visualize real and simulated tumor formations with uncertainty of tumor boundaries.",Gevorg Grigoryan;Penny Rheingans,G. Grigoryan;P. Rheingans,"University of Maryland, Baltimore, USA;University of Maryland, Baltimore, USA",10.1109/visual.1996.568105;10.1109/visual.2000.885679;10.1109/visual.2001.964492;10.1109/visual.1995.480802;10.1109/visual.1995.480798;10.1109/visual.1996.568105,"uncertainty, visualizing surface uncertainty, points as display primitives",65.0,17.0,18.0,197.0,,,visualization surfaces uncertainties;techniques pseudo coloring;polygon collection;tumor;important topic applications,0.6172;0.3416;0.3234;0.2040;0.0817,"[np.int64(-1), -1, -1, -1, -1]",116;-1;-1;-1;-1,116,116,Uncertainty Visualization
VAST,2016,GazeDx: Interactive Visual Analytics Framework for Comparative Gaze Analysis with Volumetric Medical Images,10.1109/tvcg.2016.2598796,http://dx.doi.org/10.1109/TVCG.2016.2598796,311.0,320.0,J,"We present an interactive visual analytics framework, GazeDx (abbr. of GazeDiagnosis), for the comparative analysis of gaze data from multiple readers examining volumetric images while integrating important contextual information with the gaze data. Gaze pattern comparison is essential to understanding how radiologists examine medical images, and to identifying factors influencing the examination. Most prior work depended upon comparisons with manually juxtaposed static images of gaze tracking results. Comparative gaze analysis with volumetric images is more challenging due to the additional cognitive load on 3D perception. A recent study proposed a visualization design based on direct volume rendering (DVR) for visualizing gaze patterns in volumetric images; however, effective and comprehensive gaze pattern comparison is still challenging due to a lack of interactive visualization tools for comparative gaze analysis. We take the challenge with GazeDx while integrating crucial contextual information such as pupil size and windowing into the analysis process for more in-depth and ecologically valid findings. Among the interactive visualization components in GazeDx, a context-embedded interactive scatterplot is especially designed to help users examine abstract gaze data in diverse contexts by embedding medical imaging representations well known to radiologists in it. We present the results from two case studies with two experienced radiologists, where they compared the gaze patterns of 14 radiologists reading two patients' volumetric CT images.",Hyunjoo Song;Jeongjin Lee;Tae Jung Kim;Kyoung Ho Lee;Bo Hyoung Kim;Jinwook Seo,Hyunjoo Song;Jeongjin Lee;Tae Jung Kim;Kyoung Ho Lee;Bohyoung Kim;Jinwook Seo,"Seoul National University;Soongsil University;Samsung Medical Center;Bundang Hospital, Seoul National University;Hankuk University of Foreign Studies;Seoul National University",10.1109/vast.2011.6102435;10.1109/tvcg.2010.149;10.1109/vast.2011.6102435,Eye tracking;gaze visualization;gaze pattern comparison;volumetric medical images;context-embedded interactive scatterplot;interactive temporal chart,17.0,21.0,32.0,1122.0,,,visualizing gaze patterns;patients volumetric ct;context embedded interactive;compared;ecologically valid,0.7186;0.4710;0.2223;0.1715;0.0198,"[np.int64(-1), -1, -1, -1, -1]",130;-1;-1;-1;-1,130,130,Visual Perception Analysis
InfoVis,2016,Iterating between Tools to Create and Edit Visualizations,10.1109/tvcg.2016.2598609,http://dx.doi.org/10.1109/TVCG.2016.2598609,481.0,490.0,J,"A common workflow for visualization designers begins with a generative tool, like D3 or Processing, to create the initial visualization; and proceeds to a drawing tool, like Adobe Illustrator or Inkscape, for editing and cleaning. Unfortunately, this is typically a one-way process: once a visualization is exported from the generative tool into a drawing tool, it is difficult to make further, data-driven changes. In this paper, we propose a bridge model to allow designers to bring their work back from the drawing tool to re-edit in the generative tool. Our key insight is to recast this iteration challenge as a merge problem - similar to when two people are editing a document and changes between them need to reconciled. We also present a specific instantiation of this model, a tool called Hanpuku, which bridges between D3 scripts and Illustrator. We show several examples of visualizations that are iteratively created using Hanpuku in order to illustrate the flexibility of the approach. We further describe several hypothetical tools that bridge between other visualization tools to emphasize the generality of the model.",Alex Bigelow;Steven Mark Drucker;Danyel Fisher;Miriah D. Meyer,Alex Bigelow;Steven Drucker;Danyel Fisher;Miriah Meyer,University of Utah;Microsoft Research;Microsoft Research;University of Utah,10.1109/tvcg.2014.2346292;10.1109/tvcg.2015.2467191;10.1109/tvcg.2014.2346291;10.1109/tvcg.2015.2467091;10.1109/infvis.2004.12;10.1109/tvcg.2011.209;10.1109/tvcg.2007.70584;10.1109/tvcg.2011.185;10.1109/tvcg.2014.2346292,illustration;Visualization;iteration,49.0,39.0,32.0,1225.0,,,visualization designers;bridges d3 scripts;merge;editing document changes;using hanpuku order,0.6331;0.2923;0.2921;0.2049;0.1487,"[np.int64(-1), -1, -1, -1, -1]",105;-1;-1;-1;-1,105,105,Visualization Designers
VAST,2009,Interactive visual clustering of large collections of trajectories,10.1109/vast.2009.5332584,http://dx.doi.org/10.1109/VAST.2009.5332584,3.0,10.0,C,"One of the most common operations in exploration and analysis of various kinds of data is clustering, i.e. discovery and interpretation of groups of objects having similar properties and/or behaviors. In clustering, objects are often treated as points in multi-dimensional space of properties. However, structurally complex objects, such as trajectories of moving entities and other kinds of spatio-temporal data, cannot be adequately represented in this manner. Such data require sophisticated and computationally intensive clustering algorithms, which are very hard to scale effectively to large datasets not fitting in the computer main memory. We propose an approach to extracting meaningful clusters from large databases by combining clustering and classification, which are driven by a human analyst through an interactive visual interface.",Gennady L. Andrienko;Natalia V. Andrienko;Salvatore Rinzivillo;Mirco Nanni;Dino Pedreschi;Fosca Giannotti,Gennady Andrienko;Natalia Andrienko;Salvatore Rinzivillo;Mirco Nanni;Dino Pedreschi;Fosca Giannotti,"Fraunhofer Institute of Intelligent Analysis and Information Systems (IAIS), Sankt Augustin, Germany;Fraunhofer Institute of Intelligent Analysis and Information Systems (IAIS), Sankt Augustin, Germany;KDD Lab-ISTI-CNR, Pisa, Italy;KDD Lab-ISTI-CNR, Pisa, Italy;University of Pisa, Pisa, Italy;KDD Lab-ISTI-CNR, Pisa, Italy",10.1109/vast.2008.4677356;10.1109/vast.2007.4388999;10.1109/vast.2008.4677356,"Spatio-temporal data, movement data, trajectories, clustering, classification, scalable visualization, geovisualization",291.0,144.0,26.0,1630.0,,,extracting meaningful clusters;objects trajectories moving;analyst interactive visual;memory propose approach;human,0.6338;0.3544;0.3121;0.1695;0.1557,"[np.int64(-1), -1, -1, -1, -1]",31;-1;-1;-1;-1,31,31,Meaningful Clusters
SciVis,2013,MObjects--A Novel Method for the Visualization and Interactive Exploration of Defects in Industrial XCT Data,10.1109/tvcg.2013.177,http://dx.doi.org/10.1109/TVCG.2013.177,2906.0,2915.0,J,"This paper describes an advanced visualization method for the analysis of defects in industrial 3D X-Ray Computed Tomography (XCT) data. We present a novel way to explore a high number of individual objects in a dataset, e.g., pores, inclusions, particles, fibers, and cracks demonstrated on the special application area of pore extraction in carbon fiber reinforced polymers (CFRP). After calculating the individual object properties volume, dimensions and shape factors, all objects are clustered into a mean object (MObject). The resulting MObject parameter space can be explored interactively. To do so, we introduce the visualization of mean object sets (MObject Sets) in a radial and a parallel arrangement. Each MObject may be split up into sub-classes by selecting a specific property, e.g., volume or shape factor, and the desired number of classes. Applying this interactive selection iteratively leads to the intended classifications and visualizations of MObjects along the selected analysis path. Hereby the given different scaling factors of the MObjects down the analysis path are visualized through a visual linking approach. Furthermore the representative MObjects are exported as volumetric datasets to serve as input for successive calculations and simulations. In the field of porosity determination in CFRP non-destructive testing practitioners use representative MObjects to improve ultrasonic calibration curves. Representative pores also serve as input for heat conduction simulations in active thermography. For a fast overview of the pore properties in a dataset we propose a local MObjects visualization in combination with a color-coded homogeneity visualization of cells. The advantages of our novel approach are demonstrated using real world CFRP specimens. The results were evaluated through a questionnaire in order to determine the practicality of the MObjects visualization as a supportive tool for domain specialists.",Andreas Reh;Christian Gusenbauer;Johann Kastner;M. Eduard Gröller;Christoph Heinzl,Andreas Reh;Christian Gusenbauer;Johann Kastner;M. Eduard Gröller;Christoph Heinzl,"University of Applied Sciences Upper Austria, Austria;University of Applied Sciences Upper Austria, Austria;University of Applied Sciences Upper Austria, Austria;Institute of Computer Graphics and Algorithms, Vienna University of Technology, Austria;University of Applied Sciences Upper Austria, Austria",10.1109/tvcg.2012.231;10.1109/visual.1999.809871;10.1109/tvcg.2009.121;10.1109/tvcg.2012.227;10.1109/tvcg.2011.248;10.1109/visual.2005.1532807;10.1109/tvcg.2010.190;10.1109/tvcg.2010.214;10.1109/visual.1993.398859;10.1109/visual.1997.663875,"3D X-ray computed tomography, carbon fiber reinforced polymers, porosity, parameter space analysis, MObjects",37.0,21.0,29.0,834.0,,,advanced visualization;computed tomography xct;pores inclusions;reinforced polymers cfrp;representative mobjects exported,0.5185;0.4427;0.3050;0.2771;0.1662,"[np.int64(-1), -1, -1, -1, -1]",107;-1;-1;-1;-1,107,107,Visualization Techniques
Vis,1998,Efficient warping for architectural walkthroughs using layered depth images,10.1109/visual.1998.745305,http://dx.doi.org/10.1109/VISUAL.1998.745305,211.0,215.0,C,"This paper presents efficient image-based rendering techniques used in the context of an architectural walkthrough system. Portals (doors and windows) are rendered by warping layered depth images (LDIs). In a preprocessing phase, for every portal, a number of pre-rendered images are combined into an LDI. The resulting LDI stores, exactly once, all surfaces visible in at least one of the images used in the construction, so most of the exposure errors are efficiently eliminated. The LDI can be warped in the McMillan occlusion compatible ordering. A substantial increase in performance is obtained by warping in parallel. Our parallelization scheme achieves good load balancing, scales with the number of processors, and preserves the occlusion compatible ordering. A fast, conservative reference-image-space clipping algorithm also reduces the warping effort.",Voicu Popescu;Anselmo Lastra;Daniel G. Aliaga;Manuel Menezes de Oliveira Neto,V. Popescu;A. Lastra;D. Aliaga;M. de Oliveira Neto,"University of North Carolina, Chapel Hill, USA;University of North Carolina, Chapel Hill, USA;University of North Carolina, Chapel Hill, USA;University of North Carolina, Chapel Hill, USA",10.1109/visual.1997.663903,"image-based rendering, parallel warping, occlusion compatible ordering for discrete images, portal, cell, exposure error, layered depth image, clipping, architectural walkthrough",69.0,16.0,8.0,75.0,,,layered depth images;windows rendered warping;context architectural walkthrough;achieves good load;number pre,0.6225;0.2458;0.2125;0.1130;0.0853,"[np.int64(-1), -1, -1, -1, -1]",141;-1;-1;-1;-1,141,141,Advanced Rendering Techniques
InfoVis,1995,Case study: 3D displays of Internet traffic,10.1109/infvis.1995.528697,http://dx.doi.org/10.1109/INFVIS.1995.528697,129.0,131.0,C,"The explosive growth in world-wide communications, especially the Internet, has highlighted the need for techniques to visualize network traffic. The traditional node and link network displays work well for small datasets but become visually cluttered and uninterpretable for large datasets. A natural 3D metaphor for displaying world-wide network data is to position the nodes on a globe and draw arcs between them coding the traffic. This technique has several advantages of over the traditional 2D displays, it naturally reduces line crossing clutter, provides an intuitive model for navigation and indication of time, and retains the geographic context. Coupling these strengths with some novel interaction techniques involving the globe surface translucency and arc heights illustrates the usefulness for this class of displays.",Kenneth C. Cox;Stephen G. Eick,K.C. Cox;S.G. Eick,"AT and T Bell Laboratories, USA;AT and T Bell Laboratories, Naperville, IL, USA",10.1109/visual.1993.398870;10.1109/visual.1993.398870,,52.0,14.0,8.0,201.0,,,visualize network traffic;globe draw arcs;advantages traditional 2d;retains geographic context;especially,0.6573;0.5260;0.2500;0.2269;0.1046,"[np.int64(-1), np.int64(-1), -1, -1, -1]",83;125;-1;-1;-1,83;125,83,Network Visualization
Vis,2022,Uncertainty-Aware Multidimensional Scaling,10.1109/tvcg.2022.3209420,http://dx.doi.org/10.1109/TVCG.2022.3209420,23.0,32.0,J,"We present an extension of multidimensional scaling (MDS) to uncertain data, facilitating uncertainty visualization of multidimensional data. Our approach uses local projection operators that map high-dimensional random vectors to low-dimensional space to formulate a generalized stress. In this way, our generic model supports arbitrary distributions and various stress types. We use our uncertainty-aware multidimensional scaling (UAMDS) concept to derive a formulation for the case of normally distributed random vectors and a squared stress. The resulting minimization problem is numerically solved via gradient descent. We complement UAMDS by additional visualization techniques that address the sensitivity and trustworthiness of dimensionality reduction under uncertainty. With several examples, we demonstrate the usefulness of our approach and the importance of uncertainty-aware techniques.",David Hägele;Tim Krake;Daniel Weiskopf,David Hägele;Tim Krake;Daniel Weiskopf,"University of Stuttgart, Germany;University of Stuttgart, Germany;University of Stuttgart, Germany",10.1109/infvis.1998.729560;10.1109/vast.2009.5332611;10.1109/tvcg.2019.2934812;10.1109/tvcg.2018.2864889;10.1109/tvcg.2016.2599106;10.1109/tvcg.2015.2467591;10.1109/tvcg.2016.2598919;10.1109/infvis.1998.729560,"Uncertainty visualization,dimensionality reduction,multidimensional scaling,non-linear projection",,2.0,37.0,2801.0,BP,X,uncertainty visualization multidimensional;generalized stress way;scaling uamds;local projection;normally,0.7401;0.4089;0.2399;0.2091;0.0181,"[np.int64(-1), -1, -1, -1, -1]",73;-1;-1;-1;-1,73,73,Uncertainty Visualization
VAST,2011,Visual sentiment analysis on twitter data streams,10.1109/vast.2011.6102472,http://dx.doi.org/10.1109/VAST.2011.6102472,277.0,278.0,M,"Twitter currently receives about 190 million tweets (small text-based Web posts) a day, in which people share their comments regarding a wide range of topics. A large number of tweets include opinions about products and services. However, with Twitter being a relatively new phenomenon, these tweets are underutilized as a source for evaluating customer sentiment. To explore high-volume twitter data, we introduce three novel time-based visual sentiment analysis techniques: (1) topic-based sentiment analysis that extracts, maps, and measures customer opinions; (2) stream analysis that identifies interesting tweets based on their density, negativity, and influence characteristics; and (3) pixel cell-based sentiment calendars and high density geo maps that visualize large volumes of data in a single view. We applied these techniques to a variety of twitter data, (e.g., movies, amusement parks, and hotels) to show their distribution and patterns, and to identify influential opinions.",Ming C. Hao;Christian Rohrdantz;Halldor Janetzko;Umeshwar Dayal;Daniel A. Keim;Lars-Erik Haug;Meichun Hsu,Ming Hao;Christian Rohrdantz;Halldór Janetzko;Umeshwar Dayal;Daniel A. Keim;Lars-Erik Haug;Mei-Chun Hsu,"Hewlett Packard Laboratory, USA;Hewlett-Packard Laboratories, University of Konstanz, Germany;Hewlett-Packard Laboratories, University of Konstanz, Germany;Hewlett Packard Laboratory, USA;Hewlett-Packard Laboratories, University of Konstanz, Germany;Hewlett Packard Laboratory, USA;Hewlett Packard Laboratory, USA",0.1109/vast.2009.5333919,,94.0,38.0,3.0,3669.0,,,visual sentiment analysis;190 million tweets;hotels distribution patterns;geo;introduce novel time,0.6370;0.4394;0.1451;0.1425;0.1135,"[np.int64(-1), -1, -1, -1, -1]",146;-1;-1;-1;-1,146,146,Visualization Techniques
InfoVis,2008,"The Word Tree, an Interactive Visual Concordance",10.1109/tvcg.2008.172,http://dx.doi.org/10.1109/TVCG.2008.172,1221.0,1228.0,J,"We introduce the Word Tree, a new visualization and information-retrieval technique aimed at text documents. A Word Tree is a graphical version of the traditional ""keyword-in-context"" method, and enables rapid querying and exploration of bodies of text. In this paper we describe the design of the technique, along with some of the technical issues that arise in its implementation. In addition, we discuss the results of several months of public deployment of word trees on Many Eyes, which provides a window onto the ways in which users obtain value from the visualization.",Martin Wattenberg;Fernanda B. Viégas,Martin Wattenberg;Fernanda B. Viégas,IBM Research;IBM Research,10.1109/infvis.2002.1173155;10.1109/vast.2007.4389006;10.1109/tvcg.2007.70577;10.1109/infvis.2002.1173148,"Text visualization, document visualization, Many Eyes, case study, concordance, information retrieval, search",449.0,206.0,15.0,3020.0,,,word tree graphical;rapid querying;bodies text paper;users obtain value;months public deployment,0.6574;0.3934;0.1986;0.1609;0.0528,"[np.int64(-1), -1, -1, -1, -1]",-1;-1;-1;-1;-1,,-1,Interactive 3D Visualization
InfoVis,2013,"Interactive Visualizations on Large and Small Displays: The Interrelation of Display Size, Information Space, and Scale",10.1109/tvcg.2013.170,http://dx.doi.org/10.1109/TVCG.2013.170,2336.0,2345.0,J,"In controlled experiments on the relation of display size (i.e., the number of pixels) and the usability of visualizations, the size of the information space can either be kept constant or varied relative to display size. Both experimental approaches have limitations. If the information space is kept constant then the scale ratio between an overview of the entire information space and the lowest zoom level varies, which can impact performance; if the information space is varied then the scale ratio is kept constant, but performance cannot be directly compared. In other words, display size, information space, and scale ratio are interrelated variables. We investigate this relation in two experiments with interfaces that implement classic information visualization techniques-focus+context, overview+detail, and zooming-for multi-scale navigation in maps. Display size varied between 0.17, 1.5, and 13.8 megapixels. Information space varied relative to display size in one experiment and was constant in the other. Results suggest that for tasks where users navigate targets that are visible at all map scales the interfaces do not benefit from a large display: With a constant map size, a larger display does not improve performance with the interfaces; with map size varied relative to display size, participants found interfaces harder to use with a larger display and task completion times decrease only when they are normalized to compensate for the increase in map size. The two experimental approaches show different interaction effects between display size and interface. In particular, focus+context performs relatively worse at a large display size with variable map size, and relatively worse at a small display size with a fixed map size. Based on a theoretical analysis of the interaction with the visualization techniques, we examine individual task actions empirically so as to understand the relative impact of display size and scale ratio on the visualization techniques' performance and to discuss differences between the two experimental approaches.",Mikkel R. Jakobsen;Kasper Hornbæk,Mikkel R. Jakobsen;Kasper Hornbæk,"University of Copenhagen, Denmark;University of Copenhagen, Denmark",10.1109/tvcg.2006.184;10.1109/tvcg.2006.187;10.1109/tvcg.2006.184,"Information visualization, multi-scale navigation, interaction techniques, experimental method, user studies",42.0,25.0,32.0,1625.0,,,usability visualizations size;users navigate;focus context performs;interrelated variables;directly,0.6446;0.3474;0.2870;0.1075;-0.0122,"[np.int64(-1), -1, -1, -1, -1]",146;-1;-1;-1;-1,146,146,Visualization Techniques
InfoVis,2006,Visualization of Geo-spatial Point Sets via Global Shape Transformation and Local Pixel Placement,10.1109/tvcg.2006.198,http://dx.doi.org/10.1109/TVCG.2006.198,749.0,756.0,J,"In many applications, data is collected and indexed by geo-spatial location. Discovering interesting patterns through visualization is an important way of gaining insight about such data. A previously proposed approach is to apply local placement functions such as PixelMaps that transform the input data set into a solution set that preserves certain constraints while making interesting patterns more obvious and avoid data loss from overplotting. In experience, this family of spatial transformations can reveal fine structures in large point sets, but it is sometimes difficult to relate those structures to basic geographic features such as cities and regional boundaries. Recent information visualization research has addressed other types of transformation functions that make spatially-transformed maps with recognizable shapes. These types of spatial-transformation are called global shape functions. In particular, cartogram-based map distortion has been studied. On the other hand, cartogram-based distortion does not handle point sets readily. In this study, we present a framework that allows the user to specify a global shape function and a local placement function. We combine cartogram-based layout (global shape) with PixelMaps (local placement), obtaining some of the benefits of each toward improved exploration of dense geo-spatial data sets",Christian Panse;Mike Sips;Daniel A. Keim;Stephen C. North,Christian Panse;Mike Sips;Daniel Keim;Stephen North,"University ETH Zurich, Switzerland;Max Planck Center for Visual Computing and Communication, University of Stanford, USA;University of Konstanz, Germany;AT and T Research Laboratories, NJ, USA",10.1109/visual.1998.745303;10.1109/infvis.2004.57;10.1109/visual.2003.1250410;10.1109/visual.1998.745303,"Geo-spatial Data, Shape Transformation, Cartogram, Pixel Visualization",48.0,22.0,12.0,508.0,,,cartogram based map;interesting patterns;apply local placement;transformations reveal fine;avoid,0.6521;0.2843;0.2154;0.1282;0.0954,"[np.int64(-1), -1, -1, -1, -1]",132;-1;-1;-1;-1,132,132,Geographic Visualization Techniques
Vis,2004,Interactive terascale particle visualization,10.1109/visual.2004.55,http://dx.doi.org/10.1109/VISUAL.2004.55,353.0,360.0,C,"This work describes the methods used to produce an interactive visualization of a 2 TB computational fluid dynamics (CFD) data set using particle tracing (streaklines). We use the method introduced by Bruckschen el al. (2001) that precomputes a large number of particles, stores them on disk using a space-filling curve ordering that minimizes seeks, then retrieves and displays the particles according to the user's command. We describe how the particle computation can be performed using a PC cluster, how the algorithm can be adapted to work with a multiblock curvilinear mesh, how scalars can be extracted and used to color the particles, and how the out-of-core visualization can be scaled to 293 billion particles while still achieving interactive performance on PC hardware. Compared to the earlier work, our data set size and total number of particles are an order of magnitude larger. We also describe a new compression technique that losslessly reduces the amount of particle storage by 41% and speeds the particle retrieval by about 20%.",David A. Ellsworth;Bryan Green;Patrick J. Moran,D. Ellsworth;B. Green;P. Moran,"Advanced Management Technology Incorporataed, NASA Ames Research Center, USA;Advanced Management Technology Incorporataed, NASA Ames Research Center, USA;NASA Ames Research Center, USA",10.1109/visual.2003.1250375;10.1109/visual.1998.745299;10.1109/visual.1997.663888;10.1109/visual.2003.1250420;10.1109/visual.1994.346311;10.1109/visual.1998.745343;10.1109/visual.1995.480821;10.1109/visual.2003.1250375,"visualization, particle tracing, large data, out-of-core, PC hardware, clusters, computational fluid dynamics",56.0,19.0,14.0,171.0,,,using particle tracing;storage 41 speeds;ordering minimizes;core;retrieves displays,0.6219;0.1596;0.0700;0.0332;0.0240,"[np.int64(-1), -1, -1, -1, -1]",20;-1;-1;-1;-1,20,20,Particle Flow Analysis
SciVis,2016,Physics-Based Visual Characterization of Molecular Interaction Forces,10.1109/tvcg.2016.2598825,http://dx.doi.org/10.1109/TVCG.2016.2598825,731.0,740.0,J,"Molecular simulations are used in many areas of biotechnology, such as drug design and enzyme engineering. Despite the development of automatic computational protocols, analysis of molecular interactions is still a major aspect where human comprehension and intuition are key to accelerate, analyze, and propose modifications to the molecule of interest. Most visualization algorithms help the users by providing an accurate depiction of the spatial arrangement: the atoms involved in inter-molecular contacts. There are few tools that provide visual information on the forces governing molecular docking. However, these tools, commonly restricted to close interaction between atoms, do not consider whole simulation paths, long-range distances and, importantly, do not provide visual cues for a quick and intuitive comprehension of the energy functions (modeling intermolecular interactions) involved. In this paper, we propose visualizations designed to enable the characterization of interaction forces by taking into account several relevant variables such as molecule-ligand distance and the energy function, which is essential to understand binding affinities. We put emphasis on mapping molecular docking paths obtained from Molecular Dynamics or Monte Carlo simulations, and provide time-dependent visualizations for different energy components and particle resolutions: atoms, groups or residues. The presented visualizations have the potential to support domain experts in a more efficient drug or enzyme design process.",Pedro Hermosilla;Jorge Estrada;Victor Guallar;Timo Ropinski;Àlvar Vinacua;Pere-Pau Vázquez,Pedro Hermosilla;Jorge Estrada;Victor Guallar;Timo Ropinski;Àlvar Vinacua;Pere-Pau Vázquez,"ViRVIG Group, Barcelona Supercomputing Center;Barcelona Supercomputing Center;Barcelona Supercomputing Center;Visual Computing Group, Ulm University;ViRVIG Group, UPC, Barcelona;ViRVIG Group, UPC, Barcelona",10.1109/tvcg.2009.168;10.1109/tvcg.2012.282;10.1109/tvcg.2015.2467293;10.1109/tvcg.2007.70578;10.1109/tvcg.2006.115;10.1109/tvcg.2007.70517;10.1109/tvcg.2014.2346403;10.1109/tvcg.2009.157;10.1109/tvcg.2009.168,Molecular visualization;binding analysis,21.0,17.0,52.0,708.0,,,molecule visualization;efficient drug enzyme;simulations used;docking tools commonly;taking account relevant,0.6606;0.3545;0.2855;0.2583;0.0086,"[np.int64(-1), -1, -1, -1, -1]",46;-1;-1;-1;-1,46,46,Interactive Molecular Visualization
Vis,1992,Visualization for the document space,10.1109/visual.1992.235198,http://dx.doi.org/10.1109/VISUAL.1992.235198,274.0,281.0,C,"An information retrieval frame work that promotes graphical displays, and that will make documents in the computer visualizable to the searcher, is described. As examples of such graphical displays, two simulation results of using a Kohonen feature map to generate map displays for information retrieval are presented and discussed. The map displays are a mapping from a high-dimensional document space to a two-dimensional space. They show document relationships by various visual cues, such as dots, links, clusters, and areas, as well as their measurement and spatial arrangement. Using the map displays as an interface for document retrieval systems, the user is provided with richer visual information to support browsing and searching.&lt;&lt;ETX&gt;&gt;",X. Lin,X. Lin,"Center for Computerized Legal Research, Pace University, White Plains, NY, USA",,,110.0,16.0,17.0,186.0,,,displays information retrieval;using kohonen;dimensional space;map generate map;discussed,0.6679;0.3023;0.2868;0.2539;0.0188,"[np.int64(-1), -1, -1, -1, -1]",146;-1;-1;-1;-1,146,146,Visualization Techniques
InfoVis,2020,ShuttleSpace: Exploring and Analyzing Movement Trajectory in Immersive Visualization,10.1109/tvcg.2020.3030392,http://dx.doi.org/10.1109/TVCG.2020.3030392,860.0,869.0,J,"We present ShuttleSpace, an immersive analytics system to assist experts in analyzing trajectory data in badminton. Trajectories in sports, such as the movement of players and balls, contain rich information on player behavior and thus have been widely analyzed by coaches and analysts to improve the players' performance. However, existing visual analytics systems often present the trajectories in court diagrams that are abstractions of reality, thereby causing difficulty for the experts to imagine the situation on the court and understand why the player acted in a certain way. With recent developments in immersive technologies, such as virtual reality (VR), experts gradually have the opportunity to see, feel, explore, and understand these 3D trajectories from the player's perspective. Yet, few research has studied how to support immersive analysis of sports data from such a perspective. Specific challenges are rooted in data presentation (e.g., how to seamlessly combine 2D and 3D visualizations) and interaction (e.g., how to naturally interact with data without keyboard and mouse) in VR. To address these challenges, we have worked closely with domain experts who have worked for a top national badminton team to design ShuttleSpace. Our system leverages 1) the peripheral vision to combine the 2D and 3D visualizations and 2) the VR controller to support natural interactions via a stroke metaphor. We demonstrate the effectiveness of ShuttleSpace through three case studies conducted by the experts with useful insights. We further conduct interviews with the experts whose feedback confirms that our first-person immersive analytics system is suitable and useful for analyzing badminton data.",Shuainan Ye;Zhutian Chen;Xiangtong Chu;Yifan Wang;Siwei Fu;Lejun Shen;Kun Zhou 0001;Yingcai Wu,Shuainan Ye;Zhutian Chen;Xiangtong Chu;Yifan Wang;Siwei Fu;Lejun Shen;Kun Zhou;Yingcai Wu,"State Key Lab of CAD CG, Zhejiang University;Hong Kong University of Science and Technology;State Key Lab of CAD CG, Zhejiang University;State Key Lab of CAD CG, Zhejiang University;Zhejiang Lab;Chengdu Sports University;State Key Lab of CAD CG, Zhejiang University;State Key Lab of CAD CG, Zhejiang University",10.1109/tvcg.2019.2934332;10.1109/vast.2014.7042478;10.1109/tvcg.2018.2865191;10.1109/tvcg.2016.2598831;10.1109/tvcg.2013.192;10.1109/visual.2001.964496;10.1109/tvcg.2019.2934243;10.1109/tvcg.2014.2346445;10.1109/vast.2014.7042477;10.1109/tvcg.2017.2745181;10.1109/tvcg.2017.2744218;10.1109/tvcg.2018.2865041;10.1109/tvcg.2018.2865192,"Movement trajectory,badminton analytics,virtual reality",43.0,61.0,49.0,2444.0,,,immersive analysis sports;stroke metaphor;data keyboard mouse;court understand;design shuttlespace leverages,0.7198;0.2911;0.2708;0.2008;0.1371,"[np.int64(-1), -1, -1, -1, -1]",-1;-1;-1;-1;-1,,-1,Interactive 3D Visualization
InfoVis,2009,Constructing Overview + Detail Dendrogram-Matrix Views,10.1109/tvcg.2009.130,http://dx.doi.org/10.1109/TVCG.2009.130,889.0,896.0,J,"A dendrogram that visualizes a clustering hierarchy is often integrated with a re-orderable matrix for pattern identification. The method is widely used in many research fields including biology, geography, statistics, and data mining. However, most dendrograms do not scale up well, particularly with respect to problems of graphical and cognitive information overload. This research proposes a strategy that links an overview dendrogram and a detail-view dendrogram, each integrated with a re-orderable matrix. The overview displays only a user-controlled, limited number of nodes that represent the ldquoskeletonrdquo of a hierarchy. The detail view displays the sub-tree represented by a selected meta-node in the overview. The research presented here focuses on constructing a concise overview dendrogram and its coordination with a detail view. The proposed method has the following benefits: dramatic alleviation of information overload, enhanced scalability and data abstraction quality on the dendrogram, and the support of data exploration at arbitrary levels of detail. The contribution of the paper includes a new metric to measure the ldquoimportancerdquo of nodes in a dendrogram; the method to construct the concise overview dendrogram from the dynamically-identified, important nodes; and measure for evaluating the data abstraction quality for dendrograms. We evaluate and compare the proposed method to some related existing methods, and demonstrating how the proposed method can help users find interesting patterns through a case study on county-level U.S. cervical cancer mortality and demographic data.",Jin Chen;Alan M. MacEachren;Donna J. Peuquet,Jin Chen;Alan M. MacEachren;Donna J. Peuquet,"GeoVISTA Center, Department of Geography, Pennsylvania State University, USA;GeoVISTA Center, Department of Geography, Pennsylvania State University, USA;GeoVISTA Center, Department of Geography, Pennsylvania State University, USA",10.1109/tvcg.2006.161;10.1109/tvcg.2007.70535;10.1109/infvis.2004.46;10.1109/tvcg.2006.161,"Dendrogram, reorderable matrix, compound graphs, data abstraction quality metrics, hierarchical clusters",40.0,14.0,28.0,632.0,,,dendrogram visualizes clustering;evaluating data abstraction;orderable matrix pattern;cervical cancer mortality;user controlled limited,0.7383;0.3068;0.2252;0.1697;0.0281,"[np.int64(-1), -1, -1, -1, -1]",85;-1;-1;-1;-1,85,85,Cluster Visualization
Vis,2023,ARGUS: Visualization of AI-Assisted Task Guidance in AR,10.1109/tvcg.2023.3327396,http://dx.doi.org/10.1109/TVCG.2023.3327396,1313.0,1323.0,J,"The concept of augmented reality (AR) assistants has captured the human imagination for decades, becoming a staple of modern science fiction. To pursue this goal, it is necessary to develop artificial intelligence (AI)-based methods that simultaneously perceive the 3D environment, reason about physical tasks, and model the performer, all in real-time. Within this framework, a wide variety of sensors are needed to generate data across different modalities, such as audio, video, depth, speech, and time-of-flight. The required sensors are typically part of the AR headset, providing performer sensing and interaction through visual, audio, and haptic feedback. AI assistants not only record the performer as they perform activities, but also require machine learning (ML) models to understand and assist the performer as they interact with the physical world. Therefore, developing such assistants is a challenging task. We propose ARGUS, a visual analytics system to support the development of intelligent AR assistants. Our system was designed as part of a multi-year-long collaboration between visualization researchers and ML and AR experts. This co-design process has led to advances in the visualization of ML in AR. Our system allows for online visualization of object, action, and step detection as well as offline analysis of previously recorded AR sessions. It visualizes not only the multimodal sensor data streams but also the output of the ML models. This allows developers to gain insights into the performer activities as well as the ML models, helping them troubleshoot, improve, and fine-tune the components of the AR assistant.",Sonia Castelo;João Rulff;Erin McGowan;Bea Steers;Guande Wu;Shaoyu Chen;Irán R. Román;Roque Lopez;Ethan Brewer;Chen Zhao;Jing Qian;Kyunghyun Cho;He He 0001;Qi Sun 0003;Huy T. Vo;Juan Pablo Bello;Michael Krone;Cláudio T. Silva,Sonia Castelo;Joao Rulff;Erin McGowan;Bea Steers;Guande Wu;Shaoyu Chen;Iran Roman;Roque Lopez;Ethan Brewer;Chen Zhao;Jing Qian;Kyunghyun Cho;He He;Qi Sun;Huy Vo;Juan Bello;Michael Krone;Claudio Silva,"New York University, New York;New York University, New York;New York University, New York;New York University, New York;New York University, New York;New York University, New York;New York University, New York;New York University, New York;New York University, New York;New York University, New York;New York University, New York;New York University, New York;New York University, New York;New York University, New York;New York University, New York;New York University, New York;New York University, New York;New York University, New York",0.1109/tvcg.2017.2746018;10.1109/tvcg.2018.2865152;10.1109/tvcg.2018.2864499,"Data Models,Image and Video Data,Temporal Data,Application Motivated Visualization,AR/VR/Immersive",,10.0,58.0,1124.0,HM,,reality ar assistants;performer perform activities;data streams output;modern science;necessary,0.6510;0.2641;0.1268;0.1133;0.0723,"[np.int64(-1), -1, -1, -1, -1]",50;-1;-1;-1;-1,50,50,Virtual Reality Technology
InfoVis,2002,Case study: visualizing sets of evolutionary trees,10.1109/infvis.2002.1173150,http://dx.doi.org/10.1109/INFVIS.2002.1173150,71.0,74.0,C,"We describe a visualization tool which allows a biologist to explore a large set of hypothetical evolutionary trees. Interacting with such a dataset allows the biologist to identify distinct hypotheses about how different species or organisms evolved, which would not have been clear from traditional analyses. Our system integrates a point-set visualization of the distribution of hypothetical trees with detail views of an individual tree, or of a consensus tree summarizing a subset of trees. Efficient algorithms were required for the key tasks of computing distances between trees, finding consensus trees, and laying out the point-set visualization.",Nina Amenta;Jeff Klingner,N. Amenta;J. Klingner,"University of Texas, Austin, Austin, TX, USA;Computer Sciences Department, University of Texas, Austin, Austin, TX, USA",10.1109/visual.1996.567787;10.1109/visual.1993.398870;10.1109/visual.1996.567787,,119.0,27.0,15.0,395.0,,,evolutionary trees;point set visualization;finding consensus;traditional analyses integrates;different,0.6739;0.4496;0.2237;0.0359;0.0049,"[np.int64(-1), -1, -1, -1, -1]",9;-1;-1;-1;-1,9,9,Tree Visualization Techniques
Vis,2004,Light weight space leaping using ray coherence,10.1109/visual.2004.63,http://dx.doi.org/10.1109/VISUAL.2004.63,19.0,26.0,C,"We present a space leaping technique for accelerating volume rendering with very low space and run-time complexity. Our technique exploits the ray coherence during ray casting by using the distance a ray traverses in empty space to leap its neighboring rays. Our technique works with parallel as well as perspective volume rendering, does not require any preprocessing or 3D data structures, and is independent of the transfer function. Being an image-space technique, it is independent of the complexity of the data being rendered. It can be used to accelerate both time-coherent and noncoherent animation sequences.",Sarang Lakare;Arie E. Kaufman,S. Lakare;A. Kaufman,"Center for Visual Computing (CVC) and Department of Computer Science, Stony Brook University, Stony Brook, NY, USA;Center for Visual Computing (CVC) and Department of Computer Science, Stony Brook University, Stony Brook, NY, USA",10.1109/visual.1993.398852;10.1109/visual.1999.809914;10.1109/visual.1990.146377;10.1109/visual.1998.745713;10.1109/visual.2002.1183775;10.1109/visual.1993.398852,"Direct Volume Rendering, Space Leaping, Empty Space Skipping, Ray Coherence, Volume Rendering Acceleration",34.0,6.0,13.0,114.0,,,accelerating volume rendering;space leap neighboring;casting using;does require preprocessing;coherent noncoherent,0.6881;0.3528;0.1305;0.1218;0.0724,"[np.int64(-1), -1, -1, -1, -1]",52;-1;-1;-1;-1,52,52,Volume Rendering Techniques
Vis,1990,A problem-oriented classification of visualization techniques,10.1109/visual.1990.146375,http://dx.doi.org/10.1109/VISUAL.1990.146375,139.0,,C,"Progress in scientific visualization could be accelerated if workers could more readily find visualization techniques relevant to a given problem. The authors describe an approach to this problem, based on a classification of visualization techniques, that is independent of particular application domains. A user breaks up a problem into subproblems, describes these subproblems in terms of the objects to be represented and the operations to be supported by a representation, locates applicable visualization techniques in a catalog, and combines these representations into a composite representation for the original problem. The catalog and its underlying classification provide a way for workers in different application disciplines to share methods.&lt;&lt;ETX&gt;&gt;",Stephen Wehrend;Clayton Lewis,S. Wehrend;C. Lewis,"Center for Advanced Decision Support in Water and Environmental, Systems and Department of Computer Science, University of Colorado, Boulder, CO, USA;Center for Advanced Decision Support in Water and Environmental, Systems and Department of Computer Science, University of Colorado, Boulder, CO, USA",,,483.0,112.0,6.0,1214.0,,,scientific visualization;representations composite representation;particular application domains;readily;user breaks problem,0.7366;0.1735;0.1011;0.0638;0.0245,"[np.int64(-1), -1, -1, -1, -1]",84;-1;-1;-1;-1,84,84,Scientific Visualization
SciVis,2016,Progressive Direct Volume-to-Volume Transformation,10.1109/tvcg.2016.2599042,http://dx.doi.org/10.1109/TVCG.2016.2599042,921.0,930.0,J,"We present a novel technique to generate transformations between arbitrary volumes, providing both expressive distances and smooth interpolates. In contrast to conventional morphing or warping approaches, our technique requires no user guidance, intermediate representations (like extracted features), or blending, and imposes no restrictions regarding shape or structure. Our technique operates directly on the volumetric data representation, and while linear programming approaches could solve the underlying problem optimally, their polynomial complexity makes them infeasible for high-resolution volumes. We therefore propose a progressive refinement approach designed for parallel execution that is able to quickly deliver approximate results that are iteratively improved toward the optimum. On this basis, we further present a new approach for the streaming selection of time steps in temporal data that allows for the reconstruction of the full sequence with a user-specified error bound. We finally demonstrate the utility of our technique for different applications, compare our approach against alternatives, and evaluate its characteristics with a variety of different data sets.",Steffen Frey;Thomas Ertl,Steffen Frey;Thomas Ertl,University of Stuttgart;University of Stuttgart,10.1109/tvcg.2008.140;10.1109/tvcg.2012.284;10.1109/visual.1994.346333;10.1109/tvcg.2008.143;10.1109/tvcg.2009.200;10.1109/visual.2002.1183809;10.1109/tvcg.2008.140,Volume transformation;Volume visualization;progressive;automatic;parallel;time-varying data;streaming data,14.0,12.0,47.0,679.0,,,morphing warping approaches;steps temporal data;arbitrary volumes providing;smooth;specified error,0.5367;0.3656;0.2639;0.2014;-0.0761,"[np.int64(-1), -1, -1, -1, -1]",118;-1;-1;-1;-1,118,118,Advanced Image Techniques
Vis,2009,Visual Exploration of Nasal Airflow,10.1109/tvcg.2009.198,http://dx.doi.org/10.1109/TVCG.2009.198,1407.0,1414.0,J,"Rhinologists are often faced with the challenge of assessing nasal breathing from a functional point of view to derive effective therapeutic interventions. While the complex nasal anatomy can be revealed by visual inspection and medical imaging, only vague information is available regarding the nasal airflow itself: Rhinomanometry delivers rather unspecific integral information on the pressure gradient as well as on total flow and nasal flow resistance. In this article we demonstrate how the understanding of physiological nasal breathing can be improved by simulating and visually analyzing nasal airflow, based on an anatomically correct model of the upper human respiratory tract. In particular we demonstrate how various information visualization (InfoVis) techniques, such as a highly scalable implementation of parallel coordinates, time series visualizations, as well as unstructured grid multi-volume rendering, all integrated within a multiple linked views framework, can be utilized to gain a deeper understanding of nasal breathing. Evaluation is accomplished by visual exploration of spatio-temporal airflow characteristics that include not only information on flow features but also on accompanying quantities such as temperature and humidity. To our knowledge, this is the first in-depth visual exploration of the physiological function of the nose over several simulated breathing cycles under consideration of a complete model of the nasal airways, realistic boundary conditions, and all physically relevant time-varying quantities.",Stefan Zachow;Philipp Muigg;Thomas Hildebrandt;Helmut Doleisch;Hans-Christian Hege,Stefan Zachow;Philipp Muigg;Thomas Hildebrandt;Helmut Doleisch;Hans-Christian Hege,"Zuse Institute Berlin, Germany;Institute of Computer Graphics and Algorithms, University of Technology, Vienna, Austria;Section Brain Surgery, Asklepios Clinic Birkenwerder, Germany;SimVis GmbH, Austria;Zuse Institute Berlin, Germany",10.1109/tvcg.2008.139;10.1109/tvcg.2007.70588;10.1109/visual.2003.1250390;10.1109/visual.2000.885739;10.1109/visual.1990.146402;10.1109/visual.2005.1532788;10.1109/tvcg.2006.170;10.1109/tvcg.2008.139,"Flow visualization, exploratory data analysis, interactive visual analysis of scientific data, time-dependent data",55.0,31.0,44.0,730.0,,,nasal airflow rhinomanometry;visualization infovis techniques;simulating;physically relevant time;deeper,0.6935;0.3798;0.1797;0.0991;0.0838,"[np.int64(-1), -1, -1, -1, -1]",18;-1;-1;-1;-1,18,18,Respiratory Data Analysis
Vis,2010,An Information-theoretic Framework for Visualization,10.1109/tvcg.2010.132,http://dx.doi.org/10.1109/TVCG.2010.132,1206.0,1215.0,J,"In this paper, we examine whether or not information theory can be one of the theoretic frameworks for visualization. We formulate concepts and measurements for qualifying visual information. We illustrate these concepts with examples that manifest the intrinsic and implicit use of information theory in many existing visualization techniques. We outline the broad correlation between visualization and the major applications of information theory, while pointing out the difference in emphasis and some technical gaps. Our study provides compelling evidence that information theory can explain a significant number of phenomena or events in visualization, while no example has been found which is fundamentally in conflict with information theory. We also notice that the emphasis of some traditional applications of information theory, such as data compression or data communication, may not always suit visualization, as the former typically focuses on the efficient throughput of a communication channel, whilst the latter focuses on the effectiveness in aiding the perceptual and cognitive process for data understanding and knowledge discovery. These findings suggest that further theoretic developments are necessary for adopting and adapting information theory for visualization.",Min Chen 0001;Heike Jänicke,Min Chen;Heike Jaenicke,"Swansea University, UK;Ruprecht-Karls-University Heidelberg",10.1109/tvcg.2007.70615;10.1109/visual.2005.1532781;10.1109/tvcg.2006.152;10.1109/infvis.1996.559213;10.1109/visual.2005.1532834;10.1109/infvis.2000.885096;10.1109/tvcg.2007.70515;10.1109/tvcg.2006.159;10.1109/infvis.2004.59;10.1109/tvcg.2007.70535;10.1109/tvcg.2008.140;10.1109/tvcg.2008.121;10.1109/infvis.1997.636792;10.1109/visual.2005.1532833;10.1109/infvis.2000.885092;10.1109/visual.1990.146375;10.1109/visual.2002.1183785,"Information theory, theory of visualization, quantitative evaluation",192.0,108.0,56.0,2654.0,TT,,information theory visualization;findings suggest theoretic;explain;manifest intrinsic implicit;necessary adopting,0.7910;0.2025;0.1634;0.0004;-0.0284,"[np.int64(-1), -1, -1, -1, -1]",134;-1;-1;-1;-1,134,134,Information Visualization
InfoVis,2017,MyBrush: Brushing and Linking with Personal Agency,10.1109/tvcg.2017.2743859,http://dx.doi.org/10.1109/TVCG.2017.2743859,605.0,615.0,J,"We extend the popular brushing and linking technique by incorporating personal agency in the interaction. We map existing research related to brushing and linking into a design space that deconstructs the interaction technique into three components: source (what is being brushed), link (the expression of relationship between source and target), and target (what is revealed as related to the source). Using this design space, we created MyBrush, a unified interface that offers personal agency over brushing and linking by giving people the flexibility to configure the source, link, and target of multiple brushes. The results of three focus groups demonstrate that people with different backgrounds leveraged personal agency in different ways, including performing complex tasks and showing links explicitly. We reflect on these results, paving the way for future research on the role of personal agency in information visualization.",Philipp Koytek;Charles Perin;Jo Vermeulen;Elisabeth André;Sheelagh Carpendale,Philipp Koytek;Charles Perin;Jo Vermeulen;Elisabeth André;Sheelagh Carpendale,"University of Calgary, Augsburg University;City, University of London, University of Calgary;University of Calgary;Augsburg University;University of Calgary",10.1109/tvcg.2011.185;10.1109/visual.1991.175794;10.1109/infvis.2003.1249024;10.1109/tvcg.2011.201;10.1109/tvcg.2007.70521;10.1109/vast.2009.5333443;10.1109/tvcg.2008.153;10.1109/infvis.2004.64;10.1109/infvis.1999.801858;10.1109/tvcg.2014.2346260;10.1109/visual.2000.885739;10.1109/infvis.2002.1173157;10.1109/vast.2007.4389011;10.1109/tvcg.2006.147;10.1109/tvcg.2008.116;10.1109/tvcg.2013.154;10.1109/tvcg.2010.138;10.1109/visual.1995.485139;10.1109/tvcg.2011.183;10.1109/tvcg.2009.162;10.1109/visual.1994.346302;10.1109/infvis.2004.12;10.1109/visual.1996.567800;10.1109/tvcg.2014.2346279;10.1109/infvis.1996.559216;10.1109/tvcg.2011.185,"Brushing,linking,personal agency,coordinated multiple views,interaction,design space,information visualization",36.0,27.0,82.0,1037.0,,,personal agency interaction;information visualization;popular brushing linking;source target target;different,0.5412;0.4387;0.4358;0.1131;0.0435,"[np.int64(-1), np.int64(-1), -1, -1, -1]",120;98;-1;-1;-1,98;120,120,Interactive Sensemaking
VAST,2012,Visualizing flows of images in social media,10.1109/vast.2012.6400539,http://dx.doi.org/10.1109/VAST.2012.6400539,229.0,230.0,M,"Mass and social media provide flows of images for real world events. It is sometimes difficult to represent realities and impressions of events using only text. However, even a single photo might remind us complex events. Along with events in the real world, there are representative images, such as design of products and commercial pictures. We can therefore recognize changes in trends of people's ideas, experiences, and interests through observing the flows of such representative images. This paper presents a novel 3D visualization system to explore temporal changes in trends using images associating with different topics, called Image Bricks. We show case studies using images extracted from our six-year blog archive. We first extract clusters of images as topics related to given keywords. We then visualize them on multiple timelines in a 3D space. Users can visually read stories of topics through exploring visualized images.",Masahiko Itoh;Masashi Toyoda;Tetsuya Kamijo;Masaru Kitsuregawa,Masahiko Itoh;Masashi Toyoda;Tetsuya Kamijo;Masaru Kitsuregawa,"Institute of Industrial Science, University of Tokyo;Institute of Industrial Science, University of Tokyo;Rakuten, Inc.;Institute of Industrial Science, University of Tokyo",,,1.0,2.0,6.0,345.0,,,trends using images;multiple timelines 3d;blog archive extract;read stories;bricks case,0.6963;0.3811;0.2628;0.2496;0.2086,"[np.int64(-1), -1, -1, -1, -1]",-1;-1;-1;-1;-1,,-1,Interactive 3D Visualization
Vis,1997,Constrained 3D navigation with 2D controllers,10.1109/visual.1997.663876,http://dx.doi.org/10.1109/VISUAL.1997.663876,175.0,182.0,C,"Navigation through 3D spaces is required in many interactive graphics and virtual reality applications. The authors consider the subclass of situations in which a 2D device such as a mouse controls smooth movements among viewpoints for a ""through the screen"" display of a 3D world. Frequently, there is a poor match between the goal of such a navigation activity, the control device, and the skills of the average user. They propose a unified mathematical framework for incorporating context-dependent constraints into the generalized viewpoint generation problem. These designer-supplied constraint modes provide a middle ground between the triviality of a single camera animation path and the confusing excess freedom of common unconstrained control paradigms. They illustrate the approach with a variety of examples, including terrain models, interior architectural spaces, and complex molecules.",Andrew J. Hanson;Eric A. Wernert,A.J. Hanson;E.A. Wernert,"Computer Science Department, Indiana University, Bloomington, IN, USA;Computer Science Department, Indiana University, Bloomington, IN, USA",10.1109/visual.1995.480804;10.1109/visual.1995.480804,"Navigation, Constrained Navigation, Viewing Control, Camera Control",189.0,32.0,25.0,250.0,,,navigation 3d spaces;framework incorporating context;screen display;common unconstrained;authors,0.6532;0.2401;0.2057;0.1998;0.0396,"[np.int64(-1), -1, -1, -1, -1]",69;-1;-1;-1;-1,69,69,3D Navigation Interfaces
Vis,1994,Piecewise-linear surface approximation from noisy scattered samples,10.1109/visual.1994.346336,http://dx.doi.org/10.1109/VISUAL.1994.346336,61.0,68.0,C,"We consider the problem of approximating a smooth surface f(x, y), based on n scattered samples {(x/sub i/, y/sub i/, z/sub i/)/sub i=1//sup n/} where the sample values {z/sub i/} are contaminated with noise: z/sub i/=f(x/sub i/, y/sub i/)=/spl epsiv//sub i/. We present an algorithm that generates a PLS (piecewise linear surface) f', defined on a triangulation of the sample locations V={(x/sub i/, y/sub i/)/sub i=1//sup n/}, approximating f well. Constructing the PLS involves specifying both the triangulation of V and the values of f' at the points of V. We demonstrate that even when the sampling process is not noisy, a better approximation for f is obtained using our algorithm, compared to existing methods. This algorithm is useful for DTM (digital terrain map) manipulation by polygon-based graphics engines for visualization applications.&lt;&lt;ETX&gt;&gt;",Michael Margaliot;Craig Gotsman,M. Margaliot;C. Gotsman,"Department of Electrical Engineering, Technion-Israel Institute of Technology, Haifa, Israel;Department of Computer Science, Technion-Israel Institute of Technology, Haifa, Israel",,,19.0,3.0,16.0,72.0,,,approximating smooth surface;defined triangulation;visualization applications lt;generates pls piecewise;contaminated,0.6507;0.4176;0.3435;0.2145;0.0497,"[np.int64(-1), -1, -1, -1, -1]",123;-1;-1;-1;-1,123,123,Surface Reconstruction
InfoVis,2005,Low-level components of analytic activity in information visualization,10.1109/infvis.2005.1532136,http://dx.doi.org/10.1109/INFVIS.2005.1532136,111.0,117.0,C,"Existing system level taxonomies of visualization tasks are geared more towards the design of particular representations than the facilitation of user analytic activity. We present a set of ten low level analysis tasks that largely capture people's activities while employing information visualization tools for understanding data. To help develop these tasks, we collected nearly 200 sample questions from students about how they would analyze five particular data sets from different domains. The questions, while not being totally comprehensive, illustrated the sheer variety of analytic questions typically posed by users when employing information visualization systems. We hope that the presented set of tasks is useful for information visualization system designers as a kind of common substrate to discuss the relative analytic capabilities of the systems. Further, the tasks may provide a form of checklist for system designers.",Robert A. Amar;James Eagan;John T. Stasko,R. Amar;J. Eagan;J. Stasko,"Georgia Institute of Technology,College of Computing, GVU Center;Georgia Institute of Technology,College of Computing, GVU Center;Georgia Institute of Technology,College of Computing, GVU Center",10.1109/visual.1990.146375;10.1109/infvis.1998.729560;10.1109/infvis.2000.885092;10.1109/infvis.2004.5;10.1109/infvis.2001.963289;10.1109/visual.1990.146375,"Analytic activity, taxonomy, knowledge discovery, design, evaluation",844.0,205.0,15.0,4315.0,,,information visualization designers;analytic questions typically;tasks collected nearly;kind common substrate;set low,0.7335;0.4007;0.1592;0.0402;-0.0959,"[np.int64(-1), -1, -1, -1, -1]",105;-1;-1;-1;-1,105,105,Visualization Designers
Vis,1998,Rear-projecting virtual data onto physical terrain: an exercise in two senses being better than one,10.1109/visual.1998.745341,http://dx.doi.org/10.1109/VISUAL.1998.745341,451.0,454.0,C,"This paper describes a project that combined physical model fabrication and virtual computer-based data display to create a unique visualization presentation. USGS terrain information on Prince of Wales Island, Alaska was used to create a physical prototype in SDSC's TeleManufacturing Facility. This model was then used as a mold to create a translucent plate of the terrain. Finally, deforestation data from the island was color mapped and rear-projected onto the translucent plate within a light box. The result is a very compelling display in which both the senses of sight and touch are used to make relationships between terrain features and the data more readily apparent.",Dru Clark;Richard Marciano;Rosemarie McKeon;Michael J. Bailey,D. Clark;R. Marciano;R. McKeon;M. Bailey,"San Diego Supercomputer Center, University of California, San Diego, USA;San Diego Supercomputer Center, University of California, San Diego, USA;San Diego Supercomputer Center, University of California, San Diego, USA;San Diego Supercomputer Center, University of California, San Diego, San Diego, CA, USA",10.1109/visual.1997.663862;10.1109/visual.1997.663862,,3.0,1.0,5.0,42.0,,,visualization presentation usgs;virtual computer based;used mold create;senses sight touch;island alaska used,0.6176;0.3057;0.2409;0.2146;0.1847,"[np.int64(-1), -1, -1, -1, -1]",86;-1;-1;-1;-1,86,86,Scientific Visualization Presentations
VAST,2012,Enterprise Data Analysis and Visualization: An Interview Study,10.1109/tvcg.2012.219,http://dx.doi.org/10.1109/TVCG.2012.219,2917.0,2926.0,J,"Organizations rely on data analysts to model customer engagement, streamline operations, improve production, inform business decisions, and combat fraud. Though numerous analysis and visualization tools have been built to improve the scale and efficiency at which analysts can work, there has been little research on how analysis takes place within the social and organizational context of companies. To better understand the enterprise analysts' ecosystem, we conducted semi-structured interviews with 35 data analysts from 25 organizations across a variety of sectors, including healthcare, retail, marketing and finance. Based on our interview data, we characterize the process of industrial data analysis and document how organizational features of an enterprise impact it. We describe recurring pain points, outstanding challenges, and barriers to adoption for visual analytic tools. Finally, we discuss design implications and opportunities for visual analysis research.",Sean Kandel;Andreas Paepcke;Joseph M. Hellerstein;Jeffrey Heer,Sean Kandel;Andreas Paepcke;Joseph M. Hellerstein;Jeffrey Heer,"University of Stanford, USA;University of Stanford, USA;University of California, Berkeley, USA;University of Stanford, USA",10.1109/tvcg.2008.137;10.1109/vast.2008.4677365;10.1109/vast.2011.6102438;10.1109/infvis.2005.1532136;10.1109/vast.2010.5652880;10.1109/vast.2009.5333878;10.1109/vast.2007.4389011;10.1109/vast.2011.6102435;10.1109/tvcg.2008.137,"Data, analysis, visualization, enterprise",500.0,274.0,37.0,7112.0,HM,,visual analytic tools;companies better understand;35 data;takes place social;impact recurring pain,0.6462;0.3684;0.1937;0.1162;0.0162,"[np.int64(-1), -1, -1, -1, -1]",108;-1;-1;-1;-1,108,108,Visual Analytics
Vis,2010,Direct Interval Volume Visualization,10.1109/tvcg.2010.145,http://dx.doi.org/10.1109/TVCG.2010.145,1505.0,1514.0,J,"We extend direct volume rendering with a unified model for generalized isosurfaces, also called interval volumes, allowing a wider spectrum of visual classification. We generalize the concept of scale-invariant opacity-typical for isosurface rendering-to semi-transparent interval volumes. Scale-invariant rendering is independent of physical space dimensions and therefore directly facilitates the analysis of data characteristics. Our model represents sharp isosurfaces as limits of interval volumes and combines them with features of direct volume rendering. Our objective is accurate rendering, guaranteeing that all isosurfaces and interval volumes are visualized in a crack-free way with correct spatial ordering. We achieve simultaneous direct and interval volume rendering by extending preintegration and explicit peak finding with data-driven splitting of ray integration and hybrid computation in physical and data domains. Our algorithm is suitable for efficient parallel processing for interactive applications as demonstrated by our CUDA implementation.",Marco Ament;Daniel Weiskopf;Hamish A. Carr,Marco Ament;Daniel Weiskopf;Hamish Carr,"VISUS Visualization Research Center, Universität Stuttgart, Stuttgart, Germany;VISUS Visualization Research Center, Universität Stuttgart, Stuttgart, Germany;School of Computing, University of Leeds, Leeds, UK",10.1109/visual.1998.745713;10.1109/visual.1997.663886;10.1109/visual.2004.85;10.1109/visual.1995.480789;10.1109/visual.2002.1183762;10.1109/tvcg.2009.149;10.1109/tvcg.2006.113;10.1109/tvcg.2008.186;10.1109/visual.2000.885683;10.1109/visual.2005.1532808;10.1109/tvcg.2008.160;10.1109/visual.2003.1250384;10.1109/tvcg.2009.204;10.1109/visual.1995.480807;10.1109/visual.1998.745713,"Direct volume rendering, interval volume, isosurface, ray casting, preintegration, scale-invariant opacity",28.0,16.0,41.0,654.0,,,direct volume rendering;peak finding data;called interval;crack free way;unified model generalized,0.6920;0.2725;0.1662;0.1025;0.0943,"[np.int64(-1), -1, -1, -1, -1]",52;-1;-1;-1;-1,52,52,Volume Rendering Techniques
InfoVis,2014,Combing the Communication Hairball: Visualizing Parallel Execution Traces using Logical Time,10.1109/tvcg.2014.2346456,http://dx.doi.org/10.1109/TVCG.2014.2346456,2349.0,2358.0,J,"With the continuous rise in complexity of modern supercomputers, optimizing the performance of large-scale parallel programs is becoming increasingly challenging. Simultaneously, the growth in scale magnifies the impact of even minor inefficiencies - potentially millions of compute hours and megawatts in power consumption can be wasted on avoidable mistakes or sub-optimal algorithms. This makes performance analysis and optimization critical elements in the software development process. One of the most common forms of performance analysis is to study execution traces, which record a history of per-process events and interprocess messages in a parallel application. Trace visualizations allow users to browse this event history and search for insights into the observed performance behavior. However, current visualizations are difficult to understand even for small process counts and do not scale gracefully beyond a few hundred processes. Organizing events in time leads to a virtually unintelligible conglomerate of interleaved events and moderately high process counts overtax even the largest display. As an alternative, we present a new trace visualization approach based on transforming the event history into logical time inferred directly from happened-before relationships. This emphasizes the code's structural behavior, which is much more familiar to the application developer. The original timing data, or other information, is then encoded through color, leading to a more intuitive visualization. Furthermore, we use the discrete nature of logical timelines to cluster processes according to their local behavior leading to a scalable visualization of even long traces on large process counts. We demonstrate our system using two case studies on large-scale parallel codes.",Katherine E. Isaacs;Peer-Timo Bremer;Ilir Jusufi;Todd Gamblin;Abhinav Bhatele;Martin Schulz 0001;Bernd Hamann,Katherine E. Isaacs;Peer-Timo Bremer;Ilir Jusufi;Todd Gamblin;Abhinav Bhatele;Martin Schulz;Bernd Hamann,"University of California, Davis;Lawrence Livermore National Laboratory;University of California, Davis;Lawrence Livermore National Laboratory;Lawrence Livermore National Laboratory;Lawrence Livermore National Laboratory;University of California, Davis",10.1109/tvcg.2012.286;10.1109/tvcg.2009.196;10.1109/tvcg.2011.199;10.1109/tvcg.2013.200;10.1109/tvcg.2012.286,"Information visualization, software visualization, timelines, traces, performance analysis",64.0,35.0,44.0,853.0,,,application trace visualizations;parallel codes;time leads;power consumption;moderately,0.6666;0.3318;0.2515;0.1157;0.0285,"[np.int64(-1), -1, -1, -1, -1]",83;-1;-1;-1;-1,83,83,Network Visualization
SciVis,2018,Tensor Field Visualization using Fiber Surfaces of Invariant Space,10.1109/tvcg.2018.2864846,http://dx.doi.org/10.1109/TVCG.2018.2864846,1122.0,1131.0,J,"Scientific visualization developed successful methods for scalar and vector fields. For tensor fields, however, effective, interactive visualizations are still missing despite progress over the last decades. We present a general approach for the generation of separating surfaces in symmetric, second-order, three-dimensional tensor fields. These surfaces are defined as fiber surfaces of the invariant space, i.e. as pre-images of surfaces in the range of a complete set of invariants. This approach leads to a generalization of the fiber surface algorithm by Klacansky et al. [16] to three dimensions in the range. This is due to the fact that the invariant space is three-dimensional for symmetric second-order tensors over a spatial domain. We present an algorithm for surface construction for simplicial grids in the domain and simplicial surfaces in the invariant space. We demonstrate our approach by applying it to stress fields from component design in mechanical engineering.",Felix Raith;Christian Blecha;Thomas Nagel;Francesco Parisio;Olaf Kolditz;Fabian Günther;Markus Stommel;Gerik Scheuermann,Felix Raith;Christian Blecha;Thomas Nagel;Francesco Parisio;Olaf Kolditz;Fabian Günther;Markus Stommel;Gerik Scheuermann,"Institute of Computer Science, Leipzig University, Leipzig, Germany;Institute of Computer Science, Leipzig University, Leipzig, Germany;Department of Environmental Informatics, Helmholtz Center for Environmental Research, Leipzig, Germany;Department of Environmental Informatics, Helmholtz Center for Environmental Research, Leipzig, Germany;Department of Environmental Informatics, Helmholtz Center for Environmental Research, Leipzig, Germany;Faculty for Mechanical Engineering, TU Dortmund University, Dortmund;Faculty for Mechanical Engineering, TU Dortmund University, Dortmund;Institute of Computer Science, Leipzig University, Leipzig, Germany",10.1109/visual.1994.346326;10.1109/visual.2003.1250379;10.1109/visual.1994.346326,"visualization,tensor field,invariants,fiber surface,interaction",18.0,21.0,36.0,622.0,,,tensor fields surfaces;interactive visualizations;grids domain simplicial;approach applying stress;range fact invariant,0.6828;0.3660;0.3006;0.2202;-0.0187,"[np.int64(-1), -1, -1, -1, -1]",61;-1;-1;-1;-1,61,61,Geometric Data Representation
InfoVis,2014,Revisiting Bertin Matrices: New Interactions for Crafting Tabular Visualizations,10.1109/tvcg.2014.2346279,http://dx.doi.org/10.1109/TVCG.2014.2346279,2082.0,2091.0,J,"We present Bertifier, a web app for rapidly creating tabular visualizations from spreadsheets. Bertifier draws from Jacques Bertin's matrix analysis method, whose goal was to “simplify without destroying” by encoding cell values visually and grouping similar rows and columns. Although there were several attempts to bring this method to computers, no implementation exists today that is both exhaustive and accessible to a large audience. Bertifier remains faithful to Bertin's method while leveraging the power of today's interactive computers. Tables are formatted and manipulated through crossets, a new interaction technique for rapidly applying operations on rows and columns. We also introduce visual reordering, a semi-interactive reordering approach that lets users apply and tune automatic reordering algorithms in a WYSIWYG manner. Sessions with eight users from different backgrounds suggest that Bertifier has the potential to bring Bertin's method to a wider audience of both technical and non-technical users, and empower them with data analysis and communication tools that were so far only accessible to a handful of specialists.COMPUTER",Charles Perin;Pierre Dragicevic;Jean-Daniel Fekete,Charles Perin;Pierre Dragicevic;Jean-Daniel Fekete,"INRIA, CNRS-LIMSI;INRIA;INRIA",10.1109/tvcg.2006.160;10.1109/tvcg.2014.2346292;10.1109/tvcg.2014.2346426;10.1109/tvcg.2006.160,"Visualization, Interaction, Tabular Data, Bertin, Crossing, Crossets",105.0,61.0,60.0,1031.0,,,tabular visualizations;reordering algorithms;web app rapidly;leveraging power today;bertifier remains faithful,0.6844;0.2624;0.2355;0.1610;0.1270,"[np.int64(-1), -1, -1, -1, -1]",95;-1;-1;-1;-1,95,95,Table-Based Visualizations
Vis,1990,Case study in scientific visualization: factors inducing periodic breathing in humans with blunted hypoxic sensitivity,10.1109/visual.1990.146415,http://dx.doi.org/10.1109/VISUAL.1990.146415,430.0,434.0,C,"The problem of presenting and gaining deeper understanding of a multidimensional system, a mathematical model Predicting 20-90 s oscillations in breathing, is presented. The authors utilized custom software for interactive analysis of a three-dimensional model, plus Wavefront software to render translucent images of the 3D surfaces. The results show that under conditions of no peripheral chemosensor sensitivity, periodic breathing is predicted to occur with (1) an increase in circulatory transit time between the lungs and brain, (2) the presence of marked steady state hypoventilation, and/or (3) an increase in brain blood flow rate. It is concluded that the peripheral chemosensors (carotid bodies) are not essential for the development of periodic breathing.&lt;&lt;ETX&gt;&gt;",Wayne E. Fordyce;Jeffrey Ventrella,W.E. Fordyce;J.J. Ventrella,"Research Computing Services, Syracuse University, Syracuse, NY, USA;Research Computing Services, Syracuse University, Syracuse, NY, USA",0.1109/visual.1990.146415,,1.0,1.0,10.0,46.0,,,periodic breathing predicted;peripheral chemosensors;software interactive analysis;images 3d surfaces;state,0.7084;0.3371;0.0867;0.0782;-0.0205,"[np.int64(-1), -1, -1, -1, -1]",18;-1;-1;-1;-1,18,18,Respiratory Data Analysis
InfoVis,2016,Colorgorical: Creating discriminable and preferable color palettes for information visualization,10.1109/tvcg.2016.2598918,http://dx.doi.org/10.1109/TVCG.2016.2598918,521.0,530.0,J,"We present an evaluation of Colorgorical, a web-based tool for creating discriminable and aesthetically preferable categorical color palettes. Colorgorical uses iterative semi-random sampling to pick colors from CIELAB space based on user-defined discriminability and preference importances. Colors are selected by assigning each a weighted sum score that applies the user-defined importances to Perceptual Distance, Name Difference, Name Uniqueness, and Pair Preference scoring functions, which compare a potential sample to already-picked palette colors. After, a color is added to the palette by randomly sampling from the highest scoring palettes. Users can also specify hue ranges or build off their own starting palettes. This procedure differs from previous approaches that do not allow customization (e.g., pre-made ColorBrewer palettes) or do not consider visualization design constraints (e.g., Adobe Color and ACE). In a Palette Score Evaluation, we verified that each scoring function measured different color information. Experiment 1 demonstrated that slider manipulation generates palettes that are consistent with the expected balance of discriminability and aesthetic preference for 3-, 5-, and 8-color palettes, and also shows that the number of colors may change the effectiveness of pair-based discriminability and preference scores. For instance, if the Pair Preference slider were upweighted, users would judge the palettes as more preferable on average. Experiment 2 compared Colorgorical palettes to benchmark palettes (ColorBrewer, Microsoft, Tableau, Random). Colorgorical palettes are as discriminable and are at least as preferable or more preferable than the alternative palette sets. In sum, Colorgorical allows users to make customized color palettes that are, on average, as effective as current industry standards by balancing the importance of discriminability and aesthetic preference.",Connor Gramazio;David H. Laidlaw;Karen B. Schloss,Connor C. Gramazio;David H. Laidlaw;Karen B. Schloss,"Dept. of Computer Science at Brown University;Dept. of Computer Science at Brown University;Dept. of Cognitive, Linguistic, and Psychological Sciences at Brown University",10.1109/visual.1996.568118;10.1109/tvcg.2014.2346978;10.1109/tvcg.2015.2467471;10.1109/tvcg.2014.2346983;10.1109/tvcg.2012.233;10.1109/visual.1996.568118,Aesthetics in Visualization;Color Perception;Metrics & Benchmarks;Visual Design;Visualization,119.0,101.0,37.0,3136.0,,,preference color palettes;balancing importance discriminability;demonstrated slider manipulation;generates;function measured different,0.7348;0.2763;0.1581;0.0475;-0.0502,"[np.int64(-1), -1, -1, -1, -1]",-1;-1;-1;-1;-1,,-1,Interactive 3D Visualization
Vis,1997,exVis: developing a wind tunnel data visualization tool,10.1109/visual.1997.663911,http://dx.doi.org/10.1109/VISUAL.1997.663911,417.0,420.0,C,"Software has been developed to apply visualization techniques to aeronautics data collected during wind tunnel experiments. Interaction between the software developers and the aeroscientists has been crucial in making the software. The interaction has also been important in building the scientists' confidence in the use of interactive, computer-mediated analysis tools.",Samuel P. Uselton,S.P. Uselton,"Ames Research Center, NASA, Moffett Field, CA, USA",,,22.0,6.0,0.0,95.0,,,wind tunnel experiments;software developers aeroscientists;apply visualization;use interactive computer;scientists confidence use,0.6379;0.4952;0.4543;0.2616;0.2133,"[np.int64(-1), -1, -1, -1, -1]",17;-1;-1;-1;-1,17,17,Turbulent Flow Simulation
Vis,2008,Visualization of Cellular and Microvascular Relationships,10.1109/tvcg.2008.179,http://dx.doi.org/10.1109/TVCG.2008.179,1611.0,1618.0,J,"Understanding the structure of microvasculature structures and their relationship to cells in biological tissue is an important and complex problem. Brain microvasculature in particular is known to play an important role in chronic diseases. However, these networks are only visible at the microscopic level and can span large volumes of tissue. Due to recent advances in microscopy, large volumes of data can be imaged at the resolution necessary to reconstruct these structures. Due to the dense and complex nature of microscopy data sets, it is important to limit the amount of information displayed. In this paper, we describe methods for encoding the unique structure of microvascular data, allowing researchers to selectively explore microvascular anatomy. We also identify the queries most useful to researchers studying microvascular and cellular relationships. By associating cellular structures with our microvascular framework, we allow researchers to explore interesting anatomical relationships in dense and complex data sets.",David Mayerich;Louise C. Abbott;John Keyser,David Mayerich;Louise Abbott;John Keyser,"Department of Computer Science, Texas A and M University, USA;Department of Veterinary Integrative Biosciences, Texas A and M University, USA;Department of Computer Science, Texas A and M University, USA",10.1109/visual.2005.1532859;10.1109/visual.1997.663917;10.1109/tvcg.2006.197;10.1109/tvcg.2007.70532;10.1109/visual.2004.16;10.1109/visual.2005.1532859,"microscopy, biomedical, medical, blood vessels, cells",26.0,14.0,35.0,370.0,,,structure microvascular data;problem brain;limit information displayed;methods encoding unique;advances,0.7228;0.2447;0.1752;0.1447;0.0935,"[np.int64(-1), -1, -1, -1, -1]",115;-1;-1;-1;-1,115,115,Structural Connectivity Analysis
InfoVis,2020,MobileVisFixer: Tailoring Web Visualizations for Mobile Phones Leveraging an Explainable Reinforcement Learning Framework,10.1109/tvcg.2020.3030423,http://dx.doi.org/10.1109/TVCG.2020.3030423,464.0,474.0,J,"We contribute MobileVisFixer, a new method to make visualizations more mobile-friendly. Although mobile devices have become the primary means of accessing information on the web, many existing visualizations are not optimized for small screens and can lead to a frustrating user experience. Currently, practitioners and researchers have to engage in a tedious and time-consuming process to ensure that their designs scale to screens of different sizes, and existing toolkits and libraries provide little support in diagnosing and repairing issues. To address this challenge, MobileVisFixer automates a mobile-friendly visualization re-design process with a novel reinforcement learning framework. To inform the design of MobileVisFixer, we first collected and analyzed SVG-based visualizations on the web, and identified five common mobile-friendly issues. MobileVisFixer addresses four of these issues on single-view Cartesian visualizations with linear or discrete scales by a Markov Decision Process model that is both generalizable across various visualizations and fully explainable. MobileVisFixer deconstructs charts into declarative formats, and uses a greedy heuristic based on Policy Gradient methods to find solutions to this difficult, multi-criteria optimization problem in reasonable time. In addition, MobileVisFixer can be easily extended with the incorporation of optimization algorithms for data visualizations. Quantitative evaluation on two real-world datasets demonstrates the effectiveness and generalizability of our method.",Aoyu Wu;Wai Tong;Tim Dwyer;Bongshin Lee;Petra Isenberg;Huamin Qu,Aoyu Wu;Wai Tong;Tim Dwyer;Bongshin Lee;Petra Isenberg;Huamin Qu,Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Monash University;Microsoft Research;Inria;Hong Kong University of Science and Technology,10.1109/tvcg.2018.2865234;10.1109/tvcg.2019.2934397;10.1109/tvcg.2018.2865138;10.1109/tvcg.2019.2934431;10.1109/vast.2007.4388994;10.1109/tvcg.2007.70594;10.1109/tvcg.2018.2865240;10.1109/tvcg.2017.2744320;10.1109/tvcg.2018.2865158;10.1109/tvcg.2016.2599030;10.1109/tvcg.2015.2467091;10.1109/tvcg.2012.196;10.1109/tvcg.2019.2934538;10.1109/tvcg.2018.2865234,"Mobile visualization,Responsive visualization,Machine learning for visualizations,Reinforcement learning",30.0,27.0,78.0,1404.0,,,visualizations mobile friendly;heuristic based policy;different sizes;screens lead frustrating;contribute,0.6404;0.2778;0.1615;0.1557;0.0637,"[np.int64(-1), -1, -1, -1, -1]",138;-1;-1;-1;-1,138,138,Innovative Visualization Design
InfoVis,2002,InterRing: an interactive tool for visually navigating and manipulating hierarchical structures,10.1109/infvis.2002.1173151,http://dx.doi.org/10.1109/INFVIS.2002.1173151,77.0,84.0,C,"Radial, space-filling (RSF) techniques for hierarchy visualization have several advantages over traditional node-link diagrams, including the ability to efficiently use the display space while effectively conveying the hierarchy structure. Several RSF systems and tools have been developed to date, each with varying degrees of support for interactive operations such as selection and navigation. We describe what we believe to be a complete set of desirable operations on hierarchical structures. We then present InterRing, an RSF hierarchy visualization system that supports a significantly more extensive set of these operations than prior systems. In particular, InterRing supports multi-focus distortions, interactive hierarchy reconfiguration, and both semi-automated and manual selection. We show the power and utility of these and other operations, and describe our on-going efforts to evaluate their effectiveness and usability.",Jing Yang 0001;Matthew O. Ward;Elke A. Rundensteiner,Jing Yang;M.O. Ward;E.A. Rundensteiner,"Computer Science Department, Worcester Polytechnic Institute, Worcester, MA, USA;Computer Science Department, Worcester Polytechnic Institute, Worcester, MA, USA;Computer Science Department, Worcester Polytechnic Institute, Worcester, MA, USA",10.1109/infvis.2001.963290;10.1109/infvis.2001.963285;10.1109/infvis.1997.636718;10.1109/infvis.1999.801858;10.1109/infvis.1995.528689;10.1109/infvis.2001.963283;10.1109/visual.1991.175815;10.1109/infvis.2000.885091;10.1109/infvis.1999.801860;10.1109/infvis.2001.963284;10.1109/visual.1999.809866;10.1109/infvis.2001.963281;10.1109/infvis.1998.729557;10.1109/infvis.2001.963290,"radial space-filling hierarchy visualizations, multi-focus distortion, structure-based brushing",192.0,21.0,32.0,1028.0,,,hierarchy visualization supports;space filling rsf;reconfiguration semi automated;focus;date varying,0.7759;0.2713;0.1349;0.0963;-0.0968,"[np.int64(-1), -1, -1, -1, -1]",134;-1;-1;-1;-1,134,134,Information Visualization
Vis,2021,A Critical Reflection on Visualization Research: Where Do Decision Making Tasks Hide?,10.1109/tvcg.2021.3114813,http://dx.doi.org/10.1109/TVCG.2021.3114813,1128.0,1138.0,J,"It has been widely suggested that a key goal of visualization systems is to assist decision making, but is this true? We conduct a critical investigation on whether the activity of decision making is indeed central to the visualization domain. By approaching decision making as a user <i>task</i>, we explore the degree to which decision tasks are evident in visualization research and user studies. Our analysis suggests that decision tasks are not commonly found in current visualization task taxonomies and that the visualization field has yet to leverage guidance from decision theory domains on how to study such tasks. We further found that the majority of visualizations addressing decision making were not evaluated based on their ability to assist decision tasks. Finally, to help expand the impact of visual analytics in organizational as well as casual decision making activities, we initiate a research agenda on how decision making assistance could be elevated throughout visualization research.",Evanthia Dimara;John T. Stasko,Evanthia Dimara;John Stasko,"Utrecht University, Netherlands and University of Konstanz, Germany;Georgia Tech, US",10.1109/vast.2011.6102457;10.1109/tvcg.2019.2934262;10.1109/infvis.2005.1532136;10.1109/infvis.2004.10;10.1109/vast.2007.4388995;10.1109/tvcg.2020.3028891;10.1109/tvcg.2016.2598869;10.1109/tvcg.2020.3030455;10.1109/tvcg.2013.186;10.1109/tvcg.2013.124;10.1109/tvcg.2013.146;10.1109/vast.2006.261431;10.1109/tvcg.2020.3030342;10.1109/infvis.1998.729560;10.1109/vast.2017.8585665;10.1109/infvis.1996.559213;10.1109/tvcg.2016.2598544;10.1109/tvcg.2018.2865233;10.1109/tvcg.2016.2598594;10.1109/tvcg.2017.2745138;10.1109/tvcg.2019.2934283;10.1109/tvcg.2020.3030469;10.1109/vast.2015.7347636;10.1109/tvcg.2013.226;10.1109/tvcg.2013.138;10.1109/vast.2008.4677365;10.1109/tvcg.2013.173;10.1109/vast.2010.5650815;10.1109/tvcg.2016.2598588;10.1109/tvcg.2019.2934659;10.1109/tvcg.2011.255;10.1109/tvcg.2018.2864889;10.1109/infvis.1997.636793;10.1109/tvcg.2020.3030335;10.1109/tvcg.2018.2864909;10.1109/tvcg.2012.215;10.1109/vast.2007.4388994;10.1109/tvcg.2014.2346930;10.1109/tvcg.2017.2744299;10.1109/tvcg.2018.2865159;10.1109/tvcg.2020.3028985;10.1109/tvcg.2010.177;10.1109/tvcg.2014.2346926;10.1109/tvcg.2012.278;10.1109/vast.2011.6102451;10.1109/tvcg.2016.2599106;10.1109/tvcg.2016.2598589;10.1109/vast.2006.261434;10.1109/tvcg.2015.2467754;10.1109/tvcg.2012.261;10.1109/tvcg.2011.196;10.1109/tvcg.2013.130;10.1109/vast.2009.5333920;10.1109/tvcg.2015.2467591;10.1109/tvcg.2014.2346481;10.1109/vast.2008.4677363;10.1109/tvcg.2013.120;10.1109/tvcg.2012.213;10.1109/tvcg.2015.2468011;10.1109/visual.1992.235203;10.1109/vast.2011.6102453;10.1109/visual.2005.1532781;10.1109/tvcg.2015.2468111;10.1109/tvcg.2017.2745078;10.1109/visual.1990.146375;10.1109/tvcg.2018.2865126;10.1109/infvis.1995.528682;10.1109/tvcg.2020.3028957;10.1109/tvcg.2016.2598664;10.1109/tvcg.2007.70515;10.1109/tvcg.2014.2346898;10.1109/tvcg.2018.2865076;10.1109/tvcg.2017.2744738;10.1109/tvcg.2020.3030458;10.1109/tvcg.2010.223;10.1109/tvcg.2014.2346922;10.1109/infvis.1995.528694;10.1109/vast.2011.6102457,"decision making,data,visualization,visual analytics,taxonomies,task",13.0,23.0,190.0,1955.0,,,visualizations addressing decision;making user task;study;theory domains;elevated,0.7813;0.1540;0.1104;0.0515;0.0102,"[np.int64(-1), -1, -1, -1, -1]",99;-1;-1;-1;-1,99,99,Decision-Making Visualizations
VAST,2017,SOMFlow: Guided Exploratory Cluster Analysis with Self-Organizing Maps and Analytic Provenance,10.1109/tvcg.2017.2744805,http://dx.doi.org/10.1109/TVCG.2017.2744805,120.0,130.0,J,"Clustering is a core building block for data analysis, aiming to extract otherwise hidden structures and relations from raw datasets, such as particular groups that can be effectively related, compared, and interpreted. A plethora of visual-interactive cluster analysis techniques has been proposed to date, however, arriving at useful clusterings often requires several rounds of user interactions to fine-tune the data preprocessing and algorithms. We present a multi-stage Visual Analytics (VA) approach for iterative cluster refinement together with an implementation (SOMFlow) that uses Self-Organizing Maps (SOM) to analyze time series data. It supports exploration by offering the analyst a visual platform to analyze intermediate results, adapt the underlying computations, iteratively partition the data, and to reflect previous analytical activities. The history of previous decisions is explicitly visualized within a flow graph, allowing to compare earlier cluster refinements and to explore relations. We further leverage quality and interestingness measures to guide the analyst in the discovery of useful patterns, relations, and data partitions. We conducted two pair analytics experiments together with a subject matter expert in speech intonation research to demonstrate that the approach is effective for interactive data analysis, supporting enhanced understanding of clustering results as well as the interactive process itself.",Dominik Sacha;Matthias Kraus 0002;Jürgen Bernard;Michael Behrisch 0001;Tobias Schreck;Yuki Asano 0003;Daniel A. Keim,Dominik Sacha;Matthias Kraus;Jürgen Bernard;Michael Behrisch;Tobias Schreck;Yuki Asano;Daniel A. Keim,"University of Konstanz, Germany;University of Konstanz, Germany;TU Darmstadt, Germany;University of Konstanz, Germany;Graz University of Technology;University of Tübingen;University of Konstanz, Germany",10.1109/vast.2009.5332584;10.1109/vast.2014.7042480;10.1109/tvcg.2013.178;10.1109/tvcg.2011.229;10.1109/tvcg.2011.188;10.1109/tvcg.2016.2598468;10.1109/vast.2010.5652443;10.1109/vast.2015.7347625;10.1109/vast.2007.4389013;10.1109/tvcg.2014.2346260;10.1109/tvcg.2007.70582;10.1109/vast.2007.4388999;10.1109/tvcg.2014.2346481;10.1109/tvcg.2016.2598495;10.1109/vast.2011.6102453;10.1109/vast.2009.5332584,"Visual Analytics,Interaction,Visual Cluster Analysis,Quality Metrics,Guidance,Self-Organizing Maps,Time Series",72.0,57.0,58.0,1887.0,,,interactive cluster analysis;data reflect previous;somflow uses self;intonation research;time,0.7032;0.2200;0.1985;0.1765;0.0697,"[np.int64(-1), -1, -1, -1, -1]",85;-1;-1;-1;-1,85,85,Cluster Visualization
InfoVis,2015,Off the Radar: Comparative Evaluation of Radial Visualization Solutions for Composite Indicators,10.1109/tvcg.2015.2467322,http://dx.doi.org/10.1109/TVCG.2015.2467322,569.0,578.0,J,"A composite indicator (CI) is a measuring and benchmark tool used to capture multi-dimensional concepts, such as Information and Communication Technology (ICT) usage. Individual indicators are selected and combined to reflect a phenomena being measured. Visualization of a composite indicator is recommended as a tool to enable interested stakeholders, as well as the public audience, to better understand the indicator components and evolution overtime. However, existing CI visualizations introduce a variety of solutions and there is a lack in CI's visualization guidelines. Radial visualizations are popular among these solutions because of CI's inherent multi-dimensionality. Although in dispute, Radar-charts are often used for CI presentation. However, no empirical evidence on Radar's effectiveness and efficiency for common CI tasks is available. In this paper, we aim to fill this gap by reporting on a controlled experiment that compares the Radar chart technique with two other radial visualization methods: Flowercharts as used in the well-known OECD Betterlife index, and Circle-charts which could be adopted for this purpose. Examples of these charts in the current context are shown in Figure 1. We evaluated these charts, showing the same data with each of the mentioned techniques applying small multiple views for different dimensions of the data. We compared users' performance and preference empirically under a formal task-taxonomy. Results indicate that the Radar chart was the least effective and least liked, while performance of the two other options were mixed and dependent on the task. Results also showed strong preference of participants toward the Flower chart. Summarizing our results, we provide specific design guidelines for composite indicator visualization.",Yael Albo;Joel Lanir;Peter Bak;Sheizaf Rafaeli,Yael Albo;Joel Lanir;Peter Bak;Sheizaf Rafaeli,"University of Haifa, Israel;University of Haifa, Israel;IBM Research Haifa Lab, Haifa, Israel;Sheizaf Rafaeli is with University of Haifa, Israel",10.1109/tvcg.2010.209;10.1109/tvcg.2008.125;10.1109/tvcg.2010.209,"Visualization evaluation, radial layout design, composite indicator visualization, experiment",60.0,46.0,35.0,1415.0,,,composite indicator visualization;communication technology ict;compared users;radar effectiveness efficiency;adopted purpose,0.6964;0.2733;0.2726;0.1764;-0.0205,"[np.int64(-1), -1, -1, -1, -1]",136;-1;-1;-1;-1,136,136,Trend Visualization Techniques
VAST,2009,Multiple step social structure analysis with Cytoscape,10.1109/vast.2009.5333961,http://dx.doi.org/10.1109/VAST.2009.5333961,,,M,Cytoscape is a popular open source tool for biologists to visualize interaction networks. We find that it offers most of the desired functionality for visual analytics on graph data to guide us in the identification of the underlying social structure. We demonstrate its utility in the identification of the social structure in the VAST 2009 Flitter Mini Challenge.,Hao Zhou;Anna A. Shaverdian;H. V. Jagadish;George Michailidis,Hao Zhou;Anna A. Shaverdian;H.V. Jagadish;George Michailidis,"Department of Statistics, University of Michigan, USA;Department of EECS, University of Michigan, USA;Department of EECS, University of Michigan, USA;Department of Statistics, University of Michigan, USA",,,5.0,2.0,3.0,267.0,,,visualize interaction networks;cytoscape;flitter;data guide identification;2009,0.6566;0.5268;0.2608;0.1251;0.0354,"[np.int64(-1), np.int64(-1), -1, -1, -1]",87;23;-1;-1;-1,23;87,87,Social Network Visualization
Vis,2024,2D Embeddings of Multi-Dimensional Partitionings,10.1109/tvcg.2024.3456394,http://dx.doi.org/10.1109/TVCG.2024.3456394,218.0,228.0,J,"Partitionings (or segmentations) divide a given domain into disjoint connected regions whose union forms again the entire domain. Multi-dimensional partitionings occur, for example, when analyzing parameter spaces of simulation models, where each segment of the partitioning represents a region of similar model behavior. Having computed a partitioning, one is commonly interested in understanding how large the segments are and which segments lie next to each other. While visual representations of 2D domain partitionings that reveal sizes and neighborhoods are straightforward, this is no longer the case when considering multi-dimensional domains of three or more dimensions. We propose an algorithm for computing 2D embeddings of multi-dimensional partitionings. The embedding shall have the following properties: It shall maintain the topology of the partitioning and optimize the area sizes and joint boundary lengths of the embedded segments to match the respective sizes and lengths in the multi-dimensional domain. We demonstrate the effectiveness of our approach by applying it to different use cases, including the visual exploration of 3D spatial domain segmentations and multi-dimensional parameter space partitionings of simulation ensembles. We numerically evaluate our algorithm with respect to how well sizes and lengths are preserved depending on the dimensionality of the domain and the number of segments.",Marina Evers;Lars Linsen,Marina Evers;Lars Linsen,"University of Münster, Germany;University of Münster, Germany",10.1109/tvcg.2011.186;10.1109/scivis.2015.7429487;10.1109/tvcg.2010.190;10.1109/tvcg.2009.122;10.1109/tvcg.2018.2865051;10.1109/tvcg.2014.2346321;10.1109/infvis.1999.801860;10.1109/tvcg.2016.2598830,"Multi-dimensional partitionings,segmentations,,,dimensionality reduction,parameter space visualization",,0.0,56.0,122.0,,,2d domain partitionings;simulation ensembles;including visual exploration;embeddings multi;demonstrate effectiveness,0.6854;0.4373;0.3511;0.2597;0.0041,"[np.int64(-1), -1, -1, -1, -1]",126;-1;-1;-1;-1,126,126,Geometric Mesh Processing
SciVis,2012,Derived Metric Tensors for Flow Surface Visualization,10.1109/tvcg.2012.211,http://dx.doi.org/10.1109/TVCG.2012.211,2149.0,2158.0,J,"Integral flow surfaces constitute a widely used flow visualization tool due to their capability to convey important flow information such as fluid transport, mixing, and domain segmentation. Current flow surface rendering techniques limit their expressiveness, however, by focusing virtually exclusively on displacement visualization, visually neglecting the more complex notion of deformation such as shearing and stretching that is central to the field of continuum mechanics. To incorporate this information into the flow surface visualization and analysis process, we derive a metric tensor field that encodes local surface deformations as induced by the velocity gradient of the underlying flow field. We demonstrate how properties of the resulting metric tensor field are capable of enhancing present surface visualization and generation methods and develop novel surface querying, sampling, and visualization techniques. The provided results show how this step towards unifying classic flow visualization and more advanced concepts from continuum mechanics enables more detailed and improved flow analysis.",Harald Obermaier;Kenneth I. Joy,Harald Obermaier;Kenneth I. Joy,"Institute for Data Analysis and Visualization (IDAV), University of California, Davis, USA;Institute for Data Analysis and Visualization (IDAV), University of California, Davis, USA",10.1109/tvcg.2008.163;10.1109/tvcg.2010.173;10.1109/tvcg.2011.170;10.1109/tvcg.2006.134;10.1109/tvcg.2008.133;10.1109/visual.1992.235211;10.1109/tvcg.2007.70551;10.1109/visual.2004.80;10.1109/tvcg.2009.190;10.1109/tvcg.2010.166;10.1109/tvcg.2009.154;10.1109/tvcg.2007.70554;10.1109/tvcg.2008.163,"Vector field, integral surfaces, metric tensor, deformation, velocity gradient, continuum mechanics",14.0,9.0,29.0,511.0,,,flow surface visualization;notion deformation shearing;derive metric tensor;exclusively;field encodes local,0.7172;0.3776;0.2800;-0.0091;-0.0181,"[np.int64(-1), -1, -1, -1, -1]",63;-1;-1;-1;-1,63,63,Flow Visualization Techniques
Vis,2022,Erato: Cooperative Data Story Editing via Fact Interpolation,10.1109/tvcg.2022.3209428,http://dx.doi.org/10.1109/TVCG.2022.3209428,983.0,993.0,J,"As an effective form of narrative visualization, visual data stories are widely used in data-driven storytelling to communicate complex insights and support data understanding. Although important, they are difficult to create, as a variety of interdisciplinary skills, such as data analysis and design, are required. In this work, we introduce Erato, a human-machine cooperative data story editing system, which allows users to generate insightful and fluent data stories together with the computer. Specifically, Erato only requires a number of keyframes provided by the user to briefly describe the topic and structure of a data story. Meanwhile, our system leverages a novel interpolation algorithm to help users insert intermediate frames between the keyframes to smooth the transition. We evaluated the effectiveness and usefulness of the Erato system via a series of evaluations including a Turing test, a controlled user study, a performance validation, and interviews with three expert users. The evaluation results showed that the proposed interpolation technique was able to generate coherent story content and help users create data stories more efficiently.",Mengdi Sun;Ligan Cai;Weiwei Cui;Yanqiu Wu 0001;Yang Shi 0007;Nan Cao 0001,Mengdi Sun;Ligan Cai;Weiwei Cui;Yanqiu Wu;Yang Shi;Nan Cao,"Intelligent Big Data Visualization Lab, Tongji University, China;Intelligent Big Data Visualization Lab, Tongji University, China;Microsoft Research Asia, China;Intelligent Big Data Visualization Lab, Tongji University, China;Intelligent Big Data Visualization Lab, Tongji University, China;Intelligent Big Data Visualization Lab, Tongji University, China",10.1109/tvcg.2016.2598647;10.1109/tvcg.2015.2467732;10.1109/tvcg.2016.2598876;10.1109/tvcg.2021.3114804;10.1109/tvcg.2019.2934785;10.1109/tvcg.2015.2467531;10.1109/tvcg.2013.119;10.1109/tvcg.2020.3030360;10.1109/tvcg.2021.3114775;10.1109/tvcg.2007.70594;10.1109/tvcg.2018.2865240;10.1109/tvcg.2012.249;10.1109/tvcg.2010.179;10.1109/tvcg.2020.3030403;10.1109/visual.2005.1532849;10.1109/tvcg.2018.2865232;10.1109/tvcg.2019.2934398;10.1109/visual.1995.480798;10.1109/tvcg.2015.2467191;10.1109/tvcg.2021.3114774;10.1109/tvcg.2016.2598647,"Interpolation,visual storytelling,human-machine cooperation",,6.0,61.0,987.0,,,narrative visualization;keyframes smooth transition;turing test controlled;erato requires number;including,0.7136;0.2261;0.1531;0.0820;0.0134,"[np.int64(-1), -1, -1, -1, -1]",133;-1;-1;-1;-1,133,133,Storytelling with Data
Vis,2004,"Anisotropic volume rendering for extremely dense, thin line data",10.1109/visual.2004.5,http://dx.doi.org/10.1109/VISUAL.2004.5,107.0,114.0,C,"Many large scale physics-based simulations which take place on PC clusters or supercomputers produce huge amounts of data including vector fields. While these vector data such as electromagnetic fields, fluid flow fields, or particle paths can be represented by lines, the sheer number of the lines overwhelms the memory and computation capability of a high-end PC used for visualization. Further, very dense or intertwined lines, rendered with traditional visualization techniques, can produce unintelligible results with unclear depth relationships between the lines and no sense of global structure. Our approach is to apply a lighting model to the lines and sample them into an anisotropic voxel representation based on spherical harmonics as a preprocessing step. Then we evaluate and render these voxels for a given view using traditional volume rendering. For extremely large line based datasets, conversion to anisotropic voxels reduces the overall storage and rendering for O(n) lines to O(1) with a large constant that is still small enough to allow meaningful visualization of the entire dataset at nearly interactive rates on a single commodity PC.",Gregory L. Schussman;Kwan-Liu Ma,G. Schussman;K.-L. Ma,"Stanford Linear Accelerator Center, USA;University of California Davis, USA",,"anisotropic lighting, line data, scientific visualization, vector field, volume rendering",34.0,16.0,17.0,236.0,,,traditional volume rendering;intertwined lines;fields particle;pc clusters supercomputers;entire dataset,0.5938;0.2691;0.2355;0.2194;0.1071,"[np.int64(-1), -1, -1, -1, -1]",52;-1;-1;-1;-1,52,52,Volume Rendering Techniques
InfoVis,1997,Domesticating Bead: adapting an information visualization system to a financial institution,10.1109/infvis.1997.636789,http://dx.doi.org/10.1109/INFVIS.1997.636789,73.0,80.0,C,"The Bead visualization system employs a fast algorithm for laying out high-dimensional data in a low-dimensional space, and a number of features added to 3D visualizations to improve imageability. We describe recent work on both aspects of the system, in particular a generalization of the data types laid out and the implementation of imageability features in a 2D visualization tool. The variety of data analyzed in a financial institution such as UBS, and the ubiquity of spreadsheets as a medium for analysis, led us to extend our layout tools to handle data in a generic spreadsheet format. We describe the metrics of similarity used for this data type, and give examples of layouts of sets of records of financial trades. Conservatism and scepticism with regard to 3D visualization, along with the lack of functionality of widely available 3D web browsers, led to the development of a 2D visualization tool with refinements of a number of our imageability features.",Dominique Brodbeck;Matthew Chalmers;Aran Lunzer;Pamela Cotture,D. Brodbeck;M. Chalmers;A. Lunzer;P. Cotture,"UbiLaboratory, Union Bank of Switzerland, Zurich, Switzerland;UbiLaboratory, Union Bank of Switzerland, Zurich, Switzerland;UbiLaboratory, Union Bank of Switzerland, Zurich, Switzerland;UbiLaboratory, Union Bank of Switzerland, Zurich, Switzerland",10.1109/visual.1990.146402;10.1109/infvis.1995.528686;10.1109/visual.1996.568118;10.1109/infvis.1995.528688;10.1109/visual.1994.346302;10.1109/visual.1991.175794;10.1109/visual.1996.567787;10.1109/infvis.1996.559223;10.1109/visual.1990.146402,,59.0,16.0,23.0,199.0,,,bead visualization employs;3d web browsers;metrics similarity;generic spreadsheet;data low,0.6199;0.3715;0.3500;0.3421;0.1214,"[np.int64(-1), -1, -1, -1, -1]",146;-1;-1;-1;-1,146,146,Visualization Techniques
InfoVis,2011,MoleView: An Attribute and Structure-Based Semantic Lens for Large Element-Based Plots,10.1109/tvcg.2011.223,http://dx.doi.org/10.1109/TVCG.2011.223,2600.0,2609.0,J,"We present MoleView, a novel technique for interactive exploration of multivariate relational data. Given a spatial embedding of the data, in terms of a scatter plot or graph layout, we propose a semantic lens which selects a specific spatial and attribute-related data range. The lens keeps the selected data in focus unchanged and continuously deforms the data out of the selection range in order to maintain the context around the focus. Specific deformations include distance-based repulsion of scatter plot points, deforming straight-line node-link graph drawings, and as varying the simplification degree of bundled edge graph layouts. Using a brushing-based technique, we further show the applicability of our semantic lens for scenarios requiring a complex selection of the zones of interest. Our technique is simple to implement and provides real-time performance on large datasets. We demonstrate our technique with actual data from air and road traffic control, medical imaging, and software comprehension applications.",Christophe Hurter;Alexandru C. Telea;Ozan Ersoy,Christophe Hurter;Alexandru Telea;Ozan Ersoy,"DGAC/DTI Research and Development, ENAC, University of Toulouse, France;University of Groningen, Netherlands;University of Groningen, Netherlands",10.1109/tvcg.2011.233;10.1109/tvcg.2008.135;10.1109/tvcg.2006.147;10.1109/infvis.2005.1532150;10.1109/infvis.2004.66;10.1109/infvis.2003.1249008;10.1109/tvcg.2011.233,"Semantic lenses, magic lenses, graph bundling, attribute filtering",98.0,49.0,35.0,858.0,,,interactive exploration multivariate;edge graph layouts;semantic;air road traffic;deforming straight,0.5465;0.3906;0.2541;0.1793;0.1345,"[np.int64(-1), -1, -1, -1, -1]",93;-1;-1;-1;-1,93,93,Multivariate Data Visualization
Vis,2010,Interactive Visual Analysis of Multiple Simulation Runs Using the Simulation Model View: Understanding and Tuning of an Electronic Unit Injector,10.1109/tvcg.2010.171,http://dx.doi.org/10.1109/TVCG.2010.171,1449.0,1457.0,J,"Multiple simulation runs using the same simulation model with different values of control parameters generate a large data set that captures the behavior of the modeled phenomenon. However, there is a conceptual and visual gap between the simulation model behavior and the data set that makes data analysis more difficult. We propose a simulation model view that helps to bridge that gap by visually combining the simulation model description and the generated data. The simulation model view provides a visual outline of the simulation process and the corresponding simulation model. The view is integrated in a Coordinated Multiple Views; (CMV) system. As the simulation model view provides a limited display space, we use three levels of details. We explored the use of the simulation model view, in close collaboration with a domain expert, to understand and tune an electronic unit injector (EUI). We also developed analysis procedures based on the view. The EUI is mostly used in heavy duty Diesel engines. We were mainly interested in understanding the model and how to tune it for three different operation modes: low emission, low consumption, and high power. Very positive feedback from the domain expert shows that the use of the simulation model view and the corresponding ;analysis procedures within a CMV system represents an effective technique for interactive visual analysis of multiple simulation runs.",Kresimir Matkovic;Denis Gracanin;Mario Jelovic;Andreas Ammer;Alan Lez;Helwig Hauser,Kresimir Matkovic;Denis Gracanin;Mario Jelovic;Andreas Ammer;Alan Lez;Helwig Hauser,"VRVis Research Center Vienna, Austria;Virginia Technology, USA;AVL AST d.o.o., Zagreb, Croatia;VRVis Research Center Vienna, Austria;VRVis Research Center Vienna, Austria;University of Bergen, Norway",10.1109/tvcg.2009.155;10.1109/infvis.2002.1173149;10.1109/infvis.1995.528685;10.1109/infvis.2002.1173157;10.1109/tvcg.2009.155,"Visualization in physical sciences and engineering, time series data, coordinated multiple views",45.0,29.0,20.0,788.0,,,simulation model view;duty diesel engines;tune electronic unit;gap visually combining;set captures behavior,0.6296;0.3067;0.2505;0.1200;0.0232,"[np.int64(-1), -1, -1, -1, -1]",1;-1;-1;-1;-1,1,1,Simulation Modeling
Vis,1994,Mix&Match: a construction kit for visualization,10.1109/visual.1994.346305,http://dx.doi.org/10.1109/VISUAL.1994.346305,302.0,,C,"We present an environment in which users can interactively create different visualization methods. This modular and extensible environment encapsulates most of the existing visualization algorithms. Users can easily construct new visualization methods by combining simple, fine grain building blocks. These components operate on a local subset of the data and generally either look for target features or produce visual objects. Intermediate compositions may also be used to build more complex visualizations. This environment provides a foundation for building and exploring novel visualization methods.&lt;&lt;ETX&gt;&gt;",Alex Pang;Naim Alper,A. Pang;N. Alper,"Computer Engineering & Information Sciences, University of California, Santa Cruz, CA, USA;Computer Engineering & Information Sciences, University of California, Santa Cruz, CA, USA",10.1109/visual.1993.398860;10.1109/visual.1990.146373;10.1109/visual.1991.175804;10.1109/visual.1992.235207;10.1109/visual.1992.235219;10.1109/visual.1993.398880;10.1109/visual.1993.398879;10.1109/visual.1993.398860,,27.0,7.0,18.0,60.0,,,visualization methods modular;subset data;simple fine grain;environment provides foundation;target,0.7148;0.1699;0.1089;0.0743;0.0140,"[np.int64(-1), -1, -1, -1, -1]",138;-1;-1;-1;-1,138,138,Innovative Visualization Design
InfoVis,2004,Uncovering Clusters in Crowded Parallel Coordinates Visualizations,10.1109/infvis.2004.68,http://dx.doi.org/10.1109/INFVIS.2004.68,81.0,88.0,C,"The one-to-one strategy of mapping each single data item into a graphical marker adopted in many visualization techniques has limited usefulness when the number of records and/or the dimensionality of the data set are very high. In this situation, the strong overlapping of graphical markers severely hampers the user's ability to identify patterns in the data from its visual representation. We tackle this problem here with a strategy that computes frequency or density information from the data set, and uses such information in parallel coordinates visualizations to filter out the information to be presented to the user, thus reducing visual clutter and allowing the analyst to observe relevant patterns in the data. The algorithms to construct such visualizations, and the interaction mechanisms supported, inspired by traditional image processing techniques such as grayscale manipulation and thresholding are also presented. We also illustrate how such algorithms can assist users to effectively identify clusters in very noisy large data sets",Almir Olivette Artero;Maria Cristina Ferreira de Oliveira;Haim Levkowitz,A.O. Artero;M.C.F. de Oliveira;H. Levkowitz,"Department of Computer Science, University of São Paulo, Brazil;Department of Computer Science, University of São Paulo;Department of Computer Science, University of Massachusetts, USA",10.1109/visual.1994.346302;10.1109/visual.1994.346302,"information visualization, visual clustering, density-based visualization, visual data mining",238.0,75.0,17.0,931.0,,,data visual representation;clusters noisy large;grayscale manipulation thresholding;computes frequency density;marker adopted,0.6583;0.3963;0.3641;0.1732;0.0663,"[np.int64(-1), -1, -1, -1, -1]",97;-1;-1;-1;-1,97,97,Data Visualization
Vis,1993,Dichromatic color representations for complex display systems,10.1109/visual.1993.398871,http://dx.doi.org/10.1109/VISUAL.1993.398871,212.0,219.0,C,"New display technologies have begun to provide more innovative and potentially powerful methods to present information to a viewer. However, many of these techniques struggle to deliver accurate full color. In this paper, we address this difficulty by employing the dichromatic theory of color reflection, which implies that many objects can be rendered accurately using only two primaries. Complex display systems with two primaries can be produced with significantly less work than is required for the traditional three primaries. We discuss methods for selecting objects that can be rendered accurately on two-color displays, and we present our experiments with a two-color display using monochromatic primaries.&lt;&lt;ETX&gt;&gt;",Mark S. Peercy;Lambertus Hesselink,M.S. Peercy;L. Hesselink,"Department of Applied Physics, University of Stanford, Stanford, CA, USA;Department of Electrical Engineering, Department of Aeronautics and Astronautics, University of Stanford, Stanford, CA, USA",,,7.0,0.0,22.0,51.0,,,color displays;primaries complex;reflection implies objects;powerful methods;lt lt,0.6975;0.3143;0.2249;0.1374;0.0350,"[np.int64(-1), -1, -1, -1, -1]",30;-1;-1;-1;-1,30,30,Color Displays
Vis,2004,Force-Feedback-Enhanced Navigation for Interactive Visualization of Coronary Vessels,10.1109/visual.2004.33,http://dx.doi.org/10.1109/VISUAL.2004.33,32.0,32.0,M,"Coronary heart disease (CHD) is the number one killer in the United States. Although it is well known that CHD mainly occurs due to blocked arteries, there are contradictory results from studies designed to identify basic causes for this common disease is. To find out more about the true reason for CHD, virtual models can be employed to better understand the way the heart functions. With such a model, scientists and surgeons are able to analyze the effects of different treatment options, and ultimately find more suited ways to prevent coronary heart diseases. To investigate a given model, appropriate navigation methods are required, including suitable input devices. For the visualization, graphics cards originally designed for gaming applications are used; so, it is a just natural transition to adapt gaming input devices to a visualization system for controlling of the navigation. These devices are usually well designed with respect to ergonomics and durability, yielding more degrees of freedom in steering than two-dimensional input devices, such as desktop mice. This poster describes a visualization system that provides the user with advanced control devices for navigation enabling interactive exploration of the model. Force-feedback and sound effects provide additional cues.",Thomas Wischgoll;Elke Moritz;Jörg Meyer 0002,T. Wischgoll;E. Moritz;J. Meyer,"University of California, Irvine, USA;University of California, Irvine, USA;University of California, Irvine, USA",,,5.0,1.0,5.0,68.0,,,visualization controlling navigation;gaming input devices;heart disease chd;model force;results studies designed,0.5673;0.5008;0.2698;0.2626;0.1373,"[np.int64(-1), np.int64(-1), -1, -1, -1]",62;35;-1;-1;-1,35;62,62,Interactive Visualization Tools
VAST,2020,Visual Abstraction of Geographical Point Data with Spatial Autocorrelations,10.1109/vast50239.2020.00011,http://dx.doi.org/10.1109/VAST50239.2020.00011,60.0,71.0,C,"Scatterplots are always employed to visualize geographical point datasets, which often suffer from an overdraw problem due to the increase of data sizes. A variety of sampling strategies have been proposed to reduce overdraw and visual clutter with the spatial densities of points taken into account. However, informative attributes associated with the points also play significant roles in the exploration of geographical datasets. In this paper, we propose an attribute-based abstraction method to simplify the cluttered visualization of large-scale geographical points. Spatial autocorrelations are utilized to measure the attribute relationships of points in local areas, and a novel attribute-based sampling model is designed to generate a subset of points to preserve both density and attribute characteristics of original geographical points. A set of visual designs and user-friendly interactions are implemented, enabling users to capture the spatial distribution of geographical points and get deeper insights into the attribute features across local areas. Case studies and quantitative comparisons based on the real-world datasets further demonstrate the effectiveness of our method in the abstraction and exploration of large-scale geographical point datasets.",Zhiguang Zhou;Xinlong Zhang;Zhendong Yang;Yuanyuan Chen;Yuhua Liu;Jin Wen;Binjie Chen;Ying Zhao 0001;Wei Chen 0001,Zhiguang Zhou;Xinlong Zhang;Zhendong Yang;Yuanyuan Chen;Yuhua Liu;Jin Wen;Binjie Chen;Ying Zhao;Wei Chen,"School of Information, Zhejiang University of Finance and Economics and State Key Lab of CAD & CG, Zhejiang University;School of Information, Zhejiang University of Finance and Economics;School of Information, Zhejiang University of Finance and Economics;School of Information, Zhejiang University of Finance and Economics;School of Information, Zhejiang University of Finance and Economics;School of Information, Zhejiang University of Finance and Economics;School of Information, Zhejiang University of Finance and Economics;School of Computer Sciences and Engineering, Central South University;State Key Lab of CAD & CG, Zhejiang University",10.1109/tvcg.2008.119;10.1109/tvcg.2016.2598862;10.1109/tvcg.2014.2346594;10.1109/tvcg.2019.2934541;10.1109/tvcg.2006.161;10.1109/tvcg.2019.2934670;10.1109/tvcg.2008.175;10.1109/tvcg.2007.70535;10.1109/tvcg.2010.176;10.1109/tvcg.2019.2934799;10.1109/tvcg.2016.2598432;10.1109/tvcg.2016.2598831;10.1109/tvcg.2006.170;10.1109/tvcg.2010.180;10.1109/tvcg.2014.2346265;10.1109/tvcg.2014.2346746;10.1109/tvcg.2019.2934208;10.1109/tvcg.2017.2744098;10.1109/vast47406.2019.8986943;10.1109/tvcg.2018.2865020;10.1109/tvcg.2018.2864503;10.1109/tvcg.2008.119,"Visual Abstraction,Spatial Autocorrelation,Sampling,Geospatial Analysis",6.0,9.0,61.0,692.0,,,visualize geographical;point datasets suffer;attribute based abstraction;increase;autocorrelations utilized measure,0.6627;0.4242;0.3709;0.1019;0.0780,"[np.int64(-1), -1, -1, -1, -1]",89;-1;-1;-1;-1,89,89,Geographical Visualization
Vis,2003,Video visualization,10.1109/visual.2003.1250401,http://dx.doi.org/10.1109/VISUAL.2003.1250401,409.0,416.0,C,"Video data, generated by the entertainment industry, security and traffic cameras, video conferencing systems, video emails, and so on, is perhaps most time-consuming to process by human beings. In this paper, we present a novel methodology for ""summarizing"" video sequences using volume visualization techniques. We outline a system pipeline for capturing videos, extracting features, volume rendering video and feature data, and creating video visualization. We discuss a collection of image comparison metrics, including the linear dependence detector, for constructing ""relative"" and ""absolute"" difference volumes that represent the magnitude of variation between video frames. We describe the use of a few volume visualization techniques, including volume scene graphs and spatial transfer functions, for creating video visualization. In particular, we present a stream-based technique for processing and directly rendering video data in real time. With the aid of several examples, we demonstrate the effectiveness of using video visualization to convey meaningful information contained in video sequences.",Gareth Daniel;Min Chen 0001,G. Daniel;Min Chen,"University of Wales, UK;University of Wales, UK",10.1109/visual.2002.1183790;10.1109/visual.2002.1183790," Video visualization, volume rendering, video surveillance, change detection, image-swept volume",137.0,59.0,25.0,536.0,,,video visualization;extracting features volume;industry security traffic;difference;including,0.7539;0.3731;0.1966;0.0778;0.0663,"[np.int64(-1), -1, -1, -1, -1]",71;-1;-1;-1;-1,71,71,Video Visualization
VAST,2008,Crystal structures classifier for an evolutionary algorithm structure predictor,10.1109/vast.2008.4677351,http://dx.doi.org/10.1109/VAST.2008.4677351,11.0,18.0,C,"USPEX is a crystal structure predictor based on an evolutionary algorithm. Every USPEX run produces hundreds or thousands of crystal structures, some of which may be identical. To ease the extraction of unique and potentially interesting structures we applied usual high-dimensional classification concepts to the unusual field of crystallography. We experimented with various crystal structure descriptors, distinct distance measures and tried different clustering methods to identify groups of similar structures. These methods are already applied in combinatorial chemistry to organic molecules for a different goal and in somewhat different forms, but are not widely used for crystal structures classification. We adopted a visual design and validation method in the development of a library (CrystalFp) and an end-user application to select and validate method choices, to gain userspsila acceptance and to tap into their domain expertise. The use of the classifier has already accelerated the analysis of USPEX output by at least one order of magnitude, promoting some new crystallographic insight and discovery. Furthermore the visual display of key algorithm indicators has led to diverse, unexpected discoveries that will improve the USPEX algorithms.",Mario Valle;Artem R. Oganov,Mario Valle;Artem R. Oganov,"Data Analysis and Visualization Services, Swiss National Supercomputing Centre, Switzerland;Laboratory of Crystallography, Department of Materials, ETH Zürich",,,16.0,6.0,31.0,544.0,,,crystal structure predictor;improve uspex;adopted visual;application select validate;thousands,0.6913;0.2876;0.1762;0.0217;-0.0400,"[np.int64(-1), -1, -1, -1, -1]",41;-1;-1;-1;-1,41,41,Protein Structure Design
SciVis,2015,Streamline Variability Plots for Characterizing the Uncertainty in Vector Field Ensembles,10.1109/tvcg.2015.2467204,http://dx.doi.org/10.1109/TVCG.2015.2467204,767.0,776.0,J,"We present a new method to visualize from an ensemble of flow fields the statistical properties of streamlines passing through a selected location. We use principal component analysis to transform the set of streamlines into a low-dimensional Euclidean space. In this space the streamlines are clustered into major trends, and each cluster is in turn approximated by a multivariate Gaussian distribution. This yields a probabilistic mixture model for the streamline distribution, from which confidence regions can be derived in which the streamlines are most likely to reside. This is achieved by transforming the Gaussian random distributions from the low-dimensional Euclidean space into a streamline distribution that follows the statistical model, and by visualizing confidence regions in this distribution via iso-contours. We further make use of the principal component representation to introduce a new concept of streamline-median, based on existing median concepts in multidimensional Euclidean spaces. We demonstrate the potential of our method in a number of real-world examples, and we compare our results to alternative clustering approaches for particle trajectories as well as curve boxplots.",Florian Ferstl;Kai Bürger;Rüdiger Westermann,Florian Ferstl;Kai Bürger;Rüdiger Westermann,"Computer Graphics and Visualization Group, Technische Universität München;Computer Graphics and Visualization Group, Technische Universität München;Computer Graphics and Visualization Group, Technische Universität München",10.1109/tvcg.2007.70595;10.1109/visual.2000.885715;10.1109/visual.1999.809863;10.1109/tvcg.2013.141;10.1109/tvcg.2007.70518;10.1109/tvcg.2014.2346455;10.1109/visual.2005.1532779;10.1109/tvcg.2010.181;10.1109/visual.1999.809865;10.1109/tvcg.2013.143;10.1109/tvcg.2007.70595,"Ensemble visualization, uncertainty visualization, flow visualization, streamlines, statistical modeling",109.0,83.0,50.0,1788.0,,,flow fields statistical;alternative clustering approaches;based existing median;euclidean spaces demonstrate;component,0.6407;0.3505;0.2823;0.1298;0.1010,"[np.int64(-1), -1, -1, -1, -1]",20;-1;-1;-1;-1,20,20,Particle Flow Analysis
Vis,1999,Progressive compression and transmission of arbitrary triangular meshes,10.1109/visual.1999.809902,http://dx.doi.org/10.1109/VISUAL.1999.809902,307.0,537.0,C,"The recent growth in the size and availability of large triangular surface models has generated interest in compact multi-resolution progressive representation and data transmission. An ongoing challenge is to design an efficient data structure that encompasses both compactness of geometric representations and visual quality of progressive representations. We introduce a topological layering based data structure and an encoding scheme to build a compact progressive representation of an arbitrary triangular mesh (a 2D simplicial complex in 3D) with attached attribute data. This compact representation is composed of multiple levels of detail that can be progressively transmitted and displayed. The global topology, which is the number of holes and connected components, can be flexibly changed among successive levels while still achieving guaranteed size of the coarsest level mesh for very complex models. The flexibility in our encoding scheme also allows topology preserving progressivity.",Chandrajit L. Bajaj;Valerio Pascucci;Guozhong Zhuang,C.L. Bajaj;V. Pascucci;G. Zhuang,"Department of Computer Sciences, University of Technology, Austin, TX, USA;Department of Computer Sciences, University of Technology, Austin, TX, USA;Department of Computer Sciences, University of Technology, Austin, TX, USA",10.1109/visual.1998.745283;10.1109/visual.1997.663883;10.1109/visual.1998.745283,,133.0,36.0,26.0,93.0,,,mesh 2d simplicial;quality progressive representations;structure encompasses compactness;attached attribute data;size coarsest level,0.6051;0.3744;0.2548;0.1722;0.1069,"[np.int64(-1), -1, -1, -1, -1]",79;-1;-1;-1;-1,79,79,Mesh Simplification Techniques
InfoVis,2020,Data Visceralization: Enabling Deeper Understanding of Data Using Virtual Reality,10.1109/tvcg.2020.3030435,http://dx.doi.org/10.1109/TVCG.2020.3030435,1095.0,1105.0,J,"A fundamental part of data visualization is transforming data to map abstract information onto visual attributes. While this abstraction is a powerful basis for data visualization, the connection between the representation and the original underlying data (i.e., what the quantities and measurements actually correspond with in reality) can be lost. On the other hand, virtual reality (VR) is being increasingly used to represent real and abstract models as natural experiences to users. In this work, we explore the potential of using VR to help restore the basic understanding of units and measures that are often abstracted away in data visualization in an approach we call data visceralization. By building VR prototypes as design probes, we identify key themes and factors for data visceralization. We do this first through a critical reflection by the authors, then by involving external participants. We find that data visceralization is an engaging way of understanding the qualitative aspects of physical measures and their real-life form, which complements analytical and quantitative understanding commonly gained from data visualization. However, data visceralization is most effective when there is a one-to-one mapping between data and representation, with transformations such as scaling affecting this understanding. We conclude with a discussion of future directions for data visceralization.",Benjamin Lee;Dave Brown;Bongshin Lee;Christophe Hurter;Steven Mark Drucker;Tim Dwyer,Benjamin Lee;Dave Brown;Bongshin Lee;Christophe Hurter;Steven Drucker;Tim Dwyer,"Monash University;Microsoft Research;Microsoft Research;ENAC, French Civil Aviation University;Microsoft Research;Monash University",10.1109/tvcg.2013.210;10.1109/infvis.1998.729560;10.1109/tvcg.2018.2865237;10.1109/tvcg.2010.179;10.1109/tvcg.2016.2598498;10.1109/visual.2001.964545;10.1109/tvcg.2013.210,"Data visceralization,virtual reality,exploratory study",28.0,40.0,59.0,2240.0,HM,,visualization data visceralization;reality vr increasingly;basic understanding units;critical reflection;restore basic,0.6203;0.4338;0.2924;0.2043;-0.0133,"[np.int64(-1), -1, -1, -1, -1]",146;-1;-1;-1;-1,146,146,Visualization Techniques
Vis,2000,An integrated visualization and design toolkit for flexible prosthetic heart valves,10.1109/visual.2000.885730,http://dx.doi.org/10.1109/VISUAL.2000.885730,453.0,456.0,C,"We describe a toolkit for the design and visualization of flexible artificial heart valves. The toolkit consists of interlinked modules with a visual programming interface. The user of the toolkit can set the initial geometry and material properties of the valve leaflet, solve for the flexing of the leaflet and the flow of blood around it, and display the results using the visualization capabilities of the toolkit. The interactive nature of our environment is highlighted by the fact that changes in leaflet properties are immediately reflected in the flow field and response of the leaflet. Hence the user may, in a single session, investigate a broad range of designs, each one of which provides important information about the blood flow and motion of the valve during the cardiac cycle.",A. J. Fenlon;Tim David;J. P. R. B. Walton,A.J. Fenlon;T. David;J.P.R.B. Walton,"Numerical Algorithms Group (NAG) Limited, Oxford, UK;School of Mechanical Engineering, University of Leeds, Leeds, UK;School of Mechanical Engineering, University of Leeds, Leeds, UK",,"Computational fluid dynamics, interactive design, prosthetic heart valves, visualization systems",10.0,0.0,20.0,59.0,,,flexible artificial heart;toolkit design visualization;important information blood;leaflet properties immediately;single,0.7274;0.3565;0.1912;0.1353;-0.0607,"[np.int64(-1), -1, -1, -1, -1]",-1;-1;-1;-1;-1,,-1,Interactive 3D Visualization
Vis,2003,Interactive protein manipulation,10.1109/visual.2003.1250423,http://dx.doi.org/10.1109/VISUAL.2003.1250423,581.0,588.0,C,"We describe an interactive visualization and modeling program for the creation of protein structures ""from scratch."" The input to our program is an amino acid sequence - decoded from a gene - and a sequence of predicted secondary structure types for each amino acid - provided by external structure prediction programs. Our program can be used in the set-up phase of a protein structure prediction process; the structures created with it serve as input for a subsequent global internal energy minimization, or another method of protein structure prediction. Our program supports basic visualization methods for protein structures, interactive manipulation based on inverse kinematics, and visualization guides to aid a user in creating ""good"" initial structures.",Oliver Kreylos;Nelson L. Max;Bernd Hamann;Silvia N. Crivelli;E. Wes Bethel,O. Kreylos;N.L. Max;B. Hamann;S.N. Crivelli;E. Wes Bethel,"Center for Image Processing and Integrated Computing, Department of Computer Science, University of California, Davis, CA, USA;Lawrence Berkeley National Laboratory, Berkeley, CA, USA and Center for Image Processing and Integrated Computing, Department of Computer Science, University of California, Davis, CA, USA;Lawrence Berkeley National Laboratory, Berkeley, CA, USA and Center for Image Processing and Integrated Computing, Department of Computer Science, University of California, Davis, CA, USA;Lawrence Berkeley National Laboratory, Berkeley, CA, USA;Lawrence Berkeley National Laboratory, Berkeley, CA, USA",,"Protein Structure Prediction, Protein Manipulation, Inverse Kinematics, Molecular Modeling, Molecular Visualization, Interactive Visualization, Computational Science",31.0,7.0,14.0,101.0,BA,,protein structures interactive;based inverse kinematics;prediction process;global internal energy;supports basic,0.7505;0.1914;0.1754;0.0791;0.0458,"[np.int64(-1), -1, -1, -1, -1]",46;-1;-1;-1;-1,46,46,Interactive Molecular Visualization
InfoVis,1996,Visage: a user interface environment for exploring information,10.1109/infvis.1996.559210,http://dx.doi.org/10.1109/INFVIS.1996.559210,3.0,,C,"Visage is a prototype user interface environment for exploring and analyzing information. It represents an approach to coordinating multiple visualizations, analysis and presentation tools in data-intensive domains. Visage is based on an information-centric approach to user interface design which strives to eliminate impediments to direct user access to information objects across applications and visualizations. Visage consists of a set of data manipulation operations, an intelligent system for generating a wide variety of data visualizations (SAGE) and a briefing tool that supports the conversion of visual displays used during exploration into interactive presentation slides. This paper presents the user interface components and styles of interaction that are central to Visage's information-centric approach.",Steven F. Roth;Peter Lucas 0002;Jeffrey Senn;Cristina C. Gomberg;Michael B. Burks;Philip J. Stroffolino;John A. Kolojechick;Carolyn Dunmire,S.F. Roth;P. Lucas;J.A. Senn;C.C. Gomberg;M.B. Burks;P.J. Stroffolino;A.J. Kolojechick;C. Dunmire,"School of Computer Science, Carnegie Mellon University, Pittsburgh, PA, USA and Aberdeen Proving Ground, Army Research Laboratory, MD, USA;School of Computer Science, Carnegie Mellon University, Pittsburgh, PA, USA and Aberdeen Proving Ground, Army Research Laboratory, MD, USA;School of Computer Science, Carnegie Mellon University, Pittsburgh, PA, USA and Aberdeen Proving Ground, Army Research Laboratory, MD, USA;School of Computer Science, Carnegie Mellon University, Pittsburgh, PA, USA and Aberdeen Proving Ground, Army Research Laboratory, MD, USA;School of Computer Science, Carnegie Mellon University, Pittsburgh, PA, USA and Aberdeen Proving Ground, Army Research Laboratory, MD, USA;School of Computer Science, Carnegie Mellon University, Pittsburgh, PA, USA and Aberdeen Proving Ground, Army Research Laboratory, MD, USA;;School of Computer Science, Carnegie Mellon University, Pittsburgh, PA, USA and Aberdeen Proving Ground, Army Research Laboratory, MD, USA",10.1109/visual.1993.398870;10.1109/visual.1991.175815;10.1109/visual.1993.398870,"Visualization, exploratory data analysis, graphics, user interface environment, human-computer interaction",213.0,43.0,13.0,345.0,TT,,data visualizations;components styles interaction;paper presents user;domains visage based;eliminate impediments direct,0.6749;0.2315;0.1811;0.1766;0.0805,"[np.int64(-1), -1, -1, -1, -1]",97;-1;-1;-1;-1,97,97,Data Visualization
Vis,2009,Structuring Feature Space: A Non-Parametric Method for Volumetric Transfer Function Generation,10.1109/tvcg.2009.185,http://dx.doi.org/10.1109/TVCG.2009.185,1473.0,1480.0,J,"The use of multi-dimensional transfer functions for direct volume rendering has been shown to be an effective means of extracting materials and their boundaries for both scalar and multivariate data. The most common multi-dimensional transfer function consists of a two-dimensional (2D) histogram with axes representing a subset of the feature space (e.g., value vs. value gradient magnitude), with each entry in the 2D histogram being the number of voxels at a given feature space pair. Users then assign color and opacity to the voxel distributions within the given feature space through the use of interactive widgets (e.g., box, circular, triangular selection). Unfortunately, such tools lead users through a trial-and-error approach as they assess which data values within the feature space map to a given area of interest within the volumetric space. In this work, we propose the addition of non-parametric clustering within the transfer function feature space in order to extract patterns and guide transfer function generation. We apply a non-parametric kernel density estimation to group voxels of similar features within the 2D histogram. These groups are then binned and colored based on their estimated density, and the user may interactively grow and shrink the binned regions to explore feature boundaries and extract regions of interest. We also extend this scheme to temporal volumetric data in which time steps of 2D histograms are composited into a histogram volume. A three-dimensional (3D) density estimation is then applied, and users can explore regions within the feature space across time without adjusting the transfer function at each time step. Our work enables users to effectively explore the structures found within a feature space of the volume and provide a context in which the user can understand how these structures relate to their volumetric data. We provide tools for enhanced exploration and manipulation of the transfer function, and we show that the initial transfer function generation serves as a reasonable base for volumetric rendering, reducing the trial-and-error overhead typically found in transfer function design.",Ross Maciejewski;Insoo Woo;Wei Chen 0001;David S. Ebert,Ross Maciejewski;Insoo Woo;Wei Chen;David Ebert,"Rendering and Perceptualization Laboratory, Purdue University, USA;Rendering and Perceptualization Laboratory, Purdue University, USA;State Key Laboratory of CAD&CG, University of Zhejiang, China;Rendering and Perceptualization Laboratory, Purdue University, USA",10.1109/tvcg.2008.119;10.1109/visual.1998.745319;10.1109/visual.2003.1250414;10.1109/visual.2003.1250371;10.1109/visual.2005.1532807;10.1109/tvcg.2008.162;10.1109/visual.2001.964519;10.1109/visual.2003.1250413;10.1109/visual.2005.1532858;10.1109/tvcg.2006.148;10.1109/tvcg.2008.119,"Volume rendering, kernel density estimation, transfer function design, temporal volume rendering",132.0,77.0,29.0,955.0,,,volumetric rendering;histograms composited histogram;extract patterns guide;users assign color;function time,0.6278;0.2444;0.2374;0.1828;0.0540,"[np.int64(-1), -1, -1, -1, -1]",52;-1;-1;-1;-1,52,52,Volume Rendering Techniques
InfoVis,2017,Stable Treemaps via Local Moves,10.1109/tvcg.2017.2745140,http://dx.doi.org/10.1109/TVCG.2017.2745140,729.0,738.0,J,"Treemaps are a popular tool to visualize hierarchical data: items are represented by nested rectangles and the area of each rectangle corresponds to the data being visualized for this item. The visual quality of a treemap is commonly measured via the aspect ratio of the rectangles. If the data changes, then a second important quality criterion is the stability of the treemap: how much does the treemap change as the data changes. We present a novel stable treemapping algorithm that has very high visual quality. Whereas existing treemapping algorithms generally recompute the treemap every time the input changes, our algorithm changes the layout of the treemap using only local modifications. This approach not only gives us direct control over stability, but it also allows us to use a larger set of possible layouts, thus provably resulting in treemaps of higher visual quality compared to existing algorithms. We further prove that we can reach all possible treemap layouts using only our local modifications. Furthermore, we introduce a new measure for stability that better captures the relative positions of rectangles. We finally show via experiments on real-world data that our algorithm outperforms existing treemapping algorithms also in practice on either visual quality and/or stability. Our algorithm scores high on stability regardless of whether we use an existing stability measure or our new measure.",Max Sondag;Bettina Speckmann;Kevin Verbeek,Max Sondag;Bettina Speckmann;Kevin Verbeek,TU Eindhoven;TU Eindhoven;TU Eindhoven,10.1109/infvis.2001.963283;10.1109/tvcg.2007.70529;10.1109/infvis.2005.1532145;10.1109/infvis.2001.963283,"Treemap,Stability,Local Moves",45.0,28.0,20.0,1269.0,,,treemaps;change data;aspect ratio;commonly;direct control stability,0.7471;0.1225;0.1108;0.0801;0.0080,"[np.int64(-1), -1, -1, -1, -1]",56;-1;-1;-1;-1,56,56,Treemap Visualization
Vis,2022,Unifying Effects of Direct and Relational Associations for Visual Communication,10.1109/tvcg.2022.3209443,http://dx.doi.org/10.1109/TVCG.2022.3209443,385.0,395.0,J,"People have expectations about how colors map to concepts in visualizations, and they are better at interpreting visualizations that match their expectations. Traditionally, studies on these expectations (inferred mappings) distinguished distinct factors relevant for visualizations of categorical vs. continuous information. Studies on categorical information focused on direct associations (e.g., mangos are associated with yellows) whereas studies on continuous information focused on relational associations (e.g., darker colors map to larger quantities; dark-is-more bias). We unite these two areas within a single framework of assignment inference. Assignment inference is the process by which people infer mappings between perceptual features and concepts represented in encoding systems. Observers infer globally optimal assignments by maximizing the “merit,” or “goodness,” of each possible assignment. Previous work on assignment inference focused on visualizations of categorical information. We extend this approach to visualizations of continuous data by (a) broadening the notion of merit to include relational associations and (b) developing a method for combining multiple (sometimes conflicting) sources of merit to predict people's inferred mappings. We developed and tested our model on data from experiments in which participants interpreted colormap data visualizations, representing fictitious data about environmental concepts (sunshine, shade, wild fire, ocean water, glacial ice). We found both direct and relational associations contribute independently to inferred mappings. These results can be used to optimize visualization design to facilitate visual communication.",Melissa A. Schoenlein;Johnny Campos;Kevin J. Lande;Laurent Lessard;Karen B. Schloss,Melissa A. Schoenlein;Johnny Campos;Kevin J. Lande;Laurent Lessard;Karen B. Schloss,"Psychology and Wisconsin Institute for Discovery, University of Wisconsin-Madison, USA;Cognitive Science, University of California, Merced, USA;Philosophy, Centre for Vision Research, York University, USA;Mechanical and Industrial Engineering, Northeastern University, USA;Psychology, Wisconsin Institute for Discovery, University of Wisconsin-Madison, USA",10.1109/tvcg.2017.2743978;10.1109/tvcg.2016.2598918;10.1109/visual.2002.1183788;10.1109/tvcg.2021.3114780;10.1109/tvcg.2016.2599106;10.1109/tvcg.2019.2934536;10.1109/tvcg.2018.2865147;10.1109/tvcg.2020.3030434;10.1109/tvcg.2015.2467471;10.1109/tvcg.2019.2934284;10.1109/tvcg.2017.2744359;10.1109/tvcg.2017.2743978,"Visual reasoning,information visualization,colormap data visualizations,visual encoding,color cognition",,7.0,53.0,486.0,,,participants interpreted colormap;mangos associated;merit goodness possible;glacial ice direct;single framework,0.6353;0.1751;0.1550;0.0666;-0.0661,"[np.int64(-1), -1, -1, -1, -1]",29;-1;-1;-1;-1,29,29,Colormap Interpretation
InfoVis,2012,Interaction Support for Visual Comparison Inspired by Natural Behavior,10.1109/tvcg.2012.237,http://dx.doi.org/10.1109/TVCG.2012.237,2719.0,2728.0,J,"Visual comparison is an intrinsic part of interactive data exploration and analysis. The literature provides a large body of existing solutions that help users accomplish comparison tasks. These solutions are mostly of visual nature and custom-made for specific data. We ask the question if a more general support is possible by focusing on the interaction aspect of comparison tasks. As an answer to this question, we propose a novel interaction concept that is inspired by real-world behavior of people comparing information printed on paper. In line with real-world interaction, our approach supports users (1) in interactively specifying pieces of graphical information to be compared, (2) in flexibly arranging these pieces on the screen, and (3) in performing the actual comparison of side-by-side and overlapping arrangements of the graphical information. Complementary visual cues and add-ons further assist users in carrying out comparison tasks. Our concept and the integrated interaction techniques are generally applicable and can be coupled with different visualization techniques. We implemented an interactive prototype and conducted a qualitative user study to assess the concept's usefulness in the context of three different visualization techniques. The obtained feedback indicates that our interaction techniques mimic the natural behavior quite well, can be learned quickly, and are easy to apply to visual comparison tasks.",Christian Tominski;Camilla Forsell;Jimmy Johansson 0001,Christian Tominski;Camilla Forsell;Jimmy Johansson,"University of Rostock, Germany;Linköping University, Sweden;Linköping University, Sweden",10.1109/tvcg.2008.109;10.1109/tvcg.2007.70568;10.1109/tvcg.2011.201;10.1109/tvcg.2007.70515;10.1109/tvcg.2007.70623;10.1109/tvcg.2009.151;10.1109/infvis.2002.1173157;10.1109/tvcg.2011.223;10.1109/tvcg.2007.70582;10.1109/tvcg.2008.153;10.1109/tvcg.2008.109,"Interaction techniques, visual comparison, visualization, human-computer interaction, natural interaction",68.0,46.0,51.0,1235.0,,,graphical information compared;qualitative user study;add ons assist;printed paper;propose,0.7270;0.2900;0.1780;0.1388;0.0453,"[np.int64(-1), -1, -1, -1, -1]",101;-1;-1;-1;-1,101,101,Comparative Visualization
InfoVis,2011,Evaluation of Artery Visualizations for Heart Disease Diagnosis,10.1109/tvcg.2011.192,http://dx.doi.org/10.1109/TVCG.2011.192,2479.0,2488.0,J,"Heart disease is the number one killer in the United States, and finding indicators of the disease at an early stage is critical for treatment and prevention. In this paper we evaluate visualization techniques that enable the diagnosis of coronary artery disease. A key physical quantity of medical interest is endothelial shear stress (ESS). Low ESS has been associated with sites of lesion formation and rapid progression of disease in the coronary arteries. Having effective visualizations of a patient's ESS data is vital for the quick and thorough non-invasive evaluation by a cardiologist. We present a task taxonomy for hemodynamics based on a formative user study with domain experts. Based on the results of this study we developed HemoVis, an interactive visualization application for heart disease diagnosis that uses a novel 2D tree diagram representation of coronary artery trees. We present the results of a formal quantitative user study with domain experts that evaluates the effect of 2D versus 3D artery representations and of color maps on identifying regions of low ESS. We show statistically significant results demonstrating that our 2D visualizations are more accurate and efficient than 3D representations, and that a perceptually appropriate color map leads to fewer diagnostic mistakes than a rainbow color map.",Michelle Borkin;Krzysztof Gajos;Amanda Peters Randles;Dimitrios Mitsouras;Simone Melchionna;Frank J. Rybicki;Charles L. Feldman;Hanspeter Pfister,Michelle Borkin;Krzysztof Gajos;Amanda Peters;Dimitrios Mitsouras;Simone Melchionna;Frank Rybicki;Charles Feldman;Hanspeter Pfister,"School of Engineering & Applied Sciences, Harvard University, USA;School of Engineering & Applied Sciences, Harvard University, USA;School of Engineering & Applied Sciences, Harvard University, USA;Applied Imaging Science Laboratory, USA;IPCF-CNR, Consiglio Nazionale delle Ricerche, Italy;Applied Imaging Science Laboratory, USA;Vascular Profiling Laboratory, Brigham and Women's Hospital and Harvard Medical School, USA;School of Engineering & Applied Sciences, Harvard University, USA",10.1109/tvcg.2009.169;10.1109/visual.2002.1183788;10.1109/visual.2002.1183754;10.1109/visual.2001.964510;10.1109/visual.2004.104;10.1109/tvcg.2006.172;10.1109/infvis.2005.1532136;10.1109/tvcg.2009.126;10.1109/visual.2001.964538;10.1109/tvcg.2009.126;10.1109/visual.1992.235201;10.1109/visual.1996.568118;10.1109/visual.2000.885731;10.1109/tvcg.2007.70550;10.1109/tvcg.2007.70596;10.1109/tvcg.2009.169,"Quantitative evaluation, qualitative evaluation, biomedical and medical visualization",192.0,124.0,52.0,2888.0,,,3d artery representations;user study;shear stress;rapid progression disease;mistakes rainbow,0.5945;0.2594;0.2162;0.1385;0.1040,"[np.int64(-1), -1, -1, -1, -1]",38;-1;-1;-1;-1,38,38,3D Medical Visualization
InfoVis,1996,Towards rich information landscapes for visualising structured Web spaces,10.1109/infvis.1996.559218,http://dx.doi.org/10.1109/INFVIS.1996.559218,62.0,,M,"The Harmony browser for the Hyper-G Web server utilises Hyper-G's rich data model to provide a number of tightly-coupled, two- and three-dimensional visualisation and navigational facilities. In particular the Harmony Information Landscape visualises the hierarchical structure of Hyper-G spaces upon a plane in three-dimensional space. The Harmony Information Landscape has now been extended to display a combined structure and link map by selectively superimposing hyperlink relationships in the vertical dimension above and below the hierarchy map. In addition, documents returned by search queries may be selectively ""plotted"" in the landscape, indicating their whereabouts in a broader context, and several sets of 3D icons are available for representing the various document types.",Keith Andrews;Michael Pichler;Peter Wolf,K. Andrews;M. Pichler;P. Wolf,"Institute for Information Processing and Computer Supported New Media, Graz University of Technology, Graz, Austria;Institute for Information Processing and Computer Supported New Media, Graz University of Technology, Graz, Austria;Institute for Information Processing and Computer Supported New Media, Graz University of Technology, Graz, Austria",0.1109/infvis.1995.528692,,32.0,6.0,6.0,102.0,,,harmony information landscape;sets 3d icons;superimposing hyperlink;web server utilises;selectively plotted,0.6017;0.2642;0.2466;0.1735;0.0681,"[np.int64(-1), -1, -1, -1, -1]",146;-1;-1;-1;-1,146,146,Visualization Techniques
InfoVis,2003,Edgelens: an interactive method for managing edge congestion in graphs,10.1109/infvis.2003.1249008,http://dx.doi.org/10.1109/INFVIS.2003.1249008,51.0,58.0,C,"An increasing number of tasks require people to explore, navigate and search extremely complex data sets visualized as graphs. Examples include electrical and telecommunication networks, Web structures, and airline routes. The problem is that graphs of these real world data sets have many interconnected nodes, ultimately leading to edge congestion: the density of edges is so great that they obscure nodes, individual edges, and even the visual information beneath the graph. To address this problem we developed an interactive technique called EdgeLens. An EdgeLens interactively curves graph edges away for a person's focus attention without changing the node positions. This opens up sufficient space to disambiguate node and edge relationships and to see underlying information while still preserving node layout. Initially two methods of creating this interaction were developed and compared in a user study. The results of this study were used in the selection of a basic approach and the subsequent development of the EdgeLens. We then improved the EdgeLens through use of transparency and colour and by allowing multiple lenses to appear on the graph.",Nelson Wong;Sheelagh Carpendale;Saul Greenberg,N. Wong;S. Carpendale;S. Greenberg,"Department of Computer Science, University of Calgary, Canada;Department of Computer Science, University of Calgary, Canada;Department of Computer Science, University of Calgary, Canada",10.1109/infvis.1997.636786;10.1109/infvis.1996.559214," Navigation, graph layout, distortion lens, information visualization, edge congestion, interactive visualization",205.0,56.0,22.0,955.0,,,visualized graphs;edgelens use transparency;navigate search extremely;subsequent development;individual,0.6426;0.2891;0.2781;0.0900;-0.0046,"[np.int64(-1), -1, -1, -1, -1]",96;-1;-1;-1;-1,96,96,Graph Visualization
InfoVis,2010,Untangling Euler Diagrams,10.1109/tvcg.2010.210,http://dx.doi.org/10.1109/TVCG.2010.210,1090.0,1099.0,J,"In many common data analysis scenarios the data elements are logically grouped into sets. Venn and Euler style diagrams are a common visual representation of such set membership where the data elements are represented by labels or glyphs and sets are indicated by boundaries surrounding their members. Generating such diagrams automatically such that set regions do not intersect unless the corresponding sets have a non-empty intersection is a difficult problem. Further, it may be impossible in some cases if regions are required to be continuous and convex. Several approaches exist to draw such set regions using more complex shapes, however, the resulting diagrams can be difficult to interpret. In this paper we present two novel approaches for simplifying a complex collection of intersecting sets into a strict hierarchy that can be more easily automatically arranged and drawn (Figure 1). In the first approach, we use compact rectangular shapes for drawing each set, attempting to improve the readability of the set intersections. In the second approach, we avoid drawing intersecting set regions by duplicating elements belonging to multiple sets. We compared both of our techniques to the traditional non-convex region technique using five readability tasks. Our results show that the compact rectangular shapes technique was often preferred by experimental subjects even though the use of duplications dramatically improves the accuracy and performance time for most of our tasks. In addition to general set representation our techniques are also applicable to visualization of networks with intersecting clusters of nodes.",Nathalie Henry Riche;Tim Dwyer,Nathalie Henry Riche;Tim Dwyer,"Microsoft Research Limited, USA;Microsoft Corporation, USA",10.1109/tvcg.2008.144;10.1109/tvcg.2007.70582;10.1109/infvis.2005.1532126;10.1109/tvcg.2008.141;10.1109/tvcg.2009.122;10.1109/tvcg.2006.156;10.1109/tvcg.2006.120;10.1109/tvcg.2008.130;10.1109/tvcg.2006.166;10.1109/visual.1993.398863;10.1109/tvcg.2008.153;10.1109/tvcg.2008.144,"Information Visualization, Euler diagrams, Set Visualization, Graph Visualization",182.0,106.0,33.0,1414.0,,,readability set intersections;generating diagrams automatically;clusters nodes;compared techniques traditional;required continuous convex,0.6017;0.4569;0.2949;0.1548;-0.0412,"[np.int64(-1), -1, -1, -1, -1]",145;-1;-1;-1;-1,145,145,Data Visualization Techniques
InfoVis,2012,Sketchy Rendering for Information Visualization,10.1109/tvcg.2012.262,http://dx.doi.org/10.1109/TVCG.2012.262,2749.0,2758.0,J,"We present and evaluate a framework for constructing sketchy style information visualizations that mimic data graphics drawn by hand. We provide an alternative renderer for the Processing graphics environment that redefines core drawing primitives including line, polygon and ellipse rendering. These primitives allow higher-level graphical features such as bar charts, line charts, treemaps and node-link diagrams to be drawn in a sketchy style with a specified degree of sketchiness. The framework is designed to be easily integrated into existing visualization implementations with minimal programming modification or design effort. We show examples of use for statistical graphics, conveying spatial imprecision and for enhancing aesthetic and narrative qualities of visualization. We evaluate user perception of sketchiness of areal features through a series of stimulus-response tests in order to assess users' ability to place sketchiness on a ratio scale, and to estimate area. Results suggest relative area judgment is compromised by sketchy rendering and that its influence is dependent on the shape being rendered. They show that degree of sketchiness may be judged on an ordinal scale but that its judgement varies strongly between individuals. We evaluate higher-level impacts of sketchiness through user testing of scenarios that encourage user engagement with data visualization and willingness to critique visualization design. Results suggest that where a visualization is clearly sketchy, engagement may be increased and that attitudes to participating in visualization annotation are more positive. The results of our work have implications for effective information visualization design that go beyond the traditional role of sketching as a tool for prototyping or its use for an indication of general uncertainty.",Jo Wood;Petra Isenberg;Tobias Isenberg 0001;Jason Dykes;Nadia Boukhelifa;Aidan Slingsby,Jo Wood;Petra Isenberg;Tobias Isenberg;Jason Dykes;Nadia Boukhelifa;Aidan Slingsby,"GiCentre, City University of London, UK;INRIA, Paris, France;University of Groningen, Netherlands;GiCentre, City University of London, UK;INRIA, Paris, France;GiCentre, City University of London, UK",10.1109/tvcg.2010.186;10.1109/tvcg.2011.175;10.1109/tvcg.2012.220;10.1109/tvcg.2011.251;10.1109/tvcg.2011.209;10.1109/tvcg.2011.255;10.1109/tvcg.2010.186,"NPR, non-photorealistic rendering, sketch, hand-drawn, uncertainty, visualization",101.0,58.0,47.0,1698.0,,,information visualizations;graphics environment redefines;judgement varies strongly;including line polygon;sketchy engagement,0.7036;0.1944;0.1750;0.1295;0.0762,"[np.int64(-1), -1, -1, -1, -1]",98;-1;-1;-1;-1,98,98,Information Visualization
InfoVis,2008,Stacked Graphs - Geometry & Aesthetics,10.1109/tvcg.2008.166,http://dx.doi.org/10.1109/TVCG.2008.166,1245.0,1252.0,J,"In February 2008, the New York Times published an unusual chart of box office revenues for 7500 movies over 21 years. The chart was based on a similar visualization, developed by the first author, that displayed trends in music listening. This paper describes the design decisions and algorithms behind these graphics, and discusses the reaction on the Web. We suggest that this type of complex layered graph is effective for displaying large data sets to a mass audience. We provide a mathematical analysis of how this layered graph relates to traditional stacked graphs and to techniques such as ThemeRiver, showing how each method is optimizing a different ldquoenergy functionrdquo. Finally, we discuss techniques for coloring and ordering the layers of such graphs. Throughout the paper, we emphasize the interplay between considerations of aesthetics and legibility.",Lee Byron;Martin Wattenberg,Lee Byron;Martin Wattenberg,The New York Times;Visual Communication Laboratory at IBM,10.1109/tvcg.2006.163;10.1109/infvis.2005.1532122;10.1109/tvcg.2007.70577;10.1109/infvis.2000.885098;10.1109/tvcg.2006.163,"Streamgraph, ThemeRiver, listening history, lastfm, aesthetics, communication-minded visualization, time series",557.0,257.0,19.0,3104.0,HM,,graphs techniques themeriver;revenues;type complex layered;listening paper describes;2008 new york,0.6172;0.2489;0.1845;0.1652;0.1416,"[np.int64(-1), -1, -1, -1, -1]",146;-1;-1;-1;-1,146,146,Visualization Techniques
Vis,2002,Direct surface extraction from 3D freehand ultrasound images,10.1109/visual.2002.1183755,http://dx.doi.org/10.1109/VISUAL.2002.1183755,45.0,52.0,C,"This paper presents a new technique for the extraction of surfaces from 3D ultrasound data. Surface extraction from ultrasound data is challenging for a number of reasons including noise and artifacts in the images and nonuniform data sampling. A method is proposed to fit an approximating radial basis function to the group of data samples. An explicit surface is then obtained by iso-surfacing the function. In most previous 3D ultrasound research, a pre-processing step is taken to interpolate the data into a regular voxel array and a corresponding loss of resolution. We are the first to represent the set of semi-structured ultrasound pixel data as a single function. From this we are able to extract surfaces without first reconstructing the irregularly spaced pixels into a regular 3D voxel array.",Youwei Zhang;Robert Rohling;Dinesh K. Pai,Youwei Zhang;R. Rohling;D.K. Pai,"Department of Computer Science, University of British Columbia, Vancouver, BC, Canada;Department of Electrical and Computer Engineering, University of British Columbia, Vancouver, BC, Canada;Department of Computer Science, University of British Columbia, Vancouver, BC, Canada",10.1109/visual.1991.175782;10.1109/visual.1994.346295;10.1109/visual.1991.175782,"Radial Basis Functions, Ultrasound, Isosurface, 3D Freehand Ultrasound, Direct Surface Extraction, Unstructured data",49.0,5.0,27.0,292.0,,,surfaces 3d ultrasound;irregularly spaced pixels;function able extract;represent;number reasons,0.7567;0.2330;0.1726;0.0380;-0.0031,"[np.int64(-1), -1, -1, -1, -1]",38;-1;-1;-1;-1,38,38,3D Medical Visualization
VAST,2020,PassVizor: Toward Better Understanding of the Dynamics of Soccer Passes,10.1109/tvcg.2020.3030359,http://dx.doi.org/10.1109/TVCG.2020.3030359,1322.0,1331.0,J,"In soccer, passing is the most frequent interaction between players and plays a significant role in creating scoring chances. Experts are interested in analyzing players' passing behavior to learn passing tactics, i.e., how players build up an attack with passing. Various approaches have been proposed to facilitate the analysis of passing tactics. However, the dynamic changes of a team's employed tactics over a match have not been comprehensively investigated. To address the problem, we closely collaborate with domain experts and characterize requirements to analyze the dynamic changes of a team's passing tactics. To characterize the passing tactic employed for each attack, we propose a topic-based approach that provides a high-level abstraction of complex passing behaviors. Based on the model, we propose a glyph-based design to reveal the multi-variate information of passing tactics within different phases of attacks, including player identity, spatial context, and formation. We further design and develop PassVizor, a visual analytics system, to support the comprehensive analysis of passing dynamics. With the system, users can detect the changing patterns of passing tactics and examine the detailed passing process for evaluating passing tactics. We invite experts to conduct analysis with PassVizor and demonstrate the usability of the system through an expert interview.",Xiao Xie;Jiachen Wang;Hongye Liang;Dazhen Deng;Shoubin Cheng;Hui Zhang 0051;Wei Chen 0001;Yingcai Wu,Xiao Xie;Jiachen Wang;Hongye Liang;Dazhen Deng;Shoubin Cheng;Hui Zhang;Wei Chen;Yingcai Wu,"State Key Lab of CAD&CG, Zhejiang University;State Key Lab of CAD&CG, Zhejiang University;State Key Lab of CAD&CG, Zhejiang University;State Key Lab of CAD&CG, Zhejiang University;Department of Sport Science, Zhejiang University;Department of Sport Science, Zhejiang University;State Key Lab of CAD&CG, Zhejiang University;State Key Lab of CAD&CG, Zhejiang University",10.1109/vast.2014.7042477;10.1109/tvcg.2013.192;10.1109/tvcg.2019.2934243;10.1109/tvcg.2014.2346445;10.1109/tvcg.2017.2745181;10.1109/tvcg.2019.2934630;10.1109/vast50239.2020.00009;10.1109/tvcg.2017.2744218;10.1109/tvcg.2018.2865041;10.1109/tvcg.2020.3030392;10.1109/vast.2014.7042477,"Soccer Analysis,Passing Analysis",34.0,41.0,44.0,1262.0,,,analyzing players passing;visual analytics support;changing patterns;information;propose glyph,0.6269;0.3600;0.2901;0.2736;0.2279,"[np.int64(-1), -1, -1, -1, -1]",49;-1;-1;-1;-1,49,49,Soccer Formation Analysis
Vis,2000,Constructing material interfaces from data sets with volume-fraction information,10.1109/visual.2000.885717,http://dx.doi.org/10.1109/VISUAL.2000.885717,367.0,372.0,C,"We present a new algorithm for material boundary interface reconstruction from data sets containing volume fractions. We transform the reconstruction problem to a problem that analyzes the dual data set, where each vertex in the dual mesh has an associated barycentric coordinate tuple that represents the fraction of each material present. After constructing the dual tetrahedral mesh from the original mesh, we construct material boundaries by mapping a tetrahedron into barycentric space and calculating the intersections with Voronoi cells in barycentric space. These intersections are mapped back to the original physical space and triangulated to form the boundary surface approximation. This algorithm can be applied to any grid structure and can treat any number of materials per element/vertex.",Kathleen S. Bonnell;Kenneth I. Joy;Bernd Hamann;Daniel Schikore;Mark A. Duchaineau,K.S. Bonnell;D.R. Schikore;K.I. Joy;M. Duchaineau;B. Hamann,"Department of Computer Science, University of California, Davis, CA, USA;Computational Engineering International, NC, USA;Department of Computer Science, University of California, Davis, CA, USA;Department of Computer Science, University of California, Davis, CA, USA;Center for Advanced Scientific Computing, Lawrence Livemore National Laboratory, Livermore, CA, USA",10.1109/visual.1991.175782;10.1109/visual.1997.663887;10.1109/visual.1997.663869;10.1109/visual.1991.175782,"Eulerian flow, material boundary surface, barycentric coordinates, volume fraction, Voronoi diagram",43.0,9.0,11.0,75.0,,,boundary interface reconstruction;voronoi cells;dual tetrahedral;materials element;fractions,0.5517;0.3992;0.3204;0.2054;0.0598,"[np.int64(-1), -1, -1, -1, -1]",123;-1;-1;-1;-1,123,123,Surface Reconstruction
Vis,2004,Context-Adaptive Mobile Visualization and Information Management,10.1109/visual.2004.19,http://dx.doi.org/10.1109/VISUAL.2004.19,8.0,8.0,M,"This poster abstract presents a scalable information visualization system for mobile devices and desktop systems. It is designed to support the operation and the workflow of wastewater systems. The regarded information data includes general information about buildings and units, process data, occupational safety regulations, work directions and first aid instructions in case of an accident. Technically, the presented framework combines visualization with agent technology in order to automatically scale various visualization types to fit on different platforms like PDAs (Personal Digital Assistants) or Tablet PCs. The implementation is based on but not limited to SQL, JSP, HTML and VRML.",Jochen Ehret;Achim Ebert;Lars Schuchardt;Heidrun Steinmetz;Hans Hagen,J. Ehret;A. Ebert;L. Schuchardt;H. Steinmetz;H. Hagen,"Intelligent Visualization and Simulation, German Research Center for Artificial Intelligence, Kaiserslautern, Germany;Intelligent Visualization and Simulation, German Research Center for Artificial Intelligence, Kaiserslautern, Germany;Institute of Environmental Engineering, Technical University of Kaiserslautern, Germany;Center for Innovative WasteWater Technology (tectraa), Technical University of Kaiserslautern, Germany;Intelligent Visualization and Simulation, German Research Center for Artificial Intelligence, Kaiserslautern, Germany",,,11.0,2.0,4.0,172.0,,,visualization agent technology;wastewater systems regarded;sql jsp html;tablet pcs;case accident technically,0.6038;0.5093;0.2256;0.1957;-0.0120,"[np.int64(-1), np.int64(-1), -1, -1, -1]",104;11;-1;-1;-1,11;104,104,Visualization Systems
VAST,2009,A visual analytics system for radio frequency fingerprinting-based localization,10.1109/vast.2009.5332596,http://dx.doi.org/10.1109/VAST.2009.5332596,35.0,42.0,C,"Radio frequency (RF) fingerprinting-based techniques for localization are a promising approach for ubiquitous positioning systems, particularly indoors. By finding unique fingerprints of RF signals received at different locations within a predefined area beforehand, whenever a similar fingerprint is subsequently seen again, the localization system will be able to infer a user's current location. However, developers of these systems face the problem of finding reliable RF fingerprints that are unique enough and adequately stable over time. We present a visual analytics system that enables developers of these localization systems to visually gain insight on whether their collected datasets and chosen fingerprint features have the necessary properties to enable a reliable RF fingerprinting-based localization system. The system was evaluated by testing and debugging an existing localization system.",Yi Han 0005;Erich P. Stuntebeck;John T. Stasko;Gregory D. Abowd,Yi Han;Erich P. Stuntebeck;John T. Stasko;Gregory D. Abowd,"School of Interactive Computing & GVU Center, Georgia Institute of Technology, USA;School of Interactive Computing & GVU Center, Georgia Institute of Technology, USA;School of Interactive Computing & GVU Center, Georgia Institute of Technology, USA;School of Interactive Computing & GVU Center, Georgia Institute of Technology, USA",10.1109/infvis.1997.636793;10.1109/infvis.1997.636793,,18.0,6.0,15.0,412.0,,,fingerprinting based localization;visual analytics enables;radio;testing debugging;adequately stable time,0.6238;0.2818;0.2446;0.1058;-0.0063,"[np.int64(-1), -1, -1, -1, -1]",6;-1;-1;-1;-1,6,6,Geospatial Data Analysis
VAST,2010,iVisClassifier: An interactive visual analytics system for classification based on supervised dimension reduction,10.1109/vast.2010.5652443,http://dx.doi.org/10.1109/VAST.2010.5652443,27.0,34.0,C,"We present an interactive visual analytics system for classification, iVisClassifier, based on a supervised dimension reduction method, linear discriminant analysis (LDA). Given high-dimensional data and associated cluster labels, LDA gives their reduced dimensional representation, which provides a good overview about the cluster structure. Instead of a single two- or three-dimensional scatter plot, iVisClassifier fully interacts with all the reduced dimensions obtained by LDA through parallel coordinates and a scatter plot. Furthermore, it significantly improves the interactivity and interpretability of LDA. LDA enables users to understand each of the reduced dimensions and how they influence the data by reconstructing the basis vector into the original data domain. By using heat maps, iVisClassifier gives an overview about the cluster relationship in terms of pairwise distances between cluster centroids both in the original space and in the reduced dimensional space. Equipped with these functionalities, iVisClassifier supports users' classification tasks in an efficient way. Using several facial image data, we show how the above analysis is performed.",Jaegul Choo;Hanseung Lee;Jaeyeon Kihm;Haesun Park,Jaegul Choo;Hanseung Lee;Jaeyeon Kihm;Haesun Park,"School of Computational Science and Engineering, Georgia Institute of Technology, USA;Science and Engineering and Computer Engineering, Georgia Institute of Technology, USA;School of Interactive Computing, Georgia Institute of Technology, USA;School of Computational Science and Engineering, Georgia Institute of Technology, USA",10.1109/vast.2009.5332629;10.1109/infvis.2003.1249015;10.1109/infvis.2004.60;10.1109/tvcg.2009.153;10.1109/vast.2009.5332629,,164.0,91.0,29.0,1727.0,TT,,visual analytics classification;method linear discriminant;lda lda enables;using heat;original space reduced,0.5754;0.3958;0.1576;0.1467;0.1348,"[np.int64(-1), -1, -1, -1, -1]",146;-1;-1;-1;-1,146,146,Visualization Techniques
Vis,2002,Interactive rendering of large volume data sets,10.1109/visual.2002.1183757,http://dx.doi.org/10.1109/VISUAL.2002.1183757,53.0,60.0,C,"We present a new algorithm for rendering very large volume data sets at interactive frame rates on standard PC hardware. The algorithm accepts scalar data sampled on a regular grid as input. The input data is converted into a compressed hierarchical wavelet representation in a preprocessing step. During rendering, the wavelet representation is decompressed on-the-fly and rendered using hardware texture mapping. The level of detail used for rendering is adapted to the local frequency spectrum of the data and its position relative to the viewer. Using a prototype implementation of the algorithm we were able to perform an interactive walkthrough of large data sets such as the visible human on a single off-the-shelf PC.",Stefan Guthe;Michael Wand 0001;Julius Gonser;Wolfgang Straßer,S. Guthe;M. Wand;J. Gonser;W. Strasser,"WSI/GRIS, University of Tübingen, Germany and WSI/GRIS, University of Tiibingen;WSI/GRIS, University of Tübingen, Germany and WSI/GRIS, University of Tiibingen;WSI/GRIS, University of Tübingen, Germany and WSI/GRIS, University of Tiibingen and Eberhard Karls Universitat Tubingen, Tubingen, Baden-WÃ¼rttemberg, DE;WSI/GRIS, Tubingen Univ., Germany",10.1109/visual.2001.964531;10.1109/visual.1999.809908;10.1109/visual.1999.809889;10.1109/visual.1993.398845;10.1109/visual.2001.964519;10.1109/visual.2001.964531,"Compression Algorithms, Level of Detail Algorithms, Scientific Visualization, Volume Rendering, Wavelets",338.0,81.0,36.0,601.0,,,rendering wavelet representation;interactive frame rates;walkthrough large data;pc hardware;human single shelf,0.6178;0.4300;0.3484;0.2849;0.0469,"[np.int64(-1), -1, -1, -1, -1]",22;-1;-1;-1;-1,22,22,Wavelet Techniques
Vis,2009,Depth-Dependent Halos: Illustrative Rendering of Dense Line Data,10.1109/tvcg.2009.138,http://dx.doi.org/10.1109/TVCG.2009.138,1299.0,1306.0,J,"We present a technique for the illustrative rendering of 3D line data at interactive frame rates. We create depth-dependent halos around lines to emphasize tight line bundles while less structured lines are de-emphasized. Moreover, the depth-dependent halos combined with depth cueing via line width attenuation increase depth perception, extending techniques from sparse line rendering to the illustrative visualization of dense line data. We demonstrate how the technique can be used, in particular, for illustrating DTI fiber tracts but also show examples from gas and fluid flow simulations and mathematics as well as describe how the technique extends to point data. We report on an informal evaluation of the illustrative DTI fiber tract visualizations with domain experts in neurosurgery and tractography who commented positively about the results and suggested a number of directions for future work.",Maarten H. Everts;Henk Bekker;Jos B. T. M. Roerdink;Tobias Isenberg 0001,Maarten H. Everts;Henk Bekker;Jos B.T.M. Roerdink;Tobias Isenberg,"University of Groningam, Netherlands;University of Groningam, Netherlands;University of Groningam, Netherlands;University of Groningam, Netherlands",10.1109/visual.2000.885694;10.1109/tvcg.2007.70532;10.1109/tvcg.2006.172;10.1109/visual.2000.885696;10.1109/visual.2005.1532778;10.1109/tvcg.2006.115;10.1109/visual.2005.1532859;10.1109/tvcg.2006.197;10.1109/visual.2005.1532858;10.1109/tvcg.2007.70555;10.1109/visual.1996.567777;10.1109/visual.2004.48;10.1109/visual.2000.885694,"Illustrative rendering and visualization, NPR, dense line data, DTI, black-and-white rendering, GPU technique",180.0,86.0,44.0,1131.0,TT;BP,,line rendering illustrative;dti fiber tract;halos combined depth;examples gas fluid;number,0.6279;0.4309;0.3251;0.1409;-0.0003,"[np.int64(-1), -1, -1, -1, -1]",43;-1;-1;-1;-1,43,43,Illustrative Rendering Techniques
Vis,2024,Towards Dataset-Scale and Feature-Oriented Evaluation of Text Summarization in Large Language Model Prompts,10.1109/tvcg.2024.3456398,http://dx.doi.org/10.1109/TVCG.2024.3456398,481.0,491.0,J,"Recent advancements in Large Language Models (LLMs) and Prompt Engineering have made chatbot customization more accessible, significantly reducing barriers to tasks that previously required programming skills. However, prompt evaluation, especially at the dataset scale, remains complex due to the need to assess prompts across thousands of test instances within a dataset. Our study, based on a comprehensive literature review and pilot study, summarized five critical challenges in prompt evaluation. In response, we introduce a feature-oriented workflow for systematic prompt evaluation. In the context of text summarization, our workflow advocates evaluation with summary characteristics (feature metrics) such as complexity, formality, or naturalness, instead of using traditional quality metrics like ROUGE. This design choice enables a more user-friendly evaluation of prompts, as it guides users in sorting through the ambiguity inherent in natural language. To support this workflow, we introduce Awesum, a visual analytics system that facilitates identifying optimal prompt refinements for text summarization through interactive visualizations, featuring a novel Prompt Comparator design that employs a BubbleSet-inspired design enhanced by dimensionality reduction techniques. We evaluate the effectiveness and general applicability of the system with practitioners from various domains and found that (1) our design helps overcome the learning curve for non-technical people to conduct a systematic evaluation of summarization prompts, and (2) our feature-oriented workflow has the potential to generalize to other NLG and image-generation tasks. For future works, we advocate moving towards feature-oriented evaluation of LLM prompts and discuss unsolved challenges in terms of human-agent interaction.",Sam Yu-Te Lee;Aryaman Bahukhandi;Dongyu Liu;Kwan-Liu Ma,Sam Yu-Te Lee;Aryaman Bahukhandi;Dongyu Liu;Kwan-Liu Ma,"University of California, USA;University of California, USA;University of California, USA;University of California, USA",10.1109/tvcg.2017.2743858;10.1109/tvcg.2017.2744938;10.1109/tvcg.2017.2744358;10.1109/tvcg.2015.2467112;10.1109/tvcg.2017.2744158;10.1109/tvcg.2023.3326585;10.1109/tvcg.2017.2744878,"Visual analytics,prompt engineering,,,text summarization,human-computer interaction,dimensionality reduction",,1.0,65.0,386.0,,,prompt engineering chatbot;evaluation summarization;nlg image;dataset scale remains;advocate moving,0.5657;0.4179;0.2673;0.0883;0.0219,"[np.int64(-1), -1, -1, -1, -1]",121;-1;-1;-1;-1,121,121,Interactive Software Tools
Vis,1998,Visualization for multiparameter aircraft designs,10.1109/visual.1998.745351,http://dx.doi.org/10.1109/VISUAL.1998.745351,491.0,494.0,C,"We describe an aircraft design problem in high dimensional space, with D typically being 10 to 30. In some respects this is a classic optimization problem, where the goal is to find the point that minimizes an objective function while satisfying a set of constraints. However, evaluating an individual point is expensive, and the high dimensionality makes many approaches to solving the problem infeasible. The difficulty of the problem means that aircraft designers would benefit from any insights that can be provided. We discuss how simple visualizations have already proved beneficial, and then describe how visualization might be of further help in the future.",Clifford A. Shaffer;Duane L. Knill;Layne T. Watson,C.A. Shaffer;D.L. Knill;L.T. Watson,"Computer Science, Virginia Technology, Blacksburg, VA, USA;Aeronautics and Astronautics, University of Washington, Seattle, WA, USA;Computer Science and Mathematics, Virginia Polytechnic Institute and State University, Blacksburg, VA, USA",10.1109/visual.1997.663866;10.1109/visual.1997.663868;10.1109/visual.1990.146402,,14.0,6.0,13.0,75.0,,,aircraft design;high dimensionality makes;point minimizes objective;infeasible;typically 10,0.6983;0.3459;0.3161;0.0598;0.0151,"[np.int64(-1), -1, -1, -1, -1]",8;-1;-1;-1;-1,8,8,Aerospace Design
VAST,2016,SocialBrands: Visual analysis of public perceptions of brands on social media,10.1109/vast.2016.7883513,http://dx.doi.org/10.1109/VAST.2016.7883513,71.0,80.0,C,"Public perceptions of a brand is critical to its performance. While social media has demonstrated a huge potential to shape public perceptions of brands, existing tools are not intuitive and explanatory for domain users to use as they fail to provide a comprehensive analysis framework for perceptions of brands. In this paper, we present SocialBrands, a novel visual analysis tool for brand managers to understand public perceptions of brands on social media. Social-Brands leverages brand personality framework in marketing literature and social computing approaches to compute the personality of brands from three driving factors (user imagery, employee imagery, and official announcement) on social media, and construct an evidence network explaining the association between brand personality and driving factors. These computational results are then integrated with new interactive visualizations to help brand managers understand personality traits and their driving factors. We demonstrate the usefulness and effectiveness of SocialBrands through a series of user studies with brand managers in an enterprise context. Design lessons are also derived from our studies.",Xiaotong Liu;Anbang Xu;Liang Gou;Haibin Liu;Rama Akkiraju;Han-Wei Shen,Xiaotong Liu;Anbang Xu;Liang Gou;Haibin Liu;Rama Akkiraju;Han-Wei Shen,Visa Research;IBM Research;Ohio State University;IBM Research;IBM Research;Visa Research,10.1109/tvcg.2014.2346922;10.1109/vast.2014.7042496;10.1109/tvcg.2013.227;10.1109/tvcg.2012.291;10.1109/tvcg.2010.129;10.1109/tvcg.2013.221;10.1109/infvis.2000.885091;10.1109/tvcg.2011.183;10.1109/tvcg.2014.2346922,,22.0,11.0,42.0,1471.0,,,socialbrands novel visual;understand personality traits;domain users use;computational results integrated;use fail provide,0.6660;0.3245;0.2148;0.0947;-0.0753,"[np.int64(-1), -1, -1, -1, -1]",-1;-1;-1;-1;-1,,-1,Interactive 3D Visualization
SciVis,2014,Characterizing Molecular Interactions in Chemical Systems,10.1109/tvcg.2014.2346403,http://dx.doi.org/10.1109/TVCG.2014.2346403,2476.0,2485.0,J,"Interactions between atoms have a major influence on the chemical properties of molecular systems. While covalent interactions impose the structural integrity of molecules, noncovalent interactions govern more subtle phenomena such as protein folding, bonding or self assembly. The understanding of these types of interactions is necessary for the interpretation of many biological processes and chemical design tasks. While traditionally the electron density is analyzed to interpret the quantum chemistry of a molecular system, noncovalent interactions are characterized by low electron densities and only slight variations of them - challenging their extraction and characterization. Recently, the signed electron density and the reduced gradient, two scalar fields derived from the electron density, have drawn much attention in quantum chemistry since they enable a qualitative visualization of these interactions even in complex molecular systems and experimental measurements. In this work, we present the first combinatorial algorithm for the automated extraction and characterization of covalent and noncovalent interactions in molecular systems. The proposed algorithm is based on a joint topological analysis of the signed electron density and the reduced gradient. Combining the connectivity information of the critical points of these two scalar fields enables to visualize, enumerate, classify and investigate molecular interactions in a robust manner. Experiments on a variety of molecular systems, from simple dimers to proteins or DNA, demonstrate the ability of our technique to robustly extract these interactions and to reveal their structural relations to the atoms and bonds forming the molecules. For simple systems, our analysis corroborates the observations made by the chemists while it provides new visual and quantitative insights on chemical interactions for larger molecular systems.",David Günther;Roberto Álvarez Boto;Julia Contreras-García;Jean-Philip Piquemal;Julien Tierny,David Günther;Roberto A. Boto;Juila Contreras-Garcia;Jean-Philip Piquemal;Julien Tierny,"Institut-Mines-Télécom, Télécom Paris'Iech, CNRS LTCI, Paris, France;Sorbonne Universités, UMR 7616, Laboratoire de Chimie Théorique, Paris, France;Sorbonne Universités, UMR 7616, LCT, Paris, France;Sorbonne Universités, UMR 7616, LCT, Paris, France;CNRS LIP6, UPMC, Télécom Paris'Iech, Paris, France",10.1109/tvcg.2009.163;10.1109/visual.2004.96;10.1109/visual.2003.1250376;10.1109/tvcg.2008.110;10.1109/tvcg.2009.157;10.1109/tvcg.2011.259;10.1109/tvcg.2007.70578;10.1109/tvcg.2013.158;10.1109/tvcg.2009.163,"Molecular Chemistry, Topological Data Analysis, Morse-Smale Complex, Join Tree",93.0,64.0,58.0,772.0,,,interactions reveal structural;signed electron density;topological analysis;combinatorial algorithm automated;points scalar fields,0.5968;0.3150;0.3091;0.2063;0.1333,"[np.int64(-1), -1, -1, -1, -1]",115;-1;-1;-1;-1,115,115,Structural Connectivity Analysis
SciVis,2014,A Robust Parity Test for Extracting Parallel Vectors in 3D,10.1109/tvcg.2014.2346412,http://dx.doi.org/10.1109/TVCG.2014.2346412,2526.0,2534.0,J,"Parallel vectors (PV), the loci where two vector fields are parallel, are commonly used to represent curvilinear features in 3D for data visualization. Methods for extracting PV usually operate on a 3D grid and start with detecting seed points on a cell face. We propose, to the best of our knowledge, the first provably correct test that determines the parity of the number of PV points on a cell face. The test only needs to sample along the face boundary and works for any choice of the two vector fields. A discretization of the test is described, validated, and compared with existing tests that are also based on boundary sampling. The test can guide PV-extraction algorithms to ensure closed curves wherever the input fields are continuous, which we exemplify in extracting ridges and valleys of scalar functions.",Tao Ju;Minxin Cheng;Xu Wang;Ye Duan,Tao Ju;Minxin Cheng;Xu Wang;Ye Duan,Washington University in St. Louis;University of Missouri at Columbia;University of Missouri at Columbia;University of Missouri at Columbia,10.1109/visual.2002.1183786;10.1109/visual.2005.1532851;10.1109/visual.1999.809896;10.1109/visual.2002.1183786,"Parallel vectors, feature curve extraction, ridges and valleys, parity test",7.0,6.0,17.0,385.0,HM,,extracting ridges valleys;vector fields parallel;operate 3d grid;test determines parity;commonly used represent,0.5567;0.4629;0.3792;0.2629;0.0494,"[np.int64(-1), -1, -1, -1, -1]",72;-1;-1;-1;-1,72,72,Ridge Extraction Techniques
Vis,2022,On-Tube Attribute Visualization for Multivariate Trajectory Data,10.1109/tvcg.2022.3209400,http://dx.doi.org/10.1109/TVCG.2022.3209400,1288.0,1298.0,J,"Stylized tubes are an established visualization primitive for line data as encountered in many scientific fields, ranging from characteristic lines in flow fields, fiber tracks reconstructed from diffusion tensor imaging, to trajectories of moving objects as they arise from cyber-physical systems in many engineering disciplines. Typical challenges include large data set sizes demanding for efficient rendering techniques as well as a large number of attributes that cannot be mapped simultaneously to the basic visual attributes provided by a tube-based visualization. In this work, we tackle both challenges with a new on-tube visualization approach. We improve recent work on high-quality GPU ray casting of Hermite spline tubes supporting ambient occlusion and extend it by a new layered procedural texturing technique. In the proposed framework, a large number of data set attributes can be mapped simultaneously to a variety of glyphs and plots that are embedded in texture space and organized in layers. Efficient rendering with minimal data transfer is achieved by generating the glyphs procedurally and drawing them in a deferred shading pass. We integrated these techniques in a prototype visualization tool that facilitates flexible mapping of data set attributes to visual tube and glyph attributes. We studied our approach on a variety of example data from different fields and found it to provide a highly adaptable and extensible toolbox to quickly craft tailor-made tube-based trajectory visualizations.",Benjamin Russig;David Groß;Raimund Dachselt;Stefan Gumhold,Benjamin Russig;David Groß;Raimund Dachselt;Stefan Gumhold,"Chair of Computer Graphics and Visualization, TU Dresden, Germany;Chair of Computer Graphics and Visualization, TU Dresden, Germany;Interactive Media Lab, TU Dresden, Germany;Chair of Computer Graphics and Visualization, TU Dresden, Germany",10.1109/tvcg.2016.2598416;10.1109/tvcg.2018.2864811;10.1109/tvcg.2009.138;10.1109/tvcg.2020.3028954;10.1109/tvcg.2006.151;10.1109/tvcg.2007.70532;10.1109/visual.2005.1532859;10.1109/tvcg.2012.265;10.1109/tvcg.2006.172;10.1109/tvcg.2016.2598416,"Visualization,Rendering,Line Data,Trajectories,Multivariate Data",,2.0,47.0,754.0,,,tube based visualization;generating glyphs procedurally;cyber physical;data different fields;casting hermite,0.7110;0.3385;0.1380;0.0854;0.0835,"[np.int64(-1), -1, -1, -1, -1]",128;-1;-1;-1;-1,128,128,3D Volume Visualization
Vis,1999,Detecting null alleles with vasarely charts,10.1109/visual.1999.809931,http://dx.doi.org/10.1109/VISUAL.1999.809931,463.0,466.0,C,Microsatellite genotypes can have problems that are difficult to detect with existing tools. One such problem is null alleles. This paper presents a new visualization tool that helps to find and characterize these errors. The paper explains how the tool is used to analyze groups of genotypes and proposes other possible uses.,Carl Manaster;Elizabeth Nanthakumar;Phillip A. Morin,C.J. Manaster;E. Nanthakumar;P.A. Morin,"Axys Pharmaceuticals, USA;Axys Pharmaceuticals, USA;Axys Pharmaceuticals, USA",,,3.0,0.0,20.0,43.0,,,microsatellite genotypes;characterize errors;new visualization;tools problem null;difficult,0.7563;0.2549;0.2244;0.2020;0.0932,"[np.int64(-1), -1, -1, -1, -1]",-1;-1;-1;-1;-1,,-1,Interactive 3D Visualization
Vis,2000,Combining local and remote visualization techniques for interactive volume rendering in medical applications,10.1109/visual.2000.885729,http://dx.doi.org/10.1109/VISUAL.2000.885729,449.0,452.0,C,"For a comprehensive understanding of tomographic image data in medicine, interactive and high-quality direct volume rendering is an essential prerequisite. This is provided by visualization using 3D texture mapping which is still limited to high-end graphics hardware. In order to make it available in a clinical environment, we present a system which uniquely combines local desktop computers and remote high-end graphics hardware. In this context, we exploit the standard visualization capabilities to a maximum which are available in the clinical environment. For 3D representations of high resolution and quality we access the remote specialized hardware. Various tools for 2D and 3D visualization are provided which meet the requirements of a medical diagnosis. This is demonstrated with examples from the field of neuroradiology which show the value of our strategy in practice.",Klaus Engel;Thomas Ertl;Peter Hastreiter;Bernd Tomandl;K. Eberhardt,K. Engel;P. Hastreiter;B. Tomandl;K. Eberhardt;T. Ertl,"Division of Neuroradiology, University of Erlangen Nuremberg, Germany;Visualization and Interactive Systems Group, University of Stuttgart, Germany;Neurocenter, University of Erlangen Nuremberg, Germany;Visualization and Interactive Systems Group, University of Stuttgart, Germany;Division of Neuroradiology, University of Erlangen Nuremberg, Germany",10.1109/visual.1996.568134;10.1109/visual.1996.568134,"medical data visualization, volume visualization, distributed systems, PC graphics hardware, remote rendering",112.0,21.0,14.0,245.0,,,3d visualization;image data medicine;texture mapping limited;computers remote high;diagnosis demonstrated,0.5988;0.5094;0.3115;0.2133;0.1533,"[np.int64(-1), np.int64(-1), -1, -1, -1]",82;33;-1;-1;-1,33;82,82,3D/4D Visualization
VAST,2011,Jigsaw to save vastopolis,10.1109/vast.2011.6102496,http://dx.doi.org/10.1109/VAST.2011.6102496,325.0,326.0,M,"This article describes our analytic process and experience of using the Jigsaw system in working on the VAST 2011 Mini Challenge 3. We describe how we extracted and worked with entities from the documents, and how Jigsaw's computational analysis capabilities and visualizations scaffolded the investigation. Based on our experiences, we discuss desirable features that would enhance the analytic power of Jigsaw.",Elizabeth Braunstein;Carsten Görg;Zhicheng Liu 0001;John T. Stasko,Elizabeth Braunstein;Carsten Görg;Zhicheng Liu;John Stasko,"Mercyhurst College, USA;University of Colorado Denver, USA;Georgia Tech, USA;Georgia Tech, USA",,,1.0,0.0,3.0,180.0,,,documents jigsaw computational;entities;enhance analytic power;2011 mini;extracted worked,0.6912;0.3238;0.1490;0.1088;0.0974,"[np.int64(-1), -1, -1, -1, -1]",9;-1;-1;-1;-1,9,9,Tree Visualization Techniques
Vis,2023,Visual Analysis of Displacement Processes in Porous Media using Spatio-Temporal Flow Graphs,10.1109/tvcg.2023.3326931,http://dx.doi.org/10.1109/TVCG.2023.3326931,759.0,769.0,J,"We developed a new approach comprised of different visualizations for the comparative spatio-temporal analysis of displacement processes in porous media. We aim to analyze and compare ensemble datasets from experiments to gain insight into the influence of different parameters on fluid flow. To capture the displacement of a defending fluid by an invading fluid, we first condense an input image series to a single time map. From this map, we generate a spatio-temporal flow graph covering the whole process. This graph is further simplified to only reflect topological changes in the movement of the invading fluid. Our interactive tools allow the visual analysis of these processes by visualizing the graph structure and the context of the experimental setup, as well as by providing charts for multiple metrics. We apply our approach to analyze and compare ensemble datasets jointly with domain experts, where we vary either fluid properties or the solid structure of the porous medium. We finally report the generated insights from the domain experts and discuss our contribution's advantages, generality, and limitations.",Alexander Straub;Nikolaos Karadimitriou;Guido Reina;Steffen Frey;Holger Steeb;Thomas Ertl,Alexander Straub;Nikolaos Karadimitriou;Guido Reina;Steffen Frey;Holger Steeb;Thomas Ertl,"University of Stuttgart, Germany;University of Stuttgart, Germany;University of Stuttgart, Germany;University of Groningen, The Netherlands;University of Stuttgart, Germany;University of Stuttgart, Germany",0.1109/tvcg.2010.190;10.1109/tvcg.2015.2468093;10.1109/tvcg.2013.141;10.1109/tvcg.2018.2864901;10.1109/tvcg.2018.2864849;10.1109/tvcg.2010.181;10.1109/tvcg.2014.2346321;10.1109/tvcg.2012.200;10.1109/tvcg.2010.223;10.1109/tvcg.2018.2864506,"Comparative visualization,ensemble,graph,porous media",,0.0,61.0,403.0,,X,flow graph;porous media;capture displacement defending;ensemble datasets jointly;different,0.5111;0.4639;0.2238;0.2215;0.0438,"[np.int64(-1), -1, -1, -1, -1]",63;-1;-1;-1;-1,63,63,Flow Visualization Techniques
VAST,2012,An Affordance-Based Framework for Human Computation and Human-Computer Collaboration,10.1109/tvcg.2012.195,http://dx.doi.org/10.1109/TVCG.2012.195,2859.0,2868.0,J,"Visual Analytics is “the science of analytical reasoning facilitated by visual interactive interfaces” [70]. The goal of this field is to develop tools and methodologies for approaching problems whose size and complexity render them intractable without the close coupling of both human and machine analysis. Researchers have explored this coupling in many venues: VAST, Vis, InfoVis, CHI, KDD, IUI, and more. While there have been myriad promising examples of human-computer collaboration, there exists no common language for comparing systems or describing the benefits afforded by designing for such collaboration. We argue that this area would benefit significantly from consensus about the design attributes that define and distinguish existing techniques. In this work, we have reviewed 1,271 papers from many of the top-ranking conferences in visual analytics, human-computer interaction, and visualization. From these, we have identified 49 papers that are representative of the study of human-computer collaborative problem-solving, and provide a thorough overview of the current state-of-the-art. Our analysis has uncovered key patterns of design hinging on humanand machine-intelligence affordances, and also indicates unexplored avenues in the study of this area. The results of this analysis provide a common framework for understanding these seemingly disparate branches of inquiry, which we hope will motivate future work in the field.",R. Jordan Crouser;Remco Chang,R. Jordon Crouser;Remco Chang,"Department of Computer Science, Tufts University, USA;Department of Computer Science, Tufts University, USA",10.1109/vast.2010.5652398;10.1109/vast.2011.6102461;10.1109/tvcg.2009.199;10.1109/vast.2010.5652910;10.1109/vast.2010.5652484;10.1109/vast.2009.5332584;10.1109/vast.2010.5652885;10.1109/vast.2009.5333564;10.1109/vast.2010.5652392;10.1109/vast.2009.5332586;10.1109/vast.2011.6102451;10.1109/vast.2009.5333023;10.1109/vast.2009.5333020;10.1109/vast.2009.5332628;10.1109/tvcg.2011.173;10.1109/tvcg.2011.218;10.1109/tvcg.2011.231;10.1109/vast.2010.5652443;10.1109/vast.2010.5653598;10.1109/vast.2011.6102447;10.1109/vast.2011.6102465;10.1109/vast.2011.6102467;10.1109/vast.2010.5652398,"Human computation, human complexity, theory, framework",58.0,36.0,83.0,1736.0,,,visual analytics human;patterns design hinging;papers ranking conferences;kdd;intractable close coupling,0.7109;0.1590;0.1081;0.0532;-0.0043,"[np.int64(-1), -1, -1, -1, -1]",108;-1;-1;-1;-1,108,108,Visual Analytics
InfoVis,2020,A Generic Framework and Library for Exploration of Small Multiples through Interactive Piling,10.1109/tvcg.2020.3028948,http://dx.doi.org/10.1109/TVCG.2020.3028948,358.0,368.0,J,"Small multiples are miniature representations of visual information used generically across many domains. Handling large numbers of small multiples imposes challenges on many analytic tasks like inspection, comparison, navigation, or annotation. To address these challenges, we developed a framework and implemented a library called PILlNG.JS for designing interactive piling interfaces. Based on the piling metaphor, such interfaces afford flexible organization, exploration, and comparison of large numbers of small multiples by interactively aggregating visual objects into piles. Based on a systematic analysis of previous work, we present a structured design space to guide the design of visual piling interfaces. To enable designers to efficiently build their own visual piling interfaces, PILlNG.JS provides a declarative interface to avoid having to write low-level code and implements common aspects of the design space. An accompanying GUI additionally supports the dynamic configuration of the piling interface. We demonstrate the expressiveness of PILlNG.JS with examples from machine learning, immunofluorescence microscopy, genomics, and public health.",Fritz Lekschas;Xinyi Zhou 0005;Wei Chen 0001;Nils Gehlenborg;Benjamin Bach;Hanspeter Pfister,Fritz Lekschas;Xinyi Zhou;Wei Chen;Nils Gehlenborg;Benjamin Bach;Hanspeter Pfister,"Cambridge, Harvard School of Engineering and Applied Sciences, MA, USA;State Key Lab of CAD&CG, Zhejiang University, Hangzhou, China;State Key Lab of CAD&CG, Zhejiang University, Hangzhou, China;Harvard Medical School, Boston, MA, USA;University of Edinburgh, Edinburgh, UK;Cambridge, Harvard School of Engineering and Applied Sciences, MA, USA",10.1109/tvcg.2015.2467851;10.1109/visual.2005.1532788;10.1109/tvcg.2011.185;10.1109/tvcg.2007.70535;10.1109/tvcg.2017.2745978;10.1109/tvcg.2008.125;10.1109/tvcg.2014.2346249;10.1109/tvcg.2012.237;10.1109/tvcg.2019.2934555;10.1109/tvcg.2015.2467851,"Information visualization,small multiples,interactive piling,visual aggregation,spatial organization",14.0,18.0,52.0,690.0,HM,,visual piling interfaces;js provides declarative;numbers small multiples;genomics public health;domains handling,0.7312;0.2694;0.1824;0.1756;-0.0120,"[np.int64(-1), -1, -1, -1, -1]",146;-1;-1;-1;-1,146,146,Visualization Techniques
Vis,1991,NetV: an experimental network-based volume visualization system,10.1109/visual.1991.175807,http://dx.doi.org/10.1109/VISUAL.1991.175807,239.0,245.0,C,"An experimental volume visualization system, NetV, that distributes volume imaging tasks to appropriate network resources is described. NetV gives offsite scientists easy access to high-end volume imaging software and hardware. The system allows a user to submit volume imaging jobs to an imaging spooler on a visualization-server. Remote high-power compute engines process rendering tasks, while local workstations run the user-interface. The time required to submit a job, render the job on a mini-supercomputer-class machine, and return the volume imaging to the offsite scientist is far less than the time it would take to create a similar image on a local workstation-class machine.&lt;&lt;ETX&gt;&gt;",T. Todd Elvins;David R. Nadeau,T.T. Elvins;D.R. Nadeau,"San Diego Supercomputer Center, Advanced Scientific Visualization Laboratory;San Diego Supercomputer Center, Advanced Scientific Visualization Laboratory",10.1109/visual.1990.146362;10.1109/visual.1990.146397;10.1109/visual.1990.146382;10.1109/visual.1991.175814;10.1109/visual.1990.146362,,20.0,9.0,16.0,45.0,,,experimental volume visualization;offsite scientists;supercomputer class;netv;rendering tasks local,0.7142;0.3415;0.2963;0.2434;0.2199,"[np.int64(-1), -1, -1, -1, -1]",54;-1;-1;-1;-1,54,54,Volume Visualization Techniques
Vis,2003,Hardware-based nonlinear filtering and segmentation using high-level shading languages,10.1109/visual.2003.1250387,http://dx.doi.org/10.1109/VISUAL.2003.1250387,309.0,316.0,C,"Non-linear filtering is an important task for volume analysis. This paper presents hardware-based implementations of various non-linear filters for volume smoothing with edge preservation. The Cg high-level shading language is used in combination with latest PC consumer graphics hardware. Filtering is divided into pervertex and per-fragment stages. In both stages we propose techniques to increase the filtering performance. The vertex program pre-computes texture coordinates in order to address all contributing input samples of the operator mask. Thus additional computations are avoided in the fragment program. The presented fragment programs preserve cache coherence, exploit 4D vector arithmetic, and internal fixed point arithmetic to increase performance. We show the applicability of non-linear filters as part of a GPU-based segmentation pipeline. The resulting binary mask is compressed and decompressed in the graphics memory on-the-fly.",Ivan Viola;Armin Kanitsar;M. Eduard Gröller,I. Viola;A. Kanitsar;M.E. Groller,"Institute of Computer Graphics and Algorithms, University of Technology, Vienna, Austria;Institute of Computer Graphics and Algorithms, University of Technology, Vienna, Austria;Institute of Computer Graphics and Algorithms, University of Technology, Vienna, Austria",10.1109/visual.2002.1183766;10.1109/visual.2002.1183762;10.1109/visual.1999.809934;10.1109/visual.2002.1183757;10.1109/visual.2002.1183766," Non-linear Filtering, Segmentation, Hardware Acceleration",122.0,13.0,23.0,139.0,,,linear filters gpu;shading language used;task volume;pervertex fragment;preserve cache,0.6133;0.2420;0.2007;0.1162;0.0778,"[np.int64(-1), -1, -1, -1, -1]",47;-1;-1;-1;-1,47,47,Graphics Processing Techniques
Vis,1999,Anisotropic nonlinear diffusion in flow visualization,10.1109/visual.1999.809904,http://dx.doi.org/10.1109/VISUAL.1999.809904,325.0,539.0,C,"Vector field visualization is an important topic in scientific visualization. Its aim is to graphically represent field data in an intuitively understandable and precise way. Here a new approach based on anisotropic nonlinear diffusion is introduced. It enables an easy perception of flow data and serves as an appropriate scale space method for the visualization of complicated flow patterns. The approach is closely related to nonlinear diffusion methods in image analysis where images are smoothed while still retaining and enhancing edges. An initial noisy image is smoothed along streamlines, whereas the image is sharpened in the orthogonal direction. The method is based on a continuous model and requires the solution of a parabolic PDE problem. It is discretized only in the final implementational step. Therefore, many important qualitative aspects can already be discussed on a continuous level. Applications are shown in 2D and 3D and the provisions for flow segmentation are outlined.",Tobias Preußer;Martin Rumpf,T. Preusser;M. Rumpf,"Rheinische Friedrich-Wilhelms-Universitat Bonn, Bonn, Nordrhein-Westfalen, DE;Institut für Angewandte Mathematik, Universität Bonn, Bonn, Germany",10.1109/visual.1993.398875;10.1109/visual.1995.480817;10.1109/visual.1994.346312;10.1109/visual.1997.663912;10.1109/visual.1996.567784;10.1109/visual.1997.663898;10.1109/visual.1993.398875,"flow visualization, multiscale, nonlinear diffusion, segmentation",77.0,13.0,21.0,108.0,,,vector field visualization;anisotropic nonlinear diffusion;image sharpened;implementational step important;closely related,0.6783;0.6297;0.1529;0.0163;-0.0164,"[np.int64(-1), np.int64(-1), -1, -1, -1]",127;39;-1;-1;-1,39;127,127,Field Visualization
SciVis,2019,Dynamic Nested Tracking Graphs,10.1109/tvcg.2019.2934368,http://dx.doi.org/10.1109/TVCG.2019.2934368,249.0,258.0,J,"This work describes an approach for the interactive visual analysis of large-scale simulations, where numerous superlevel set components and their evolution are of primary interest. The approach first derives, at simulation runtime, a specialized Cinema database that consists of images of component groups, and topological abstractions. This database is processed by a novel graph operation-based nested tracking graph algorithm (GO-NTG) that dynamically computes NTGs for component groups based on size, overlap, persistence, and level thresholds. The resulting NTGs are in turn used in a feature-centered visual analytics framework to query specific database elements and update feature parameters, facilitating flexible post hoc analysis.",Jonas Lukasczyk;Christoph Garth;Gunther H. Weber;Tim Biedert;Ross Maciejewski;Heike Leitte,Jonas Lukasczyk;Christoph Garth;Gunther H. Weber;Tim Biedert;Ross Maciejewski;Heike Leitte,"Technische Universität Kaiserslautern;Technische Universität Kaiserslautern;Lawrence Berkeley National Laboratory, University of California, Davis;NVIDIA Corporation;Arizona State University;Technische Universität Kaiserslautern",10.1109/tvcg.2018.2865265;10.1109/visual.1998.745288;10.1109/tvcg.2012.228;10.1109/tvcg.2018.2865265,"Topological Data Analysis,Nested Tracking Graphs,Image Databases,Feature Tracking,Post Hoc Visual Analytics",16.0,18.0,35.0,701.0,,,large scale simulations;nested tracking graph;superlevel set;images component;update feature parameters,0.5336;0.4386;0.2979;0.1182;0.0810,"[np.int64(-1), -1, -1, -1, -1]",113;-1;-1;-1;-1,113,113,Marine Simulation Studies
InfoVis,1998,Similarity clustering of dimensions for an enhanced visualization of multidimensional data,10.1109/infvis.1998.729559,http://dx.doi.org/10.1109/INFVIS.1998.729559,52.0,,C,"The order and arrangement of dimensions (variates) is crucial for the effectiveness of a large number of visualization techniques such as parallel coordinates, scatterplots, recursive pattern, and many others. We describe a systematic approach to arrange the dimensions according to their similarity. The basic idea is to rearrange the data dimensions such that dimensions showing a similar behavior are positioned next to each other. For the similarity clustering of dimensions, we need to define similarity measures which determine the partial or global similarity of dimensions. We then consider the problem of finding an optimal one- or two-dimensional arrangement of the dimensions based on their similarity. Theoretical considerations show that both, the one- and the two-dimensional arrangement problem are surprisingly hard problems, i.e. they are NP complete. Our solution of the problem is therefore based on heuristic algorithms. An empirical evaluation using a number of different visualization techniques shows the high impact of our similarity clustering of dimensions on the visualization results.",Mihael Ankerst;Stefan Berchtold;Daniel A. Keim,M. Ankerst;S. Berchtold;D.A. Keim,"University of Munich (LMU), Munich, Germany;AT and T Bell Laboratories, Inc., Florham Park, NJ, USA;Martin Luther University of Halle-Wittenberg, Halle, Germany",10.1109/visual.1990.146402;10.1109/visual.1994.346302;10.1109/visual.1995.485140;10.1109/visual.1990.146402,,351.0,132.0,30.0,996.0,,,clustering dimensions visualization;idea rearrange data;define similarity;techniques parallel;recursive pattern,0.6824;0.3456;0.3410;0.2664;0.1200,"[np.int64(-1), -1, -1, -1, -1]",85;-1;-1;-1;-1,85,85,Cluster Visualization
VAST,2020,Auditing the Sensitivity of Graph-based Ranking with Visual Analytics,10.1109/tvcg.2020.3028958,http://dx.doi.org/10.1109/TVCG.2020.3028958,1459.0,1469.0,J,"Graph mining plays a pivotal role across a number of disciplines, and a variety of algorithms have been developed to answer who/what type questions. For example, what items shall we recommend to a given user on an e-commerce platform? The answers to such questions are typically returned in the form of a ranked list, and graph-based ranking methods are widely used in industrial information retrieval settings. However, these ranking algorithms have a variety of sensitivities, and even small changes in rank can lead to vast reductions in product sales and page hits. As such, there is a need for tools and methods that can help model developers and analysts explore the sensitivities of graph ranking algorithms with respect to perturbations within the graph structure. In this paper, we present a visual analytics framework for explaining and exploring the sensitivity of any graph-based ranking algorithm by performing perturbation-based what-if analysis. We demonstrate our framework through three case studies inspecting the sensitivity of two classic graph-based ranking algorithms (PageRank and HITS) as applied to rankings in political news media and social networks.",Tiankai Xie;Yuxin Ma;Hanghang Tong;My T. Thai;Ross Maciejewski,Tiankai Xie;Yuxin Ma;Hanghang Tong;My T. Thai;Ross Maciejewski,Arizona State University;Arizona State University;University of Illinois at Urbana-Champaign;University of Florida;Arizona State University,10.1109/tvcg.2019.2934300;10.1109/tvcg.2018.2864477;10.1109/tvcg.2013.173;10.1109/tvcg.2017.2745085;10.1109/tvcg.2017.2743858;10.1109/tvcg.2019.2934396;10.1109/tvcg.2012.253;10.1109/tvcg.2017.2745078;10.1109/tvcg.2019.2934798;10.1109/tvcg.2019.2934805;10.1109/tvcg.2018.2865126;10.1109/tvcg.2019.2934619;10.1109/tvcg.2019.2934300,"Graph-based ranking,sensitivity analysis,visual analytics",8.0,3.0,51.0,638.0,,,graph based ranking;political news;product sales page;sensitivities small changes;demonstrate framework,0.6874;0.2556;0.1876;0.0875;-0.0303,"[np.int64(-1), -1, -1, -1, -1]",44;-1;-1;-1;-1,44,44,Graph Theory Analysis
InfoVis,2018,Vistrates: A Component Model for Ubiquitous Analytics,10.1109/tvcg.2018.2865144,http://dx.doi.org/10.1109/TVCG.2018.2865144,586.0,596.0,J,"Visualization tools are often specialized for specific tasks, which turns the user's analytical workflow into a fragmented process performed across many tools. In this paper, we present a component model design for data visualization to promote modular designs of visualization tools that enhance their analytical scope. Rather than fragmenting tasks across tools, the component model supports unification, where components-the building blocks of this model-can be assembled to support a wide range of tasks. Furthermore, the model also provides additional key properties, such as support for collaboration, sharing across multiple devices, and adaptive usage depending on expertise, from creating visualizations using dropdown menus, through instantiating components, to actually modifying components or creating entirely new ones from scratch using JavaScript or Python source code. To realize our model, we introduce Vistrates, a literate computing platform for developing, assembling, and sharing visualization components. From a visualization perspective, Vistrates features cross-cutting components for visual representations, interaction, collaboration, and device responsiveness maintained in a component repository. From a development perspective, Vistrates offers a collaborative programming environment where novices and experts alike can compose component pipelines for specific analytical activities. Finally, we present several Vistrates use cases that span the full range of the classic “anytime” and “anywhere” motto for ubiquitous analysis: from mobile and on-the-go usage, through office settings, to collaborative smart environments covering a variety of tasks and devices..",Sriram Karthik Badam;Andreas Mathisen;Roman Rädle;Clemens Nylandsted Klokmose;Niklas Elmqvist,Sriram Karthik Badam;Andreas Mathisen;Roman Rädle;Clemens N. Klokmose;Niklas Elmqvist,"University of Maryland at College Park, College Park, MD, US;Aarhus Universitet, Aarhus, DK;Aarhus Universitet, Aarhus, DK;Aarhus Universitet, Aarhus, DK;University of Maryland at College Park, College Park, MD, US",10.1109/tvcg.2016.2598647;10.1109/tvcg.2017.2743990;10.1109/tvcg.2009.174;10.1109/tvcg.2011.185;10.1109/tvcg.2017.2745278;10.1109/infvis.2000.885092;10.1109/tvcg.2013.197;10.1109/vast.2007.4389011;10.1109/tvcg.2008.137;10.1109/tvcg.2017.2744019;10.1109/tvcg.2012.204;10.1109/tvcg.2013.191;10.1109/tvcg.2014.2346573;10.1109/tvcg.2013.200;10.1109/tvcg.2014.2346291;10.1109/tvcg.2016.2599030;10.1109/tvcg.2014.2346574;10.1109/infvis.2000.885086;10.1109/tvcg.2009.162;10.1109/tvcg.2007.70577;10.1109/tvcg.2007.70589;10.1109/tvcg.2016.2598647,"Components,literate computing,development,exploration,dissemination,collaboration,heterogeneous devices",43.0,33.0,80.0,903.0,,,creating visualizations;devices adaptive usage;component pipelines specific;anytime motto ubiquitous;provides additional key,0.6631;0.3311;0.2051;0.0697;0.0419,"[np.int64(-1), -1, -1, -1, -1]",106;-1;-1;-1;-1,106,106,Visualization Development
Vis,2005,Illuminated lines revisited,10.1109/visual.2005.1532772,http://dx.doi.org/10.1109/VISUAL.2005.1532772,19.0,26.0,C,"For the rendering of vector and tensor fields, several texture-based volumetric rendering methods were presented in recent years. While they have indisputable merits, the classical vertex-based rendering of integral curves has the advantage of better zooming capabilities as it is not bound to a fixed resolution. It has been shown that lighting can improve spatial perception of lines significantly, especially if lines appear in bundles. Although OpenGL does not directly support lighting of lines, fast rendering of illuminated lines can be achieved by using basic texture mapping. This existing technique is based on a maximum principle which gives a good approximation of specular reflection. Diffuse reflection however is essentially limited to bidirectional lights at infinity. We show how the realism can be further increased by improving diffuse reflection. We present simplified expressions for the Phong/Blinn lighting of infinitesimally thin cylindrical tubes. Based on these, we propose a fast rendering technique with diffuse and specular reflection for orthographic and perspective views and for multiple local and infinite lights. The method requires commonly available programmable vertex and fragment shaders and only two-dimensional lookup textures.",Ovidio Mallo;Ronald Peikert;Christian Sigg;Filip Sadlo,O. Mallo;R. Peikert;C. Sigg;F. Sadlo,"ETH Zürich, Switzerland;ETH Zürich, Switzerland;ETH Zürich, Switzerland;ETH Zürich, Switzerland",10.1109/visual.2004.5;10.1109/visual.2003.1250378;10.1109/visual.2002.1183797;10.1109/visual.1996.567777;10.1109/visual.1997.663912;10.1109/visual.2004.5,"Field lines, illumination, vector field visualization,texture mapping, graphics hardware",101.0,31.0,17.0,567.0,,,rendering illuminated lines;tensor fields;infinitesimally cylindrical;zooming capabilities;blinn,0.6575;0.3327;0.2188;0.1292;0.1020,"[np.int64(-1), -1, -1, -1, -1]",43;-1;-1;-1;-1,43,43,Illustrative Rendering Techniques
VAST,2019,Tac-Simur: Tactic-based Simulative Visual Analytics of Table Tennis,10.1109/tvcg.2019.2934630,http://dx.doi.org/10.1109/TVCG.2019.2934630,407.0,417.0,J,"Simulative analysis in competitive sports can provide prospective insights, which can help improve the performance of players in future matches. However, adequately simulating the complex competition process and effectively explaining the simulation result to domain experts are typically challenging. This work presents a design study to address these challenges in table tennis. We propose a well-established hybrid second-order Markov chain model to characterize and simulate the competition process in table tennis. Compared with existing methods, our approach is the first to support the effective simulation of tactics, which represent high-level competition strategies in table tennis. Furthermore, we introduce a visual analytics system called Tac-Simur based on the proposed model for simulative visual analytics. Tac-Simur enables users to easily navigate different players and their tactics based on their respective performance in matches to identify the player and the tactics of interest for further analysis. Then, users can utilize the system to interactively explore diverse simulation tasks and visually explain the simulation results. The effectiveness and usefulness of this work are demonstrated by two case studies, in which domain experts utilize Tac-Simur to find interesting and valuable insights. The domain experts also provide positive feedback on the usability of Tac-Simur. Our work can be extended to other similar sports such as tennis and badminton.",Jiachen Wang;Kejian Zhao;Dazhen Deng;Anqi Cao;Xiao Xie;Zheng Zhou;Hui Zhang 0051;Yingcai Wu,Jiachen Wang;Kejian Zhao;Dazhen Deng;Anqi Cao;Xiao Xie;Zheng Zhou;Hui Zhang;Yingcai Wu,"State Key Lab of CAD&CG, Zhejiang University;State Key Lab of CAD&CG, Zhejiang University;State Key Lab of CAD&CG, Zhejiang University;State Key Lab of CAD&CG, Zhejiang University;State Key Lab of CAD&CG, Zhejiang University;Department of Sport Science, Zhejiang University;Department of Sport Science, Zhejiang University;State Key Lab of CAD&CG, Zhejiang University",10.1109/vast.2014.7042478;10.1109/tvcg.2016.2598432;10.1109/tvcg.2013.192;10.1109/tvcg.2012.263;10.1109/tvcg.2014.2346445;10.1109/tvcg.2018.2865126;10.1109/tvcg.2017.2744218;10.1109/tvcg.2018.2865041;10.1109/vast.2014.7042478,"Simulative Visual Analytics,Table Tennis,Design Study",45.0,55.0,48.0,1478.0,,,simulative visual analytics;sports tennis;navigate different players;order markov chain;utilize tac,0.5968;0.4178;0.3298;0.2238;0.1164,"[np.int64(-1), -1, -1, -1, -1]",146;-1;-1;-1;-1,146,146,Visualization Techniques
Vis,1994,Visualizing flow over curvilinear grid surfaces using line integral convolution,10.1109/visual.1994.346313,http://dx.doi.org/10.1109/VISUAL.1994.346313,240.0,,C,"Line integral convolution (LIC), introduced by B. Cabral and C. Leedom (1993), is a powerful technique for imaging and animating vector fields. We extend the LIC paradigm in three ways: the existing technique is limited to vector fields over a regular Cartesian grid and we extend it to vector fields over parametric surfaces, specifically those found in curvilinear grids, used in computational fluid dynamics simulations; periodic motion filters can be used to animate the flow visualization, but when the flow lies on a parametric surface, the motion appears misleading, and we explain why this problem arises and show how to adjust the LIC algorithm to handle it; we introduce a technique to visualize vector magnitude as well as vector direction, which is based on varying the frequency of the filter function and we develop a different technique based on kernel phase shifts which we have found to show substantially better results. Implementation of these algorithms utilizes texture-mapping hardware to run in real time, which allows them to be included in interactive applications.&lt;&lt;ETX&gt;&gt;",Lisa K. Forssell,L.K. Forssell,"Computer Sciences Corporation, NASA Ames Research Center, University of Stanford, USA",10.1109/visual.1992.235227;10.1109/visual.1990.146360;10.1109/visual.1991.175771;10.1109/visual.1992.235210;10.1109/visual.1990.146359;10.1109/visual.1993.398846;10.1109/visual.1993.398850;10.1109/visual.1991.175773;10.1109/visual.1992.235226;10.1109/visual.1992.235227,,148.0,35.0,17.0,131.0,BP,,animating vector fields;powerful technique imaging;integral convolution lic;cartesian grid;hardware run,0.6512;0.2833;0.2238;0.1712;0.0471,"[np.int64(-1), -1, -1, -1, -1]",60;-1;-1;-1;-1,60,60,Vector Field Visualization
VAST,2007,Visual Analytics with Jigsaw,10.1109/vast.2007.4389017,http://dx.doi.org/10.1109/VAST.2007.4389017,201.0,202.0,M,This article briefly introduces the Jigsaw system and describes how we used it in analysis activities for the VAST '07 Contest. Jigsaw is a visual analytic system that provides multiple coordinated views to show connections between entities that are extracted from a collection of documents.,Carsten Görg;Zhicheng Liu 0001;Neel Parekh;Kanupriya Singhal;John T. Stasko,Carsten Gorg;Zhicheng Liu;Neel Parekh;Kanupriya Singhal;John Stasko,"School of Interactive Computing, Georgia Institute of Technology;School of Interactive Computing, Georgia Institute of Technology, USA;School of Interactive Computing, Georgia Institute of Technology, USA;School of Interactive Computing, Georgia Institute of Technology, USA;School of Interactive Computing, Georgia Institute of Technology, USA",0.1109/vast.2007.4389006;10.1109/vast.2007.4389034,,21.0,4.0,3.0,236.0,,,jigsaw visual analytic;entities extracted collection;briefly introduces;multiple coordinated;contest,0.6344;0.2442;0.2408;0.1934;0.1899,"[np.int64(-1), -1, -1, -1, -1]",146;-1;-1;-1;-1,146,146,Visualization Techniques
VAST,2006,Accelerating Network Traffic Analytics Using Query-Driven Visualization,10.1109/vast.2006.261437,http://dx.doi.org/10.1109/VAST.2006.261437,115.0,122.0,C,"Realizing operational analytics solutions where large and complex data must be analyzed in a time-critical fashion entails integrating many different types of technology. This paper focuses on an interdisciplinary combination of scientific data management and visualization/analysis technologies targeted at reducing the time required for data filtering, querying, hypothesis testing and knowledge discovery in the domain of network connection data analysis. We show that use of compressed bitmap indexing can quickly answer queries in an interactive visual data analysis application, and compare its performance with two alternatives for serial and parallel filtering/querying on 2.5 billion records' worth of network connection data collected over a period of 42 weeks. Our approach to visual network connection data exploration centers on two primary factors: interactive ad-hoc and multiresolution query formulation and execution over n dimensions and visual display of the n-dimensional histogram results. This combination is applied in a case study to detect a distributed network scan and to then identify the set of remote hosts participating in the attack. Our approach is sufficiently general to be applied to a diverse set of data understanding problems as well as used in conjunction with a diverse set of analysis and visualization tools",E. Wes Bethel;Scott Campbell;Eli Dart;Kurt Stockinger;Kesheng Wu,E. Wes Bethel;Scott Campbell;Eli Dart;Kurt Stockinger;Kesheng Wu,"Computational Research Division and Lawrence Berkeley National Laboratory, University of California, Berkeley, CA;National Energy Research Scientific Computing Center Division and Lawrence Berkeley National Laboratory, University of California, Berkeley, CA, USA;Energy Sciences Network and Lawrence Berkeley National Laboratory, University of California, Berkeley, CA, USA;Computational Research Division and Lawrence Berkeley National Laboratory, University of California, Berkeley, CA, USA;Computational Research Division and Lawrence Berkeley National Laboratory, University of California, Berkeley, CA, USA",10.1109/visual.1999.809930;10.1109/visual.2005.1532792;10.1109/visual.1999.809930,"query-driven visualization, network security, data mining, visual analytics",63.0,21.0,44.0,351.0,,,visualization analysis technologies;data filtering querying;hosts participating attack;indexing quickly answer;operational,0.6179;0.3509;0.2390;0.1778;0.1408,"[np.int64(-1), -1, -1, -1, -1]",109;-1;-1;-1;-1,109,109,Visualization Technologies
Vis,1994,Volume rendering methods for computational fluid dynamics visualization,10.1109/visual.1994.346314,http://dx.doi.org/10.1109/VISUAL.1994.346314,232.0,,C,"The paper describes three alternative volume rendering approaches to visualizing computational fluid dynamics (CFD) data. One new approach uses realistic volumetric gas rendering techniques to produce photo-realistic images and animations from scalar CFD data. The second uses ray casting that is based an a sampler illumination model and is mainly centered around a versatile new tool for the design of transfer functions. The third method employs a simple illumination model and rapid rendering mechanisms to provide efficient preview capabilities. These tools provide a large range of volume rendering capabilities to be used by the CFD explorer to render rapidly for navigation through the data, to emphasize data features (e.g., shock waves) with a specific transfer function, or to present a realistic rendition of the model.&lt;&lt;ETX&gt;&gt;",David S. Ebert;Roni Yagel;James N. Scott;Yair Kurzion,D.S. Ebert;R. Yagel;J. Scott;Y. Kurzion,"Computer Science Department, University of Maryland Baltimore County, Baltimore, MD, USA;Department of Computer and Information Science, Ohio State Uinversity, Columbus, OH, USA;Department of Aeronautical and Astronautical Engineering, Ohio State Uinversity, Columbus, OH, USA;Department of Computer and Information Science, Ohio State Uinversity, Columbus, OH, USA",,,46.0,6.0,18.0,161.0,,,volumetric gas rendering;approaches visualizing computational;dynamics cfd data;tool design transfer;rapid,0.6700;0.4799;0.4447;0.1402;0.0868,"[np.int64(-1), -1, -1, -1, -1]",52;-1;-1;-1;-1,52,52,Volume Rendering Techniques
Vis,2021,Joint t-SNE for Comparable Projections of Multiple High-Dimensional Datasets,10.1109/tvcg.2021.3114765,http://dx.doi.org/10.1109/TVCG.2021.3114765,623.0,632.0,J,"We present Joint t-Stochastic Neighbor Embedding (Joint t-SNE), a technique to generate comparable projections of multiple high-dimensional datasets. Although t-SNE has been widely employed to visualize high-dimensional datasets from various domains, it is limited to projecting a single dataset. When a series of high-dimensional datasets, such as datasets changing over time, is projected independently using t-SNE, misaligned layouts are obtained. Even items with identical features across datasets are projected to different locations, making the technique unsuitable for comparison tasks. To tackle this problem, we introduce edge similarity, which captures the similarities between two adjacent time frames based on the Graphlet Frequency Distribution (GFD). We then integrate a novel loss term into the t-SNE loss function, which we call vector constraints, to preserve the vectors between projected points across the projections, allowing these points to serve as visual landmarks for direct comparisons between projections. Using synthetic datasets whose ground-truth structures are known, we show that Joint t-SNE outperforms existing techniques, including Dynamic t-SNE, in terms of local coherence error, Kullback-Leibler divergence, and neighborhood preservation. We also showcase a real-world use case to visualize and compare the activation of different layers of a neural network.",Yinqiao Wang;Lu Chen;Jaemin Jo;Yunhai Wang,Yinqiao Wang;Lu Chen;Jaemin Jo;Yunhai Wang,"Shandong University, CN, China;Shandong University, CN, China;Sungkyunkwan University, KR, South Korea;Shandong University, CN, China",10.1109/tvcg.2019.2934433;10.1109/tvcg.2015.2467553;10.1109/tvcg.2017.2743858;10.1109/tvcg.2017.2745919;10.1109/tvcg.2018.2864911;10.1109/tvcg.2019.2934433,"High-dimensional data,projection,embedding,t-stochastic neighbor embedding",3.0,14.0,44.0,1108.0,,,stochastic neighbor embedding;visualize compare activation;changing time projected;real world use;misaligned layouts obtained,0.6066;0.3668;0.1352;0.0930;0.0730,"[np.int64(-1), -1, -1, -1, -1]",24;-1;-1;-1;-1,24,24,Embedding Techniques
Vis,2022,DendroMap: Visual Exploration of Large-Scale Image Datasets for Machine Learning with Treemaps,10.1109/tvcg.2022.3209425,http://dx.doi.org/10.1109/TVCG.2022.3209425,320.0,330.0,J,"In this paper, we present DendroMap, a novel approach to interactively exploring large-scale image datasets for machine learning (ML). ML practitioners often explore image datasets by generating a grid of images or projecting high-dimensional representations of images into 2-D using dimensionality reduction techniques (e.g., t-SNE). However, neither approach effectively scales to large datasets because images are ineffectively organized and interactions are insufficiently supported. To address these challenges, we develop DendroMap by adapting Treemaps, a well-known visualization technique. DendroMap effectively organizes images by extracting hierarchical cluster structures from high-dimensional representations of images. It enables users to make sense of the overall distributions of datasets and interactively zoom into specific areas of interests at multiple levels of abstraction. Our case studies with widely-used image datasets for deep learning demonstrate that users can discover insights about datasets and trained models by examining the diversity of images, identifying underperforming subgroups, and analyzing classification errors. We conducted a user study that evaluates the effectiveness of DendroMap in grouping and searching tasks by comparing it with a gridified version of t-SNE and found that participants preferred DendroMap. DendroMap is available at https://div-lab.github.io/dendromap/.",Donald Bertucci;Md Montaser Hamid;Yashwanthi Anand;Anita Ruangrotsakun;Delyar Tabatabai;Melissa Perez;Minsuk Kahng,Donald Bertucci;Md Montaser Hamid;Yashwanthi Anand;Anita Ruangrotsakun;Delyar Tabatabai;Melissa Perez;Minsuk Kahng,"Oregon State University, USA;Oregon State University, USA;Oregon State University, USA;Oregon State University, USA;Oregon State University, USA;Oregon State University, USA;Oregon State University, USA",10.1109/infvis.2005.1532136;10.1109/vast47406.2019.8986948;10.1109/tvcg.2020.3030342;10.1109/tvcg.2013.212;10.1109/tvcg.2013.162;10.1109/tvcg.2014.2346276;10.1109/tvcg.2021.3114855;10.1109/tvcg.2019.2934659;10.1109/tvcg.2017.2744718;10.1109/tvcg.2016.2598445;10.1109/tvcg.2016.2598838;10.1109/tvcg.2016.2598828;10.1109/tvcg.2019.2934619;10.1109/vast47406.2019.8986943;10.1109/tvcg.2007.70515;10.1109/vast.2014.7042476;10.1109/tvcg.2020.3030383;10.1109/tvcg.2021.3114837;10.1109/infvis.2005.1532136,"Visualization for machine learning,image data,treemaps,visual analytics,data-centric AI,error analysis",,12.0,71.0,1004.0,,,explore image datasets;dendromap grouping;high dimensional representations;version sne;ineffectively organized,0.5755;0.3940;0.3516;0.1454;0.1249,"[np.int64(-1), -1, -1, -1, -1]",14;-1;-1;-1;-1,14,14,Image Dataset Comparison
VAST,2020,Integrating Prior Knowledge in Mixed-Initiative Social Network Clustering,10.1109/tvcg.2020.3030347,http://dx.doi.org/10.1109/TVCG.2020.3030347,1775.0,1785.0,J,"We propose a new approach-called PK-clustering-to help social scientists create meaningful clusters in social networks. Many clustering algorithms exist but most social scientists find them difficult to understand, and tools do not provide any guidance to choose algorithms, or to evaluate results taking into account the prior knowledge of the scientists. Our work introduces a new clustering approach and a visual analytics user interface that address this issue. It is based on a process that 1) captures the prior knowledge of the scientists as a set of incomplete clusters, 2) runs multiple clustering algorithms (similarly to clustering ensemble methods), 3) visualizes the results of all the algorithms ranked and summarized by how well each algorithm matches the prior knowledge, 4) evaluates the consensus between user-selected algorithms and 5) allows users to review details and iteratively update the acquired knowledge. We describe our approach using an initial functional prototype, then provide two examples of use and early feedback from social scientists. We believe our clustering approach offers a novel constructive method to iteratively build knowledge while avoiding being overly influenced by the results of often randomly selected black-box clustering algorithms.",Alexis Pister;Paolo Buono;Jean-Daniel Fekete;Catherine Plaisant;Paola Valdivia,Alexis Pister;Paolo Buono;Jean-Daniel Fekete;Catherine Plaisant;Paola Valdivia,"Université Paris-Saclay, CNRS, Inria, LRI, France;University of Bari, Italy;Université Paris-Saclay, CNRS, Inria, LRI, France;Université Paris-Saclay, CNRS, Inria, LRI, France and University of Maryland, USA;Université Paris-Saclay, CNRS, Inria, LRI, France",10.1109/tvcg.2018.2864477;10.1109/vast.2015.7347625;10.1109/tvcg.2014.2346260;10.1109/tvcg.2006.147;10.1109/tvcg.2017.2745178;10.1109/tvcg.2014.2346248;10.1109/tvcg.2014.2346321;10.1109/tvcg.2017.2745078;10.1109/tvcg.2018.2864477,"Social network analysis,network visualization,clustering,mixed-initiative,prior knowledge,user interface",13.0,17.0,58.0,754.0,,,meaningful clusters social;allows users review;method iteratively build;selected black box;overly,0.6658;0.1736;0.0789;0.0668;0.0332,"[np.int64(-1), -1, -1, -1, -1]",31;-1;-1;-1;-1,31,31,Meaningful Clusters
Vis,1999,Interactive lens visualization techniques,10.1109/visual.1999.809882,http://dx.doi.org/10.1109/VISUAL.1999.809882,155.0,521.0,C,"The paper describes new techniques for minimally immersive visualization of 3D scalar and vector fields, and visualization of document corpora. In our glyph based visualization system, the user interacts with the 3D volume of glyphs using a pair of button-enhanced 3D position and orientation trackers. The user may also examine the volume using an interactive lens, which is a rectangle that slices through the 3D volume and displays scalar information on its surface. A lens allows the display of scalar data in the 3D volume using a contour diagram, and a texture based volume rendering.",Christopher D. Shaw;James A. Hall;David S. Ebert;D. Aaron Roberts,C.D. Shaw;J.A. Hall;D.S. Ebert;D.A. Roberts,"Department of Computer Science, University of Regina, Regina, SAS, Canada;Department of Computer Science, University of Regina, Regina, SAS, Canada;Computer Science and Electrical Engineering Department, University of Maryland, Baltimore, MD, USA;NASA Goddard Space Flight Center, Greenbelt, MD, USA",10.1109/visual.1995.485141;10.1109/visual.1996.568109;10.1109/visual.1995.485141,"Volumetric Data, Glyphs, Two-Handed Interfaces, Interactive Volume Rendering, Contour Diagrams, Stereoscopic Field Analyzer SFA, Seed Fill, Over Blending",25.0,7.0,19.0,116.0,,,glyph based visualization;3d scalar vector;fields;user interacts;volume using contour,0.6906;0.3271;0.2116;0.2109;0.2059,"[np.int64(-1), -1, -1, -1, -1]",91;-1;-1;-1;-1,91,91,Wordle Visualizations
VAST,2008,Visual analysis for mutual fund performance,10.1109/vast.2008.4677376,http://dx.doi.org/10.1109/VAST.2008.4677376,181.0,182.0,M,"Mutual funds are one of the most important investment instruments available. However, choosing among mutual funds is not an easy task because they vary in many different dimensions, such as asset size, turnover and fee structure, and these characteristics may affect fund returns. It is thus important to understand the relation between fund performance and these properties. In this work, we use a new visual analytical tool, the density-based distribution map, to assist in this task. By visualizing various important fund characteristics from a real-world database of the US stock funds, our new visual representations greatly help understand the relation between fund characteristics and returns.",Ye Zhao 0003;Jamal Alsakran;Xinlei Zhao,Ye Zhao;Jamal Alsakran;Xinlei Zhao,"Kent University, USA;Kent University, USA;Kent University, USA",,,4.0,0.0,4.0,230.0,,,fund characteristics;visual analytical tool;world database stock;map assist;understand,0.5791;0.4143;0.1960;0.1890;0.1364,"[np.int64(-1), -1, -1, -1, -1]",-1;-1;-1;-1;-1,,-1,Interactive 3D Visualization
Vis,1994,Restorer: a visualization technique for handling missing data,10.1109/visual.1994.346317,http://dx.doi.org/10.1109/VISUAL.1994.346317,212.0,,C,"Pseudocoloring is a frequently used technique in scientific visualization for mapping a color to a data value. When using pseudocolor and animation to visualize data that contain missing regions displayed as black or transparent, the missing regions popping in and out can distract the viewer from the more relevant information. Filling these gaps with interpolated data could lead to a misinterpretation of the data. The paper presents a method for combining pseudocoloring and grayscale in the same colormap. Valid data are mapped to colors in the colormap. The luminance values of the colors bounding areas of missing data are used in interpolating over these regions. The missing data are mapped to the grayscale portion of the colormap. This approach has the advantages of eliminating distracting gaps caused by missing data and distinguishing between those areas that represent valid data and those areas that do not. This approach was inspired by a technique used in the restoration of paintings.&lt;&lt;ETX&gt;&gt;",Ray Twiddy;John Cavallo;Shahram M. Shiri,R. Twiddy;J. Cavallo;S.M. Shiri,"NASA Goddard Space Flight Center, Scientific Visualization Studio, Hughes STX Corporation, Greenbelt, MD, USA;NASA Goddard Space Flight Center, Scientific Visualization Studio, Hughes STX Corporation, Greenbelt, MD, USA;NASA Goddard Space Flight Center, Scientific Visualization Studio, Hughes STX Corporation, Greenbelt, MD, USA",,,39.0,10.0,17.0,214.0,,,pseudocolor animation visualize;luminance values;missing data mapped;bounding areas;frequently used technique,0.6588;0.3134;0.3050;0.1379;0.1353,"[np.int64(-1), -1, -1, -1, -1]",140;-1;-1;-1;-1,140,140,Dynamic Visualization Techniques
InfoVis,2012,Assessing the Effect of Visualizations on Bayesian Reasoning through Crowdsourcing,10.1109/tvcg.2012.199,http://dx.doi.org/10.1109/TVCG.2012.199,2536.0,2545.0,J,"People have difficulty understanding statistical information and are unaware of their wrong judgments, particularly in Bayesian reasoning. Psychology studies suggest that the way Bayesian problems are represented can impact comprehension, but few visual designs have been evaluated and only populations with a specific background have been involved. In this study, a textual and six visual representations for three classic problems were compared using a diverse subject pool through crowdsourcing. Visualizations included area-proportional Euler diagrams, glyph representations, and hybrid diagrams combining both. Our study failed to replicate previous findings in that subjects' accuracy was remarkably lower and visualizations exhibited no measurable benefit. A second experiment confirmed that simply adding a visualization to a textual Bayesian problem is of little help, even when the text refers to the visualization, but suggests that visualizations are more effective when the text is given without numerical values. We discuss our findings and the need for more such experiments to be carried out on heterogeneous populations of non-experts.",Luana Micallef;Pierre Dragicevic;Jean-Daniel Fekete,Luana Micallef;Pierre Dragicevic;Jean-Daniel Fekete,"INRIA and School of Computing, University of Kent, UK;INRIA, France;INRIA, France",10.1109/tvcg.2010.210;10.1109/tvcg.2009.122;10.1109/tvcg.2010.210,"Bayesian reasoning, base rate fallacy, probabilistic judgment, Euler diagrams, glyphs, crowdsourcing",181.0,120.0,58.0,1647.0,HM,,visualization textual bayesian;psychology studies suggest;classic problems compared;area proportional euler;failed replicate,0.6686;0.3116;0.3053;0.1870;-0.0040,"[np.int64(-1), -1, -1, -1, -1]",146;-1;-1;-1;-1,146,146,Visualization Techniques
InfoVis,2019,Decoding a Complex Visualization in a Science Museum – An Empirical Study,10.1109/tvcg.2019.2934401,http://dx.doi.org/10.1109/TVCG.2019.2934401,472.0,481.0,J,"This study describes a detailed analysis of museum visitors' decoding process as they used a visualization designed to support exploration of a large, complex dataset. Quantitative and qualitative analyses revealed that it took, on average, 43 seconds for visitors to decode enough of the visualization to see patterns and relationships in the underlying data represented, and 54 seconds to arrive at their first correct data interpretation. Furthermore, visitors decoded throughout and not only upon initial use of the visualization. The study analyzed think-aloud data to identify issues visitors had mapping the visual representations to their intended referents, examine why they occurred, and consider if and how these decoding issues were resolved. The paper also describes how multiple visual encodings both helped and hindered decoding and concludes with implications on the design and adaptation of visualizations for informal science learning venues.",Joyce Ma;Kwan-Liu Ma;Jennifer Frazier,Joyce Ma;Kwan-Liu Ma;Jennifer Frazier,"Exploratorium, San Francisco;University of California, Davis;Exploratorium, San Francisco",10.1109/tvcg.2012.244;10.1109/tvcg.2008.127;10.1109/tvcg.2015.2467195;10.1109/tvcg.2012.244,"Museums,informal science learning,interactive exhibit,public data visualization,decoding,visual encoding",12.0,5.0,35.0,886.0,,,visualizations informal science;museum visitors decoding;hindered decoding;referents examine occurred;average 43 seconds,0.6521;0.6208;0.2663;0.1247;0.0218,"[np.int64(-1), np.int64(-1), -1, -1, -1]",84;16;-1;-1;-1,16;84,84,Scientific Visualization
Vis,2022,Quick Clusters: A GPU-Parallel Partitioning for Efficient Path Tracing of Unstructured Volumetric Grids,10.1109/tvcg.2022.3209418,http://dx.doi.org/10.1109/TVCG.2022.3209418,537.0,547.0,J,"We propose a simple yet effective method for clustering finite elements to improve preprocessing times and rendering performance of unstructured volumetric grids without requiring auxiliary connectivity data. Rather than building bounding volume hierarchies (BVHs) over individual elements, we sort elements along with a Hilbert curve and aggregate neighboring elements together, improving BVH memory consumption by over an order of magnitude. Then to further reduce memory consumption, we cluster the mesh on the fly into sub-meshes with smaller indices using a series of efficient parallel mesh re-indexing operations. These clusters are then passed to a highly optimized ray tracing API for point containment queries and ray-cluster intersection testing. Each cluster is assigned a maximum extinction value for adaptive sampling, which we rasterize into non-overlapping view-aligned bins allocated along the ray. These maximum extinction bins are then used to guide the placement of samples along the ray during visualization, reducing the number of samples required by multiple orders of magnitude (depending on the dataset), thereby improving overall visualization interactivity. Using our approach, we improve rendering performance over a competitive baseline on the NASA Mars Lander dataset from 6× (1 frame per second (fps) and 1.0 M rays per second (rps) up to now 6 fps and 12.4 M rps, now including volumetric shadows) while simultaneously reducing memory consumption by 3×(33 GB down to 11 GB) and avoiding any offline preprocessing steps, enabling high-quality interactive visualization on consumer graphics cards. Then by utilizing the full 48 GB of an RTX 8000, we improve the performance of Lander by 17 × (1 fps up to 17 fps, 1.0 M rps up to 35.6 M rps).",Nate Morrical;Alper Sahistan;Ugur Güdükbay;Ingo Wald;Valerio Pascucci,Nate Morrical;Alper Sahistan;Uğur Güdükbay;Ingo Wald;Valerio Pascucci,"SCI Institute, University of Utah, USA;Bilkent University, Turkey;Bilkent University, Turkey;NVIDIA, USA;SCI Institute, University of Utah, USA",10.1109/tvcg.2014.2346333;10.1109/tvcg.2011.252;10.1109/tvcg.2011.216;10.1109/tvcg.2021.3114869;10.1109/tvcg.2020.3030470;10.1109/tvcg.2014.2346333,"Ray Tracing,Path Tracing,Volume Rendering,Scientific Visualization,Delta Tracking",,3.0,53.0,897.0,HM,,unstructured volumetric grids;mars lander;cluster intersection;8000 improve performance;finite,0.6338;0.2774;0.2119;0.1304;0.0652,"[np.int64(-1), -1, -1, -1, -1]",74;-1;-1;-1;-1,74,74,3D Surface Extraction
InfoVis,2010,PedVis: A Structured; Space-Efficient Technique for Pedigree Visualization,10.1109/tvcg.2010.185,http://dx.doi.org/10.1109/TVCG.2010.185,1063.0,1072.0,J,"Public genealogical databases are becoming increasingly populated with historical data and records of the current population's ancestors. As this increasing amount of available information is used to link individuals to their ancestors, the resulting trees become deeper and more dense, which justifies the need for using organized, space-efficient layouts to display the data. Existing layouts are often only able to show a small subset of the data at a time. As a result, it is easy to become lost when navigating through the data or to lose sight of the overall tree structure. On the contrary, leaving space for unknown ancestors allows one to better understand the tree's structure, but leaving this space becomes expensive and allows fewer generations to be displayed at a time. In this work, we propose that the H-tree based layout be used in genealogical software to display ancestral trees. We will show that this layout presents an increase in the number of displayable generations, provides a nicely arranged, symmetrical, intuitive and organized fractal structure, increases the user's ability to understand and navigate through the data, and accounts for the visualization requirements necessary for displaying such trees. Finally, user-study results indicate potential for user acceptance of the new layout.",Claurissa Tuttle;Luis Gustavo Nonato;Cláudio T. Silva,Claurissa Tuttle;Luis Gustavo Nonato;Claudio Silva,"University of Utah, USA;Universidade de Sáo Paulo, Brazil;University of Utah, USA",10.1109/tvcg.2008.158;10.1109/tvcg.2008.141;10.1109/infvis.2005.1532124;10.1109/infvis.2003.1249004;10.1109/visual.1991.175815;10.1109/infvis.2002.1173152;10.1109/infvis.2002.1173148;10.1109/infvis.1997.636718;10.1109/tvcg.2008.158,"Genealogy, Pedigree, H-tree",40.0,25.0,35.0,697.0,,,genealogical software display;resulting trees deeper;fractal structure;contrary leaving space;used link,0.7177;0.3849;0.3431;0.0623;0.0186,"[np.int64(-1), -1, -1, -1, -1]",16;-1;-1;-1;-1,16,16,Digital Archive Management
InfoVis,2017,Active Reading of Visualizations,10.1109/tvcg.2017.2745958,http://dx.doi.org/10.1109/TVCG.2017.2745958,770.0,780.0,J,"We investigate whether the notion of active reading for text might be usefully applied to visualizations. Through a qualitative study we explored whether people apply observable active reading techniques when reading paper-based node-link visualizations. Participants used a range of physical actions while reading, and from these we synthesized an initial set of active reading techniques for visualizations. To learn more about the potential impact such techniques may have on visualization reading, we implemented support for one type of physical action from our observations (making freeform marks) in an interactive node-link visualization. Results from our quantitative study of this implementation show that interactive support for active reading techniques can improve the accuracy of performing low-level visualization tasks. Together, our studies suggest that the active reading space is ripe for research exploration within visualization and can lead to new interactions that make for a more flexible and effective visualization reading experience.",Jagoda Walny;Samuel Huron;Charles Perin;Tiffany Wun;Richard Pusch;Sheelagh Carpendale,Jagoda Walny;Samuel Huron;Charles Perin;Tiffany Wun;Richard Pusch;Sheelagh Carpendale,University of Calgary;University of Calgary and Telecom ParisTech;University of London and University of Calgary;University of Calgary;University of Calgary;University of Calgary,10.1109/infvis.2005.1532136;10.1109/tvcg.2011.185;10.1109/tvcg.2015.2467201;10.1109/tvcg.2014.2346984;10.1109/tvcg.2016.2598594;10.1109/infvis.2004.1;10.1109/tvcg.2014.2346435;10.1109/tvcg.2010.164;10.1109/tvcg.2008.141;10.1109/tvcg.2015.2467452;10.1109/tvcg.2015.2467671;10.1109/tvcg.2015.2467195;10.1109/tvcg.2014.2346573;10.1109/tvcg.2015.2467811;10.1109/tvcg.2014.2346422;10.1109/tvcg.2010.179;10.1109/tvcg.2013.164;10.1109/tvcg.2012.189;10.1109/tvcg.2014.2346292;10.1109/tvcg.2014.2346279,"active reading of visualizations,active reading,information visualization,spectrum of physical engagement",35.0,24.0,74.0,1887.0,,,visualization reading experience;type physical action;usefully;based node link;accuracy performing low,0.7349;0.2779;0.1783;0.1560;0.0426,"[np.int64(-1), -1, -1, -1, -1]",94;-1;-1;-1;-1,94,94,Visualization Literacy
Vis,1991,Interactive data visualization using focusing and linking,10.1109/visual.1991.175794,http://dx.doi.org/10.1109/VISUAL.1991.175794,156.0,,C,"Two basic principles for interactive visualization of high-dimensional data-focusing and linking-are discussed. Focusing techniques may involve selecting subsets, dimension reduction, or some more general manipulation of the layout information on the page or screen. A consequent of focusing is that each view only conveys partial information about the data and needs to be linked so that the information contained in individual views can be integrated into a coherent image of the data as a whole. Examples are given of how graphical data analysis methods based on focusing and linking are used in applications including linguistics, geographic information systems, time series analysis, and the analysis of multi-channel images arising in radiology and remote sensing.&lt;&lt;ETX&gt;&gt;",Andreas Buja;John Alan McDonald;J. Michalak;Werner Stuetzle,A. Buja;J.A. McDonald;J. Michalak;W. Stuetzle,"Bellcore, Morristown, NJ, USA;Department of Statistics, University of Washington, Seattle, WA, USA;Department of Statistics, University of Washington, Seattle, WA, USA;Department of Statistics, University of Washington, Seattle, WA, USA",,,2.0,111.0,34.0,1274.0,,,graphical data analysis;focusing linking used;radiology remote sensing;including linguistics;high,0.6799;0.3517;0.2385;0.1981;-0.0036,"[np.int64(-1), -1, -1, -1, -1]",96;-1;-1;-1;-1,96,96,Graph Visualization
Vis,1990,Parallel coordinates: a tool for visualizing multi-dimensional geometry,10.1109/visual.1990.146402,http://dx.doi.org/10.1109/VISUAL.1990.146402,361.0,378.0,C,"A methodology for visualizing analytic and synthetic geometry in R/sup N/ is presented. It is based on a system of parallel coordinates which induces a nonprojective mapping between N-dimensional and two-dimensional sets. Hypersurfaces are represented by their planar images which have some geometrical properties analogous to the properties of the hypersurface that they represent. A point from to line duality when N=2 generalizes to lines and hyperplanes enabling the representation of polyhedra in R/sup N/. The representation of a class of convex and non-convex hypersurfaces is discussed, together with an algorithm for constructing and displaying any interior point. The display shows some local properties of the hypersurface and provides information on the point's proximity to the boundary. Applications are discussed.&lt;&lt;ETX&gt;&gt;",Alfred Inselberg;Bernard Dimsdale,A. Inselberg;B. Dimsdale,"IBM Scientific Center, Los Angeles, CA, USA and Department of Computer Sciences, University of Southern California, Los Angeles, CA, USA;IBM Scientific Center, Los Angeles, CA, USA",,,1746.0,407.0,47.0,1296.0,,,hypersurfaces represented;geometry sup;algorithm constructing displaying;analytic;interior point,0.6400;0.4024;0.2327;0.2313;0.1934,"[np.int64(-1), -1, -1, -1, -1]",61;-1;-1;-1;-1,61,61,Geometric Data Representation
Vis,2006,Distributed Shared Memory for Roaming Large Volumes,10.1109/tvcg.2006.135,http://dx.doi.org/10.1109/TVCG.2006.135,1299.0,1306.0,J,"We present a cluster-based volume rendering system for roaming very large volumes. This system allows to move a gigabyte-sized probe inside a total volume of several tens or hundreds of gigabytes in real-time. While the size of the probe is limited by the total amount of texture memory on the cluster, the size of the total data set has no theoretical limit. The cluster is used as a distributed graphics processing unit that both aggregates graphics power and graphics memory. A hardware-accelerated volume renderer runs in parallel on the cluster nodes and the final image compositing is implemented using a pipelined sort-last rendering algorithm. Meanwhile, volume bricking and volume paging allow efficient data caching. On each rendering node, a distributed hierarchical cache system implements a global software-based distributed shared memory on the cluster. In case of a cache miss, this system first checks page residency on the other cluster nodes instead of directly accessing local disks. Using two gigabit Ethernet network interfaces per node, we accelerate data fetching by a factor of 4 compared to directly accessing local disks. The system also implements asynchronous disk access and texture loading, which makes it possible to overlap data loading, volume slicing and rendering for optimal volume roaming",Laurent Castanie;Christophe Mion;Xavier Cavin;Bruno Lévy 0001,Laurent Castanie;Christophe Mion;Xavier Cavin;Bruno Levy,"ALICE Group, INRIA, Lorraine, Nancy, France;ALICE Group, INRIA, Lorraine, Nancy, France;ALICE Group, INRIA, Lorraine, Nancy, France;ALICE Group, INRIA, Lorraine, Nancy, France",10.1109/visual.2005.1532794;10.1109/visual.1997.663888;10.1109/visual.2005.1532785;10.1109/visual.2005.1532802;10.1109/visual.2005.1532794,"Large volumes, volume roaming, out-of-core, hierarchical caching, distributed shared memory, hardware-accelerated volume visualization, graphics hardware, parallel rendering, graphics cluster",23.0,12.0,38.0,365.0,,,distributed graphics processing;disk access texture;cluster size total;paging;bricking volume,0.5999;0.3929;0.2883;0.2304;0.1940,"[np.int64(-1), -1, -1, -1, -1]",48;-1;-1;-1;-1,48,48,Scalable Graphics Processing
InfoVis,2002,"Internet traffic: visualization, discovery, and very large displays",10.1109/infvis.2002.1173140,http://dx.doi.org/10.1109/INFVIS.2002.1173140,3.0,4.0,M,"For a decade, the ruling common wisdom for Internet traffic held that it was everywhere bursty: over periods lasting tens of milliseconds to hundreds, the traffic was either much below its average rate or much above. In other words, the traffic was not smooth, not staying at all times close to its average. It was bursty on the cable running down a street, carrying the merged traffic of a small number of cable modem users in one section of a town. It was bursty on the core fiber of an Internet service provider, carrying the merged traffic of thousands of users from all over the country. The Internet was designed to accommodate the bursty traffic. The routers and switches that forward traffic from one place to the next were designed for burstiness, and Internet service providers allocated traffic loads on the devices based on an assumption of burstiness. Recently, it was discovered that the old common wisdom is not true. Visualization played a fundamental role in the discovery. The old wisdom held up for links with a small numbers of users. But as the number of users increases, the burstiness dissipates, and the traffic becomes smooth. Design of the high-load part of the Internet needs to be rethought. The old wisdom had persisted for high-load links because the databases of traffic measurements from them are immense, and the traffic measurements had not been studied in their fullest detail, which is necessary to see the smoothing. Visualization tools allowed the detail to be seen, and allowed the verification of a mathematical theory that predicts the smoothing. To see the detail, individual visual displays were created that take up an amount of virtual screen real estate measured in hundreds of pages. It is a simple idea: if you have a lot of data, and you want to see it in detail, you need a lot of space. What is needed now is a rich set of ideas and methods for navigating such very large displays.",William S. Cleveland,W.S. Cleveland,"Statistics Research Bell Laboratories, USA",,,1.0,0.0,0.0,179.0,,,designed burstiness internet;visualization tools;measured hundreds;fundamental role;discovered old common,0.7266;0.2822;0.1915;0.0709;0.0657,"[np.int64(-1), -1, -1, -1, -1]",6;-1;-1;-1;-1,6,6,Geospatial Data Analysis
Vis,2007,Efficient Surface Reconstruction using Generalized Coulomb Potentials,10.1109/tvcg.2007.70553,http://dx.doi.org/10.1109/TVCG.2007.70553,1512.0,1519.0,J,"We propose a novel, geometrically adaptive method for surface reconstruction from noisy and sparse point clouds, without orientation information. The method employs a fast convection algorithm to attract the evolving surface towards the data points. The force field in which the surface is convected is based on generalized Coulomb potentials evaluated on an adaptive grid (i.e., an octree) using a fast, hierarchical algorithm. Formulating reconstruction as a convection problem in a velocity field generated by Coulomb potentials offers a number of advantages. Unlike methods which compute the distance from the data set to the implicit surface, which are sensitive to noise due to the very reliance on the distance transform, our method is highly resilient to shot noise since global, generalized Coulomb potentials can be used to disregard the presence of outliers due to noise. Coulomb potentials represent long-range interactions that consider all data points at once, and thus they convey global information which is crucial in the fitting process. Both the spatial and temporal complexities of our spatially-adaptive method are proportional to the size of the reconstructed object, which makes our method compare favorably with respect to previous approaches in terms of speed and flexibility. Experiments with sparse as well as noisy data sets show that the method is capable of delivering crisp and detailed yet smooth surfaces.",Andrei C. Jalba;Jos B. T. M. Roerdink,Andrei C. Jalba;Jos B.T.M. Roerdink,"Institute for Mathematics and Computing Science, University of Groningam, Netherlands;Institute for Mathematics and Computing Science, University of Groningam, Netherlands",,"Surface reconstruction, Implicit surfaces, Octrees, Generalized Coulomb potentials, Polygonization",30.0,14.0,31.0,252.0,,,surface reconstruction;points force field;noise coulomb potentials;convection problem velocity;method highly resilient,0.5867;0.2872;0.2815;0.1798;0.0915,"[np.int64(-1), -1, -1, -1, -1]",76;-1;-1;-1;-1,76,76,Surface Reconstruction Techniques
Vis,2002,Visibility-guided simplification,10.1109/visual.2002.1183784,http://dx.doi.org/10.1109/VISUAL.2002.1183784,267.0,274.0,C,"For some graphics applications, object interiors and hard-to-see regions contribute little to the final images and need not be processed. In this paper, we define a view-independent visibility measure on mesh surfaces based on the visibility function between the surfaces and a surrounding sphere of cameras. We demonstrate the usefulness of this measure with a visibility-guided simplification algorithm. Mesh simplification reduces the polygon counts of 3D models and speeds up the rendering process. Many mesh simplification algorithms are based on sequences of edge collapses that minimize geometric and attribute errors. By combining the surface visibility measure with a geometric error measure, we obtain simplified models with improvement proportional to the number of low visibility regions in the original models.",Eugene Zhang;Greg Turk,E. Zhang;G. Turk,"College of Computing, Georgia Institute of Technology, GVU Center, USA;College of Computing, Georgia Institute of Technology, GVU Center, USA",10.1109/visual.1999.809869;10.1109/visual.2000.885723;10.1109/visual.1999.809869,"Visualization, Visibility, Mesh Simplification, Rendering",72.0,14.0,28.0,179.0,,,mesh simplification algorithms;surface visibility;define view independent;processed paper define;counts,0.6766;0.5100;0.1760;0.0761;0.0399,"[np.int64(-1), np.int64(-1), -1, -1, -1]",79;141;-1;-1;-1,79;141,79,Mesh Simplification Techniques
VAST,2015,Supporting Iterative Cohort Construction with Visual Temporal Queries,10.1109/tvcg.2015.2467622,http://dx.doi.org/10.1109/TVCG.2015.2467622,91.0,100.0,J,"Many researchers across diverse disciplines aim to analyze the behavior of cohorts whose behaviors are recorded in large event databases. However, extracting cohorts from databases is a difficult yet important step, often overlooked in many analytical solutions. This is especially true when researchers wish to restrict their cohorts to exhibit a particular temporal pattern of interest. In order to fill this gap, we designed COQUITO, a visual interface that assists users defining cohorts with temporal constraints. COQUITO was designed to be comprehensible to domain experts with no preknowledge of database queries and also to encourage exploration. We then demonstrate the utility of COQUITO via two case studies, involving medical and social media researchers.",Josua Krause;Adam Perer;Harry Stavropoulos,Josua Krause;Adam Perer;Harry Stavropoulos,NYU;IBM T.J. Watson Research Center;IBM T.J. Watson Research Center,10.1109/tvcg.2011.185;10.1109/vast.2007.4389013;10.1109/vast.2006.261421;10.1109/tvcg.2014.2346682;10.1109/vast.2010.5652890;10.1109/tvcg.2014.2346482;10.1109/tvcg.2013.200;10.1109/tvcg.2013.206;10.1109/tvcg.2009.117;10.1109/infvis.2001.963273;10.1109/tvcg.2012.225;10.1109/tvcg.2013.167;10.1109/tvcg.2011.185,"Visual temporal queries, cohort definition, electronic medical records, information visualization",91.0,66.0,44.0,1021.0,,,users defining cohorts;event databases extracting;encourage exploration demonstrate;coquito visual;wish,0.6543;0.3514;0.3139;0.2251;0.0739,"[np.int64(-1), -1, -1, -1, -1]",25;-1;-1;-1;-1,25,25,Data Interpretation Challenges
Vis,2021,Communicating Visualizations without Visuals: Investigation of Visualization Alternative Text for People with Visual Impairments,10.1109/tvcg.2021.3114846,http://dx.doi.org/10.1109/TVCG.2021.3114846,1095.0,1105.0,J,"Alternative text is critical in communicating graphics to people who are blind or have low vision. Especially for graphics that contain rich information, such as visualizations, poorly written or an absence of alternative texts can worsen the information access inequality for people with visual impairments. In this work, we consolidate existing guidelines and survey current practices to inspect to what extent current practices and recommendations are aligned. Then, to gain more insight into what people want in visualization alternative texts, we interviewed 22 people with visual impairments regarding their experience with visualizations and their information needs in alternative texts. The study findings suggest that participants actively try to construct an image of visualizations in their head while listening to alternative texts and wish to carry out visualization tasks (e.g., retrieve specific values) as sighted viewers would. The study also provides ample support for the need to reference the underlying data instead of visual elements to reduce users' cognitive burden. Informed by the study, we provide a set of recommendations to compose an informative alternative text.",Crescentia Jung;Shubham Mehta;Atharva Kulkarni;Yuhang Zhao 0001;Yea-Seul Kim,Crescentia Jung;Shubham Mehta;Atharva Kulkarni;Yuhang Zhao;Yea-Seul Kim,"University of Wisconsin-Madison, United States;University of Wisconsin-Madison, United States;University of Wisconsin-Madison, United States;University of Wisconsin-Madison, United States;University of Wisconsin-Madison, United States",10.1109/tvcg.2020.3030378;10.1109/tvcg.2018.2865237;10.1109/tvcg.2020.3030378,"accessible visualization,assistive technologies,alternative text for graphics",19.0,36.0,91.0,1903.0,HM,,graphics people blind;informative alternative text;construct;22;tasks retrieve specific,0.6940;0.4303;0.1038;-0.0115;-0.0821,"[np.int64(-1), -1, -1, -1, -1]",-1;-1;-1;-1;-1,,-1,Interactive 3D Visualization
Vis,2024,DG Comics: Semi-Automatically Authoring Graph Comics for Dynamic Graphs,10.1109/tvcg.2024.3456340,http://dx.doi.org/10.1109/TVCG.2024.3456340,973.0,983.0,J,"Comics are an effective method for sequential data-driven storytelling, especially for dynamic graphs—graphs whose vertices and edges change over time. However, manually creating such comics is currently time-consuming, complex, and error-prone. In this paper, we propose DG COMICS, a novel comic authoring tool for dynamic graphs that allows users to semi-automatically build and annotate comics. The tool uses a newly developed hierarchical clustering algorithm to segment consecutive snapshots of dynamic graphs while preserving their chronological order. It also presents rich information on both individuals and communities extracted from dynamic graphs in multiple views, where users can explore dynamic graphs and choose what to tell in comics. For evaluation, we provide an example and report the results of a user study and an expert review.",Joohee Kim;Hyunwook Lee;Duc M. Nguyen;Minjeong Shin;Bum Chul Kwon;Sungahn Ko;Niklas Elmqvist,Joohee Kim;Hyunwook Lee;Duc M. Nguyen;Minjeong Shin;Bum Chul Kwon;Sungahn Ko;Niklas Elmqvist,"UNIST (Ulsan National Institute of Science and Technology), Korea;UNIST (Ulsan National Institute of Science and Technology), Korea;UNIST (Ulsan National Institute of Science and Technology), Korea;UNIST (Ulsan National Institute of Science and Technology), Korea;IBM Research, USA;UNIST (Ulsan National Institute of Science and Technology), Korea;Aarhus University, Denmark",10.1109/tvcg.2010.159;10.1109/tvcg.2011.185;10.1109/tvcg.2020.3030398;10.1109/tvcg.2009.122;10.1109/tvcg.2013.198;10.1109/tvcg.2006.160;10.1109/tvcg.2007.70582;10.1109/tvcg.2022.3209384;10.1109/tvcg.2013.119;10.1109/infvis.2002.1173148;10.1109/tvcg.2010.179;10.1109/tvcg.2015.2468078;10.1109/tvcg.2018.2865232;10.1109/tvcg.2020.3030433;10.1109/tvcg.2021.3114849,"Data-driven storytelling,narrative visualization,,,dynamic graphs,graph comics",,0.0,86.0,185.0,,,data driven storytelling;manually creating comics;hierarchical clustering algorithm;edges change time;complex error,0.5969;0.4829;0.3695;0.1960;-0.0348,"[np.int64(-1), -1, -1, -1, -1]",133;-1;-1;-1;-1,133,133,Storytelling with Data
VAST,2019,explAIner: A Visual Analytics Framework for Interactive and Explainable Machine Learning,10.1109/tvcg.2019.2934629,http://dx.doi.org/10.1109/TVCG.2019.2934629,1064.0,1074.0,J,"We propose a framework for interactive and explainable machine learning that enables users to (1) understand machine learning models; (2) diagnose model limitations using different explainable AI methods; as well as (3) refine and optimize the models. Our framework combines an iterative XAI pipeline with eight global monitoring and steering mechanisms, including quality monitoring, provenance tracking, model comparison, and trust building. To operationalize the framework, we present explAIner, a visual analytics system for interactive and explainable machine learning that instantiates all phases of the suggested pipeline within the commonly used TensorBoard environment. We performed a user-study with nine participants across different expertise levels to examine their perception of our workflow and to collect suggestions to fill the gap between our system and framework. The evaluation confirms that our tightly integrated system leads to an informed machine learning process while disclosing opportunities for further extensions.",Thilo Spinner;Udo Schlegel;Hanna Schäfer;Mennatallah El-Assady,Thilo Spinner;Udo Schlegel;Hanna Schäfer;Mennatallah El-Assady,University of Konstanz;University of Konstanz;University of Konstanz;University of Konstanz,10.1109/tvcg.2017.2744683;10.1109/tvcg.2019.2934654;10.1109/tvcg.2017.2745080;10.1109/tvcg.2018.2864769;10.1109/tvcg.2017.2744718;10.1109/vast.2017.8585720;10.1109/vast.2018.8802509;10.1109/tvcg.2017.2744938;10.1109/tvcg.2016.2598831;10.1109/tvcg.2018.2864812;10.1109/tvcg.2017.2744358;10.1109/tvcg.2016.2598838;10.1109/tvcg.2014.2346481;10.1109/tvcg.2018.2864838;10.1109/tvcg.2018.2865044;10.1109/tvcg.2017.2744158;10.1109/tvcg.2018.2864504;10.1109/tvcg.2017.2744878;10.1109/tvcg.2018.2864499;10.1109/tvcg.2018.2864475;10.1109/vast.2017.8585721;10.1109/tvcg.2017.2744683,"Explainable AI,Interactive Machine Learning,Deep Learning,Visual Analytics,Interpretability,Explainability",143.0,96.0,86.0,7075.0,,,explainable machine learning;commonly used tensorboard;framework evaluation confirms;workflow collect;different,0.7307;0.2816;0.2352;0.1021;0.0171,"[np.int64(-1), -1, -1, -1, -1]",13;-1;-1;-1;-1,13,13,Advanced Machine Learning
InfoVis,2017,Modeling Color Difference for Visualization Design,10.1109/tvcg.2017.2744359,http://dx.doi.org/10.1109/TVCG.2017.2744359,392.0,401.0,J,"Color is frequently used to encode values in visualizations. For color encodings to be effective, the mapping between colors and values must preserve important differences in the data. However, most guidelines for effective color choice in visualization are based on either color perceptions measured using large, uniform fields in optimal viewing environments or on qualitative intuitions. These limitations may cause data misinterpretation in visualizations, which frequently use small, elongated marks. Our goal is to develop quantitative metrics to help people use color more effectively in visualizations. We present a series of crowdsourced studies measuring color difference perceptions for three common mark types: points, bars, and lines. Our results indicate that peoples' abilities to perceive color differences varies significantly across mark types. Probabilistic models constructed from the resulting data can provide objective guidance for designers, allowing them to anticipate viewer perceptions in order to inform effective encoding design.",Danielle Albers Szafir,Danielle Albers Szafir,University of Colorado,10.1109/visual.1995.480803;10.1109/tvcg.2011.185;10.1109/tvcg.2010.154;10.1109/tvcg.2014.2346978;10.1109/tvcg.2016.2598918;10.1109/visual.1996.568118;10.1109/tvcg.2011.194;10.1109/tvcg.2012.279;10.1109/tvcg.2016.2599106;10.1109/tvcg.2016.2599030;10.1109/tvcg.2008.118;10.1109/visual.1995.480803,"Color Perception,Graphical Perception,Color Models,Crowdsourcing",133.0,117.0,55.0,3773.0,BP,,color effectively visualizations;crowdsourced studies measuring;bars lines results;used encode values;types points,0.6930;0.4336;0.2647;0.2129;0.2076,"[np.int64(-1), -1, -1, -1, -1]",131;-1;-1;-1;-1,131,131,Visual Aesthetics
SciVis,2015,PathlinesExplorer ??? Image-based exploration of large-scale pathline fields,10.1109/scivis.2015.7429512,http://dx.doi.org/10.1109/SciVis.2015.7429512,159.0,160.0,M,"PathlinesExplorer is a novel image-based tool, which has been designed to visualize large scale pathline fields on a single computer [7]. PathlinesExplorer integrates explorable images (EI) technique [4] with order-independent transparency (OIT) method [2]. What makes this method different is that it allows users to handle large data on a single workstation. Although it is a view-dependent method, PathlinesExplorer combines both exploration and modification of visual aspects without re-accessing the original huge data. Our approach is based on constructing a per-pixel linked list data structure in which each pixel contains a list of pathline segments. With this view-dependent method, it is possible to filter, color-code, and explore large-scale flow data in real-time. In addition, optimization techniques such as early-ray termination and deferred shading are applied, which further improves the performance and scalability of our approach.",Omniah H. Nagoor;Markus Hadwiger;Madhusudhanan Srinivasan,Omniah H. Nagoor;Markus Hadwiger;Madhusudhanan Srinivasan,KAUST;KAUST;KAUST,,,0.0,0.0,7.0,113.0,,,large scale pathline;exploration modification visual;transparency oit;list data;technique order,0.5781;0.3914;0.2812;0.1481;0.1146,"[np.int64(-1), -1, -1, -1, -1]",126;-1;-1;-1;-1,126,126,Geometric Mesh Processing
InfoVis,2014,PanoramicData: Data Analysis through Pen & Touch,10.1109/tvcg.2014.2346293,http://dx.doi.org/10.1109/TVCG.2014.2346293,2112.0,2121.0,J,"Interactively exploring multidimensional datasets requires frequent switching among a range of distinct but inter-related tasks (e.g., producing different visuals based on different column sets, calculating new variables, and observing the interactions between sets of data). Existing approaches either target specific different problem domains (e.g., data-transformation or data-presentation) or expose only limited aspects of the general exploratory process; in either case, users are forced to adopt coping strategies (e.g., arranging windows or using undo as a mechanism for comparison instead of using side-by-side displays) to compensate for the lack of an integrated suite of exploratory tools. PanoramicData (PD) addresses these problems by unifying a comprehensive set of tools for visual data exploration into a hybrid pen and touch system designed to exploit the visualization advantages of large interactive displays. PD goes beyond just familiar visualizations by including direct UI support for data transformation and aggregation, filtering and brushing. Leveraging an unbounded whiteboard metaphor, users can combine these tools like building blocks to create detailed interactive visual display networks in which each visualization can act as a filter for others. Further, by operating directly on relational-databases, PD provides an approachable visual language that exposes a broad set of the expressive power of SQL including functionally complete logic filtering, computation of aggregates and natural table joins. To understand the implications of this novel approach, we conducted a formative user study with both data and visualization experts. The results indicated that the system provided a fluid and natural user experience for probing multi-dimensional data and was able to cover the full range of queries that the users wanted to pose.",Emanuel Zgraggen;Robert C. Zeleznik;Steven Mark Drucker,Emanuel Zgraggen;Robert Zeleznik;Steven M. Drucker,Brown University;Brown University;Microsoft Research,10.1109/infvis.2000.885086;10.1109/tvcg.2009.162;10.1109/tvcg.2010.164;10.1109/tvcg.2011.251;10.1109/tvcg.2013.191;10.1109/tvcg.2012.275;10.1109/vast.2007.4389013;10.1109/tvcg.2013.150;10.1109/tvcg.2007.70521;10.1109/tvcg.2008.137;10.1109/infvis.2005.1532136;10.1109/tvcg.2007.70594;10.1109/tvcg.2012.204,"Visual analytics, pen and touch, user interfaces, interaction design, coordinated and multiple views",50.0,34.0,38.0,977.0,,,data visualization experts;hybrid pen touch;sql including functionally;unbounded;adopt coping strategies,0.6776;0.2287;0.1924;0.0391;-0.0052,"[np.int64(-1), -1, -1, -1, -1]",97;-1;-1;-1;-1,97,97,Data Visualization
Vis,1999,Hue-balls and lit-tensors for direct volume rendering of diffusion tensor fields,10.1109/visual.1999.809886,http://dx.doi.org/10.1109/VISUAL.1999.809886,183.0,524.0,C,"With the development of magnetic resonance imaging techniques for acquiring diffusion tensor data from biological tissue, visualization of tensor data has become a new research focus. The diffusion tensor describes the directional dependence of water molecules' diffusion and can be represented by a three-by-three symmetric matrix. Visualization of second-order tensor fields is difficult because the data values have many degrees of freedom. Existing visualization techniques are best at portraying the tensor's properties over a two-dimensional field, or over a small subset of locations within a three-dimensional field. A means of visualizing the global structure in measured diffusion tensor data is needed. We propose the use of direct volume rendering, with novel approaches for the tensors' coloring, lighting, and opacity assignment. Hue-balls use a two-dimensional colormap on the unit sphere to illustrate the tensor's action as a linear operator. Lit-tensors provide a lighting model for tensors which includes as special cases both lit-lines (from streamline vector visualization) and standard Phong surface lighting. Together with an opacity assignment based on a novel two-dimensional barycentric space of anisotropy, these methods are shown to produce informative renderings of measured diffusion tensor data from the human brain.",Gordon L. Kindlmann;David M. Weinstein,G. Kindlmann;D. Weinstein,"Scientific Computing and Imaging, Department of Computer Science, University of Utah, USA;Scientific Computing and Imaging, Department of Computer Science, University of Utah, USA",10.1109/visual.1990.146373;10.1109/visual.1992.235193;10.1109/visual.1996.567777;10.1109/visual.1998.745294;10.1109/visual.1990.146373,,143.0,48.0,22.0,115.0,BP,,tissue visualization tensor;coloring lighting opacity;dependence water molecules;linear operator lit;cases,0.6826;0.2823;0.1955;0.0931;0.0021,"[np.int64(-1), -1, -1, -1, -1]",40;-1;-1;-1;-1,40,40,Tensor MRI Visualization
Vis,2002,Case study: Visual debugging of finite element codes,10.1109/visual.2002.1183819,http://dx.doi.org/10.1109/VISUAL.2002.1183819,517.0,520.0,C,"We present an innovative application developed at Sandia National Laboratories for visual debugging of unstructured finite element physics codes. Our tool automatically locates anomalous regions, such as inverted elements or nodes whose variable values lie outside a prescribed range, then extracts mesh subsets around these features for detailed examination. The subsets are viewed using color coding of variable values superimposed on the mesh structure. This allows the values and their relative spatial locations within the mesh to be correlated at a glance. Both topological irregularities and hot spots within the data stand out visually, allowing the user to explore the exact numeric values of the grid at surrounding points over time. We demonstrate the utility of this approach by debugging a cell inversion in a simulation of an exploding wire.",Patricia Crossno;David H. Rogers 0001;Christopher J. Garasi,P. Crossno;D.H. Rogers;C.J. Garasi,"Sandia National Laboratories, Albuquerque, NM, USA;Sandia National Laboratories, Albuquerque, NM, USA;Sandia National Laboratories, Albuquerque, NM, USA",10.1109/visual.1999.809919;10.1109/visual.2001.964543;10.1109/visual.1999.809919,"visual debugging, parallel finite element codes and simulations",10.0,5.0,9.0,86.0,,,visual debugging unstructured;element physics codes;mesh correlated;exploding wire;points time,0.6117;0.4480;0.3673;0.3283;-0.0530,"[np.int64(-1), -1, -1, -1, -1]",146;-1;-1;-1;-1,146,146,Visualization Techniques
Vis,1996,Generation of Transfer Functions with Stochastic Search Technique,10.1109/visual.1996.568113,http://dx.doi.org/10.1109/VISUAL.1996.568113,227.0,234.0,C,"This paper presents a novel approach to assist the user in exploring appropriate transfer functions for the visualization of volumetric datasets. The search for a transfer function is treated as a parameter optimization problem and addressed with stochastic search techniques. Starting from an initial population of (random or pre-defined) transfer functions, the evolution of the stochastic algorithms is controlled by either direct user selection of intermediate images or automatic fitness evaluation using user-specified objective functions. This approach essentially shields the user from the complex and tedious ""trial and error"" approach, and demonstrates effective and convenient generation of transfer functions.",Taosong He;Lichan Hong;Arie E. Kaufman;Hanspeter Pfister,Taosong He;Lichan Hong;A. Kaufman;H. Pfister,"Department of Computer Science
State University of New York at Stony Brook, Stony Brook, NY;State University of New York at Stony Brook, Stony Brook, NY;State University of New York at Stony Brook, Stony Brook, NY;State University of New York at Stony Brook, Stony Brook, NY",,,342.0,7.0,0.0,200.0,,,visualization volumetric datasets;transfer functions evolution;search techniques starting;images automatic;user specified,0.5504;0.3922;0.2734;0.2519;0.1449,"[np.int64(-1), -1, -1, -1, -1]",55;-1;-1;-1;-1,55,55,Volumetric Data Visualization
Vis,2002,Interactive visualization of complex plant ecosystems,10.1109/visual.2002.1183778,http://dx.doi.org/10.1109/VISUAL.2002.1183778,219.0,226.0,C,"We present a method for interactive rendering of large outdoor scenes. Complex polygonal plant models and whole plant populations are represented by relatively small sets of point and line primitives. This enables us to show landscapes faithfully using only a limited percentage of primitives. In addition, a hierarchical data structure allows us to smoothly reduce the geometrical representation to any desired number of primitives. The scene is hierarchically divided into local portions of geometry to achieve large reduction factors for distant regions. Additionally, the data reduction is adapted to the visual importance of geometric objects. This allows us to maintain the visual fidelity of the representation while reducing most of the geometry drastically. With our system, we are able to interactively render very complex landscapes with good visual quality.",Oliver Deussen;Carsten Colditz;Marc Stamminger;George Drettakis,O. Deussen;C. Colditz;M. Stamminger;G. Drettakis,"Faculty of Computer Science, Dresden University of Technology, Germany;Faculty of Computer Science, Dresden University of Technology, Germany;Bauhaus Universitat Weimar, Germany;Sophia Antipolis, REVES/INRIA, France",10.1109/visual.1997.663860;10.1109/visual.2001.964491;10.1109/visual.2001.964492;10.1109/visual.1997.663860,"Synthetic Plants, Ecosystems, Point-based rendering, Level-of-detail Algorithms",261.0,33.0,24.0,313.0,,,render complex landscapes;data reduction;number primitives;drastically;sets point line,0.6706;0.2678;0.1492;0.1162;0.0363,"[np.int64(-1), -1, -1, -1, -1]",132;-1;-1;-1;-1,132,132,Geographic Visualization Techniques
Vis,2005,The magic volume lens: an interactive focus+context technique for volume rendering,10.1109/visual.2005.1532818,http://dx.doi.org/10.1109/VISUAL.2005.1532818,367.0,374.0,C,"The size and resolution of volume datasets in science and medicine are increasing at a rate much greater than the resolution of the screens used to view them. This limits the amount of data that can be viewed simultaneously, potentially leading to a loss of overall context of the data when the user views or zooms into a particular area of interest. We propose a focus+context framework that uses various standard and advanced magnification lens rendering techniques to magnify the features of interest, while compressing the remaining volume regions without clipping them away completely. Some of these lenses can be interactively configured by the user to specify the desired magnification patterns, while others are feature-adaptive. All our lenses are accelerated on the GPU. They allow the user to interactively manage the available screen area, dedicating more area to the more resolution-important features.",Lujin Wang;Ye Zhao 0004;Klaus Mueller 0001;Arie E. Kaufman,L. Wang;Y. Zhao;K. Mueller;A. Kaufman,"Center for Visual Computing, Computer Science, Stony Brook University, USA;Center for Visual Computing, Computer Science, Stony Brook University, USA;Center for Visual Computing, Computer Science, Stony Brook University, USA;Center for Visual Computing, Computer Science, Stony Brook University, USA",10.1109/infvis.1997.636786;10.1109/infvis.1996.559215;10.1109/infvis.1996.559214;10.1109/visual.2001.964552;10.1109/visual.2003.1250386;10.1109/visual.2003.1250384;10.1109/visual.2004.48;10.1109/visual.2003.1250400;10.1109/visual.2000.885697;10.1109/infvis.1997.636786,"Focus+Context Techniques,Lens,Volume Rendering, Hardware-assisted Volume Rendering",186.0,28.0,25.0,636.0,,,rendering techniques magnify;remaining volume regions;science medicine;gpu allow;context data user,0.6037;0.3386;0.2320;0.2275;0.1354,"[np.int64(-1), -1, -1, -1, -1]",43;-1;-1;-1;-1,43,43,Illustrative Rendering Techniques
SciVis,2015,Adaptive Multilinear Tensor Product Wavelets,10.1109/tvcg.2015.2467412,http://dx.doi.org/10.1109/TVCG.2015.2467412,985.0,994.0,J,"Many foundational visualization techniques including isosurfacing, direct volume rendering and texture mapping rely on piecewise multilinear interpolation over the cells of a mesh. However, there has not been much focus within the visualization community on techniques that efficiently generate and encode globally continuous functions defined by the union of multilinear cells. Wavelets provide a rich context for analyzing and processing complicated datasets. In this paper, we exploit adaptive regular refinement as a means of representing and evaluating functions described by a subset of their nonzero wavelet coefficients. We analyze the dependencies involved in the wavelet transform and describe how to generate and represent the coarsest adaptive mesh with nodal function values such that the inverse wavelet transform is exactly reproduced via simple interpolation (subdivision) over the mesh elements. This allows for an adaptive, sparse representation of the function with on-demand evaluation at any point in the domain. We focus on the popular wavelets formed by tensor products of linear B-splines, resulting in an adaptive, nonconforming but crack-free quadtree (2D) or octree (3D) mesh that allows reproducing globally continuous functions via multilinear interpolation over its cells.",Kenneth Weiss 0001;Peter Lindstrom 0001,Kenneth Weiss;Peter Lindstrom,Lawrence Livermore National Laboratory;Lawrence Livermore National Laboratory,10.1109/tvcg.2010.145;10.1109/visual.1997.663860;10.1109/visual.2002.1183810;10.1109/tvcg.2011.252;10.1109/visual.1996.568127;10.1109/tvcg.2009.186;10.1109/tvcg.2010.145,"Multilinear interpolation, adaptive wavelets, multiresolution models, octrees, continuous reconstruction",6.0,5.0,51.0,591.0,,,interpolation subdivision mesh;popular wavelets formed;rendering texture;continuous functions multilinear;rich context,0.5703;0.3614;0.2497;0.2214;0.0683,"[np.int64(-1), -1, -1, -1, -1]",78;-1;-1;-1;-1,78,78,Mesh Refinement Techniques
Vis,1991,Realistic volume imaging,10.1109/visual.1991.175805,http://dx.doi.org/10.1109/VISUAL.1991.175805,226.0,,C,"A set of volume visualization tools that are based on the use of recursive ray tracing as the primary vehicle for realistic volume imaging is presented. The tools include shadows, mirrors, specularity, and constructive solid geometry. The underlying representation for the ray tracer is a 3-D raster of voxels that holds the discrete form of the scene. Unlike traditional volume rendering techniques, the discrete recursive ray tracer models many illumination phenomena by traversing discrete rays in voxel space. The approach provides true ray tracing of sampled or computed datasets, as well as ray tracing of hybrid scenes where sampled or computed data are intermixed with geometric models and enhances the understanding of complex biomedical datasets.&lt;&lt;ETX&gt;&gt;",Roni Yagel;Arie E. Kaufman;Qiang Zhang,R. Yagel;A. Kaufman;Q. Zhang,"Department of Computer Science, State University of New York, Stony Brook, Stony Brook, NY, USA;Department of Computer Science, State University of New York, Stony Brook, Stony Brook, NY, USA;Department of Computer Science, State University of New York, Stony Brook, Stony Brook, NY, USA",,,52.0,11.0,24.0,74.0,,,volume visualization;biomedical datasets;ray;shadows mirrors specularity;discrete recursive,0.6870;0.3172;0.2952;0.2622;0.1259,"[np.int64(-1), -1, -1, -1, -1]",54;-1;-1;-1;-1,54,54,Volume Visualization Techniques
InfoVis,2017,Data Through Others' Eyes: The Impact of Visualizing Others' Expectations on Visualization Interpretation,10.1109/tvcg.2017.2745240,http://dx.doi.org/10.1109/TVCG.2017.2745240,760.0,769.0,J,"In addition to visualizing input data, interactive visualizations have the potential to be social artifacts that reveal other people's perspectives on the data. However, how such social information embedded in a visualization impacts a viewer's interpretation of the data remains unknown. Inspired by recent interactive visualizations that display people's expectations of data against the data, we conducted a controlled experiment to evaluate the effect of showing social information in the form of other people's expectations on people's ability to recall the data, the degree to which they adjust their expectations to align with the data, and their trust in the accuracy of the data. We found that social information that exhibits a high degree of consensus lead participants to recall the data more accurately relative to participants who were exposed to the data alone. Additionally, participants trusted the accuracy of the data less and were more likely to maintain their initial expectations when other people's expectations aligned with their own initial expectations but not with the data. We conclude by characterizing the design space for visualizing others' expectations alongside data.",Yea-Seul Kim;Katharina Reinecke;Jessica Hullman,Yea-Seul Kim;Katharina Reinecke;Jessica Hullman,University of Washington;University of Washington;University of Washington,10.1109/vast.2007.4389011;10.1109/infvis.2005.1532126;10.1109/tvcg.2011.255;10.1109/tvcg.2014.2346419;10.1109/tvcg.2007.70577;10.1109/infvis.2005.1532122;10.1109/tvcg.2007.70589;10.1109/tvcg.2010.177,"Social influence,Social visualization,Data interpretation",50.0,30.0,40.0,1285.0,,,visualizations potential social;trusted accuracy;maintain initial expectations;data remains;high,0.5739;0.3549;0.3505;0.2460;-0.0411,"[np.int64(-1), -1, -1, -1, -1]",87;-1;-1;-1;-1,87,87,Social Network Visualization
Vis,1999,Geo-spatial visualization for situational awareness,10.1109/visual.1999.809925,http://dx.doi.org/10.1109/VISUAL.1999.809925,441.0,559.0,C,"Situational awareness applications require a highly detailed geospatial visualization covering a large geographic area. Conventional polygon based terrain modeling would exceed the capacity of current computer rendering. Terrain visualization techniques for a situational awareness application are described in this case study. Visualizing large amounts of terrain data has been achieved using very large texture maps. Sun shading is applied to the terrain texture map to enhance perception of relief features. Perception of submarine positions has been enhanced using a translucent, textured water surface.",Eliot Feibush;Nikhil Gagvani;Daniel Williams,E. Feibush;N. Gagvani;D. Williams,"Sarnoff Corporation, Princeton, NJ, USA;Sarnoff Corporation, Princeton, NJ, USA;Systems and Scientific Software, Elkins Park, PA, USA",,,6.0,0.0,12.0,153.0,,,terrain visualization;situational awareness;sun shading applied;water;exceed capacity current,0.7224;0.3185;0.2811;0.1036;0.0171,"[np.int64(-1), -1, -1, -1, -1]",80;-1;-1;-1;-1,80,80,Terrain Visualization
Vis,2024,SpreadLine: Visualizing Egocentric Dynamic Influence,10.1109/tvcg.2024.3456373,http://dx.doi.org/10.1109/TVCG.2024.3456373,1050.0,1060.0,J,"Egocentric networks, often visualized as node-link diagrams, portray the complex relationship (link) dynamics between an entity (node) and others. However, common analytics tasks are multifaceted, encompassing interactions among four key aspects: strength, function, structure, and content. Current node-link visualization designs may fall short, focusing narrowly on certain aspects and neglecting the holistic, dynamic nature of egocentric networks. To bridge this gap, we introduce SpreadLine, a novel visualization framework designed to enable the visual exploration of egocentric networks from these four aspects at the microscopic level. Leveraging the intuitive appeal of storyline visualizations, SpreadLine adopts a storyline-based design to represent entities and their evolving relationships. We further encode essential topological information in the layout and condense the contextual information in a metro map metaphor, allowing for a more engaging and effective way to explore temporal and attribute-based information. To guide our work, with a thorough review of pertinent literature, we have distilled a task taxonomy that addresses the analytical needs specific to egocentric network exploration. Acknowledging the diverse analytical requirements of users, SpreadLine offers customizable encodings to enable users to tailor the framework for their tasks. We demonstrate the efficacy and general applicability of SpreadLine through three diverse real-world case studies (disease surveillance, social media trends, and academic career evolution) and a usability study.",Yun-Hsin Kuo;Dongyu Liu;Kwan-Liu Ma,Yun-Hsin Kuo;Dongyu Liu;Kwan-Liu Ma,"University of California, USA;University of California, USA;University of California, USA",10.1109/vast.2017.8585487;10.1109/tvcg.2020.3030437;10.1109/vast.2016.7883510;10.1109/tvcg.2023.3326578;10.1109/tvcg.2022.3209480;10.1109/vast.2018.8802415;10.1109/vast.2015.7347632;10.1109/tvcg.2013.196;10.1109/tvcg.2020.3030403;10.1109/tvcg.2012.212;10.1109/tvcg.2020.3030467;10.1109/tvcg.2018.2864899;10.1109/tvcg.2015.2468151,"Egocentric network,network analysis,,,design study,storyline visualization,visual exploration,metaphor",,0.0,75.0,201.0,,,networks visualized node;metaphor allowing engaging;condense;tailor framework tasks;encodings enable users,0.6865;0.2660;0.0837;0.0714;-0.0838,"[np.int64(-1), -1, -1, -1, -1]",87;-1;-1;-1;-1,87,87,Social Network Visualization
Vis,2021,Explanatory Journeys: Visualising to Understand and Explain Administrative Justice Paths of Redress,10.1109/tvcg.2021.3114818,http://dx.doi.org/10.1109/TVCG.2021.3114818,518.0,528.0,J,"Administrative justice concerns the relationships between individuals and the state. It includes redress and complaints on decisions of a child's education, social care, licensing, planning, environment, housing and homelessness. However, if someone has a complaint or an issue, it is challenging for people to understand different possible redress paths and explore what path is suitable for their situation. Explanatory visualisation has the potential to display these paths of redress in a clear way, such that people can see, understand and explore their options. The visualisation challenge is further complicated because information is spread across many documents, laws, guidance and policies and requires judicial interpretation. Consequently, there is not a single database of paths of redress. In this work we present how we have co-designed a system to visualise administrative justice paths of redress. Simultaneously, we classify, collate and organise the underpinning data, from expert workshops, heuristic evaluation and expert critical reflection. We make four contributions: (i) an application design study of the explanatory visualisation tool (Artemus), (ii) coordinated and co-design approach to aggregating the data, (iii) two in-depth case studies in housing and education demonstrating explanatory paths of redress in administrative law, and (iv) reflections on the expert co-design process and expert data gathering and explanatory visualisation for administrative justice and law.",Jonathan C. Roberts;Peter W. S. Butcher;Ann Sherlock;Sarah Nason,Jonathan C. Roberts;Peter Butcher;Ann Sherlock;Sarah Nason,"Bangor University, United Kingdom;Bangor University, United Kingdom;Bangor University, United Kingdom;Bangor University, United Kingdom",10.1109/tvcg.2020.3030375;10.1109/visual.2005.1532788;10.1109/tvcg.2011.185;10.1109/tvcg.2011.255;10.1109/tvcg.2013.119;10.1109/tvcg.2014.2346331;10.1109/tvcg.2015.2467271;10.1109/tvcg.2017.2745878;10.1109/tvcg.2012.213;10.1109/tvcg.2010.179;10.1109/vast.2007.4389006;10.1109/tvcg.2009.139;10.1109/infvis.2004.12;10.1109/infvis.2005.1532143;10.1109/tvcg.2009.111;10.1109/tvcg.2020.3030375,"Explanatory Visualisation,Administrative Justice,Law,Law Visualisation",8.0,4.0,70.0,615.0,HM,,visualisation administrative justice;workshops heuristic evaluation;database paths redress;environment housing;single,0.7400;0.2229;0.2009;0.1595;-0.0604,"[np.int64(-1), -1, -1, -1, -1]",99;-1;-1;-1;-1,99,99,Decision-Making Visualizations
Vis,2023,Perceptually Uniform Construction of Illustrative Textures,10.1109/tvcg.2023.3326574,http://dx.doi.org/10.1109/TVCG.2023.3326574,1052.0,1062.0,J,"Illustrative textures, such as stippling or hatching, were predominantly used as an alternative to conventional Phong rendering. Recently, the potential of encoding information on surfaces or maps using different densities has also been recognized. This has the significant advantage that additional color can be used as another visual channel and the illustrative textures can then be overlaid. Effectively, it is thus possible to display multiple information, such as two different scalar fields on surfaces simultaneously. In previous work, these textures were manually generated and the choice of density was unempirically determined. Here, we first want to determine and understand the perceptual space of illustrative textures. We chose a succession of simplices with increasing dimensions as primitives for our textures: Dots, lines, and triangles. Thus, we explore the texture types of stippling, hatching, and triangles. We create a range of textures by sampling the density space uniformly. Then, we conduct three perceptual studies in which the participants performed pairwise comparisons for each texture type. We use multidimensional scaling (MDS) to analyze the perceptual spaces per category. The perception of stippling and triangles seems relatively similar. Both are adequately described by a 1D manifold in 2D space. The perceptual space of hatching consists of two main clusters: Crosshatched textures, and textures with only one hatching direction. However, the perception of hatching textures with only one hatching direction is similar to the perception of stippling and triangles. Based on our findings, we construct perceptually uniform illustrative textures. Afterwards, we provide concrete application examples for the constructed textures.",Anna Sterzik;Monique Meuschke;Douglas W. Cunningham;Kai Lawonn,Anna Sterzik;Monique Meuschke;Douglas W. Cunningham;Kai Lawonn,"University of Jena, Germany;University of Magdeburg, Germany;Brandenburg University of Technology, Germany;University of Jena, Germany",0.1109/tvcg.2006.180;10.1109/visual.1996.568110;10.1109/tvcg.2016.2598795;10.1109/tvcg.2023.3326523,"Illustrative Visualization,Perceptual Evaluation,Hatching,Stippling",,0.0,55.0,225.0,,,illustrative textures;space hatching;scaling mds analyze;alternative conventional phong;studies participants performed,0.6983;0.2614;0.1362;0.1202;0.0108,"[np.int64(-1), -1, -1, -1, -1]",43;-1;-1;-1;-1,43,43,Illustrative Rendering Techniques
Vis,2008,Visualization of Myocardial Perfusion Derived from Coronary Anatomy,10.1109/tvcg.2008.180,http://dx.doi.org/10.1109/TVCG.2008.180,1595.0,1602.0,J,"Visually assessing the effect of the coronary artery anatomy on the perfusion of the heart muscle in patients with coronary artery disease remains a challenging task. We explore the feasibility of visualizing this effect on perfusion using a numerical approach. We perform a computational simulation of the way blood is perfused throughout the myocardium purely based on information from a three-dimensional anatomical tomographic scan. The results are subsequently visualized using both three-dimensional visualizations and bullpsilas eye plots, partially inspired by approaches currently common in medical practice. Our approach results in a comprehensive visualization of the coronary anatomy that compares well to visualizations commonly used for other scanning technologies. We demonstrate techniques giving detailed insight in blood supply, coronary territories and feeding coronary arteries of a selected region. We demonstrate the advantages of our approach through visualizations that show information which commonly cannot be directly observed in scanning data, such as a separate visualization of the supply from each coronary artery. We thus show that the results of a computational simulation can be effectively visualized and facilitate visually correlating these results to for example perfusion data.",Maurice Termeer;Javier Oliván Bescós;Marcel Breeuwer;Anna Vilanova;Frans A. Gerritsen;M. Eduard Gröller;Eike Nagel,Maurice Termeer;Javier Oliván Bescós;Marcel Breeuwer;Anna Vilanova;Frans Gerritsen;M. Eduard Gröller;Eike Nagel,"Vienna University of Technology, Austria;Philips Healthcare;Philips Healthcare;Eindhoven University of Technology, Netherlands;Philips Healthcare;Vienna University of Technology, Austria;King's College London, London, UK",10.1109/tvcg.2007.70550;10.1109/visual.2002.1183754;10.1109/tvcg.2007.70550,"Cardiac visualization, coronary artery territories, myocardial perfusion",34.0,15.0,21.0,469.0,,,visualization coronary anatomy;effect perfusion using;bullpsilas eye;numerical approach perform;purely based information,0.7640;0.3856;0.1727;0.1369;0.0573,"[np.int64(-1), -1, -1, -1, -1]",38;-1;-1;-1;-1,38,38,3D Medical Visualization
Vis,2003,Piecewise C¹ continuous surface reconstruction of noisy point clouds via local implicit quadric regression,10.1109/visual.2003.1250359,http://dx.doi.org/10.1109/VISUAL.2003.1250359,91.0,98.0,C,"This paper addresses the problem of surface reconstruction of highly noisy point clouds. The surfaces to be reconstructed are assumed to be 2-manifolds of piecewise C/sup 1/ continuity, with isolated small irregular regions of high curvature, sophisticated local topology or abrupt burst of noise. At each sample point, a quadric field is locally fitted via a modified moving least squares method. These locally fitted quadric fields are then blended together to produce a pseudo-signed distance field using Shepard's method. We introduce a prioritized front growing scheme in the process of local quadrics fitting. Flatter surface areas tend to grow faster. The already fitted regions will subsequently guide the fitting of those irregular regions in their neighborhood.",Hui Xie 0001;Jianning Wang;Jing Hua 0001;Hong Qin 0001;Arie E. Kaufman,Hui Xie;Jianning Wang;Jing Hua;Hong Qin;A. Kaufman,"Center for Visual Computing (CVC) and Department of Computer Science, Stony Brook University, Stony Brook, NY, USA;Center for Visual Computing (CVC) and Department of Computer Science, Stony Brook University, Stony Brook, NY, USA;Center for Visual Computing (CVC) and Department of Computer Science, Stony Brook University, Stony Brook, NY, USA;Center for Visual Computing (CVC) and Department of Computer Science, Stony Brook University, Stony Brook, NY, USA;Center for Visual Computing (CVC) and Department of Computer Science, Stony Brook University, Stony Brook, NY, USA",10.1109/visual.2001.964489;10.1109/visual.2001.964489,"Computer Graphics, Surface Reconstruction, Point Cloud, Surface Representation, Solid Modeling, Moving Least Squares, Shepard's Method",1.0,20.0,21.0,192.0,,,noisy point clouds;quadric field locally;shepard method introduce;grow faster;piecewise sup continuity,0.6265;0.2609;0.1359;0.0461;0.0262,"[np.int64(-1), -1, -1, -1, -1]",126;-1;-1;-1;-1,126,126,Geometric Mesh Processing
Vis,2024,DataGarden: Formalizing Personal Sketches into Structured Visualization Templates,10.1109/tvcg.2024.3456336,http://dx.doi.org/10.1109/TVCG.2024.3456336,1268.0,1278.0,J,"Sketching is a common practice among visualization designers and serves an approachable entry to data visualization for non-experts. However, moving from a sketch to a full fledged data visualization often requires throwing away the original sketch and recreating it from scratch. Our goal is to formalize these sketches, enabling them to support iteration and systematic data mapping through a visual-first templating workflow. In this workflow, authors sketch a representative visualization and structure it into an expressive template for an envisioned or partial dataset, capturing implicit style as well as explicit data mappings. To demonstrate our proposed workflow, we implement DataGarden and evaluate it through a reproduction and a freeform study. We investigate how DataGarden supports personal expression and delve into the variety of visualizations that authors can produce with it, identifying cases that demonstrate the limitations of our approach and discussing avenues for future work.",Anna Offenwanger;Theophanis Tsandilas;Fanny Chevalier,Anna Offenwanger;Theophanis Tsandilas;Fanny Chevalier,"Université Paris Saclay, CRNS, Inria, LISN, France;Université Paris Saclay, CRNS, Inria, LISN, France;Departments of Computer Science and Statistical Sciences, University of Toronto, Canada",10.1109/tvcg.2010.164;10.1109/tvcg.2014.2346292;10.1109/tvcg.2016.2598620;10.1109/tvcg.2013.191;10.1109/tvcg.2022.3209451;10.1109/tvcg.2018.2865240;10.1109/tvcg.2023.3326520;10.1109/tvcg.2018.2865158;10.1109/tvcg.2016.2598839;10.1109/tvcg.2019.2934281;10.1109/tvcg.2015.2467153;10.1109/tvcg.2020.3030476;10.1109/tvcg.2012.262;10.1109/tvcg.2020.3030367,"Personal visualization,Visualization template,,,Sketch input,Sketch-based visualization,Visualization by-example",,0.0,69.0,162.0,,,visualization designers;datagarden supports personal;dataset capturing implicit;common practice;recreating scratch goal,0.6655;0.3367;0.2758;0.1336;0.0858,"[np.int64(-1), -1, -1, -1, -1]",105;-1;-1;-1;-1,105,105,Visualization Designers
InfoVis,2020,SafetyLens: Visual Data Analysis of Functional Safety of Vehicles,10.1109/tvcg.2020.3030382,http://dx.doi.org/10.1109/TVCG.2020.3030382,1688.0,1697.0,J,"Modern automobiles have evolved from just being mechanical machines to having full-fledged electronics systems that enhance vehicle dynamics and driver experience. However, these complex hardware and software systems, if not properly designed, can experience failures that can compromise the safety of the vehicle, its occupants, and the surrounding environment. For example, a system to activate the brakes to avoid a collision saves lives when it functions properly, but could lead to tragic outcomes if the brakes were applied in a way that's inconsistent with the design. Broadly speaking, the analysis performed to minimize such risks falls into a systems engineering domain called Functional Safety. In this paper, we present SafetyLens, a visual data analysis tool to assist engineers and analysts in analyzing automotive Functional Safety datasets. SafetyLens combines techniques including network exploration and visual comparison to help analysts perform domain-specific tasks. This paper presents the design study with domain experts that resulted in the design guidelines, the tool, and user feedback.",Arpit Narechania;Ahsan Qamar;Alex Endert,Arpit Narechania;Ahsan Qamar;Alex Endert,Georgia Institute of Technology;Ford Motor Company;Georgia Institute of Technology,10.1109/vast.2006.261426;10.1109/tvcg.2014.2346248;10.1109/tvcg.2011.185;10.1109/tvcg.2014.2346249;10.1109/tvcg.2012.255;10.1109/tvcg.2006.166;10.1109/tvcg.2009.108,"Visual data analysis,Design study,Network visualization,Functional safety,Automotive engineering",2.0,1.0,57.0,644.0,,,automotive functional safety;network exploration visual;inconsistent design;collision saves;called,0.6729;0.3637;0.2181;0.1558;0.0783,"[np.int64(-1), -1, -1, -1, -1]",32;-1;-1;-1;-1,32,32,Automotive Safety Systems
Vis,1993,Computer visualization of long genomic sequences,10.1109/visual.1993.398883,http://dx.doi.org/10.1109/VISUAL.1993.398883,308.0,315.0,C,"Human beings find it difficult to analyze local and global oligonucleotide patterns in the linear primary sequences of a genome. In this paper, we present a family of iterated function systems (IFS) that can be used to generate a set of visual models of a DNA sequence. A new visualization function, the W-curve, that is derived from this IFS family is introduced. Using W-curves, a user can readily compare subsequences within a long genomic sequence - or between genomic sequences - and can visually evaluate the effect of local variations (mutations) upon the global genomic information content.&lt;&lt;ETX&gt;&gt;",Dachywan Wu;James Robergé;Douglas J. Cork;Bao Gia Nguyen;Thom Grace,D. Wu;J. Roberge;D.J. Cork;B.G. Nguyen;T. Grace,"Department of Computer Science, Illinois Institute of Technology, Chicago, IL, USA;Department of Computer Science, Illinois Institute of Technology, Chicago, IL, USA;Department of Biology, Illinois Institute of Technology, Chicago, IL, USA;Department of Mathematics, Illinois Institute of Technology, Chicago, IL, USA;Department of Computer Science, Illinois Institute of Technology, Chicago, IL, USA",,,42.0,8.0,14.0,100.0,,,genomic sequences visually;function systems ifs;using curves user;human beings difficult;local,0.7186;0.2938;0.2160;0.0756;-0.0131,"[np.int64(-1), -1, -1, -1, -1]",26;-1;-1;-1;-1,26,26,Biological Sequence Visualization
InfoVis,2002,"SpaceTree: supporting exploration in large node link tree, design evolution and empirical evaluation",10.1109/infvis.2002.1173148,http://dx.doi.org/10.1109/INFVIS.2002.1173148,57.0,64.0,C,"We present a novel tree browser that builds on the conventional node link tree diagrams. It adds dynamic rescaling of branches of the tree to best fit the available screen space, optimized camera movement, and the use of preview icons summarizing the topology of the branches that cannot be expanded. In addition, it includes integrated search and filter functions. This paper reflects on the evolution of the design and highlights the principles that emerged from it. A controlled experiment showed benefits for navigation to already previously visited nodes and estimation of overall tree topology.",Catherine Plaisant;Jesse Grosjean;Benjamin B. Bederson,C. Plaisant;J. Grosjean;B.B. Bederson,"Human-Computer Interaction Laboratory, University of Maryland, USA;Human-Computer Interaction Laboratory, University of Maryland, USA;Human-Computer Interaction Laboratory, University of Maryland, USA",10.1109/visual.1996.567745;10.1109/visual.1996.567745,,519.0,71.0,23.0,2216.0,,,novel tree browser;rescaling;search filter functions;visited;includes,0.8092;0.1605;0.1582;0.1424;0.0502,"[np.int64(-1), -1, -1, -1, -1]",9;-1;-1;-1;-1,9,9,Tree Visualization Techniques
Vis,1998,Selective visualization of vortices in hydrodynamic flows,10.1109/visual.1998.745333,http://dx.doi.org/10.1109/VISUAL.1998.745333,419.0,422.0,C,"Vortices are important features in many research and engineering fields. Visualization is an important step in gaining more understanding and control of vortices. Vortex detection criteria fall into two categories: point based scalar quantities, calculated at single points, and curve based geometric criteria, calculated for, e.g., streamlines. The first category is easy to compute, but does not work in all cases. The second category is more intuitive and should work in all cases, but currently only works in 2D (or 3D projected) flows. We show applications of both approaches in hydrodynamic flows.",I. Ari Sadarjoen;Frits H. Post;Bing Ma;David C. Banks;Hans-Georg Pagendarm,I.A. Sadarjoen;F.H. Post;Bing Ma;D.C. Banks;H.-G. Pagendarm,"Department of Computer Science, Delft University of Technnology, Delft, Netherlands;Department of Computer Science, Delft University of Technnology, Delft, Netherlands;Laboratory for Aero and Hydrodynamics,Delft University of Technology, Tsinghua University, Beijing, China;Department of Computer Science, Mississippi State University, USA;DLR: Deutsches Zentrum für Luft-und Raumfahrt, German Aerospace Center, Germany",10.1109/visual.1995.485158;10.1109/visual.1997.663910;10.1109/visual.1994.346327;10.1109/visual.1996.568137;10.1109/visual.1995.485158,,111.0,28.0,12.0,251.0,,,vortices vortex detection;single points curve;2d 3d projected;research engineering fields;important,0.7879;0.2638;0.1855;0.0769;0.0082,"[np.int64(-1), -1, -1, -1, -1]",21;-1;-1;-1;-1,21,21,Vortex Identification
Vis,2021,Rapid Labels: Point-Feature Labeling on GPU,10.1109/tvcg.2021.3114854,http://dx.doi.org/10.1109/TVCG.2021.3114854,604.0,613.0,J,"Labels, short textual annotations are an important component of data visualizations, illustrations, infographics, and geographical maps. In interactive applications, the labeling method responsible for positioning the labels should not take the resources from the application itself. In other words, the labeling method should provide the result as fast as possible. In this work, we propose a greedy point-feature labeling method running on GPU. In contrast to existing methods that position the labels sequentially, the proposed method positions several labels in parallel. Yet, we guarantee that the positioned labels will not overlap, nor will they overlap important visual features. When the proposed method is searching for the label position of a point-feature, the available label candidates are evaluated with respect to overlaps with important visual features, conflicts with label candidates of other point-features, and their ambiguity. The evaluation of each label candidate is done in constant time independently from the number of point-features, the number of important visual features, and the resolution of the created image. Our measurements indicate that the proposed method is able to position more labels than existing greedy methods that do not evaluate conflicts between the label candidates. At the same time, the proposed method achieves a significant increase in performance. The increase in performance is mainly due to the parallelization and the efficient evaluation of label candidates.",Vaclav Pavlovec;Ladislav Cmolík,Vaclav Pavlovec;Ladislav Cmolik,"Faculty of Electrical Engineering, Czech Technical University in Prague, Czech Republic;Faculty of Electrical Engineering, Czech Technical University in Prague, Czech Republic",10.1109/tvcg.2006.136;10.1109/tvcg.2008.152;10.1109/tvcg.2006.136,"Label placement,Point-feature labeling,GPU",1.0,3.0,33.0,496.0,,,point feature labeling;maps interactive applications;method running gpu;textual;overlap,0.5078;0.4351;0.2059;0.1986;0.1978,"[np.int64(-1), -1, -1, -1, -1]",-1;-1;-1;-1;-1,,-1,Interactive 3D Visualization
VAST,2009,Visual analysis of graphs with multiple connected components,10.1109/vast.2009.5333893,http://dx.doi.org/10.1109/VAST.2009.5333893,155.0,162.0,C,"In this paper, we present a system for the interactive visualization and exploration of graphs with many weakly connected components. The visualization of large graphs has recently received much research attention. However, specific systems for visual analysis of graph data sets consisting of many components are rare. In our approach, we rely on graph clustering using an extensive set of topology descriptors. Specifically, we use the self-organizing-map algorithm in conjunction with a user-adaptable combination of graph features for clustering of graphs. It offers insight into the overall structure of the data set. The clustering output is presented in a grid containing clusters of the connected components of the input graph. Interactive feature selection and task-tailored data views allow the exploration of the whole graph space. The system provides also tools for assessment and display of cluster quality. We demonstrate the usefulness of our system by application to a shareholder network analysis problem based on a large real-world data set. While so far our approach is applied to weighted directed graphs only, it can be used for various graph types.",Tatiana von Landesberger;Melanie Görner;Tobias Schreck,Tatiana von Landesberger;Melanie Gorner;Tobias Schreck,"Interactive Graphics Systems Group, Technische Universität Darmstadt and Fraunhofer IGD, Germany;Interactive Graphics Systems Group, Technische Universität Darmstadt, Germany;Interactive Graphics Systems Group, Technische Universität Darmstadt, Germany",10.1109/tvcg.2006.193;10.1109/tvcg.2008.135;10.1109/infvis.2003.1249011;10.1109/tvcg.2006.147;10.1109/tvcg.2006.193,,53.0,25.0,48.0,724.0,,,visualization large graphs;application shareholder network;set clustering output;weakly connected components;use self,0.6441;0.3520;0.3170;0.3022;0.1117,"[np.int64(-1), -1, -1, -1, -1]",96;-1;-1;-1;-1,96,96,Graph Visualization
InfoVis,2015,Beyond Memorability: Visualization Recognition and Recall,10.1109/tvcg.2015.2467732,http://dx.doi.org/10.1109/TVCG.2015.2467732,519.0,528.0,J,"In this paper we move beyond memorability and investigate how visualizations are recognized and recalled. For this study we labeled a dataset of 393 visualizations and analyzed the eye movements of 33 participants as well as thousands of participant-generated text descriptions of the visualizations. This allowed us to determine what components of a visualization attract people's attention, and what information is encoded into memory. Our findings quantitatively support many conventional qualitative design guidelines, including that (1) titles and supporting text should convey the message of a visualization, (2) if used appropriately, pictograms do not interfere with understanding and can improve recognition, and (3) redundancy helps effectively communicate the message. Importantly, we show that visualizations memorable “at-a-glance” are also capable of effectively conveying the message of the visualization. Thus, a memorable visualization is often also an effective one.",Michelle A. Borkin;Zoya Bylinskii;Nam Wook Kim;Constance May Bainbridge;Chelsea S. Yeh;Daniel Borkin;Hanspeter Pfister;Aude Oliva,Michelle A. Borkin;Zoya Bylinskii;Nam Wook Kim;Constance May Bainbridge;Chelsea S. Yeh;Daniel Borkin;Hanspeter Pfister;Aude Oliva,"University of British Columbia, Harvard University;Computer Science and Artificial Intelligence Laboratory (CSAIL), Massachusetts Institute of Technology (MIT);School of Engineering & Applied Sciences, Harvard University;Computer Science and Artificial Intelligence Laboratory (CSAIL), Massachusetts Institute of Technology (MIT);School of Engineering & Applied Sciences, Harvard University;University of Michigan;School of Engineering & Applied Sciences, Harvard University;Computer Science and Artificial Intelligence Laboratory (CSAIL), Massachusetts Institute of Technology (MIT)",10.1109/tvcg.2012.197;10.1109/tvcg.2013.234;10.1109/tvcg.2011.193;10.1109/tvcg.2012.233;10.1109/tvcg.2011.175;10.1109/tvcg.2013.234;10.1109/tvcg.2012.215;10.1109/vast.2010.5653598;10.1109/tvcg.2012.245;10.1109/tvcg.2012.221;10.1109/tvcg.2012.197,"Information visualization, memorability, recognition, recall, eye-tracking study",295.0,218.0,48.0,5663.0,,,visualizations memorable;recognized recalled study;titles supporting text;thousands;allowed determine,0.8168;0.1981;0.1948;0.0897;0.0073,"[np.int64(-1), -1, -1, -1, -1]",94;-1;-1;-1;-1,94,94,Visualization Literacy
Vis,2000,multi-user view-dependent rendering,10.1109/visual.2000.885713,http://doi.ieeecomputersociety.org/10.1109/VISUAL.2000.885713,335.0,342.0,C,"We present a novel architecture which allows rendering of a large-shared dataset at interactive rates on an inexpensive workstation. The idea is based on view-dependent rendering on a client-server network. The server stores the large dataset and manages the selection of the various levels of detail while the inexpensive clients receive a stream of update operations that generate the appropriate level of detail in an incremental fashion. These update operations are based on changes in the clients' view-parameters. Our approach dramatically reduces the amount of memory needed by each client and the entire computing system since the dataset is stored only once on the server's local memory. In addition, it decreases the load on the network as results of the incremental update contributed by view-dependent rendering.",Jihad El-Sana,J. El-Sana,"Dept. of Comput. Sci., Ben-Gurion Univ. of the Negev, Beer-Sheva, Israel",10.1109/visual.1999.809877;10.1109/visual.1995.480805,,7.0,1.0,0.0,20.0,,,rendering client server;level incremental fashion;dataset manages selection;update contributed view;memory addition,0.5707;0.3089;0.1946;0.1890;0.1656,"[np.int64(-1), -1, -1, -1, -1]",43;-1;-1;-1;-1,43,43,Illustrative Rendering Techniques
InfoVis,2008,Spatially Ordered Treemaps,10.1109/tvcg.2008.165,http://dx.doi.org/10.1109/TVCG.2008.165,1348.0,1355.0,J,"Existing treemap layout algorithms suffer to some extent from poor or inconsistent mappings between data order and visual ordering in their representation, reducing their cognitive plausibility. While attempts have been made to quantify this mismatch, and algorithms proposed to minimize inconsistency, solutions provided tend to concentrate on one-dimensional ordering. We propose extensions to the existing squarified layout algorithm that exploit the two-dimensional arrangement of treemap nodes more effectively. Our proposed spatial squarified layout algorithm provides a more consistent arrangement of nodes while maintaining low aspect ratios. It is suitable for the arrangement of data with a geographic component and can be used to create tessellated cartograms for geovisualization. Locational consistency is measured and visualized and a number of layout algorithms are compared. CIELab color space and displacement vector overlays are used to assess and emphasize the spatial layout of treemap nodes. A case study involving locations of tagged photographs in the Flickr database is described.",Jo Wood;Jason Dykes,Jo Wood;Jason Dykes,"School of Informatics, City University, London, UK;School of Informatics, City University, London, UK",10.1109/infvis.2001.963283;10.1109/infvis.2001.963290;10.1109/tvcg.2007.70522;10.1109/tvcg.2007.70529;10.1109/infvis.2001.963283,"Geovisualization, treemaps, cartograms, CIELab, geographic information, tree structures",216.0,113.0,32.0,1570.0,,,spatial layout treemap;flickr database described;displacement vector;representation reducing cognitive;cielab,0.7244;0.2612;0.1402;0.1199;0.0422,"[np.int64(-1), -1, -1, -1, -1]",56;-1;-1;-1;-1,56,56,Treemap Visualization
SciVis,2012,Automatic Detection and Visualization of Qualitative Hemodynamic Characteristics in Cerebral Aneurysms,10.1109/tvcg.2012.202,http://dx.doi.org/10.1109/TVCG.2012.202,2178.0,2187.0,J,"Cerebral aneurysms are a pathological vessel dilatation that bear a high risk of rupture. For the understanding and evaluation of the risk of rupture, the analysis of hemodynamic information plays an important role. Besides quantitative hemodynamic information, also qualitative flow characteristics, e.g., the inflow jet and impingement zone are correlated with the risk of rupture. However, the assessment of these two characteristics is currently based on an interactive visual investigation of the flow field, obtained by computational fluid dynamics (CFD) or blood flow measurements. We present an automatic and robust detection as well as an expressive visualization of these characteristics. The detection can be used to support a comparison, e.g., of simulation results reflecting different treatment options. Our approach utilizes local streamline properties to formalize the inflow jet and impingement zone. We extract a characteristic seeding curve on the ostium, on which an inflow jet boundary contour is constructed. Based on this boundary contour we identify the impingement zone. Furthermore, we present several visualization techniques to depict both characteristics expressively. Thereby, we consider accuracy and robustness of the extracted characteristics, minimal visual clutter and occlusions. An evaluation with six domain experts confirms that our approach detects both hemodynamic characteristics reasonably.",Rocco Gasteiger;Dirk J. Lehmann;Roy van Pelt;Gábor Janiga;Oliver Beuing;Anna Vilanova;Holger Theisel;Bernhard Preim,Rocco Gasteiger;Dirk J. Lehmann;Roy van Pelt;Gábor Janiga;Oliver Beuing;Anna Vilanova;Holger Theisel;Bernhard Preim,"Department of Simulation and Graphics, group Visualization, University of Magdeburg, Germany;Department of Simulation and Graphics, group Visual Computing, University of Magdeburg, Germany;Department of Biomedical Engineering, group of Biomedical Image Analysis, Eindhoven University of Technology, Netherlands;Institute of Fluid Dynamics and Thermodynamics, University of Magdeburg, Germany;Department of Neuroradiology, University Hospital Magdeburg, Germany;Department of Biomedical Engineering, group of Biomedical Image Analysis, Eindhoven University of Technology, Netherlands;Department of Simulation and Graphics, group Visual Computing, University of Magdeburg, Germany;Department of Simulation and Graphics, group Visualization, University of Magdeburg, Germany",10.1109/tvcg.2011.215;10.1109/tvcg.2011.159;10.1109/tvcg.2011.243;10.1109/tvcg.2009.138;10.1109/tvcg.2010.153;10.1109/tvcg.2010.173;10.1109/tvcg.2011.215,"Cerebral aneurysm, Hemodynamic, Inflow jet, Impingement zone, Visualization, Glyph",35.0,24.0,37.0,538.0,,,detects hemodynamic characteristics;computational fluid dynamics;contour constructed based;risk rupture understanding;depict,0.4898;0.4468;0.3354;0.2432;0.1740,"[-1, -1, -1, -1, -1]",-1;-1;-1;-1;-1,,-1,Interactive 3D Visualization
InfoVis,2019,Evaluating an Immersive Space-Time Cube Geovisualization for Intuitive Trajectory Data Exploration,10.1109/tvcg.2019.2934415,http://dx.doi.org/10.1109/TVCG.2019.2934415,514.0,524.0,J,"A Space-Time Cube enables analysts to clearly observe spatio-temporal features in movement trajectory datasets in geovisualization. However, its general usability is impacted by a lack of depth cues, a reported steep learning curve, and the requirement for efficient 3D navigation. In this work, we investigate a Space-Time Cube in the Immersive Analytics domain. Based on a review of previous work and selecting an appropriate exploration metaphor, we built a prototype environment where the cube is coupled to a virtual representation of the analyst's real desk, and zooming and panning in space and time are intuitively controlled using mid-air gestures. We compared our immersive environment to a desktop-based implementation in a user study with 20 participants across 7 tasks of varying difficulty, which targeted different user interface features. To investigate how performance is affected in the presence of clutter, we explored two scenarios with different numbers of trajectories. While the quantitative performance was similar for the majority of tasks, large differences appear when we analyze the patterns of interaction and consider subjective metrics. The immersive version of the Space-Time Cube received higher usability scores, much higher user preference, and was rated to have a lower mental workload, without causing participants discomfort in 25-minute-long VR sessions.",Jorge A. Wagner Filho;Wolfgang Stuerzlinger;Luciana P. Nedel,Jorge A. Wagner Filho;Wolfgang Stuerzlinger;Luciana Nedel,Federal University of Rio Grande do Sul and Simon Fraser University;Simon Fraser University;Federal University of Rio Grande do Sul,10.1109/tvcg.2018.2865191;10.1109/infvis.2004.27;10.1109/tvcg.2018.2865191,"Space-time cube,Trajectory visualization,Immersive analytics",59.0,83.0,59.0,2160.0,,,immersive analytics;space time intuitively;mid air gestures;tasks varying difficulty;25 minute,0.6740;0.3544;0.2332;0.1305;0.0487,"[np.int64(-1), -1, -1, -1, -1]",90;-1;-1;-1;-1,90,90,Immersive Visual Analytics
InfoVis,2005,An optimization-based approach to dynamic visual context management,10.1109/infvis.2005.1532146,http://dx.doi.org/10.1109/INFVIS.2005.1532146,187.0,194.0,C,"We are building an intelligent multimodal conversation system to aid users in exploring large and complex data sets. To tailor to diverse user queries introduced during a conversation, we automate the generation of system responses, including both spoken and visual outputs. In this paper, we focus on the problem of visual context management, a process that dynamically updates an existing visual display to effectively incorporate new information requested by subsequent user queries. Specifically, we develop an optimization based approach to visual context management. Compared to existing approaches, which normally handle predictable visual context updates, our work offers two unique contributions. First, we provide a general computational framework that can effectively manage a visual context for diverse, unanticipated situations encountered in a user system conversation. Moreover, we optimize the satisfaction of both semantic and visual constraints, which otherwise are difficult to balance using simple heuristics. Second, we present an extensible representation model that uses feature based metrics to uniformly define all constraints. We have applied our work to two different applications and our evaluation has shown the promise of this work.",Zhen Wen;Michelle X. Zhou;Vikram Aggarwal,Zhen Wen;M.X. Zhou;V. Aggarwal,"T.J. Watson Research Center, IBM, Hawthorne, NY, USA;T.J. Watson Research Center, IBM, Hawthorne, NY, USA;T.J. Watson Research Center, IBM, Hawthorne, NY, USA",10.1109/infvis.2000.885091;10.1109/infvis.2000.885093;10.1109/infvis.1997.636718;10.1109/infvis.2000.885091,"intelligent multimodal interfaces, visual context management, automated generation of visualization, visual momentum",18.0,1.0,21.0,218.0,,,visual context management;encountered user conversation;automate generation responses;based metrics uniformly;promise work,0.6174;0.3818;0.3717;0.0995;0.0149,"[np.int64(-1), -1, -1, -1, -1]",146;-1;-1;-1;-1,146,146,Visualization Techniques
Vis,2022,Multiple Forecast Visualizations (MFVs): Trade-offs in Trust and Performance in Multiple COVID-19 Forecast Visualizations,10.1109/tvcg.2022.3209457,http://dx.doi.org/10.1109/TVCG.2022.3209457,12.0,22.0,J,"The prevalence of inadequate SARS-COV-2 (COVID-19) responses may indicate a lack of trust in forecasts and risk communication. However, no work has empirically tested how multiple forecast visualization choices impact trust and task-based performance. The three studies presented in this paper ($N=1299$) examine how visualization choices impact trust in COVID-19 mortality forecasts and how they influence performance in a trend prediction task. These studies focus on line charts populated with real-time COVID-19 data that varied the number and color encoding of the forecasts and the presence of best/worst-case forecasts. The studies reveal that trust in COVID-19 forecast visualizations initially increases with the number of forecasts and then plateaus after 6–9 forecasts. However, participants were most trusting of visualizations that showed less visual information, including a 95% confidence interval, single forecast, and grayscale encoded forecasts. Participants maintained high trust in intervals labeled with 50% and 25% and did not proportionally scale their trust to the indicated interval size. Despite the high trust, the 95% CI condition was the most likely to evoke predictions that did not correspond with the actual COVID-19 trend. Qualitative analysis of participants' strategies confirmed that many participants trusted both the simplistic visualizations and those with numerous forecasts. This work provides practical guides for how COVID-19 forecast visualizations influence trust, including recommendations for identifying the range where forecasts balance trade-offs between trust and task-based performance.",Lace M. K. Padilla;Racquel Fygenson;Spencer C. Castro;Enrico Bertini,Lace Padilla;Racquel Fygenson;Spencer C. Castro;Enrico Bertini,"University of California Merced, USA;New York University, USA;University of California Merced, USA;Northeastern University, USA",10.1109/tvcg.2021.3114803;10.1109/tvcg.2014.2346298;10.1109/tvcg.2019.2934287;10.1109/tvcg.2017.2743898;10.1109/tvcg.2020.3030335;10.1109/tvcg.2018.2864909;10.1109/tvcg.2018.2865193;10.1109/infvis.2004.15;10.1109/tvcg.2021.3114803,"COVID-19,multiple forecast visualizations,uncertainty visualization,line charts,time-series data",,12.0,66.0,2809.0,BP,,visualizations influence trust;covid 19 forecast;interval size;grayscale encoded;confirmed,0.6872;0.4575;0.0894;0.0434;-0.0298,"[np.int64(-1), -1, -1, -1, -1]",87;-1;-1;-1;-1,87,87,Social Network Visualization
VAST,2014,DecisionFlow: Visual Analytics for High-Dimensional Temporal Event Sequence Data,10.1109/tvcg.2014.2346682,http://dx.doi.org/10.1109/TVCG.2014.2346682,1783.0,1792.0,J,"Temporal event sequence data is increasingly commonplace, with applications ranging from electronic medical records to financial transactions to social media activity. Previously developed techniques have focused on low-dimensional datasets (e.g., with less than 20 distinct event types). Real-world datasets are often far more complex. This paper describes DecisionFlow, a visual analysis technique designed to support the analysis of high-dimensional temporal event sequence data (e.g., thousands of event types). DecisionFlow combines a scalable and dynamic temporal event data structure with interactive multi-view visualizations and ad hoc statistical analytics. We provide a detailed review of our methods, and present the results from a 12-person user study. The study results demonstrate that DecisionFlow enables the quick and accurate completion of a range of sequence analysis tasks for datasets containing thousands of event types and millions of individual events.",David Gotz;Harry Stavropoulos,David Gotz;Harry Stavropoulos,University of North Carolina at Chapel Hill;IBM T.J. Watson Research Center,10.1109/tvcg.2013.206;10.1109/tvcg.2012.225;10.1109/tvcg.2011.179;10.1109/infvis.2000.885097;10.1109/vast.2009.5332595;10.1109/vast.2010.5652890;10.1109/tvcg.2009.117;10.1109/vast.2006.261421;10.1109/tvcg.2013.200;10.1109/tvcg.2013.206,"Information Visualization, Temporal Event Sequences, Visual Analytics, Flow Diagrams, Medical Informatics",189.0,129.0,34.0,2726.0,,,event sequence data;statistical analytics;multi view visualizations;decisionflow enables quick;millions,0.6283;0.4229;0.3891;0.3674;0.1215,"[np.int64(-1), -1, -1, -1, -1]",58;-1;-1;-1;-1,58,58,Event Data Analysis
VAST,2011,Analysis of large digital collections with interactive visualization,10.1109/vast.2011.6102462,http://dx.doi.org/10.1109/VAST.2011.6102462,241.0,250.0,C,"To make decisions about the long-term preservation and access of large digital collections, archivists gather information such as the collections' contents, their organizational structure, and their file format composition. To date, the process of analyzing a collection - from data gathering to exploratory analysis and final conclusions - has largely been conducted using pen and paper methods. To help archivists analyze large-scale digital collections for archival purposes, we developed an interactive visual analytics application. The application narrows down different kinds of information about the collection, and presents them as meaningful data views. Multiple views and analysis features can be linked or unlinked on demand to enable researchers to compare and contrast different analyses, and to identify trends. We describe and present two user scenarios to show how the application allowed archivists to learn about a collection with accuracy, facilitated decision-making, and helped them arrive at conclusions.",Weijia Xu;Maria Esteva;Suyog Dott Jain;Varun Jain,Weijia Xu;Maria Esteva;Suyog Dutt Jain;Varun Jain,"University of Texas, Austin, USA;University of Texas, Austin, USA;University of Texas, Austin, USA;University of Texas, Austin, USA",10.1109/infvis.2000.885091;10.1109/tvcg.2008.172;10.1109/tvcg.2009.176;10.1109/vast.2007.4389006;10.1109/infvis.2004.64;10.1109/vast.2010.5652931;10.1109/infvis.1999.801860,"Digital collections, archival analysis, visual anaytics, data curation",19.0,8.0,34.0,717.0,,,digital collections archivists;interactive visual analytics;file format;decision;application narrows different,0.7552;0.5398;0.1837;0.0647;0.0387,"[np.int64(-1), np.int64(-1), -1, -1, -1]",16;108;-1;-1;-1,16;108,16,Digital Archive Management
Vis,2004,Visual Inspection Methods for Quality Control in Automotive Engineering,10.1109/visual.2004.111,http://dx.doi.org/10.1109/VISUAL.2004.111,3.0,3.0,M,"The automotive industry demands visual support for the verification of the quality of their products from the design phase to the manufacturing phase. This implies the need of tools for measurement planning, programming measuring devices, managing measurement data, and the visual exploration of the measurement results. To improve the quality control throughout the whole process chain an integration of such tools in a platform independent framework is crucial. We present eMMA (enhanced Measure Management Application), a client/server system integrating measurement planning, data management, and straightforward as well as sophisticated visual exploration tools in a single framework.",Hans Hagen;Andreas Disch;Jochen Ehret;Ralf Klein;Sascha Köhn;Dirk Zeckzer;Michael Münchhofen,H. Hagen;A. Disch;J. Ehret;R. Klein;S. Kohn;D. Zeckzer;M. Munchhofen,"DFKI GmbH, IVS, Kaiserslautern, Germany and IVs DFKI GmbH Kaiserslautern, Germany;DFKI GmbH, IVS, Kaiserslautern, Germany and IVs DFKI GmbH Kaiserslautern, Germany;DFKI GmbH, IVS, Kaiserslautern, Germany and IVs DFKI GmbH Kaiserslautern, Germany;DFKI GmbH, IVS, Kaiserslautern, Germany and IVs DFKI GmbH Kaiserslautern, Germany;DFKI GmbH, IVS, Kaiserslautern, Germany and IVs DFKI GmbH Kaiserslautern, Germany;DFKI GmbH, IVS, Kaiserslautern, Germany and IVs DFKI GmbH Kaiserslautern, Germany;ProCAEss GmbH Landau, Germany",,,4.0,0.0,0.0,328.0,,,visual exploration measurement;automotive industry demands;platform independent framework;implies need tools;verification,0.5622;0.3738;0.2810;0.2052;0.1541,"[np.int64(-1), -1, -1, -1, -1]",146;-1;-1;-1;-1,146,146,Visualization Techniques
InfoVis,2010,ManiWordle: Providing Flexible Control over Wordle,10.1109/tvcg.2010.175,http://dx.doi.org/10.1109/TVCG.2010.175,1190.0,1197.0,J,"Among the multifarious tag-clouding techniques, Wordle stands out to the community by providing an aesthetic layout, eliciting the emergence of the participatory culture and usage of tag-clouding in the artistic creations. In this paper, we introduce ManiWordle, a Wordle-based visualization tool that revamps interactions with the layout by supporting custom manipulations. ManiWordle allows people to manipulate typography, color, and composition not only for the layout as a whole, but also for the individual words, enabling them to have better control over the layout result. We first describe our design rationale along with the interaction techniques for tweaking the layout. We then present the results both from the preliminary usability study and from the comparative study between ManiWordle and Wordle. The results suggest that ManiWordle provides higher user satisfaction and an efficient method of creating the desired ""art work,"" harnessing the power behind the ever-increasing popularity of Wordle.",Kyle Koh;Bongshin Lee;Bo Hyoung Kim;Jinwook Seo,Kyle Koh;Bongshin Lee;Bohyoung Kim;Jinwook Seo,"Seoul National University, South Korea;Microsoft Research Limited, USA;Seoul National University, South Korea;Seoul National University, South Korea",10.1109/tvcg.2007.70541;10.1109/tvcg.2007.70515;10.1109/tvcg.2009.171;10.1109/vast.2009.5333443;10.1109/infvis.2003.1249031;10.1109/tvcg.2007.70541,"Interaction design, direct manipulation, flexibilty-usability tradeoff, tag-cloud, participatory visualization, user study ",140.0,84.0,30.0,1462.0,,,wordle based visualization;tag clouding artistic;tweaking layout;design rationale;higher user,0.6447;0.4584;0.3590;0.2277;0.1104,"[np.int64(-1), -1, -1, -1, -1]",91;-1;-1;-1;-1,91,91,Wordle Visualizations
InfoVis,2015,How do People Make Sense of Unfamiliar Visualizations?: A Grounded Model of Novice's Information Visualization Sensemaking,10.1109/tvcg.2015.2467195,http://dx.doi.org/10.1109/TVCG.2015.2467195,499.0,508.0,J,"In this paper, we would like to investigate how people make sense of unfamiliar information visualizations. In order to achieve the research goal, we conducted a qualitative study by observing 13 participants when they endeavored to make sense of three unfamiliar visualizations (i.e., a parallel-coordinates plot, a chord diagram, and a treemap) that they encountered for the first time. We collected data including audio/video record of think-aloud sessions and semi-structured interview; and analyzed the data using the grounded theory method. The primary result of this study is a grounded model of NOvice's information VIsualization Sensemaking (NOVIS model), which consists of the five major cognitive activities: 1 encountering visualization, 2 constructing a frame, 3 exploring visualization, 4 questioning the frame, and 5 floundering on visualization. We introduce the NOVIS model by explaining the five activities with representative quotes from our participants. We also explore the dynamics in the model. Lastly, we compare with other existing models and share further research directions that arose from our observations.",Sukwon Lee;Sung-Hee Kim;Ya-Hsin Hung;Heidi Lam;Youn-Ah Kang;Ji Soo Yi,Sukwon Lee;Sung-Hee Kim;Ya-Hsin Hung;Heidi Lam;Youn-Ah Kang;Ji Soo Yi,"School of Industrial Engineering, Purdue University, West Lafayette, IN, USA;Department of Computer Science, University of British Columbia, Vancouver, BC, Canada;School of Industrial Engineering, Purdue University, West Lafayette, IN, USA;Google Inc., Mountain View, CA, USA;Techno-Art Division, Yonsei University, Incheon, South Korea;School of Industrial Engineering, Purdue University, West Lafayette, IN, USA",10.1109/tvcg.2013.234;10.1109/tvcg.2014.2346984;10.1109/tvcg.2010.164;10.1109/vast.2011.6102435;10.1109/tvcg.2014.2346452;10.1109/tvcg.2010.177;10.1109/tvcg.2014.2346481;10.1109/tvcg.2010.179;10.1109/tvcg.2007.70515;10.1109/tvcg.2013.234,"Sensemaking model, information visualization, novice users, grounded theory, qualitative study",147.0,91.0,48.0,4623.0,,,visualization sensemaking;paper like investigate;quotes;including audio video;primary,0.7649;0.1343;0.0587;0.0435;0.0190,"[np.int64(-1), -1, -1, -1, -1]",94;-1;-1;-1;-1,94,94,Visualization Literacy
InfoVis,1998,Dynamic aggregation with circular visual designs,10.1109/infvis.1998.729557,http://dx.doi.org/10.1109/INFVIS.1998.729557,35.0,,C,"One very effective method for managing large data sets is aggregation or binning. We consider two aggregation methods that are tightly coupled with interactive manipulation and the visual representation of the data. Through this integration we hope to provide effective support for the aggregation process, specifically by enabling: 1) automatic aggregation, 2) continuous change and control of the aggregation level, 3) spatially based aggregates, 4) context maintenance across different aggregate levels, and 5) feedback on the level of aggregation.",Mei C. Chuah,M.C. Chuah,"School of Computer Science, Carnegie Mellon University, Pittsburgh, PA, USA",10.1109/infvis.1997.636787;10.1109/visual.1992.235206,,128.0,35.0,13.0,331.0,,,aggregation binning;interactive manipulation visual;context maintenance different;specifically;hope,0.6160;0.4696;0.1916;0.1244;0.0346,"[np.int64(-1), -1, -1, -1, -1]",117;-1;-1;-1;-1,117,117,Cluster Visualization
Vis,2023,"2D, 2.5D, or 3D? An Exploratory Study on Multilayer Network Visualisations in Virtual Reality",10.1109/tvcg.2023.3327402,http://dx.doi.org/10.1109/TVCG.2023.3327402,469.0,479.0,J,"Relational information between different types of entities is often modelled by a multilayer network (MLN) – a network with subnetworks represented by layers. The layers of an MLN can be arranged in different ways in a visual representation, however, the impact of the arrangement on the readability of the network is an open question. Therefore, we studied this impact for several commonly occurring tasks related to MLN analysis. Additionally, layer arrangements with a dimensionality beyond 2D, which are common in this scenario, motivate the use of stereoscopic displays. We ran a human subject study utilising a Virtual Reality headset to evaluate 2D, 2.5D, and 3D layer arrangements. The study employs six analysis tasks that cover the spectrum of an MLN task taxonomy, from path finding and pattern identification to comparisons between and across layers. We found no clear overall winner. However, we explore the task-to-arrangement space and derive empirical-based recommendations on the effective use of 2D, 2.5D, and 3D layer arrangements for MLNs.",Stefan P. Feyer;Bruno Pinaud;Stephen G. Kobourov;Nicolas Brich;Michael Krone;Andreas Kerren;Michael Behrisch 0001;Falk Schreiber;Karsten Klein 0001,Stefan P. Feyer;Bruno Pinaud;Stephen Kobourov;Nicolas Brich;Michael Krone;Andreas Kerren;Michael Behrisch;Falk Schreiber;Karsten Klein,"Life Science Informatics, University of Konstanz, Germany;Univ. Bordeaux, CNRS, Bordeaux INP, LaBRI, UMR 5800, France;University of Arizona, USA;University of Tübingen, Germany;University of Tübingen, Germany;Linköping University, Sweden;Utrecht University, NL;University of Konstanz, Germany;Life Science Informatics, University of Konstanz, Germany",0.1109/infvis.2005.1532136;10.1109/tvcg.2016.2599107;10.1109/tvcg.2020.3030371;10.1109/tvcg.2021.3114863;10.1109/tvcg.2014.2346441;10.1109/tvcg.2020.3030427;10.1109/tvcg.2018.2865192,"Network,Guidelines,VisDesign,HumanQuant,CompSystems",,3.0,67.0,671.0,,,arrangement readability network;utilising virtual reality;layers layers;dimensionality 2d common;different,0.5976;0.3830;0.3112;0.3006;0.0549,"[np.int64(-1), -1, -1, -1, -1]",-1;-1;-1;-1;-1,,-1,Interactive 3D Visualization
Vis,1991,Gray scale diagrams as business charts,10.1109/visual.1991.175791,http://dx.doi.org/10.1109/VISUAL.1991.175791,140.0,147.0,C,"Gray-scale diagrams, which can present large amounts of quantitative information in a compact format, are considered as a candidate for business charts. Hundreds of data points can easily be represented in one diagram, using small gray-scale squares (or tiles), without visually overloading a viewer. An experiment was done to compare the subjects' responses to questions from three types of charts, traditional column and line charts and gray-scale tile charts. The results showed that questions were answered more correctly and more quickly using gray-scale tile charts than using traditional charts. However, subjects reported they experienced more strain using gray-scale charts.&lt;&lt;ETX&gt;&gt;",W. R. Feeney,W.R. Feeney,"Infomation and Decision Systems Department, San Diego State University, San Diego, CA, USA",,,1.0,1.0,12.0,83.0,,,business charts;visually overloading viewer;scale tile;subjects reported experienced;answered,0.6852;0.2704;0.2298;0.1779;-0.0573,"[np.int64(-1), -1, -1, -1, -1]",146;-1;-1;-1;-1,146,146,Visualization Techniques
Vis,2024,StuGPTViz: A Visual Analytics Approach to Understand Student-ChatGPT Interactions,10.1109/tvcg.2024.3456363,http://dx.doi.org/10.1109/TVCG.2024.3456363,908.0,918.0,J,"The integration of Large Language Models (LLMs), especially ChatGPT, into education is poised to revolutionize students' learning experiences by introducing innovative conversational learning methodologies. To empower students to fully leverage the capabilities of ChatGPT in educational scenarios, understanding students' interaction patterns with ChatGPT is crucial for instructors. However, this endeavor is challenging due to the absence of datasets focused on student-ChatGPT conversations and the complexities in identifying and analyzing the evolutional interaction patterns within conversations. To address these challenges, we collected conversational data from 48 students interacting with ChatGPT in a master's level data visualization course over one semester. We then developed a coding scheme, grounded in the literature on cognitive levels and thematic analysis, to categorize students' interaction patterns with ChatGPT. Furthermore, we present a visual analytics system, StuGPTViz, that tracks and compares temporal patterns in student prompts and the quality of ChatGPT's responses at multiple scales, revealing significant pedagogical insights for instructors. We validated the system's effectiveness through expert interviews with six data visualization instructors and three case studies. The results confirmed StuGPTViz's capacity to enhance educators' insights into the pedagogical value of ChatGPT. We also discussed the potential research opportunities of applying visual analytics in education and developing AI-driven personalized learning solutions.",Zixin Chen;Jiachen Wang;Meng Xia 0002;Kento Shigyo;Dingdong Liu;Rong Zhang 0011;Huamin Qu,Zixin Chen;Jiachen Wang;Meng Xia;Kento Shigyo;Dingdong Liu;Rong Zhang;Huamin Qu,"Hong Kong University of Science and Technology, Hong Kong, China;Hong Kong University of Science and Technology, Hong Kong, China;Texas A&M University, College Station, Texas, the United States;Hong Kong University of Science and Technology, Hong Kong, China;Hong Kong University of Science and Technology, Hong Kong, China;Hong Kong University of Science and Technology, Hong Kong, China;Hong Kong University of Science and Technology, Hong Kong, China",10.1109/tvcg.2023.3327378;10.1109/tvcg.2023.3327165;10.1109/tvcg.2013.162;10.1109/tvcg.2016.2598444;10.1109/vast.2011.6102472;10.1109/tvcg.2015.2467555;10.1109/infvis.2005.1532152;10.1109/tvcg.2014.2346481,"Visual analytics for education,ChatGPT for education,,,student-ChatGPT interaction",,0.0,77.0,429.0,,,visualization instructors;large language models;value chatgpt discussed;evolutional interaction patterns;studies results,0.5354;0.3632;0.2603;0.2269;0.1066,"[np.int64(-1), -1, -1, -1, -1]",94;-1;-1;-1;-1,94,94,Visualization Literacy
Vis,2005,Extracting higher order critical points and topological simplification of 3D vector fields,10.1109/visual.2005.1532842,http://dx.doi.org/10.1109/VISUAL.2005.1532842,559.0,566.0,C,"This paper presents an approach to extracting and classifying higher order critical points of 3D vector fields. To do so, we place a closed convex surface s around the area of interest. Then we show that the complete 3D classification of a critical point into areas of different flow behavior is equivalent to extracting the topological skeleton of an appropriate 2D vector field on s, if each critical point is equipped with an additional bit of information. Out of this skeleton, we create an icon which replaces the complete topological structure inside s for the visualization. We apply our method to find a simplified visual representation of clusters of critical points, leading to expressive visualizations of topologically complex 3D vector fields.",Tino Weinkauf;Holger Theisel;Kuangyu Shi;Hans-Christian Hege;Hans-Peter Seidel,T. Weinkauf;H. Theisel;K. Shi;H.-C. Hege;H.-P. Seidel,"ZIB Berlin, Germany;MPI Saarbrücken, Germany;MPI Saarbrücken, Germany;ZIB Berlin, Germany;MPI Saarbrücken, Germany",10.1109/visual.1999.809907;10.1109/visual.2002.1183786;10.1109/visual.2000.885714;10.1109/visual.1991.175773;10.1109/visual.2000.885716;10.1109/visual.2001.964507;10.1109/visual.2003.1250376;10.1109/visual.1999.809907,,95.0,15.0,22.0,261.0,,,3d vector fields;expressive visualizations topologically;clusters critical;skeleton;method simplified,0.5923;0.5839;0.2501;0.0720;0.0347,"[np.int64(-1), np.int64(-1), -1, -1, -1]",60;146;-1;-1;-1,60;146,60,Vector Field Visualization
InfoVis,2019,The Perceptual Proxies of Visual Comparison,10.1109/tvcg.2019.2934786,http://dx.doi.org/10.1109/TVCG.2019.2934786,1012.0,1021.0,J,"Perceptual tasks in visualizations often involve comparisons. Of two sets of values depicted in two charts, which set had values that were the highest overall? Which had the widest range? Prior empirical work found that the performance on different visual comparison tasks (e.g., “biggest delta”, “biggest correlation”) varied widely across different combinations of marks and spatial arrangements. In this paper, we expand upon these combinations in an empirical evaluation of two new comparison tasks: the “biggest mean” and “biggest range” between two sets of values. We used a staircase procedure to titrate the difficulty of the data comparison to assess which arrangements produced the most precise comparisons for each task. We find visual comparisons of biggest mean and biggest range are supported by some chart arrangements more than others, and that this pattern is substantially different from the pattern for other tasks. To synthesize these dissonant findings, we argue that we must understand which features of a visualization are actually used by the human visual system to solve a given task. We call these perceptual proxies. For example, when comparing the means of two bar charts, the visual system might use a “Mean length” proxy that isolates the actual lengths of the bars and then constructs a true average across these lengths. Alternatively, it might use a “Hull Area” proxy that perceives an implied hull bounded by the bars of each chart and then compares the areas of these hulls. We propose a series of potential proxies across different tasks, marks, and spatial arrangements. Simple models of these proxies can be empirically evaluated for their explanatory power by matching their performance to human performance across these marks, arrangements, and tasks. We use this process to highlight candidates for perceptual proxies that might scale more broadly to explain performance in visual comparison.",Nicole Jardine;Brian D. Ondov;Niklas Elmqvist;Steven Franconeri,Nicole Jardine;Brian D. Ondov;Niklas Elmqvist;Steven Franconeri,"Cook County Assessor's Office, Northwestern University, Chicago;National Institutes of Health, Bethesda, USA and University of Maryland, College Park, USA;University of Maryland, College Park, USA;Cook County Assessor's Office, Northwestern University, Evanston, USA",10.1109/infvis.2005.1532136;10.1109/tvcg.2015.2466971;10.1109/tvcg.2017.2744199;10.1109/tvcg.2014.2346979;10.1109/tvcg.2010.162;10.1109/tvcg.2018.2864884;10.1109/tvcg.2007.70515,"Graphical perception,visual perception,visual comparison,crowdsourced evaluation",27.0,29.0,29.0,1253.0,HM,,visualizations involve comparisons;true average lengths;hull area proxy;actually used human;bar,0.6987;0.2348;0.2001;0.1303;0.1183,"[np.int64(-1), -1, -1, -1, -1]",135;-1;-1;-1;-1,135,135,Comparative Visualization Bias
Vis,2007,Efficient Visualization of Lagrangian Coherent Structures by filtered AMR Ridge Extraction,10.1109/tvcg.2007.70554,http://dx.doi.org/10.1109/TVCG.2007.70554,1456.0,1463.0,J,"This paper presents a method for filtered ridge extraction based on adaptive mesh refinement. It is applicable in situations where the underlying scalar field can be refined during ridge extraction. This requirement is met by the concept of Lagrangian coherent structures which is based on trajectories started at arbitrary sampling grids that are independent of the underlying vector field. The Lagrangian coherent structures are extracted as ridges in finite Lyapunov exponent fields computed from these grids of trajectories. The method is applied to several variants of finite Lyapunov exponents, one of which is newly introduced. High computation time due to the high number of required trajectories is a main drawback when computing Lyapunov exponents of 3-dimensional vector fields. The presented method allows a substantial speed-up by avoiding the seeding of trajectories in regions where no ridges are present or do not satisfy the prescribed filter criteria such as a minimum finite Lyapunov exponent.",Filip Sadlo;Ronald Peikert,Filip Sadlo;Ronald Peikert,"ETH Zurich, Switzerland;ETH Zurich, Switzerland",10.1109/visual.1999.809896;10.1109/visual.2004.99;10.1109/tvcg.2007.70551;10.1109/visual.1999.809896,"Ridge extraction, flow visualization, coherent structures, vector field topology, unsteady vector fields",213.0,127.0,30.0,778.0,,,filtered ridge extraction;computed grids trajectories;finite lyapunov exponents;field lagrangian;situations underlying,0.5971;0.5252;0.3308;0.2010;-0.1140,"[np.int64(-1), np.int64(-1), -1, -1, -1]",72;119;-1;-1;-1,72;119,72,Ridge Extraction Techniques
InfoVis,2000,"Creativity, complexity, and precision: information visualization for (landscape) architecture",10.1109/infvis.2000.885105,http://dx.doi.org/10.1109/INFVIS.2000.885105,167.0,171.0,C,"Drawing on ethnographic studies of (landscape) architects at work, this paper presents a human-centered approach to information visualization. A 3D collaborative electronic workspace allows people to configure, save and browse arrangements of heterogeneous work materials. Spatial arrangements and links are created and maintained as an integral part of ongoing work with 'live' documents and objects. The result is an extension of the physical information space of the architects' studio that utilizes the potential of electronic data storage, visualization and network technologies to support work with information in context.",Monika Büscher;Dan Shapiro;Michael Christensen 0002;Preben Mogensen 0002;Peter Ørbæk,M. Buscher;D. Shapiro;M. Christensen;P. Mogensen;P. Orbaek,"Department of Computer Science, University of Århus, Aarhus, Denmark;Department of Computer Science, University of Århus, Aarhus, Denmark;Department of Computer Science, University of Århus, Aarhus, Denmark;Department of Sociology, Lancaster University, Lancaster, UK;Department of Sociology, Lancaster University, Lancaster, UK",,"Information visualization, architecture,work materials, context,spatio-temporal order, electronic workspace ",11.0,2.0,11.0,171.0,,,collaborative electronic workspace;visualization 3d;studies landscape architects;data;integral ongoing,0.6154;0.4276;0.4183;0.1960;0.0039,"[np.int64(-1), -1, -1, -1, -1]",121;-1;-1;-1;-1,121,121,Interactive Software Tools
Vis,2023,Dead or Alive: Continuous Data Profiling for Interactive Data Science,10.1109/tvcg.2023.3327367,http://dx.doi.org/10.1109/TVCG.2023.3327367,197.0,207.0,J,"Profiling data by plotting distributions and analyzing summary statistics is a critical step throughout data analysis. Currently, this process is manual and tedious since analysts must write extra code to examine their data after every transformation. This inefficiency may lead to data scientists profiling their data infrequently, rather than after each transformation, making it easy for them to miss important errors or insights. We propose continuous data profiling as a process that allows analysts to immediately see interactive visual summaries of their data throughout their data analysis to facilitate fast and thorough analysis. Our system, AutoProfiler, presents three ways to support continuous data profiling: (1) it automatically displays data distributions and summary statistics to facilitate data comprehension; (2) it is live, so visualizations are always accessible and update automatically as the data updates; (3) it supports follow up analysis and documentation by authoring code for the user in the notebook. In a user study with 16 participants, we evaluate two versions of our system that integrate different levels of automation: both automatically show data profiles and facilitate code authoring, however, one version updates reactively (“live”) and the other updates only on demand (“dead”). We find that both tools, dead or alive, facilitate insight discovery with 91% of user-generated insights originating from the tools rather than manual profiling code written by users. Participants found live updates intuitive and felt it helped them verify their transformations while those with on-demand profiles liked the ability to look at past visualizations. We also present a longitudinal case study on how AutoProfiler helped domain scientists find serendipitous insights about their data through automatic, live data profiles. Our results have implications for the design of future tools that offer automated data analysis support.",Will Epperson;Vaishnavi Gorantla;Dominik Moritz;Adam Perer,Will Epperson;Vaishnavi Gorantla;Dominik Moritz;Adam Perer,"Carnegie Mellon University, USA;Carnegie Mellon University, USA;Carnegie Mellon University, USA;Carnegie Mellon University, USA",0.1109/tvcg.2018.2865040;10.1109/tvcg.2012.219;10.1109/tvcg.2015.2467191,"Data Profiling,Data Quality,Exploratory Data Analysis,Interactive Data Science",,7.0,51.0,1797.0,HM,,data scientists profiling;past visualizations;live updates intuitive;verify transformations;easy,0.6679;0.3681;0.2892;0.1827;0.0973,"[np.int64(-1), -1, -1, -1, -1]",64;-1;-1;-1;-1,64,64,Collaborative Data Analysis
Vis,1992,Visualization of simulated airflow in a clean room,10.1109/visual.1992.235213,http://dx.doi.org/10.1109/VISUAL.1992.235213,156.0,163.0,C,"Techniques for visualizing a simulated air flow in a clean room are developed by using an efficient cell traverse of tetrahedral cells generated from irregular volumes. The proposed techniques, probing and stream line display, are related to the measurement techniques used in actual clean rooms. The efficient traverse makes it possible to move freely around a given irregular volume and to spawn off stream lines. A successful application of these techniques to a problem in a clean room is also described.&lt;&lt;ETX&gt;&gt;",Koji Koyamada,K. Koyamada,"Tokyo Research Laboratory, IBM Japan Limited, Japan",10.1109/visual.1991.175771;10.1109/visual.1991.175771,,12.0,7.0,9.0,101.0,,,visualizing simulated air;efficient cell;room developed using;display related measurement;problem clean,0.6619;0.3495;0.3461;0.2227;0.2006,"[np.int64(-1), -1, -1, -1, -1]",67;-1;-1;-1;-1,67,67,Atmospheric Visualization
VAST,2010,An exploratory study of co-located collaborative visual analytics around a tabletop display,10.1109/vast.2010.5652880,http://dx.doi.org/10.1109/VAST.2010.5652880,179.0,186.0,C,"Co-located collaboration can be extremely valuable during complex visual analytics tasks. This paper presents an exploratory study of a system designed to support collaborative visual analysis tasks on a digital tabletop display. Fifteen participant pairs employed Cam-biera, a visual analytics system, to solve a problem involving 240 digital documents. Our analysis, supported by observations, system logs, questionnaires, and interview data, explores how pairs approached the problem around the table. We contribute a unique, rich understanding of how users worked together around the table and identify eight types of collaboration styles that can be used to identify how closely people work together while problem solving. We show how the closeness of teams' collaboration influenced how well they performed on the task overall. We further discuss the role of the tabletop for visual analytics tasks and derive novel design implications for future co-located collaborative tabletop problem solving systems.",Petra Isenberg;Danyel Fisher;Meredith Ringel Morris;Kori Inkpen;Mary Czerwinski,Petra Isenberg;Danyel Fisher;Meredith Ringel Morris;Kori Inkpen;Mary Czerwinski,"Microsoft Research Limited, USA and INRIA, France;Microsoft Research Limited, USA;Microsoft Research Limited, USA;Microsoft Research Limited, USA;Microsoft Research Limited, USA",10.1109/vast.2006.261439;10.1109/vast.2007.4389006;10.1109/vast.2006.261415;10.1109/tvcg.2007.70577;10.1109/vast.2008.4677358;10.1109/tvcg.2007.70568;10.1109/vast.2006.261420;10.1109/vast.2006.261439,,127.0,71.0,22.0,816.0,HM,,collaborative visual analysis;tabletop problem;logs questionnaires interview;biera;worked,0.7102;0.3995;0.1447;0.1400;0.0325,"[np.int64(-1), -1, -1, -1, -1]",146;-1;-1;-1;-1,146,146,Visualization Techniques
Vis,2009,Color Seamlessness in Multi-Projector Displays Using Constrained Gamut Morphing,10.1109/tvcg.2009.124,http://dx.doi.org/10.1109/TVCG.2009.124,1317.0,1326.0,J,"Multi-projector displays show significant spatial variation in 3D color gamut due to variation in the chromaticity gamuts across the projectors, vignetting effect of each projector and also overlap across adjacent projectors. In this paper we present a new constrained gamut morphing algorithm that removes all these variations and results in true color seamlessness across tiled multi-projector displays. Our color morphing algorithm adjusts the intensities of light from each pixel of each projector precisely to achieve a smooth morphing from one projector's gamut to the other's through the overlap region. This morphing is achieved by imposing precise constraints on the perceptual difference between the gamuts of two adjacent pixels. In addition, our gamut morphing assures a C1 continuity yielding visually pleasing appearance across the entire display. We demonstrate our method successfully on a planar and a curved display using both low and high-end projectors. Our approach is completely scalable, efficient and automatic. We also demonstrate the real-time performance of our image correction algorithm on GPUs for interactive applications. To the best of our knowledge, this is the first work that presents a scalable method with a strong foundation in perception and realizes, for the first time, a truly seamless display where the number of projectors cannot be deciphered.",Behzad Sajadi;Maxim Lazarov;M. Gopi 0001;Aditi Majumder,Behzad Sajadi;Maxim Lazarov;M. Gopi;Aditi Majumder,"Computer Science Department, University of California, Irvine, USA;Computer Science Department, University of California, Irvine, USA;Computer Science Department, University of California, Irvine, USA;Computer Science Department, University of California, Irvine, USA",10.1109/visual.2001.964508;10.1109/visual.2002.1183793;10.1109/visual.2000.885684;10.1109/visual.1999.809883;10.1109/tvcg.2007.70586;10.1109/tvcg.2006.121;10.1109/visual.2001.964508,"Color Calibration, Multi-Projector Displays, Tiled Displays",87.0,43.0,19.0,738.0,,,morphing projector gamut;gpus;significant spatial variation;assures c1 continuity;realizes time truly,0.6748;0.2768;0.1986;0.0790;0.0175,"[np.int64(-1), -1, -1, -1, -1]",0;-1;-1;-1;-1,0,0,Projector Technology
Vis,2024,“I Came Across a Junk”: Understanding Design Flaws of Data Visualization from the Public's Perspective,10.1109/tvcg.2024.3456341,http://dx.doi.org/10.1109/TVCG.2024.3456341,393.0,403.0,J,"The visualization community has a rich history of reflecting upon visualization design flaws. Although research in this area has remained lively, we believe it is essential to continuously revisit this classic and critical topic in visualization research by incorporating more empirical evidence from diverse sources, characterizing new design flaws, building more systematic theoretical frameworks, and understanding the underlying reasons for these flaws. To address the above gaps, this work investigated visualization design flaws through the lens of the public, constructed a framework to summarize and categorize the identified flaws, and explored why these flaws occur. Specifically, we analyzed 2227 flawed data visualizations collected from an online gallery and derived a design task-associated taxonomy containing 76 specific design flaws. These flaws were further classified into three high-level categories (i.e., misinformation, uninformativeness, unsociability) and ten subcategories (e.g., inaccuracy, unfairness, ambiguity). Next, we organized five focus groups to explore why these design flaws occur and identified seven causes of the flaws. Finally, we proposed a research agenda for combating visualization design flaws and summarize nine research opportunities.",Xingyu Lan;Yu Liu,Xingyu Lan;Yu Liu,"Fudan University, China;University of Edinburgh, U.K.",10.1109/tvcg.2023.3326914;10.1109/tvcg.2022.3209490;10.1109/tvcg.2021.3114830;10.1109/tvcg.2012.197;10.1109/tvcg.2013.234;10.1109/tvcg.2014.2346984;10.1109/tvcg.2021.3114835;10.1109/tvcg.2021.3114804;10.1109/tvcg.2007.70535;10.1109/tvcg.2023.3327385;10.1109/tvcg.2016.2598920;10.1109/tvcg.2018.2865240;10.1109/tvcg.2014.2346419;10.1109/tvcg.2021.3114959;10.1109/tvcg.2023.3327158;10.1109/tvcg.2019.2934538,"Visualization Design,General Public,,,Chart Junk,Deceptive Visualization,Misinformation,User Experience",,0.0,75.0,326.0,HM,,combating visualization design;inaccuracy unfairness ambiguity;online gallery;associated taxonomy containing;2227,0.8039;0.2087;0.1297;0.0192;-0.0595,"[np.int64(-1), -1, -1, -1, -1]",138;-1;-1;-1;-1,138,138,Innovative Visualization Design
Vis,2010,Articulated Planar Reformation for Change Visualization in Small Animal Imaging,10.1109/tvcg.2010.134,http://dx.doi.org/10.1109/TVCG.2010.134,1396.0,1404.0,J,"The analysis of multi-timepoint whole-body small animal CT data is greatly complicated by the varying posture of the subject at different timepoints. Due to these variations, correctly relating and comparing corresponding regions of interest is challenging.In addition, occlusion may prevent effective visualization of these regions of interest. To address these problems, we have developed a method that fully automatically maps the data to a standardized layout of sub-volumes, based on an articulated atlas registration.We have dubbed this process articulated planar reformation, or APR. A sub-volume can be interactively selected for closer inspection and can be compared with the corresponding sub-volume at the other timepoints, employing a number of different comparative visualization approaches. We provide an additional tool that highlights possibly interesting areas based on the change of bone density between timepoints. Furthermore we allow visualization of the local registration error, to give an indication of the accuracy of the registration. We have evaluated our approach on a case that exhibits cancer-induced bone resorption.",Peter Kok;Martin Baiker;Emile A. Hendriks;Frits H. Post;Jouke Dijkstra;Clemens W. G. M. Löwik;Boudewijn P. F. Lelieveldt;Charl P. Botha,Peter Kok;Martin Baiker;Emile A. Hendriks;Frits H. Post;Jouke Dijkstra;Clemens W.G.M. Lowik;Boudewijn P.F. Lelieveldt;Charl P. Botha,"Division of Image Processing, Leiden University Medical Center, Netherlands and Computer Graphics section Department of Mediamatics, Delft University of Technnology, Netherlands;Division of Image Processing, Leiden University Medical Center, Netherlands;Vision Lab, Department of Mediamatics, Delft University of Technnology, Netherlands;Computer Graphics section Department of Mediamatics, Delft University of Technnology, Netherlands;Division of Image Processing, Leiden University Medical Center, Netherlands;Department of Endocrinology, Leiden University Medical Center, Netherlands;Division of Image Processing, Leiden University Medical Center, Netherlands and Vision Lab, Department of Mediamatics, Delft University of Technnology, Netherlands;Division of Image Processing, Leiden University Medical Center, Netherlands and Computer Graphics section Department of Mediamatics, Delft University of Technnology, Netherlands",10.1109/tvcg.2009.169;10.1109/visual.2002.1183754;10.1109/visual.2003.1250400;10.1109/tvcg.2006.140;10.1109/tvcg.2008.143;10.1109/tvcg.2006.164;10.1109/tvcg.2009.111;10.1109/tvcg.2009.169,"Small animal imaging, comparative visualization, multi-timepoint, molecular imaging, articulated planar reformation",44.0,22.0,28.0,439.0,,,animal ct data;articulated planar reformation;automatically maps data;registration error indication;timepoints employing number,0.5875;0.3796;0.2212;0.1676;0.0938,"[np.int64(-1), -1, -1, -1, -1]",33;-1;-1;-1;-1,33,33,Medical Imaging Analysis
Vis,1998,Pixel masks for screen-door transparency,10.1109/visual.1998.745323,http://dx.doi.org/10.1109/VISUAL.1998.745323,351.0,358.0,C,"Rendering objects transparently gives additional insight in complex and overlapping structures. However, traditional techniques for the rendering of transparent objects such as alpha blending are not very well suited for the rendering of multiple transparent objects in dynamic scenes. Screen door transparency is a technique to render transparent objects in a simple and efficient way: no sorting is required and intersecting polygons can be handled without further preprocessing. With this technique, polygons are rendered through a mask: only where the mask is present, pixels are set. However, artifacts such as incorrect opacities and distracting patterns can easily occur if the masks are not carefully designed. The requirements on the masks are considered. Next, three algorithms are presented for the generation of pixel masks. One algorithm is designed for the creation of small (e.g. 4/spl times/4) masks. The other two algorithms can be used for the creation of larger masks (e.g. 32/spl times/32). For each of these algorithms, results are presented and discussed.",Jurriaan D. Mulder;Frans C. A. Groen;Jarke J. van Wijk,J.D. Mulder;F.C.A. Groen;J.J. van Wijk,"Center of Mathematics and Computer Science, Amsterdam, Netherlands;Faculty of Mathematics, Computer Science, Physics, and Astronomy, University of Amsterdam, Netherlands;Faculty of Mathematics and Computer Science, Eindhovan University of Technology, Netherlands",10.1109/visual.1990.146361;10.1109/visual.1990.146361,Screen-Door Transparency,40.0,4.0,11.0,135.0,,,techniques rendering transparent;intersecting polygons;scenes screen door;algorithm designed creation;32,0.6147;0.3273;0.3244;0.1795;0.0310,"[np.int64(-1), -1, -1, -1, -1]",43;-1;-1;-1;-1,43,43,Illustrative Rendering Techniques
Vis,2000,Visualizing high-dimensional predictive model quality,10.1109/visual.2000.885740,http://dx.doi.org/10.1109/VISUAL.2000.885740,493.0,496.0,C,"Using inductive learning techniques to construct classification models from large, high-dimensional data sets is a useful way to make predictions in complex domains. However, these models can be difficult for users to understand. We have developed a set of visualization methods that help users to understand and analyze the behavior of learned models, including techniques for high-dimensional data space projection, display of probabilistic predictions, variable/class correlation, and instance mapping. We show the results of applying these techniques to models constructed from a benchmark data set of census data, and draw conclusions about the utility of these methods for model understanding.",Penny Rheingans;Marie desJardins,P. Rheingans;M. DesJardins,"Artificial Intelligence Center, SRI International, Inc., USA;Department of Computer Science and Electrical Engineering, University of Maryland Baltimore County, USA",10.1109/visual.1997.663922;10.1109/infvis.1998.729565;10.1109/visual.1990.146402;10.1109/visual.1997.663868;10.1109/visual.1997.663922,,57.0,12.0,14.0,166.0,,,using inductive learning;set visualization methods;census data;users understand developed;high,0.4724;0.3630;0.2960;0.2482;-0.0118,"[-1, -1, -1, -1, -1]",-1;-1;-1;-1;-1,,-1,Interactive 3D Visualization
Vis,1996,Flexible information visualization of multivariate data from biological sequence similarity searches,10.1109/visual.1996.567796,http://dx.doi.org/10.1109/VISUAL.1996.567796,133.0,140.0,C,"Information visualization faces challenges presented by the need to represent abstract data and the relationships within the data. Previously, we presented a system for visualizing similarities between a single DNA sequence and a large database of other DNA sequences (E.H. Chi et al., 1995). Similarity algorithms generate similarity information in textual reports that can be hundreds or thousands of pages long. Our original system visualized the most important variables from these reports. However, the biologists we work with found this system so useful they requested visual representations of other variables. We present an enhanced system for interactive exploration of this multivariate data. We identify a larger set of useful variables in the information space. The new system involves more variables, so it focuses on exploring subsets of the data. We present an interactive system allowing mapping of different variables to different axes, incorporating animation using a time axis, and providing tools for viewing subsets of the data. Detail-on-demand is preserved by hyperlinks to the analysis reports. We present three case studies illustrating the use of these techniques. The combined technique of applying a time axis with a 3D scatter plot and query filters to visualization of biological sequence similarity data is both powerful and novel.",Ed Huai-hsin Chi;John Riedl;Elizabeth Shoop;John V. Carlis;Ernest Retzel;Phillip Barry,E.H.-H. Chi;J. Riedl;E. Shoop;J.V. Carlis;E. Retzel;P. Barry,"Computational Biology Centers, Medical School, University of Minnesota, Minneapolis, MN, USA;Department of Computer Science, University of Minnesota, Minneapolis, MN, USA;Department of Computer Science, University of Minnesota, Minneapolis, MN, USA;Computer Science Department, University of Minnesota, Minneapolis, MN, USA;Computer Science Department, University of Minnesota, Minneapolis, MN, USA;Computer Science Department, University of Minnesota, USA",10.1109/visual.1993.398883;10.1109/visual.1990.146402;10.1109/visual.1995.480794;10.1109/visual.1993.398883,"Information Visualization, Biomedical Visualization, Multimodal and Multidimensional Visualization, Applications of Visualization",41.0,10.0,19.0,119.0,,,visualization biological sequence;similarities;hyperlinks analysis reports;3d scatter;variables present,0.6690;0.3110;0.3097;0.1536;0.0746,"[np.int64(-1), -1, -1, -1, -1]",26;-1;-1;-1;-1,26,26,Biological Sequence Visualization
Vis,2005,Eyegaze analysis of displays with combined 2D and 3D views,10.1109/visual.2005.1532837,http://dx.doi.org/10.1109/VISUAL.2005.1532837,519.0,526.0,C,"Displays combining both 2D and 3D views have been shown to support higher performance on certain visualization tasks. However, it is not clear how best to arrange a combination of 2D and 3D views spatially in a display. In this study, we analyzed the eyegaze strategies of participants using two arrangements of 2D and 3D views to estimate the relative position of objects in a 3D scene. Our results show that the 3D view was used significantly more often than individual 2D views in both displays, indicating the importance of the 3D view for successful task completion. However, viewing patterns were significantly different between the two displays: transitions through centrally-placed views were always more frequent, and users avoided saccades between views that were far apart. Although the change in viewing strategy did not result in significant performance differences, error analysis indicates that a 3D overview in the center may reduce the number of serious errors compared to a 3D overview placed off to the side.",Melanie Tory;M. Stella Atkins;Arthur E. Kirkpatrick;Marios Nicolaou;Guang-Zhong Yang,M. Tory;M.S. Atkins;A.E. Kirkpatrick;M. Nicolaou;G.-Z. Yang,"Department of Computer, Science University of British, Columbia, USA;School of Computing Science, Simon Fraser University, Canada;School of Computing Science, Simon Fraser University, Canada;Department of Computing, Imperial College London, UK;Department of Computing, Imperial College London, UK",10.1109/visual.2003.1250396;10.1109/visual.1997.663914;10.1109/visual.2003.1250396,"visualization, 2D/3D combination display, user study, experiment, eyegaze analysis",37.0,7.0,19.0,308.0,,,3d views;avoided saccades;participants using arrangements;performance differences error;importance,0.5731;0.3491;0.1595;0.1570;0.1190,"[np.int64(-1), -1, -1, -1, -1]",82;-1;-1;-1;-1,82,82,3D/4D Visualization
VAST,2014,EvoRiver: Visual Analysis of Topic Coopetition on Social Media,10.1109/tvcg.2014.2346919,http://dx.doi.org/10.1109/TVCG.2014.2346919,1753.0,1762.0,J,"Cooperation and competition (jointly called “coopetition”) are two modes of interactions among a set of concurrent topics on social media. How do topics cooperate or compete with each other to gain public attention? Which topics tend to cooperate or compete with one another? Who plays the key role in coopetition-related interactions? We answer these intricate questions by proposing a visual analytics system that facilitates the in-depth analysis of topic coopetition on social media. We model the complex interactions among topics as a combination of carry-over, coopetition recruitment, and coopetition distraction effects. This model provides a close functional approximation of the coopetition process by depicting how different groups of influential users (i.e., “topic leaders”) affect coopetition. We also design EvoRiver, a time-based visualization, that allows users to explore coopetition-related interactions and to detect dynamically evolving patterns, as well as their major causes. We test our model and demonstrate the usefulness of our system based on two Twitter data sets (social topics data and business topics data).",Guodao Sun;Yingcai Wu;Shixia Liu;Tai-Quan Peng;Jonathan J. H. Zhu;Ronghua Liang,Guodao Sun;Yingcai Wu;Shixia Liu;Tai-Quan Peng;Jonathan J. H. Zhu;Ronghua Liang,Zhejiang University of Technology;Microsoft Research;Microsoft Research;Nanyang Technological University;City University of Hong Kong;Zhejiang University of Technology,10.1109/vast.2010.5652931;10.1109/tvcg.2012.291;10.1109/tvcg.2008.166;10.1109/tvcg.2011.239;10.1109/tvcg.2012.253;10.1109/tvcg.2014.2346920;10.1109/tvcg.2013.221;10.1109/tvcg.2013.196;10.1109/tvcg.2013.162;10.1109/vast.2010.5652931,"Topic coopetition, information diffusion, information propagation, time-based visualization",128.0,94.0,46.0,2033.0,,,topics cooperate compete;influential users;time based visualization;carry coopetition recruitment;evoriver,0.6188;0.3926;0.3056;0.2482;0.1292,"[np.int64(-1), -1, -1, -1, -1]",15;-1;-1;-1;-1,15,15,Topic Competition Dynamics
Vis,1992,Optimizing triangulations by curvature equalization,10.1109/visual.1992.235191,http://dx.doi.org/10.1109/VISUAL.1992.235191,333.0,339.0,C,"An algorithm that attempts to improve a triangulation by shifting the vertices so that curvature within the triangles is nearly equal is presented. Unnecessary triangles are removed. The method is an effective way of guaranteeing that the triangle vertices are points of higher curvature, and that the triangle edges correspond to distinctive edges on the surfaces. Triangulations of surfaces with constant curvature-and hence no distinctive features-will gain nothing from this or any other optimization algorithm. As demonstrated by the results, the techinque of moving triangle vertices can improve some triangulation models. Greatest improvements occur with surfaces characterized by sharp edges, such as the pyramid and ridge models. Less improvement occurs on models that already approximate the surface topology and/or have less distinctive features.&lt;&lt;ETX&gt;&gt;",Lori L. Scarlatos;Theo Pavlidis,L.L. Scarlatos;T. Pavlidis,"Grumman Data Systems, Woodbury, NY, USA;Department of Computer Science, State University of New York, Stony Brook, NY, USA",,,30.0,8.0,14.0,52.0,,,edges surfaces triangulations;optimization algorithm;removed method effective;occurs models approximate;higher,0.7736;0.2509;0.0902;0.0891;0.0151,"[np.int64(-1), -1, -1, -1, -1]",77;-1;-1;-1;-1,77,77,Mesh Geometry Techniques
Vis,2004,Panel 1: Can We Determine the Top Unresolved Problems of Visualization?,10.1109/visual.2004.76,http://dx.doi.org/10.1109/VISUAL.2004.76,563.0,566.0,M,"Many of us working in visualization have our own list of our top 5 or 10 unresolved problems in visualization. We have assembled a group of panelists to debate and perhaps reach concensus on the top problems in visualization that still need to be explored. We include panelists from both the information and scientific visualization domains. After our presentations, we encourage interaction with the audience to see if we can further formulate and perhaps finalize our list of top unresolved problems in visualization.",Theresa-Marie Rhyne;William L. Hibbard;Chris R. Johnson 0001;Chaomei Chen;Steve Eick,T. Rhyne;B. Hibbard;C. Johnson;Chaomei Chen;S. Eick,"North Carolina State University, USA;University of Wisconsin, Madison, USA;University of Utah, USA;Drexel University, USA;SSS-Research, Inc., University of Illinois, Chicago, USA",,,29.0,10.0,0.0,193.0,,,visualization need explored;panelists;list unresolved problems;scientific;reach,0.7006;0.2677;0.2152;0.1754;0.0523,"[np.int64(-1), -1, -1, -1, -1]",107;-1;-1;-1;-1,107,107,Visualization Techniques
VAST,2006,"Toward a Multi-Analyst, Collaborative Framework for Visual Analytics",10.1109/vast.2006.261439,http://dx.doi.org/10.1109/VAST.2006.261439,129.0,136.0,C,"We describe a framework for the display of complex, multidimensional data, designed to facilitate exploration, analysis, and collaboration among multiple analysts. This framework aims to support human collaboration by making it easier to share representations, to translate from one point of view to another, to explain arguments, to update conclusions when underlying assumptions change, and to justify or account for decisions or actions. Multidimensional visualization techniques are used with interactive, context-sensitive, and tunable graphs. Visual representations are flexibly generated using a knowledge representation scheme based on annotated logic; this enables not only tracking and fusing different viewpoints, but also unpacking them. Fusing representations supports the creation of multidimensional meta-displays as well as the translation or mapping from one point of view to another. At the same time, analysts also need to be able to unpack one another's complex chains of reasoning, especially if they have reached different conclusions, and to determine the implications, if any, when underlying assumptions or evidence turn out to be false. The framework enables us to support a variety of scenarios as well as to systematically generate and test experimental hypotheses about the impact of different kinds of visual representations upon interactive collaboration by teams of distributed analysts",Susan E. Brennan;Klaus Mueller 0001;Gregory J. Zelinsky;I. V. Ramakrishnan;David Scott Warren;Arie E. Kaufman,Susan E. Brennan;Klaus Mueller;Greg Zelinsky;IV Ramakrishnan;David S. Warren;Arie Kaufman,"Psychology Department, Stony Brook University, Stony Brook, NY, USA;Computer Science Department, Stony Brook University, Stony Brook, NY, USA;Psychology Department, Stony Brook University, Stony Brook, NY, USA;Computer Science Department, Stony Brook University, Stony Brook, NY, USA;Computer Science Department, Stony Brook University, Stony Brook, NY, USA;Computer Science Department, Stony Brook University, Stony Brook, NY, USA",,"visual analytics, collaborative and distributed visualization, data management and knowledge representation, visual knowledge discovery",59.0,34.0,25.0,548.0,,,graphs visual representations;multiple analysts framework;explain arguments update;unpack;false framework enables,0.5803;0.4719;0.2316;0.1375;0.0030,"[np.int64(-1), -1, -1, -1, -1]",96;-1;-1;-1;-1,96,96,Graph Visualization
Vis,1992,Four-dimensional views of 3D scalar fields,10.1109/visual.1992.235222,http://dx.doi.org/10.1109/VISUAL.1992.235222,84.0,91.0,C,"Scalar functions of three variables, w=f(x, y, z), are common in many types of scientific and medical applications. Such 3D scalar fields can be understood as elevation maps in four dimensions, with three independent variables (x, y, z) and a fourth, dependent, variable w that corresponds to the elevations. It is shown how techniques developed originally for the display of 3-manifolds in 4D Euclidean space can be adapted to visualize 3D scalar fields in a variety of ways.&lt;&lt;ETX&gt;&gt;",Andrew J. Hanson;Pheng-Ann Heng,A.J. Hanson;P.A. Heng,"CN/AS Division, CERN, Geneva, Switzerland and Department of Computer Science, Indiana University, Bloomington, IN, USA;Department of Computer Science, Indiana University, Bloomington, IN, USA",10.1109/visual.1990.146363;10.1109/visual.1991.175821;10.1109/visual.1990.146391;10.1109/visual.1990.146363,,38.0,14.0,17.0,75.0,,,visualize 3d scalar;manifolds;fourth dependent;techniques developed originally;lt lt,0.7166;0.3632;0.1413;0.1258;-0.0472,"[np.int64(-1), -1, -1, -1, -1]",82;-1;-1;-1;-1,82,82,3D/4D Visualization
Vis,1993,Volume sampled voxelization of geometric primitives,10.1109/visual.1993.398854,http://dx.doi.org/10.1109/VISUAL.1993.398854,78.0,84.0,C,"We present a 3-D antialiasing algorithm for voxel-based geometric models. The technique band-limits the continuous object before sampling it at the desired 3-D raster resolution. By precomputing tables of filter values for different types and sizes of geometric objects, the algorithm is very efficient and has a complexity that is linear with the number of voxels generated. The algorithm not only creates voxel models which are free from object space aliasing, but it also incorporates the image space antialiasing information as part of the view independent voxel model. The resulting alias-free voxel models have been used to model synthetic scenes, for discrete ray tracing applications. The discrete ray-traced image is superior in quality to the image generated with a conventional surface-based ray tracer, since silhouettes of objects, shadows, and reflections appear smooth (jaggy-less). In addition, the alias-free models are also suitable for intermixing with sampled datasets, since they can be treated uniformly as one common data representation.&lt;&lt;ETX&gt;&gt;",Sidney W. Wang;Arie E. Kaufman,S.W. Wang;A.E. Kaufman,"Department of Computer Science, State University of New York, Stony Brook, Stony Brook, NY, USA;Department of Computer Science, State University of New York, Stony Brook, Stony Brook, NY, USA",10.1109/visual.1992.235190;10.1109/visual.1992.235190,"voxelization, volume sampling, discrete ray tracing, filtering",196.0,37.0,20.0,347.0,,,antialiasing algorithm voxel;addition alias free;view;tracing applications;different types,0.7458;0.1773;0.1507;0.1370;0.0142,"[np.int64(-1), -1, -1, -1, -1]",47;-1;-1;-1;-1,47,47,Graphics Processing Techniques
Vis,2006,Multifield-Graphs: An Approach to Visualizing Correlations in Multifield Scalar Data,10.1109/tvcg.2006.165,http://dx.doi.org/10.1109/TVCG.2006.165,917.0,924.0,J,"We present an approach to visualizing correlations in 3D multifield scalar data. The core of our approach is the computation of correlation fields, which are scalar fields containing the local correlations of subsets of the multiple fields. While the visualization of the correlation fields can be done using standard 3D volume visualization techniques, their huge number makes selection and handling a challenge. We introduce the multifield-graph to give an overview of which multiple fields correlate and to show the strength of their correlation. This information guides the selection of informative correlation fields for visualization. We use our approach to visually analyze a number of real and synthetic multifield datasets",Natascha Sauber;Holger Theisel;Hans-Peter Seidel,Natascha Sauber;Holger Theisel;Hans-peter Seidel,"MPI Informatik Saarbrücken, Germany;MPI Informatik Saarbrücken, Germany;MPI Informatik Saarbrücken, Germany",10.1109/visual.1999.809865;10.1109/visual.2004.68;10.1109/visual.2004.46;10.1109/visual.1999.809905;10.1109/visual.2003.1250362;10.1109/visual.1999.809865,"Visualization, multifield, correlation",151.0,89.0,28.0,887.0,,,correlation fields visualization;standard 3d volume;strength;containing local;number real,0.8313;0.3755;0.0691;0.0102;-0.0072,"[np.int64(-1), -1, -1, -1, -1]",127;-1;-1;-1;-1,127,127,Field Visualization
Vis,2004,Immersive design of DNA molecules with a tangible interface,10.1109/visual.2004.47,http://dx.doi.org/10.1109/VISUAL.2004.47,227.0,234.0,C,"This work presents an experimental immersive interface for designing DNA components for application in nanotechnology. While much research has been done on immersive visualization, this is one of the first systems to apply advanced interface techniques to a scientific design problem. This system uses tangible 3D input devices (tongs, a raygun, and a multipurpose handle tool) to create and edit a purely digital representation of DNA. The tangible controllers are associated with functions (not data) while a virtual display is used to render the model. This interface was built in collaboration with a research group investigating the design of DNA tiles. A user study shows that scientists find the immersive interface more satisfying than a 2D interface due to the enhanced understanding gained by directly interacting with molecules in 3D space.",Steven Schkolne;Hiroshi Ishii 0001;Peter Schröder,S. Schkolne;H. Ishii;P. Schroder,"Caltech, USA;MIT Media Laboratory, USA;Caltech, USA",,"tangible user interface, molecular visualization, props, molecular modeling, spatial construction, virtual reality, augmented reality, responsive workbench, DNA design",46.0,27.0,34.0,237.0,,,representation dna tangible;virtual display used;tool create edit;controllers associated functions;study,0.7345;0.2054;0.1458;0.1114;-0.0080,"[np.int64(-1), -1, -1, -1, -1]",45;-1;-1;-1;-1,45,45,DNA Representation
Vis,1998,Scientific visualization and data modeling of scattered sediment contaminant data in New York/New Jersey estuaries,10.1109/visual.1998.745345,http://dx.doi.org/10.1109/VISUAL.1998.745345,467.0,470.0,C,"Sediments in many parts of the New York and New Jersey estuary system are contaminated with toxic organic and inorganic compounds by different sources. Because of the potential environmental consequences, detailed information on the spatial distribution of sediment contaminants is essential in order to carry out routine shipping channel dredging in an environmentally responsible way, and to remediate hot spots cost-effectively and safely. Scientific visualization and scatter data modeling techniques have been successfully applied in analyzing the sparse sampling data of sediment contaminants in New York and New Jersey estuaries, the underlying spatial characteristics of which are otherwise difficult to comprehend. Continuous realizations of contaminant concentrations in the region were obtained by using a spectral domain-decomposition scattered data model and IBM Data Explorer which is a software package for scientific data visualization.",Hong Ma;Keith W. Jones;Eric A. Stern,H. Ma;K.W. Jones;E.A. Stern,"Brockhaven National Laboratory, Upton, NY, USA;Brockhaven National Laboratory, Upton, NY, USA;U.S. Enviromental Protection Agency, New York, NY, USA",,,8.0,1.0,9.0,83.0,,,data sediment contaminants;visualization;carry routine shipping;spectral domain;hot spots cost,0.6239;0.2579;0.1423;0.1239;0.0298,"[np.int64(-1), -1, -1, -1, -1]",11;-1;-1;-1;-1,11,11,Water Contaminant Analysis
VAST,2020,HypoML: Visual Analysis for Hypothesis-based Evaluation of Machine Learning Models,10.1109/tvcg.2020.3030449,http://dx.doi.org/10.1109/TVCG.2020.3030449,1417.0,1426.0,J,"In this paper, we present a visual analytics tool for enabling hypothesis-based evaluation of machine learning (ML) models. We describe a novel ML-testing framework that combines the traditional statistical hypothesis testing (commonly used in empirical research) with logical reasoning about the conclusions of multiple hypotheses. The framework defines a controlled configuration for testing a number of hypotheses as to whether and how some extra information about a “concept” or “feature” may benefit or hinder an ML model. Because reasoning multiple hypotheses is not always straightforward, we provide HypoML as a visual analysis tool, with which, the multi-thread testing results are first transformed to analytical results using statistical and logical inferences, and then to a visual representation for rapid observation of the conclusions and the logical flow between the testing results and hypotheses. We have applied HypoML to a number of hypothesized concepts, demonstrating the intuitive and explainable nature of the visual analysis.",Qianwen Wang;William Alexander;Jack Pegg;Huamin Qu;Min Chen 0001,Qianwen Wang;William Alexander;Jack Pegg;Huamin Qu;Min Chen,"Hong Kong University of Science and Technology, China;University of Oxford, UK;University of Oxford, UK;Hong Kong University of Science and Technology, China;University of Oxford, UK",10.1109/tvcg.2012.197;10.1109/tvcg.2019.2934659;10.1109/tvcg.2017.2744718;10.1109/tvcg.2017.2744938;10.1109/tvcg.2016.2598831;10.1109/tvcg.2017.2744358;10.1109/tvcg.2016.2598838;10.1109/tvcg.2016.2598828;10.1109/tvcg.2018.2864838;10.1109/tvcg.2017.2744158;10.1109/tvcg.2016.2598829;10.1109/tvcg.2019.2934619;10.1109/tvcg.2018.2864499;10.1109/tvcg.2018.2864500;10.1109/tvcg.2012.197,"Visual analytics,model-developmental visualization,machine learning,neural network,hypothesis test,HypoML",4.0,6.0,44.0,676.0,,,visual analytics;testing results hypotheses;hinder ml model;thread;framework defines controlled,0.5392;0.3999;0.2489;0.1407;0.0218,"[np.int64(-1), -1, -1, -1, -1]",108;-1;-1;-1;-1,108,108,Visual Analytics
Vis,2009,Continuous Parallel Coordinates,10.1109/tvcg.2009.131,http://dx.doi.org/10.1109/TVCG.2009.131,1531.0,1538.0,J,"Typical scientific data is represented on a grid with appropriate interpolation or approximation schemes,defined on a continuous domain. The visualization of such data in parallel coordinates may reveal patterns latently contained in the data and thus can improve the understanding of multidimensional relations. In this paper, we adopt the concept of continuous scatterplots for the visualization of spatially continuous input data to derive a density model for parallel coordinates. Based on the point-line duality between scatterplots and parallel coordinates, we propose a mathematical model that maps density from a continuous scatterplot to parallel coordinates and present different algorithms for both numerical and analytical computation of the resulting density field. In addition, we show how the 2-D model can be used to successively construct continuous parallel coordinates with an arbitrary number of dimensions. Since continuous parallel coordinates interpolate data values within grid cells, a scalable and dense visualization is achieved, which will be demonstrated for typical multi-variate scientific data.",Julian Heinrich;Daniel Weiskopf,Julian Heinrich;Daniel Weiskopf,"VISUS (Visualization Research Center), Universität Stuttgart, Stuttgart, Germany;VISUS (Visualization Research Center), Universität Stuttgart, Stuttgart, Germany",10.1109/tvcg.2006.168;10.1109/tvcg.2008.119;10.1109/tvcg.2008.131;10.1109/infvis.2005.1532139;10.1109/tvcg.2009.179;10.1109/tvcg.2006.138;10.1109/visual.1990.146402;10.1109/infvis.2005.1532138;10.1109/tvcg.2008.160;10.1109/infvis.2002.1173157;10.1109/visual.1999.809866;10.1109/tvcg.2006.170;10.1109/infvis.2004.68;10.1109/tvcg.2006.168,"Parallel coordinates, integrating spatial and non-spatial data visualization, multi-variate visualization, interpolation",128.0,86.0,28.0,1399.0,,,scatterplots visualization spatially;derive density model;values grid cells;different algorithms numerical;concept continuous,0.6153;0.3743;0.2460;0.2404;0.1304,"[np.int64(-1), -1, -1, -1, -1]",68;-1;-1;-1;-1,68,68,Scatterplot Visualization
InfoVis,2011,Exploring Uncertainty in Geodemographics with Interactive Graphics,10.1109/tvcg.2011.197,http://dx.doi.org/10.1109/TVCG.2011.197,2545.0,2554.0,J,"Geodemographic classifiers characterise populations by categorising geographical areas according to the demographic and lifestyle characteristics of those who live within them. The dimension-reducing quality of such classifiers provides a simple and effective means of characterising population through a manageable set of categories, but inevitably hides heterogeneity, which varies within and between the demographic categories and geographical areas, sometimes systematically. This may have implications for their use, which is widespread in government and commerce for planning, marketing and related activities. We use novel interactive graphics to delve into OAC - a free and open geodemographic classifier that classifies the UK population in over 200,000 small geographical areas into 7 super-groups, 21 groups and 52 sub-groups. Our graphics provide access to the original 41 demographic variables used in the classification and the uncertainty associated with the classification of each geographical area on-demand. It also supports comparison geographically and by category. This serves the dual purpose of helping understand the classifier itself leading to its more informed use and providing a more comprehensive view of population in a comprehensible manner. We assess the impact of these interactive graphics on experienced OAC users who explored the details of the classification, its uncertainty and the nature of between - and within - class variation and then reflect on their experiences. Visualization of the complexities and subtleties of the classification proved to be a thought-provoking exercise both confirming and challenging users' understanding of population, the OAC classifier and the way it is used in their organisations. Users identified three contexts for which the techniques were deemed useful in the context of local government, confirming the validity of the proposed methods.",Aidan Slingsby;Jason Dykes;Jo Wood,Aidan Slingsby;Jason Dykes;Jo Wood,"City University London, UK;City University London, UK;City University London, UK",10.1109/infvis.1996.559216;10.1109/tvcg.2010.191;10.1109/tvcg.2007.70574;10.1109/tvcg.2010.186;10.1109/visual.1999.809866;10.1109/tvcg.2008.165;10.1109/tvcg.2006.202;10.1109/tvcg.2007.70515;10.1109/infvis.2004.12;10.1109/infvis.1996.559216,"Geodemographics, OAC, classification, cartography, uncertainty",82.0,38.0,58.0,1393.0,,,demographic categories geographical;reflect experiences visualization;understand classifier leading;52;access original,0.6723;0.3040;0.1435;0.1270;-0.0578,"[np.int64(-1), -1, -1, -1, -1]",6;-1;-1;-1;-1,6,6,Geospatial Data Analysis
Vis,1998,Data level comparison of wind tunnel and computational fluid dynamics data,10.1109/visual.1998.745332,http://dx.doi.org/10.1109/VISUAL.1998.745332,415.0,418.0,C,"The paper describes the architecture of a data level comparative visualization system and experiences using it to study computational fluid dynamics data and experimental wind tunnel data. We illustrate how the system can be used to compare data sets from different sources, data sets with different resolutions and data sets computed using different mathematical models of fluid flow. Suggested improvements to the system based on user feedback are also discussed.",Qin Shen;Alex Pang;Samuel P. Uselton,Q. Shen;A. Pang;S. Uselton,"Computer Science Department, University of California, Santa Cruz, USA;Computer Science Department, University of California, Santa Cruz, USA;MRJ Technology Solutions, Inc., USA",10.1109/visual.1997.663910;10.1109/visual.1996.568115;10.1109/visual.1996.568116;10.1109/visual.1997.663911;10.1109/visual.1997.663910,,54.0,11.0,10.0,145.0,,,level comparative visualization;computational fluid dynamics;tunnel data;experiences using;different sources,0.6719;0.4642;0.1647;0.1520;0.0902,"[np.int64(-1), -1, -1, -1, -1]",101;-1;-1;-1;-1,101,101,Comparative Visualization
Vis,2021,Simultaneous Matrix Orderings for Graph Collections,10.1109/tvcg.2021.3114773,http://dx.doi.org/10.1109/TVCG.2021.3114773,1.0,10.0,J,"Undirected graphs are frequently used to model phenomena that deal with interacting objects, such as social networks, brain activity and communication networks. The topology of an undirected graph <inline-formula><tex-math notation=""LaTeX"">$G$</tex-math><alternatives><graphic orientation=""portrait"" position=""float"" xlink:href=""28tvcg01-beusekom-3114773-eqinline-1-small.tif"" xmlns:xlink=""http://www.w3.org/1999/xlink""/></alternatives></inline-formula> can be captured by an adjacency matrix; this matrix in turn can be visualized directly to give insight into the graph structure. Which visual patterns appear in such a matrix visualization crucially depends on the <i>ordering</i> of its rows and columns. Formally defining the quality of an ordering and then automatically computing a high-quality ordering are both challenging problems; however, effective heuristics exist and are used in practice. <p>Often, graphs do not exist in isolation but as part of a collection of graphs on the same set of vertices, for example, brain scans over time or of different people. To visualize such graph collections, we need a <i>single</i> ordering that works well for all matrices <i>simultaneously</i>. The current state-of-the-art solves this problem by taking a (weighted) union over all graphs and applying existing heuristics. However, this union leads to a loss of information, specifically in those parts of the graphs which are different. We propose a <i>collection-aware</i> approach to avoid this loss of information and apply it to two popular heuristic methods: leaf order and barycenter.</p> <p>The de-facto standard computational quality metrics for matrix ordering capture only block-diagonal patterns (cliques). Instead, we propose to use <i>Moran's</i> <inline-formula><tex-math notation=""LaTeX"">$I$</tex-math><alternatives><graphic orientation=""portrait"" position=""float"" xlink:href=""28tvcg01-beusekom-3114773-eqinline-2-small.tif"" xmlns:xlink=""http://www.w3.org/1999/xlink""/></alternatives></inline-formula>, a spatial auto-correlation metric, which captures the full range of established patterns. Moran's <inline-formula><tex-math notation=""LaTeX"">$I$</tex-math><alternatives><graphic orientation=""portrait"" position=""float"" xlink:href=""28tvcg01-beusekom-3114773-eqinline-3-small.tif"" xmlns:xlink=""http://www.w3.org/1999/xlink""/></alternatives></inline-formula> refines previously proposed stress measures. Furthermore, the popular leaf order method heuristically optimizes a similar measure which further supports the use of Moran's <inline-formula><tex-math notation=""LaTeX"">$I$</tex-math><alternatives><graphic orientation=""portrait"" position=""float"" xlink:href=""28tvcg01-beusekom-3114773-eqinline-4-small.tif"" xmlns:xlink=""http://www.w3.org/1999/xlink""/></alternatives></inline-formula> in this context. An ordering that maximizes Moran's <inline-formula><tex-math notation=""LaTeX"">$I$</tex-math><alternatives><graphic orientation=""portrait"" position=""float"" xlink:href=""28tvcg01-beusekom-3114773-eqinline-5-small.tif"" xmlns:xlink=""http://www.w3.org/1999/xlink""/></alternatives></inline-formula> can be computed via solutions to the Traveling Salesperson Problem (TSP); orderings that approximate the optimal ordering can be computed more efficiently, using any of the approximation algorithms for metric TSP.</p> <p>We evaluated our methods for simultaneous orderings on real-world datasets using Moran's <inline-formula><tex-math notation=""LaTeX"">$I$</tex-math><alternatives><graphic orientation=""portrait"" position=""float"" xlink:href=""28tvcg01-beusekom-3114773-eqinline-6-small.tif"" xmlns:xlink=""http://www.w3.org/1999/xlink""/></alternatives></inline-formula> as the quality metric. Our results show that our collection-aware approach matches or improves performance compared to the union approach, depending on the similarity of the graphs in the collection. Specifically, our Moran's <inline-formula><tex-math notation=""LaTeX"">$I$</tex-math><alternatives><graphic orientation=""portrait"" position=""float"" xlink:href=""28tvcg01-beusekom-3114773-eqinline-7-small.tif"" xmlns:xlink=""http://www.w3.org/1999/xlink""/></alternatives></inline-formula>-based collection-aware leaf order implementation consistently outperforms other implementations. Our collection-aware implementations carry no significant additional computational costs.</p>",Nathan van Beusekom;Wouter Meulemans;Bettina Speckmann,Nathan van Beusekom;Wouter Meulemans;Bettina Speckmann,"TU Eindhoven, the Netherlands;TU Eindhoven, the Netherlands;TU Eindhoven, the Netherlands",10.1109/tvcg.2016.2598862;10.1109/tvcg.2016.2598467;10.1109/infvis.2004.1;10.1109/tvcg.2020.3030373;10.1109/tvcg.2016.2598862,"Matrix ordering,graph visualization,algorithms,quality measures",7.0,8.0,34.0,1022.0,BP,,graph structure;example brain;auto correlation;capture block diagonal;implementations carry significant,0.6245;0.2782;0.2313;0.1192;0.0699,"[np.int64(-1), -1, -1, -1, -1]",44;-1;-1;-1;-1,44,44,Graph Theory Analysis
InfoVis,2012,Graphical Tests for Power Comparison of Competing Designs,10.1109/tvcg.2012.230,http://dx.doi.org/10.1109/TVCG.2012.230,2441.0,2448.0,J,"Lineups [4, 28] have been established as tools for visual testing similar to standard statistical inference tests, allowing us to evaluate the validity of graphical findings in an objective manner. In simulation studies [12] lineups have been shown as being efficient: the power of visual tests is comparable to classical tests while being much less stringent in terms of distributional assumptions made. This makes lineups versatile, yet powerful, tools in situations where conditions for regular statistical tests are not or cannot be met. In this paper we introduce lineups as a tool for evaluating the power of competing graphical designs. We highlight some of the theoretical properties and then show results from two studies evaluating competing designs: both studies are designed to go to the limits of our perceptual abilities to highlight differences between designs. We use both accuracy and speed of evaluation as measures of a successful design. The first study compares the choice of coordinate system: polar versus cartesian coordinates. The results show strong support in favor of cartesian coordinates in finding fast and accurate answers to spotting patterns. The second study is aimed at finding shift differences between distributions. Both studies are motivated by data problems that we have recently encountered, and explore using simulated data to evaluate the plot designs under controlled conditions. Amazon Mechanical Turk (MTurk) is used to conduct the studies. The lineups provide an effective mechanism for objectively evaluating plot designs.",Heike Hofmann;Lendie Follett;Mahbubul Majumder;Dianne Cook,Heike Hofmann;Lendie Follett;Mahbubul Majumder;Dianne Cook,"Iowa State University, USA;Iowa State University, USA;Iowa State University, USA;Iowa State University, USA",10.1109/tvcg.2009.111;10.1109/tvcg.2010.161;10.1109/tvcg.2009.111,"Lineups, Visual inference, Power comparison, Efficiency of displays",56.0,31.0,27.0,914.0,,,competing graphical designs;statistical tests;lineups 28 established;coordinate polar;use accuracy speed,0.6987;0.3533;0.1688;0.1026;0.0864,"[np.int64(-1), -1, -1, -1, -1]",146;-1;-1;-1;-1,146,146,Visualization Techniques
Vis,1996,Complex-valued contour meshing,10.1109/visual.1996.568103,http://dx.doi.org/10.1109/VISUAL.1996.568103,173.0,180.0,C,"An isovalue contour of a function of two complex variables defines a surface in four-space. We present a robust technique for creating polygonal contours of complex-valued functions. The technique, contour meshing, generalizes well to larger dimensions.",Chris Weigle;David C. Banks,C. Weigle;D.C. Banks,"Department of Computer Science, Mississippi State University, USA;Department of Computer Science, Mississippi State University, USA",10.1109/visual.1993.398869;10.1109/visual.1991.175782;10.1109/visual.1993.398869,,62.0,18.0,15.0,68.0,,,polygonal contours complex;defines surface;valued functions;space present robust;technique creating,0.7111;0.3396;0.2191;0.1535;0.1322,"[np.int64(-1), -1, -1, -1, -1]",126;-1;-1;-1;-1,126,126,Geometric Mesh Processing
Vis,1997,Optimized geometry compression for real-time rendering,10.1109/visual.1997.663902,http://dx.doi.org/10.1109/VISUAL.1997.663902,347.0,354.0,C,"Most existing visualization applications use 3D geometry as their basic rendering primitive. As users demand more complex data sets, the memory requirements for retrieving and storing large 3D models are becoming excessive. In addition, the current 3D rendering hardware is facing a large memory bus bandwidth bottleneck at the processor to graphics pipeline interface. Rendering 1 million triangles with 24 bytes per triangle at 30 Hz requires as much as 720 MB/sec memory bus bandwidth. This transfer rate is well beyond the current low-cost graphics systems. A solution is to compress the static 3D geometry as an off-line pre-process. Then, only the compressed geometry needs to be stored in main memory and sent down to the graphics pipeline for real-time decompression and rendering. The author presents several new techniques for compression of 3D geometry that produce 2 to 3 times better compression ratios than existing methods. They first introduce several algorithms for the efficient encoding of the original geometry as generalized triangle meshes. This encoding allows most of the mesh vertices to be reused when forming new triangles. Their second contribution allows various parts of a geometric model to be compressed with different precision depending on the level of details present. Together, the meshifying algorithms and the variable compression method achieve compression ratios of 30 and 37 to one over ASCII encoded formats and 10 and 15 to one over binary encoded triangle strips. The experimental results show a dramatically lowered memory bandwidth required for real-time visualization of complex data sets.",Mike M. Chow,M.M. Chow,"Massachusetts Institute of Technology, USA",10.1109/visual.1996.568125;10.1109/visual.1996.568125,,320.0,57.0,11.0,320.0,,,compression 3d geometry;time visualization complex;large memory bus;primitive users;strips experimental results,0.6870;0.2673;0.2459;0.0767;0.0101,"[np.int64(-1), -1, -1, -1, -1]",70;-1;-1;-1;-1,70,70,3D Geometry Compression
Vis,2004,Constrained inverse volume rendering for planetary nebulae,10.1109/visual.2004.18,http://dx.doi.org/10.1109/VISUAL.2004.18,83.0,90.0,C,"Determining the three-dimensional structure of distant astronomical objects is a challenging task, given that terrestrial observations provide only one viewpoint. For this task, bipolar planetary nebulae are interesting objects of study because of their pronounced axial symmetry due to fundamental physical processes. Making use of this symmetry constraint, we present a technique to automatically recover the axisymmetric structure of bipolar planetary nebulae from two-dimensional images. With GPU-based volume rendering driving a nonlinear optimization, we estimate the nebula's local emission density as a function of its radial and axial coordinates, and we recover the orientation of the nebula relative to Earth. The optimization refines the nebula model and its orientation by minimizing the differences between the rendered image and the original astronomical image. The resulting model enables realistic 3D visualizations of planetary nebulae, e.g. for educational purposes in planetarium shows. In addition, the recovered spatial distribution of the emissive gas allows validating computer simulation results of the astrophysical formation processes of planetary nebulae.",Marcus A. Magnor;Gordon L. Kindlmann;Neb Duric;Charles D. Hansen,M. Magnor;G. Kindlmann;N. Duric;C. Hansen,"MPI Informatik, Germany;SCI Institute, University of Utah, USA;SCI Institute, University of Utah, USA;Department Physics and Astronomy, University of New Mexico, USA",,"volumetric modeling, inverse rendering, volume rendering, volume reconstruction, planetary nebulae",50.0,19.0,36.0,204.0,,,visualizations planetary nebulae;gpu based volume;model orientation minimizing;rendered image original;bipolar,0.7445;0.3452;0.2591;0.1749;0.0745,"[np.int64(-1), -1, -1, -1, -1]",125;-1;-1;-1;-1,125,125,Celestial Visualization
Vis,1992,Logical time in visualizations produced by parallel programs,10.1109/visual.1992.235209,http://dx.doi.org/10.1109/VISUAL.1992.235209,186.0,193.0,C,"Techniques that manipulate logical time in order to produce coherent animations of parallel program behavior despite the presence of asynchrony are presented. The techniques interpret program behavior in light of user-defined abstractions and generate animations based on a logical, rather than a physical, view of time. If this interpretation succeeds, the resulting animation is easily understood. If it fails, the programmer can be assured that the failure was not an artifact of the visualization. It is shown that these techniques can be generally applied to enhance visualizations of a variety of types of data as they are produced by parallel, MIMD (multiple instruction stream, multiple data stream) computations.&lt;&lt;ETX&gt;&gt;",Janice E. Cuny;Alfred Hough;Joydip Kunda,J.E. Cuny;A.A. Hough;J. Kundu,"Dept. of Comput. Sci., Massachusetts Univ., Amherst, MA, USA;Department of Computer Science, University of Massachusetts, Amherst, MA, USA;Department of Computer Science, University of Massachusetts, Amherst, MA, USA",,,18.0,4.0,18.0,49.0,,,animations parallel program;manipulate logical time;failure artifact visualization;despite presence asynchrony;types data,0.5873;0.3939;0.3121;0.1590;0.1207,"[np.int64(-1), -1, -1, -1, -1]",-1;-1;-1;-1;-1,,-1,Interactive 3D Visualization
Vis,2004,TetSplat: real-time rendering and volume clipping of large unstructured tetrahedral meshes,10.1109/visual.2004.102,http://dx.doi.org/10.1109/VISUAL.2004.102,433.0,440.0,C,"We present a novel approach to interactive visualization and exploration of large unstructured tetrahedral meshes. These massive 3D meshes are used in mission-critical CFD and structural mechanics simulations, and typically sample multiple field values on several millions of unstructured grid points. Our method relies on the preprocessing of the tetrahedral mesh to partition it into nonconvex boundaries and internal fragments that are subsequently encoded into compressed multiresolution data representations. These compact hierarchical data structures are then adaptively rendered and probed in real-time on a commodity PC. Our point-based rendering algorithm, which is inspired by QSplat, employs a simple but highly efficient splatting technique that guarantees interactive frame-rates regardless of the size of the input mesh and the available rendering hardware. It furthermore allows for real-time probing of the volumetric data-set through constructive solid geometry operations as well as interactive editing of color transfer functions for an arbitrary number of field values. Thus, the presented visualization technique allows end-users for the first time to interactively render and explore very large unstructured tetrahedral meshes on relatively inexpensive hardware.",Ken Museth;Santiago V. Lombeyda,K. Museth;S. Lombeyda,"Linköping Institute of Technology, Sweden;California Institute of Technology, USA",10.1109/visual.2000.885703;10.1109/visual.1998.745329;10.1109/visual.2000.885680;10.1109/visual.1997.663869;10.1109/visual.2000.885703,"Large volumetric data, tetrahedral meshes, real-time visualization, point-based rendering, constructive solid geometry",18.0,4.0,22.0,116.0,,,unstructured tetrahedral meshes;render explore large;mission critical cfd;qsplat;frame rates regardless,0.6729;0.2654;0.1721;0.1530;0.0744,"[np.int64(-1), -1, -1, -1, -1]",77;-1;-1;-1;-1,77,77,Mesh Geometry Techniques
VAST,2015,Visually and statistically guided imputation of missing values in univariate seasonal time series,10.1109/vast.2015.7347672,http://dx.doi.org/10.1109/VAST.2015.7347672,189.0,190.0,M,"Missing values are a problem in many real world applications, for example failing sensor measurements. For further analysis these missing values need to be imputed. Thus, imputation of such missing values is important in a wide range of applications. We propose a visually and statistically guided imputation approach, that allows applying different imputation techniques to estimate the missing values as well as evaluating and fine tuning the imputation by visual guidance. In our approach we include additional visual information about uncertainty and employ the cyclic structure of time inherent in the data. Including this cyclic structure enables visually judging the adequateness of the estimated values with respect to the uncertainty/error boundaries and according to the patterns of the neighbouring time points in linear and cyclic (e.g., the months of the year) time.",Markus Bögl;Peter Filzmoser;Theresia Gschwandtner;Silvia Miksch;Wolfgang Aigner;Alexander Rind;Tim Lammarsch,M. Bögl;P. Filzmoser;T. Gschwandtner;S. Miksch;W. Aigner;A. Rind;T. Lammarsch,Vienna University of Technology;Vienna University of Technology;Vienna University of Technology;Vienna University of Technology;Vienna University of Technology;St.Pölten University of Applied Sciences;MODUL University Vienna,,,14.0,13.0,11.0,340.0,,,imputation visual guidance;sensor measurements analysis;months year time;cyclic structure;values important,0.6844;0.3035;0.1676;0.0931;0.0343,"[np.int64(-1), -1, -1, -1, -1]",145;-1;-1;-1;-1,145,145,Data Visualization Techniques
Vis,2002,Face-based luminance matching for perceptual colormap generation,10.1109/visual.2002.1183788,http://dx.doi.org/10.1109/VISUAL.2002.1183788,299.0,306.0,C,"Most systems used for creating and displaying colormap-based visualizations are not photometrically calibrated. That is, the relationship between RGB input levels and perceived luminance is usually not known, due to variations in the monitor, hardware configuration, and the viewing environment. However, the luminance component of perceptually based colormaps should be controlled, due to the central role that luminance plays in our visual processing. We address this problem with a simple and effective method for performing luminance matching on an uncalibrated monitor. The method is akin to the minimally distinct border technique (a previous method of luminance matching used for measuring luminous efficiency), but our method relies on the brain's highly developed ability to distinguish human faces. We present a user study showing that our method produces equivalent results to the minimally distinct border technique, but with significantly improved precision. We demonstrate how results from our luminance matching method can be directly applied to create new univariate colormaps.",Gordon L. Kindlmann;Erik Reinhard;Sarah Creem,G. Kindlmann;E. Reinhard;S. Creem,"Sch. of Comput., Utah Univ., Salt Lake City, UT, USA;School of Electrical Engineering and Computer Science, University of Central Florida, USA;Department of Psychology, University of Utah, USA",10.1109/visual.1995.480803;10.1109/visual.1992.235201;10.1109/visual.2001.964510;10.1109/visual.1995.480803,"Colormaps, Color Scales, Isoluminance, Brightness Matching, Perceptually-based Visualization",110.0,36.0,26.0,679.0,,,perceptually based colormaps;used measuring luminous;human faces present;hardware configuration viewing;directly applied create,0.7173;0.3424;0.2470;0.1650;-0.0224,"[np.int64(-1), -1, -1, -1, -1]",14;-1;-1;-1;-1,14,14,Image Dataset Comparison
InfoVis,2009,Interaction Techniques for Selecting and Manipulating Subgraphs in Network Visualizations,10.1109/tvcg.2009.151,http://dx.doi.org/10.1109/TVCG.2009.151,937.0,944.0,J,"We present a novel and extensible set of interaction techniques for manipulating visualizations of networks by selecting subgraphs and then applying various commands to modify their layout or graphical properties. Our techniques integrate traditional rectangle and lasso selection, and also support selecting a node's neighbourhood by dragging out its radius (in edges) using a novel kind of radial menu. Commands for translation, rotation, scaling, or modifying graphical properties (such as opacity) and layout patterns can be performed by using a hotbox (a transiently popped-up, semi-transparent set of widgets) that has been extended in novel ways to integrate specification of commands with 1D or 2D arguments. Our techniques require only one mouse button and one keyboard key, and are designed for fast, gestural, in-place interaction. We present the design and integration of these interaction techniques, and illustrate their use in interactive graph visualization. Our techniques are implemented in NAViGaTOR, a software package for visualizing and analyzing biological networks. An initial usability study is also reported.",Michael J. McGuffin;Igor Jurisica,Michael J. McGuffin;Igor Jurisica,"École de technologie supérieure, Montreal, Canada;PMH/UHN, Ontario Cancer Institute, Toronto, Canada",10.1109/infvis.2005.1532124;10.1109/infvis.1996.559216;10.1109/infvis.2005.1532124,"Interactive graph drawing, network layout, radial menus, marking menus, hotbox, biological networks",94.0,47.0,19.0,1060.0,HM,,interactive graph visualization;rectangle lasso selection;novel kind radial;menu commands translation;transiently,0.6490;0.3834;0.1368;0.1057;-0.0003,"[np.int64(-1), -1, -1, -1, -1]",96;-1;-1;-1;-1,96,96,Graph Visualization
Vis,2007,Interactive sound rendering in complex and dynamic scenes using frustum tracing,10.1109/tvcg.2007.70567,http://dx.doi.org/10.1109/TVCG.2007.70567,1672.0,1679.0,J,"We present a new approach for real-time sound rendering in complex, virtual scenes with dynamic sources and objects. Our approach combines the efficiency of interactive ray tracing with the accuracy of tracing a volumetric representation. We use a four-sided convex frustum and perform clipping and intersection tests using ray packet tracing. A simple and efficient formulation is used to compute secondary frusta and perform hierarchical traversal. We demonstrate the performance of our algorithm in an interactive system for complex environments and architectural models with tens or hundreds of thousands of triangles. Our algorithm can perform real-time simulation and rendering on a high-end PC.",Christian Lauterbach;Anish Chandak;Dinesh Manocha,Christian Lauterbach;Anish Chandak;Dinesh Manocha,"Department of Computer Science, University of North Carolina, Chapel Hill, Chapel Hill, NC, USA;Department of Computer Science, University of North Carolina, Chapel Hill, Chapel Hill, NC, USA;Department of Computer Science, University of North Carolina, Chapel Hill, Chapel Hill, NC, USA",10.1109/tvcg.2006.125;10.1109/visual.2005.1532790;10.1109/tvcg.2006.125,"Acoustic propagation,Interactive systems",87.0,38.0,48.0,460.0,,,sound rendering;clipping intersection tests;perform hierarchical traversal;packet tracing simple;thousands triangles,0.6883;0.2443;0.1646;0.1624;0.1534,"[np.int64(-1), -1, -1, -1, -1]",141;-1;-1;-1;-1,141,141,Advanced Rendering Techniques
InfoVis,2020,Guidelines For Pursuing and Revealing Data Abstractions,10.1109/tvcg.2020.3030355,http://dx.doi.org/10.1109/TVCG.2020.3030355,1503.0,1513.0,J,"Many data abstraction types, such as networks or set relationships, remain unfamiliar to data workers beyond the visualization research community. We conduct a survey and series of interviews about how people describe their data, either directly or indirectly. We refer to the latter as latent data abstractions. We conduct a Grounded Theory analysis that (1) interprets the extent to which latent data abstractions exist, (2) reveals the far-reaching effects that the interventionist pursuit of such abstractions can have on data workers, (3) describes why and when data workers may resist such explorations, and (4) suggests how to take advantage of opportunities and mitigate risks through transparency about visualization research perspectives and agendas. We then use the themes and codes discovered in the Grounded Theory analysis to develop guidelines for data abstraction in visualization projects. To continue the discussion, we make our dataset open along with a visual interface for further exploration.",Alex Bigelow;Katy Williams;Katherine E. Isaacs,Alex Bigelow;Katy Williams;Katherine E. Isaacs,University of Arizona;University of Arizona;University of Arizona,10.1109/vast47406.2019.8986909;10.1109/infvis.2000.885092;10.1109/tvcg.2013.145;10.1109/vast.2011.6102441;10.1109/tvcg.2018.2865241;10.1109/tvcg.2014.2346331;10.1109/tvcg.2019.2934539;10.1109/tvcg.2009.111;10.1109/tvcg.2009.116;10.1109/tvcg.2012.213;10.1109/tvcg.2017.2744843;10.1109/tvcg.2019.2934538;10.1109/tvcg.2019.2934285;10.1109/vast47406.2019.8986909,"Data abstraction,Grounded theory,Survey design,Data wrangling",3.0,4.0,50.0,474.0,,,visualization research perspectives;make dataset open;exist reveals far;series interviews people;conduct grounded,0.6703;0.3002;0.1768;0.1685;0.1081,"[np.int64(-1), -1, -1, -1, -1]",106;-1;-1;-1;-1,106,106,Visualization Development
VAST,2008,Grand challenge award 2008: Support for diverse analytic techniques - nSpace2 and GeoTime visual analytics,10.1109/vast.2008.4677385,http://dx.doi.org/10.1109/VAST.2008.4677385,,,M,"GeoTime and nSpace2 are interactive visual analytics tools that were used to examine and interpret all four of the 2008 VAST Challenge datasets. GeoTime excels in visualizing event patterns in time and space, or in time and any abstract landscape, while nSpace2 is a web-based analytical tool designed to support every step of the analytical process. nSpace2 is an integrating analytic environment. This paper highlights the VAST analytical experience with these tools that contributed to the success of these tools and this team for the third consecutive year.",Lynn Chien;Annie Tat;Pascale Proulx;Adeel Khamisa;William Wright,Lynn Chien;Annie Tat;Pascale Proulx;Adeel Khamisa;William Wright,"Oculus Info, Inc.;Oculus Info, Inc.;Oculus Info, Inc.;Oculus Info, Inc.;Oculus Info, Inc.",0.1109/vast.2008.4677355;10.1109/infvis.2004.27,,5.0,3.0,4.0,143.0,,,visualizing event patterns;interpret 2008 vast;geotime;landscape nspace2 web;integrating analytic,0.5481;0.4672;0.4009;0.1646;0.0907,"[np.int64(-1), -1, -1, -1, -1]",65;-1;-1;-1;-1,65,65,Event Visualization
InfoVis,2019,A Comparison of Visualizations for Identifying Correlation over Space and Time,10.1109/tvcg.2019.2934807,http://dx.doi.org/10.1109/TVCG.2019.2934807,375.0,385.0,J,"Observing the relationship between two or more variables over space and time is essential in many domains. For instance, looking, for different countries, at the evolution of both the life expectancy at birth and the fertility rate will give an overview of their demographics. The choice of visual representation for such multivariate data is key to enabling analysts to extract patterns and trends. Prior work has compared geo-temporal visualization techniques for a single thematic variable that evolves over space and time, or for two variables at a specific point in time. But how effective visualization techniques are at communicating correlation between two variables that evolve over space and time remains to be investigated. We report on a study comparing three techniques that are representative of different strategies to visualize geo-temporal multivariate data: either juxtaposing all locations for a given time step, or juxtaposing all time steps for a given location; and encoding thematic attributes either using symbols overlaid on top of map features, or using visual channels of the map features themselves. Participants performed a series of tasks that required them to identify if two variables were correlated over time and if there was a pattern in their evolution. Tasks varied in granularity for both dimensions: time (all time steps, a subrange of steps, one step only) and space (all locations, locations in a subregion, one location only). Our results show that a visualization's effectiveness depends strongly on the task to be carried out. Based on these findings we present a set of design guidelines about geo-temporal visualization techniques for communicating correlation.",Vanessa Peña Araya;Emmanuel Pietriga;Anastasia Bezerianos,Vanessa Peña-Araya;Emmanuel Pietriga;Anastasia Bezerianos,"Univ. Paris-Sud, CNRS, INRIA, Université Paris-Saclay;Univ. Paris-Sud, CNRS, INRIA, Université Paris-Saclay;Univ. Paris-Sud, CNRS, INRIA, Université Paris-Saclay",10.1109/tvcg.2016.2598862;10.1109/tvcg.2011.185;10.1109/tvcg.2015.2467199;10.1109/tvcg.2007.70623;10.1109/tvcg.2014.2346979;10.1109/tvcg.2018.2865141;10.1109/tvcg.2015.2467671;10.1109/tvcg.2011.194;10.1109/tvcg.2008.125;10.1109/tvcg.2013.130;10.1109/tvcg.2015.2467091;10.1109/tvcg.2016.2598862,"geo-temporal data,bivariate maps,correlation,controlled study,bar chart,Dorling cartogram,small multiples",23.0,17.0,71.0,1302.0,,,visualize geo temporal;variables correlated;evolve;design guidelines;data key enabling,0.7163;0.3025;0.1180;0.1017;-0.0041,"[np.int64(-1), -1, -1, -1, -1]",65;-1;-1;-1;-1,65,65,Event Visualization
Vis,2023,A Comparative Visual Analytics Framework for Evaluating Evolutionary Processes in Multi-Objective Optimization,10.1109/tvcg.2023.3326921,http://dx.doi.org/10.1109/TVCG.2023.3326921,661.0,671.0,J,"Evolutionary multi-objective optimization (EMO) algorithms have been demonstrated to be effective in solving multi-criteria decision-making problems. In real-world applications, analysts often employ several algorithms concurrently and compare their solution sets to gain insight into the characteristics of different algorithms and explore a broader range of feasible solutions. However, EMO algorithms are typically treated as black boxes, leading to difficulties in performing detailed analysis and comparisons between the internal evolutionary processes. Inspired by the successful application of visual analytics tools in explainable AI, we argue that interactive visualization can significantly enhance the comparative analysis between multiple EMO algorithms. In this paper, we present a visual analytics framework that enables the exploration and comparison of evolutionary processes in EMO algorithms. Guided by a literature review and expert interviews, the proposed framework addresses various analytical tasks and establishes a multi-faceted visualization design to support the comparative analysis of intermediate generations in the evolution as well as solution sets. We demonstrate the effectiveness of our framework through case studies on benchmarking and real-world multi-objective optimization problems to elucidate how analysts can leverage our framework to inspect and compare diverse algorithms.",Yansong Huang;Zherui Zhang;Ao Jiao;Yuxin Ma;Ran Cheng,Yansong Huang;Zherui Zhang;Ao Jiao;Yuxin Ma;Ran Cheng,"Department of Computer Science and Engineering, Southern University of Science and Technology, China;Department of Computer Science and Engineering, Southern University of Science and Technology, China;Department of Computer Science and Engineering, Southern University of Science and Technology, China;Department of Computer Science and Engineering, Southern University of Science and Technology, China;Department of Computer Science and Engineering, Southern University of Science and Technology, China",0.1109/tvcg.2015.2467851;10.1109/tvcg.2017.2744199;10.1109/tvcg.2018.2864500;10.1109/tvcg.2017.2744938;10.1109/tvcg.2017.2744378;10.1109/tvcg.2020.3028888;10.1109/tvcg.2014.2346578;10.1109/tvcg.2020.3030361;10.1109/tvcg.2020.3030347;10.1109/visual.2005.1532820;10.1109/vast50239.2020.00006;10.1109/tvcg.2021.3114790;10.1109/tvcg.2020.3030418;10.1109/tvcg.2020.3030458;10.1109/tvcg.2021.3114850;10.1109/vast50239.2020.00007;10.1109/tvcg.2020.3030432;10.1109/tvcg.2018.2864499,"Visual analytics,evolutionary multi-objective optimization",,2.0,79.0,900.0,,,evolutionary multi objective;analytics tools explainable;benchmarking real;paper;framework addresses,0.5723;0.4337;0.1664;0.0518;0.0134,"[np.int64(-1), -1, -1, -1, -1]",3;-1;-1;-1;-1,3,3,Multi-Objective Optimization
Vis,1997,Visualization of plant growth,10.1109/visual.1997.663925,http://dx.doi.org/10.1109/VISUAL.1997.663925,475.0,478.0,C,"The measurement, analysis and visualization of plant growth is of primary interest to plant biologists. We are developing software tools to support such investigations. There are two parts in this investigation, namely growth visualization of (i) a plant root and (ii) a plant stem. For both domains, the input data is a stream of images taken by cameras. The tools being developed make it possible to measure various time-varying quantities, such as differential growth. For both domains, the plant is modeled by using flexible templates to represent non-rigid motions.",Jeremy J. Loomis;Xiuwen Liu;Zhaohua Ding;Kikuo Fujimura;Michael L. Evans;Hideo Ishikawa,J.J. Loomis;Xiuwen Liu;Zhaohua Ding;K. Fujimura;M.L. Evans;H. Ishikawa,"Dept. of Computer and Information Science, The Ohio State University, Columbus, OH;Dept. of Computer and Information Science, The Ohio State University, Columbus, OH;Biomedical Engineering Center, The Ohio State University, Columbus, OH;Dept. of Computer and Information Science, The Ohio State University, Columbus, OH;Dept. of Plant Biology, The Ohio State University, Columbus, OH;Dept. of Plant Biology, The Ohio State University, Columbus, OH",,"Shape representation, image sequence analysis, non-rigid motion, plant biology",12.0,1.0,14.0,81.0,,,visualization plant growth;non rigid motions;taken cameras tools;using flexible templates;stream,0.7748;0.2947;0.2661;0.1491;0.0153,"[np.int64(-1), -1, -1, -1, -1]",129;-1;-1;-1;-1,129,129,Plant Growth Visualization
InfoVis,2016,Many-to-Many Geographically-Embedded Flow Visualisation: An Evaluation,10.1109/tvcg.2016.2598885,http://dx.doi.org/10.1109/TVCG.2016.2598885,411.0,420.0,J,"Showing flows of people and resources between multiple geographic locations is a challenging visualisation problem. We conducted two quantitative user studies to evaluate different visual representations for such dense many-to-many flows. In our first study we compared a bundled node-link flow map representation and OD Maps [37] with a new visualisation we call MapTrix. Like OD Maps, MapTrix overcomes the clutter associated with a traditional flow map while providing geographic embedding that is missing in standard OD matrix representations. We found that OD Maps and MapTrix had similar performance while bundled node-link flow map representations did not scale at all well. Our second study compared participant performance with OD Maps and MapTrix on larger data sets. Again performance was remarkably similar.",Yalong Yang 0001;Tim Dwyer;Sarah Goodwin;Kim Marriott,Yalong Yang;Tim Dwyer;Sarah Goodwin;Kim Marriott,"Monash University, CSIRO, Victoria;Monash University;Monash University;Monash University, CSIRO, Victoria",10.1109/infvis.2004.1;10.1109/tvcg.2011.202;10.1109/tvcg.2014.2346441;10.1109/tvcg.2008.165;10.1109/infvis.2005.1532150;10.1109/infvis.2004.1,Flow Maps;Matrix Visualisation;Cartographic Information Visualisation,86.0,63.0,39.0,2539.0,HM,,flow map representations;people resources multiple;standard od matrix;bundled;second study compared,0.6535;0.2595;0.1523;0.0748;0.0130,"[np.int64(-1), -1, -1, -1, -1]",63;-1;-1;-1;-1,63,63,Flow Visualization Techniques
Vis,2010,Noodles: A Tool for Visualization of Numerical Weather Model Ensemble Uncertainty,10.1109/tvcg.2010.181,http://dx.doi.org/10.1109/TVCG.2010.181,1421.0,1430.0,J,"Numerical weather prediction ensembles are routinely used for operational weather forecasting. The members of these ensembles are individual simulations with either slightly perturbed initial conditions or different model parameterizations, or occasionally both. Multi-member ensemble output is usually large, multivariate, and challenging to interpret interactively. Forecast meteorologists are interested in understanding the uncertainties associated with numerical weather prediction; specifically variability between the ensemble members. Currently, visualization of ensemble members is mostly accomplished through spaghetti plots of a single midtroposphere pressure surface height contour. In order to explore new uncertainty visualization methods, the Weather Research and Forecasting (WRF) model was used to create a 48-hour, 18 member parameterization ensemble of the 13 March 1993 ""Superstorm"". A tool was designed to interactively explore the ensemble uncertainty of three important weather variables: water-vapor mixing ratio, perturbation potential temperature, and perturbation pressure. Uncertainty was quantified using individual ensemble member standard deviation, inter-quartile range, and the width of the 95% confidence interval. Bootstrapping was employed to overcome the dependence on normality in the uncertainty metrics. A coordinated view of ribbon and glyph-based uncertainty visualization, spaghetti plots, iso-pressure colormaps, and data transect plots was provided to two meteorologists for expert evaluation. They found it useful in assessing uncertainty in the data, especially in finding outliers in the ensemble run and therefore avoiding the WRF parameterizations that lead to these outliers. Additionally, the meteorologists could identify spatial regions where the uncertainty was significantly high, allowing for identification of poorly simulated storm environments and physical interpretation of these model issues.",Jibonananda Sanyal;Song Zhang 0004;Jamie L. Dyer;Andrew Mercer 0001;Philip Amburn;Robert J. Moorhead,Jibonananda Sanyal;Song Zhang;Jamie Dyer;Andrew Mercer;Philip Amburn;Robert Moorhead,"Geosystems Research Institute, Mississippi State University, USA;Department of Computer Science and Engineering, Mississippi State University, USA;Department of Geosciences, Mississippi State University, USA;Department of Geosciences and Northern Gulf Institute, Mississippi State University, USA;Geosystems Research Institute, Mississippi State University, USA;Geosystems Research Institute, Mississippi State University, USA",10.1109/tvcg.2009.114;10.1109/infvis.2002.1173145;10.1109/tvcg.2009.114,"Uncertainty visualization, weather ensemble, geographic/geospatial visualization, glyph-based techniques, time-varying data, qualitative evaluation",307.0,192.0,58.0,3132.0,,,weather prediction ensembles;uncertainty visualization spaghetti;midtroposphere pressure;view ribbon glyph;model used create,0.6616;0.5643;0.2166;0.1101;0.0729,"[np.int64(-1), np.int64(-1), -1, -1, -1]",12;73;-1;-1;-1,12;73,12,Climate Modeling
InfoVis,2013,Nanocubes for Real-Time Exploration of Spatiotemporal Datasets,10.1109/tvcg.2013.179,http://dx.doi.org/10.1109/TVCG.2013.179,2456.0,2465.0,J,"Consider real-time exploration of large multidimensional spatiotemporal datasets with billions of entries, each defined by a location, a time, and other attributes. Are certain attributes correlated spatially or temporally? Are there trends or outliers in the data? Answering these questions requires aggregation over arbitrary regions of the domain and attributes of the data. Many relational databases implement the well-known data cube aggregation operation, which in a sense precomputes every possible aggregate query over the database. Data cubes are sometimes assumed to take a prohibitively large amount of space, and to consequently require disk storage. In contrast, we show how to construct a data cube that fits in a modern laptop's main memory, even for billions of entries; we call this data structure a nanocube. We present algorithms to compute and query a nanocube, and show how it can be used to generate well-known visual encodings such as heatmaps, histograms, and parallel coordinate plots. When compared to exact visualizations created by scanning an entire dataset, nanocube plots have bounded screen error across a variety of scales, thanks to a hierarchical structure in space and time. We demonstrate the effectiveness of our technique on a variety of real-world datasets, and present memory, timing, and network bandwidth measurements. We find that the timings for the queries in our examples are dominated by network and user-interaction latencies.",Lauro Didier Lins;James T. Klosowski;Carlos Eduardo Scheidegger,Lauro Lins;James T. Klosowski;Carlos Scheidegger,"AT&T Research, USA;AT&T Research, USA;AT&T Research, USA",10.1109/tvcg.2006.161;10.1109/infvis.2002.1173141;10.1109/tvcg.2009.191;10.1109/vast.2008.4677357;10.1109/tvcg.2007.70594;10.1109/infvis.2002.1173156;10.1109/visual.1990.146386;10.1109/tvcg.2011.185;10.1109/tvcg.2006.161,"Data cube, Data structures, Interactive exploration",319.0,174.0,36.0,3076.0,HM,,data cubes;spatiotemporal;nanocube used;prohibitively;screen error,0.6653;0.3567;0.2817;0.1129;0.0109,"[np.int64(-1), -1, -1, -1, -1]",4;-1;-1;-1;-1,4,4,Spatial Data Structures
Vis,1998,Seabed visualization,10.1109/visual.1998.745348,http://dx.doi.org/10.1109/VISUAL.1998.745348,479.0,481.0,C,"The development of a high speed multi-frequency continuous scan sonar at Sonar Research &amp; Development Ltd has resulted in the acquisition of extremely accurate, high resolution bathymetric data. This rich underwater data provides new challenges and possibilities within the field of seabed visualization. This paper introduces the reader to seabed visualization by describing two example case studies which use the Seabed Visualization System developed at SRD. Both case studies, harbour wall and shipwreck visualization, are implemented using real survey data. The high resolution of the data obtained means slight changes in the seabed topography are easily distinguishable. Annual survey inspections in both case studies enable comparisons to be made between the data sets making the visualization system an important tool for management and planning.",Paul Chapman;Peter Stevens;Derek Wills;Graham R. Brookes,P. Chapman;P. Stevens;D. Wills;G. Brookes,"Department of Computer Science, University of Hull, UK;Department of Computer Science, University of Hull, UK;Department of Computer Science, University of Hull, UK;Department of Computer Science, University of Hull, UK",,,15.0,7.0,5.0,92.0,,,seabed visualization developed;survey data high;tool management planning;multi frequency continuous;resulted acquisition,0.8249;0.2173;0.1971;0.0857;-0.0184,"[np.int64(-1), -1, -1, -1, -1]",80;-1;-1;-1;-1,80,80,Terrain Visualization
SciVis,2015,TelCoVis: Visual Exploration of Co-occurrence in Urban Human Mobility Based on Telco Data,10.1109/tvcg.2015.2467194,http://dx.doi.org/10.1109/TVCG.2015.2467194,935.0,944.0,J,"Understanding co-occurrence in urban human mobility (i.e. people from two regions visit an urban place during the same time span) is of great value in a variety of applications, such as urban planning, business intelligence, social behavior analysis, as well as containing contagious diseases. In recent years, the widespread use of mobile phones brings an unprecedented opportunity to capture large-scale and fine-grained data to study co-occurrence in human mobility. However, due to the lack of systematic and efficient methods, it is challenging for analysts to carry out in-depth analyses and extract valuable information. In this paper, we present TelCoVis, an interactive visual analytics system, which helps analysts leverage their domain knowledge to gain insight into the co-occurrence in urban human mobility based on telco data. Our system integrates visualization techniques with new designs and combines them in a novel way to enhance analysts' perception for a comprehensive exploration. In addition, we propose to study the correlations in co-occurrence (i.e. people from multiple regions visit different places during the same time span) by means of biclustering techniques that allow analysts to better explore coordinated relationships among different regions and identify interesting patterns. The case studies based on a real-world dataset and interviews with domain experts have demonstrated the effectiveness of our system in gaining insights into co-occurrence and facilitating various analytical tasks.",Wenchao Wu;Jiayi Xu 0001;Haipeng Zeng;Yixian Zheng;Huamin Qu;Bing Ni;Mingxuan Yuan;Lionel M. Ni,Wenchao Wu;Jiayi Xu;Haipeng Zeng;Yixian Zheng;Huamin Qu;Bing Ni;Mingxuan Yuan;Lionel M. Ni,"Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Noah's Ark Lab, Huawei Technologies Investment Co. Ltd.;Noah's Ark Lab, Huawei Technologies Investment Co. Ltd.;University of Macau",10.1109/vast.2010.5652478;10.1109/tvcg.2013.193;10.1109/tvcg.2014.2346276;10.1109/tvcg.2013.226;10.1109/tvcg.2011.166;10.1109/tvcg.2013.173;10.1109/tvcg.2014.2346271;10.1109/vast.2011.6102455;10.1109/infvis.2000.885091;10.1109/tvcg.2014.2346665;10.1109/tvcg.2012.265;10.1109/tvcg.2013.228;10.1109/vast.2014.7042490;10.1109/tvcg.2014.2346922;10.1109/vast.2010.5652478,"Co-occurrence, human mobility, telco data, bicluster, visual analytics",102.0,69.0,45.0,2158.0,,,urban human mobility;visual analytics;understanding occurrence;biclustering techniques;diseases recent,0.6425;0.4833;0.2891;0.2713;0.1051,"[np.int64(-1), np.int64(-1), -1, -1, -1]",6;108;-1;-1;-1,6;108,6,Geospatial Data Analysis
SciVis,2015,Distribution Driven Extraction and Tracking of Features for Time-varying Data Analysis,10.1109/tvcg.2015.2467436,http://dx.doi.org/10.1109/TVCG.2015.2467436,837.0,846.0,J,"Effective analysis of features in time-varying data is essential in numerous scientific applications. Feature extraction and tracking are two important tasks scientists rely upon to get insights about the dynamic nature of the large scale time-varying data. However, often the complexity of the scientific phenomena only allows scientists to vaguely define their feature of interest. Furthermore, such features can have varying motion patterns and dynamic evolution over time. As a result, automatic extraction and tracking of features becomes a non-trivial task. In this work, we investigate these issues and propose a distribution driven approach which allows us to construct novel algorithms for reliable feature extraction and tracking with high confidence in the absence of accurate feature definition. We exploit two key properties of an object, motion and similarity to the target feature, and fuse the information gained from them to generate a robust feature-aware classification field at every time step. Tracking of features is done using such classified fields which enhances the accuracy and robustness of the proposed algorithm. The efficacy of our method is demonstrated by successfully applying it on several scientific data sets containing a wide range of dynamic time-varying features.",Soumya Dutta;Han-Wei Shen,Soumya Dutta;Han-Wei Shen,"GRAVITY group, The Ohio State University;GRAVITY group, The Ohio State University",10.1109/tvcg.2007.70599;10.1109/visual.1993.398877;10.1109/visual.2004.107;10.1109/tvcg.2011.246;10.1109/tvcg.2007.70615;10.1109/visual.2003.1250374;10.1109/tvcg.2013.152;10.1109/tvcg.2014.2346423;10.1109/tvcg.2007.70579;10.1109/visual.1996.567807;10.1109/visual.1998.745288;10.1109/tvcg.2008.163;10.1109/tvcg.2008.140;10.1109/tvcg.2007.70599,"Gaussian mixture model (GMM), Incremental learning, Feature extraction and tracking, Time-varying data analysis",44.0,34.0,45.0,1230.0,,,time varying features;extraction tracking high;scientists vaguely;algorithms reliable;definition exploit key,0.5741;0.2709;0.2649;0.1686;-0.0001,"[np.int64(-1), -1, -1, -1, -1]",112;-1;-1;-1;-1,112,112,Temporal Feature Analysis
InfoVis,2004,Keynote Address: From Information Visualization to Sensemaking: Connecting the Mind's Eye to the Mind's Muscle,10.1109/infvis.2004.44,http://dx.doi.org/10.1109/INFVIS.2004.44,,,M,Provides an abstract of the keynote presentation and a brief professional biography of the presenter. The complete presentation was not made available for publication as part of the conference proceedings.,Stuart K. Card,S. Card,"Palo Alto Research Center, Inc.orporated, USA",,,9.0,1.0,0.0,182.0,,,abstract keynote presentation;provides;publication;professional;available,0.5086;0.2441;0.2099;0.1765;0.0690,"[np.int64(-1), -1, -1, -1, -1]",7;-1;-1;-1;-1,7,7,Motivational Speaking
Vis,2001,PixelFlex: a reconfigurable multi-projector display system,10.1109/visual.2001.964508,http://dx.doi.org/10.1109/VISUAL.2001.964508,167.0,554.0,C,"This paper presents PixelFlex - a spatially reconfigurable multi-projector display system. The PixelFlex system is composed of ceiling-mounted projectors, each with computer-controlled pan, tilt, zoom and focus; and a camera for closed-loop calibration. Working collectively, these controllable projectors function as a single logical display capable of being easily modified into a variety of spatial formats of differing pixel density, size and shape. New layouts are automatically calibrated within minutes to generate the accurate warping and blending functions needed to produce seamless imagery across planar display surfaces, thus giving the user the flexibility to quickly create, save and restore multiple screen configurations. Overall, PixelFlex provides a new level of automatic reconfigurability and usage, departing from the static, one-size-fits-all design of traditional large-format displays. As a front-projection system, PixelFlex can be installed in most environments with space constraints and requires little or no post-installation mechanical maintenance because of the closed-loop calibration.",Ruigang Yang;David Gotz;Justin Hensley;Herman Towles;Michael S. Brown,Ruigang Yang;D. Gotz;J. Hensley;H. Towles;M.S. Brown,"Department of Computer Science, University of North Carolina, Chapel Hill, USA;Department of Computer Science, University of North Carolina, Chapel Hill, USA;Department of Computer Science, University of North Carolina, Chapel Hill, USA;Department of Computer Science, University of North Carolina, Chapel Hill, USA;Department of Computer Science, University of Kentucky, USA",10.1109/visual.2000.885685;10.1109/visual.1999.809890;10.1109/visual.1999.809883;10.1109/visual.2000.885712,"large-format projection display, camera-based registration and calibration",277.0,33.0,30.0,664.0,,,reconfigurable multi projector;overall pixelflex provides;little post installation;minutes generate accurate;logical,0.7340;0.3360;0.1055;0.0467;0.0329,"[np.int64(-1), -1, -1, -1, -1]",0;-1;-1;-1;-1,0,0,Projector Technology
InfoVis,2004,BinX: Dynamic Exploration of Time Series Datasets Across Aggregation Levels,10.1109/infvis.2004.11,http://dx.doi.org/10.1109/INFVIS.2004.11,2.0,2.0,M,"Many fields of study produce time series datasets, and both the size and number of theses datasets are increasing rapidly due to the improvement of data accumulation methods such as small, cheap sensors and routine logging of events. Humans often fail to comprehend the structure of a long time series dataset because of the overwhelming amount of data and the range of different time scales at which there may be meaningful patterns. BinX is an interactive tool that provides dynamic visualization and manipulation of long time series datasets. The dataset is visualized through user controlled aggregation, augmented by various information visualization techniques.",Lior Berry;Tamara Munzner,L. Berry;T. Munzner,"University of British Columbia, Canada;University of British Columbia, Canada",0.1109/infvis.1999.801851;10.1109/infvis.1998.729557,,57.0,8.0,4.0,375.0,,,time series datasets;visualization techniques;binx interactive tool;increasing rapidly;structure,0.6074;0.4266;0.3065;0.1856;0.1475,"[np.int64(-1), -1, -1, -1, -1]",5;-1;-1;-1;-1,5,5,Synthetic Time Series
Vis,1996,Perceptualisation using a tactile mouse,10.1109/visual.1996.568104,http://dx.doi.org/10.1109/VISUAL.1996.568104,181.0,188.0,C,"Whilst there has been considerable effort in constructing force feedback devices for use in virtual environments, and in the use of touch as a prosthesis for the blind, there has been little work on the use of touch in the visualisation or more properly, perceptualisation of data. Touch potentially offers an additional dimension of perception where visualisation is limited by screen size, resolution, and visual overload. We describe some tactile mice and experiments in using tactile mice for a variety of perceptualisation tasks.",Robert G. Hughes;A. Robin Forrest,R.G. Hughes;A.R. Forrest,"School of Information Systems, University of East Anglia, Norwich, Norfolk, GB;School of Information Systems, University of East Anglia, Norwich, Norfolk, GB",10.1109/visual.1995.480802;10.1109/visual.1995.480802,,53.0,6.0,24.0,97.0,,,using tactile mice;resolution visual;effort constructing force;whilst;potentially offers,0.7391;0.3058;0.1666;0.0881;0.0030,"[np.int64(-1), -1, -1, -1, -1]",35;-1;-1;-1;-1,35,35,Gaming Peripherals
InfoVis,2004,Paint Inspired Color Mixing and Compositing for Visualization,10.1109/infvis.2004.52,http://dx.doi.org/10.1109/INFVIS.2004.52,113.0,118.0,C,"Color is often used to convey information, and color compositing is often required while visualizing multiattribute information. This paper proposes an alternative method for color compositing. In order to present understandable color blending to the general public, several techniques are proposed. First, a paint-inspired RYB color space is used. In addition, noise patterns are employed to produce subregions of pure color within an overlapped region. We show examples to demonstrate the effectiveness of our technique for visualization",Nathan Gossett;Baoquan Chen,N. Gossett;Baoquan Chen,"University of Minnesota, Twin city, France;University of Minnesota, Twin city, France",10.1109/visual.2003.1250362;10.1109/visual.2003.1250362,"RYB, Color Mixing, Perception",81.0,21.0,6.0,688.0,,,information color compositing;noise patterns;produce subregions;ryb;examples demonstrate,0.6945;0.3277;0.1913;0.1812;0.1530,"[np.int64(-1), -1, -1, -1, -1]",-1;-1;-1;-1;-1,,-1,Interactive 3D Visualization
SciVis,2014,Visualizing 2-dimensional Manifolds with Curve Handles in 4D,10.1109/tvcg.2014.2346425,http://dx.doi.org/10.1109/TVCG.2014.2346425,2575.0,2584.0,J,"In this paper, we present a mathematical visualization paradigm for exploring curves embedded in 3D and surfaces in 4D mathematical world. The basic problem is that, 3D figures of 4D mathematical entities often twist, turn, and fold back on themselves, leaving important properties behind the surface sheets. We propose an interactive system to visualize the topological features of the original 4D surface by slicing its 3D figure into a series of feature diagram. A novel 4D visualization interface is designed to allow users to control 4D topological shapes via the collection of diagram handles using the established curve manipulation mechanism. Our system can support rich mathematical interaction of 4D mathematical objects which is very difficult with any existing approach. We further demonstrate the effectiveness of the proposed visualization tool using various experimental results and cases studies.",Hui Zhang 0006;Jianguang Weng;Guangchen Ruan,Hui Zhang;Jianguang Weng;Guangchen Ruan,"Pervasive Technology Institute, Indiana University;Zhejiang University of Media and Communication;School of Informatics and Computing, Indiana University",10.1109/tvcg.2012.242;10.1109/visual.2005.1532804;10.1109/visual.2005.1532843;10.1109/tvcg.2010.151;10.1109/visual.2005.1532833;10.1109/tvcg.2007.70593;10.1109/tvcg.2012.242,"math visualization, 4D, deformation, Reidemeister theorem",13.0,8.0,38.0,426.0,,,4d visualization interface;using established curve;twist turn;important properties;allow users,0.7245;0.1907;0.1797;0.0820;0.0515,"[np.int64(-1), -1, -1, -1, -1]",82;-1;-1;-1;-1,82,82,3D/4D Visualization
VAST,2015,Sequencing of categorical time series,10.1109/vast.2015.7347684,http://dx.doi.org/10.1109/VAST.2015.7347684,213.0,214.0,M,"Exploring and comparing categorical time series and finding temporal patterns are complex tasks in the field of time series data mining. Although different analysis approaches exist, these tasks remain challenging, especially when numerous time series are considered at once. We propose a visual analysis approach that supports exploring such data by ordering time series in meaningful ways. We provide interaction techniques to steer the automated arrangement and to allow users to investigate patterns in detail.",Christian Richter;Martin Luboschik;Martin Rohlig;Heidrun Schumann,Christian Richter;Martin Luboschik;Martin Röhlig;Heidrun Schumann,"Universitat Rostock, Rostock, Mecklenburg-Vorpommern, DE;Universitat Rostock, Rostock, Mecklenburg-Vorpommern, DE;Universitat Rostock, Rostock, Mecklenburg-Vorpommern, DE;University of Rostock",,,4.0,2.0,5.0,198.0,,,finding temporal patterns;propose visual;mining different;especially;allow users,0.6172;0.2316;0.2123;0.0445;-0.0565,"[np.int64(-1), -1, -1, -1, -1]",59;-1;-1;-1;-1,59,59,Temporal Analysis
SciVis,2013,Acuity-Driven Gigapixel Visualization,10.1109/tvcg.2013.127,http://dx.doi.org/10.1109/TVCG.2013.127,2886.0,2895.0,J,"We present a framework for acuity-driven visualization of super-high resolution image data on gigapixel displays. Tiled display walls offer a large workspace that can be navigated physically by the user. Based on head tracking information, the physical characteristics of the tiled display and the formulation of visual acuity, we guide an out-of-core gigapixel rendering scheme by delivering high levels of detail only in places where it is perceivable to the user. We apply this principle to gigapixel image rendering through adaptive level of detail selection. Additionally, we have developed an acuity-driven tessellation scheme for high-quality Focus-and-Context (F+C) lenses that significantly reduces visual artifacts while accurately capturing the underlying lens function. We demonstrate this framework on the Reality Deck, an immersive gigapixel display. We present the results of a user study designed to quantify the impact of our acuity-driven rendering optimizations in the visual exploration process. We discovered no evidence suggesting a difference in search task performance between our framework and naive rendering of gigapixel resolution data, while realizing significant benefits in terms of data transfer overhead. Additionally, we show that our acuity-driven tessellation scheme offers substantially increased frame rates when compared to naive pre-tessellation, while providing indistinguishable image quality.",Charilaos Papadopoulos;Arie E. Kaufman,Charilaos Papadopoulos;Arie E. Kaufman,"Stony Brook University, USA;Stony Brook University, USA",10.1109/tvcg.2011.231;10.1109/infvis.2004.66,"Gigapixel visualization, visual acuity, focus and context, Reality Deck, gigapixel display",13.0,8.0,45.0,710.0,,,acuity driven rendering;guide core gigapixel;demonstrate framework reality;workspace navigated;benefits,0.6617;0.1607;0.1476;0.0903;0.0254,"[np.int64(-1), -1, -1, -1, -1]",43;-1;-1;-1;-1,43,43,Illustrative Rendering Techniques
VAST,2007,Balancing Interactive Data Management of Massive Data with Situational Awareness through Smart Aggregation,10.1109/vast.2007.4388998,http://dx.doi.org/10.1109/VAST.2007.4388998,67.0,74.0,C,"Designing a visualization system capable of processing, managing, and presenting massive data sets while maximizing the user's situational awareness (SA) is a challenging, but important, research question in visual analytics. Traditional data management and interactive retrieval approaches have often focused on solving the data overload problem at the expense of the user's SA. This paper discusses various data management strategies and the strengths and limitations of each approach in providing the user with SA. A new data management strategy, coined Smart Aggregation, is presented as a powerful approach to overcome the challenges of both massive data sets and maintaining SA. By combining automatic data aggregation with user-defined controls on what, how, and when data should be aggregated, we present a visualization system that can handle massive amounts of data while affording the user with the best possible SA. This approach ensures that a system is always usable in terms of both system resources and human perceptual resources. We have implemented our Smart Aggregation approach in a visual analytics system called VIAssist (Visual Assistant for Information Assurance Analysis) to facilitate exploration, discovery, and SA in the domain of Information Assurance.",Daniel R. Tesone;John R. Goodall,Daniel R. Tesone;John R. Goodall,"Division of Applied Visions Inc., Secure Decisions;Division of Applied Visions Inc., Secure Decisions",10.1109/vast.2006.261437;10.1109/visual.2005.1532792;10.1109/infvis.2004.10;10.1109/vast.2006.261437,"Data management, visual analytics, data retrieval, information visualization, smart aggregation, situational awareness",27.0,11.0,9.0,274.0,,,visual analytics;providing user sa;overload problem;important research;defined,0.6984;0.1942;0.1547;0.1065;0.0649,"[np.int64(-1), -1, -1, -1, -1]",108;-1;-1;-1;-1,108,108,Visual Analytics
SciVis,2014,Multiscale Symmetry Detection in Scalar Fields by Clustering Contours,10.1109/tvcg.2014.2346332,http://dx.doi.org/10.1109/TVCG.2014.2346332,2427.0,2436.0,J,"The complexity in visualizing volumetric data often limits the scope of direct exploration of scalar fields. Isocontour extraction is a popular method for exploring scalar fields because of its simplicity in presenting features in the data. In this paper, we present a novel representation of contours with the aim of studying the similarity relationship between the contours. The representation maps contours to points in a high-dimensional transformation-invariant descriptor space. We leverage the power of this representation to design a clustering based algorithm for detecting symmetric regions in a scalar field. Symmetry detection is a challenging problem because it demands both segmentation of the data and identification of transformation invariant segments. While the former task can be addressed using topological analysis of scalar fields, the latter requires geometry based solutions. Our approach combines the two by utilizing the contour tree for segmenting the data and the descriptor space for determining transformation invariance. We discuss two applications, query driven exploration and asymmetry visualization, that demonstrate the effectiveness of the approach.",Dilip Mathew Thomas;Vijay Natarajan,Dilip Mathew Thomas;Vijay Natarajan,"Department of Computer Science and Automation, Indian Institute of Science, Bangalore, India;Department of Computer Science and Automation and Supercomputer Education Research Centre, Indian Institute of Science, Bangalore, India",10.1109/tvcg.2013.142;10.1109/visual.1999.809869;10.1109/tvcg.2006.149;10.1109/tvcg.2011.236;10.1109/tvcg.2008.143;10.1109/tvcg.2011.258;10.1109/tvcg.2013.148;10.1109/tvcg.2013.142,"Scalar field visualization, symmetry detection, contour tree, data exploration",52.0,33.0,43.0,571.0,,,visualizing volumetric data;fields isocontour;identification transformation invariant;addressed using topological;combines,0.6331;0.4523;0.2882;0.2366;-0.0202,"[np.int64(-1), -1, -1, -1, -1]",55;-1;-1;-1;-1,55,55,Volumetric Data Visualization
Vis,2000,Simplification of tetrahedral meshes with accurate error evaluation,10.1109/visual.2000.885680,http://dx.doi.org/10.1109/VISUAL.2000.885680,85.0,92.0,C,"The techniques for reducing the size of a volume dataset by preserving both the geometrical/topological shape and the information encoded in an attached scalar field are attracting growing interest. Given the framework of incremental 3D mesh simplification based on edge collapse, we propose an approach for the integrated evaluation of the error introduced by both the modification of the domain and the approximation of the field of the original volume dataset. We present and compare various techniques to evaluate the approximation error or to produce a sound prediction. A flexible simplification tool has been implemented, which provides a different degree of accuracy and computational efficiency for the selection of the edge to be collapsed. Techniques for preventing a geometric or topological degeneration of the mesh are also presented.",Paolo Cignoni;D. Constanza;Claudio Montani;Claudio Rocchini;Roberto Scopigno,P. Cignoni;D. Costanza;C. Montani;C. Rocchini;R. Scopigno,"Istituto Scienza e Tecnologia dellInformazione, Consiglio Nationale delle Ricerche, Italy;Istituto Scienza e Tecnologia dellInformazione, Consiglio Nationale delle Ricerche, Italy;Istituto Scienza e Tecnologia dellInformazione, Consiglio Nationale delle Ricerche, Italy;Istituto Scienza e Tecnologia dellInformazione, Consiglio Nationale delle Ricerche, Italy;Istituto Scienza e Tecnologia dellInformazione, Consiglio Nationale delle Ricerche, Italy",10.1109/visual.1998.745315;10.1109/visual.1997.663907;10.1109/visual.1998.745329;10.1109/visual.1998.745312;10.1109/visual.1998.745315,"Simplicial Complexes, Mesh Simplification,Volume Visualization, Unstructured Grids",149.0,32.0,24.0,167.0,,,3d mesh simplification;original volume dataset;selection edge;integrated evaluation error;encoded attached scalar,0.6899;0.4667;0.0988;0.0922;0.0753,"[np.int64(-1), -1, -1, -1, -1]",79;-1;-1;-1;-1,79,79,Mesh Simplification Techniques
SciVis,2014,ViSlang: A System for Interpreted Domain-Specific Languages for Scientific Visualization,10.1109/tvcg.2014.2346318,http://dx.doi.org/10.1109/TVCG.2014.2346318,2388.0,2396.0,J,"Researchers from many domains use scientific visualization in their daily practice. Existing implementations of algorithms usually come with a graphical user interface (high-level interface), or as software library or source code (low-level interface). In this paper we present a system that integrates domain-specific languages (DSLs) and facilitates the creation of new DSLs. DSLs provide an effective interface for domain scientists avoiding the difficulties involved with low-level interfaces and at the same time offering more flexibility than high-level interfaces. We describe the design and implementation of ViSlang, an interpreted language specifically tailored for scientific visualization. A major contribution of our design is the extensibility of the ViSlang language. Novel DSLs that are tailored to the problems of the domain can be created and integrated into ViSlang. We show that our approach can be added to existing user interfaces to increase the flexibility for expert users on demand, but at the same time does not interfere with the user experience of novice users. To demonstrate the flexibility of our approach we present new DSLs for volume processing, querying and visualization. We report the implementation effort for new DSLs and compare our approach with Matlab and Python implementations in terms of run-time performance.",Peter Rautek;Stefan Bruckner;M. Eduard Gröller;Markus Hadwiger,Peter Rautek;Stefan Bruckner;M. Eduard Gröller;Markus Hadwiger,"KAUST;University of Bergen;Vienna University of Technology, VrVis Research Center;KAUST",10.1109/visual.2005.1532792;10.1109/visual.1992.235219;10.1109/tvcg.2009.174;10.1109/tvcg.2014.2346322;10.1109/visual.2004.95;10.1109/tvcg.2011.185;10.1109/visual.2005.1532788;10.1109/visual.1992.235202;10.1109/tvcg.2008.184,"Domain-specific languages, Volume visualization, Volume visualization framework",28.0,23.0,42.0,800.0,,,scientific visualization;specific languages dsls;paper present integrates;usually;added,0.6753;0.3161;0.0955;-0.0231;-0.0353,"[np.int64(-1), -1, -1, -1, -1]",84;-1;-1;-1;-1,84,84,Scientific Visualization
Vis,2022,Tac-Trainer: A Visual Analytics System for IoT-based Racket Sports Training,10.1109/tvcg.2022.3209352,http://dx.doi.org/10.1109/TVCG.2022.3209352,951.0,961.0,J,"Conventional racket sports training highly relies on coaches' knowledge and experience, leading to biases in the guidance. To solve this problem, smart wearable devices based on Internet of Things technology (IoT) have been extensively investigated to support data-driven training. Considerable studies introduced methods to extract valuable information from the sensor data collected by IoT devices. However, the information cannot provide actionable insights for coaches due to the large data volume and high data dimensions. We proposed an IoT + VA framework, Tac-Trainer, to integrate the sensor data, the information, and coaches' knowledge to facilitate racket sports training. Tac-Trainer consists of four components: device configuration, data interpretation, training optimization, and result visualization. These components collect trainees' kinematic data through IoT devices, transform the data into attributes and indicators, generate training suggestions, and provide an interactive visualization interface for exploration, respectively. We further discuss new research opportunities and challenges inspired by our work from two perspectives, VA for IoT and IoT for VA.",Jiachen Wang;Ji Ma;Kangping Hu;Zheng Zhou;Hui Zhang 0051;Xiao Xie;Yingcai Wu,Jiachen Wang;Ji Ma;Kangping Hu;Zheng Zhou;Hui Zhang;Xiao Xie;Yingcai Wu,"State Key Lab of CAD&CG, Zhejiang University, China;State Key Lab of CAD&CG, Zhejiang University, China;State Key Lab of CAD&CG, Zhejiang University, China;Department of Sports Science, Zhejiang University, China;Department of Sports Science, Zhejiang University, China;State Key Lab of CAD&CG, Zhejiang University, China;State Key Lab of CAD&CG, Zhejiang University, China",10.1109/tvcg.2013.178;10.1109/tvcg.2019.2934280;10.1109/tvcg.2021.3114806;10.1109/tvcg.2020.3030342;10.1109/tvcg.2021.3114861;10.1109/tvcg.2015.2468292;10.1109/tvcg.2011.208;10.1109/tvcg.2013.192;10.1109/tvcg.2019.2934243;10.1109/tvcg.2014.2346445;10.1109/tvcg.2017.2745181;10.1109/tvcg.2019.2934630;10.1109/tvcg.2017.2744218;10.1109/tvcg.2018.2865041;10.1109/tvcg.2020.3030359;10.1109/tvcg.2012.263;10.1109/tvcg.2013.178,"IoT,racket sports,training,sensor data,visual analytics",,10.0,91.0,1335.0,,,kinematic data iot;sports training highly;result visualization;va;experience leading biases,0.5765;0.4268;0.1613;0.1382;0.1080,"[np.int64(-1), -1, -1, -1, -1]",6;-1;-1;-1;-1,6,6,Geospatial Data Analysis
Vis,2001,Interactive volume rendering using multi-dimensional transfer functions and direct manipulation widgets,10.1109/visual.2001.964519,http://dx.doi.org/10.1109/VISUAL.2001.964519,255.0,262.0,C,"Most direct volume renderings produced today employ one-dimensional transfer functions, which assign color and opacity to the volume based solely on the single scalar quantity which comprises the dataset. Though they have not received widespread attention, multi-dimensional transfer functions are a very effective way to extract specific material boundaries and convey subtle surface properties. However, identifying good transfer functions is difficult enough in one dimension, let alone two or three dimensions. This paper demonstrates an important class of three-dimensional transfer functions for scalar data (based on data value, gradient magnitude, and a second directional derivative), and describes a set of direct manipulation widgets which make specifying such transfer functions intuitive and convenient. We also describe how to use modem graphics hardware to interactively render with multi-dimensional transfer functions. The transfer functions, widgets, and hardware combine to form a powerful system for interactive volume exploration.",Joe Kniss;Gordon L. Kindlmann;Charles D. Hansen,J. Kniss;G. Kindlmann;C. Hansen,"Scientific Computing and Imaging Institute, School of Computing, University of Utah, USA;Scientific Computing and Imaging Institute, School of Computing, University of Utah, USA;Scientific Computing and Imaging Institute, School of Computing, University of Utah, USA",10.1109/visual.1995.480803;10.1109/visual.1999.809908;10.1109/visual.1999.809889;10.1109/visual.1996.568113;10.1109/visual.1997.663875;10.1109/visual.1995.480803,"volume visualization, direct volume rendering, multi-dimensional transfer functions, direct manipulation widgets, graphics hardware",579.0,137.0,34.0,647.0,BP,,direct volume renderings;second directional derivative;functions widgets;assign color;identifying good transfer,0.7290;0.2627;0.1856;0.1317;0.1071,"[np.int64(-1), -1, -1, -1, -1]",52;-1;-1;-1;-1,52,52,Volume Rendering Techniques
VAST,2006,A Visual Interface for Multivariate Temporal Data: Finding Patterns of Events across Multiple Histories,10.1109/vast.2006.261421,http://dx.doi.org/10.1109/VAST.2006.261421,167.0,174.0,C,"Finding patterns of events over time is important in searching patient histories, Web logs, news stories, and criminal activities. This paper presents PatternFinder, an integrated interface for query and result-set visualization for search and discovery of temporal patterns within multivariate and categorical data sets. We define temporal patterns as sequences of events with inter-event time spans. PatternFinder allows users to specify the attributes of events and time spans to produce powerful pattern queries that are difficult to express with other formalisms. We characterize the range of queries PatternFinder supports as users vary the specificity at which events and time spans are defined. Pattern Finder's query capabilities together with coupled ball-and-chain and tabular visualizations enable users to effectively query, explore and analyze event patterns both within and across data entities (e.g. patient histories, terrorist groups, Web logs, etc.)",Jerry Alan Fails;Amy K. Karlson;Layla Shahamat;Ben Shneiderman,Jerry Alan Fails;Amy Karlson;Layla Shahamat;Ben Shneiderman,"Department of Computer Science & Human-Computer Interaction Lab, University of Maryland, College Park, Maryland, USA;Department of Computer Science & Human-Computer Interaction Lab, University of Maryland, College Park, Maryland, USA;Department of Computer Science & Human-Computer Interaction Lab, University of Maryland, College Park, Maryland, USA;Department of Computer Science & Human-Computer Interaction Lab, University of Maryland, College Park, Maryland",10.1109/infvis.2001.963273;10.1109/infvis.2001.963273,"Temporal query, information visualization, user interface",168.0,83.0,27.0,1188.0,TT,,event patterns data;finder;ball chain tabular;spans produce powerful;enable users,0.6779;0.2643;0.1712;0.1281;-0.0739,"[np.int64(-1), -1, -1, -1, -1]",58;-1;-1;-1;-1,58,58,Event Data Analysis
SciVis,2012,Effects of Stereo and Screen Size on the Legibility of Three-Dimensional Streamtube Visualization,10.1109/tvcg.2012.216,http://dx.doi.org/10.1109/TVCG.2012.216,2130.0,2139.0,J,"We report the impact of display characteristics (stereo and size) on task performance in diffusion magnetic resonance imaging (DMRI) in a user study with 12 participants. The hypotheses were that (1) adding stereo and increasing display size would improve task accuracy and reduce completion time, and (2) the greater the complexity of a spatial task, the greater the benefits of an improved display. Thus we expected to see greater performance gains when detailed visual reasoning was required. Participants used dense streamtube visualizations to perform five representative tasks: (1) determine the higher average fractional anisotropy (FA) values between two regions, (2) find the endpoints of fiber tracts, (3) name a bundle, (4) mark a brain lesion, and (5) judge if tracts belong to the same bundle. Contrary to our hypotheses, we found the task completion time was not improved by the use of the larger display and that performance accuracy was hurt rather than helped by the introduction of stereo in our study with dense DMRI data. Bigger was not always better. Thus cautious should be taken when selecting displays for scientific visualization applications. We explored the results further using the body-scale unit and subjective size and stereo experiences.",Jian Chen 0006;Haipeng Cai;Alexander P. Auchus;David H. Laidlaw,Jian Chen;Haipeng Cai;Alexander P. Auchus;David H. Laidlaw,"University of Maryland, Baltimore, USA;University of Southern Mississippi, USA;University of Mississippi Medical Center, USA;Brown University, USA",10.1109/tvcg.2009.126;10.1109/visual.2000.885694;10.1109/visual.2003.1250414;10.1109/tvcg.2009.111;10.1109/tvcg.2009.138;10.1109/tvcg.2006.183;10.1109/tvcg.2009.126,"Display characteristics, diffusion tensor MRI, virtual environment",46.0,27.0,49.0,718.0,,,scientific visualization;use larger display;dmri user;task completion time;fractional anisotropy fa,0.5399;0.3152;0.1784;0.1593;0.1365,"[np.int64(-1), -1, -1, -1, -1]",84;-1;-1;-1;-1,84,84,Scientific Visualization
InfoVis,2017,Orko: Facilitating Multimodal Interaction for Visual Exploration and Analysis of Networks,10.1109/tvcg.2017.2745219,http://dx.doi.org/10.1109/TVCG.2017.2745219,511.0,521.0,J,"Data visualization systems have predominantly been developed for WIMP-based direct manipulation interfaces. Only recently have other forms of interaction begun to appear, such as natural language or touch-based interaction, though usually operating only independently. Prior evaluations of natural language interfaces for visualization have indicated potential value in combining direct manipulation and natural language as complementary interaction techniques. We hypothesize that truly multimodal interfaces for visualization, those providing users with freedom of expression via both natural language and touch-based direct manipulation input, may provide an effective and engaging user experience. Unfortunately, however, little work has been done in exploring such multimodal visualization interfaces. To address this gap, we have created an architecture and a prototype visualization system called Orko that facilitates both natural language and direct manipulation input. Specifically, Orko focuses on the domain of network visualization, one that has largely relied on WIMP-based interfaces and direct manipulation interaction, and has little or no prior research exploring natural language interaction. We report results from an initial evaluation study of Orko, and use our observations to discuss opportunities and challenges for future work in multimodal network visualization interfaces.",Arjun Srinivasan;John T. Stasko,Arjun Srinivasan;John Stasko,Georgia Institute of Technology;Georgia Institute of Technology,10.1109/infvis.2005.1532136;10.1109/tvcg.2011.185;10.1109/tvcg.2013.124;10.1109/tvcg.2010.164;10.1109/tvcg.2012.204;10.1109/tvcg.2009.108;10.1109/tvcg.2016.2599107,"Multimodal interaction,network visualization,natural language input,direct manipulation,multitouch input",95.0,84.0,70.0,1864.0,,,visualization interfaces;manipulation natural language;orko facilitates;independently prior evaluations;natural,0.6567;0.3561;0.1856;0.0912;0.0815,"[np.int64(-1), -1, -1, -1, -1]",109;-1;-1;-1;-1,109,109,Visualization Technologies
Vis,1992,Visualizing wind velocities by advecting cloud textures,10.1109/visual.1992.235210,http://dx.doi.org/10.1109/VISUAL.1992.235210,179.0,184.0,C,"In order to visualize both clouds and wind in climate simulations, clouds were rendered using a 3D texture which was advected by the wind flow. The simulation is described. Rendering, the advection of texture coordinates, and haze effects are discussed. Results are presented.&lt;&lt;ETX&gt;&gt;",Nelson L. Max;Roger Crawfis;Dean Williams,N. Max;R. Crawfis;D. Williams,"Lawrence Livemore National Laboratory, Livermore, CA, USA;Lawrence Livemore National Laboratory, Livermore, CA, USA;Lawrence Livemore National Laboratory, Livermore, CA, USA",10.1109/visual.1991.175773;10.1109/visual.1991.175773,"advection, 3-D texture, volume visualization, vectorfield, wind, clouds, climate modeling",89.0,28.0,11.0,133.0,,,visualize clouds wind;using 3d texture;rendering;simulation described;lt etx,0.7921;0.3951;0.3567;0.2015;-0.0109,"[np.int64(-1), -1, -1, -1, -1]",67;-1;-1;-1;-1,67,67,Atmospheric Visualization
VAST,2020,HyperTendril: Visual Analytics for User-Driven Hyperparameter Optimization of Deep Neural Networks,10.1109/tvcg.2020.3030380,http://dx.doi.org/10.1109/TVCG.2020.3030380,1407.0,1416.0,J,"To mitigate the pain of manually tuning hyperparameters of deep neural networks, automated machine learning (AutoML) methods have been developed to search for an optimal set of hyperparameters in large combinatorial search spaces. However, the search results of AutoML methods significantly depend on initial configurations, making it a non-trivial task to find a proper configuration. Therefore, human intervention via a visual analytic approach bears huge potential in this task. In response, we propose HyperTendril, a web-based visual analytics system that supports user-driven hyperparameter tuning processes in a model-agnostic environment. HyperTendril takes a novel approach to effectively steering hyperparameter optimization through an iterative, interactive tuning procedure that allows users to refine the search spaces and the configuration of the AutoML method based on their own insights from given results. Using HyperTendril, users can obtain insights into the complex behaviors of various hyperparameter search algorithms and diagnose their configurations. In addition, HyperTendril supports variable importance analysis to help the users refine their search spaces based on the analysis of relative importance of different hyperparameters and their interaction effects. We present the evaluation demonstrating how HyperTendril helps users steer their tuning processes via a longitudinal user study based on the analysis of interaction logs and in-depth interviews while we deploy our system in a professional industrial environment.",Heungseok Park;Yoonsoo Nam;Jihoon Kim 0001;Jaegul Choo,Heungseok Park;Yoonsoo Nam;Ji-Hoon Kim;Jaegul Choo,"Clova AI Research, NAVER Corporation;Clova AI Research, NAVER Corporation;Clova AI Research, NAVER Corporation;KAIST",10.1109/tvcg.2016.2598829;10.1109/tvcg.2019.2934629;10.1109/tvcg.2018.2864838;10.1109/tvcg.2017.2744358;10.1109/tvcg.2014.2346248;10.1109/tvcg.2016.2598829,"Visual analytics,deep learning,machine learning,automated machine learning,human-centered computing",11.0,16.0,46.0,908.0,,,tuning hyperparameters deep;visual analytics;interviews deploy;takes novel approach;non,0.6389;0.4213;0.1474;0.1272;0.0368,"[np.int64(-1), np.int64(-1), -1, -1, -1]",13;108;-1;-1;-1,13;108,13,Advanced Machine Learning
InfoVis,2014,NeuroLines: A Subway Map Metaphor for Visualizing Nanoscale Neuronal Connectivity,10.1109/tvcg.2014.2346312,http://dx.doi.org/10.1109/TVCG.2014.2346312,2369.0,2378.0,J,"We present NeuroLines, a novel visualization technique designed for scalable detailed analysis of neuronal connectivity at the nanoscale level. The topology of 3D brain tissue data is abstracted into a multi-scale, relative distance-preserving subway map visualization that allows domain scientists to conduct an interactive analysis of neurons and their connectivity. Nanoscale connectomics aims at reverse-engineering the wiring of the brain. Reconstructing and analyzing the detailed connectivity of neurons and neurites (axons, dendrites) will be crucial for understanding the brain and its development and diseases. However, the enormous scale and complexity of nanoscale neuronal connectivity pose big challenges to existing visualization techniques in terms of scalability. NeuroLines offers a scalable visualization framework that can interactively render thousands of neurites, and that supports the detailed analysis of neuronal structures and their connectivity. We describe and analyze the design of NeuroLines based on two real-world use-cases of our collaborators in developmental neuroscience, and investigate its scalability to large-scale neuronal connectivity data.",Ali K. Al-Awami;Johanna Beyer;Hendrik Strobelt;Narayanan Kasthuri;Jeff W. Lichtman;Hanspeter Pfister;Markus Hadwiger,Ali K. Al-Awami;Johanna Beyer;Hendrik Strobelt;Narayanan Kasthuri;Jeff W. Lichtman;Hanspeter Pfister;Markus Hadwiger,King Abdullah University of Science and Technology (KAUST);School of Engineering and Applied Sciences at Harvard University;School of Engineering and Applied Sciences at Harvard University;Center for Brain Science at Harvard University;Center for Brain Science at Harvard University;School of Engineering and Applied Sciences at Harvard University;King Abdullah University of Science and Technology (KAUST),10.1109/tvcg.2013.142;10.1109/tvcg.2012.240;10.1109/tvcg.2014.2346371;10.1109/tvcg.2009.121;10.1109/vast.2011.6102439;10.1109/tvcg.2009.108;10.1109/tvcg.2011.192;10.1109/visual.2002.1183754;10.1109/tvcg.2013.154;10.1109/tvcg.2013.142,"Connectomics, Neuroscience, Data Abstraction, Multi-Trees, Focus+Context",65.0,53.0,47.0,1357.0,HM,,connectivity nanoscale connectomics;visualization technique;thousands;development diseases;allows domain,0.6727;0.3517;0.0932;0.0762;0.0181,"[np.int64(-1), -1, -1, -1, -1]",115;-1;-1;-1;-1,115,115,Structural Connectivity Analysis
Vis,2001,"Case study: reconstruction, visualization and quantification of neuronal fiber pathways",10.1109/visual.2001.964549,http://dx.doi.org/10.1109/VISUAL.2001.964549,453.0,456.0,C,"It is of significant interest for neurological studies to determine and visualize neuronal fiber pathways in the human brain. By exploiting the capability of diffusion tensor magnetic resonance imaging to detect local orientations of neuronal fibers, we have developed a system of algorithms to reconstruct, visualize and quantify neuronal fiber pathways in vivo. Illustrative results show that the system is a promising tool for visual analysis of fiber connectivity and quantitative studies of neuronal fibers.",Zhaohua Ding;John C. Gore;Adam W. Anderson,Zhaohua Ding;J.C. Gore;A.W. Anderson,"Department of Diagnostic Radiology, Yale University School of Medicine, USA;Department of Diagnostic Radiology, Yale University School of Medicine, USA;Department of Diagnostic Radiology, Yale University School of Medicine, USA",,"neuronal fiber pathway, diffusion tensor imaging",33.0,2.0,12.0,107.0,,,visualize neuronal fiber;diffusion tensor magnetic;detect local orientations;developed algorithms;significant,0.7095;0.4194;0.1689;0.1377;-0.0371,"[np.int64(-1), -1, -1, -1, -1]",42;-1;-1;-1;-1,42,42,Neural Visualization Techniques
Vis,1994,Challenges and opportunities in visualization for NASA's EOS Mission to Planet Earth,10.1109/visual.1994.346289,http://dx.doi.org/10.1109/VISUAL.1994.346289,392.0,395.0,M,"Visualization will be vital to the success of the NASA EOS Mission to Planet Earth (MTPE), which will gather, generate, and distribute an unprecedented volume of data for the purpose of global change research and environmental policy decisions. The paper focuses on the challenges and opportunities for visualization with regard to the Mission to Planet Earth. Directions presently being taken within NASA to fund and assist development of new tools are also discussed.&lt;&lt;ETX&gt;&gt;",Mike E. Botts;Jon D. Dykstra;Lee S. Elson;Steven J. Goodman;Meemong Lee,M. Botts;J.D. Dykstra;L.S. Elson;S.J. Goodman;Meemong Lee,"University of Alabama Huntsville, USA;Intergraph Corporation;Jet Propulsion Laboratory;NASA Marshall Space Flight Center;Jet Propulsion Laboratory",,,0.0,1.0,0.0,50.0,,,visualization regard mission;research environmental policy;earth;mtpe gather generate;etx gt gt,0.6161;0.2469;0.2435;0.1626;0.0350,"[np.int64(-1), -1, -1, -1, -1]",86;-1;-1;-1;-1,86,86,Scientific Visualization Presentations
Vis,1998,Comparing LIC and spot noise,10.1109/visual.1998.745324,http://dx.doi.org/10.1109/VISUAL.1998.745324,359.0,365.0,C,Spot noise and line integral convolution (LIC) are two texture synthesis techniques for vector field visualization. The two techniques are compared. Continuous directional convolution is used as a common basis for comparing the techniques. It is shown that the techniques are based on the same mathematical concept. Comparisons of the visual appearance of the output and performance of the algorithms are made.,Wim C. de Leeuw;Robert van Liere,W. de Leeuw;R. van Liere,"Center for Mathematics and Computer Science, CWI, Mexico;Department of Software Engineering, CWI, Amsterdam, Netherlands",10.1109/visual.1997.663898;10.1109/visual.1997.663912;10.1109/visual.1995.480817;10.1109/visual.1997.663897;10.1109/visual.1997.663898,"flow visualization, texture synthesis",64.0,10.0,15.0,75.0,,,vector field visualization;convolution lic texture;noise;synthesis techniques;mathematical concept,0.6661;0.4450;0.2383;0.1823;0.1021,"[np.int64(-1), -1, -1, -1, -1]",127;-1;-1;-1;-1,127,127,Field Visualization
InfoVis,2013,LineUp: Visual Analysis of Multi-Attribute Rankings,10.1109/tvcg.2013.173,http://dx.doi.org/10.1109/TVCG.2013.173,2277.0,2286.0,J,"Rankings are a popular and universal approach to structuring otherwise unorganized collections of items by computing a rank for each item based on the value of one or more of its attributes. This allows us, for example, to prioritize tasks or to evaluate the performance of products relative to each other. While the visualization of a ranking itself is straightforward, its interpretation is not, because the rank of an item represents only a summary of a potentially complicated relationship between its attributes and those of the other items. It is also common that alternative rankings exist which need to be compared and analyzed to gain insight into how multiple heterogeneous attributes affect the rankings. Advanced visual exploration tools are needed to make this process efficient. In this paper we present a comprehensive analysis of requirements for the visualization of multi-attribute rankings. Based on these considerations, we propose LineUp - a novel and scalable visualization technique that uses bar charts. This interactive technique supports the ranking of items based on multiple heterogeneous attributes with different scales and semantics. It enables users to interactively combine attributes and flexibly refine parameters to explore the effect of changes in the attribute combination. This process can be employed to derive actionable insights as to which attributes of an item need to be modified in order for its rank to change. Additionally, through integration of slope graphs, LineUp can also be used to compare multiple alternative rankings on the same set of items, for example, over time or across different attribute combinations. We evaluate the effectiveness of the proposed multi-attribute visualization technique in a qualitative study. The study shows that users are able to successfully solve complex ranking tasks in a short period of time.",Samuel Gratzl;Alexander Lex;Nils Gehlenborg;Hanspeter Pfister;Marc Streit,Samuel Gratzl;Alexander Lex;Nils Gehlenborg;Hanspeter Pfister;Marc Streit,"Johannes Kepler University of Linz, Austria;Johannes Kepler University of Linz, Austria;Harvard University, USA;Harvard University, USA;Harvard Medical School, USA",10.1109/tvcg.2012.253;10.1109/tvcg.2008.166;10.1109/visual.1996.568118;10.1109/tvcg.2008.181;10.1109/tvcg.2007.70539;10.1109/tvcg.2009.111,"Ranking visualization, ranking, scoring, multi-attribute, multifactorial, multi-faceted, stacked bar charts",329.0,219.0,35.0,2729.0,BP,,rankings advanced visual;structuring unorganized collections;qualitative study study;flexibly refine parameters;tools needed make,0.7460;0.2445;0.1338;0.1154;0.0254,"[np.int64(-1), -1, -1, -1, -1]",146;-1;-1;-1;-1,146,146,Visualization Techniques
InfoVis,2004,Matrix Zoom: A Visual Interface to Semi-External Graphs,10.1109/infvis.2004.46,http://dx.doi.org/10.1109/INFVIS.2004.46,183.0,190.0,C,"In Web data, telecommunications traffic and in epidemiological studies, dense subgraphs correspond to subsets of subjects (i.e. users, patients) that share a collection of attributes values (i.e. accessed Web pages, email-calling patterns or disease diagnostic profiles). Visual and computational identification of these ""clusters"" becomes useful when domain experts desire to determine those factors of major influence in the formation of access and communication clusters or in the detection and contention of disease spread. With the current increases in graphic hardware capabilities and RAM sizes, it is more useful to relate graph sizes to the available screen real estate S and the amount of available RAM M, instead of the number of edges or nodes in the graph. We offer a visual interface that is parameterized by M and S and is particularly suited for navigation tasks that require the identification of subgraphs whose edge density is above certain threshold. This is achieved by providing a zoomable matrix view of the underlying data. This view is strongly coupled to a hierarchical view of the essential information elements present in the data domain. We illustrate the applicability of this work to the visual navigation of cancer incidence data and to an aggregated sample of phone call traffic",James Abello;Frank van Ham,J. Abello;F. van Ham,"DIMACS, Rutgers University, Piscataway, NJ, USA;Department of Mathematics and Computer Science, Technische Universiteit Eindhoven, The Netherlands",10.1109/infvis.2003.1249030;10.1109/infvis.2003.1249030,"Graph Visualization, Hierarchy Trees, Clustering, External Memory Algorithms, Cancer Data, Phone Traffic",163.0,34.0,14.0,695.0,,,studies dense subgraphs;providing zoomable matrix;web data;visual navigation cancer;email calling,0.5263;0.3792;0.3498;0.3225;0.1046,"[np.int64(-1), -1, -1, -1, -1]",44;-1;-1;-1;-1,44,44,Graph Theory Analysis
InfoVis,2005,Visual correlation for situational awareness,10.1109/infvis.2005.1532134,http://dx.doi.org/10.1109/INFVIS.2005.1532134,95.0,102.0,C,"We present a novel visual correlation paradigm for situational awareness (SA) and suggest its usage in a diverse set of applications that require a high level of SA. Our approach is based on a concise and scalable representation, which leads to a flexible visualization tool that is both clear and intuitive to use. Situational awareness is the continuous extraction of environmental information, its integration with previous knowledge to form a coherent mental picture, and the use of that picture in anticipating future events. In this paper we build on our previous work on visualization for network intrusion detection and show how that approach can be generalized to encompass a much broader class of SA systems. We first propose a generalization that is based on what we term, the w/sup 3/ premise, namely that each event must have at least the what, when and where attributes. We also present a second generalization, which increases flexibility and facilitates complex visual correlations. Finally, we demonstrate the generality of our approaches by applying our visualization paradigm in a collection of diverse SA areas.",Yarden Livnat;James Agutter;Shaun Moon;Stefano Foresti,Y. Livnat;J. Agutter;Shaun Moon;S. Foresti,"Scientific Computing and Imaging Institute, University of Utah, USA;College of Architecture Planning, University of Utah, USA;College of Architecture Planning, University of Utah, USA;Center for High Performance Computing, University of Utah, USA",10.1109/visual.2003.1250415,"situation awareness, network intrusion, visualization",125.0,24.0,19.0,1025.0,,,visualization network intrusion;situational awareness continuous;environmental information integration;correlations finally demonstrate;build,0.5939;0.5237;0.3687;0.2436;0.0479,"[np.int64(-1), np.int64(-1), -1, -1, -1]",83;32;-1;-1;-1,32;83,83,Network Visualization
SciVis,2013,ConnectomeExplorer: Query-Guided Visual Analysis of Large Volumetric Neuroscience Data,10.1109/tvcg.2013.142,http://dx.doi.org/10.1109/TVCG.2013.142,2868.0,2877.0,J,"This paper presents ConnectomeExplorer, an application for the interactive exploration and query-guided visual analysis of large volumetric electron microscopy (EM) data sets in connectomics research. Our system incorporates a knowledge-based query algebra that supports the interactive specification of dynamically evaluated queries, which enable neuroscientists to pose and answer domain-specific questions in an intuitive manner. Queries are built step by step in a visual query builder, building more complex queries from combinations of simpler queries. Our application is based on a scalable volume visualization framework that scales to multiple volumes of several teravoxels each, enabling the concurrent visualization and querying of the original EM volume, additional segmentation volumes, neuronal connectivity, and additional meta data comprising a variety of neuronal data attributes. We evaluate our application on a data set of roughly one terabyte of EM data and 750 GB of segmentation data, containing over 4,000 segmented structures and 1,000 synapses. We demonstrate typical use-case scenarios of our collaborators in neuroscience, where our system has enabled them to answer specific scientific questions using interactive querying and analysis on the full-size data for the first time.",Johanna Beyer;Ali K. Al-Awami;Narayanan Kasthuri;Jeff W. Lichtman;Hanspeter Pfister;Markus Hadwiger,Johanna Beyer;Ali Al-Awami;Narayanan Kasthuri;Jeff W. Lichtman;Hanspeter Pfister;Markus Hadwiger,"King Abdullah University of Science and Technology, Saudi Arabia;King Abdullah University of Science and Technology, Saudi Arabia;Center for Brain Science, Harvard University, USA;Center for Brain Science, Harvard University, USA;School of Engineering and Applied Sciences, Harvard University, USA;King Abdullah University of Science and Technology, Saudi Arabia",10.1109/infvis.2000.885086;10.1109/visual.2005.1532792;10.1109/tvcg.2009.178;10.1109/tvcg.2012.240;10.1109/tvcg.2006.195;10.1109/visual.1995.485139;10.1109/tvcg.2007.70560;10.1109/tvcg.2009.118;10.1109/tvcg.2009.121,"Connectomics, neuroscience, query algebra, visual knowledge discovery, petascale volume analysis",78.0,57.0,45.0,986.0,,,queries enable neuroscientists;step visual;large volumetric electron;framework scales multiple;teravoxels enabling concurrent,0.6055;0.2403;0.2167;0.1647;0.1275,"[np.int64(-1), -1, -1, -1, -1]",13;-1;-1;-1;-1,13,13,Advanced Machine Learning
Vis,2009,A Visual Approach to Efficient Analysis and Quantification of Ductile Iron and Reinforced Sprayed Concrete,10.1109/tvcg.2009.115,http://dx.doi.org/10.1109/TVCG.2009.115,1343.0,1350.0,J,"This paper describes advanced volume visualization and quantification for applications in non-destructive testing (NDT), which results in novel and highly effective interactive workflows for NDT practitioners. We employ a visual approach to explore and quantify the features of interest, based on transfer functions in the parameter spaces of specific application scenarios. Examples are the orientations of fibres or the roundness of particles. The applicability and effectiveness of our approach is illustrated using two specific scenarios of high practical relevance. First, we discuss the analysis of Steel Fibre Reinforced Sprayed Concrete (SFRSpC). We investigate the orientations of the enclosed steel fibres and their distribution, depending on the concrete's application direction. This is a crucial step in assessing the material's behavior under mechanical stress, which is still in its infancy and therefore a hot topic in the building industry. The second application scenario is the designation of the microstructure of ductile cast irons with respect to the contained graphite. This corresponds to the requirements of the ISO standard 945-1, which deals with 2D metallographic samples. We illustrate how the necessary analysis steps can be carried out much more efficiently using our system for 3D volumes. Overall, we show that a visual approach with custom transfer functions in specific application domains offers significant benefits and has the potential of greatly improving and optimizing the workflows of domain scientists and engineers.",Laura Fritz;Markus Hadwiger;Georg Geier;Gerhard Pittino;M. Eduard Gröller,Laura Fritz;Markus Hadwiger;Georg Geier;Gerhard Pittino;M. Eduard Groller,"VRVis Research Center, Vienna, Austria;VRVis Research Center, Vienna, Austria;Austrian Foundry Research Institute, Leoben, Austria;Institute for Subsurface Engineering, University of Leoben, Austria;University of Technology, Vienna, Vienna, Austria",10.1109/tvcg.2008.147;10.1109/visual.2003.1250418;10.1109/tvcg.2008.162;10.1109/visual.2001.964519;10.1109/visual.2003.1250384;10.1109/tvcg.2007.70603;10.1109/tvcg.2008.147,"Non-Destructive Testing, Multi-Dimensional Transfer Functions, Direction Visualization, Volume Rendering",28.0,14.0,22.0,485.0,,,volume visualization quantification;destructive testing ndt;concrete application direction;steel fibres;transfer functions parameter,0.5896;0.3796;0.3755;0.3221;0.0775,"[np.int64(-1), -1, -1, -1, -1]",54;-1;-1;-1;-1,54,54,Volume Visualization Techniques
InfoVis,2012,Facilitating Discourse Analysis with Interactive Visualization,10.1109/tvcg.2012.226,http://dx.doi.org/10.1109/TVCG.2012.226,2639.0,2648.0,J,"A discourse parser is a natural language processing system which can represent the organization of a document based on a rhetorical structure tree-one of the key data structures enabling applications such as text summarization, question answering and dialogue generation. Computational linguistics researchers currently rely on manually exploring and comparing the discourse structures to get intuitions for improving parsing algorithms. In this paper, we present DAViewer, an interactive visualization system for assisting computational linguistics researchers to explore, compare, evaluate and annotate the results of discourse parsers. An iterative user-centered design process with domain experts was conducted in the development of DAViewer. We report the results of an informal formative study of the system to better understand how the proposed visualization and interaction techniques are used in the real research environment.",Jian Zhao 0010;Fanny Chevalier;Christopher Collins 0001;Ravin Balakrishnan,Jian Zhao;Fanny Chevalier;Christopher Collins;Ravin Balakrishnan,"University of Toronto, Canada;University of Toronto, Canada;University of Ontario Institute of Technology (UOIT), Canada;University of Toronto, Canada",10.1109/vast.2011.6102439;10.1109/tvcg.2007.70529;10.1109/tvcg.2009.122;10.1109/infvis.1999.801869;10.1109/infvis.2003.1249030;10.1109/vast.2011.6102439,"Discourse structure, tree comparison, computational linguisitics, visual analytics, interaction techniques",77.0,32.0,30.0,1447.0,,,discourse parser;daviewer interactive visualization;research environment;enabling applications text;proposed,0.7195;0.2872;0.1790;0.0870;0.0709,"[np.int64(-1), -1, -1, -1, -1]",28;-1;-1;-1;-1,28,28,Natural Language Processing
VAST,2007,Activity Analysis Using Spatio-Temporal Trajectory Volumes in Surveillance Applications,10.1109/vast.2007.4388990,http://dx.doi.org/10.1109/VAST.2007.4388990,3.0,10.0,C,"In this paper, we present a system to analyze activities and detect anomalies in a surveillance application, which exploits the intuition and experience of security and surveillance experts through an easy- to-use visual feedback loop. The multi-scale and location specific nature of behavior patterns in space and time is captured using a wavelet-based feature descriptor. The system learns the fundamental descriptions of the behavior patterns in a semi-supervised fashion by the higher order singular value decomposition of the space described by the training data. This training process is guided and refined by the users in an intuitive fashion. Anomalies are detected by projecting the test data into this multi-linear space and are visualized by the system to direct the attention of the user to potential problem spots. We tested our system on real-world surveillance data, and it satisfied the security concerns of the environment.",Firdaus Janoos;Shantanu Singh;M. Okan Irfanoglu;Raghu Machiraju;Richard E. Parent,Firdaus Janoos;Shantanu Singh;Okan Irfanoglu;Raghu Machiraju;Richard Parent,"Department of Computer Science and Engineering, Ohio State Uinversity, USA;Department of Computer Science and Engineering, Ohio State Uinversity, USA;Department of Computer Science and Engineering, Ohio State Uinversity, USA;Department of Computer Science and Engineering, Ohio State Uinversity, USA;Department of Computer Science and Engineering, Ohio State Uinversity, USA",10.1109/tvcg.2006.194;10.1109/tvcg.2006.194,"wavelets, HOSVD, surveillance, anomaly detection, trajectory",28.0,9.0,29.0,345.0,,,detect anomalies surveillance;feature descriptor learns;using wavelet;multi linear space;easy use,0.5928;0.3474;0.3467;0.2139;0.1154,"[np.int64(-1), -1, -1, -1, -1]",57;-1;-1;-1;-1,57,57,Anomaly Detection Techniques
VAST,2008,Visual mining of multimedia data for social and behavioral studies,10.1109/vast.2008.4677369,http://dx.doi.org/10.1109/VAST.2008.4677369,155.0,162.0,C,"With advances in computing techniques, a large amount of high-resolution high-quality multimedia data (video and audio, etc.) has been collected in research laboratories in various scientific disciplines, particularly in social and behavioral studies. How to automatically and effectively discover new knowledge from rich multimedia data poses a compelling challenge since state-of-the-art data mining techniques can most often only search and extract pre-defined patterns or knowledge from complex heterogeneous data. In light of this, our approach is to take advantages of both the power of human perception system and the power of computational algorithms. More specifically, we propose an approach that allows scientists to use data mining as a first pass, and then forms a closed loop of visual analysis of current results followed by more data mining work inspired by visualization, the results of which can be in turn visualized and lead to the next round of visual exploration and analysis. In this way, new insights and hypotheses gleaned from the raw data and the current level of analysis can contribute to further analysis. As a first step toward this goal, we implement a visualization system with three critical components: (1) A smooth interface between visualization and data mining. The new analysis results can be automatically loaded into our visualization tool. (2) A flexible tool to explore and query temporal data derived from raw multimedia data. We represent temporal data into two forms - continuous variables and event variables. We have developed various ways to visualize both temporal correlations and statistics of multiple variables with the same type, and conditional and high-order statistics between continuous and event variables. (3) A seamless interface between raw multimedia data and derived data. Our visualization tool allows users to explore, compare, and analyze multi-stream derived variables and simultaneously switch to access raw multimedia data. We demonstrate various functions in our visualization program using a set of multimedia data including video, audio and motion tracking data.",Chen Yu 0001;Yiwen Zhong;Thomas Smith 0003;Ikhyun Park;Weixia Huang,Chen Yu;Yiwen Zhong;Thomas Smith;Ikhyun Park;Weixia Huang,"Indiana University, USA;Indiana University, Fujian Agriculture and Forestry University, USA;Indiana University, USA;Indiana University, USA;Indiana University, USA",10.1109/infvis.2001.963273;10.1109/infvis.1999.801851;10.1109/infvis.2001.963273,"visual data mining, multimedia data",10.0,0.0,12.0,1219.0,,,visualization data mining;access raw multimedia;advantages power human;simultaneously;results automatically loaded,0.6850;0.2036;0.0877;0.0448;0.0357,"[np.int64(-1), -1, -1, -1, -1]",97;-1;-1;-1;-1,97,97,Data Visualization
InfoVis,2010,Perceptual Guidelines for Creating Rectangular Treemaps,10.1109/tvcg.2010.186,http://dx.doi.org/10.1109/TVCG.2010.186,990.0,998.0,J,"Treemaps are space-filling visualizations that make efficient use of limited display space to depict large amounts of hierarchical data. Creating perceptually effective treemaps requires carefully managing a number of design parameters including the aspect ratio and luminance of rectangles. Moreover, treemaps encode values using area, which has been found to be less accurate than judgments of other visual encodings, such as length. We conduct a series of controlled experiments aimed at producing a set of design guidelines for creating effective rectangular treemaps. We find no evidence that luminance affects area judgments, but observe that aspect ratio does have an effect. Specifically, we find that the accuracy of area comparisons suffers when the compared rectangles have extreme aspect ratios or when both are squares. Contrary to common assumptions, the optimal distribution of rectangle aspect ratios within a treemap should include non-squares, but should avoid extremes. We then compare treemaps with hierarchical bar chart displays to identify the data densities at which length-encoded bar charts become less effective than area-encoded treemaps. We report the transition points at which treemaps exhibit judgment accuracy on par with bar charts for both leaf and non-leaf tree nodes. We also find that even at relatively low data densities treemaps result in faster comparisons than bar charts. Based on these results, we present a set of guidelines for the effective use of treemaps and suggest alternate approaches for treemap layout.",Nicholas Kong;Jeffrey Heer;Maneesh Agrawala,Nicholas Kong;Jeffrey Heer;Maneesh Agrawala,"Computer Science Division, University of California Berkeley, Berkeley, CA, USA;Computer Science Department, University of Stanford, Stanford, CA, USA;Computer Science Division, University of California Berkeley, Berkeley, CA, USA",10.1109/infvis.2000.885091;10.1109/infvis.2005.1532145;10.1109/infvis.2004.70;10.1109/infvis.2005.1532144;10.1109/tvcg.2007.70583;10.1109/infvis.2001.963283;10.1109/infvis.2001.963290;10.1109/tvcg.2008.171;10.1109/infvis.1999.801860;10.1109/infvis.2002.1173153;10.1109/infvis.2000.885091,"Graphical Perception, Visualization, Treemaps, Rectangular Area, Visual Encoding, Experiment, Mechanical Turk",132.0,72.0,45.0,1209.0,HM,,perceptually effective treemaps;data densities length;ratios squares contrary;encoded bar;carefully managing number,0.6396;0.2563;0.1546;0.1502;0.1282,"[np.int64(-1), -1, -1, -1, -1]",56;-1;-1;-1;-1,56,56,Treemap Visualization
InfoVis,2009,Participatory Visualization with Wordle,10.1109/tvcg.2009.171,http://dx.doi.org/10.1109/TVCG.2009.171,1137.0,1144.0,J,"We discuss the design and usage of ldquoWordle,rdquo a Web-based tool for visualizing text. Wordle creates tag-cloud-like displays that give careful attention to typography, color, and composition. We describe the algorithms used to balance various aesthetic criteria and create the distinctive Wordle layouts. We then present the results of a study of Wordle usage, based both on spontaneous behaviour observed in the wild, and on a large-scale survey of Wordle users. The results suggest that Wordles have become a kind of medium of expression, and that a ldquoparticipatory culturerdquo has arisen around them.",Fernanda B. Viégas;Martin Wattenberg;Jonathan Feinberg,Fernanda B. Viegas;Martin Wattenberg;Jonathan Feinberg,"IBM Research, USA;IBM Research, USA;IBM Research, USA",10.1109/infvis.2005.1532122;10.1109/tvcg.2007.70577,"Visualization, text, tag cloud, participatory culture, memory, educational visualization, social data analysis",534.0,263.0,15.0,3675.0,,,visualizing text wordle;tag cloud;various aesthetic criteria;culturerdquo;algorithms used balance,0.6544;0.5103;0.3099;0.2951;0.0877,"[np.int64(-1), np.int64(-1), -1, -1, -1]",91;37;-1;-1;-1,37;91,91,Wordle Visualizations
Vis,2006,Scalable Data Servers for Large Multivariate Volume Visualization,10.1109/tvcg.2006.175,http://dx.doi.org/10.1109/TVCG.2006.175,1291.0,1298.0,J,"Volumetric datasets with multiple variables on each voxel over multiple time steps are often complex, especially when considering the exponentially large attribute space formed by the variables in combination with the spatial and temporal dimensions. It is intuitive, practical, and thus often desirable, to interactively select a subset of the data from within that high-dimensional value space for efficient visualization. This approach is straightforward to implement if the dataset is small enough to be stored entirely in-core. However, to handle datasets sized at hundreds of gigabytes and beyond, this simplistic approach becomes infeasible and thus, more sophisticated solutions are needed. In this work, we developed a system that supports efficient visualization of an arbitrary subset, selected by range-queries, of a large multivariate time-varying dataset. By employing specialized data structures and schemes of data distribution, our system can leverage a large number of networked computers as parallel data servers, and guarantees a near optimal load-balance. We demonstrate our system of scalable data servers using two large time-varying simulation datasets",Markus Glatter;Jian Huang 0007;Jinzhu Gao;Colin Mollenhour,Markus Glatter;Jian Huang;Jinzhu Gao;Colin Mollenhour,"University of Tennessee, USA;University of Tennessee, USA;University of Tennessee, USA;Oak Ridge National Laboratory, USA",10.1109/visual.2005.1532792;10.1109/visual.2005.1532794;10.1109/visual.1999.809910;10.1109/visual.1996.568121;10.1109/visual.2003.1250412;10.1109/visual.2001.964519;10.1109/visual.1998.745311;10.1109/visual.2000.885698,"Parallel and distributed volume visualization, large Data Set Visualization, multi-variate Visualization, volume Visualization",35.0,17.0,25.0,252.0,,,volumetric datasets;networked computers parallel;arbitrary subset selected;especially considering;time steps complex,0.6084;0.2580;0.1691;0.1431;0.0936,"[np.int64(-1), -1, -1, -1, -1]",111;-1;-1;-1;-1,111,111,3D Data Processing
Vis,1998,Fast and memory efficient polygonal simplification,10.1109/visual.1998.745314,http://dx.doi.org/10.1109/VISUAL.1998.745314,279.0,286.0,C,"Conventional wisdom says that in order to produce high-quality simplified polygonal models, one must retain and use information about the original model during the simplification process. We demonstrate that excellent simplified models can be produced without the need to compare against information from the original geometry while performing local changes to the model. We use edge collapses to perform simplification, as do a number of other methods. We select the position of the new vertex so that the original volume of the model is maintained and we minimize the per-triangle change in volume of the tetrahedra swept out by those triangles that are moved. We also maintain surface area near boundaries and minimize the per-triangle area changes. Calculating the edge collapse priorities and the positions of the new vertices requires only the face connectivity and the the vertex locations in the intermediate model. This approach is memory efficient, allowing the simplification of very large polygonal models, and it is also fast. Moreover, simplified models created using this technique compare favorably to a number of other published simplification methods in terms of mean geometric error.",Peter Lindstrom 0001;Greg Turk,P. Lindstrom;G. Turk,"Georgia Institute of Technology, USA;Georgia Institute of Technology, USA",10.1109/visual.1995.485142;10.1109/visual.1997.663883;10.1109/visual.1997.663908;10.1109/visual.1997.663906;10.1109/visual.1995.485142,,533.0,106.0,22.0,425.0,,,simplified polygonal models;edge collapse priorities;simplification large;performing local changes;conventional wisdom says,0.7173;0.4181;0.3222;0.1602;-0.0311,"[np.int64(-1), -1, -1, -1, -1]",126;-1;-1;-1;-1,126,126,Geometric Mesh Processing
SciVis,2014,Combined Visualization of Wall Thickness and Wall Shear Stress for the Evaluation of Aneurysms,10.1109/tvcg.2014.2346406,http://dx.doi.org/10.1109/TVCG.2014.2346406,2506.0,2515.0,J,"For an individual rupture risk assessment of aneurysms, the aneurysm's wall morphology and hemodynamics provide valuable information. Hemodynamic information is usually extracted via computational fluid dynamic (CFD) simulation on a previously extracted 3D aneurysm surface mesh or directly measured with 4D phase-contrast magnetic resonance imaging. In contrast, a noninvasive imaging technique that depicts the aneurysm wall in vivo is still not available. Our approach comprises an experiment, where intravascular ultrasound (IVUS) is employed to probe a dissected saccular aneurysm phantom, which we modeled from a porcine kidney artery. Then, we extracted a 3D surface mesh to gain the vessel wall thickness and hemodynamic information from a CFD simulation. Building on this, we developed a framework that depicts the inner and outer aneurysm wall with dedicated information about local thickness via distance ribbons. For both walls, a shading is adapted such that the inner wall as well as its distance to the outer wall is always perceivable. The exploration of the wall is further improved by combining it with hemodynamic information from the CFD simulation. Hence, the visual analysis comprises a brushing and linking concept for individual highlighting of pathologic areas. Also, a surface clustering is integrated to provide an automatic division of different aneurysm parts combined with a risk score depending on wall thickness and hemodynamic information. In general, our approach can be employed for vessel visualization purposes where an inner and outer wall has to be adequately represented.",Sylvia Glaßer;Kai Lawonn;Thomas Hoffmann 0002;Martin Skalej;Bernhard Preim,Sylvia Glaßer;Kai Lawonn;Thomas Hoffmann;Martin Skalej;Bernhard Preim,"Department for Simulation and Graphics, Otto von Guericke Universitat Magdeburg, Magdeburg, Sachsen-Anhalt, DE;Department for Simulation and Graphics, University of Magdeburg, Germany;Neuroradiology Department, University hospital of Magdeburg, Germany;Neuroradiology Department, University hospital of Magdeburg, Germany;Department for Simulation and Graphics, University of Magdeburg, Germany",10.1109/tvcg.2012.202;10.1109/tvcg.2007.70550;10.1109/visual.1995.480795;10.1109/tvcg.2011.189;10.1109/tvcg.2012.202,"Aneurysm, IVUS, Wall Thickness, Wall Shear Stress, Brushing and Linking, Focus + Context",27.0,24.0,43.0,718.0,,,3d aneurysm surface;fluid dynamic cfd;porcine kidney;contrast;clustering integrated provide,0.6912;0.2681;0.1721;0.1436;0.0818,"[np.int64(-1), -1, -1, -1, -1]",38;-1;-1;-1;-1,38,38,3D Medical Visualization
Vis,2003,Planet-sized batched dynamic adaptive meshes (P-BDAM),10.1109/visual.2003.1250366,http://dx.doi.org/10.1109/VISUAL.2003.1250366,147.0,154.0,C,"We describe an efficient technique for out-of-core management and interactive rendering of planet sized textured terrain surfaces. The technique, called planet-sized batched dynamic adaptive meshes (P-BDAM), extends the BDAM approach by using as basic primitive a general triangulation of points on a displaced triangle. The proposed framework introduces several advances with respect to the state of the art: thanks to a batched host-to-graphics communication model, we outperform current adaptive tessellation solutions in terms of rendering speed; we guarantee overall geometric continuity, exploiting programmable graphics hardware to cope with the accuracy issues introduced by single precision floating points; we exploit a compressed out of core representation and speculative prefetching for hiding disk latency during rendering of out-of-core data; we efficiently construct high quality simplified representations with a novel distributed out of core simplification algorithm working on a standard PC network.",Paolo Cignoni;Fabio Ganovelli;Enrico Gobbetti;Fabio Marton;Federico Ponchio;Roberto Scopigno,P. Cignoni;F. Ganovelli;E. Gobbetti;F. Marton;F. Ponchio;R. Scopigno,"ISTI-CNR, Pisa, Italy;ISTI-CNR, Italy;CRS4, Pula, Italy;CRS4, Italy;ISTI-CNR, Italy;ISTI-CNR, Italy",10.1109/visual.1997.663860;10.1109/visual.2002.1183783;10.1109/visual.1997.663902;10.1109/visual.1998.745282;10.1109/visual.2000.885699;10.1109/visual.2002.1183800;10.1109/visual.1996.567600;10.1109/visual.1998.745280;10.1109/visual.1999.809902;10.1109/visual.1996.568126;10.1109/visual.1997.663860," Multiresolution, terrains, huge dataset",222.0,46.0,33.0,181.0,,,adaptive tessellation;rendering core;hiding disk latency;single precision floating;host,0.5534;0.3863;0.1724;0.1695;0.1626,"[np.int64(-1), -1, -1, -1, -1]",78;-1;-1;-1;-1,78,78,Mesh Refinement Techniques
Vis,2024,StyleRF-VolVis: Style Transfer of Neural Radiance Fields for Expressive Volume Visualization,10.1109/tvcg.2024.3456342,http://dx.doi.org/10.1109/TVCG.2024.3456342,613.0,623.0,J,"In volume visualization, visualization synthesis has attracted much attention due to its ability to generate novel visualizations without following the conventional rendering pipeline. However, existing solutions based on generative adversarial networks often require many training images and take significant training time. Still, issues such as low quality, consistency, and flexibility persist. This paper introduces StyleRF-VolVis, an innovative style transfer framework for expressive volume visualization (VolVis) via neural radiance field (NeRF). The expressiveness of StyleRF-VolVis is upheld by its ability to accurately separate the underlying scene geometry (i.e., content) and color appearance (i.e., style), conveniently modify color, opacity, and lighting of the original rendering while maintaining visual content consistency across the views, and effectively transfer arbitrary styles from reference images to the reconstructed 3D scene. To achieve these, we design a base NeRF model for scene geometry extraction, a palette color network to classify regions of the radiance field for photorealistic editing, and an unrestricted color network to lift the color palette constraint via knowledge distillation for non-photorealistic editing. We demonstrate the superior quality, consistency, and flexibility of StyleRF-VolVis by experimenting with various volume rendering scenes and reference images and comparing StyleRF-VolVis against other image-based (AdaIN), video-based (ReReVST), and NeRF-based (ARF and SNeRF) style rendering solutions.",Kaiyuan Tang;Chaoli Wang 0001,Kaiyuan Tang;Chaoli Wang,"Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, USA;Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, USA",10.1109/tvcg.2019.2934255;10.1109/tvcg.2021.3114815;10.1109/tvcg.2020.3030346;10.1109/tvcg.2019.2934312;10.1109/tvcg.2022.3209413;10.1109/tvcg.2023.3327194,"Style transfer,neural radiance field,,,knowledge distillation,volume visualization",,0.0,62.0,225.0,,,volume rendering scenes;palette color network;comparing stylerf;ability generate novel;time issues low,0.6243;0.4366;0.2263;0.1756;-0.0887,"[np.int64(-1), -1, -1, -1, -1]",52;-1;-1;-1;-1,52,52,Volume Rendering Techniques
Vis,2008,Hypothesis Generation in Climate Research with Interactive Visual Data Exploration,10.1109/tvcg.2008.139,http://dx.doi.org/10.1109/TVCG.2008.139,1579.0,1586.0,J,"One of the most prominent topics in climate research is the investigation, detection, and allocation of climate change. In this paper, we aim at identifying regions in the atmosphere (e.g., certain height layers) which can act as sensitive and robust indicators for climate change. We demonstrate how interactive visual data exploration of large amounts of multi-variate and time-dependent climate data enables the steered generation of promising hypotheses for subsequent statistical evaluation. The use of new visualization and interaction technology-in the context of a coordinated multiple views framework-allows not only to identify these promising hypotheses, but also to efficiently narrow down parameters that are required in the process of computational data analysis. Two datasets, namely an ECHAM5 climate model run and the ERA-40 reanalysis incorporating observational data, are investigated. Higher-order information such as linear trends or signal-to-noise ratio is derived and interactively explored in order to detect and explore those regions which react most sensitively to climate change. As one conclusion from this study, we identify an excellent potential for usefully generalizing our approach to other, similar application cases, as well.",Johannes Kehrer;Florian Ladstädter;Philipp Muigg;Helmut Doleisch;Andrea K. Steiner;Helwig Hauser,Johannes Kehrer;Florian Ladstädter;Philipp Muigg;Helmut Doleisch;Andrea Steiner;Helwig Hauser,"Department of Informatics, University of Bergen, Norway;Wegener Center for Climate and Global Change (WegCenter) and the Institute for Geophysics, Astrophysics,  and Meteorology (IGAM), University of Graz, Austria;VRVis Research Center, SimVis GmbH, Vienna, Austria;VRVis Research Center, SimVis GmbH, Vienna, Austria;Wegener Center for Climate and Global Change (WegCenter) and the Institute for Geophysics, Astrophysics,  and Meteorology (IGAM), University of Graz, Austria;Department of Informatics, University of Bergen, Norway",10.1109/infvis.2005.1532138;10.1109/visual.1994.346302;10.1109/visual.2005.1532850;10.1109/tvcg.2006.170;10.1109/infvis.2005.1532138,"Interactive visual hypothesis generation, interactive visual exploration and analysis, visualization for climate research",85.0,44.0,29.0,762.0,,,climate data enables;identify promising hypotheses;coordinated multiple views;sensitively;variate time,0.5995;0.3176;0.2248;0.0667;0.0582,"[np.int64(-1), -1, -1, -1, -1]",12;-1;-1;-1;-1,12,12,Climate Modeling
VAST,2018,RetainVis: Visual Analytics with Interpretable and Interactive Recurrent Neural Networks on Electronic Medical Records,10.1109/tvcg.2018.2865027,http://dx.doi.org/10.1109/TVCG.2018.2865027,299.0,309.0,J,"We have recently seen many successful applications of recurrent neural networks (RNNs) on electronic medical records (EMRs), which contain histories of patients' diagnoses, medications, and other various events, in order to predict the current and future states of patients. Despite the strong performance of RNNs, it is often challenging for users to understand why the model makes a particular prediction. Such black-box nature of RNNs can impede its wide adoption in clinical practice. Furthermore, we have no established methods to interactively leverage users' domain expertise and prior knowledge as inputs for steering the model. Therefore, our design study aims to provide a visual analytics solution to increase interpretability and interactivity of RNNs via a joint effort of medical experts, artificial intelligence scientists, and visual analytics researchers. Following the iterative design process between the experts, we design, implement, and evaluate a visual analytics tool called RetainVis, which couples a newly improved, interpretable, and interactive RNN-based model called RetainEX and visualizations for users' exploration of EMR data in the context of prediction tasks. Our study shows the effective use of RetainVis for gaining insights into how individual medical codes contribute to making risk predictions, using EMRs of patients with heart failure and cataract symptoms. Our study also demonstrates how we made substantial changes to the state-of-the-art RNN model called RETAIN in order to make use of temporal information and increase interactivity. This study will provide a useful guideline for researchers that aim to design an interpretable and interactive visual analytics tool for RNNs.",Bum Chul Kwon;Min-Je Choi;Joanne Taery Kim;Edward Choi;Young Bin Kim;Soonwook Kwon;Jimeng Sun 0001;Jaegul Choo,Bum Chul Kwon;Min-Je Choi;Joanne Taery Kim;Edward Choi;Young Bin Kim;Soonwook Kwon;Jimeng Sun;Jaegul Choo,"IBM T.J. Watson Research Center, Korea University;Korea University, Seongbuk-gu, Seoul, KR;Korea University, Seongbuk-gu, Seoul, KR;Georgia Institute of Technology, Atlanta, GA, US;Chung-Ang University, Seoul, Seoul, KR;Catholic University of Daegu, Gyeongsan, Gyeongsangbuk-do, KR;Georgia Institute of Technology, Atlanta, GA, US;Korea University, Seongbuk-gu, Seoul, KR",10.1109/tvcg.2013.212;10.1109/tvcg.2017.2745080;10.1109/tvcg.2012.277;10.1109/tvcg.2017.2744718;10.1109/tvcg.2017.2745085;10.1109/tvcg.2016.2598446;10.1109/tvcg.2015.2467555;10.1109/tvcg.2016.2598831;10.1109/vast.2017.8585721;10.1109/tvcg.2017.2744358;10.1109/tvcg.2016.2598838;10.1109/tvcg.2012.213;10.1109/tvcg.2017.2744158;10.1109/tvcg.2017.2744878;10.1109/tvcg.2015.2467591;10.1109/tvcg.2013.212,"Interactive Artificial Intelligence,XAI (Explainable Artificial Intelligence),Interpretable Deep Learning,Healthcare",224.0,187.0,85.0,4417.0,,,rnns electronic medical;interactive visual analytics;risk predictions using;understand;failure cataract symptoms,0.5265;0.4768;0.3812;0.2063;0.1518,"[np.int64(-1), np.int64(-1), -1, -1, -1]",18;108;-1;-1;-1,18;108,18,Respiratory Data Analysis
Vis,2003,A frequency-sensitive point hierarchy for images and volumes,10.1109/visual.2003.1250403,http://dx.doi.org/10.1109/VISUAL.2003.1250403,425.0,432.0,C,"This paper introduces a method for converting an image or volume sampled on a regular grid into a space-efficient irregular point hierarchy. The conversion process retains the original frequency characteristics of the dataset by matching the spatial distribution of sample points with the required frequency. To achieve good blending, the spherical points commonly used in volume rendering are generalized to ellipsoidal point primitives. A family of multiresolution, oriented Gabor wavelets provide the frequency-space analysis of the dataset. The outcome of this frequency analysis is the reduced set of points, in which the sampling rate is decreased in originally oversampled areas. During rendering, the traversal of the hierarchy can be controlled by any suitable error metric or quality criteria. The local level of refinement is also sensitive to the transfer function. Areas with density ranges mapped to high transfer function variability are rendered at higher point resolution than others. Our decomposition is flexible and can be used for iso-surface rendering, alpha compositing and X-ray rendering of volumes. We demonstrate our hierarchy with an interactive splatting volume renderer, in which the traversal of the point hierarchy for rendering is modulated by a user-specified frame rate.",Tomihisa Welsh;Klaus Mueller 0001,T. Welsh;K. Mueller,"Center for Visual Computing, Computer Science, Stony Brook University, USA;Center for Visual Computing, Computer Science, Stony Brook University, USA",10.1109/visual.2002.1183770;10.1109/visual.2001.964498;10.1109/visual.2002.1183776;10.1109/visual.2001.964492;10.1109/visual.2001.964491;10.1109/visual.2002.1183757;10.1109/visual.2001.964490;10.1109/visual.2002.1183770,"volume rendering, point-based rendering, splatting",26.0,3.0,32.0,96.0,,,volume rendering generalized;oriented gabor wavelets;points required frequency;primitives family;transfer,0.6428;0.3700;0.1926;0.0610;0.0262,"[np.int64(-1), -1, -1, -1, -1]",52;-1;-1;-1;-1,52,52,Volume Rendering Techniques
Vis,1996,Octree-based decimation of marching cubes surfaces,10.1109/visual.1996.568127,http://dx.doi.org/10.1109/VISUAL.1996.568127,335.0,342.0,C,"The marching cubes (MC) algorithm is a method for generating isosurfaces. It also generates an excessively large number of triangles to represent an isosurface; this increases the rendering time. This paper presents a decimation method to reduce the number of triangles generated. Decimation is carried out before creating a large number of triangles. Four major steps comprise the algorithm: surface tracking, merging, crack patching and triangulation. Surface tracking is an enhanced implementation of the MC algorithm. Starting from a seed point, the surface tracker visits only those cells likely to compose part of the desired isosurface. The cells making up the extracted surface are stored in an octree that is further processed. A bottom-up approach is taken in merging the cells containing a relatively flat approximating surface. The finer surface details are maintained. Cells are merged as long as the error due to such an operation is within a user-specified error parameter, or a cell acquires more than one connected surface component in it. A crack patching method is described that forces edges of smaller cells to lie along those of the larger neighboring cells. The overall saving in the number of triangles depends both on the specified error value and the nature of the data. Use of the hierarchical octree data structure also presents the potential of incremental representation of surfaces. We can generate a highly smoothed surface representation which can be progressively refined as the user-specified error value is decreased.",Raj Shekhar;Elias Fayyad;Roni Yagel;J. Fredrick Cornhill,R. Shekhar;E. Fayyad;R. Yagel;J.F. Cornhill,"Department of Biomedical Engineering, Cleveland Clinic Foundation, USA;Biomedical Engineering Center, USA;Department of Computer and Information Science, Ohio State Uinversity, USA;Department of Biomedical Engineering, Cleveland Clinic Foundation, USA",10.1109/visual.1994.346308;10.1109/visual.1994.346308,,333.0,74.0,7.0,669.0,,,marching cubes;surface component crack;use hierarchical;error parameter;relatively,0.5944;0.2573;0.1288;0.0064;-0.0037,"[np.int64(-1), -1, -1, -1, -1]",74;-1;-1;-1;-1,74,74,3D Surface Extraction
InfoVis,2011,Synthetic Generation of High-Dimensional Datasets,10.1109/tvcg.2011.237,http://dx.doi.org/10.1109/TVCG.2011.237,2317.0,2324.0,J,"Generation of synthetic datasets is a common practice in many research areas. Such data is often generated to meet specific needs or certain conditions that may not be easily found in the original, real data. The nature of the data varies according to the application area and includes text, graphs, social or weather data, among many others. The common process to create such synthetic datasets is to implement small scripts or programs, restricted to small problems or to a specific application. In this paper we propose a framework designed to generate high dimensional datasets. Users can interactively create and navigate through multi dimensional datasets using a suitable graphical user-interface. The data creation is driven by statistical distributions based on a few user-defined parameters. First, a grounding dataset is created according to given inputs, and then structures and trends are included in selected dimensions and orthogonal projection planes. Furthermore, our framework supports the creation of complex non-orthogonal trends and classified datasets. It can successfully be used to create synthetic datasets simulating important trends as multidimensional clusters, correlations and outliers.",Georgia Albuquerque;Thomas Löwe;Marcus A. Magnor,Georgia Albuquerque;Thomas Lowe;Marcus Magnor,"Computer Graphics Laboratory, TU Braunschweig, Germany;Computer Graphics Laboratory, TU Braunschweig, Germany;Computer Graphics Laboratory, TU Braunschweig, Germany",10.1109/infvis.2005.1532142;10.1109/visual.1994.346302;10.1109/vast.2010.5652433;10.1109/vast.2009.5332628;10.1109/infvis.2004.15;10.1109/tvcg.2008.153;10.1109/infvis.2005.1532142,"Synthetic data generation, multivariate data, high-dimensional data, interaction",71.0,35.0,20.0,2028.0,,,create synthetic datasets;multidimensional clusters correlations;trends;scripts programs restricted;navigate multi,0.7025;0.4607;0.2526;0.0753;0.0509,"[np.int64(-1), -1, -1, -1, -1]",5;-1;-1;-1;-1,5,5,Synthetic Time Series
Vis,2022,D-BIAS: A Causality-Based Human-in-the-Loop System for Tackling Algorithmic Bias,10.1109/tvcg.2022.3209484,http://dx.doi.org/10.1109/TVCG.2022.3209484,473.0,482.0,J,"With the rise of AI, algorithms have become better at learning underlying patterns from the training data including ingrained social biases based on gender, race, etc. Deployment of such algorithms to domains such as hiring, healthcare, law enforcement, etc. has raised serious concerns about fairness, accountability, trust and interpretability in machine learning algorithms. To alleviate this problem, we propose D-BIAS, a visual interactive tool that embodies human-in-the-loop AI approach for auditing and mitigating social biases from tabular datasets. It uses a graphical causal model to represent causal relationships among different features in the dataset and as a medium to inject domain knowledge. A user can detect the presence of bias against a group, say females, or a subgroup, say black females, by identifying unfair causal relationships in the causal network and using an array of fairness metrics. Thereafter, the user can mitigate bias by refining the causal model and acting on the unfair causal edges. For each interaction, say weakening/deleting a biased causal edge, the system uses a novel method to simulate a new (debiased) dataset based on the current causal model while ensuring a minimal change from the original dataset. Users can visually assess the impact of their interactions on different fairness metrics, utility metrics, data distortion, and the underlying data distribution. Once satisfied, they can download the debiased dataset and use it for any downstream application for fairer predictions. We evaluate D-BIAS by conducting experiments on 3 datasets and also a formal user study. We found that D-BIAS helps reduce bias significantly compared to the baseline debiasing approach across different fairness metrics while incurring little data distortion and a small loss in utility. Moreover, our human-in-the-loop based approach significantly outperforms an automated approach on trust, interpretability and accountability.",Bhavya Ghai;Klaus Mueller 0001,Bhavya Ghai;Klaus Mueller,"Computer Science department, Stony Brook University, USA;Computer Science department, Stony Brook University, USA",10.1109/tvcg.2019.2934262;10.1109/vast.2017.8585647;10.1109/tvcg.2021.3114850;10.1109/tvcg.2020.3028957;10.1109/vast47406.2019.8986948;10.1109/tvcg.2019.2934262,"Algorithmic Fairness,Causality,Debiasing,Human-in-the-loop,Visual Analytics",,18.0,50.0,1276.0,,,mitigating social biases;interpretability machine learning;original dataset;domains hiring;uses graphical,0.6165;0.4703;0.2379;0.1238;0.1083,"[np.int64(-1), -1, -1, -1, -1]",25;-1;-1;-1;-1,25,25,Data Interpretation Challenges
InfoVis,2009,Conjunctive Visual Forms,10.1109/tvcg.2009.129,http://dx.doi.org/10.1109/TVCG.2009.129,929.0,936.0,J,"Visual exploration of multidimensional data is a process of isolating and extracting relationships within and between dimensions. Coordinated multiple view approaches are particularly effective for visual exploration because they support precise expression of heterogeneous multidimensional queries using simple interactions. Recent visual analytics research has made significant progress in identifying and understanding patterns of composed views and coordinations that support fast, flexible, and open-ended data exploration. What is missing is formalization of the space of expressible queries in terms of visual representation and interaction. This paper introduces the conjunctive visual form model in which visual exploration consists of interactively-driven sequences of transitions between visual states that correspond to conjunctive normal forms in boolean logic. The model predicts several new and useful ways to extend the space of rapidly expressible queries through addition of simple interactive capabilities to existing compositional patterns. Two recent related visual tools offer a subset of these capabilities, providing a basis for conjecturing about such extensions.",Chris E. Weaver,Chris Weaver,"School of Computer Science and the Center Spatial Analysis, University of Oklahama, USA",10.1109/vast.2006.261427;10.1109/infvis.2001.963287;10.1109/infvis.2003.1249024;10.1109/tvcg.2007.70577;10.1109/visual.1995.485139;10.1109/tvcg.2007.70594;10.1109/infvis.1996.559216;10.1109/vast.2007.4389006;10.1109/vast.2008.4677370;10.1109/tvcg.2008.153;10.1109/vast.2006.261427,"Boolean query, brushing, conjunctive normal form, exploratory visualization, multiple views, visual abstraction",18.0,8.0,26.0,482.0,,,visual analytics;composed views coordinations;states correspond conjunctive;flexible open;driven sequences,0.6645;0.4438;0.3214;0.1365;0.1184,"[np.int64(-1), -1, -1, -1, -1]",108;-1;-1;-1;-1,108,108,Visual Analytics
Vis,2002,TetFusion: an algorithm for rapid tetrahedral mesh simplification,10.1109/visual.2002.1183767,http://dx.doi.org/10.1109/VISUAL.2002.1183767,133.0,140.0,C,"This paper introduces an algorithm for rapid progressive simplification of tetrahedral meshes: TetFusion. We describe how a simple geometry decimation operation steers a rapid and controlled progressive simplification of tetrahedral meshes, while also taking care of complex mesh-inconsistency problems. The algorithm features a high decimation ratio per step, and inherently discourages any cases of self-intersection of boundary, element-boundary intersection at concave boundary-regions, and negative volume tetrahedra (flipping). We achieved rigorous reduction ratios of up to 98% for meshes consisting of 827,904 elements in less than 2 minutes, progressing through a series of level-of-details (LoDs) of the mesh in a controlled manner. We describe how the approach supports a balanced re-distribution of space between tetrahedral elements, and explain some useful control parameters that make it faster and more intuitive than 'edge collapse'-based decimation methods for volumetric meshes. Finally, we discuss how this approach can be employed for rapid LoD prototyping of large time-varying datasets as an aid to interactive visualization.",Prashant Chopra;Joerg Meyer 0003,P. Chopra;J. Meyer,"Engineering Research Center, Mississippi State University, MS, USA;Engineering Research Center, Mississippi State University, MS, USA",10.1109/visual.1998.745329;10.1109/visual.1997.663883;10.1109/visual.1999.809868;10.1109/visual.2000.885680;10.1109/visual.1998.745315;10.1109/visual.1999.809901;10.1109/visual.1998.745329,"mesh simplification, multi resolution, level-of-detail, unstructured meshes",72.0,18.0,23.0,283.0,,,simplification tetrahedral meshes;lod prototyping;decimation ratio;time varying datasets;inherently discourages cases,0.7264;0.2805;0.2031;0.1673;-0.0195,"[np.int64(-1), -1, -1, -1, -1]",79;-1;-1;-1;-1,79,79,Mesh Simplification Techniques
SciVis,2012,KnotPad: Visualizing and Exploring Knot Theory with Fluid Reidemeister Moves,10.1109/tvcg.2012.242,http://dx.doi.org/10.1109/TVCG.2012.242,2051.0,2060.0,J,"We present KnotPad, an interactive paper-like system for visualizing and exploring mathematical knots; we exploit topological drawing and math-aware deformation methods in particular to enable and enrich our interactions with knot diagrams. Whereas most previous efforts typically employ physically based modeling to simulate the 3D dynamics of knots and ropes, our tool offers a Reidemeister move based interactive environment that is much closer to the topological problems being solved in knot theory, yet without interfering with the traditional advantages of paper-based analysis and manipulation of knot diagrams. Drawing knot diagrams with many crossings and producing their equivalent is quite challenging and error-prone. KnotPad can restrict user manipulations to the three types of Reidemeister moves, resulting in a more fluid yet mathematically correct user experience with knots. For our principal test case of mathematical knots, KnotPad permits us to draw and edit their diagrams empowered by a family of interactive techniques. Furthermore, we exploit supplementary interface elements to enrich the user experiences. For example, KnotPad allows one to pull and drag on knot diagrams to produce mathematically valid moves. Navigation enhancements in KnotPad provide still further improvement: by remembering and displaying the sequence of valid moves applied during the entire interaction, KnotPad allows a much cleaner exploratory interface for the user to analyze and study knot equivalence. All these methods combine to reveal the complex spatial relationships of knot diagrams with a mathematically true and rich user experience.",Hui Zhang 0006;Jianguang Weng;Lin Jing;Yiwen Zhong,Hui Zhang;Jianguang Weng;Lin Jing;Yiwen Zhong,"Pervasive Technology Institute, Indiana University, USA;Zhejiang University of Media and Communications, China;Fujian Agriculture and Forestry University, China;Fujian Agriculture and Forestry University, China",10.1109/visual.2005.1532804;10.1109/visual.2005.1532843;10.1109/tvcg.2007.70593,"Knot Theory, Math Visualization",12.0,10.0,33.0,620.0,,,exploring mathematical knots;interactive paper like;3d;displaying sequence;allows cleaner,0.7388;0.4007;0.2401;0.0903;0.0710,"[np.int64(-1), -1, -1, -1, -1]",142;-1;-1;-1;-1,142,142,Mathematical Art
Vis,2021,VizLinter: A Linter and Fixer Framework for Data Visualization,10.1109/tvcg.2021.3114804,http://dx.doi.org/10.1109/TVCG.2021.3114804,206.0,216.0,J,"Despite the rising popularity of automated visualization tools, existing systems tend to provide direct results which do not always fit the input data or meet visualization requirements. Therefore, additional specification adjustments are still required in real-world use cases. However, manual adjustments are difficult since most users do not necessarily possess adequate skills or visualization knowledge. Even experienced users might create imperfect visualizations that involve chart construction errors. We present a framework, VizLinter, to help users detect flaws and rectify already-built but defective visualizations. The framework consists of two components, (1) a visualization linter, which applies well-recognized principles to inspect the legitimacy of rendered visualizations, and (2) a visualization fixer, which automatically corrects the detected violations according to the linter. We implement the framework into an online editor prototype based on Vega-Lite specifications. To further evaluate the system, we conduct an in-lab user study. The results prove its effectiveness and efficiency in identifying and fixing errors for data visualizations.",Qing Chen 0001;Fuling Sun;Xinyue Xu;Zui Chen;Jiazhe Wang;Nan Cao 0001,Qing Chen;Fuling Sun;Xinyue Xu;Zui Chen;Jiazhe Wang;Nan Cao,"Intelligent Big Data Visualization Lab at Tongji University, China;Intelligent Big Data Visualization Lab at Tongji University, China;Intelligent Big Data Visualization Lab at Tongji University, China;Intelligent Big Data Visualization Lab at Tongji University, China;Ant Group, China;Intelligent Big Data Visualization Lab at Tongji University, China",10.1109/tvcg.2008.166;10.1109/tvcg.2006.138;10.1109/tvcg.2006.163;10.1109/tvcg.2013.126;10.1109/tvcg.2012.219;10.1109/tvcg.2018.2865240;10.1109/tvcg.2017.2744198;10.1109/tvcg.2016.2599030;10.1109/tvcg.2017.2745140;10.1109/infvis.2000.885086;10.1109/tvcg.2020.3030467;10.1109/vast.2009.5332628;10.1109/infvis.2003.1249018;10.1109/tvcg.2018.2864912;10.1109/tvcg.2017.2745919;10.1109/tvcg.2015.2467191;10.1109/tvcg.2020.3030423;10.1109/tvcg.2013.234;10.1109/tvcg.2008.166,"Visualization Linting,Automated Visualization Design,Visualization Optimization",9.0,32.0,64.0,1919.0,,,visualizations visualization fixer;vega lite specifications;evaluate conduct lab;rising popularity;necessarily possess,0.7597;0.1966;0.1062;0.0410;0.0159,"[np.int64(-1), -1, -1, -1, -1]",139;-1;-1;-1;-1,139,139,Visualization Tools
InfoVis,2013,Empirical Guidance on Scatterplot and Dimension Reduction Technique Choices,10.1109/tvcg.2013.153,http://dx.doi.org/10.1109/TVCG.2013.153,2634.0,2643.0,J,"To verify cluster separation in high-dimensional data, analysts often reduce the data with a dimension reduction (DR) technique, and then visualize it with 2D Scatterplots, interactive 3D Scatterplots, or Scatterplot Matrices (SPLOMs). With the goal of providing guidance between these visual encoding choices, we conducted an empirical data study in which two human coders manually inspected a broad set of 816 scatterplots derived from 75 datasets, 4 DR techniques, and the 3 previously mentioned scatterplot techniques. Each coder scored all color-coded classes in each scatterplot in terms of their separability from other classes. We analyze the resulting quantitative data with a heatmap approach, and qualitatively discuss interesting scatterplot examples. Our findings reveal that 2D scatterplots are often 'good enough', that is, neither SPLOM nor interactive 3D adds notably more cluster separability with the chosen DR technique. If 2D is not good enough, the most promising approach is to use an alternative DR technique in 2D. Beyond that, SPLOM occasionally adds additional value, and interactive 3D rarely helps but often hurts in terms of poorer class separation and usability. We summarize these results as a workflow model and implications for design. Our results offer guidance to analysts during the DR exploration process.",Michael Sedlmair;Tamara Munzner;Melanie Tory,Michael Sedlmair;Tamara Munzner;Melanie Tory,"University of Vienna, Austria;University of British Columbia, Canada;University of Victoria, Canada",10.1109/tvcg.2009.127;10.1109/tvcg.2011.229;10.1109/tvcg.2007.70596;10.1109/infvis.2005.1532142;10.1109/infvis.1997.636793;10.1109/vast.2010.5652392;10.1109/vast.2012.6400490;10.1109/tvcg.2008.109;10.1109/vast.2009.5332628;10.1109/tvcg.2009.127,"Dimensionality reduction, scatterplots, quantitative study",186.0,124.0,53.0,1418.0,,,visualize 2d scatterplots;cluster separability chosen;datasets dr techniques;coders manually inspected;derived,0.5478;0.4412;0.3949;0.1608;0.1008,"[np.int64(-1), -1, -1, -1, -1]",68;-1;-1;-1;-1,68,68,Scatterplot Visualization
SciVis,2013,Ambient Volume Scattering,10.1109/tvcg.2013.129,http://dx.doi.org/10.1109/TVCG.2013.129,2936.0,2945.0,J,"We present ambient scattering as a preintegration method for scattering on mesoscopic scales in direct volume rendering. Far-range scattering effects usually provide negligible contributions to a given location due to the exponential attenuation with increasing distance. This motivates our approach to preintegrating multiple scattering within a finite spherical region around any given sample point. To this end, we solve the full light transport with a Monte-Carlo simulation within a set of spherical regions, where each region may have different material parameters regarding anisotropy and extinction. This precomputation is independent of the data set and the transfer function, and results in a small preintegration table. During rendering, the look-up table is accessed for each ray sample point with respect to the viewing direction, phase function, and material properties in the spherical neighborhood of the sample. Our rendering technique is efficient and versatile because it readily fits in existing ray marching algorithms and can be combined with local illumination and volumetric ambient occlusion. It provides interactive volumetric scattering and soft shadows, with interactive control of the transfer function, anisotropy parameter of the phase function, lighting conditions, and viewpoint. A GPU implementation demonstrates the benefits of ambient scattering for the visualization of different types of data sets, with respect to spatial perception, high-quality illumination, translucency, and rendering speed.",Marco Ament;Filip Sadlo;Daniel Weiskopf,Marco Ament;Filip Sadlo;Daniel Weiskopf,"VISUS, University of Stuttgart, Germany;VISUS, University of Stuttgart, Germany;VISUS, University of Stuttgart, Germany",10.1109/tvcg.2011.211;10.1109/tvcg.2007.70555;10.1109/visual.2003.1250394;10.1109/visual.2000.885683;10.1109/tvcg.2010.187;10.1109/visual.2004.64;10.1109/visual.2003.1250406;10.1109/tvcg.2010.145;10.1109/tvcg.2012.232;10.1109/tvcg.2011.161;10.1109/tvcg.2011.198;10.1109/visual.2002.1183764;10.1109/visual.2005.1532803;10.1109/tvcg.2009.204;10.1109/tvcg.2011.211,"Direct volume rendering, volume illumination, ambient scattering, preintegrated light transport, gradient-free shading",41.0,29.0,50.0,784.0,HM,,interactive volumetric scattering;lighting conditions;table accessed;precomputation independent;increasing,0.7437;0.2664;0.0701;0.0660;0.0318,"[np.int64(-1), -1, -1, -1, -1]",124;-1;-1;-1;-1,124,124,Volumetric Surface Visualization
VAST,2009,"VIScover: Visualizing, exploring, and analysing structured data",10.1109/vast.2009.5333946,http://dx.doi.org/10.1109/VAST.2009.5333946,,,M,"Today's challenging task in intelligent data processing is not to store large volumes of interlinked data but to visualize, explore, and understand its explicit or implicit relationships. Our solution to this is the VIScover system. VIScover combines semantic technologies with interactive exploration and visualization techniques able to analyze large volumes of structured data. We briefly describe our VIScover system and show its potential using the example of the VAST 2009 social network and geospatial data set.",Thorsten Liebig;Olaf Noppens;Friedrich W. von Henke,Thorsten Liebig;Olaf Noppens;Friedrich von Henke,"Derivo GmbH, Ulm University, Germany;Derivo GmbH, Ulm University, Germany;Ulm University, Germany",,,1.0,3.0,3.0,151.0,,,interlinked data visualize;semantic technologies;geospatial;processing store large;today,0.6089;0.5241;0.1857;0.1551;-0.0053,"[np.int64(-1), np.int64(-1), -1, -1, -1]",146;81;-1;-1;-1,81;146,146,Visualization Techniques
Vis,2009,Verifiable Visualization for Isosurface Extraction,10.1109/tvcg.2009.194,http://dx.doi.org/10.1109/TVCG.2009.194,1227.0,1234.0,J,"Visual representations of isosurfaces are ubiquitous in the scientific and engineering literature. In this paper, we present techniques to assess the behavior of isosurface extraction codes. Where applicable, these techniques allow us to distinguish whether anomalies in isosurface features can be attributed to the underlying physical process or to artifacts from the extraction process. Such scientific scrutiny is at the heart of verifiable visualization - subjecting visualization algorithms to the same verification process that is used in other components of the scientific pipeline. More concretely, we derive formulas for the expected order of accuracy (or convergence rate) of several isosurface features, and compare them to experimentally observed results in the selected codes. This technique is practical: in two cases, it exposed actual problems in implementations. We provide the reader with the range of responses they can expect to encounter with isosurface techniques, both under ldquonormal operating conditionsrdquo and also under adverse conditions. Armed with this information - the results of the verification process - practitioners can judiciously select the isosurface extraction technique appropriate for their problem of interest, and have confidence in its behavior.",Tiago Etiene;Carlos Eduardo Scheidegger;Luis Gustavo Nonato;Robert M. Kirby;Cláudio T. Silva,Tiago Etiene;Carlos Scheidegger;Luis Gustavo Nonato;Robert Mike Kirby;Cláudio Silva,"School of Computing and Scientific Computing and Imaging Institute, University of Utah, Salt Lake, UT, USA;School of Computing and Scientific Computing and Imaging Institute, University of Utah, Salt Lake, UT, USA;University of São Paulo, Brazil;School of Computing and Scientific Computing and Imaging Institute, University of Utah, Salt Lake, UT, USA;School of Computing and Scientific Computing and Imaging Institute, University of Utah, Salt Lake, UT, USA",10.1109/tvcg.2006.149;10.1109/visual.1994.346331;10.1109/tvcg.2006.149,"Verification, V&V, Isosurface Extraction, Marching Cubes",35.0,20.0,29.0,350.0,,,behavior isosurface extraction;verifiable visualization;scientific pipeline;expected order accuracy;codes applicable,0.7395;0.4452;0.1665;0.1156;0.1127,"[np.int64(-1), -1, -1, -1, -1]",72;-1;-1;-1;-1,72,72,Ridge Extraction Techniques
InfoVis,2004,The InfoVis Toolkit,10.1109/infvis.2004.64,http://dx.doi.org/10.1109/INFVIS.2004.64,167.0,174.0,C,"This article presents the InfoVis toolkit, designed to support the creation, extension and integration of advanced 2D information visualization components into interactive Java swing applications. The InfoVis toolkit provides specific data structures to achieve a fast action/feedback loop required by dynamic queries. It comes with a large set of components such as range sliders and tailored control panels required to control and configure the visualizations. These components are integrated into a coherent framework that simplifies the management of rich data structures and the design and extension of visualizations. Supported data structures currently include tables, trees and graphs. Supported visualizations include scatter plots, time series, parallel coordinates, treemaps, icicle trees, node-link diagrams for trees and graphs and adjacency matrices for graphs. All visualizations can use fisheye lenses and dynamic labeling. The InfoVis toolkit supports hardware acceleration when available through Agile2D, an implementation of the Java graphics API based on OpenGL, achieving speedups of 10 to 200 times. The article also shows how new visualizations can be added and extended to become components, enriching visualizations as well as general applications",Jean-Daniel Fekete,J.-D. Fekete,"INRIA Futurs/LRI, Université Paris Sud, Orsay, France",10.1109/infvis.2003.1249008;10.1109/infvis.2000.885086;10.1109/infvis.2002.1173156;10.1109/infvis.1995.528688;10.1109/infvis.2002.1173148;10.1109/infvis.2003.1249008,"Information Visualization, Toolkit, Graphics, Integration",424.0,109.0,27.0,1166.0,,,information visualization;java swing applications;time series parallel;set components range;added extended,0.6782;0.5017;0.1661;0.1202;-0.0210,"[np.int64(-1), np.int64(-1), -1, -1, -1]",98;121;-1;-1;-1,98;121,98,Information Visualization
InfoVis,2019,Data Sampling in Multi-view and Multi-class Scatterplots via Set Cover Optimization,10.1109/tvcg.2019.2934799,http://dx.doi.org/10.1109/TVCG.2019.2934799,739.0,748.0,J,"We present a method for data sampling in scatterplots by jointly optimizing point selection for different views or classes. Our method uses space-filling curves (Z-order curves) that partition a point set into subsets that, when covered each by one sample, provide a sampling or coreset with good approximation guarantees in relation to the original point set. For scatterplot matrices with multiple views, different views provide different space-filling curves, leading to different partitions of the given point set. For multi-class scatterplots, the focus on either per-class distribution or global distribution provides two different partitions of the given point set that need to be considered in the selection of the coreset. For both cases, we convert the coreset selection problem into an Exact Cover Problem (ECP), and demonstrate with quantitative and qualitative evaluations that an approximate solution that solves the ECP efficiently is able to provide high-quality samplings.",Ruizhen Hu;Tingkai Sha;Oliver van Kaick;Oliver Deussen;Hui Huang 0004,Ruizhen Hu;Tingkai Sha;Oliver Van Kaick;Oliver Deussen;Hui Huang,"Shenzhen University, Visual Computing Research Center, China;Shenzhen University, Visual Computing Research Center, China;Carleton University, School of Computer Science, Canada;Konstanz University, Germany and Shenzhen VisuCA Key Lab, SIAT, China;Shenzhen University, Visual Computing Research Center, China",10.1109/tvcg.2018.2864912;10.1109/tvcg.2013.153;10.1109/tvcg.2010.176;10.1109/tvcg.2007.70535;10.1109/tvcg.2014.2346594;10.1109/tvcg.2011.229;10.1109/tvcg.2008.119;10.1109/tvcg.2006.170;10.1109/visual.1998.745301;10.1109/tvcg.2018.2864912,"Sampling,Scatterplot,SPLOM,Exact Cover Problem",19.0,16.0,43.0,842.0,,,sampling scatterplots;filling curves leading;jointly optimizing point;multi class;exact cover,0.7015;0.2494;0.2298;0.1837;0.1680,"[np.int64(-1), -1, -1, -1, -1]",68;-1;-1;-1;-1,68,68,Scatterplot Visualization
Vis,1995,Turbulent flow visualization in computational and experimental hydraulics,10.1109/visual.1995.485158,http://dx.doi.org/10.1109/VISUAL.1995.485158,388.0,,C,"Many practical problems in open channel hydraulics that were traditionally investigated in hydraulic model experiments, are nowadays being solved by using computational fluid dynamics. However, in order to interpret computational results, there is a clear preference among scientists and engineers for visualization in analogy with experimental techniques. One such technique, particle tracing, enables a dynamic (Lagrangian) interpretation of a statically (Eulerian) computed vector field. However, quite often the emphasis in particle tracing is only on the mean flow properties, while effects due to dispersion and mixing are often not accounted for. Hence turbulent flow characteristics have to be incorporated in a visualization system for practical hydraulic engineering problems. The particle tracing technique presented in this case study has been specifically developed to combine both mean and fluctuating velocity vectors, thus simulating stochastic perturbations around mean flow conditions. A number of cases are presented that demonstrate the practical applicability of advanced visualization techniques in realistic engineering studies.",Arthur E. Mynett;I. Ari Sadarjoen;A. J. S. Hin,A.E. Mynett;I.A. Sadarjoen;A.J.S. Hin,"Strategic R&D, Delft Hydraulics, Delft, Netherlands;Department of Technical Informatics, Delft University of Technnology, Delft, Netherlands;Department of Computing Science, University of Groningam, Groningen, Netherlands",0.1109/visual.1994.346329,,7.0,3.0,6.0,134.0,,,visualization practical hydraulic;problems particle tracing;stochastic perturbations mean;eulerian computed vector;nowadays,0.6773;0.4138;0.1619;0.1348;0.0511,"[np.int64(-1), -1, -1, -1, -1]",63;-1;-1;-1;-1,63,63,Flow Visualization Techniques
InfoVis,2018,A Heuristic Approach to Value-Driven Evaluation of Visualizations,10.1109/tvcg.2018.2865146,http://dx.doi.org/10.1109/TVCG.2018.2865146,491.0,500.0,J,"Recently, an approach for determining the value of a visualization was proposed, one moving beyond simple measurements of task accuracy and speed. The value equation contains components for the time savings a visualization provides, the insights and insightful questions it spurs, the overall essence of the data it conveys, and the confidence about the data and its domain it inspires. This articulation of value is purely descriptive, however, providing no actionable method of assessing a visualization's value. In this work, we create a heuristic-based evaluation methodology to accompany the value equation for assessing interactive visualizations. We refer to the methodology colloquially as ICE-T, based on an anagram of the four value components. Our approach breaks the four components down into guidelines, each of which is made up of a small set of low-level heuristics. Evaluators who have knowledge of visualization design principles then assess the visualization with respect to the heuristics. We conducted an initial trial of the methodology on three interactive visualizations of the same data set, each evaluated by 15 visualization experts. We found that the methodology showed promise, obtaining consistent ratings across the three visualizations and mirroring judgments of the utility of the visualizations by instructors of the course in which they were developed.",Emily Wall;Meeshu Agnihotri;Laura E. Matzen;Kristin Divis;Michael Haass;Alex Endert;John T. Stasko,Emily Wall;Meeshu Agnihotri;Laura Matzen;Kristin Divis;Michael Haass;Alex Endert;John Stasko,"Georgia Institute of Technology, Atlanta, GA, US;Georgia Institute of Technology, Atlanta, GA, US;Sandia National Laboratories, Albuquerque, NM, US;Sandia National Laboratories, Albuquerque, NM, US;Sandia National Laboratories, Albuquerque, NM, US;Georgia Institute of Technology, Atlanta, GA, US;Georgia Institute of Technology, Atlanta, GA, US",10.1109/infvis.2001.963289;10.1109/visual.2003.1250401;10.1109/infvis.2001.963289,"Visualization evaluation,heuristics,value of visualization",61.0,67.0,35.0,2501.0,,,assessing visualization value;heuristic;colloquially ice;instructors course developed;equation contains components,0.7857;0.2580;0.1352;0.1090;-0.0337,"[np.int64(-1), -1, -1, -1, -1]",102;-1;-1;-1;-1,102,102,Visualization Value Assessment
InfoVis,2012,Does an Eye Tracker Tell the Truth about Visualizations?: findings while Investigating Visualizations for Decision Making,10.1109/tvcg.2012.215,http://dx.doi.org/10.1109/TVCG.2012.215,2421.0,2430.0,J,"For information visualization researchers, eye tracking has been a useful tool to investigate research participants' underlying cognitive processes by tracking their eye movements while they interact with visual techniques. We used an eye tracker to better understand why participants with a variant of a tabular visualization called `SimulSort' outperformed ones with a conventional table and typical one-column sorting feature (i.e., Typical Sorting). The collected eye-tracking data certainly shed light on the detailed cognitive processes of the participants; SimulSort helped with decision-making tasks by promoting efficient browsing behavior and compensatory decision-making strategies. However, more interestingly, we also found unexpected eye-tracking patterns with Simul- Sort. We investigated the cause of the unexpected patterns through a crowdsourcing-based study (i.e., Experiment 2), which elicited an important limitation of the eye tracking method: incapability of capturing peripheral vision. This particular result would be a caveat for other visualization researchers who plan to use an eye tracker in their studies. In addition, the method to use a testing stimulus (i.e., influential column) in Experiment 2 to verify the existence of such limitations would be useful for researchers who would like to verify their eye tracking results.",Sung-Hee Kim;Zhihua Dong;Hanjun Xian;Benjavan Upatising;Ji Soo Yi,Sung-Hee Kim;Zhihua Dong;Hanjun Xian;Benjavan Upatising;Ji Soo Yi,"School of Industrial Engineering, Purdue University, USA;School of Industrial Engineering, Purdue University, USA;School of Engineering Education, Purdue University, USA;School of Industrial Engineering, Purdue University, USA;School of Industrial Engineering, Purdue University, USA",10.1109/visual.1990.146402;10.1109/tvcg.2011.193;10.1109/vast.2008.4677363;10.1109/tvcg.2010.149;10.1109/tvcg.2011.183;10.1109/vast.2009.5333920;10.1109/visual.1990.146402,"Visualized decision making, eye tracking, crowdsourcing, quantitative empirical study, limitations, peripheral vision",86.0,45.0,55.0,1611.0,,,visualization researchers eye;efficient browsing behavior;column sorting;cause unexpected patterns;compensatory decision,0.6825;0.3352;0.3260;0.1427;0.0423,"[np.int64(-1), -1, -1, -1, -1]",137;-1;-1;-1;-1,137,137,Visualization Research Studies
Vis,2005,On the optimization of visualizations of complex phenomena,10.1109/visual.2005.1532782,http://dx.doi.org/10.1109/VISUAL.2005.1532782,87.0,94.0,C,"The problem of perceptually optimizing complex visualizations is a difficult one, involving perceptual as well as aesthetic issues. In our experience, controlled experiments are quite limited in their ability to uncover interrelationships among visualization parameters, and thus may not be the most useful way to develop rules-of-thumb or theory to guide the production of high-quality visualizations. In this paper, we propose a new experimental approach to optimizing visualization quality that integrates some of the strong points of controlled experiments with methods more suited to investigating complex highly-coupled phenomena. We use human-in-the-loop experiments to search through visualization parameter space, generating large databases of rated visualization solutions. This is followed by data mining to extract results such as exemplar visualizations, guidelines for producing visualizations, and hypotheses about strategies leading to strong visualizations. The approach can easily address both perceptual and aesthetic concerns, and can handle complex parameter interactions. We suggest a genetic algorithm as a valuable way of guiding the human-in-the-loop search through visualization parameter space. We describe our methods for using clustering, histogramming, principal component analysis, and neural networks for data mining. The experimental approach is illustrated with a study of the problem of optimal texturing for viewing layered surfaces so that both surfaces are maximally observable.",Donald H. House;Alethea Bair;Colin Ware,D. House;A. Bair;C. Ware,"Texas A and M University, USA;Texas A and M University, USA;University of New Hampshire, USA",10.1109/visual.1996.568113;10.1109/visual.1996.567784,"perception, visualization evaluation,layered surfaces, genetic algorithm, data mining, principal component analysis, neural networks",40.0,6.0,30.0,238.0,,,optimizing visualization quality;neural networks data;loop search;genetic;coupled phenomena,0.6607;0.3107;0.1533;0.1508;0.0629,"[np.int64(-1), -1, -1, -1, -1]",100;-1;-1;-1;-1,100,100,Visualization Quality
SciVis,2013,Visualization of Morse Connection Graphs for Topologically Rich 2D Vector fields,10.1109/tvcg.2013.229,http://dx.doi.org/10.1109/TVCG.2013.229,2763.0,2772.0,J,"Recent advances in vector field topologymake it possible to compute its multi-scale graph representations for autonomous 2D vector fields in a robust and efficient manner. One of these representations is a Morse Connection Graph (MCG), a directed graph whose nodes correspond to Morse sets, generalizing stationary points and periodic trajectories, and arcs - to trajectories connecting them. While being useful for simple vector fields, the MCG can be hard to comprehend for topologically rich vector fields, containing a large number of features. This paper describes a visual representation of the MCG, inspired by previous work on graph visualization. Our approach aims to preserve the spatial relationships between the MCG arcs and nodes and highlight the coherent behavior of connecting trajectories. Using simulations of ocean flow, we show that it can provide useful information on the flow structure. This paper focuses specifically on MCGs computed for piecewise constant (PC) vector fields. In particular, we describe extensions of the PC framework that make it more flexible and better suited for analysis of data on complex shaped domains with a boundary. We also describe a topology simplification scheme that makes our MCG visualizations less ambiguous. Despite the focus on the PC framework, our approach could also be applied to graph representations or topological skeletons computed using different methods.",Andrzej Szymczak;Levente Sipeki,Andrzej Szymczak;Levente Sipeki,"Colorado School of Mines, USA;Colorado School of Mines, USA",10.1109/tvcg.2011.233;10.1109/tvcg.2008.135;10.1109/tvcg.2012.209;10.1109/visual.2000.885716;10.1109/tvcg.2011.233,"Morse connection graph, vector field topology",4.0,2.0,34.0,344.0,,,morse connection graph;ocean flow;mcgs computed piecewise;fields containing large;pc framework make,0.6049;0.3595;0.1092;0.0446;-0.0223,"[np.int64(-1), -1, -1, -1, -1]",115;-1;-1;-1;-1,115,115,Structural Connectivity Analysis
Vis,2023,CLAMS: A Cluster Ambiguity Measure for Estimating Perceptual Variability in Visual Clustering,10.1109/tvcg.2023.3327201,http://dx.doi.org/10.1109/TVCG.2023.3327201,770.0,780.0,J,"Visual clustering is a common perceptual task in scatterplots that supports diverse analytics tasks (e.g., cluster identification). However, even with the same scatterplot, the ways of perceiving clusters (i.e., conducting visual clustering) can differ due to the differences among individuals and ambiguous cluster boundaries. Although such perceptual variability casts doubt on the reliability of data analysis based on visual clustering, we lack a systematic way to efficiently assess this variability. In this research, we study perceptual variability in conducting visual clustering, which we call Cluster Ambiguity. To this end, we introduce CLAMS, a data-driven visual quality measure for automatically predicting cluster ambiguity in monochrome scatterplots. We first conduct a qualitative study to identify key factors that affect the visual separation of clusters (e.g., proximity or size difference between clusters). Based on study findings, we deploy a regression module that estimates the human-judged separability of two clusters. Then, CLAMS predicts cluster ambiguity by analyzing the aggregated results of all pairwise separability between clusters that are generated by the module. CLAMS outperforms widely-used clustering techniques in predicting ground truth cluster ambiguity. Meanwhile, CLAMS exhibits performance on par with human annotators. We conclude our work by presenting two applications for optimizing and benchmarking data mining techniques using CLAMS. The interactive demo of CLAMS is available at clusterambiguity.dev.",Hyeon Jeon;Ghulam Jilani Quadri;Hyunwook Lee;Paul Rosen 0001;Danielle Albers Szafir;Jinwook Seo,Hyeon Jeon;Ghulam Jilani Quadri;Hyunwook Lee;Paul Rosen;Danielle Albers Szafir;Jinwook Seo,"Seoul National University, South Korea;University of North Carolina, Chapel Hill, USA;UNIST, South Korea;University of Utah, USA;Seoul National University, South Korea;Seoul National University, South Korea",0.1109/infvis.2005.1532136;10.1109/tvcg.2011.229;10.1109/tvcg.2013.124;10.1109/tvcg.2014.2346572;10.1109/tvcg.2021.3114833;10.1109/tvcg.2017.2744718;10.1109/tvcg.2019.2934811;10.1109/tvcg.2018.2865240;10.1109/tvcg.2020.3030365;10.1109/tvcg.2017.2744184;10.1109/tvcg.2018.2864912;10.1109/tvcg.2021.3114694,"Cluster,scatterplot,perception,cluster analysis,cluster ambiguity,visual quality measure",,8.0,86.0,977.0,HM,,visual separation clusters;benchmarking data;clams predicts;ambiguity end;key factors affect,0.6600;0.2530;0.2051;0.1275;0.0579,"[np.int64(-1), -1, -1, -1, -1]",117;-1;-1;-1;-1,117,117,Cluster Visualization
Vis,1996,Choosing effective colours for data visualization,10.1109/visual.1996.568118,http://dx.doi.org/10.1109/VISUAL.1996.568118,263.0,270.0,C,"We describe a technique for choosing multiple colours for use during data visualization. Our goal is a systematic method for maximizing the total number of colours available for use, while still allowing an observer to rapidly and accurately search a display for any one of the given colours. Previous research suggests that we need to consider three separate effects during colour selection: colour distance, linear separation, and colour category. We describe a simple method for measuring and controlling all of these effects. Our method was tested by performing a set of target identification studies; we analysed the ability of thirty eight observers to find a colour target in displays that contained differently coloured background elements. Results showed our method can be used to select a group of colours that will provide good differentiation between data elements during data visualization.",Christopher G. Healey,C.G. Healey,"Department of Computer Science, University of British Columbia, Vancouver, BC, Canada",10.1109/visual.1995.480803;10.1109/visual.1993.398874;10.1109/visual.1995.480803,,417.0,87.0,22.0,2195.0,,,colour target displays;elements data visualization;choosing multiple;distance linear separation;research,0.6312;0.4158;0.2501;0.1923;0.0799,"[np.int64(-1), -1, -1, -1, -1]",30;-1;-1;-1;-1,30,30,Color Displays
Vis,2008,Continuous Scatterplots,10.1109/tvcg.2008.119,http://dx.doi.org/10.1109/TVCG.2008.119,1428.0,1435.0,J,"Scatterplots are well established means of visualizing discrete data values with two data variables as a collection of discrete points. We aim at generalizing the concept of scatterplots to the visualization of spatially continuous input data by a continuous and dense plot. An example of a continuous input field is data defined on an n-D spatial grid with respective interpolation or reconstruction of in-between values. We propose a rigorous, accurate, and generic mathematical model of continuous scatterplots that considers an arbitrary density defined on an input field on an n-D domain and that maps this density to m-D scatterplots. Special cases are derived from this generic model and discussed in detail: scatterplots where the n-D spatial domain and the m-D data attribute domain have identical dimension, 1-D scatterplots as a way to define continuous histograms, and 2-D scatterplots of data on 3-D spatial grids. We show how continuous histograms are related to traditional discrete histograms and to the histograms of isosurface statistics. Based on the mathematical model of continuous scatterplots, respective visualization algorithms are derived, in particular for 2-D scatterplots of data from 3-D tetrahedral grids. For several visualization tasks, we show the applicability of continuous scatterplots. Since continuous scatterplots do not only sample data at grid points but interpolate data values within cells, a dense and complete visualization of the data set is achieved that scales well with increasing data set size. Especially for irregular grids with varying cell size, improved results are obtained when compared to conventional scatterplots. Therefore, continuous scatterplots are a suitable extension of a statistics visualization technique to be applied to typical data from scientific computation.",Sven Bachthaler;Daniel Weiskopf,Sven Bachthaler;Daniel Weiskopf,"VISUS (Visualization Research Center), Universität Stuttgart, Stuttgart, Germany;VISUS (Visualization Research Center), Universität Stuttgart, Stuttgart, Germany",10.1109/tvcg.2006.168;10.1109/tvcg.2008.160;10.1109/tvcg.2006.168,"Scatterplot, histogram, continuous frequency plot, interpolation",193.0,121.0,15.0,1348.0,,,scatterplots visualization spatially;interpolation reconstruction values;size especially;example continuous;derived generic model,0.7308;0.2630;0.1009;0.0591;-0.0463,"[np.int64(-1), -1, -1, -1, -1]",68;-1;-1;-1;-1,68,68,Scatterplot Visualization
Vis,1996,Anatomy-based facial tissue modeling using the finite element method,10.1109/visual.1996.567595,http://dx.doi.org/10.1109/VISUAL.1996.567595,21.0,28.0,C,"Anatomy-based facial tissue modeling for surgical simulation is a field whose time has come. Real-time facial animation has been created in the last few years using models based on the anatomical structure of the human skin. Anatomy-based models are also under development in the field of medical visualization, with which facial surgery can be realistically simulated. In this article, we present an anatomy-based 3D finite element tissue model. Integrated into a computer-aided surgical planning system, this model allows the precise prediction of soft tissue changes resulting from the realignment of the underlying bone structure. The model has already been used in our Department of Oral and Maxillofacial Surgery and has improved craniofacial surgical planning procedures. The model is described in detail, and surgical simulation results are shown and discussed.",Erwin Keeve;Sabine Girod;Paula Pfeifle;Bernd Girod,E. Keeve;S. Girod;P. Pfeifle;B. Girod,"Telecommunications Institute, University of Erlangen Nuremberg, Germany;Department of Oral and Maxillofacial Surgery, University of Erlangen Nuremberg, Germany;Telecommunications Institute, University of Erlangen Nuremberg, Germany;Telecommunications Institute, University of Erlangen Nuremberg, Germany",,"human facial modeling, finite element method, computer-aided surgery, surgery planning and simulation",158.0,32.0,12.0,306.0,,,visualization facial surgery;3d finite element;bone;precise prediction soft;development field,0.7270;0.4155;0.2123;0.1028;0.0867,"[np.int64(-1), -1, -1, -1, -1]",38;-1;-1;-1;-1,38,38,3D Medical Visualization
Vis,2021,E-ffective: A Visual Analytic System for Exploring the Emotion and Effectiveness of Inspirational Speeches,10.1109/tvcg.2021.3114789,http://dx.doi.org/10.1109/TVCG.2021.3114789,508.0,517.0,J,"What makes speeches effective has long been a subject for debate, and until today there is broad controversy among public speaking experts about what factors make a speech effective as well as the roles of these factors in speeches. Moreover, there is a lack of quantitative analysis methods to help understand effective speaking strategies. In this paper, we propose E-ffective, a visual analytic system allowing speaking experts and novices to analyze both the role of speech factors and their contribution in effective speeches. From interviews with domain experts and investigating existing literature, we identified important factors to consider in inspirational speeches. We obtained the generated factors from multi-modal data that were then related to effectiveness data. Our system supports rapid understanding of critical factors in inspirational speeches, including the influence of emotions by means of novel visualization methods and interaction. Two novel visualizations include E-spiral (that shows the emotional shifts in speeches in a visually compact way) and E-script (that connects speech content with key speech delivery information). In our evaluation we studied the influence of our system on experts' domain knowledge about speech factors. We further studied the usability of the system by speaking novices and experts on assisting analysis of inspirational speech effectiveness.",Kevin T. Maher;Ze-Yuan Huang;Jian-Cheng Song;Xiaoming Deng 0001;Yu-Kun Lai;Cuixia Ma;Hao Wang 0005;Yong-Jin Liu 0001;Hongan Wang,Kevin Maher;Zeyuan Huang;Jiancheng Song;Xiaoming Deng;Yu-Kun Lai;Cuixia Ma;Hao Wang;Yong-Jin Liu;Hongan Wang,"Institute of Software, Chinese Academy of Sciences, Tsinghua University, China;State Key Laboratory of Computer Science, Beijing Key Lab of Human-Computer Interaction, Institute of Software, Chinese Academy of Sciences, University of Chinese Academy of Sciences, China;State Key Laboratory of Computer Science, Beijing Key Lab of Human-Computer Interaction, Institute of Software, Chinese Academy of Sciences, University of Chinese Academy of Sciences, China;State Key Laboratory of Computer Science, Beijing Key Lab of Human-Computer Interaction, Institute of Software, Chinese Academy of Sciences, University of Chinese Academy of Sciences, China;Cardiff University, United Kingdom;State Key Laboratory of Computer Science, Beijing Key Lab of Human-Computer Interaction, Institute of Software, Chinese Academy of Sciences, University of Chinese Academy of Sciences, China;State Key Laboratory of Computer Science, Beijing Key Lab of Human-Computer Interaction, Institute of Software, Chinese Academy of Sciences, University of Chinese Academy of Sciences, China;Tsinghua University, China;Alibaba Group, China",10.1109/tvcg.2019.2934656;10.1109/tvcg.2019.2934656,"Affective visualization,multimodal analysis,speech effectiveness",1.0,8.0,34.0,1169.0,,,inspirational speech effectiveness;visualizations include spiral;multi modal;domain experts;generated factors,0.6466;0.3507;0.2039;0.1755;0.1196,"[np.int64(-1), -1, -1, -1, -1]",7;-1;-1;-1;-1,7,7,Motivational Speaking
Vis,2024,Learnable and Expressive Visualization Authoring Through Blended Interfaces,10.1109/tvcg.2024.3456598,http://dx.doi.org/10.1109/TVCG.2024.3456598,459.0,469.0,J,"A wide range of visualization authoring interfaces enable the creation of highly customized visualizations. However, prioritizing expressiveness often impedes the learnability of the authoring interface. The diversity of users, such as varying computational skills and prior experiences in user interfaces, makes it even more challenging for a single authoring interface to satisfy the needs of a broad audience. In this paper, we introduce a framework to balance learnability and expressivity in a visualization authoring system. Adopting insights from learnability studies, such as multimodal interaction and visualization literacy, we explore the design space of blending multiple visualization authoring interfaces for supporting authoring tasks in a complementary and flexible manner. To evaluate the effectiveness of blending interfaces, we implemented a proof-of-concept system, Blace, that combines four common visualization authoring interfaces–template-based, shelf configuration, natural language, and code editor–that are tightly linked to one another to help users easily relate unfamiliar interfaces to more familiar ones. Using the system, we conducted a user study with 12 domain experts who regularly visualize genomics data as part of their analysis workflow. Participants with varied visualization and programming backgrounds were able to successfully reproduce unfamiliar visualization examples without a guided tutorial in the study. Feedback from a post-study qualitative questionnaire further suggests that blending interfaces enabled participants to learn the system easily and assisted them in confidently editing unfamiliar visualization grammar in the code editor, enabling expressive customization. Reflecting on our study results and the design of our system, we discuss the different interaction patterns that we identified and design implications for blending visualization authoring interfaces.",Sehi L'Yi;Astrid van den Brandt;Etowah Adams;Huyen N. Nguyen;Nils Gehlenborg,Sehi L’Yi;Astrid van den Brandt;Etowah Adams;Huyen N. Nguyen;Nils Gehlenborg,"Harvard Medical School, USA;Eindhoven University of Technology and Harvard Medical School, Netherlands;Harvard Medical School, USA;Harvard Medical School, USA;Harvard Medical School, USA",10.1109/tvcg.2011.185;10.1109/tvcg.2010.164;10.1109/tvcg.2017.2743859;10.1109/tvcg.2016.2598920;10.1109/tvcg.2022.3209398;10.1109/tvcg.2020.3030419;10.1109/tvcg.2021.3114876;10.1109/tvcg.2022.3209407;10.1109/tvcg.2014.2346291;10.1109/tvcg.2018.2865158;10.1109/tvcg.2016.2598839;10.1109/tvcg.2019.2934281;10.1109/tvcg.2016.2599030;10.1109/tvcg.2017.2745219;10.1109/tvcg.2023.3326585;10.1109/tvcg.2022.3209435;10.1109/tvcg.2022.3209357;10.1109/tvcg.2015.2467191;10.1109/tvcg.2020.3030367,"Visualization authoring,blended interfaces,,,genomics data visualization",,0.0,83.0,566.0,HM,,visualization authoring interfaces;natural language code;study;shelf configuration;blace combines common,0.6880;0.3507;0.1364;0.1008;0.0435,"[np.int64(-1), -1, -1, -1, -1]",139;-1;-1;-1;-1,139,139,Visualization Tools
VAST,2019,You can't always sketch what you want: Understanding Sensemaking in Visual Query Systems,10.1109/tvcg.2019.2934666,http://dx.doi.org/10.1109/TVCG.2019.2934666,1267.0,1277.0,J,"Visual query systems (VQSs) empower users to interactively search for line charts with desired visual patterns, typically specified using intuitive sketch-based interfaces. Despite decades of past work on VQSs, these efforts have not translated to adoption in practice, possibly because VQSs are largely evaluated in unrealistic lab-based settings. To remedy this gap in adoption, we collaborated with experts from three diverse domains—astronomy, genetics, and material science—via a year-long user-centered design process to develop a VQS that supports their workflow and analytical needs, and evaluate how VQSs can be used in practice. Our study results reveal that ad-hoc sketch-only querying is not as commonly used as prior work suggests, since analysts are often unable to precisely express their patterns of interest. In addition, we characterize three essential sensemaking processes supported by our enhanced VQS. We discover that participants employ all three processes, but in different proportions, depending on the analytical needs in each domain. Our findings suggest that all three sensemaking processes must be integrated in order to make future VQSs useful for a wide range of analytical inquiries.",Doris Jung Lin Lee;John Lee 0005;Tarique Siddiqui;Jaewoo Kim;Karrie Karahalios;Aditya G. Parameswaran,Doris Jung-Lin Lee;John Lee;Tarique Siddiqui;Jaewoo Kim;Karrie Karahalios;Aditya Parameswaran,"University of California, Berkeley;University of Illinois, Urbana-Champaign;University of Illinois, Urbana-Champaign;University of Illinois, Urbana-Champaign;University of Illinois, Urbana-Champaign;University of California, Berkeley",10.1109/infvis.2005.1532136;10.1109/vast.2008.4677353;10.1109/tvcg.2017.2743990;10.1109/vast.2016.7883519;10.1109/tvcg.2009.111;10.1109/tvcg.2012.213,"Visual analytics,exploratory analysis,visual queries",27.0,16.0,50.0,693.0,,,visual query systems;findings suggest sensemaking;astronomy genetics material;evaluated unrealistic lab;decades,0.6236;0.4161;0.2586;0.1759;0.0839,"[np.int64(-1), -1, -1, -1, -1]",146;-1;-1;-1;-1,146,146,Visualization Techniques
Vis,1999,Structured spatial domain image and data comparison metrics,10.1109/visual.1999.809873,http://dx.doi.org/10.1109/VISUAL.1999.809873,97.0,515.0,C,"Often, images or datasets have to be compared to facilitate choices of visualization and simulation parameters respectively. Common comparison techniques include side-by-side viewing and juxtaposition, in order to facilitate visual verification of verisimilitude. We propose quantitative techniques which accentuate differences in images and datasets. The comparison is enabled through a collection of partial metrics which, essentially, measure the lack of correlation between the datasets or images being compared. That is, they attempt to expose and measure the extent of the inherent structures in the difference between images or datasets. Besides yielding numerical attributes, the metrics also produce images which can visually highlight differences. Our metrics are simple to compute and operate in the spatial domain. We demonstrate the effectiveness of our metrics through examples for comparing images and datasets.",Nivedita Sahasrabudhe;John E. West;Raghu Machiraju;Mark Janus,N. Sahasrabudhe;J.E. West;R. Machiraju;M. Janus,"NSF Engineering Research Center, Mississippi State University, USA;NSF Engineering Research Center, Mississippi State University, USA and DoD High Performance Computing Center, Information Technology Laboratory, USAE Waterways Experiment Station, USA;Department of Computer Science, NSF Engineering Research Center, Mississippi State University, USA;Department of AeroSpace Engineering, NSF Engineering Research Center, Mississippi State University, USA",10.1109/visual.1997.663848;10.1109/visual.1990.146360;10.1109/visual.1998.745332;10.1109/visual.1997.663848,"metrics, steering, rendering, correlation measure",33.0,14.0,20.0,103.0,,,comparing images datasets;visually highlight;simulation parameters;operate spatial domain;facilitate,0.6372;0.2931;0.1824;0.1797;0.0753,"[np.int64(-1), -1, -1, -1, -1]",14;-1;-1;-1;-1,14,14,Image Dataset Comparison
VAST,2017,CRICTO: Supporting Sensemaking through Crowdsourced Information Schematization,10.1109/vast.2017.8585484,http://dx.doi.org/10.1109/VAST.2017.8585484,139.0,150.0,C,"We present CRICTO, a new crowdsourcing visual analytics environment for making sense of and analyzing text data, whereby multiple crowdworkers are able to parallelize the simple information schematization tasks of relating and connecting entities across documents. The diverse links from these schematization tasks are then automatically combined and the system visualizes them based on the semantic types of the linkages. CRICTO also includes several tools that allow analysts to interactively explore and refine crowdworkers' results to better support their own sensemaking processes. We evaluated CRICTO's techniques and analysis workflow with deployments of CRICTO using Amazon Mechanical Turk and a user study that assess the effect of crowdsourced schematization in sensemaking tasks. The results of our evaluation show that CRICTO's crowdsourcing approaches and workflow help analysts explore diverse aspects of datasets, and uncover more accurate hidden stories embedded in the text datasets.",Haeyong Chung;Sai Prashanth Dasari;Santhosh Nandhakumar;Christopher Andrews 0001,Haeyong Chung;Sai Prashanth Dasari;Santhosh Nandhakumar;Christopher Andrews,University of Alabama in Huntsville;University of Alabama in Huntsville;University of Alabama in Huntsville;Middlebury College,10.1109/vast.2007.4389006;10.1109/tvcg.2013.164;10.1109/tvcg.2007.70577;10.1109/vast.2009.5333878;10.1109/vast.2008.4677362;10.1109/tvcg.2014.2346573;10.1109/vast.2006.261439;10.1109/vast.2010.5652932;10.1109/vast.2007.4389011,"Visual text analytics,sensemaking,crowdsourcing",8.0,5.0,51.0,258.0,,,crowdsourced schematization sensemaking;analytics environment;stories embedded text;combined;cricto techniques,0.6727;0.2778;0.2542;0.1075;0.0919,"[np.int64(-1), -1, -1, -1, -1]",81;-1;-1;-1;-1,81,81,Semantic Sensemaking
Vis,2023,Visualizing Historical Book Trade Data: An Iterative Design Study with Close Collaboration with Domain Experts,10.1109/tvcg.2023.3326923,http://dx.doi.org/10.1109/TVCG.2023.3326923,540.0,550.0,J,"The circulation of historical books has always been an area of interest for historians. However, the data used to represent the journey of a book across different places and times can be difficult for domain experts to digest due to buried geographical and chronological features within text-based presentations. This situation provides an opportunity for collaboration between visualization researchers and historians. This paper describes a design study where a variant of the Nine-Stage Framework [46] was employed to develop a Visual Analytics (VA) tool called DanteExploreVis. This tool was designed to aid domain experts in exploring, explaining, and presenting book trade data from multiple perspectives. We discuss the design choices made and how each panel in the interface meets the domain requirements. We also present the results of a qualitative evaluation conducted with domain experts. The main contributions of this paper include: 1) the development of a VA tool to support domain experts in exploring, explaining, and presenting book trade data; 2) a comprehensive documentation of the iterative design, development, and evaluation process following the variant Nine-Stage Framework; 3) a summary of the insights gained and lessons learned from this design study in the context of the humanities field; and 4) reflections on how our approach could be applied in a more generalizable way.",Yiwen Xing;Cristina Dondi;Rita Borgo;Alfie Abdul-Rahman,Yiwen Xing;Cristina Dondi;Rita Borgo;Alfie Abdul-Rahman,"King's College London, United Kingdom;University of Oxford, United Kingdom;King's College London, United Kingdom;King's College London, United Kingdom",0.1109/tvcg.2014.2346431;10.1109/tvcg.2013.124;10.1109/tvcg.2021.3114797;10.1109/tvcg.2015.2467771;10.1109/tvcg.2014.2346331;10.1109/tvcg.2009.111;10.1109/tvcg.2012.213;10.1109/tvcg.2022.3209483;10.1109/tvcg.2018.2865076,"Design study,application motivated visualization,geospatial data",,0.0,59.0,429.0,,,visualization researchers historians;framework summary insights;journey book different;tool support domain;trade,0.6661;0.3251;0.2991;0.1483;0.0136,"[np.int64(-1), -1, -1, -1, -1]",137;-1;-1;-1;-1,137,137,Visualization Research Studies
SciVis,2019,Multi-Scale Topological Analysis of Asymmetric Tensor Fields on Surfaces,10.1109/tvcg.2019.2934314,http://dx.doi.org/10.1109/TVCG.2019.2934314,270.0,279.0,J,"Asymmetric tensor fields have found applications in many science and engineering domains, such as fluid dynamics. Recent advances in the visualization and analysis of 2D asymmetric tensor fields focus on pointwise analysis of the tensor field and effective visualization metaphors such as colors, glyphs, and hyperstreamlines. In this paper, we provide a novel multi-scale topological analysis framework for asymmetric tensor fields on surfaces. Our multi-scale framework is based on the notions of eigenvalue and eigenvector graphs. At the core of our framework are the identification of atomic operations that modify the graphs and the scale definition that guides the order in which the graphs are simplified to enable clarity and focus for the visualization of topological analysis on data of different sizes. We also provide efficient algorithms to realize these operations. Furthermore, we provide physical interpretation of these graphs. To demonstrate the utility of our system, we apply our multi-scale analysis to data in computational fluid dynamics.",Fariba Khan;Lawrence Roy;Eugene Zhang;Botong Qu;Shih-Hsuan Hung;Harry Yeh;Robert S. Laramee;Yue Zhang 0009,Fariba Khan;Lawrence Roy;Eugene Zhang;Botong Qu;Shih-Hsuan Hung;Harry Yeh;Robert S. Laramee;Yue Zhang,Oregon State University;Oregon State University;Oregon State University;Oregon State University;Oregon State University;Oregon State University;Swansea University;Oregon State University,10.1109/visual.1994.346326;10.1109/visual.1998.745312;10.1109/tvcg.2016.2598998;10.1109/tvcg.2009.126;10.1109/visual.2005.1532850;10.1109/visual.2004.59;10.1109/visual.2004.59;10.1109/tvcg.2011.170;10.1109/tvcg.2010.199;10.1109/visual.2001.964507;10.1109/visual.2000.885716;10.1109/visual.2002.1183784;10.1109/visual.2005.1532770;10.1109/visual.1994.346326,"Tensor field visualization,tensor field topology,2D asymmetric tensor fields,2D asymmetric tensor field topology,eigenvalue graphs,eigenvector graphs",8.0,5.0,37.0,538.0,,,tensor fields surfaces;scale topological analysis;interpretation graphs demonstrate;notions eigenvalue;atomic operations modify,0.5757;0.4581;0.2877;0.2525;0.0418,"[np.int64(-1), -1, -1, -1, -1]",61;-1;-1;-1;-1,61,61,Geometric Data Representation
Vis,1998,Development of a multi-source visualization prototype,10.1109/visual.1998.745331,http://dx.doi.org/10.1109/VISUAL.1998.745331,411.0,414.0,C,"This case study describes the design and development of VISOR (Visual Integration of Simulated and Observed Results), a tool which supports the visualization and analysis of a wide variety of data relevant to aerospace engineering design. Integrating data from such disparate sources is challenging; overcoming the obstacles results in a powerful tool. The process has also been valuable in exposing requirements for the libraries of reusable software tools for visualization and data analysis being developed at NASA Ames.",Leslie Keely;Samuel P. Uselton,L. Keely;S. Uselton,"MRJ Technology Solutions, NASA Ames Research Center, USA;MRJ Technology Solutions, NASA Ames Research Center, USA",10.1109/visual.1997.663911;10.1109/visual.1996.568115;10.1109/visual.1998.745332;10.1109/visual.1997.663911,,7.0,2.0,8.0,48.0,,,aerospace engineering design;tool supports visualization;simulated observed;visor;disparate sources challenging,0.5701;0.5344;0.2434;0.2080;0.1840,"[np.int64(-1), np.int64(-1), -1, -1, -1]",8;139;-1;-1;-1,8;139,8,Aerospace Design
Vis,2021,Rotate or Wrap? Interactive Visualisations of Cyclical Data on Cylindrical or Toroidal Topologies,10.1109/tvcg.2021.3114693,http://dx.doi.org/10.1109/TVCG.2021.3114693,727.0,736.0,J,"In this paper, we report on a study of visual representations for cyclical data and the effect of interactively <i>wrapping</i> a bar chart ‘around its boundaries’. Compared to linear bar chart, polar (or radial) visualisations have the advantage that cyclical data can be presented continuously without mentally bridging the visual ‘cut’ across the left-and-right boundaries. To investigate this hypothesis and to assess the effect the cut has on analysis performance, this paper presents results from a crowdsourced, controlled experiment with 72 participants comparing new continuous panning technique to linear bar charts (<i>interactive wrapping</i>). Our results show that bar charts with interactive wrapping lead to less errors compared to standard bar charts or polar charts. Inspired by these results, we generalise the concept of interactive wrapping to other visualisations for cyclical or relational data. We describe a design space based on the concept of one-dimensional wrapping and two-dimensional wrapping, linked to two common 3D topologies; cylinder and torus that can be used to metaphorically explain one- and two-dimensional wrapping. This design space suggests that interactive wrapping is widely applicable to many different data types.",Kun-Ting Chen;Tim Dwyer;Benjamin Bach;Kim Marriott,Kun-Ting Chen;Tim Dwyer;Benjamin Bach;Kim Marriott,"Monash University, Australia;Monash University, Australia;University of Edinburgh, United Kingdom;Monash University, Australia",10.1109/tvcg.2015.2467851;10.1109/tvcg.2018.2865234;10.1109/tvcg.2013.124;10.1109/tvcg.2014.2346320;10.1109/tvcg.2012.265;10.1109/tvcg.2019.2934784;10.1109/tvcg.2011.195;10.1109/tvcg.2015.2467851,"Cyclic temporal data,cylindrical topologies,toroidal topologies,interaction techniques,bar charts,polar charts,crowdsourced experiment",3.0,3.0,46.0,575.0,,,visualisations cyclical;bar chart boundaries;data;wrapping lead;compared standard,0.7131;0.4545;0.2595;0.1391;0.1243,"[np.int64(-1), -1, -1, -1, -1]",-1;-1;-1;-1;-1,,-1,Interactive 3D Visualization
VAST,2013,Vis4Heritage: Visual Analytics Approach on Grotto Wall Painting Degradations,10.1109/tvcg.2013.219,http://dx.doi.org/10.1109/TVCG.2013.219,1982.0,1991.0,J,"For preserving the grotto wall paintings and protecting these historic cultural icons from the damage and deterioration in nature environment, a visual analytics framework and a set of tools are proposed for the discovery of degradation patterns. In comparison with the traditional analysis methods that used restricted scales, our method provides users with multi-scale analytic support to study the problems on site, cave, wall and particular degradation area scales, through the application of multidimensional visualization techniques. Several case studies have been carried out using real-world wall painting data collected from a renowned World Heritage site, to verify the usability and effectiveness of the proposed method. User studies and expert reviews were also conducted through by domain experts ranging from scientists such as microenvironment researchers, archivists, geologists, chemists, to practitioners such as conservators, restorers and curators.",Jiawan Zhang;Kai Kang;Dajian Liu;Ye Yuan;E. Yanli,Jiawan Zhang;Kai Kang;Dajian Liu;Ye Yuan;Yanli E.,"School of Computer Software and Information Technology Research Center for Cultural Heritage Conservation and Promotion, Tianjin University, China;School of Computer Software, Tianjin University, China;School of Computer Software, Tianjin University, China;School of Computer Software, Tianjin University, China;School of Computer Software, Tianjin University, Tianjin, Tianjin, CN",10.1109/tvcg.2011.239;10.1109/infvis.2004.1;10.1109/tvcg.2008.173;10.1109/infvis.2005.1532138;10.1109/tvcg.2006.147;10.1109/tvcg.2012.244;10.1109/vast.2007.4389013;10.1109/tvcg.2008.153;10.1109/infvis.2000.885098;10.1109/vast.2010.5651617;10.1109/tvcg.2011.239,"Cultural heritage, wall paintings, degradation, visual analytics",15.0,16.0,46.0,820.0,,,environment visual analytics;researchers archivists geologists;deterioration nature;wall paintings protecting;restricted scales method,0.5279;0.4085;0.3877;0.3561;0.2646,"[np.int64(-1), -1, -1, -1, -1]",90;-1;-1;-1;-1,90,90,Immersive Visual Analytics
Vis,2004,Visualizing cortical waves and timing from data,10.1109/visual.2004.121,http://dx.doi.org/10.1109/VISUAL.2004.121,401.0,408.0,C,"Waves are a fundamental mechanism for conveying information in many physical problems. Direct visualization techniques are often used to display wave fronts. However, the information derived from such visualizations may not be as central to an investigation as an understanding of how the location, structure and time course of the wave change as key experimental parameters are varied. In experimental data, these questions are confounded by noise and incomplete data. Recognition of waves in networks of neurons is additionally complicated by the presence of long-range physical connections and recurrent excitation. This work applies visual techniques to analyze the structural details of waves in response data from the turtle visual cortex. We emphasize low-cost visualizations that allow comparisons across neural data sets and variables to reconstruct the choreography for a complex response.",Kay A. Robbins;Mark A. Robinson;David M. Senseman,K.A. Robbins;M. Robinson;D.M. Senseman,"Cajal Neuroscience Research Center, University of Texas, San Antonio, USA;University of Texas, San Antonio, USA;Cajal Neuroscience Research Center, University of Texas, San Antonio, USA",10.1109/visual.2001.964493;10.1109/visual.1990.146402;10.1109/visual.2000.885686;10.1109/visual.2001.964493,"waves, neural networks, PCA, KL decomposition, wave subspaces, flow visualization",5.0,1.0,26.0,82.0,,,waves networks neurons;low cost visualizations;response data turtle;reconstruct choreography;central investigation understanding,0.6304;0.3667;0.3293;0.2141;0.0791,"[np.int64(-1), -1, -1, -1, -1]",-1;-1;-1;-1;-1,,-1,Interactive 3D Visualization
Vis,1999,Visualizing the evolution of a subject domain: a case study,10.1109/visual.1999.809927,http://dx.doi.org/10.1109/VISUAL.1999.809927,449.0,561.0,C,"We explore the potential of information visualization techniques in enhancing existing methodologies for domain analysis and modeling. In this case study, we particularly focus on visualizing the evolution of the hypertext field based on author co-citation patterns, including the use of a sliding-window scheme to generate a series of annual snapshots of the domain structure, and a factor-referenced color-coding scheme to highlight predominant specialties in the field.",Chaomei Chen;Les Carr,C. Chen;L. Carr,"Brunei University, UK;Southampton University, UK",10.1109/visual.1993.398870;10.1109/visual.1993.398870,,67.0,10.0,13.0,110.0,,,visualizing evolution hypertext;predominant specialties field;color coding scheme;enhancing existing methodologies;generate series annual,0.5972;0.2668;0.2326;0.1940;0.0204,"[np.int64(-1), -1, -1, -1, -1]",-1;-1;-1;-1;-1,,-1,Interactive 3D Visualization
VAST,2015,Integrating predictive analytics into a spatiotemporal epidemic simulation,10.1109/vast.2015.7347626,http://dx.doi.org/10.1109/VAST.2015.7347626,17.0,24.0,C,"The Epidemic Simulation System (EpiSimS) is a scalable, complex modeling tool for analyzing disease within the United States. Due to its high input dimensionality, time requirements, and resource constraints, simulating over the entire parameter space is unfeasible. One solution is to take a granular sampling of the input space and use simpler predictive models (emulators) in between. The quality of the implemented emulator depends on many factors: robustness, sophistication, configuration, and suitability to the input data. Visual analytics can be leveraged to provide guidance and understanding of these things to the user. In this paper, we have implemented a novel interface and workflow for emulator building and use. We introduce a workflow to build emulators, make predictions, and then analyze the results. Our prediction process first predicts temporal time series, and uses these to derive predicted spatial densities. Integrated into the EpiSimS framework, we target users who are non-experts at statistical modeling. This approach allows for a high level of analysis into the state of the built emulators and their resultant predictions. We present our workflow, models, the associated system, and evaluate the overall utility with feedback from EpiSimS scientists.",Chris Bryan;Xue Wu;Susan M. Mniszewski;Kwan-Liu Ma,Chris Bryan;Xue Wu;Susan Mniszewski;Kwan-Liu Ma,VIDi;VIDi;Los Alamos National Lab;VIDi,10.1109/vast.2011.6102457;10.1109/infvis.1998.729563;10.1109/tvcg.2014.2346926;10.1109/tvcg.2013.125;10.1109/tvcg.2010.181;10.1109/tvcg.2014.2346321;10.1109/tvcg.2011.248;10.1109/tvcg.2012.190;10.1109/vast.2011.6102457,"Predictive Modeling, Visual Analytics, Epidemic Visualization, Spatial-Temporal Systems",24.0,14.0,36.0,658.0,,,epidemic simulation episims;derive predicted spatial;input data visual;present workflow models;build,0.7212;0.3014;0.3000;0.2237;0.0817,"[np.int64(-1), -1, -1, -1, -1]",1;-1;-1;-1;-1,1,1,Simulation Modeling
Vis,1994,"A distributed, parallel, interactive volume rendering package",10.1109/visual.1994.346341,http://dx.doi.org/10.1109/VISUAL.1994.346341,21.0,,C,"This paper presents a parallel ray-casting volume rendering algorithm and its implementation on the massively parallel IBM SP-1 computer using the Chameleon message passing library. Though this algorithm takes advantage of many of the unique features of the SP-1 (e.g. high-speed switch, large memory per node, high-speed disk array, HIPPI display, et al.), the use of Chameleon allows the code to be executed on any collection of workstations. The algorithm is image-ordered and distributes the data and the computational load to individual processors. After the volume data is distributed, all processors then perform local ray tracing of their respective subvolumes concurrently. No interprocess communication takes place during the ray tracing process. After a subimage is generated by each processor, the final image is obtained by composing subimages between all the processors. The program itself is implemented as an interactive process through a GUI residing on a graphics workstation which is coupled to the parallel rendering algorithm via sockets. The paper highlights the Chameleon implementation, the GUI, some optimization improvements, static load balancing, and direct parallel display to a HIPPI framebuffer.&lt;&lt;ETX&gt;&gt;",John S. Rowlan;G. Edward Lent;Nihar Gokhale;Shannon Bradshaw,J.S. Rowlan;G.E. Lent;N. Gokhale;S. Bradshaw,"Mathematics Computer Science Division, Argonne National Laboratory, Argonne, IL, USA;Mathematics Computer Science Division, Argonne National Laboratory, Argonne, IL, USA;Mathematics Computer Science Division, Argonne National Laboratory, Argonne, IL, USA;Mathematics Computer Science Division, Argonne National Laboratory, Argonne, IL, USA",,,58.0,9.0,11.0,65.0,,,parallel rendering algorithm;volume data;ibm sp computer;takes place ray;allows code executed,0.6638;0.3873;0.3332;0.2472;0.0031,"[np.int64(-1), -1, -1, -1, -1]",48;-1;-1;-1;-1,48,48,Scalable Graphics Processing
Vis,2022,BeauVis: A Validated Scale for Measuring the Aesthetic Pleasure of Visual Representations,10.1109/tvcg.2022.3209390,http://dx.doi.org/10.1109/TVCG.2022.3209390,363.0,373.0,J,"We developed and validated a rating scale to assess the aesthetic pleasure (or beauty) of a visual data representation: the BeauVis scale. With our work we offer researchers and practitioners a simple instrument to compare the visual appearance of different visualizations, unrelated to data or context of use. Our rating scale can, for example, be used to accompany results from controlled experiments or be used as informative data points during in-depth qualitative studies. Given the lack of an aesthetic pleasure scale dedicated to visualizations, researchers have mostly chosen their own terms to study or compare the aesthetic pleasure of visualizations. Yet, many terms are possible and currently no clear guidance on their effectiveness regarding the judgment of aesthetic pleasure exists. To solve this problem, we engaged in a multi-step research process to develop the first validated rating scale specifically for judging the aesthetic pleasure of a visualization (osf.io/fxs76). Our final BeauVis scale consists of five items, “enjoyable,” “likable,” “pleasing,” “nice,” and “appealing.” Beyond this scale itself, we contribute (a) a systematic review of the terms used in past research to capture aesthetics, (b) an investigation with visualization experts who suggested terms to use for judging the aesthetic pleasure of a visualization, and (c) a confirmatory survey in which we used our terms to study the aesthetic pleasure of a set of 3 visualizations.",Tingying He;Petra Isenberg;Raimund Dachselt;Tobias Isenberg 0001,Tingying He;Petra Isenberg;Raimund Dachselt;Tobias Isenberg,"Université Paris-Saclay, CNRS, Inria, LISN, France;Université Paris-Saclay, CNRS, Inria, LISN, France;Technische Universität Dresden, Germany;Université Paris-Saclay, CNRS, Inria, LISN, France",10.1109/infvis.2005.1532128;10.1109/tvcg.2006.187;10.1109/tvcg.2008.166;10.1109/tvcg.2020.3030411;10.1109/tvcg.2009.122;10.1109/infvis.1997.636793;10.1109/tvcg.2020.3030456;10.1109/tvcg.2010.134;10.1109/tvcg.2013.196;10.1109/tvcg.2010.199;10.1109/tvcg.2014.2352953;10.1109/tvcg.2020.3030400;10.1109/tvcg.2015.2467411;10.1109/tvcg.2012.189;10.1109/infvis.2005.1532128,"Aesthetics,aesthetic pleasure,validated scale,scale development,visual representations",,7.0,79.0,1083.0,,X,aesthetic pleasure visualizations;likable;data context use;contribute systematic review;set,0.8305;0.1944;0.1358;0.0676;0.0205,"[np.int64(-1), -1, -1, -1, -1]",131;-1;-1;-1;-1,131,131,Visual Aesthetics
VAST,2015,TargetVue: Visual Analysis of Anomalous User Behaviors in Online Communication Systems,10.1109/tvcg.2015.2467196,http://dx.doi.org/10.1109/TVCG.2015.2467196,280.0,289.0,J,"Users with anomalous behaviors in online communication systems (e.g. email and social medial platforms) are potential threats to society. Automated anomaly detection based on advanced machine learning techniques has been developed to combat this issue; challenges remain, though, due to the difficulty of obtaining proper ground truth for model training and evaluation. Therefore, substantial human judgment on the automated analysis results is often required to better adjust the performance of anomaly detection. Unfortunately, techniques that allow users to understand the analysis results more efficiently, to make a confident judgment about anomalies, and to explore data in their context, are still lacking. In this paper, we propose a novel visual analysis system, TargetVue, which detects anomalous users via an unsupervised learning model and visualizes the behaviors of suspicious users in behavior-rich context through novel visualization designs and multiple coordinated contextual views. Particularly, TargetVue incorporates three new ego-centric glyphs to visually summarize a user's behaviors which effectively present the user's communication activities, features, and social interactions. An efficient layout method is proposed to place these glyphs on a triangle grid, which captures similarities among users and facilitates comparisons of behaviors of different users. We demonstrate the power of TargetVue through its application in a social bot detection challenge using Twitter data, a case study based on email records, and an interview with expert users. Our evaluation shows that TargetVue is beneficial to the detection of users with anomalous communication behaviors.",Nan Cao 0001;Conglei Shi;W. Sabrina Lin;Jie Lu 0002;Yu-Ru Lin;Ching-Yung Lin,Nan Cao;Conglei Shi;Sabrina Lin;Jie Lu;Yu-Ru Lin;Ching-Yung Lin,IBM T. J. Watson Research Center;IBM T. J. Watson Research Center;IBM T. J. Watson Research Center;IBM T. J. Watson Research Center;University of Pissburg;IBM T. J. Watson Research Center,10.1109/tvcg.2012.291;10.1109/tvcg.2006.170;10.1109/visual.2002.1183816;10.1109/tvcg.2014.2346922;10.1109/tvcg.2012.291,"Anomaly Detection, Social Media, Visual Analysis",143.0,108.0,45.0,2928.0,,,anomalous users unsupervised;context novel visualization;place glyphs triangle;evaluation shows targetvue;allow,0.6253;0.3542;0.1719;0.1049;0.0575,"[np.int64(-1), -1, -1, -1, -1]",57;-1;-1;-1;-1,57,57,Anomaly Detection Techniques
Vis,2008,VisComplete: Automating Suggestions for Visualization Pipelines,10.1109/tvcg.2008.174,http://dx.doi.org/10.1109/TVCG.2008.174,1691.0,1698.0,J,"Building visualization and analysis pipelines is a large hurdle in the adoption of visualization and workflow systems by domain scientists. In this paper, we propose techniques to help users construct pipelines by consensus-automatically suggesting completions based on a database of previously created pipelines. In particular, we compute correspondences between existing pipeline subgraphs from the database, and use these to predict sets of likely pipeline additions to a given partial pipeline. By presenting these predictions in a carefully designed interface, users can create visualizations and other data products more efficiently because they can augment their normal work patterns with the suggested completions. We present an implementation of our technique in a publicly-available, open-source scientific workflow system and demonstrate efficiency gains in real-world situations.",David Koop;Carlos Eduardo Scheidegger;Steven P. Callahan;Juliana Freire;Cláudio T. Silva,D. Koop;C.E. Scheidegger;S.P. Callahan;J. Freire;C.T. Silva,"School of Computing, University of Utah, USA;Scientific Computing and Imaging (SCI) Institute, University of Utah, USA;Scientific Computing and Imaging (SCI) Institute, University of Utah, USA;School of Computing, University of Utah, USA;Scientific Computing and Imaging (SCI) Institute, University of Utah, USA",10.1109/tvcg.2007.70584;10.1109/tvcg.2007.70577;10.1109/visual.2005.1532834;10.1109/visual.2005.1532833;10.1109/visual.2005.1532788;10.1109/visual.2005.1532795;10.1109/tvcg.2007.70584,"Scientific Workflows, Scientific Visualization, Auto Completion",132.0,65.0,39.0,823.0,,,visualization workflow systems;automatically suggesting completions;sets likely pipeline;scientists paper propose;given partial,0.6855;0.4821;0.3692;0.2669;0.0022,"[np.int64(-1), -1, -1, -1, -1]",104;-1;-1;-1;-1,104,104,Visualization Systems
VAST,2020,A Visual Analytics Framework for Explaining and Diagnosing Transfer Learning Processes,10.1109/tvcg.2020.3028888,http://dx.doi.org/10.1109/TVCG.2020.3028888,1385.0,1395.0,J,"Many statistical learning models hold an assumption that the training data and the future unlabeled data are drawn from the same distribution. However, this assumption is difficult to fulfill in real-world scenarios and creates barriers in reusing existing labels from similar application domains. Transfer Learning is intended to relax this assumption by modeling relationships between domains, and is often applied in deep learning applications to reduce the demand for labeled data and training time. Despite recent advances in exploring deep learning models with visual analytics tools, little work has explored the issue of explaining and diagnosing the knowledge transfer process between deep learning models. In this paper, we present a visual analytics framework for the multi-level exploration of the transfer learning processes when training deep neural networks. Our framework establishes a multi-aspect design to explain how the learned knowledge from the existing model is transferred into the new learning task when training deep neural networks. Based on a comprehensive requirement and task analysis, we employ descriptive visualization with performance measures and detailed inspections of model behaviors from the statistical, instance, feature, and model structure levels. We demonstrate our framework through two case studies on image classification by fine-tuning AlexNets to illustrate how analysts can utilize our framework.",Yuxin Ma;Arlen Fan;Jingrui He;Arun Reddy Nelakurthi;Ross Maciejewski,Yuxin Ma;Arlen Fan;Jingrui He;Arun Reddy Nelakurthi;Ross Maciejewski,Arizona State University;Arizona State University;University of Illinois at Urbana-Champaign;Samsung Research America;Arizona State University,10.1109/tvcg.2019.2934262;10.1109/tvcg.2015.2467618;10.1109/tvcg.2017.2744683;10.1109/tvcg.2013.124;10.1109/vast47406.2019.8986948;10.1109/tvcg.2011.188;10.1109/tvcg.2019.2934261;10.1109/tvcg.2014.2346594;10.1109/tvcg.2017.2744199;10.1109/tvcg.2019.2934659;10.1109/tvcg.2017.2744718;10.1109/tvcg.2014.2346482;10.1109/tvcg.2018.2865027;10.1109/vast.2018.8802509;10.1109/tvcg.2017.2744938;10.1109/tvcg.2016.2598831;10.1109/tvcg.2017.2744378;10.1109/tvcg.2019.2934631;10.1109/vast.2017.8585721;10.1109/tvcg.2018.2864812;10.1109/tvcg.2014.2346578;10.1109/tvcg.2017.2744358;10.1109/tvcg.2012.207;10.1109/tvcg.2016.2598838;10.1109/tvcg.2016.2598828;10.1109/tvcg.2019.2934629;10.1109/tvcg.2018.2865044;10.1109/visual.2005.1532820;10.1109/tvcg.2018.2864504;10.1109/tvcg.2019.2934619;10.1109/tvcg.2017.2744878;10.1109/tvcg.2018.2864499;10.1109/tvcg.2016.2598541;10.1109/tvcg.2018.2864475;10.1109/tvcg.2017.2744158;10.1109/tvcg.2018.2864500;10.1109/tvcg.2019.2934262,"Transfer learning,deep learning,visual analytics",15.0,23.0,84.0,1065.0,,,transfer learning;visual analytics tools;explaining diagnosing;structure levels;time despite,0.5664;0.3132;0.2694;0.0745;0.0418,"[np.int64(-1), -1, -1, -1, -1]",13;-1;-1;-1;-1,13,13,Advanced Machine Learning
Vis,2024,Uncertainty Visualization of Critical Points of 2D Scalar Fields for Parametric and Nonparametric Probabilistic Models,10.1109/tvcg.2024.3456393,http://dx.doi.org/10.1109/TVCG.2024.3456393,108.0,118.0,J,"This paper presents a novel end-to-end framework for closed-form computation and visualization of critical point uncertainty in 2D uncertain scalar fields. Critical points are fundamental topological descriptors used in the visualization and analysis of scalar fields. The uncertainty inherent in data (e.g., observational and experimental data, approximations in simulations, and compression), however, creates uncertainty regarding critical point positions. Uncertainty in critical point positions, therefore, cannot be ignored, given their impact on downstream data analysis tasks. In this work, we study uncertainty in critical points as a function of uncertainty in data modeled with probability distributions. Although Monte Carlo (MC) sampling techniques have been used in prior studies to quantify critical point uncertainty, they are often expensive and are infrequently used in production-quality visualization software. We, therefore, propose a new end-to-end framework to address these challenges that comprises a threefold contribution. First, we derive the critical point uncertainty in closed form, which is more accurate and efficient than the conventional MC sampling methods. Specifically, we provide the closed-form and semianalytical (a mix of closed-form and MC methods) solutions for parametric (e.g., uniform, Epanechnikov) and nonparametric models (e.g., histograms) with finite support. Second, we accelerate critical point probability computations using a parallel implementation with the VTK-m library, which is platform portable. Finally, we demonstrate the integration of our implementation with the ParaView software system to demonstrate near-real-time results for real datasets.",Tushar M. Athawale;Zhe Wang;David Pugmire;Kenneth Moreland;Qian Gong;Scott Klasky;Chris R. Johnson 0001;Paul Rosen 0001,Tushar M. Athawale;Zhe Wang;David Pugmire;Kenneth Moreland;Qian Gong;Scott Klasky;Chris R. Johnson;Paul Rosen,"Oak Ridge National Laboratory, USA;Oak Ridge National Laboratory, USA;Oak Ridge National Laboratory, USA;Oak Ridge National Laboratory, USA;Oak Ridge National Laboratory, USA;Oak Ridge National Laboratory, USA;University of Utah, USA;University of Utah, USA",10.1109/tvcg.2013.208;10.1109/tvcg.2022.3209424;10.1109/tvcg.2020.3030394;10.1109/tvcg.2015.2467958;10.1109/tvcg.2023.3326592;10.1109/tvcg.2015.2467204;10.1109/visual.2002.1183769;10.1109/visual.2005.1532839;10.1109/tvcg.2017.2744099;10.1109/tvcg.2007.70518;10.1109/tvcg.2012.249;10.1109/tvcg.2017.2743938;10.1109/tvcg.2019.2934256;10.1109/tvcg.2019.2934242,"Topology,uncertainty,,,critical points,probabilistic analysis",,0.0,70.0,160.0,,,uncertainty critical points;visualization software propose;scalar fields;simulations compression creates;uniform,0.5196;0.3073;0.2860;0.2676;0.0331,"[np.int64(-1), -1, -1, -1, -1]",36;-1;-1;-1;-1,36,36,Uncertainty Visualization
VAST,2010,A continuous analysis process between desktop and collaborative visual analytics environments,10.1109/vast.2010.5652958,http://dx.doi.org/10.1109/VAST.2010.5652958,231.0,232.0,M,"Since its inception, the field of visual analytics has undergone tremendous growth in understanding how to create interactive visual tools to solve analytical problems. However, with few exceptions, most of these tools have been designed for single users in desktop environments. While often effective on their own, most single-user systems do not reflect the collaborative nature of solving real-world analytical tasks. Many intelligence analysts, for example, have been observed to switch repeatedly between working alone and collaborating with members of a small team. In this paper, we propose that a complete visual analytical system designed for solving real-world tasks ought to have two integrated components: a single-user desktop system and a mirroring system suitable for a collaborative environment.",Dong Hyun Jeong;Evan A. Suma;Thomas Butkiewicz;William Ribarsky;Remco Chang,Dong Hyun Jeong;Evan Suma;Thomas Butkiewicz;William Ribarsky;Remco Chang,"University of District of Columbia, USA and University of North Carolina, Charlotte, USA;University of North Carolina, Charlotte, USA and University of Southern California, USA;University of North Carolina, Charlotte, USA;University of North Carolina, Charlotte, USA;University of North Carolina, Charlotte, USA and Tufts University, USA",,,1.0,2.0,2.0,150.0,,,visual analytics;single user desktop;repeatedly working collaborating;solving real;undergone,0.7263;0.3538;0.3308;0.0494;-0.0088,"[np.int64(-1), -1, -1, -1, -1]",108;-1;-1;-1;-1,108,108,Visual Analytics
SciVis,2020,Visual Analysis of Large Multivariate Scattered Data using Clustering and Probabilistic Summaries,10.1109/tvcg.2020.3030379,http://dx.doi.org/10.1109/TVCG.2020.3030379,1580.0,1590.0,J,"Rapidly growing data sizes of scientific simulations pose significant challenges for interactive visualization and analysis techniques. In this work, we propose a compact probabilistic representation to interactively visualize large scattered datasets. In contrast to previous approaches that represent blocks of volumetric data using probability distributions, we model clusters of arbitrarily structured multivariate data. In detail, we discuss how to efficiently represent and store a high-dimensional distribution for each cluster. We observe that it suffices to consider low-dimensional marginal distributions for two or three data dimensions at a time to employ common visual analysis techniques. Based on this observation, we represent high-dimensional distributions by combinations of low-dimensional Gaussian mixture models. We discuss the application of common interactive visual analysis techniques to this representation. In particular, we investigate several frequency-based views, such as density plots in 1D and 2D, density-based parallel coordinates, and a time histogram. We visualize the uncertainty introduced by the representation, discuss a level-of-detail mechanism, and explicitly visualize outliers. Furthermore, we propose a spatial visualization by splatting anisotropic 3D Gaussians for which we derive a closed-form solution. Lastly, we describe the application of brushing and linking to this clustered representation. Our evaluation on several large, real-world datasets demonstrates the scaling of our approach.",Tobias Rapp;Christoph Peters 0002;Carsten Dachsbacher,Tobias Rapp;Christoph Peters;Carsten Dachsbacher,Karlsruhe Institute of Technology;Karlsruhe Institute of Technology;Karlsruhe Institute of Technology,10.1109/infvis.2004.68;10.1109/tvcg.2008.119;10.1109/tvcg.2008.131;10.1109/visual.2003.1250389;10.1109/tvcg.2016.2598604;10.1109/tvcg.2010.176;10.1109/tvcg.2017.2744099;10.1109/tvcg.2018.2864801;10.1109/tvcg.2009.131;10.1109/infvis.2005.1532138;10.1109/tvcg.2006.170;10.1109/tvcg.2019.2934335;10.1109/tvcg.2014.2346324;10.1109/visual.2001.964490;10.1109/infvis.2004.68,"interactive visual analysis,probabilistic data summaries,multivariate data,scattered data,Gaussian mixture models,Gaussian rendering",2.0,7.0,49.0,642.0,,,spatial visualization splatting;store high dimensional;time histogram;gaussians derive closed;consider low,0.6011;0.3174;0.2361;0.1865;0.0355,"[np.int64(-1), -1, -1, -1, -1]",146;-1;-1;-1;-1,146,146,Visualization Techniques
VAST,2013,Visual Traffic Jam Analysis Based on Trajectory Data,10.1109/tvcg.2013.228,http://dx.doi.org/10.1109/TVCG.2013.228,2159.0,2168.0,J,"In this work, we present an interactive system for visual analysis of urban traffic congestion based on GPS trajectories. For these trajectories we develop strategies to extract and derive traffic jam information. After cleaning the trajectories, they are matched to a road network. Subsequently, traffic speed on each road segment is computed and traffic jam events are automatically detected. Spatially and temporally related events are concatenated in, so-called, traffic jam propagation graphs. These graphs form a high-level description of a traffic jam and its propagation in time and space. Our system provides multiple views for visually exploring and analyzing the traffic condition of a large city as a whole, on the level of propagation graphs, and on road segment level. Case studies with 24 days of taxi GPS trajectories collected in Beijing demonstrate the effectiveness of our system.",Zuchao Wang;Min Lu 0002;Xiaoru Yuan;Junping Zhang;Huub van de Wetering,Zuchao Wang;Min Lu;Xiaoru Yuan;Junping Zhang;Huub van de Wetering,"Key Laboratory of Machine Perception (Ministry of Education), Peking University, China;Key Laboratory of Machine Perception (Ministry of Education), Peking University, China;Shanghai Key Laboratory of Intelligent Information Processing, and School of Computer Science, Fudan University, China and Key Laboratory of Machine Perception (Ministry of Education), Peking University;Shanghai Key Laboratory of Intelligent Information Processing, Fudan University, China;Department of Mathematics and Computer Science, Technische Universiteit Eindhoven, Eindhoven, Noord-Brabant, NL",10.1109/visual.1997.663866;10.1109/vast.2011.6102454;10.1109/tvcg.2009.145;10.1109/vast.2012.6400556;10.1109/infvis.2004.27;10.1109/vast.2008.4677356;10.1109/tvcg.2011.202;10.1109/vast.2012.6400553;10.1109/tvcg.2012.265;10.1109/tvcg.2011.181;10.1109/vast.2009.5332593;10.1109/tvcg.2008.125;10.1109/vast.2011.6102455;10.1109/vast.2010.5653580,"Traffic visualization, traffic jam propagation",401.0,263.0,54.0,7804.0,,,traffic jam information;visually exploring;cleaning trajectories matched;propagation time;extract derive,0.6824;0.2988;0.2927;0.1414;0.0307,"[np.int64(-1), -1, -1, -1, -1]",6;-1;-1;-1;-1,6,6,Geospatial Data Analysis
InfoVis,2020,Cartographic Relief Shading with Neural Networks,10.1109/tvcg.2020.3030456,http://dx.doi.org/10.1109/TVCG.2020.3030456,1225.0,1235.0,J,"Shaded relief is an effective method for visualising terrain on topographic maps, especially when the direction of illumination is adapted locally to emphasise individual terrain features. However, digital shading algorithms are unable to fully match the expressiveness of hand-crafted masterpieces, which are created through a laborious process by highly specialised cartographers. We replicate hand-drawn relief shading using U-Net neural networks. The deep neural networks are trained with manual shaded relief images of the Swiss topographic map series and terrain models of the same area. The networks generate shaded relief that closely resemble hand-drawn shaded relief art. The networks learn essential design principles from manual relief shading such as removing unnecessary terrain details, locally adjusting the illumination direction to accentuate individual terrain features, and varying brightness to emphasise larger landforms. Neural network shadings are generated from digital elevation models in a few seconds, and a study with 18 relief shading experts found that they are of high quality.",Bernhard Jenny;Magnus Heitzler;Dilpreet Singh;Marianna Farmakis-Serebryakova;Jeffery Chieh Liu;Lorenz Hurni,Bernhard Jenny;Magnus Heitzler;Dilpreet Singh;Marianna Farmakis-Serebryakova;Jeffery Chieh Liu;Lorenz Hurni,"Monash University, Melbourne;Institute of Cartography and Geoinformation, ETH, Zurich;Monash University, Melbourne;Institute of Cartography and Geoinformation, ETH, Zurich;Monash University, Melbourne;Institute of Cartography and Geoinformation, ETH, Zurich",10.1109/tvcg.2006.172;10.1109/tvcg.2006.172,"Relief shading,shaded relief,hillshade,neural rendering,illustrative visualisation,image-to-image translation",26.0,31.0,82.0,1024.0,,,visualising terrain topographic;deep neural;masterpieces created;adjusting illumination;study 18 relief,0.5775;0.4422;0.2537;0.2193;0.1283,"[np.int64(-1), -1, -1, -1, -1]",80;-1;-1;-1;-1,80,80,Terrain Visualization
Vis,1992,Approximation and rendering of volume data using wavelet transforms,10.1109/visual.1992.235230,http://dx.doi.org/10.1109/VISUAL.1992.235230,21.0,28.0,C,"A method is presented to obtain a unique shape description of an object by using wavelet transforms. Wavelet transform is a signal analysis technique which decomposes a signal using a family of functions having a local property in both time and frequency domains. A multiresolution expression of 3D volume data was first obtained by applying 3D orthogonal wavelet transforms, with the shape then being approximated with a relatively small number of 3D orthogonal functions using only the significant functions. In addition, the resolution of the approximation can be varied point by point using the local property of the wavelets. The method is applied to real volume data, i.e. facial range data and MR images of a human head, and typical results are shown.&lt;&lt;ETX&gt;&gt;",Shigeru Muraki,S. Muraki,"Image Understanding Section, ElectroTechnical Laboratory, Tsukuba, Japan",,,,31.0,17.0,99.0,,,wavelet transforms;3d volume;human head typical;using local property;applied,0.6785;0.3675;0.2745;0.0667;0.0580,"[np.int64(-1), -1, -1, -1, -1]",22;-1;-1;-1;-1,22,22,Wavelet Techniques
InfoVis,2008,Who Votes For What? A Visual Query Language for Opinion Data,10.1109/tvcg.2008.187,http://dx.doi.org/10.1109/TVCG.2008.187,1197.0,1204.0,J,"Surveys and opinion polls are extremely popular in the media, especially in the months preceding a general election. However, the available tools for analyzing poll results often require specialized training. Hence, data analysis remains out of reach for many casual computer users. Moreover, the visualizations used to communicate the results of surveys are typically limited to traditional statistical graphics like bar graphs and pie charts, both of which are fundamentally noninteractive. We present a simple interactive visualization that allows users to construct queries on large tabular data sets, and view the results in real time. The results of two separate user studies suggest that our interface lowers the learning curve for naive users, while still providing enough analytical power to discover interesting correlations in the data.",Geoffrey M. Draper;Richard F. Riesenfeld,Geoffrey Draper;Richard Riesenfeld,"School of Computing, University of Utah, USA; School of Computing, University of Utah, USA",10.1109/tvcg.2007.70584;10.1109/infvis.1996.559210;10.1109/infvis.2005.1532134;10.1109/infvis.2001.963279;10.1109/visual.1990.146402;10.1109/tvcg.2007.70617;10.1109/vast.2006.261438;10.1109/infvis.1998.729570;10.1109/infvis.2001.963287;10.1109/infvis.2000.885086;10.1109/tvcg.2007.70539;10.1109/vast.2007.4389013;10.1109/infvis.2000.885091;10.1109/tvcg.2007.70577;10.1109/tvcg.2006.147;10.1109/tvcg.2007.70584,"Visual query languages, radial visualization, data analysis, human-computer interaction",43.0,16.0,45.0,406.0,,,analyzing poll results;data sets view;casual computer users;graphics like bar;lowers learning curve,0.6404;0.4228;0.3299;0.3166;0.1016,"[np.int64(-1), -1, -1, -1, -1]",25;-1;-1;-1;-1,25,25,Data Interpretation Challenges
Vis,2005,OpenGL multipipe SDK: a toolkit for scalable parallel rendering,10.1109/visual.2005.1532786,http://dx.doi.org/10.1109/VISUAL.2005.1532786,119.0,126.0,C,"We describe OpenGL multipipe SDK (MPK), a toolkit for scalable parallel rendering based on OpenGL. MPK provides a uniform application programming interface (API) to manage scalable graphics applications across many different graphics subsystems. MPK-based applications run seamlessly from single-processor, single-pipe desktop systems to large multi-processor, multipipe scalable graphics systems. The application is oblivious of the system configuration, which can be specified through a configuration file at run time. To scale application performance, MPK uses a decomposition system that supports different modes for task partitioning and implements optimized CPU-based composition algorithms. MPK also provides a customizable image composition interface, which can be used to apply post-processing algorithms on raw pixel data obtained from executing sub-tasks on multiple graphics pipes in parallel. This can be used to implement parallel versions of any CPU-based algorithm, not necessarily used for rendering. In this paper, we motivate the need for a scalable graphics API and discuss the architecture of MPK. We present MPK's graphics configuration interface, introduce the notion of compound-based decomposition schemes and describe our implementation. We present some results from our work on a couple of target system architectures and conclude with future directions of research in this area.",Praveen Bhaniramka;Philippe C. D. Robert;Stefan Eilemann,Praveen Bhaniramka;P.C.D. Robert;S. Eilemann,"Silicon Graphics, Inc.;University of Bern, Switzerland;University of Zurich, Switzerland",10.1109/visual.1999.809890;10.1109/visual.1999.809890,"Scalable Rendering, Parallel Rendering, Immersive Environments, Scalable Graphics Hardware",55.0,4.0,39.0,330.0,,,multipipe scalable graphics;sdk mpk;executing sub tasks;conclude;specified configuration file,0.7502;0.2575;0.2068;0.0668;0.0034,"[np.int64(-1), -1, -1, -1, -1]",48;-1;-1;-1;-1,48,48,Scalable Graphics Processing
InfoVis,2016,Screenit: Visual Analysis of Cellular Screens,10.1109/tvcg.2016.2598587,http://dx.doi.org/10.1109/TVCG.2016.2598587,591.0,600.0,J,"High-throughput and high-content screening enables large scale, cost-effective experiments in which cell cultures are exposed to a wide spectrum of drugs. The resulting multivariate data sets have a large but shallow hierarchical structure. The deepest level of this structure describes cells in terms of numeric features that are derived from image data. The subsequent level describes enveloping cell cultures in terms of imposed experiment conditions (exposure to drugs). We present Screenit, a visual analysis approach designed in close collaboration with screening experts. Screenit enables the navigation and analysis of multivariate data at multiple hierarchy levels and at multiple levels of detail. Screenit integrates the interactive modeling of cell physical states (phenotypes) and the effects of drugs on cell cultures (hits). In addition, quality control is enabled via the detection of anomalies that indicate low-quality data, while providing an interface that is designed to match workflows of screening experts. We demonstrate analyses for a real-world data set, CellMorph, with 6 million cells across 20,000 cell cultures.",Kasper Dinkla;Hendrik Strobelt;Bryan Genest;Stephan Reiling;Mark Borowsky;Hanspeter Pfister,Kasper Dinkla;Hendrik Strobelt;Bryan Genest;Stephan Reiling;Mark Borowsky;Hanspeter Pfister,Harvard University;Harvard University;Novartis Institute of BioMedical Research;Novartis Institute of BioMedical Research;Novartis Institute of BioMedical Research;Harvard University,10.1109/vast.2012.6400492;10.1109/tvcg.2014.2346752;10.1109/tvcg.2015.2466971;10.1109/tvcg.2011.253;10.1109/vast.2010.5652443;10.1109/tvcg.2012.213;10.1109/tvcg.2014.2346578;10.1109/tvcg.2013.173;10.1109/vast.2011.6102453;10.1109/tvcg.2014.2346482;10.1109/vast.2012.6400492,High-content screening;visual analysis;feature selection;image classification;biology;multivariate;hierarchy,9.0,8.0,48.0,717.0,,,interactive modeling cell;multivariate data sets;drugs present screenit;level describes enveloping;million,0.4817;0.2973;0.2717;0.1286;0.0104,"[-1, -1, -1, -1, -1]",-1;-1;-1;-1;-1,,-1,Interactive 3D Visualization
Vis,2022,A Scanner Deeply: Predicting Gaze Heatmaps on Visualizations Using Crowdsourced Eye Movement Data,10.1109/tvcg.2022.3209472,http://dx.doi.org/10.1109/TVCG.2022.3209472,396.0,406.0,J,"Visual perception is a key component of data visualization. Much prior empirical work uses eye movement as a proxy to understand human visual perception. Diverse apparatus and techniques have been proposed to collect eye movements, but there is still no optimal approach. In this paper, we review 30 prior works for collecting eye movements based on three axes: (1) the tracker technology used to measure eye movements; (2) the image stimulus shown to participants; and (3) the collection methodology used to gather the data. Based on this taxonomy, we employ a webcam-based eyetracking approach using task-specific visualizations as the stimulus. The low technology requirement means that virtually anyone can participate, thus enabling us to collect data at large scale using crowdsourcing: approximately 12,000 samples in total. Choosing visualization images as stimulus means that the eye movements will be specific to perceptual tasks associated with visualization. We use these data to propose a Scanner Deeply, a virtual eyetracker model that, given an image of a visualization, generates a gaze heatmap for that image. We employ a computationally efficient, yet powerful convolutional neural network for our model. We compare the results of our work with results from the DVS model and a neural network trained on the Salicon dataset. The analysis of our gaze patterns enables us to understand how users grasp the structure of visualized data. We also make our stimulus dataset of visualization images available as part of this paper's contribution.",Sungbok Shin;Sunghyo Chung;Sanghyun Hong 0001;Niklas Elmqvist,Sungbok Shin;Sunghyo Chung;Sanghyun Hong;Niklas Elmqvist,"University of Maryland, College Park, USA;Kakao Corp., South Korea;Oregon State University, USA;University of Maryland, College Park, USA",10.1109/tvcg.2015.2467732;10.1109/tvcg.2011.193;10.1109/tvcg.2018.2865138;10.1109/tvcg.2012.215;10.1109/tvcg.2015.2467195;10.1109/tvcg.2017.2743939;10.1109/tvcg.2015.2467732,"Gaze prediction,visualization,webcam-based eye-tracking,crowdsourcing,deep learning",,1.0,72.0,1262.0,,,deeply virtual eyetracker;heatmap image employ;collection methodology used;large;proxy understand,0.6366;0.3338;0.1759;0.0985;0.0177,"[np.int64(-1), -1, -1, -1, -1]",50;-1;-1;-1;-1,50,50,Virtual Reality Technology
Vis,2008,Geodesic Distance-weighted Shape Vector Image Diffusion,10.1109/tvcg.2008.134,http://dx.doi.org/10.1109/TVCG.2008.134,1643.0,1650.0,J,"This paper presents a novel and efficient surface matching and visualization framework through the geodesic distance-weighted shape vector image diffusion. Based on conformal geometry, our approach can uniquely map a 3D surface to a canonical rectangular domain and encode the shape characteristics (e.g., mean curvatures and conformal factors) of the surface in the 2D domain to construct a geodesic distance-weighted shape vector image, where the distances between sampling pixels are not uniform but the actual geodesic distances on the manifold. Through the novel geodesic distance-weighted shape vector image diffusion presented in this paper, we can create a multiscale diffusion space, in which the cross-scale extrema can be detected as the robust geometric features for the matching and registration of surfaces. Therefore, statistical analysis and visualization of surface properties across subjects become readily available. The experiments on scanned surface models show that our method is very robust for feature extraction and surface matching even under noise and resolution change. We have also applied the framework on the real 3D human neocortical surfaces, and demonstrated the excellent performance of our approach in statistical analysis and integrated visualization of the multimodality volumetric data over the shape vector image.",Jing Hua 0001;Zhaoqiang Lai;Ming Dong 0001;Xianfeng Gu;Hong Qin 0001,Jing Hua;Zhaoqiang Lai;Ming Dong;Xianfeng Gu;Hong Qin,"Wayne State University, USA;Wayne State University, USA;Wayne State University, USA;Stony Brook University, USA;Stony Brook University, USA",,"Surface Matching, Shape Vector Image, Multiscale Diffusion, Visualization",54.0,31.0,32.0,436.0,,,surface matching visualization;multiscale diffusion space;novel geodesic;human neocortical;encode,0.5559;0.4570;0.3771;0.2295;0.0152,"[np.int64(-1), -1, -1, -1, -1]",126;-1;-1;-1;-1,126,126,Geometric Mesh Processing
InfoVis,2020,"Comparative Layouts Revisited: Design Space, Guidelines, and Future Directions",10.1109/tvcg.2020.3030419,http://dx.doi.org/10.1109/TVCG.2020.3030419,1525.0,1535.0,J,"We present a systematic review on three comparative layouts-juxtaposition, superposition, and explicit-encoding-which are information visualization (InfoVis) layouts designed to support comparison tasks. For the last decade, these layouts have served as fundamental idioms in designing many visualization systems. However, we found that the layouts have been used with inconsistent terms and confusion, and the lessons from previous studies are fragmented. The goal of our research is to distill the results from previous studies into a consistent and reusable framework. We review 127 research papers, including 15 papers with quantitative user studies, which employed comparative layouts. We first alleviate the ambiguous boundaries in the design space of comparative layouts by suggesting lucid terminology (e.g., chart-wise and item-wise juxtaposition). We then identify the diverse aspects of comparative layouts, such as the advantages and concerns of using each layout in the real-world scenarios and researchers' approaches to overcome the concerns. Building our knowledge on top of the initial insights gained from the Gleicher et al.'s survey [19], we elaborate on relevant empirical evidence that we distilled from our survey (e.g., the actual effectiveness of the layouts in different study settings) and identify novel facets that the original work did not cover (e.g., the familiarity of the layouts to people). Finally, we show the consistent and contradictory results on the performance of comparative layouts and offer practical implications for using the layouts by suggesting trade-offs and seven actionable guidelines.",Sehi L'Yi;Jaemin Jo;Jinwook Seo,Sehi LYi;Jaemin Jo;Jinwook Seo,Harvard Medical School;Sungkyunkwan University;Seoul National University,10.1109/tvcg.2007.70535;10.1109/tvcg.2017.2744199;10.1109/tvcg.2010.164;10.1109/tvcg.2007.70623;10.1109/tvcg.2007.70539;10.1109/tvcg.2019.2934786;10.1109/tvcg.2010.162;10.1109/tvcg.2013.122;10.1109/vast.2018.8802454;10.1109/tvcg.2013.161;10.1109/tvcg.2017.2745298;10.1109/tvcg.2019.2934801;10.1109/tvcg.2018.2864884;10.1109/tvcg.2017.2744198;10.1109/tvcg.2013.149;10.1109/tvcg.2013.233;10.1109/tvcg.2013.213;10.1109/tvcg.2016.2598796;10.1109/tvcg.2014.2346320;10.1109/tvcg.2012.237;10.1109/tvcg.2015.2467751;10.1109/tvcg.2018.2864510;10.1109/tvcg.2007.70535,"Comparative layout,visual comparison,literature review,juxtaposition,superposition,explicit-encoding",16.0,22.0,74.0,1471.0,,,visualization systems layouts;systematic review comparative;item wise;superposition explicit;relevant,0.6779;0.2878;0.1690;0.0677;0.0285,"[np.int64(-1), -1, -1, -1, -1]",103;-1;-1;-1;-1,103,103,Visualization Design
InfoVis,2004,Visualizing and Interacting with Multi-Tree Hierarchical Data,10.1109/infvis.2004.74,http://dx.doi.org/10.1109/INFVIS.2004.74,15.0,15.0,M,This work focuses on visualizing highly cyclic hierarchical data. A user interface is discussed and its interaction is illustrated using a recipe database example. This example showcases a database with multiple categories for each recipe (database entry).,Mahnas Jean Mohammadi-Aragh;T. J. Jankun-Kelly,M.J. Mohammadi-Aragh;T.J. Jankun-Kelly,"Visualization, Analysis, and Imaging Laboratory, GeoResources Institute, Engineering Research Center, Mississippi State University, MS, USA;Department of Computer Science and Engineering, Mississippi State University, MS, USA",0.1109/infvis.2003.1249009,,0.0,0.0,5.0,99.0,,,cyclic hierarchical data;illustrated using recipe;showcases database multiple;highly;work focuses,0.6714;0.3648;0.3184;0.0768;0.0161,"[np.int64(-1), -1, -1, -1, -1]",-1;-1;-1;-1;-1,,-1,Interactive 3D Visualization
SciVis,2016,Correlated Photon Mapping for Interactive Global Illumination of Time-Varying Volumetric Data,10.1109/tvcg.2016.2598430,http://dx.doi.org/10.1109/TVCG.2016.2598430,901.0,910.0,J,"We present a method for interactive global illumination of both static and time-varying volumetric data based on reduction of the overhead associated with re-computation of photon maps. Our method uses the identification of photon traces invariant to changes of visual parameters such as the transfer function (TF), or data changes between time-steps in a 4D volume. This lets us operate on a variant subset of the entire photon distribution. The amount of computation required in the two stages of the photon mapping process, namely tracing and gathering, can thus be reduced to the subset that are affected by a data or visual parameter change. We rely on two different types of information from the original data to identify the regions that have changed. A low resolution uniform grid containing the minimum and maximum data values of the original data is derived for each time step. Similarly, for two consecutive time-steps, a low resolution grid containing the difference between the overlapping data is used. We show that this compact metadata can be combined with the transfer function to identify the regions that have changed. Each photon traverses the low-resolution grid to identify if it can be directly transferred to the next photon distribution state or if it needs to be recomputed. An efficient representation of the photon distribution is presented leading to an order of magnitude improved performance of the raycasting step. The utility of the method is demonstrated in several examples that show visual fidelity, as well as performance. The examples show that visual quality can be retained when the fraction of retraced photons is as low as 40%-50%.",Daniel Jönsson;Anders Ynnerman,Daniel Jönsson;Anders Ynnerman,"Linköping University, Nörrköping, Sweden;Linköping University, Nörrköping, Sweden",10.1109/tvcg.2011.161;10.1109/tvcg.2014.2346333;10.1109/tvcg.2012.232;10.1109/tvcg.2007.70518;10.1109/tvcg.2011.198;10.1109/tvcg.2011.211;10.1109/tvcg.2011.161,Volume rendering;photon mapping;global illumination;participating media,22.0,17.0,45.0,875.0,HM,,photon maps;varying volumetric data;interactive global;needs recomputed efficient;derived time step,0.5950;0.3210;0.1762;0.1168;0.1034,"[np.int64(-1), -1, -1, -1, -1]",141;-1;-1;-1;-1,141,141,Advanced Rendering Techniques
InfoVis,2016,An Evaluation of Visual Search Support in Maps,10.1109/tvcg.2016.2598898,http://dx.doi.org/10.1109/TVCG.2016.2598898,421.0,430.0,J,"Visual search can be time-consuming, especially if the scene contains a large number of possibly relevant objects. An instance of this problem is present when using geographic or schematic maps with many different elements representing cities, streets, sights, and the like. Unless the map is well-known to the reader, the full map or at least large parts of it must be scanned to find the elements of interest. In this paper, we present a controlled eye-tracking study (30 participants) to compare four variants of map annotation with labels: within-image annotations, grid reference annotation, directional annotation, and miniature annotation. Within-image annotation places labels directly within the map without any further search support. Grid reference annotation corresponds to the traditional approach known from atlases. Directional annotation utilizes a label in combination with an arrow pointing in the direction of the label within the map. Miniature annotation shows a miniature grid to guide the reader to the area of the map in which the label is located. The study results show that within-image annotation is outperformed by all other annotation approaches. Best task completion times are achieved with miniature annotation. The analysis of eye-movement data reveals that participants applied significantly different visual task solution strategies for the different visual annotations.",Rudolf Netzel;Marcel Hlawatsch;Michael Burch;Sanjeev Balakrishnan;Hansjörg Schmauder;Daniel Weiskopf,Rudolf Netzel;Marcel Hlawatsch;Michael Burch;Sanjeev Balakrishnan;Hansjörg Schmauder;Daniel Weiskopf,"VISUS, University of Stuttgart;VISUS, University of Stuttgart;VISUS, University of Stuttgart;VISUS, University of Stuttgart;VISUS, University of Stuttgart;VISUS, University of Stuttgart",10.1109/tvcg.2014.2346420;10.1109/tvcg.2010.191;10.1109/tvcg.2014.2346420,Visual search;laboratory study;eye tracking;map visualization,29.0,15.0,37.0,1064.0,,,map miniature annotation;eye tracking study;search support;different elements;unless,0.6142;0.3966;0.2876;0.0886;0.0104,"[np.int64(-1), -1, -1, -1, -1]",132;-1;-1;-1;-1,132,132,Geographic Visualization Techniques
InfoVis,2007,Geographically Weighted Visualization: Interactive Graphics for Scale-Varying Exploratory Analysis,10.1109/tvcg.2007.70558,http://dx.doi.org/10.1109/TVCG.2007.70558,1161.0,1168.0,J,"We introduce a series of geographically weighted (GW) interactive graphics, or geowigs, and use them to explore spatial relationships at a range of scales. We visually encode information about geographic and statistical proximity and variation in novel ways through &lt;i&gt;gw-choropleth maps&lt;/i&gt;, multivariate &lt;i&gt;gw-boxplots, gw-shading&lt;/i&gt; and &lt;i&gt;scalograms&lt;/i&gt;. The new graphic types reveal information about GW statistics at several scales concurrently. We impement these views in prototype software containing dynamic links and GW interactions that encourage exploration and refine them to consider directional geographies. An informal evaluation uses interactive GW techniques to consider Guerry's dataset of 'moral statistics', casting doubt on correlations originally proposed through visual analysis, revealing new local anomalies and suggesting multivariate geographic relationships. Few attempts at visually synthesising geography with multivariate statistical values at multiple scales have been reported. The &lt;i&gt;geowigs &lt;/i&gt;proposed here provide informative representations of multivariate local variation, particularly when combined with interactions that coordinate views and result in &lt;i&gt;gw-shading&lt;/i&gt;. We argue that they are widely applicable to area and point-based geographic data and provide a set of methods to support visual analysis using GW statistics through which the effects of geography can be explored at multiple scales.",Jason Dykes;Chris Brunsdon,Jason Dykes;Chris Brunsdon,"Department of Information Science, City University, London, UK;Department of Geography, University of Leicester, Leicester, UK",,"Geographical weighting, exploratory data analysis, scale, multivariate, directional, interaction, coordinated views",68.0,50.0,21.0,861.0,,,visually synthesising geography;series geographically weighted;statistical values;interactions encourage;gw,0.6714;0.3647;0.2226;0.1621;0.0806,"[np.int64(-1), -1, -1, -1, -1]",132;-1;-1;-1;-1,132,132,Geographic Visualization Techniques
InfoVis,2017,Data Visualization Saliency Model: A Tool for Evaluating Abstract Data Visualizations,10.1109/tvcg.2017.2743939,http://dx.doi.org/10.1109/TVCG.2017.2743939,563.0,573.0,J,"Evaluating the effectiveness of data visualizations is a challenging undertaking and often relies on one-off studies that test a visualization in the context of one specific task. Researchers across the fields of data science, visualization, and human-computer interaction are calling for foundational tools and principles that could be applied to assessing the effectiveness of data visualizations in a more rapid and generalizable manner. One possibility for such a tool is a model of visual saliency for data visualizations. Visual saliency models are typically based on the properties of the human visual cortex and predict which areas of a scene have visual features (e.g. color, luminance, edges) that are likely to draw a viewer's attention. While these models can accurately predict where viewers will look in a natural scene, they typically do not perform well for abstract data visualizations. In this paper, we discuss the reasons for the poor performance of existing saliency models when applied to data visualizations. We introduce the Data Visualization Saliency (DVS) model, a saliency model tailored to address some of these weaknesses, and we test the performance of the DVS model and existing saliency models by comparing the saliency maps produced by the models to eye tracking data obtained from human viewers. Finally, we describe how modified saliency models could be used as general tools for assessing the effectiveness of visualizations, including the strengths and weaknesses of this approach.",Laura E. Matzen;Michael J. Haass;Kristin M. Divis;Zhiyuan Wang;Andrew T. Wilson,Laura E. Matzen;Michael J. Haass;Kristin M. Divis;Zhiyuan Wang;Andrew T. Wilson,"Sandia National Laboratories;Sandia National Laboratories;Sandia National Laboratories;University of Illinois, Urbana-Champaign;Sandia National Laboratories",10.1109/tvcg.2015.2467732;10.1109/tvcg.2015.2467732,"Visual saliency,evaluation,eye tracking",45.0,40.0,49.0,2822.0,,,data visualization saliency;cortex predict;reasons poor;including;obtained,0.8226;0.2003;0.1008;0.0967;-0.1211,"[np.int64(-1), -1, -1, -1, -1]",94;-1;-1;-1;-1,94,94,Visualization Literacy
Vis,1998,Wavelets over curvilinear grids,10.1109/visual.1998.745318,http://dx.doi.org/10.1109/VISUAL.1998.745318,313.0,317.0,C,"We develop multiresolution models for analyzing and visualizing two-dimensional flows over curvilinear grids. Our models are based upon nested spaces of piecewise defined functions defined over nested curvilinear grid domains. The nested domains are selected so as to maintain the original geometry of the inner boundary. We first give the refinement and decomposition equations for Haar wavelets over these domains. Next, using lifting techniques we develop and show examples of piecewise linear wavelets over curvilinear grids.",Gregory M. Nielson;Il-Hong Jung;Junwon Sung,G.M. Nielson;Il.-H. Jung;J. Sung,"Department of Computer Science and Engineering, Arizona State University, Tempe, AZ, USA;Department of Computer Science and Engineering, Arizona State University, Tempe, AZ, USA;Department of Computer Science and Engineering, Arizona State University, Tempe, AZ, USA",10.1109/visual.1997.663883;10.1109/visual.1997.663872;10.1109/visual.1997.663871;10.1109/visual.1997.663883,,17.0,3.0,11.0,64.0,,,wavelets curvilinear grids;piecewise defined;nested domains;equations haar;selected maintain original,0.7670;0.2674;0.2027;0.1468;-0.0496,"[np.int64(-1), -1, -1, -1, -1]",22;-1;-1;-1;-1,22,22,Wavelet Techniques
Vis,2005,Hardware-accelerated simulated radiography,10.1109/visual.2005.1532815,http://dx.doi.org/10.1109/VISUAL.2005.1532815,343.0,350.0,C,"We present the application of hardware accelerated volume rendering algorithms to the simulation of radiographs as an aid to scientists designing experiments, validating simulation codes, and understanding experimental data. The techniques presented take advantage of 32-bit floating point texture capabilities to obtain solutions to the radiative transport equation for X-rays. The hardware accelerated solutions are accurate enough to enable scientists to explore the experimental design space with greater efficiency than the methods currently in use. An unsorted hexahedron projection algorithm is presented for curvilinear hexahedral meshes that produces simulated radiographs in the absorption-only regime. A sorted tetrahedral projection algorithm is presented that simulates radiographs of emissive materials. We apply the tetrahedral projection algorithm to the simulation of experimental diagnostics for inertial confinement fusion experiments on a laser at the University of Rochester.",Daniel E. Laney;Steven P. Callahan;Nelson L. Max;Cláudio T. Silva;Steven Langer;Randall Frank,D. Laney;S.P. Callahan;N. Max;C.T. Silva;S. Langer;R. Frank,"Lawrence Livemore National Laboratory, USA;University of Utah, USA;Lawrence Livemore National Laboratory, USA;University of Utah, USA;Lawrence Livemore National Laboratory, USA;Computational Engineering International",10.1109/visual.2000.885683;10.1109/visual.2004.85;10.1109/visual.2003.1250390;10.1109/visual.2000.885683," volume rendering, hardware acceleration",19.0,3.0,20.0,129.0,,,algorithms simulation radiographs;curvilinear hexahedral meshes;confinement fusion;32 bit floating;aid,0.6261;0.4121;0.3163;0.2315;-0.0426,"[np.int64(-1), -1, -1, -1, -1]",33;-1;-1;-1;-1,33,33,Medical Imaging Analysis
Vis,2010,Computing Robustness and Persistence for Images,10.1109/tvcg.2010.139,http://dx.doi.org/10.1109/TVCG.2010.139,1251.0,1260.0,J,"We are interested in 3-dimensional images given as arrays of voxels with intensity values. Extending these values to a continuous function, we study the robustness of homology classes in its level and interlevel sets, that is, the amount of perturbation needed to destroy these classes. The structure of the homology classes and their robustness, over all level and interlevel sets, can be visualized by a triangular diagram of dots obtained by computing the extended persistence of the function. We give a fast hierarchical algorithm using the dual complexes of oct-tree approximations of the function. In addition, we show that for balanced oct-trees, the dual complexes are geometrically realized in R&lt;sup&gt;3&lt;/sup&gt; and can thus be used to construct level and interlevel sets. We apply these tools to study 3-dimensional images of plant root systems.",Paul Bendich;Herbert Edelsbrunner;Michael Kerber,Paul Bendich;Herbert Edelsbrunner;Michael Kerber,"IST Austria, Austria;IST Austria, Duke University, USA;IST Austria, Austria",10.1109/visual.1997.663875,"Voxel arrays, oct-trees, persistent homology, persistence diagrams, level sets, robustness, approximations, plant roots",114.0,70.0,20.0,642.0,,,dimensional images plant;complexes oct tree;robustness homology;level interlevel sets;destroy classes structure,0.5143;0.4537;0.3993;0.3262;0.1091,"[np.int64(-1), -1, -1, -1, -1]",129;-1;-1;-1;-1,129,129,Plant Growth Visualization
Vis,2003,Counting cases in marching cubes: toward a generic algorithm for producing substitopes,10.1109/visual.2003.1250354,http://dx.doi.org/10.1109/VISUAL.2003.1250354,51.0,58.0,C,"We describe how to count the cases that arise in a family of visualization techniques, including marching cubes, sweeping simplices, contour meshing, interval volumes, and separating surfaces. Counting the cases is the first step toward developing a generic visualization algorithm to produce substitopes (geometric substitution of polytopes). We demonstrate the method using a software system (""GAP"") for computational group theory. The case-counts are organized into a table that provides taxonomy of members of the family; numbers in the table are derived from actual lists of cases, which are computed by our methods. The calculation confirms previously reported case-counts for large dimensions that are too large to check by hand, and predicts the number of cases that will arise in algorithms that have not yet been invented.",David C. Banks;Stephen A. Linton,D.C. Banks;S. Linton,"Florida State University, USA;University of Saint Andrews, UK",10.1109/visual.2000.885704;10.1109/visual.1997.663886;10.1109/visual.1996.568103;10.1109/visual.1996.568121;10.1109/visual.1995.480806;10.1109/visual.1991.175780;10.1109/visual.1997.663887;10.1109/visual.2001.964564;10.1109/visual.2000.885704,"level set, isosurface, orbit, group action, Marching Cubes, separating surfaces, geometric substitution, substitope",46.0,11.0,31.0,166.0,BP,,visualization techniques including;geometric substitution polytopes;gap computational group;methods calculation confirms;previously reported case,0.5734;0.5251;0.3866;0.1014;0.0101,"[np.int64(-1), np.int64(-1), -1, -1, -1]",107;126;-1;-1;-1,107;126,107,Visualization Techniques
Vis,1995,Interactive realism for visualization using ray tracing,10.1109/visual.1995.480791,http://dx.doi.org/10.1109/VISUAL.1995.480791,19.0,,C,"Visual realism is necessary for many virtual reality applications. In order to convince the user that the virtual environment is real, the scene presented should faithfully model the expected actual environment. A highly accurate, fully modeled, interactive environment is thus seen as ""virtually real"". The paper addresses the problem of interactive visual realism and discusses a possible solution: a hybrid rendering paradigm that ties distributed graphics hardware and ray tracing systems together for use in interactive, high visual realism applications. This new paradigm is examined in the context of a working rendering system. This system is capable of producing images of higher fidelity than possible through the use of graphics hardware alone, able both to render images at speeds useful for interactive systems and to progressively refine static, high quality snapshots.",Robert A. Cross,R.A. Cross,"Naval Research Laboratory, Inc., Washington D.C., DC, USA",,,22.0,3.0,12.0,68.0,,,interactive visual realism;user virtual;ray;tracing systems use;addresses problem,0.7206;0.2967;0.2422;0.1888;0.0073,"[np.int64(-1), -1, -1, -1, -1]",43;-1;-1;-1;-1,43,43,Illustrative Rendering Techniques
VAST,2017,BiDots: Visual Exploration of Weighted Biclusters,10.1109/tvcg.2017.2744458,http://dx.doi.org/10.1109/TVCG.2017.2744458,195.0,204.0,J,"Discovering and analyzing biclusters, i.e., two sets of related entities with close relationships, is a critical task in many real-world applications, such as exploring entity co-occurrences in intelligence analysis, and studying gene expression in bio-informatics. While the output of biclustering techniques can offer some initial low-level insights, visual approaches are required on top of that due to the algorithmic output complexity. This paper proposes a visualization technique, called BiDots, that allows analysts to interactively explore biclusters over multiple domains. BiDots overcomes several limitations of existing bicluster visualizations by encoding biclusters in a more compact and cluster-driven manner. A set of handy interactions is incorporated to support flexible analysis of biclustering results. More importantly, BiDots addresses the cases of weighted biclusters, which has been underexploited in the literature. The design of BiDots is grounded by a set of analytical tasks derived from previous work. We demonstrate its usefulness and effectiveness for exploring computed biclusters with an investigative document analysis task, in which suspicious people and activities are identified from a text corpus.",Jian Zhao 0010;Maoyuan Sun;Francine Chen 0001;Patrick Chiu,Jian Zhao;Maoyuan Sun;Francine Chen;Patrick Chiu,"FX Palo Alto Laboratory;University of Massachusetts, Dartmouth;FX Palo Alto Laboratory;FX Palo Alto Laboratory",10.1109/tvcg.2012.252;10.1109/tvcg.2008.153;10.1109/tvcg.2013.223;10.1109/tvcg.2007.70582;10.1109/visual.1990.146402;10.1109/tvcg.2011.250;10.1109/tvcg.2010.138;10.1109/tvcg.2016.2598831;10.1109/tvcg.2014.2346752;10.1109/vast.2007.4389006;10.1109/tvcg.2015.2467813;10.1109/tvcg.2014.2346665;10.1109/tvcg.2013.167;10.1109/tvcg.2012.252,"Biclustering,coordinated relationship analysis,visual analytics",23.0,20.0,41.0,938.0,,,bicluster visualizations;sets related entities;task suspicious people;expression bio;multiple domains,0.6813;0.3254;0.2991;0.1986;0.0674,"[np.int64(-1), -1, -1, -1, -1]",85;-1;-1;-1;-1,85,85,Cluster Visualization
Vis,1990,The VIS-5D system for easy interactive visualization,10.1109/visual.1990.146361,http://dx.doi.org/10.1109/VISUAL.1990.146361,28.0,,C,"The VIS-5D system provides highly interactive visual access to five-dimensional data sets containing up to 50 million data points. VIS-5D runs on the Stardent ST-1000 and ST-2000 workstations and generates animated three-dimensional graphics from gridded data sets in real time. It provides a widget-based user interface and fast visual response which allows scientists to interactively explore their data sets. VIS-5D generates literal and intuitive depictions of data, has user controls that are data oriented rather than graphics oriented, and provides a WYSIWYG (what-you-see-is-what-you-get) response. The result is a system that enables scientists to produce and direct their own animations.&lt;&lt;ETX&gt;&gt;",William L. Hibbard;David A. Santek,B. Hibbard;D. Santek,"Space Science and Engineering Center, University of Wisconsin, Madison, USA;Space Science and Engineering Center, University of Wisconsin, Madison, USA",,,139.0,24.0,2.0,179.0,,,allows scientists interactively;graphics gridded data;vis 5d runs;animated;sets containing,0.5946;0.4545;0.4453;0.3070;0.0041,"[np.int64(-1), -1, -1, -1, -1]",-1;-1;-1;-1;-1,,-1,Interactive 3D Visualization
Vis,2022,Studying Early Decision Making with Progressive Bar Charts,10.1109/tvcg.2022.3209426,http://dx.doi.org/10.1109/TVCG.2022.3209426,407.0,417.0,J,"We conduct a user study to quantify and compare user performance for a value comparison task using four bar chart designs, where the bars show the mean values of data loaded progressively and updated every second (progressive bar charts). Progressive visualization divides different stages of the visualization pipeline—data loading, processing, and visualization—into iterative animated steps to limit the latency when loading large amounts of data. An animated visualization appearing quickly, unfolding, and getting more accurate with time, enables users to make early decisions. However, intermediate mean estimates are computed only on partial data and may not have time to converge to the true means, potentially misleading users and resulting in incorrect decisions. To address this issue, we propose two new designs visualizing the history of values in progressive bar charts, in addition to the use of confidence intervals. We comparatively study four progressive bar chart designs: with/without confidence intervals, and using near-history representation with/without confidence intervals, on three realistic data distributions. We evaluate user performance based on the percentage of correct answers (accuracy), response time, and user confidence. Our results show that, overall, users can make early and accurate decisions with 92% accuracy using only 18% of the data, regardless of the design. We find that our proposed bar chart design with only near-history is comparable to bar charts with only confidence intervals in performance, and the qualitative feedback we received indicates a preference for designs with history.",Ameya Patil;Gaëlle Richer;Christopher Jermaine;Dominik Moritz;Jean-Daniel Fekete,Ameya Patil;Gaëlle Richer;Christopher Jermaine;Dominik Moritz;Jean-Daniel Fekete,"University of Washington, Seattle, USA;Inria & Université Paris-Saclay, France;Rice University, USA;Carnegie Mellon University, USA;Inria & Université Paris-Saclay, France",10.1109/infvis.2005.1532136;10.1109/tvcg.2021.3114803;10.1109/tvcg.2014.2346298;10.1109/tvcg.2019.2934287;10.1109/tvcg.2011.175;10.1109/tvcg.2018.2864909;10.1109/tvcg.2014.2346452;10.1109/tvcg.2008.125;10.1109/tvcg.2014.2346320;10.1109/tvcg.2018.2864889;10.1109/tvcg.2014.2346574;10.1109/infvis.2005.1532136,"Progressive visualization,Uncertainty,Bar charts,Confidence intervals",,6.0,60.0,735.0,,,progressive bar charts;user confidence results;history comparable;value;latency loading large,0.6157;0.4470;0.2514;0.2109;0.1570,"[np.int64(-1), -1, -1, -1, -1]",53;-1;-1;-1;-1,53,53,Dynamic Data Visualizations
Vis,2023,Classes are Not Clusters: Improving Label-Based Evaluation of Dimensionality Reduction,10.1109/tvcg.2023.3327187,http://dx.doi.org/10.1109/TVCG.2023.3327187,781.0,791.0,J,"A common way to evaluate the reliability of dimensionality reduction (DR) embeddings is to quantify how well labeled classes form compact, mutually separated clusters in the embeddings. This approach is based on the assumption that the classes stay as clear clusters in the original high-dimensional space. However, in reality, this assumption can be violated; a single class can be fragmented into multiple separated clusters, and multiple classes can be merged into a single cluster. We thus cannot always assure the credibility of the evaluation using class labels. In this paper, we introduce two novel quality measures—Label-Trustworthiness and Label-Continuity (Label-T&C)—advancing the process of DR evaluation based on class labels. Instead of assuming that classes are well-clustered in the original space, Label-T&C work by (1) estimating the extent to which classes form clusters in the original and embedded spaces and (2) evaluating the difference between the two. A quantitative evaluation showed that Label-T&C outperform widely used DR evaluation measures (e.g., Trustworthiness and Continuity, Kullback-Leibler divergence) in terms of the accuracy in assessing how well DR embeddings preserve the cluster structure, and are also scalable. Moreover, we present case studies demonstrating that Label-T&C can be successfully used for revealing the intrinsic characteristics of DR techniques and their hyperparameters.",Hyeon Jeon;Yun-Hsin Kuo;Michaël Aupetit 0001;Kwan-Liu Ma;Jinwook Seo,Hyeon Jeon;Yun-Hsin Kuo;Michaël Aupetit;Kwan-Liu Ma;Jinwook Seo,"Seoul National University, South Korea;University of California, Davis, South Korea;Qatar Computing Research Institute, Hamad Bin Khalifa University, Qatar;University of California, Davis, South Korea;Seoul National University, South Korea",0.1109/tvcg.2021.3114833;10.1109/tvcg.2011.220;10.1109/tvcg.2017.2745085;10.1109/tvcg.2020.3030365;10.1109/tvcg.2013.153;10.1109/tvcg.2017.2745258;10.1109/tvcg.2022.3209423;10.1109/tvcg.2021.3114694,"Dimensionality Reduction,Reliability,Clustering,Clustering Validation Measures,Dimensionality Reduction Evaluation",,2.0,74.0,887.0,,,embeddings quantify labeled;way evaluate reliability;clear clusters original;space reality assumption;divergence terms,0.6255;0.1905;0.1679;0.1537;0.0227,"[np.int64(-1), -1, -1, -1, -1]",24;-1;-1;-1;-1,24,24,Embedding Techniques
Vis,1997,Viewing IGES files through VRML,10.1109/visual.1997.663924,http://dx.doi.org/10.1109/VISUAL.1997.663924,471.0,474.0,C,This paper describes our experiences with using the Virtual Reality Modeling Language (VRML) to view files in the Initial Graphics Exchange Specification (IGES) format using a Java-based translator from IGES to VRML and HTML (Hypertext Markup Language). The paper examines the conversion problems between IGES and VRML and presents some results of the process.,Jed Marti,J. Marti,"Defense Group, Inc., Salt Lake, UT, USA",,"Computer-aided Design, Applications of Visualization",9.0,1.0,10.0,62.0,,,virtual reality modeling;java based translator;iges format using;html hypertext markup;view files initial,0.6072;0.4025;0.3689;0.3373;0.1739,"[np.int64(-1), -1, -1, -1, -1]",50;-1;-1;-1;-1,50,50,Virtual Reality Technology
Vis,2004,STEPS - an application for simulation of transsphenoidal endonasal pituitary surgery,10.1109/visual.2004.98,http://dx.doi.org/10.1109/VISUAL.2004.98,513.0,520.0,C,"Endonasal transsphenoidal pituitary surgery is a minimally invasive endoscopic procedure, applied to remove various kinds of pituitary tumors. To reduce the risk associated with this treatment, the surgeon must be skilled and well-prepared. Virtual endoscopy can be beneficial as a tool for training, preoperative planning and intraoperative support. This work introduces STEPS, a virtual endoscopy system designed to aid surgeons in getting acquainted with the endoscopic view, the handling of instruments, the transsphenoidal approach and challenges associated with the procedure. STEPS also assists experienced surgeons in planning a real endoscopic intervention by getting familiar with the individual patient anatomy, identifying landmarks, planning the approach and deciding upon the ideal target position of the actual surgical activity. Besides interactive visualization using two different first-hit ray casting techniques, the application provides navigation and perception aids and the possibility to simulate the procedure, including haptic feedback and simulation of surgical instruments.",André Neubauer 0002;Stefan Wolfsberger;Marie-Thérèse Forster;Lukas Mroz;Rainer Wegenkittl;Katja Bühler,A. Neubauer;L. Mroz;S. Wolfsberger;R. Wegenkittl;M.-T. Forster;K. Buhler,"Research Center, VRVis Research Center, Vienna, Austria;Department of Neurosurgery, Medical University, Vienna, Austria;Department of Neurosurgery, Medical University, Vienna, Austria;;Research Center, VRVis Research Center, Vienna, Austria;Research Center, VRVis Research Center, Vienna, Austria",10.1109/visual.2000.885732;10.1109/visual.2000.885702;10.1109/visual.2000.885673;10.1109/visual.2000.885732,"virtual endoscopy, ray casting, iso-surfacing, pituitary surgery",46.0,11.0,21.0,165.0,BA,,virtual endoscopy designed;pituitary tumors reduce;activity interactive visualization;hit ray casting;support work,0.6431;0.3430;0.2354;0.1127;0.1002,"[np.int64(-1), -1, -1, -1, -1]",27;-1;-1;-1;-1,27,27,Virtual Endoscopy Techniques
Vis,2001,Visualizing 2D probability distributions from EOS satellite image-derived data sets: a case study,10.1109/visual.2001.964550,http://dx.doi.org/10.1109/VISUAL.2001.964550,457.0,460.0,C,"Maps of biophysical and geophysical variables using Earth Observing System (EOS) satellite image data are an important component of Earth science. These maps have a single value derived at every grid cell and standard techniques are used to visualize them. Current tools fall short, however, when it is necessary to describe a distribution of values at each grid cell. Distributions may represent a frequency of occurrence over time, frequency of occurrence from multiple runs of an ensemble forecast or possible values from an uncertainty model. We identify these ""distribution data sets"" and present a case study to visualize such 2D distributions. Distribution data sets are different from multivariate data sets in the sense that the values are for a single variable instead of multiple variables. Data for this case study consists of multiple realizations of percent forest cover, generated using a geostatistical technique that combines ground measurements and satellite imagery to model uncertainty about forest cover. We present two general approaches for analyzing and visualizing such data sets. The first is a pixel-wise analysis of the probability density functions for the 2D image while the second is an analysis of features identified within the image. Such pixel-wise and feature-wise views will give Earth scientists a more complete understanding of distribution data sets. See www.cse.ucsc.edu/research/avis/nasa is for additional information.",David L. Kao;Jennifer L. Dungan;Alex Pang,D. Kao;J.L. Dungan;A. Pang,"Ames Research Center, NASA, USA;Ames Research Center, NASA, USA;Computer Science Department, University of California, Santa Cruz, USA",,"uncertainty, probability density function, geostatistics, conditional simulation, data assimilation",70.0,21.0,15.0,349.0,,,earth science maps;cell distributions represent;percent forest;multiple runs ensemble;value derived,0.5706;0.4599;0.4047;0.1009;0.0523,"[np.int64(-1), -1, -1, -1, -1]",-1;-1;-1;-1;-1,,-1,Interactive 3D Visualization
VAST,2009,Solving the traffic and flitter challenges with tulip,10.1109/vast.2009.5334456,http://dx.doi.org/10.1109/VAST.2009.5334456,,,M,"We present our visualization systems and findings for the badge and network traffic as well as the social network and geospatial challenges of the 2009 VAST contest. The summary starts by presenting an overview of our time series encoding of badge information and network traffic. Our findings suggest that employee 30 may be of interest. In the second part of the paper, we describe our system for finding subgraphs in the social network subject to degree constraints. Subsequently, we present our most likely candidate network which is similar to scenario B.",Paolo Simonetto;Pierre-Yves Koenig;Faraz Zaidi;Daniel Archambault;Frédéric Gilbert 0001;Trung-Tien Phan-Quang;Morgan Mathiaut;Antoine Lambert;Jonathan Dubois;Ronan Sicre;Mathieu Brulin;Rémy Vieux;Guy Melançon,Paolo Simonetto;Mathieu Brulin;Remy Vieux;Guy Melancon;Pierre-Yves Koenig;Faraz Zaidi;Daniel Archambault;Frederic Gilbert;Trung-Tien Phan-Quang;Morgan Mathiaut;Antoine Lambert;Jonathan Dubois;Ronan Sicre,"INRIA Bordeaux Sud-Ouest and LaBRI, Université de Bordeaux 1, France;INRIA Bordeaux Sud-Ouest and LaBRI, Université de Bordeaux 1, France;INRIA Bordeaux Sud-Ouest and LaBRI, Université de Bordeaux 1, France;INRIA Bordeaux Sud-Ouest and LaBRI, Université de Bordeaux 1, France;INRIA Bordeaux Sud-Ouest and LaBRI, Université de Bordeaux 1, France;INRIA Bordeaux Sud-Ouest and LaBRI, Université de Bordeaux 1, France;INRIA Bordeaux Sud-Ouest and LaBRI, Université de Bordeaux 1, France;INRIA Bordeaux Sud-Ouest and LaBRI, Université de Bordeaux 1, France;INRIA Bordeaux Sud-Ouest and LaBRI, Université de Bordeaux 1, France;INRIA Bordeaux Sud-Ouest and LaBRI, Université de Bordeaux 1, France;INRIA Bordeaux Sud-Ouest and LaBRI, Université de Bordeaux 1, France;INRIA Bordeaux Sud-Ouest and LaBRI, Université de Bordeaux 1, France;INRIA Bordeaux Sud-Ouest and LaBRI, Université de Bordeaux 1, France",,,1.0,0.0,1.0,113.0,,,badge network;geospatial challenges 2009;overview time series;likely candidate;constraints subsequently present,0.6148;0.3643;0.2219;0.1744;0.0236,"[np.int64(-1), -1, -1, -1, -1]",37;-1;-1;-1;-1,37,37,Visual Representations
Vis,2000,Topology preserving compression of 2D vector fields,10.1109/visual.2000.885714,http://dx.doi.org/10.1109/VISUAL.2000.885714,343.0,350.0,C,"We present an algorithm for compressing 2D vector fields that preserves topology. Our approach is to simplify the given data set using constrained clustering. We employ different types of global and local error metrics including the earth mover's distance metric to measure the degradation in topology as well as weighted magnitude and angular errors. As a result, we obtain precise error bounds in the compressed vector fields. Experiments with both analytic and simulated data sets are presented. Results indicate that one can obtain significant compression with low errors without losing topology information.",Suresh K. Lodha;Jose C. Renteria;Krishna M. Roskin,S.K. Lodha;J.C. Renteria;K.M. Roskin,"Department of Computer Science, University of California, Santa Cruz, CA, USA;Department of Computer Science, University of California, Santa Cruz, CA, USA;Department of Computer Science, University of California, Santa Cruz, CA, USA",10.1109/visual.1999.809865;10.1109/visual.1998.745291;10.1109/visual.1999.809907;10.1109/visual.1998.745297;10.1109/visual.1999.809863;10.1109/visual.1999.809897;10.1109/visual.1991.175773;10.1109/visual.1997.663858;10.1109/visual.1998.745284;10.1109/visual.1999.809874;10.1109/visual.1999.809865,"compression, topology, vector fields, error metrics,clustering",87.0,24.0,15.0,134.0,,,compressed vector fields;topology weighted magnitude;clustering employ different;including earth;angular errors,0.6067;0.3415;0.2734;0.1233;0.0424,"[np.int64(-1), -1, -1, -1, -1]",-1;-1;-1;-1;-1,,-1,Interactive 3D Visualization
Vis,1999,Isosurface extraction techniques for Web-based volume visualization,10.1109/visual.1999.809878,http://dx.doi.org/10.1109/VISUAL.1999.809878,139.0,519.0,C,"The reconstruction of isosurfaces from scalar volume data has positioned itself as a fundamental visualization technique in many different applications. But the dramatically increasing size of volumetric data sets often prohibits the handling of these models on affordable low-end single processor architectures. Distributed client-server systems integrating high-bandwidth transmission channels and Web based visualization tools are one alternative to attack this particular problem, but therefore new approaches to reduce the load of numerical processing and the number of generated primitives are required. We outline different scenarios for distributed isosurface reconstruction from large scale volumetric data sets. We demonstrate how to directly generate stripped surface representations and we introduce adaptive and hierarchical concepts to minimize the number of vertices that have to be reconstructed, transmitted and rendered. Furthermore, we propose a novel computation scheme, which allows the user to flexibly exploit locally available resources. The proposed algorithms have been merged together in order to build a platform-independent Web based application. Extensive use of VRML and Java OpenGL bindings allows for the exploration of large scale volume data quite efficiently.",Klaus D. Engel;Rüdiger Westermann;Thomas Ertl,K. Engel;R. Westermann;T. Ertl,"Visualization and Interactive Systems Group, University of Stuttgart, Germany;Department of Computer Science, University of Utah, USA;Visualization and Interactive Systems Group, University of Stuttgart, Germany",10.1109/visual.1997.663891;10.1109/visual.1996.568121;10.1109/visual.1995.480806;10.1109/visual.1991.175782;10.1109/visual.1998.745300;10.1109/visual.1996.568127;10.1109/visual.1996.568125;10.1109/visual.1997.663891,"Volume visualization, Isosurface reconstruction, Distributed Systems, Web-based Applications",101.0,18.0,26.0,124.0,,,distributed isosurface reconstruction;volume data;opengl bindings allows;java;approaches reduce load,0.6732;0.3966;0.2379;0.1114;0.1054,"[np.int64(-1), -1, -1, -1, -1]",75;-1;-1;-1;-1,75,75,Surface Reconstruction Techniques
Vis,1994,The design and implementation of the Cortex visualization system,10.1109/visual.1994.346310,http://dx.doi.org/10.1109/VISUAL.1994.346310,265.0,,C,"Cortex has been designed for interactive analysis and display of simulation data generated by CFD applications based on unstructured-grid solvers. Unlike post-processing visualization environments, Cortex is designed to work in co-processing mode with the CFD application. This significantly reduces data storage and data movement requirements for visualization and also allows users to interactively steer the application. Further, Cortex supports high-performance by running on massively parallel computers and workstation clusters. An important goal for Cortex, is to provide visualization to a variety of solvers which differ in their solution methodologies and supported flow models. Coupled with the co-processing requirement, this has required the development of a well defined programming interface to the CFD solver that lets the visualization system communicate efficiently with the solver, and requires minimal programming effort for porting to new solvers. Further, the requirement for targeting multiple solvers and application niches demands that the visualization system be rapidly and easily modifiable. Such flexibility is attained in Cortex by using the high-level, interpreted language Scheme for implementing user-interfaces and high-level visualization functions. By making the Scheme interpreter available from the Cortex text interface, the user can also customize and extend the visualization system.&lt;&lt;ETX&gt;&gt;",Deb Banerjee;Chris Morley;Wayne Smith,D. Banerjee;C. Morley;W. Smith,"Centerra Resource Park, Fluent, Inc., Lebanon, NH, USA;Centerra Resource Park, Fluent, Inc., Lebanon, NH, USA;Centerra Resource Park, Fluent, Inc., Lebanon, NH, USA",10.1109/visual.1992.235223;10.1109/visual.1991.175833;10.1109/visual.1990.146360;10.1109/visual.1992.235202;10.1109/visual.1992.235223,"interactive, extensible, spray rendering, smart particles, visualization environment",5.0,2.0,14.0,61.0,,,cfd solver;unstructured grid;cortex text interface;application niches demands;significantly,0.6052;0.4127;0.2785;0.1542;0.0280,"[np.int64(-1), -1, -1, -1, -1]",17;-1;-1;-1;-1,17,17,Turbulent Flow Simulation
Vis,2008,Invariant Crease Lines for Topological and Structural Analysis of Tensor fields,10.1109/tvcg.2008.148,http://dx.doi.org/10.1109/TVCG.2008.148,1627.0,1634.0,J,"We introduce a versatile framework for characterizing and extracting salient structures in three-dimensional symmetric second-order tensor fields. The key insight is that degenerate lines in tensor fields, as defined by the standard topological approach, are exactly crease (ridge and valley) lines of a particular tensor invariant called mode. This reformulation allows us to apply well-studied approaches from scientific visualization or computer vision to the extraction of topological lines in tensor fields. More generally, this main result suggests that other tensor invariants, such as anisotropy measures like fractional anisotropy (FA), can be used in the same framework in lieu of mode to identify important structural properties in tensor fields. Our implementation addresses the specific challenge posed by the non-linearity of the considered scalar measures and by the smoothness requirement of the crease manifold computation. We use a combination of smooth reconstruction kernels and adaptive refinement strategy that automatically adjust the resolution of the analysis to the spatial variation of the considered quantities. Together, these improvements allow for the robust application of existing ridge line extraction algorithms in the tensor context of our problem. Results are proposed for a diffusion tensor MRI dataset, and for a benchmark stress tensor field used in engineering research.",Xavier Tricoche;Gordon L. Kindlmann;Carl-Fredrik Westin,Xavier Tricoche;Gordon Kindlmann;Carl-Fredrik Westin,"Computer Science Department, Purdue University, USA;Brigham and Women's Hospital, Harvard Medical School;Brigham and Women's Hospital, Harvard Medical School",10.1109/visual.2004.105;10.1109/tvcg.2007.70602;10.1109/visual.1999.809896;10.1109/visual.1991.175773;10.1109/visual.1994.346326;10.1109/visual.1994.346326;10.1109/visual.1990.146359;10.1109/tvcg.2007.70554;10.1109/visual.2004.105,"Tensor fields, tensor invariants, ridge lines, crease extraction, structural analysis, topology",69.0,45.0,43.0,422.0,,,tensor mri;extraction topological lines;symmetric second order;adaptive refinement strategy;important,0.6317;0.4068;0.1310;0.0755;0.0586,"[np.int64(-1), -1, -1, -1, -1]",40;-1;-1;-1;-1,40,40,Tensor MRI Visualization
SciVis,2018,Visualization of Neuronal Structures in Wide-Field Microscopy Brain Images,10.1109/tvcg.2018.2864852,http://dx.doi.org/10.1109/TVCG.2018.2864852,1018.0,1028.0,J,"Wide-field microscopes are commonly used in neurobiology for experimental studies of brain samples. Available visualization tools are limited to electron, two-photon, and confocal microscopy datasets, and current volume rendering techniques do not yield effective results when used with wide-field data. We present a workflow for the visualization of neuronal structures in wide-field microscopy images of brain samples. We introduce a novel gradient-based distance transform that overcomes the out-of-focus blur caused by the inherent design of wide-field microscopes. This is followed by the extraction of the 3D structure of neurites using a multi-scale curvilinear filter and cell-bodies using a Hessian-based enhancement filter. The response from these filters is then applied as an opacity map to the raw data. Based on the visualization challenges faced by domain experts, our workflow provides multiple rendering modes to enable qualitative analysis of neuronal structures, which includes separation of cell-bodies from neurites and an intensity-based classification of the structures. Additionally, we evaluate our visualization results against both a standard image processing deconvolution technique and a confocal microscopy image of the same specimen. We show that our method is significantly faster and requires less computational resources, while producing high quality visualizations. We deploy our workflow in an immersive gigapixel facility as a paradigm for the processing and visualization of large, high-resolution, wide-field microscopy brain datasets.",Saeed Boorboor;Shreeraj Jadhav;Mala Ananth 0001;David Talmage;Lorna Role;Arie E. Kaufman,Saeed Boorboor;Shreeraj Jadhav;Mala Ananth;David Talmage;Lorna Role;Arie Kaufman,"Department of Computer Science, Stony Brook University;Department of Computer Science, Stony Brook University;Department of Neurobiology & behavior, Stony Brook University;Department of Neurobiology & behavior, Stony Brook University;Department of Neurobiology & behavior, Stony Brook University;Department of Computer Science, Stony Brook University and Connectomics project, Harvard University",10.1109/tvcg.2014.2346312;10.1109/tvcg.2013.142;10.1109/tvcg.2012.203;10.1109/tvcg.2017.2744079;10.1109/tvcg.2009.118;10.1109/tvcg.2016.2598472;10.1109/tvcg.2014.2346312,"Wide-field microscopy,volume visualization,neuron visualization,neuroscience",13.0,15.0,58.0,1009.0,,,visualization neuronal structures;curvilinear filter;focus blur caused;deploy workflow;faster requires,0.6539;0.2281;0.1513;0.0554;0.0393,"[np.int64(-1), -1, -1, -1, -1]",42;-1;-1;-1;-1,42,42,Neural Visualization Techniques
VAST,2012,Spatiotemporal social media analytics for abnormal event detection and examination using seasonal-trend decomposition,10.1109/vast.2012.6400557,http://dx.doi.org/10.1109/VAST.2012.6400557,143.0,152.0,C,"Recent advances in technology have enabled social media services to support space-time indexed data, and internet users from all over the world have created a large volume of time-stamped, geo-located data. Such spatiotemporal data has immense value for increasing situational awareness of local events, providing insights for investigations and understanding the extent of incidents, their severity, and consequences, as well as their time-evolving nature. In analyzing social media data, researchers have mainly focused on finding temporal trends according to volume-based importance. Hence, a relatively small volume of relevant messages may easily be obscured by a huge data set indicating normal situations. In this paper, we present a visual analytics approach that provides users with scalable and interactive social media data analysis and visualization including the exploration and examination of abnormal topics and events within various social media data sources, such as Twitter, Flickr and YouTube. In order to find and understand abnormal events, the analyst can first extract major topics from a set of selected messages and rank them probabilistically using Latent Dirichlet Allocation. He can then apply seasonal trend decomposition together with traditional control chart methods to find unusual peaks and outliers within topic time series. Our case studies show that situational awareness can be improved by incorporating the anomaly and trend examination techniques into a highly interactive visual analysis process.",Junghoon Chae;Dennis Thom;Harald Bosch;Yun Jang;Ross Maciejewski;David S. Ebert;Thomas Ertl,Junghoon Chae;Dennis Thom;Harald Bosch;Yun Jang;Ross Maciejewski;David S. Ebert;Thomas Ertl,Purdue University;University of Stuttgart;University of Stuttgart;Sejong University;Arizona State University;Purdue University;University of Stuttgart,10.1109/vast.2011.6102456;10.1109/vast.2011.6102461;10.1109/tvcg.2008.175;10.1109/vast.2011.6102488;10.1109/vast.2011.6102456,,354.0,171.0,39.0,3235.0,,,finding temporal trends;interactive social media;understand abnormal;messages easily obscured;located,0.5448;0.3739;0.2836;0.1939;0.0495,"[np.int64(-1), -1, -1, -1, -1]",59;-1;-1;-1;-1,59,59,Temporal Analysis
Vis,2009,An interactive visualization tool for multi-channel confocal microscopy data in neurobiology research,10.1109/tvcg.2009.118,http://dx.doi.org/10.1109/TVCG.2009.118,1489.0,1496.0,J,"Confocal microscopy is widely used in neurobiology for studying the three-dimensional structure of the nervous system. Confocal image data are often multi-channel, with each channel resulting from a different fluorescent dye or fluorescent protein; one channel may have dense data, while another has sparse; and there are often structures at several spatial scales: subneuronal domains, neurons, and large groups of neurons (brain regions). Even qualitative analysis can therefore require visualization using techniques and parameters fine-tuned to a particular dataset. Despite the plethora of volume rendering techniques that have been available for many years, the techniques standardly used in neurobiological research are somewhat rudimentary, such as looking at image slices or maximal intensity projections. Thus there is a real demand from neurobiologists, and biologists in general, for a flexible visualization tool that allows interactive visualization of multi-channel confocal data, with rapid fine-tuning of parameters to reveal the three-dimensional relationships of structures of interest. Together with neurobiologists, we have designed such a tool, choosing visualization methods to suit the characteristics of confocal data and a typical biologist's workflow. We use interactive volume rendering with intuitive settings for multidimensional transfer functions, multiple render modes and multi-views for multi-channel volume data, and embedding of polygon data into volume data for rendering and editing. As an example, we apply this tool to visualize confocal microscopy datasets of the developing zebrafish visual system.",Yong Wan;Hideo Otsuna;Chi-Bin Chien;Charles D. Hansen,Yong Wan;Hideo Otsuna;Chi-Bin Chien;Charles Hansen,"Scientific and Imaging Institute, University of Utah, USA;Department of Neurobiology and Anatomy, University of Utah, USA;Department of Neurobiology and Anatomy, University of Utah, USA;Scientific and Imaging Institute, University of Utah, USA",10.1109/visual.1999.809887;10.1109/tvcg.2006.148;10.1109/visual.1999.809887,"Visualization, neurobiology, confocal microscopy, qualitative analysis, volume rendering",103.0,93.0,26.0,786.0,,,visualize confocal microscopy;polygon data volume;intuitive settings multidimensional;standardly used neurobiological;different,0.6352;0.3340;0.3017;0.2662;0.0148,"[np.int64(-1), -1, -1, -1, -1]",42;-1;-1;-1;-1,42,42,Neural Visualization Techniques
VAST,2016,Patterns and Sequences: Interactive Exploration of Clickstreams to Understand Common Visitor Paths,10.1109/tvcg.2016.2598797,http://dx.doi.org/10.1109/TVCG.2016.2598797,321.0,330.0,J,"Modern web clickstream data consists of long, high-dimensional sequences of multivariate events, making it difficult to analyze. Following the overarching principle that the visual interface should provide information about the dataset at multiple levels of granularity and allow users to easily navigate across these levels, we identify four levels of granularity in clickstream analysis: patterns, segments, sequences and events. We present an analytic pipeline consisting of three stages: pattern mining, pattern pruning and coordinated exploration between patterns and sequences. Based on this approach, we discuss properties of maximal sequential patterns, propose methods to reduce the number of patterns and describe design considerations for visualizing the extracted sequential patterns and the corresponding raw sequences. We demonstrate the viability of our approach through an analysis scenario and discuss the strengths and limitations of the methods based on user feedback.",Zhicheng Liu 0001;Yang Wang;Mira Dontcheva;Matthew Hoffman 0001;Seth Walker;Alan Wilson 0004,Zhicheng Liu;Yang Wang;Mira Dontcheva;Matthew Hoffman;Seth Walker;Alan Wilson,"Adobe Research;University of California, Davis;Adobe Research;Adobe Research;Adobe Research;Adobe Systems Inc.",10.1109/vast.2010.5652910;10.1109/vast.2010.5652926;10.1109/tvcg.2013.225;10.1109/tvcg.2013.200;10.1109/infvis.2005.1532152;10.1109/infvis.2000.885091;10.1109/tvcg.2014.2346574;10.1109/vast.2007.4389008;10.1109/tvcg.2011.185;10.1109/vast.2014.7042487;10.1109/tvcg.2015.2467622;10.1109/vast.2012.6400494;10.1109/vast.2010.5652910,event sequences;Clickstream Data;sequence mining;visual analytics,125.0,86.0,38.0,2153.0,,,clickstream analysis patterns;visualizing extracted;easily navigate;levels granularity allow;long,0.7830;0.3205;0.2871;0.1904;0.0266,"[np.int64(-1), -1, -1, -1, -1]",57;-1;-1;-1;-1,57,57,Anomaly Detection Techniques
Vis,2001,Distance-field based skeletons for virtual navigation,10.1109/visual.2001.964517,http://dx.doi.org/10.1109/VISUAL.2001.964517,239.0,246.0,C,"We present a generic method for rapid flight planning, virtual navigation and effective camera control in a volumetric environment. Directly derived from an accurate distance from boundary (DFB) field, our automatic path planning algorithm rapidly generates centered flight paths, a skeleton, in the navigable region of the virtual environment. Based on precomputed flight paths and the DFB field, our dual-mode physically based camera control model supports a smooth, safe, and sticking-free virtual navigation with six degrees of freedom. By using these techniques, combined with accelerated volume rendering, we have successfully developed a real-time virtual colonoscopy system on low-cost PCs and confirmed the high speed, high accuracy and robustness of our techniques on more than 40 patient datasets.",Ming Wan;Frank Dachille;Arie E. Kaufman,Ming Wan;F. Dachille;A. Kaufman,"Boeing Company, Seattle, WA, USA;Department of Computer Science, State University of New York, Stony Brook, Stony Brook, NY, USA;Department of Computer Science, State University of New York, Stony Brook, Stony Brook, NY, USA",10.1109/visual.1997.663915;10.1109/visual.2000.885675,"Distance fields, path planning, centerline, camera control, virtual navigation, volumetric environment, physically based modeling, virtual colonoscopy",160.0,7.0,27.0,259.0,,,virtual colonoscopy;camera control model;flight paths dfb;volume rendering successfully;confirmed,0.6376;0.3483;0.2843;0.2403;-0.0204,"[np.int64(-1), -1, -1, -1, -1]",27;-1;-1;-1;-1,27,27,Virtual Endoscopy Techniques
Vis,1995,Virtual GIS: a real-time 3D geographic information system,10.1109/visual.1995.480800,http://dx.doi.org/10.1109/VISUAL.1995.480800,94.0,,C,"Advances in computer graphics hardware and algorithms, visualization, and interactive techniques for analysis offer the components for a highly integrated, efficient real-time 3D Geographic Information System. We have developed ""Virtual GIS"", a system with truly immersive capability for navigating and understanding complex and dynamic terrain-based databases. The system provides the means for visualizing terrain models consisting of elevation and imagery data, along with GIS raster layers, protruding features, buildings, vehicles, and other objects. We have implemented window-based and virtual reality versions and in both cases provide a direct manipulation, visual interface for accessing the GIS data. Unique terrain data structures and algorithms allow rendering of large, high resolution datasets at interactive rates.",David Koller;Peter Lindstrom 0001;William Ribarsky;Larry F. Hodges;Nickolas Faust;Gregory A. Turner,D. Koller;P. Lindstrom;W. Ribarsky;L.F. Hodges;N. Faust;G. Turner,"Coll. of Comput., Georgia Inst. of Technol., Atlanta, GA, USA;Graphics Visualizaton Usability Center College of Computing, Georgia Institute of Technology, Atlanta, GA, USA;Graphics Visualizaton Usability Center College of Computing, Georgia Institute of Technology, Atlanta, GA, USA;Graphics Visualizaton Usability Center College of Computing, Georgia Institute of Technology, Atlanta, GA, USA;Georgia Tech Research Institute, Georgia Institute of Technology, USA;Army Research Laboratory, Information Processing Branch",0.1109/visual.1994.346284,,313.0,36.0,19.0,584.0,,,gis truly immersive;hardware algorithms;layers protruding features;versions cases;high,0.6661;0.1667;0.1441;0.0311;0.0311,"[np.int64(-1), -1, -1, -1, -1]",143;-1;-1;-1;-1,143,143,Immersive Spatial Support
VAST,2007,Stories in GeoTime,10.1109/vast.2007.4388992,http://dx.doi.org/10.1109/VAST.2007.4388992,19.0,26.0,C,"A story is a powerful abstraction used by intelligence analysts to conceptualize threats and understand patterns as part of the analytical process. This paper demonstrates a system that detects geo-temporal patterns and integrates story narration to increase analytic sense-making cohesion in GeoTime. The GeoTime geo-temporal event visualization tool was augmented with a story system that uses narratives, hypertext linked visualizations, visual annotations, and pattern detection to create an environment for analytic exploration and communication, thereby assisting the analyst in identifying, extracting, arranging and presenting stories within the data The story system lets analysts operate at the story level with higher-level abstractions of data, such as behaviors and events, while staying connected to the evidence. The story system was developed and evaluated in collaboration with analysts.",Ryan Eccles;Thomas Kapler;Robert Harper 0002;William Wright,Ryan Eccles;Thomas Kapler;Robert Harper;William Wright,"Oculus Info, Inc., USA;Oculus Info, Inc., USA;Oculus Info, Inc., USA;Oculus Info, Inc., USA",10.1109/infvis.2004.27;10.1109/vast.2006.261436;10.1109/infvis.2004.27,"human information interaction, visual analytics, sense-making, narrative, pattern detection, story making, story telling",0.0,43.0,19.0,940.0,,,temporal event visualization;intelligence analysts conceptualize;story;detects geo;hypertext linked,0.5759;0.4957;0.2619;0.2266;0.1916,"[np.int64(-1), -1, -1, -1, -1]",65;-1;-1;-1;-1,65,65,Event Visualization
VAST,2010,"Geo-historical context support for information foraging and sensemaking: Conceptual model, implementation, and assessment",10.1109/vast.2010.5652895,http://dx.doi.org/10.1109/VAST.2010.5652895,139.0,146.0,C,"Information foraging and sensemaking with heterogeneous information are context-dependent activities. Thus visual analytics tools to support these activities must incorporate context. But, context is a difficult concept to define, model, and represent. Creating and representing context in support of visually-enabled reasoning about complex problems with complex information is a complementary but different challenge than that addressed in context-aware computing. In the latter, the goal is automated adaptation of the system to meet user needs for applications such as mobile location-based services where information about the location, the user, and the user goals filters what gets presented on a small mobile device. In contrast, for visual analytics-enabled information foraging and sensemaking, the user is likely to take an active role in foraging for the contextual information needed to support sensemaking in relation to some multifaceted problem. In this paper, we address the challenges of constructing and representing context within visual interfaces that support analytical reasoning in crisis management and humanitarian relief. The challenges stem from the diverse forms of information that can provide context and difficulty in defining and operationalizing context itself. Here, we pay particular attention to document foraging to support construction of the geographic and historical context within which monitoring and sensemaking can be carried out. Specifically, we present the concept of geo-historical context (GHC) and outline an empirical assessment of both the concept and its implementation in the Context Discovery Application, a web-based tool that supports document foraging and sensemaking.",Brian M. Tomaszewski;Alan M. MacEachren,Brian Tomaszewski;Alan M. MacEachren,"Department of Information Sciences and Technologies, Rochester Institute of Technology, Rochester, NY, USA;Department of Geography and GeoVISTA Center, Pennsylvania State University, University Park, PA, USA",,"context, foraging, sensemaking, mapping, text analysis, geographic information retrieval",23.0,10.0,32.0,373.0,,,context monitoring sensemaking;geographic historical;diverse forms information;relief challenges stem;likely,0.6379;0.3356;0.2990;0.1701;0.0268,"[np.int64(-1), -1, -1, -1, -1]",120;-1;-1;-1;-1,120,120,Interactive Sensemaking
Vis,2001,Continuous topology simplification of planar vector fields,10.1109/visual.2001.964507,http://dx.doi.org/10.1109/VISUAL.2001.964507,159.0,166.0,C,"Vector fields can present complex structural behavior, especially in turbulent computational fluid dynamics. The topological analysis of these data sets reduces the information, but one is usually still left with too many details for interpretation. In this paper, we present a simplification approach that removes pairs of critical points from the data set, based on relevance measures. In contrast to earlier methods, no grid changes are necessary, since the whole method uses small local changes of the vector values defining the vector field. An interpretation in terms of bifurcations underlines the continuous, natural flavor of the algorithm.",Xavier Tricoche;Gerik Scheuermann;Hans Hagen,X. Tricoche;G. Scheuermann;H. Hagen,"Computer Science Department, University of Kaiserslautern, Kaiserslautern, Germany;Computer Science Department, University of Kaiserslautern, Kaiserslautern, Germany;Computer Science Department, University of Kaiserslautern, Kaiserslautern, Germany",10.1109/visual.2000.885716;10.1109/visual.1998.745318;10.1109/visual.1991.175773;10.1109/visual.1999.809907;10.1109/visual.2000.885716,"vector field topology, flow visualization, unstructured grid, simplification",183.0,55.0,10.0,245.0,,,turbulent computational;defining vector field;pairs critical points;topological analysis;relevance measures contrast,0.6324;0.3404;0.3194;0.2567;0.1671,"[np.int64(-1), -1, -1, -1, -1]",17;-1;-1;-1;-1,17,17,Turbulent Flow Simulation
InfoVis,2016,booc.io: An Education System with Hierarchical Concept Maps and Dynamic Non-linear Learning Plans,10.1109/tvcg.2016.2598518,http://dx.doi.org/10.1109/TVCG.2016.2598518,571.0,580.0,J,"Information hierarchies are difficult to express when real-world space or time constraints force traversing the hierarchy in linear presentations, such as in educational books and classroom courses. We present booc.io, which allows linear and non-linear presentation and navigation of educational concepts and material. To support a breadth of material for each concept, booc.io is Web based, which allows adding material such as lecture slides, book chapters, videos, and LTIs. A visual interface assists the creation of the needed hierarchical structures. The goals of our system were formed in expert interviews, and we explain how our design meets these goals. We adapt a real-world course into booc.io, and perform introductory qualitative evaluation with students.",Michail Schwab;Hendrik Strobelt;James Tompkin 0001;Colin Fredericks;Connor Huff;Dana Higgins;Anton Strezhnev;Mayya Komisarchik;Gary King;Hanspeter Pfister,Michail Schwab;Hendrik Strobelt;James Tompkin;Colin Fredericks;Connor Huff;Dana Higgins;Anton Strezhnev;Mayya Komisarchik;Gary King;Hanspeter Pfister,Harvard Paulson SEAS;Harvard Paulson SEAS;Harvard Paulson SEAS;HarvardX;Harvard Institute for Quantitative Social Sciences;Harvard Institute for Quantitative Social Sciences;Harvard Institute for Quantitative Social Sciences;Harvard Institute for Quantitative Social Sciences;Harvard Institute for Quantitative Social Sciences;Harvard Paulson SEAS,0.1109/tvcg.2006.147,education;Hierarchies;information visualization,39.0,21.0,37.0,1408.0,,,presentation navigation educational;hierarchies;non linear;material;booc io allows,0.6516;0.3868;0.1959;0.1256;0.1074,"[np.int64(-1), -1, -1, -1, -1]",146;-1;-1;-1;-1,146,146,Visualization Techniques
Vis,1992,Visual query specification in a multimedia database system,10.1109/visual.1992.235208,http://dx.doi.org/10.1109/VISUAL.1992.235208,194.0,201.0,C,"A visual interface for a multimedia database management system (MDBMS) is described. DBMS query languages are linear in syntax. Although natural language interfaces have been found to be useful, natural language is ambiguous and difficult to process. For queries on standard (relational) data, these difficulties can be avoided with the use of a visual, graphical interface to guide the user in specifying the query. For image and other media data which are ambiguous in nature, natural language processing, combined with direct graphical access to the domain knowledge, is used to interpret and evaluate the natural language query. The system fully supports graphical and image input/output in different formats. The combination of visual effect and natural language specification, the support of media data, and the allowance of incremental query specification simplify the process of query specification not only for image or multimedia databases but also for all databases.&lt;&lt;ETX&gt;&gt;",Daniel A. Keim;Vincent Y. Lum,D.A. Keim;V. Lum,"Institut für Informatik, Universität Munchen, Munchen, Germany;Systems Engineering, Chinese University of Hong Kong, Sha Tin, Hong Kong, China",,"Visual Query Specijication, Graphical User Interface, Multimedia Database System, Natural-Language Interface, Information Retrieval, Image Data Management",19.0,1.0,15.0,92.0,,,multimedia database management;interface guide user;specifying query;interpret evaluate natural;combination visual effect,0.6983;0.3490;0.3078;0.2164;0.1808,"[np.int64(-1), -1, -1, -1, -1]",16;-1;-1;-1;-1,16,16,Digital Archive Management
