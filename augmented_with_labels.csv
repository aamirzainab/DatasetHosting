Conference,Year,Title,DOI,Link,FirstPage,LastPage,PaperType,Abstract,AuthorNames-Deduped,AuthorNames,AuthorAffiliation,InternalReferences,AuthorKeywords,AminerCitationCount,CitationCount_CrossRef,PubsCited_CrossRef,Downloads_Xplore,Award,GraphicsReplicabilityStamp,Keywords,RelevanceScore,KeywordClusters,RefinedKeywordClusters,AllClusters,DominantCluster,Area
VAST,2006,Pixnostics: Towards Measuring the Value of Visualization,10.1109/vast.2006.261423,http://dx.doi.org/10.1109/VAST.2006.261423,199.0,206.0,C,"During the last two decades a wide variety of advanced methods for the visual exploration of large data sets have been proposed. For most of these techniques user interaction has become a crucial element, since there are many situations in which a user or an analyst has to select the right parameter settings from among many or select a subset of the available attribute space for the visualization process, in order to construct valuable visualizations that provide insight, into the data and reveal interesting patterns. The right choice of input parameters is often essential, since suboptimal parameter settings or the investigation of irrelevant data dimensions make the exploration process more time consuming and may result in wrong conclusions. In this paper we propose a novel method for automatically determining meaningful parameter- and attribute settings based on the information content of the resulting visualizations. Our technique called Pixnostics, in analogy to Scagnostics (Wilkinson et al., 2005), automatically analyses pixel images resulting from diverse parameter mappings and ranks them according to the potential value for the user. This allows a more effective and more efficient visual data analysis process, since the attribute/parameter space is reduced to meaningful selections and thus the analyst obtains faster insight into the data. Real world applications are provided to show the benefit of the proposed approach",Jörn Schneidewind;Mike Sips;Daniel A. Keim,Jorn Schneidewind;Mike Sips;Daniel A. Keim,"University of Konstanz, Germany;University of Stanford, USA;University of Konstanz, Germany",10.1109/infvis.2005.1532145;10.1109/infvis.2005.1532142;10.1109/visual.2005.1532782;10.1109/visual.2005.1532781;10.1109/infvis.2000.885092;10.1109/infvis.2005.1532145,"Visual Data Exploration, Visualization technique,Visual Analytics",63.0,35.0,24.0,684.0,,,construct valuable visualizations;parameter attribute settings;called pixnostics;select subset;2005 automatically,0.6616;0.2800;0.2359;0.1310;0.0510,"[np.int64(1), -1, -1, -1, -1]",15;-1;-1;-1;-1,15,15,Visualization Design
VAST,2015,Interactive semi-automatic categorization for spinel group minerals,10.1109/vast.2015.7347676,http://dx.doi.org/10.1109/VAST.2015.7347676,197.0,198.0,M,"Spinel group minerals are excellent indicators of geological environments (tectonic settings). In 2001, Barnes and Roeder defined a set of contours corresponding to compositional fields for spinel group minerals. Geologists typically use this contours to estimate the tectonic environment where a particular spinel composition could have been formed. This task is prone to errors and requires tedious manual comparison of overlapping diagrams. We introduce a semi-automatic, interactive detection of tectonic settings for an arbitrary dataset based on the Barnes and Roeder contours. The new approach integrates the mentioned contours and includes a novel interaction called contour brush. The new methodology is integrated in the Spinel Explorer system and it improves the scientist's workflow significantly.",Maria Luján Ganuza;Maria Florencia Gargiulo;Gabriela Ferracutti;Silvia Mabel Castro;Ernesto A. Bjerg;M. Eduard Gröller;Kresimir Matkovic,María Luján Ganuza;Florencia Gargiulo;Gabriela Ferracutti;Silvia Castro;Ernesto Bjerg;Eduard Gröller;Krešimir Matković,"UNS, VyGLab;INGEOSUR CONICET;INGEOSUR CONICET;UNS, VyGLab;INGEOSUR CONICET;TU Wien;VRVis",0.1109/tvcg.2014.2346754,,5.0,2.0,5.0,106.0,,,interactive detection tectonic;compositional fields spinel;settings arbitrary dataset;group;prone errors,0.6692;0.3364;0.1164;0.0436;0.0330,"[np.int64(-1), -1, -1, -1, -1]",84;-1;-1;-1;-1,84,84,Geospatial Visualization Techniques
Vis,1994,Visualization in medicine: VIRTUAL reality or ACTUAL reality ?,10.1109/visual.1994.346288,http://dx.doi.org/10.1109/VISUAL.1994.346288,396.0,399.0,M,Discusses and debates the role played by 3D visualization in medicine as a set of methods and techniques for displaying 3D spatial information related to the anatomy and the physiology of the human body.&lt;&lt;ETX&gt;&gt;,Christian Roux;Jean-Louis Coatrieux;Jean-Louis Dillenseger;Elliot K. Fishman;Murray H. Loew;Hans-Peter Meinzer;Justin D. Pearlman,C. Roux;J.L. Coatrieux;J.-L. Dillenseger;E.K. Fishman;M. Loew;H.-P. Meinzer;J.D. Pearlman,"Département Image et Traitement de l'Information, Ecole Nationale Supérieure des TéIécommunications, Brest, France;Labratoire Tiaitement du Signal et de l'Image, Université de Rennes 1, Rennes, France;University of Rennes I, France;Johns Hopkins School of Medicine, USA;Washington University, USA;German Cancer Center Heidelberg, Germany;Harvard Medical School, USA",,,3.0,1.0,3.0,96.0,,,3d visualization medicine;body;methods techniques displaying;lt etx;debates role,0.8177;0.2443;0.2170;0.0906;0.0320,"[np.int64(-1), -1, -1, -1, -1]",-1;-1;-1;-1;-1,,-1,Complex Data Analysis
InfoVis,2014,Attribute Signatures: Dynamic Visual Summaries for Analyzing Multivariate Geographical Data,10.1109/tvcg.2014.2346265,http://dx.doi.org/10.1109/TVCG.2014.2346265,2033.0,2042.0,J,"The visual analysis of geographically referenced datasets with a large number of attributes is challenging due to the fact that the characteristics of the attributes are highly dependent upon the locations at which they are focussed, and the scale and time at which they are measured. Specialized interactive visual methods are required to help analysts in understanding the characteristics of the attributes when these multiple aspects are considered concurrently. Here, we develop attribute signatures-interactively crafted graphics that show the geographic variability of statistics of attributes through which the extent of dependency between the attributes and geography can be visually explored. We compute a number of statistical measures, which can also account for variations in time and scale, and use them as a basis for our visualizations. We then employ different graphical configurations to show and compare both continuous and discrete variation of location and scale. Our methods allow variation in multiple statistical summaries of multiple attributes to be considered concurrently and geographically, as evidenced by examples in which the census geography of London and the wider UK are explored.",Cagatay Turkay;Aidan Slingsby;Helwig Hauser;Jo Wood;Jason Dykes,Cagatay Turkay;Aidan Slingsby;Helwig Hauser;Jo Wood;Jason Dykes,"Dep. of Computer Science at City University London, UK;Dep. of Computer Science at City University London, UK;Department of Informatics at University of Bergen, Bergen, Norway;Dep. of Computer Science at City University London, UK;Dep. of Computer Science at City University London, UK",10.1109/tvcg.2013.173;10.1109/tvcg.2011.178;10.1109/tvcg.2013.226;10.1109/tvcg.2011.197;10.1109/tvcg.2007.70558;10.1109/tvcg.2008.149;10.1109/infvis.2004.12;10.1109/tvcg.2012.256;10.1109/tvcg.2007.70574;10.1109/vast.2008.4677350;10.1109/tvcg.2008.125;10.1109/tvcg.2013.122;10.1109/tvcg.2013.173,"Visual analytics, multi-variate data, geographic information, geovisualization, interactive data analysis",65.0,39.0,54.0,1343.0,,,visual analysis geographically;statistical measures account;referenced datasets large;concurrently develop attribute;different,0.7344;0.2434;0.2329;0.1353;0.0790,"[np.int64(-1), -1, -1, -1, -1]",60;-1;-1;-1;-1,60,60,Geographic Visual Analytics
SciVis,2020,Polyphorm: Structural Analysis of Cosmological Datasets via Interactive Physarum Polycephalum Visualization,10.1109/tvcg.2020.3030407,http://dx.doi.org/10.1109/TVCG.2020.3030407,806.0,816.0,J,"This paper introduces Polyphorm, an interactive visualization and model fitting tool that provides a novel approach for investigating cosmological datasets. Through a fast computational simulation method inspired by the behavior of Physarum polycephalum, an unicellular slime mold organism that efficiently forages for nutrients, astrophysicists are able to extrapolate from sparse datasets, such as galaxy maps archived in the Sloan Digital Sky Survey, and then use these extrapolations to inform analyses of a wide range of other data, such as spectroscopic observations captured by the Hubble Space Telescope. Researchers can interactively update the simulation by adjusting model parameters, and then investigate the resulting visual output to form hypotheses about the data. We describe details of Polyphorm's simulation model and its interaction and visualization modalities, and we evaluate Polyphorm through three scientific use cases that demonstrate the effectiveness of our approach.",Oskar Elek;Joseph N. Burchett;J. Xavier Prochaska;Angus G. Forbes,Oskar Elek;Joseph N. Burchett;J. Xavier Prochaska;Angus G. Forbes,"Dept. of Computational Media, University of California, Santa Cruz;Dept. of Astronomy and Astrophysics, University of California, Santa Cruz;Dept. of Astronomy and Astrophysics, University of California, Santa Cruz;Dept. of Computational Media, University of California, Santa Cruz",10.1109/tvcg.2019.2934259;10.1109/tvcg.2019.2934259,"Astrophysics visualization,agent-based modeling,intergalactic media,Physarum polycephalum,Cosmic Web",13.0,10.0,79.0,530.0,,,investigating cosmological datasets;polyphorm interactive visualization;mold organism efficiently;interactively update;cases,0.6864;0.4737;0.2242;0.0722;-0.0446,"[np.int64(-1), np.int64(1), -1, -1, -1]",17;51;-1;-1;-1,17;51,17,Cosmological Data Analysis
VAST,2017,Clustering Trajectories by Relevant Parts for Air Traffic Analysis,10.1109/tvcg.2017.2744322,http://dx.doi.org/10.1109/TVCG.2017.2744322,34.0,44.0,J,"Clustering of trajectories of moving objects by similarity is an important technique in movement analysis. Existing distance functions assess the similarity between trajectories based on properties of the trajectory points or segments. The properties may include the spatial positions, times, and thematic attributes. There may be a need to focus the analysis on certain parts of trajectories, i.e., points and segments that have particular properties. According to the analysis focus, the analyst may need to cluster trajectories by similarity of their relevant parts only. Throughout the analysis process, the focus may change, and different parts of trajectories may become relevant. We propose an analytical workflow in which interactive filtering tools are used to attach relevance flags to elements of trajectories, clustering is done using a distance function that ignores irrelevant elements, and the resulting clusters are summarized for further analysis. We demonstrate how this workflow can be useful for different analysis tasks in three case studies with real data from the domain of air traffic. We propose a suite of generic techniques and visualization guidelines to support movement data analysis by means of relevance-aware trajectory clustering.",Gennady L. Andrienko;Natalia V. Andrienko;Georg Fuchs;Jose Manuel Cordero Garcia,Gennady Andrienko;Natalia Andrienko;Georg Fuchs;Jose Manuel Cordero Garcia,"Fraunhofer IAIS, City University, London;Fraunhofer IAIS, City University, London;Fraunhofer Institute IAIS;CRIDA (Reference Center for Research, Development and Innovation in ATM)",10.1109/vast.2009.5332584;10.1109/tvcg.2013.193;10.1109/tvcg.2011.233;10.1109/tvcg.2015.2468292;10.1109/vast.2008.4677350;10.1109/vast.2009.5332584,"Visual analytics,movement data analysis,trajectory clustering,air traffic",90.0,62.0,53.0,2561.0,,,trajectories clustering using;important technique movement;relevance flags;workflow interactive;air,0.7251;0.2497;0.1665;0.1544;0.1401,"[np.int64(-1), -1, -1, -1, -1]",31;-1;-1;-1;-1,31,31,Trajectory Data Analysis
Vis,1996,Volume Thinning for Automatic Isosurface Propagation,10.1109/visual.1996.568123,http://doi.ieeecomputersociety.org/10.1109/VISUAL.1996.568123,303.0,310.0,C,"An isosurface can be efficiently generated by visiting adjacent intersected cells in order, as if the isosurface were propagating itself. We previously proposed an extrema graph method (T. Itoh and K. Koyamada, 1995), which generates a graph connecting extremum points. The isosurface propagation starts from some of the intersected cells that are found both by visiting the cells through which arcs of the graph pass and by visiting the cells on the boundary of a volume. We propose an efficient method of searching for cells intersected by an isosurface. This method generates a volumetric skeleton. consisting of cells, like an extrema graph, by applying a thinning algorithm used in the image recognition area. Since it preserves the topological features of the volume and the connectivity of the extremum points, it necessarily intersects every isosurface. The method is more efficient than the extrema graph method, since it does not require that cells on the boundary be visited.",Takayuki Itoh;Yasushi Yamaguchi 0001;Koji Koyamada,T. Itoh;Y. Yamaguchi;K. Koyamada,"Tokyo Research Laboratory, IBM Japan;Graduate School of Arts and Sciences, The University of Tokyo;Tokyo Research Laboratory, IBM Japan",10.1109/visual.1991.175780,,73.0,22.0,0.0,28.0,,,cells order isosurface;recognition area preserves;generates graph connecting;volume;method searching,0.5701;0.4382;0.3050;0.2427;0.2146,"[np.int64(-1), np.int64(-1), -1, -1, -1]",77;54;-1;-1;-1,54;77,77,Surface Polygonization
Vis,2008,Sinus Endoscopy - Application of Advanced GPU Volume Rendering for Virtual Endoscopy,10.1109/tvcg.2008.161,http://dx.doi.org/10.1109/TVCG.2008.161,1491.0,1498.0,J,"For difficult cases in endoscopic sinus surgery, a careful planning of the intervention is necessary. Due to the reduced field of view during the intervention, the surgeons have less information about the surrounding structures in the working area compared to open surgery. Virtual endoscopy enables the visualization of the operating field and additional information, such as risk structures (e.g., optical nerve and skull base) and target structures to be removed (e.g., mucosal swelling). The Sinus Endoscopy system provides the functional range of a virtual endoscopic system with special focus on a realistic representation. Furthermore, by using direct volume rendering, we avoid time-consuming segmentation steps for the use of individual patient datasets. However, the image quality of the endoscopic view can be adjusted in a way that a standard computer with a modern standard graphics card achieves interactive frame rates with low CPU utilization. Thereby, characteristics of the endoscopic view are systematically used for the optimization of the volume rendering speed. The system design was based on a careful analysis of the endoscopic sinus surgery and the resulting needs for computer support. As a small standalone application it can be instantly used for surgical planning and patient education. First results of a clinical evaluation with ENT surgeons were employed to fine-tune the user interface, in particular to reduce the number of controls by using appropriate default values wherever possible. The system was used for preoperative planning in 102 cases, provides useful information for intervention planning (e.g., anatomic variations of the Rec. Frontalis), and closely resembles the intraoperative situation.",Arno Krüger;Christoph Kubisch;Gero Strauß;Bernhard Preim,Arno Krueger;Christoph Kubisch;Bernhard Preim;Gero Strauss,"Department of Simulation and Graphics, Otto-von-Guericke-University of Magdeburg, Germany;Department of Simulation and Graphics, Otto-von-Guericke-University of Magdeburg, Germany;ENT Department, University Hospital of Leipzig;Department of Simulation and Graphics, Otto-von-Guericke-University of Magdeburg, Germany",10.1109/visual.2003.1250370;10.1109/visual.2003.1250384;10.1109/visual.2004.98;10.1109/visual.2003.1250370,"medical visualization, sinus surgery, operation planning, virtual endoscopy, volume rendering",57.0,35.0,22.0,593.0,,,surgery virtual endoscopy;swelling sinus;provides useful information;frame rates;using appropriate default,0.6810;0.3314;0.1187;0.0552;0.0181,"[np.int64(-1), -1, -1, -1, -1]",48;-1;-1;-1;-1,48,48,Medical Imaging Techniques
InfoVis,2006,Measuring Data Abstraction Quality in Multiresolution Visualizations,10.1109/tvcg.2006.161,http://dx.doi.org/10.1109/TVCG.2006.161,709.0,716.0,J,"Data abstraction techniques are widely used in multiresolution visualization systems to reduce visual clutter and facilitate analysis from overview to detail. However, analysts are usually unaware of how well the abstracted data represent the original dataset, which can impact the reliability of results gleaned from the abstractions. In this paper, we define two data abstraction quality measures for computing the degree to which the abstraction conveys the original dataset: the histogram difference measure and the nearest neighbor measure. They have been integrated within XmdvTool, a public-domain multiresolution visualization system for multivariate data analysis that supports sampling as well as clustering to simplify data. Several interactive operations are provided, including adjusting the data abstraction level, changing selected regions, and setting the acceptable data abstraction quality level. Conducting these operations, analysts can select an optimal data abstraction level. Also, analysts can compare different abstraction methods using the measures to see how well relative data density and outliers are maintained, and then select an abstraction method that meets the requirement of their analytic tasks",Qingguang Cui;Matthew O. Ward;Elke A. Rundensteiner;Jing Yang 0001,Qingguang Cui;Matthew Ward;Elke Rundensteiner;Jing Yang,"Worcester Polytechnic Institute, Worcester, MA, USA;Worcester Polytechnic Institute, Worcester, MA, USA;Worcester Polytechnic Institute, Worcester, MA, USA;University of North Carolina, Charlotte, Charlotte, NC, USA",10.1109/infvis.2004.19;10.1109/visual.2005.1532819;10.1109/infvis.2004.15;10.1109/visual.1995.485139;10.1109/infvis.2000.885088;10.1109/infvis.2004.19,"Metrics, Clustering, Sampling, Multiresolution Visualization",128.0,68.0,28.0,977.0,,,visualization multivariate data;nearest neighbor;unaware abstracted;impact reliability results;regions setting acceptable,0.5716;0.1777;0.1415;0.1315;0.1158,"[np.int64(1), -1, -1, -1, -1]",11;-1;-1;-1;-1,11,11,Multivariate Data Visualization
Vis,1999,Spiraling Edge: fast surface reconstruction from partially organized sample points,10.1109/visual.1999.809903,http://dx.doi.org/10.1109/VISUAL.1999.809903,317.0,538.0,C,"Many applications produce three-dimensional points that must be further processed to generate a surface. Surface reconstruction algorithms that start with a set of unorganized points are extremely time-consuming. Sometimes however, points are generated such that there is additional information available to the reconstruction algorithm. We present Spiraling Edge, a specialized algorithm for surface reconstruction that is three orders of magnitude faster than algorithms for the general case. In addition to sample point locations, our algorithm starts with normal information and knowledge of each point's neighbors. Our algorithm produces a localized approximation to the surface by creating a star-shaped triangulation between a point and a subset of its nearest neighbors. This surface patch is extended by locally triangulating each of the points along the edge of the patch. As each edge point is triangulated, it is removed from the edge and new edge points along the patch's edge are inserted in its place. The updated edge spirals out over the surface until the edge encounters a surface boundary and stops growing in that direction, or until the edge reduces to a small hole that is filled by the final triangle.",Patricia Crossno;Edward Angel,P. Crossno;E. Angel,"Sandia National Laboratories, USA;University of New Mexico, USA",10.1109/visual.1997.663930;10.1109/visual.1998.745286;10.1109/visual.1997.663930,"Surface reconstruction, advancing front, triangulation",37.0,8.0,6.0,87.0,,,algorithm surface reconstruction;spirals;information knowledge point;patch extended locally;extremely time,0.6886;0.2777;0.1489;0.1463;-0.0510,"[np.int64(-1), -1, -1, -1, -1]",65;-1;-1;-1;-1,65,65,Surface Reconstruction Techniques
Vis,2021,Revisiting Dimensionality Reduction Techniques for Visual Cluster Analysis: An Empirical Study,10.1109/tvcg.2021.3114694,http://dx.doi.org/10.1109/TVCG.2021.3114694,529.0,539.0,J,"Dimensionality Reduction (DR) techniques can generate 2D projections and enable visual exploration of cluster structures of high-dimensional datasets. However, different DR techniques would yield various patterns, which significantly affect the performance of visual cluster analysis tasks. We present the results of a user study that investigates the influence of different DR techniques on visual cluster analysis. Our study focuses on the most concerned property types, namely the linearity and locality, and evaluates twelve representative DR techniques that cover the concerned properties. Four controlled experiments were conducted to evaluate how the DR techniques facilitate the tasks of 1) cluster identification, 2) membership identification, 3) distance comparison, and 4) density comparison, respectively. We also evaluated users' subjective preference of the DR techniques regarding the quality of projected clusters. The results show that: 1) Non-linear and Local techniques are preferred in cluster identification and membership identification; 2) Linear techniques perform better than non-linear techniques in density comparison; 3) UMAP (Uniform Manifold Approximation and Projection) and t-SNE (t-Distributed Stochastic Neighbor Embedding) perform the best in cluster identification and membership identification; 4) NMF (Nonnegative Matrix Factorization) has competitive performance in distance comparison; 5) t-SNLE (t-Distributed Stochastic Neighbor Linear Embedding) has competitive performance in density comparison.",Jiazhi Xia;Yuchen Zhang;Jie Song;Yang Chen;Yunhai Wang;Shixia Liu,Jiazhi Xia;Yuchen Zhang;Jie Song;Yang Chen;Yunhai Wang;Shixia Liu,"School of Computer Science and Engineering, Central South University, China;School of Computer Science and Engineering, Central South University, China;School of Computer Science and Engineering, Central South University, China;I4 data, United States;School of Computer Science and Technology, Shandong University, China;School of Software, Tsinghua University, China",10.1109/tvcg.2015.2467552;10.1109/tvcg.2011.220;10.1109/infvis.2003.1249017;10.1109/tvcg.2016.2598831;10.1109/tvcg.2017.2745258;10.1109/vast47406.2019.8986943;10.1109/tvcg.2020.3030432;10.1109/tvcg.2019.2934660;10.1109/tvcg.2018.2865020;10.1109/tvcg.2015.2467552,"Dimensionality reduction,visual cluster analysis,perception-based evaluation",17.0,39.0,61.0,1783.0,,,visual cluster analysis;linearity locality evaluates;significantly affect performance;identification nmf nonnegative;property types,0.7279;0.2847;0.0893;0.0846;0.0654,"[np.int64(1), -1, -1, -1, -1]",8;-1;-1;-1;-1,8,8,Cluster Analysis Tools
InfoVis,2008,HiPP: A Novel Hierarchical Point Placement Strategy and its Application to the Exploration of Document Collections,10.1109/tvcg.2008.138,http://dx.doi.org/10.1109/TVCG.2008.138,1229.0,1236.0,J,"Point placement strategies aim at mapping data points represented in higher dimensions to bi-dimensional spaces and are frequently used to visualize relationships amongst data instances. They have been valuable tools for analysis and exploration of data sets of various kinds. Many conventional techniques, however, do not behave well when the number of dimensions is high, such as in the case of documents collections. Later approaches handle that shortcoming, but may cause too much clutter to allow flexible exploration to take place. In this work we present a novel hierarchical point placement technique that is capable of dealing with these problems. While good grouping and separation of data with high similarity is maintained without increasing computation cost, its hierarchical structure lends itself both to exploration in various levels of detail and to handling data in subsets, improving analysis capability and also allowing manipulation of larger data sets.",Fernando Vieira Paulovich;Rosane Minghim,Fernando V. Paulovich;Rosane Minghim,"ICMC, Instituto de Ciências Matemáticas e de Computaçãao, University of São Paulo, Sao Paulo, Brazil;ICMC, Instituto de Ciências Matemáticas e de Computaçãao, University of São Paulo, Sao Paulo, Brazil",10.1109/visual.1999.809866;10.1109/visual.1991.175815;10.1109/vast.2007.4389002;10.1109/visual.1996.567787,"Text and document visualization, hierarchical multidimensional visualization, visual knowledge discovery, high-dimensional data",118.0,62.0,24.0,836.0,,,hierarchical point placement;documents collections;bi dimensional spaces;data;increasing computation cost,0.6046;0.4158;0.3215;0.2702;0.1649,"[np.int64(-1), np.int64(-1), -1, -1, -1]",74;75;-1;-1;-1,74;75,74,Dense Point Visualization
Vis,2011,Vortex Visualization in Ultra Low Reynolds Number Insect Flight,10.1109/tvcg.2011.260,http://dx.doi.org/10.1109/TVCG.2011.260,2071.0,2079.0,J,"We present the visual analysis of a biologically inspired CFD simulation of the deformable flapping wings of a dragonfly as it takes off and begins to maneuver, using vortex detection and integration-based flow lines. The additional seed placement and perceptual challenges introduced by having multiple dynamically deforming objects in the highly unsteady 3D flow domain are addressed. A brief overview of the high speed photogrammetry setup used to capture the dragonfly takeoff, parametric surfaces used for wing reconstruction, CFD solver and underlying flapping flight theory is presented to clarify the importance of several unsteady flight mechanisms, such as the leading edge vortex, that are captured visually. A novel interactive seed placement method is used to simplify the generation of seed curves that stay in the vicinity of relevant flow phenomena as they move with the flapping wings. This method allows a user to define and evaluate the quality of a seed's trajectory over time while working with a single time step. The seed curves are then used to place particles, streamlines and generalized streak lines. The novel concept of flowing seeds is also introduced in order to add visual context about the instantaneous vector fields surrounding smoothly animate streak lines. Tests show this method to be particularly effective at visually capturing vortices that move quickly or that exist for a very brief period of time. In addition, an automatic camera animation method is used to address occlusion issues caused when animating the immersed wing boundaries alongside many geometric flow lines. Each visualization method is presented at multiple time steps during the up-stroke and down-stroke to highlight the formation, attachment and shedding of the leading edge vortices in pairs of wings. Also, the visualizations show evidence of wake capture at stroke reversal which suggests the existence of previously unknown unsteady lift generation mechanisms that are unique to quad wing insects.",Christopher Koehler;Thomas Wischgoll;Haibo Dong;Zachary Gaston,Christopher Koehler;Thomas Wischgoll;Haibo Dong;Zachary Gaston,"College of Engineering and Computer Science, Wright State University, USA;College of Engineering and Computer Science, Wright State University, USA;College of Mechanical and Materials Engineering, Wright State University, USA;College of Mechanical and Materials Engineering, Wright State University, USA",10.1109/visual.2002.1183789;10.1109/visual.2005.1532830;10.1109/tvcg.2007.70557;10.1109/visual.2005.1532831;10.1109/tvcg.2008.163;10.1109/tvcg.2010.169;10.1109/visual.2005.1532848;10.1109/visual.2005.1532850;10.1109/tvcg.2010.212;10.1109/visual.2000.885690;10.1109/tvcg.2010.198;10.1109/visual.2004.113;10.1109/visual.1998.745296;10.1109/tvcg.2007.70595;10.1109/tvcg.2009.190;10.1109/tvcg.2008.133;10.1109/tvcg.2006.199;10.1109/visual.2002.1183821;10.1109/tvcg.2007.70545;10.1109/tvcg.2010.166;10.1109/tvcg.2006.201;10.1109/visual.2002.1183789,"Flow visualization, flowing seed points, streak lines, streamlines, insect flight, vortex visualization, unsteady flow",42.0,31.0,47.0,1318.0,,,wings visualizations;reconstruction cfd solver;caused animating immersed;detection integration based;simplify generation seed,0.6005;0.3056;0.1888;0.1145;0.0880,"[np.int64(1), -1, -1, -1, -1]",3;-1;-1;-1;-1,3,3,Aerospace Visualizations
Vis,2021,MultiVision: Designing Analytical Dashboards with Deep Learning Based Recommendation,10.1109/tvcg.2021.3114826,http://dx.doi.org/10.1109/TVCG.2021.3114826,162.0,172.0,J,"We contribute a deep-learning-based method that assists in designing analytical dashboards for analyzing a data table. Given a data table, data workers usually need to experience a tedious and time-consuming process to select meaningful combinations of data columns for creating charts. This process is further complicated by the needs of creating dashboards composed of multiple views that unveil different perspectives of data. Existing automated approaches for recommending multiple-view visualizations mainly build on manually crafted design rules, producing sub-optimal or irrelevant suggestions. To address this gap, we present a deep learning approach for selecting data columns and recommending multiple charts. More importantly, we integrate the deep learning models into a mixed-initiative system. Our model could make recommendations given optional user-input selections of data columns. The model, in turn, learns from provenance data of authoring logs in an offline manner. We compare our deep learning model with existing methods for visualization recommendation and conduct a user study to evaluate the usefulness of the system.",Aoyu Wu;Yun Wang 0012;Mengyu Zhou;Xinyi He;Haidong Zhang;Huamin Qu;Dongmei Zhang 0001,Aoyu Wu;Yun Wang;Mengyu Zhou;Xinyi He;Haidong Zhang;Huamin Qu;Dongmei Zhang,"Hong Kong University of Science and Technology, Hong Kong and Microsoft Research Area, United States;Microsoft Research Area, United States;Microsoft Research Area, United States;Microsoft Research Area, United States;Microsoft Research Area, United States;Hong Kong University of Science and Technology, Hong Kong;Microsoft Research Area, United States",10.1109/tvcg.2020.3030338;10.1109/tvcg.2019.2934810;10.1109/tvcg.2019.2934332;10.1109/tvcg.2018.2865138;10.1109/tvcg.2013.119;10.1109/tvcg.2016.2598620;10.1109/tvcg.2017.2744019;10.1109/tvcg.2018.2865235;10.1109/tvcg.2007.70594;10.1109/tvcg.2020.3030430;10.1109/tvcg.2018.2865240;10.1109/tvcg.2020.3030387;10.1109/tvcg.2017.2744198;10.1109/tvcg.2014.2346291;10.1109/tvcg.2018.2865158;10.1109/tvcg.2018.2864903;10.1109/tvcg.2016.2599030;10.1109/tvcg.2020.3030403;10.1109/tvcg.2020.3030396;10.1109/tvcg.2018.2865145;10.1109/tvcg.2017.2744843;10.1109/tvcg.2019.2934798;10.1109/tvcg.2019.2934398;10.1109/tvcg.2015.2467191;10.1109/tvcg.2020.3030423,"Visualization Recommendation,Deep Learning,Multiple-View,Dashboard,Mixed-Initiative,Visualization Provenance",14.0,31.0,73.0,1788.0,,,dashboards analyzing data;present deep learning;select meaningful combinations;manually crafted;irrelevant,0.5685;0.3128;0.2108;0.1375;0.0307,"[np.int64(1), -1, -1, -1, -1]",14;-1;-1;-1;-1,14,14,Visual Analytics Systems
Vis,2001,Chromatin decondensation: case study of tracking features in confocal data,10.1109/visual.2001.964546,http://dx.doi.org/10.1109/VISUAL.2001.964546,441.0,444.0,C,"In this case study we discuss an interactive feature tracking system and its use for the analysis of chromatin decondensation. Features are described as points in a multidimensional attribute space. Distances between points are used as a measure for feature correspondence. Users can interactively experiment with the correspondence measure in order to gain insight in chromatin movement. In addition, by defining time as an attribute, tracking problems related to noisy confocal data can be circumvented.",Wim C. de Leeuw;Robert van Liere,W. de Leeuw;R. van Liere,"Center of Mathematics and Computer Science, Amsterdam, Netherlands;Center of Mathematics and Computer Science, Amsterdam, Netherlands",10.1109/visual.2000.885735,"feature tracking, multidimensional visualization, biomedical imaging",13.0,3.0,8.0,63.0,,,insight chromatin movement;measure feature correspondence;users interactively;noisy confocal;addition defining time,0.6764;0.3660;0.2113;0.1903;0.0508,"[np.int64(-1), np.int64(-1), -1, -1, -1]",32;54;-1;-1;-1,32;54,32,Chromatin Visualization
InfoVis,2017,Skeleton-Based Scagnostics,10.1109/tvcg.2017.2744339,http://dx.doi.org/10.1109/TVCG.2017.2744339,542.0,552.0,J,"Scatterplot matrices (SPLOMs) are widely used for exploring multidimensional data. Scatterplot diagnostics (scagnostics) approaches measure characteristics of scatterplots to automatically find potentially interesting plots, thereby making SPLOMs more scalable with the dimension count. While statistical measures such as regression lines can capture orientation, and graph-theoretic scagnostics measures can capture shape, there is no scatterplot characterization measure that uses both descriptors. Based on well-known results in shape analysis, we propose a scagnostics approach that captures both scatterplot shape and orientation using skeletons (or medial axes). Our representation can handle complex spatial distributions, helps discovery of principal trends in a multiscale way, scales visually well with the number of samples, is robust to noise, and is automatic and fast to compute. We define skeleton-based similarity metrics for the visual exploration and analysis of SPLOMs. We perform a user study to measure the human perception of scatterplot similarity and compare the outcome to our results as well as to graph-based scagnostics and other visual quality metrics. Our skeleton-based metrics outperform previously defined measures both in terms of closeness to perceptually-based similarity and computation time efficiency.",José Matute;Alexandru C. Telea;Lars Linsen,José Matute;Alexandru C. Telea;Lars Linsen,"Institute of Computer Science, University of Münster, Germany;Johann Bernoulli Institute for Mathematics and Computer Science, University of Groningen, Groningen, The Netherlands;Institute of Computer Science, University of Münster, Germany",10.1109/vast.2011.6102437;10.1109/tvcg.2011.233;10.1109/tvcg.2010.213;10.1109/tvcg.2011.223;10.1109/tvcg.2011.220;10.1109/vast.2008.4677367;10.1109/vast.2009.5332628;10.1109/vast.2011.6102437,"Multidimensional Data (primary keyword),High-Dimensional Data",30.0,22.0,65.0,729.0,,,perception scatterplot similarity;define skeleton;sploms widely used;representation handle complex;perform,0.6837;0.2581;0.2043;0.1282;0.0343,"[np.int64(-1), -1, -1, -1, -1]",62;-1;-1;-1;-1,62,62,Visual Perception Analysis
Vis,1997,Two-phase perspective ray casting for interactive volume navigation,10.1109/visual.1997.663878,http://dx.doi.org/10.1109/VISUAL.1997.663878,183.0,189.0,C,"Volume navigation is the interactive exploration of volume data sets by ""flying"" the view point through the data, producing a volume rendered view at each frame. The authors present an inexpensive perspective volume navigation method designed to run on a PC platform with accelerated 3D graphics hardware. They compute perspective projections at each frame, allow trilinear interpolation of sample points, and render both gray scale and RGB volumes by volumetric compositing. The implementation handles arbitrarily large volumes, by dynamically swapping data within the local depth-limited frustum into main memory as the viewpoint moves through the volume. They describe a new ray casting algorithm that takes advantage of the coherence inherent in adjacent frames to generate a sequence of approximate animated frames much faster than they could be computed individually. They also take advantage of the 3D graphics acceleration hardware to offload much of the alpha blending and resampling from the CPU.",Martin L. Brady;Kenneth K. Jung;H. T. Nguyen;Thinh P. Q. Nguyen,M. Brady;K. Jung;H.T. Nguyen;T. Nguyen,"Microcomputer Research Laboratories, Intel Corporation, USA;Microcomputer Research Laboratories, Intel Corporation, USA;;Microcomputer Research Laboratories, Intel Corporation, USA",10.1109/visual.1994.346340;10.1109/visual.1995.485154;10.1109/visual.1996.567603;10.1109/visual.1994.346340,"Volume navigation, volume rendering, 3D medical imaging, scientific visualization, texture mapping",67.0,9.0,18.0,130.0,,,volumetric compositing implementation;animated frames;faster;limited frustum main;data local,0.6213;0.3354;0.1005;0.0993;0.0544,"[np.int64(0), -1, -1, -1, -1]",0;-1;-1;-1;-1,0,0,Volume Rendering Techniques
Vis,2005,Particle and texture based spatiotemporal visualization of time-dependent vector fields,10.1109/visual.2005.1532852,http://dx.doi.org/10.1109/VISUAL.2005.1532852,639.0,646.0,C,"We propose a hybrid particle and texture based approach for the visualization of time-dependent vector fields. The underlying space-time framework builds a dense vector field representation in a two-step process: 1) particle-based forward integration of trajectories in spacetime for temporal coherence, and 2) texture-based convolution along another set of paths through the spacetime for spatially correlated patterns. Particle density is controlled by stochastically injecting and removing particles, taking into account the divergence of the vector field. Alternatively, a uniform density can be maintained by placing exactly one particle in each cell of a uniform grid, which leads to particle-in-cell forward advection. Moreover, we discuss strategies of previous visualization methods for unsteady flow and show how they address issues of spatiotemporal coherence and dense visual representations. We demonstrate how our framework is capable of realizing several of these strategies. Finally, we present an efficient GPU implementation that facilitates an interactive visualization of unsteady 2D flow on Shader Model 3 compliant graphics hardware.",Daniel Weiskopf;Frederik Schramm;Gordon Erlebacher;Thomas Ertl,D. Weiskopf;F. Schramm;G. Erlebacher;T. Ertl,"Institute of Visualization and Interactive Systems, University of Stuttgart, Germany and Graphics, Usability and Visualization (GrUVi) Laboratory, Simon Fraser University, Canada;Institute of Visualization and Interactive Systems, University of Stuttgart, Germany;School of Computational Science and Information Technology, Florida State University, USA;Institute of Visualization and Interactive Systems, University of Stuttgart, Germany",10.1109/visual.2003.1250377;10.1109/visual.2003.1250363;10.1109/visual.2003.1250361;10.1109/visual.2000.885689;10.1109/visual.2003.1250402;10.1109/visual.2003.1250364;10.1109/visual.2003.1250377,"Unsteady flow visualization, visualization framework, LIC, texture advection, particle systems, GPU methods",36.0,7.0,31.0,259.0,,,particle texture based;visualization unsteady;spacetime temporal coherence;gpu implementation facilitates;account divergence,0.5397;0.3726;0.3573;0.3134;0.1209,"[np.int64(-1), np.int64(-1), np.int64(-1), -1, -1]",72;83;17;-1;-1,17;72;83,72,Textured Motion Analysis
Vis,2023,Let the Chart Spark: Embedding Semantic Context into Chart with Text-to-Image Generative Model,10.1109/tvcg.2023.3326913,http://dx.doi.org/10.1109/TVCG.2023.3326913,284.0,294.0,J,"Pictorial visualization seamlessly integrates data and semantic context into visual representation, conveying complex information in an engaging and informative manner. Extensive studies have been devoted to developing authoring tools to simplify the creation of pictorial visualizations. However, mainstream works follow a retrieving-and-editing pipeline that heavily relies on retrieved visual elements from a dedicated corpus, which often compromise data integrity. Text-guided generation methods are emerging, but may have limited applicability due to their predefined entities. In this work, we propose ChartSpark, a novel system that embeds semantic context into chart based on text-to-image generative models. ChartSpark generates pictorial visualizations conditioned on both semantic context conveyed in textual inputs and data information embedded in plain charts. The method is generic for both foreground and background pictorial generation, satisfying the design practices identified from empirical research into existing pictorial visualizations. We further develop an interactive visual interface that integrates a text analyzer, editing module, and evaluation module to enable users to generate, modify, and assess pictorial visualizations. We experimentally demonstrate the usability of our tool, and conclude with a discussion of the potential of using text-to-image generative models combined with an interactive interface for visualization design.",Shishi Xiao;Suizi Huang;Yue Lin;Yilin Ye;Wei Zeng 0004,Shishi Xiao;Suizi Huang;Yue Lin;Yilin Ye;Wei Zeng,"Hong Kong University of Science and Technology (Guangzhou), Guangzhou, China;Hong Kong University of Science and Technology (Guangzhou), Guangzhou, China;Hong Kong University of Science and Technology (Guangzhou), Guangzhou, China;Hong Kong University of Science and Technology (Guangzhou), Guangzhou, China;Hong Kong University of Science and Technology (Guangzhou), Guangzhou, China",0.1109/tvcg.2012.197;10.1109/tvcg.2015.2467732;10.1109/tvcg.2013.234;10.1109/tvcg.2019.2934810;10.1109/tvcg.2019.2934785;10.1109/tvcg.2011.175;10.1109/tvcg.2016.2598620;10.1109/tvcg.2012.221;10.1109/tvcg.2020.3030448;10.1109/tvcg.2022.3209486;10.1109/tvcg.2022.3209357;10.1109/tvcg.2019.2934398;10.1109/tvcg.2022.3209447,"pictorial visualization,generative model,authoring tool",,5.0,61.0,1226.0,,,generates pictorial visualizations;data semantic context;editing module evaluation;dedicated corpus compromise;simplify,0.6739;0.3490;0.1645;0.1555;0.0430,"[np.int64(1), -1, -1, -1, -1]",51;-1;-1;-1;-1,51,51,Dynamic Visualizations
VAST,2011,How locus of control influences compatibility with visualization style,10.1109/vast.2011.6102445,http://dx.doi.org/10.1109/VAST.2011.6102445,81.0,90.0,C,"Existing research suggests that individual personality differences are correlated with a user's speed and accuracy in solving problems with different types of complex visualization systems. In this paper, we extend this research by isolating factors in personality traits as well as in the visualizations that could have contributed to the observed correlation. We focus on a personality trait known as “locus of control,” which represents a person's tendency to see themselves as controlled by or in control of external events. To isolate variables of the visualization design, we control extraneous factors such as color, interaction, and labeling, and specifically focus on the overall layout style of the visualizations. We conduct a user study with four visualizations that gradually shift from an indentation metaphor to a containment metaphor and compare the participants' speed, accuracy, and preference with their locus of control. Our findings demonstrate that there is indeed a correlation between the two: participants with an internal locus of control perform more poorly with visualizations that employ a containment metaphor, while those with an external locus of control perform well with such visualizations. We discuss a possible explanation for this relationship based in cognitive psychology and propose that these results can be used to better understand how people use visualizations and how to adapt visual analytics design to an individual user's needs.",Caroline Ziemkiewicz;R. Jordan Crouser;Ashley Rye Yauilla;Sara L. Su;William Ribarsky;Remco Chang,Caroline Ziemkiewicz;R. Jordan Crouser;Ashley Rye Yauilla;Sara L. Su;William Ribarsky;Remco Chang,"Brown University, USA;Tufts University, USA;Winthrop University, USA;Tufts University, USA;UNC-Charlotte, USA;Tufts University, USA",10.1109/vast.2010.5653587;10.1109/tvcg.2008.171;10.1109/tvcg.2008.121;10.1109/vast.2010.5653587,,70.0,40.0,31.0,509.0,HM,,user study visualizations;personality trait;indentation metaphor;speed accuracy solving;control extraneous,0.6874;0.2593;0.2516;0.1096;0.0234,"[np.int64(1), -1, -1, -1, -1]",69;-1;-1;-1;-1,69,69,Visualization User Studies
Vis,1999,Visual debugging of visualization software: a case study for particle systems,10.1109/visual.1999.809919,http://dx.doi.org/10.1109/VISUAL.1999.809919,417.0,554.0,C,"Visualization systems are complex dynamic software systems. Debugging such systems is difficult using conventional debuggers because the programmer must try to imagine the three-dimensional geometry based on a list of positions and attributes. In addition, the programmer must be able to mentally animate changes in those positions and attributes to grasp dynamic behaviors within the algorithm. We show that representing geometry, attributes, and relationships graphically permits visual pattern recognition skills to be applied to the debugging problem. The particular application is a particle system used for isosurface extraction from volumetric data. Coloring particles based on individual attributes is especially helpful when these colorings are viewed as animations over successive iterations in the program. Although we describe a particular application, the types of tools that we discuss can be applied to a variety of problems.",Patricia Crossno;Edward Angel,P. Crossno;E. Angel,"Sandia National Laboratories, USA;University of New Mexico, USA",10.1109/visual.1996.568120;10.1109/visual.1997.663930;10.1109/visual.1996.568120,,17.0,7.0,17.0,111.0,,,visualization systems;using conventional debuggers;particle used isosurface;animate changes positions;able,0.5637;0.3595;0.2617;0.1512;-0.0170,"[np.int64(1), np.int64(-1), -1, -1, -1]",16;23;-1;-1;-1,16;23,16,Interactive Visualization Systems
Vis,2023,ExTreeM: Scalable Augmented Merge Tree Computation via Extremum Graphs,10.1109/tvcg.2023.3326526,http://dx.doi.org/10.1109/TVCG.2023.3326526,1085.0,1094.0,J,"Over the last decade merge trees have been proven to support a plethora of visualization and analysis tasks since they effectively abstract complex datasets. This paper describes the ExTreeM-Algorithm: A scalable algorithm for the computation of merge trees via extremum graphs. The core idea of ExTreeM is to first derive the extremum graph $\mathcal{G}$ of an input scalar field $f$ defined on a cell complex $\mathcal{K}$, and subsequently compute the unaugmented merge tree of $f$ on $\mathcal{G}$ instead of $\mathcal{K}$; which are equivalent. Any merge tree algorithm can be carried out significantly faster on $\mathcal{G}$, since $\mathcal{K}$ in general contains substantially more cells than $\mathcal{G}$. To further speed up computation, ExTreeM includes a tailored procedure to derive merge trees of extremum graphs. The computation of the fully augmented merge tree, i.e., a merge tree domain segmentation of $\mathcal{K}$, can then be performed in an optional post-processing step. All steps of ExTreeM consist of procedures with high parallel efficiency, and we provide a formal proof of its correctness. Our experiments, performed on publicly available datasets, report a speedup of up to one order of magnitude over the state-of-the-art algorithms included in the TTK and VTK-m software libraries, while also requiring significantly less memory and exhibiting excellent scaling behavior.",Jonas Lukasczyk;Michael Will;Florian Wetzels;Gunther H. Weber;Christoph Garth,Jonas Lukasczyk;Michael Will;Florian Wetzels;Gunther H. Weber;Christoph Garth,"RPTU Kaiserslautern-Landau, Germany;RPTU Kaiserslautern-Landau, Germany;RPTU Kaiserslautern-Landau, Germany;Lawrence Berkeley National Lab., USA;RPTU Kaiserslautern-Landau, Germany",0.1109/tvcg.2019.2934257;10.1109/tvcg.2017.2743938,"Scalar field topology,merge trees,persistence pairs,high performance computing",,0.0,41.0,334.0,,,computation merge trees;domain segmentation;extremum graph;contains substantially cells;scalar field,0.6246;0.3878;0.3239;0.1739;0.1321,"[np.int64(-1), np.int64(-1), -1, -1, -1]",19;53;-1;-1;-1,19;53,19,Tree Structures
InfoVis,2012,PivotPaths: Strolling through Faceted Information Spaces,10.1109/tvcg.2012.252,http://dx.doi.org/10.1109/TVCG.2012.252,2709.0,2718.0,J,"We present PivotPaths, an interactive visualization for exploring faceted information resources. During both work and leisure, we increasingly interact with information spaces that contain multiple facets and relations, such as authors, keywords, and citations of academic publications, or actors and genres of movies. To navigate these interlinked resources today, one typically selects items from facet lists resulting in abrupt changes from one subset of data to another. While filtering is useful to retrieve results matching specific criteria, it can be difficult to see how facets and items relate and to comprehend the effect of filter operations. In contrast, the PivotPaths interface exposes faceted relations as visual paths in arrangements that invite the viewer to `take a stroll' through an information space. PivotPaths supports pivot operations as lightweight interaction techniques that trigger gradual transitions between views. We designed the interface to allow for casual traversal of large collections in an aesthetically pleasing manner that encourages exploration and serendipitous discoveries. This paper shares the findings from our iterative design-and-evaluation process that included semi-structured interviews and a two-week deployment of PivotPaths applied to a large database of academic publications.",Marian Dörk;Nathalie Henry Riche;Gonzalo A. Ramos;Susan T. Dumais,Marian Dörk;Nathalie Henry Riche;Gonzalo Ramos;Susan Dumais,"University of Calgary, Canada;Microsoft, USA;Microsoft, USA;Microsoft, USA",10.1109/vast.2009.5333443;10.1109/tvcg.2010.154;10.1109/vast.2006.261426;10.1109/vast.2007.4389006;10.1109/vast.2008.4677370;10.1109/tvcg.2007.70539;10.1109/tvcg.2008.175;10.1109/tvcg.2009.108;10.1109/vast.2009.5333443,"Information visualization, interactivity, node-link diagrams, animation, information seeking, exploratory search",217.0,126.0,24.0,1637.0,,,exploring faceted information;lightweight interaction techniques;pivotpaths applied large;work leisure increasingly;invite,0.6254;0.2994;0.2773;0.1799;-0.1157,"[np.int64(-1), -1, -1, -1, -1]",55;-1;-1;-1;-1,55,55,Information Visualization Preparation
Vis,2023,Average Estimates in Line Graphs Are Biased Toward Areas of Higher Variability,10.1109/tvcg.2023.3326589,http://dx.doi.org/10.1109/TVCG.2023.3326589,306.0,315.0,J,"We investigate variability overweighting, a previously undocumented bias in line graphs, where estimates of average value are biased toward areas of higher variability in that line. We found this effect across two preregistered experiments with 140 and 420 participants. These experiments also show that the bias is reduced when using a dot encoding of the same series. We can model the bias with the average of the data series and the average of the points drawn along the line. This bias might arise because higher variability leads to stronger weighting in the average calculation, either due to the longer line segments (even though those segments contain the same number of data values) or line segments with higher variability being otherwise more visually salient. Understanding and predicting this bias is important for visualization design guidelines, recommendation systems, and tool builders, as the bias can adversely affect estimates of averages and trends.",Dominik Moritz;Lace M. K. Padilla;Francis Nguyen;Steven L. Franconeri,Dominik Moritz;Lace M. Padilla;Francis Nguyen;Steven L. Franconeri,"Carnegie Mellon University, USA;Northeastern University, USA;Northwestern University, USA;UBC, Canada",0.1109/infvis.2005.1532136;10.1109/tvcg.2018.2865077;10.1109/tvcg.2009.131;10.1109/tvcg.2021.3114783;10.1109/tvcg.2010.162;10.1109/tvcg.2021.3114684;10.1109/tvcg.2019.2934784;10.1109/tvcg.2019.2934400;10.1109/tvcg.2021.3114865,"bias,lines graph,ensemble perception,average",,2.0,34.0,440.0,HM,,bias important visualization;series average;using dot encoding;systems tool builders;longer,0.5901;0.3591;0.0936;0.0786;0.0677,"[np.int64(1), np.int64(-1), -1, -1, -1]",4;-1;-1;-1;-1,4,4,Visualization Bias Analysis
Vis,2024,Motion-Based Visual Encoding Can Improve Performance on Perceptual Tasks with Dynamic Time Series,10.1109/tvcg.2024.3456405,http://dx.doi.org/10.1109/TVCG.2024.3456405,163.0,173.0,J,"Dynamic data visualizations can convey large amounts of information over time, such as using motion to depict changes in data values for multiple entities. Such dynamic displays put a demand on our visual processing capacities, yet our perception of motion is limited. Several techniques have been shown to improve the processing of dynamic displays. Staging the animation to sequentially show steps in a transition and tracing object movement by displaying trajectory histories can improve processing by reducing the cognitive load. In this paper, We examine the effectiveness of staging and tracing in dynamic displays. We showed participants animated line charts depicting the movements of lines and asked them to identify the line with the highest mean and variance. We manipulated the animation to display the lines with or without staging, tracing and history, and compared the results to a static chart as a control. Results showed that tracing and staging are preferred by participants, and improve their performance in mean and variance tasks respectively. They also preferred display time 3 times shorter when staging is used. Also, encoding animation speed with mean and variance in congruent tasks is associated with higher accuracy. These findings help inform real-world best practices for building dynamic displays. The supplementary materials can be found at https://osf.io/8c95v/",Songwen Hu;Ouxun Jiang;Jeffrey Riedmiller;Cindy Xiong Bearfield,Songwen Hu;Ouxun Jiang;Jeffrey Riedmiller;Cindy Xiong Bearfield,"Georgia Tech., USA;Northwestern University, USA;Dolby Laboratories, USA;Georgia Tech., USA",10.1109/infvis.1999.801854;10.1109/tvcg.2019.2934397;10.1109/tvcg.2019.2934288;10.1109/tvcg.2014.2346424;10.1109/vast.2012.6400552;10.1109/tvcg.2020.3029413;10.1109/tvcg.2007.70539;10.1109/tvcg.2018.2864909;10.1109/tvcg.2013.191;10.1109/tvcg.2018.2865193;10.1109/tvcg.2008.125;10.1109/tvcg.2018.2865147;10.1109/tvcg.2020.3030418;10.1109/infvis.2001.963279;10.1109/tvcg.2022.3209369,"Animation,Dynamic Displays,,,Perception,Motion,Analytic Tasks",,0.0,56.0,130.0,,,animated line charts;processing reducing cognitive;tracing staging preferred;highest mean variance;materials https,0.6243;0.3407;0.1860;0.0798;0.0170,"[np.int64(-1), -1, -1, -1, -1]",85;-1;-1;-1;-1,85,85,Dynamic Data Visualization
Vis,2024,Defogger: A Visual Analysis Approach for Data Exploration of Sensitive Data Protected by Differential Privacy,10.1109/tvcg.2024.3456304,http://dx.doi.org/10.1109/TVCG.2024.3456304,448.0,458.0,J,"Differential privacy ensures the security of individual privacy but poses challenges to data exploration processes because the limited privacy budget incapacitates the flexibility of exploration and the noisy feedback of data requests leads to confusing uncertainty. In this study, we take the lead in describing corresponding exploration scenarios, including underlying requirements and available exploration strategies. To facilitate practical applications, we propose a visual analysis approach to the formulation of exploration strategies. Our approach applies a reinforcement learning model to provide diverse suggestions for exploration strategies according to the exploration intent of users. A novel visual design for representing uncertainty in correlation patterns is integrated into our prototype system to support the proposed approach. Finally, we implemented a user study and two case studies. The results of these studies verified that our approach can help develop strategies that satisfy the exploration intent of users.",Xumeng Wang;Shuangcheng Jiao;Chris Bryan,Xumeng Wang;Shuangcheng Jiao;Chris Bryan,"DISSec, Nankai University, China;DISSec, Nankai University, China;SCAI, Arizona State University, USA",10.1109/tvcg.2018.2865040;10.1109/tvcg.2013.124;10.1109/tvcg.2015.2467199;10.1109/tvcg.2017.2743959;10.1109/tvcg.2018.2864889;10.1109/tvcg.2023.3327195;10.1109/tvcg.2018.2865027;10.1109/tvcg.2023.3326929;10.1109/tvcg.2009.114;10.1109/vast50239.2020.00006;10.1109/tvcg.2017.2745139;10.1109/tvcg.2015.2467191;10.1109/tvcg.2020.3030369;10.1109/tvcg.2022.3209391,"Differential privacy,Visual data analysis,,,Data exploration,Visualization for uncertainty illustration",,0.0,44.0,176.0,,,data exploration;privacy budget incapacitates;representing uncertainty correlation;intent users novel;available,0.6115;0.4134;0.2617;0.2232;-0.0658,"[np.int64(1), np.int64(-1), -1, -1, -1]",75;42;-1;-1;-1,42;75,75,Collaborative Data Analysis
Vis,2024,SimpleSets: Capturing Categorical Point Patterns with Simple Shapes,10.1109/tvcg.2024.3456168,http://dx.doi.org/10.1109/TVCG.2024.3456168,262.0,271.0,J,"Points of interest on a map such as restaurants, hotels, or subway stations, give rise to categorical point data: data that have a fixed location and one or more categorical attributes. Consequently, recent years have seen various set visualization approaches that visually connect points of the same category to support users in understanding the spatial distribution of categories. Existing methods use complex and often highly irregular shapes to connect points of the same category, leading to high cognitive load for the user. In this paper we introduce SimpleSets, which uses simple shapes to enclose categorical point patterns, thereby providing a clean overview of the data distribution. SimpleSets is designed to visualize sets of points with a single categorical attribute; as a result, the point patterns enclosed by SimpleSets form a partition of the data. We give formal definitions of point patterns that correspond to simple shapes and describe an algorithm that partitions categorical points into few such patterns. Our second contribution is a rendering algorithm that transforms a given partition into a clean set of shapes resulting in an aesthetically pleasing set visualization. Our algorithm pays particular attention to resolving intersections between nearby shapes in a consistent manner. We compare SimpleSets to the state-of-the-art set visualizations using standard datasets from the literature.",Steven van den Broek;Wouter Meulemans;Bettina Speckmann,Steven van den Broek;Wouter Meulemans;Bettina Speckmann,"TU Eindhoven, the Netherlands;TU Eindhoven, the Netherlands;TU Eindhoven, the Netherlands",10.1109/tvcg.2011.186;10.1109/tvcg.2009.122;10.1109/infvis.2005.1532126;10.1109/tvcg.2010.210;10.1109/tvcg.2006.122;10.1109/tvcg.2021.3114761,"Set visualization,geographic visualization,,,algorithms",,0.0,32.0,156.0,,X,pleasing set visualization;map restaurants;category support users;irregular;definitions,0.6297;0.4239;0.1491;0.1442;0.0990,"[np.int64(-1), np.int64(-1), -1, -1, -1]",63;61;-1;-1;-1,61;63,63,Set Visualization
Vis,2011,Visualization of AMR Data With Multi-Level Dual-Mesh Interpolation,10.1109/tvcg.2011.252,http://dx.doi.org/10.1109/TVCG.2011.252,1862.0,1871.0,J,"We present a new technique for providing interpolation within cell-centered Adaptive Mesh Refinement (AMR) data that achieves C&lt;sup&gt;0&lt;/sup&gt; continuity throughout the 3D domain. Our technique improves on earlier work in that it does not require that adjacent patches differ by at most one refinement level. Our approach takes the dual of each mesh patch and generates ""stitching cells"" on the fly to fill the gaps between dual meshes. We demonstrate applications of our technique with data from Enzo, an AMR cosmological structure formation simulation code. We show ray-cast visualizations that include contributions from particle data (dark matter and stars, also output by Enzo) and gridded hydrodynamic data. We also show results from isosurface studies, including surfaces in regions where adjacent patches differ by more than one refinement level.",Patrick J. Moran;David A. Ellsworth,Patrick Moran;David Ellsworth,"NASA Ames Research Center, USA;Computer Sciences Corporation, NASA Ames, USA",10.1109/visual.1991.175782;10.1109/tvcg.2009.149;10.1109/visual.2002.1183820;10.1109/visual.1991.175782,"Adaptive mesh refinement, AMR, Enzo, interpolation, ray casting, isosurfaces, dual meshes, stitching cells",17.0,14.0,22.0,576.0,,,adaptive mesh refinement;amr cosmological;cast visualizations include;gaps;cell centered,0.6673;0.3243;0.2032;0.1550;0.1151,"[np.int64(-1), -1, -1, -1, -1]",64;-1;-1;-1;-1,64,64,Mesh Optimization Techniques
Vis,2024,Curio: A Dataflow-Based Framework for Collaborative Urban Visual Analytics,10.1109/tvcg.2024.3456353,http://dx.doi.org/10.1109/TVCG.2024.3456353,1224.0,1234.0,J,"Over the past decade, several urban visual analytics systems and tools have been proposed to tackle a host of challenges faced by cities, in areas as diverse as transportation, weather, and real estate. Many of these tools have been designed through collaborations with urban experts, aiming to distill intricate urban analysis workflows into interactive visualizations and interfaces. However, the design, implementation, and practical use of these tools still rely on siloed approaches, resulting in bespoke systems that are difficult to reproduce and extend. At the design level, these tools undervalue rich data workflows from urban experts, typically treating them only as data providers and evaluators. At the implementation level, they lack interoperability with other technical frameworks. At the practical use level, they tend to be narrowly focused on specific fields, inadvertently creating barriers to cross-domain collaboration. To address these gaps, we present Curio, a framework for collaborative urban visual analytics. Curio uses a dataflow model with multiple abstraction levels (code, grammar, GUI elements) to facilitate collaboration across the design and implementation of visual analytics components. The framework allows experts to intertwine data preprocessing, management, and visualization stages while tracking the provenance of code and visualizations. In collaboration with urban experts, we evaluate Curio through a diverse set of usage scenarios targeting urban accessibility, urban microclimate, and sunlight access. These scenarios use different types of data and domain methodologies to illustrate Curio's flexibility in tackling pressing societal challenges. Curio is available at urbantk.org/curio.",Gustavo Moreira;Maryam Hosseini;Carolina Veiga Ferreira de Souza;Lucas Alexandre;Nicola Colaninno;Daniel de Oliveira 0001;Nivan Ferreira;Marcos Lage;Fabio Miranda 0001,Gustavo Moreira;Maryam Hosseini;Carolina Veiga;Lucas Alexandre;Nicola Colaninno;Daniel de Oliveira;Nivan Ferreira;Marcos Lage;Fabio Miranda,"University of Illinois, USA;University of California, Berkeley, and the Massachusetts Institute of Technology, USA;University of Illinois Urbana-Champaign, USA;Universidade Federal Fluminense, Brazil;Politecnico di Milano, Italy;Universidade Federal Fluminense, Brazil;Universidade Federal de Pernambuco, Brazil;Universidade Federal Fluminense, Brazil;University of Illinois, USA",10.1109/tvcg.2018.2865040;10.1109/tvcg.2017.2743990;10.1109/visual.2005.1532788;10.1109/tvcg.2019.2934670;10.1109/vast.2015.7347636;10.1109/tvcg.2013.226;10.1109/tvcg.2021.3114876;10.1109/tvcg.2016.2598585;10.1109/tvcg.2023.3326598;10.1109/tvcg.2022.3209474;10.1109/tvcg.2016.2599030;10.1109/tvcg.2017.2743938;10.1109/tvcg.2022.3209360;10.1109/tvcg.2016.2598497,"Urban analytics,urban data,,,spatial data,dataflow,provenance,visualization framework,visualization system",,0.0,75.0,171.0,,,urban visual analytics;bespoke systems difficult;microclimate sunlight;curio flexibility tackling;specific fields inadvertently,0.7834;0.1591;0.1220;0.0119;-0.0103,"[np.int64(1), -1, -1, -1, -1]",60;-1;-1;-1;-1,60,60,Geographic Visual Analytics
Vis,2022,MosaicSets: Embedding Set Systems into Grid Graphs,10.1109/tvcg.2022.3209485,http://dx.doi.org/10.1109/TVCG.2022.3209485,875.0,885.0,J,"Visualizing sets of elements and their relations is an important research area in information visualization. In this paper, we present MosaicSets: a novel approach to create Euler-like diagrams from non-spatial set systems such that each element occupies one cell of a regular hexagonal or square grid. The main challenge is to find an assignment of the elements to the grid cells such that each set constitutes a contiguous region. As use case, we consider the research groups of a university faculty as elements, and the departments and joint research projects as sets. We aim at finding a suitable mapping between the research groups and the grid cells such that the department structure forms a base map layout. Our objectives are to optimize both the compactness of the entirety of all cells and of each set by itself. We show that computing the mapping is NP-hard. However, using integer linear programming we can solve real-world instances optimally within a few seconds. Moreover, we propose a relaxation of the contiguity requirement to visualize otherwise non-embeddable set systems. We present and discuss different rendering styles for the set overlays. Based on a case study with real-world data, our evaluation comprises quantitative measures as well as expert interviews.",Peter Rottmann;Markus Wallinger;Annika Bonerath;Sven Gedicke;Martin Nöllenburg;Jan-Henrik Haunert,Peter Rottmann;Markus Wallinger;Annika Bonerath;Sven Gedicke;Martin Nöllenburg;Jan-Henrik Haunert,"Geoinformation Group of the University of Bonn, Germany;Algorithms and Complexity Group of the Technical University of Vienna, Austria;Geoinformation Group of the University of Bonn, Germany;Geoinformation Group of the University of Bonn, Germany;Algorithms and Complexity Group of the Technical University of Vienna, Austria;Geoinformation Group of the University of Bonn, Germany",10.1109/tvcg.2011.186;10.1109/tvcg.2009.122;10.1109/tvcg.2020.3030475;10.1109/tvcg.2021.3114834;10.1109/tvcg.2014.2346248;10.1109/tvcg.2016.2598542;10.1109/tvcg.2020.3028953;10.1109/tvcg.2012.199;10.1109/tvcg.2010.210;10.1109/tvcg.2014.2346249;10.1109/tvcg.2008.165;10.1109/tvcg.2011.186,"Set Visualization,Euler Diagram,Integer Linear Programming,Hypergraph",,4.0,66.0,504.0,,,visualizing sets;layout objectives optimize;base map;groups university faculty;integer linear,0.6362;0.3083;0.2748;0.2368;0.0502,"[np.int64(-1), -1, -1, -1, -1]",63;-1;-1;-1;-1,63,63,Set Visualization
VAST,2016,Supporting visual exploration for multiple users in large display environments,10.1109/vast.2016.7883506,http://dx.doi.org/10.1109/VAST.2016.7883506,1.0,10.0,C,"We present a design space exploration of interaction techniques for supporting multiple collaborators exploring data on a shared large display. Our proposed solution is based on users controlling individual lenses using both explicit gestures as well as proxemics: the spatial relations between people and physical artifacts such as their distance, orientation, and movement. We discuss different design considerations for implicit and explicit interactions through the lens, and evaluate the user experience to find a balance between the implicit and explicit interaction styles. Our findings indicate that users favor implicit interaction through proxemics for navigation and collaboration, but prefer using explicit mid-air gestures to perform actions that are perceived to be direct, such as terminating a lens composition. Based on these results, we propose a hybrid technique utilizing both proxemics and mid-air gestures, along with examples applying this technique to other datasets. Finally, we performed a usability evaluation of the hybrid technique and observed user performance improvements in the presence of both implicit and explicit interaction styles.",Sriram Karthik Badam;Fereshteh Amini;Niklas Elmqvist;Pourang Irani,Sriram Karthik Badam;Fereshteh Amini;Niklas Elmqvist;Pourang Irani,"University of Maryland, College Park, MD, USA;University of Manitoba, Winnipeg, MB, Canada;University of Maryland, College Park, MD, USA;University of Manitoba, Winnipeg, MB, Canada",10.1109/tvcg.2013.166;10.1109/tvcg.2009.162;10.1109/tvcg.2013.163;10.1109/tvcg.2011.185;10.1109/tvcg.2013.166,,34.0,27.0,41.0,885.0,,,interaction techniques supporting;distance orientation;terminating lens;proxemics mid air;shared large,0.6070;0.2646;0.1772;0.1621;0.1538,"[np.int64(-1), -1, -1, -1, -1]",43;-1;-1;-1;-1,43,43,Augmented Reality Interfaces
Vis,2024,Visual Support for the Loop Grafting Workflow on Proteins,10.1109/tvcg.2024.3456401,http://dx.doi.org/10.1109/TVCG.2024.3456401,580.0,590.0,J,"In understanding and redesigning the function of proteins in modern biochemistry, protein engineers are increasingly focusing on exploring regions in proteins called loops. Analyzing various characteristics of these regions helps the experts design the transfer of the desired function from one protein to another. This process is denoted as loop grafting. We designed a set of interactive visualizations that provide experts with visual support through all the loop grafting pipeline steps. The workflow is divided into several phases, reflecting the steps of the pipeline. Each phase is supported by a specific set of abstracted 2D visual representations of proteins and their loops that are interactively linked with the 3D View of proteins. By sequentially passing through the individual phases, the user shapes the list of loops that are potential candidates for loop grafting. Finally, the actual in-silico insertion of the loop candidates from one protein to the other is performed, and the results are visually presented to the user. In this way, the fully computational rational design of proteins and their loops results in newly designed protein structures that can be further assembled and tested through in-vitro experiments. We showcase the contribution of our visual support design on a real case scenario changing the enantiomer selectivity of the engineered enzyme. Moreover, we provide the readers with the experts' feedback.",Filip Opálený;Pavol Ulbrich;Joan Planas-Iglesias;Jan Byska;Jan Stourac;David Bednár;Katarína Furmanová;Barbora Kozlíková,Filip Opálený;Pavol Ulbrich;Joan Planas-Iglesias;Jan Byška;Jan Štourač;David Bednář;Katarína Furmanová;Barbora Kozlíková,"Department of Visual Computing, Faculty of Informatics, Masaryk University, Brno, Czech Republic;Department of Visual Computing, Faculty of Informatics, Masaryk University, Brno, Czech Republic;Department of Experimental Biology and RECETOX, Loschmidt Laboratories, Faculty of Science, Masaryk University, Brno, Czech Republic;Department of Visual Computing, Faculty of Informatics, Masaryk University, Brno, Czech Republic;Department of Experimental Biology and RECETOX, Loschmidt Laboratories, Faculty of Science, Masaryk University, Brno, Czech Republic;Department of Experimental Biology and RECETOX, Loschmidt Laboratories, Faculty of Science, Masaryk University, Brno, Czech Republic;Department of Visual Computing, Faculty of Informatics, Masaryk University, Brno, Czech Republic;Department of Visual Computing, Faculty of Informatics, Masaryk University, Brno, Czech Republic",10.1109/tvcg.2016.2598544;10.1109/tvcg.2009.111;10.1109/tvcg.2020.3030438;10.1109/tvcg.2012.213;10.1109/tvcg.2022.3209434,"Protein visualization,protein engineering,,,loop grafting,abstract views",,0.0,59.0,127.0,HM,,design proteins loops;interactive visualizations provide;grafting;actual;divided phases reflecting,0.6395;0.4680;0.2552;0.0055;-0.0389,"[np.int64(-1), np.int64(1), -1, -1, -1]",27;16;-1;-1;-1,16;27,27,Molecular Design Techniques
Vis,1995,Interval set: a volume rendering technique generalizing isosurface extraction,10.1109/visual.1995.480789,http://dx.doi.org/10.1109/VISUAL.1995.480789,3.0,,C,"A scalar volume V={(x,f(x))|x/spl isin/R} is described by a function f(x) defined over some region R of the three dimensional space. The paper presents a simple technique for rendering interval sets of the form I/sub g/(a,b)={(x,f(x))|a/spl les/g(x)/spl les/b}, where a and b are either real numbers of infinities. We describe an algorithm for triangulating interval sets as /spl alpha/ shapes, which can be accurately and efficiently rendered as surfaces or semi transparent clouds. On the theoretical side, interval sets provide an unified approach to isosurface extraction and direct volume rendering. On the practical side, interval sets add flexibility to scalar volume visualization-we may choose to, for example, have an interactive, high quality display of the volume surrounding or ""inside"" an isosurface when such display for the entire volume is too expensive to produce.",Baining Guo,Baining Guo,"Department of Computer Science, University of Toronto, Toronto, ONT, Canada",,,57.0,8.0,22.0,100.0,,,volume visualization;infinities algorithm triangulating;approach isosurface extraction;theoretical interval sets;unified,0.6629;0.4109;0.4096;0.3593;0.0388,"[np.int64(0), np.int64(-1), np.int64(-1), np.int64(-1), -1]",0;59;58;-1;-1,0;58;59,0,Volume Rendering Techniques
Vis,2006,Feature Aligned Volume Manipulation for Illustration and Visualization,10.1109/tvcg.2006.144,http://dx.doi.org/10.1109/TVCG.2006.144,1069.0,1076.0,J,"In this paper we describe a GPU-based technique for creating illustrative visualization through interactive manipulation of volumetric models. It is partly inspired by medical illustrations, where it is common to depict cuts and deformation in order to provide a better understanding of anatomical and biological structures or surgical processes, and partly motivated by the need for a real-time solution that supports the specification and visualization of such illustrative manipulation. We propose two new feature aligned techniques, namely surface alignment and segment alignment, and compare them with the axis-aligned techniques which were reported in previous work on volume manipulation. We also present a mechanism for defining features using texture volumes, and methods for computing correct normals for the deformed volume in respect to different alignments. We describe a GPU-based implementation to achieve real-time performance of the techniques and a collection of manipulation operators including peelers, retractors, pliers and dilators which are adaptations of the metaphors and tools used in surgical procedures and medical illustrations. Our approach is directly applicable in medical and biological illustration, and we demonstrate how it works as an interactive tool for focus+context visualization, as well as a generic technique for volume graphics",Carlos D. Correa;Deborah Silver;Min Chen 0001,Carlos Correa;Deborah Silver;Min Chen,"Department of Electrical and Computer Engineering, State University of New Jersey, Rutgers, USA;Department of Electrical and Computer Engineering, State University of New Jersey, Rutgers, USA;Department of Computer Science, University of Wales, Swansea, UK",10.1109/visual.2003.1250400;10.1109/visual.2000.885694;10.1109/visual.2003.1250400,"Illustrative visualization, Illustrative manipulation, GPU computing, volume rendering, volume deformation, computerassisted medical illustration",125.0,61.0,25.0,708.0,,,interactive manipulation volumetric;paper gpu;common depict cuts;medical biological;different alignments,0.6684;0.3553;0.3234;0.1470;0.0573,"[np.int64(0), np.int64(-1), -1, -1, -1]",0;20;-1;-1;-1,0;20,0,Volume Rendering Techniques
Vis,1995,On enhancing the speed of splatting with indexing,10.1109/visual.1995.480797,http://dx.doi.org/10.1109/VISUAL.1995.480797,69.0,,C,"Splatting is an object space direct volume rendering algorithm that produces images of high quality, but is computationally expensive like many other volume rendering algorithms. The paper presents a new technique that enhances the speed of splatting without trading off image quality. This new method reduces rendering time by employing a simple indexing mechanism which allows to visit and splat only the voxels of interest. It is shown that this algorithm is suitable for the dynamic situation in which viewing parameters and opacity transfer functions change interactively. We report experimental results on several test data sets of useful site and complexity, and discuss the cost/benefit trade off of our method.",Insung Ihm;Rae Kyoung Lee,Insung Ihm;Rae Kyoung Lee,"Department of Computer Science, Sogang University, Seoul, South Korea;Department of Computer Science, Sogang University, Seoul, South Korea",10.1109/visual.1990.146377;10.1109/visual.1990.146377,,40.0,3.0,13.0,48.0,,,volume rendering algorithms;splat;indexing mechanism allows;change interactively;test data sets,0.7297;0.2959;0.1286;0.0515;0.0459,"[np.int64(0), -1, -1, -1, -1]",0;-1;-1;-1;-1,0,0,Volume Rendering Techniques
Vis,1999,Visualizing gridded datasets with large number of missing values,10.1109/visual.1999.809916,http://dx.doi.org/10.1109/VISUAL.1999.809916,405.0,551.0,C,"Much of the research in scientific visualization has focused on complete sets of gridded data. The paper presents our experience dealing with gridded data sets with a large number of missing or invalid data, and some of our experiments in addressing the shortcomings of standard off-the-shelf visualization algorithms. In particular, we discuss the options in modifying known algorithms to adjust to the specifics of sparse datasets, and provide a new technique to smooth out the side-effects of the operations. We apply our findings to data acquired from NEXRAD (NEXt generation RADars) weather radars, which usually have no more than 3 to 4 percent of all possible cell points filled.",Suzana Djurcilov;Alex Pang,S. Djurcilov;A. Pang,"Computer Science Department, University of California, Santa Cruz, USA;Computer Science Department, University of California, Santa Cruz, USA",10.1109/visual.1996.568145;10.1109/visual.1996.568145,,23.0,11.0,12.0,91.0,,,gridded data sets;nexrad generation radars;smooth effects operations;usually percent;missing invalid,0.6045;0.3215;0.0936;0.0649;0.0598,"[np.int64(-1), -1, -1, -1, -1]",29;-1;-1;-1;-1,29,29,Multivariate Grid Data
VAST,2016,NameClarifier: A Visual Analytics System for Author Name Disambiguation,10.1109/tvcg.2016.2598465,http://dx.doi.org/10.1109/TVCG.2016.2598465,141.0,150.0,J,"In this paper, we present a novel visual analytics system called NameClarifier to interactively disambiguate author names in publications by keeping humans in the loop. Specifically, NameClarifier quantifies and visualizes the similarities between ambiguous names and those that have been confirmed in digital libraries. The similarities are calculated using three key factors, namely, co-authorships, publication venues, and temporal information. Our system estimates all possible allocations, and then provides visual cues to users to help them validate every ambiguous case. By looping users in the disambiguation process, our system can achieve more reliable results than general data mining models for highly ambiguous cases. In addition, once an ambiguous case is resolved, the result is instantly added back to our system and serves as additional cues for all the remaining unidentified names. In this way, we open up the black box in traditional disambiguation processes, and help intuitively and comprehensively explain why the corresponding classifications should hold. We conducted two use cases and an expert review to demonstrate the effectiveness of NameClarifier.",Qiaomu Shen;Tongshuang Wu;Haiyan Yang;Yanhong Wu;Huamin Qu;Weiwei Cui,Qiaomu Shen;Tongshuang Wu;Haiyan Yang;Yanhong Wu;Huamin Qu;Weiwei Cui,Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Microsoft Research,10.1109/tvcg.2012.252;10.1109/tvcg.2011.188;10.1109/vast.2006.261429;10.1109/tvcg.2012.252,Name disambiguation;analytical reasoning,47.0,26.0,41.0,1681.0,,,interactively disambiguate author;novel visual analytics;libraries similarities;cases addition;humans loop specifically,0.6837;0.3352;0.3076;0.1292;0.1121,"[np.int64(-1), -1, -1, -1, -1]",75;-1;-1;-1;-1,75,75,Collaborative Data Analysis
VAST,2011,Exploring agent-based simulations using temporal graphs,10.1109/vast.2011.6102469,http://dx.doi.org/10.1109/VAST.2011.6102469,271.0,272.0,M,"Agent-based simulation has become a key technique for modeling and simulating dynamic, complicated behaviors in social and behavioral sciences. Lacking the appropriate tools and support, it is difficult for social scientists to thoroughly analyze the results of these simulations. In this work, we capture the complex relationships between discrete simulation states by visualizing the data as a temporal graph. In collaboration with expert analysts, we identify two graph structures which capture important relationships between pivotal states in the simulation and their inevitable outcomes. Finally, we demonstrate the utility of these structures in the interactive analysis of a large-scale social science simulation of political power in present-day Thailand.",R. Jordan Crouser;Jeremy G. Freeman;Remco Chang,R. Jordan Crouser;Jeremy G. Freeman;Remco Chang,"Tufts University, USA;Tufts University, USA;Tufts University, USA",0.1109/infvis.2005.1532126,,0.0,0.0,8.0,163.0,,,simulation political power;identify graph;day thailand;thoroughly analyze results;support difficult social,0.6789;0.2714;0.1644;0.1467;0.0936,"[np.int64(-1), -1, -1, -1, -1]",79;-1;-1;-1;-1,79,79,Social Media Analysis
Vis,2007,Visualization of Cosmological Particle-Based Datasets,10.1109/tvcg.2007.70526,http://dx.doi.org/10.1109/TVCG.2007.70526,1712.0,1718.0,J,"We describe our visualization process for a particle-based simulation of the formation of the first stars and their impact on cosmic history. The dataset consists of several hundred time-steps of point simulation data, with each time-step containing approximately two million point particles. For each time-step, we interpolate the point data onto a regular grid using a method taken from the radiance estimate of photon mapping [21]. We import the resulting regular grid representation into ParaView [24], with which we extract isosurfaces across multiple variables. Our images provide insights into the evolution of the early universe, tracing the cosmic transition from an initially homogeneous state to one of increasing complexity. Specifically, our visualizations capture the build-up of regions of ionized gas around the first stars, their evolution, and their complex interactions with the surrounding matter. These observations will guide the upcoming James Webb Space Telescope, the key astronomy mission of the next decade.",Paul A. Navrátil;Jarrett Johnson;Volker Bromm,Paul Navratil;Jarrett Johnson;Volker Bromm,"Texas Advanced Computing Center, University of Texas at Austin;Department of Astronomy, University of Technology, Austin, USA and Department of Astronomy, University of Texas at Austin;Department of Astronomy, University of Technology, Austin, USA and Department of Astronomy, University of Texas at Austin",10.1109/visual.2004.52;10.1109/visual.2004.29;10.1109/visual.2004.52,"Interpolation, Isosurface, Astronomy, Cosmology",51.0,23.0,41.0,403.0,,,early universe tracing;grid representation paraview;isosurfaces;james webb;homogeneous state increasing,0.6233;0.2497;0.2129;0.1076;0.0266,"[np.int64(-1), -1, -1, -1, -1]",17;-1;-1;-1;-1,17,17,Cosmological Data Analysis
InfoVis,2012,Visualizing Flow of Uncertainty through Analytical Processes,10.1109/tvcg.2012.285,http://dx.doi.org/10.1109/TVCG.2012.285,2526.0,2535.0,J,"Uncertainty can arise in any stage of a visual analytics process, especially in data-intensive applications with a sequence of data transformations. Additionally, throughout the process of multidimensional, multivariate data analysis, uncertainty due to data transformation and integration may split, merge, increase, or decrease. This dynamic characteristic along with other features of uncertainty pose a great challenge to effective uncertainty-aware visualization. This paper presents a new framework for modeling uncertainty and characterizing the evolution of the uncertainty information through analytical processes. Based on the framework, we have designed a visual metaphor called uncertainty flow to visually and intuitively summarize how uncertainty information propagates over the whole analysis pipeline. Our system allows analysts to interact with and analyze the uncertainty information at different levels of detail. Three experiments were conducted to demonstrate the effectiveness and intuitiveness of our design.",Yingcai Wu;Guo-Xun Yuan;Kwan-Liu Ma,Yingcai Wu;Guo-Xun Yuan;Kwan-Liu Ma,"University of California, Davis, USA;University of California,슠Davis, USA;University of California, Davis, USA",10.1109/tvcg.2008.137;10.1109/tvcg.2011.178;10.1109/infvis.2004.2;10.1109/infvis.2002.1173145;10.1109/visual.1993.398857;10.1109/vast.2009.5332611;10.1109/tvcg.2010.183;10.1109/tvcg.2009.114;10.1109/tvcg.2011.197;10.1109/tvcg.2010.176,"Uncertainty visualization, uncertainty quantification, uncertainty propagation, error ellipsoids, uncertainty fusion",69.0,43.0,46.0,1098.0,,,uncertainty aware visualization;analysts interact;transformations additionally process;sequence data;called,0.7671;0.3211;0.2009;0.1445;0.0247,"[np.int64(1), -1, -1, -1, -1]",7;-1;-1;-1;-1,7,7,Uncertainty Visualization
VAST,2019,GPGPU Linear Complexity t-SNE Optimization,10.1109/tvcg.2019.2934307,http://dx.doi.org/10.1109/TVCG.2019.2934307,1172.0,1181.0,J,"In recent years the t-distributed Stochastic Neighbor Embedding (t-SNE) algorithm has become one of the most used and insightful techniques for exploratory data analysis of high-dimensional data. It reveals clusters of high-dimensional data points at different scales while only requiring minimal tuning of its parameters. However, the computational complexity of the algorithm limits its application to relatively small datasets. To address this problem, several evolutions of t-SNE have been developed in recent years, mainly focusing on the scalability of the similarity computations between data points. However, these contributions are insufficient to achieve interactive rates when visualizing the evolution of the t-SNE embedding for large datasets. In this work, we present a novel approach to the minimization of the t-SNE objective function that heavily relies on graphics hardware and has linear computational complexity. Our technique decreases the computational cost of running t-SNE on datasets by orders of magnitude and retains or improves on the accuracy of past approximated techniques. We propose to approximate the repulsive forces between data points by splatting kernel textures for each data point. This approximation allows us to reformulate the t-SNE minimization problem as a series of tensor operations that can be efficiently executed on the graphics card. An efficient implementation of our technique is integrated and available for use in the widely used Google TensorFlow.js, and an open-source C++ library.",Nicola Pezzotti;Julian Thijssen;Alexander Mordvintsev;Thomas Höllt;Baldur van Lew;Boudewijn P. F. Lelieveldt;Elmar Eisemann;Anna Vilanova,Nicola Pezzotti;Julian Thijssen;Alexander Mordvintsev;Thomas Höllt;Baldur Van Lew;Boudewijn P.F. Lelieveldt;Elmar Eisemann;Anna Vilanova,"Google AI, Zürich, Switzerland and Delft University of Technology, Delft, The Netherlands;Delft University of Technology, Delft, The Netherlands;Google AI, Zürich, Switzerland;Delft University of Technology, Delft, The Netherlands and Leiden University Medical Center, Leiden, The Netherlands;Leiden University Medical Center, Leiden, The Netherlands;Delft University of Technology, Delft, The Netherlands and Leiden University Medical Center, Leiden, The Netherlands;Delft University of Technology, Delft, The Netherlands;Delft University of Technology, Delft, The Netherlands",10.1109/tvcg.2017.2744318;10.1109/tvcg.2017.2744718;10.1109/tvcg.2017.2745141;10.1109/tvcg.2017.2744358;10.1109/tvcg.2014.2346574,"High Dimensional Data,Dimensionality Reduction,Progressive Visual Analytics,Approximate Computation,GPGPU",59.0,45.0,45.0,1185.0,,,stochastic neighbor embedding;visualizing evolution;tensorflow js open;repulsive forces;graphics card efficient,0.6117;0.3444;0.2563;0.2062;0.1546,"[np.int64(-1), -1, -1, -1, -1]",79;-1;-1;-1;-1,79,79,Social Media Analysis
VAST,2012,Visual analytics methods for categoric spatio-temporal data,10.1109/vast.2012.6400553,http://dx.doi.org/10.1109/VAST.2012.6400553,183.0,192.0,C,"We focus on visual analysis of space- and time-referenced categorical data, which describe possible states of spatial (geographical) objects or locations and their changes over time. The analysis of these data is difficult as there are only limited possibilities to analyze the three aspects (location, time and category) simultaneously. We present a new approach which interactively combines (a) visualization of categorical changes over time; (b) various spatial data displays; (c) computational techniques for task-oriented selection of time steps. They provide an expressive visualization with regard to either the overall evolution over time or unusual changes. We apply our approach on two use cases demonstrating its usefulness for a wide variety of tasks. We analyze data from movement tracking and meteorologic areas. Using our approach, expected events could be detected and new insights were gained.",Tatiana von Landesberger;Sebastian Bremm;Natalia V. Andrienko;Gennady L. Andrienko;Maria Tekusova,T. von Landesberger;Sebastian Bremm;Natalia Andrienko;Gennady Andrienko;Mária Tekušová,"TU Darmstadt, Darmstadt, Germany;TU Darmstadt, Darmstadt, Germany;Fraunhofer IAIS, Bonn, Germany;Fraunhofer IAIS, Bonn, Germany;SHMU, Bratislava, Slovakia",10.1109/tvcg.2011.174;10.1109/tvcg.2009.117;10.1109/tvcg.2009.181;10.1109/infvis.2000.885098;10.1109/tvcg.2010.138;10.1109/vast.2010.5652530;10.1109/infvis.2004.27;10.1109/infvis.2005.1532152;10.1109/infvis.2001.963281;10.1109/tvcg.2008.165;10.1109/tvcg.2009.153;10.1109/tvcg.2011.174,,100.0,43.0,43.0,1416.0,,,visualization categorical changes;task oriented selection;location time;meteorologic areas using;expected events,0.6561;0.3065;0.2926;0.2926;0.1431,"[np.int64(1), -1, -1, -1, -1]",6;-1;-1;-1;-1,6,6,Dynamic Data Visualization
Vis,2024,DimBridge: Interactive Explanation of Visual Patterns in Dimensionality Reductions with Predicate Logic,10.1109/tvcg.2024.3456391,http://dx.doi.org/10.1109/TVCG.2024.3456391,207.0,217.0,J,"Dimensionality reduction techniques are widely used for visualizing high-dimensional data. However, support for interpreting patterns of dimension reduction results in the context of the original data space is often insufficient. Consequently, users may struggle to extract insights from the projections. In this paper, we introduce DimBridge, a visual analytics tool that allows users to interact with visual patterns in a projection and retrieve corresponding data patterns. DimBridge supports several interactions, allowing users to perform various analyses, from contrasting multiple clusters to explaining complex latent structures. Leveraging first-order predicate logic, DimBridge identifies subspaces in the original dimensions relevant to a queried pattern and provides an interface for users to visualize and interact with them. We demonstrate how DimBridge can help users overcome the challenges associated with interpreting visual patterns in projections.",Brian Montambault;Gabriel Appleby;Jen Rogers;Camelia D. Brumar;Mingwei Li;Remco Chang,Brian Montambault;Gabriel Appleby;Jen Rogers;Camelia D. Brumar;Mingwei Li;Remco Chang,"Tufts University, USA;Tufts University, USA;Tufts University, USA;Tufts University, USA;Tufts University, USA;Tufts University, USA",10.1109/tvcg.2011.229;10.1109/tvcg.2018.2864477;10.1109/vast.2012.6400489;10.1109/tvcg.2019.2934251;10.1109/tvcg.2021.3114807;10.1109/vast.2008.4677352;10.1109/infvis.2002.1173157;10.1109/tvcg.2017.2745085;10.1109/visual.1990.146386;10.1109/tvcg.2022.3209382;10.1109/visual.1995.485139;10.1109/tvcg.2018.2864812;10.1109/tvcg.2013.153;10.1109/tvcg.2021.3114870;10.1109/tvcg.2017.2744843;10.1109/tvcg.2015.2467717;10.1109/vast.2012.6400488;10.1109/tvcg.2017.2745258;10.1109/infvis.2005.1532142;10.1109/tvcg.2022.3209423;10.1109/vast.2006.261436,"Predicates,Dimensionality Reduction,,,Explainable Machine Learning",,0.0,95.0,220.0,,,visualizing high dimensional;multiple clusters explaining;logic dimbridge identifies;reduction results;support,0.6151;0.4332;0.3196;0.1879;0.1271,"[np.int64(1), np.int64(-1), -1, -1, -1]",11;38;-1;-1;-1,11;38,11,Multivariate Data Visualization
Vis,2003,Interactive view-dependent rendering with conservative occlusion culling in complex environments,10.1109/visual.2003.1250368,http://dx.doi.org/10.1109/VISUAL.2003.1250368,163.0,170.0,C,"This paper presents an algorithm combining view-dependent rendering and conservative occlusion culling for interactive display of complex environments. A vertex hierarchy of the entire scene is decomposed into a cluster hierarchy through a novel clustering and partitioning algorithm. The cluster hierarchy is then used for view-frustum and occlusion culling. Using hardware accelerated occlusion queries and frame-to-frame coherence, a potentially visible set of clusters is computed. An active vertex front and face list is computed from the visible clusters and rendered using vertex arrays. The integrated algorithm has been implemented on a Pentium IV PC with a NVIDIA GeForce 4 graphics card and applied in two complex environments composed of millions of triangles. The resulting system can render these environments at interactive rates with little loss in image quality and minimal popping artifacts.",Sung-Eui Yoon;Brian Salomon;Dinesh Manocha,Sung-Eui Yoon;B. Salomon;D. Manocha,"University of North Carolina, Chapel Hill, USA;University of North Carolina, Chapel Hill, USA;University of North Carolina, Chapel Hill, USA",10.1109/visual.2002.1183760;10.1109/visual.2001.964534;10.1109/visual.2002.1183796;10.1109/visual.2002.1183760,"Interactive Display, View-Dependent Rendering, Occlusion Culling, Level of Detail, Multiresolution Hierarchies",56.0,6.0,40.0,118.0,,,hardware accelerated occlusion;display complex environments;cluster hierarchy used;scene;list computed,0.6035;0.4821;0.2570;0.1520;0.0705,"[np.int64(-1), np.int64(-1), -1, -1, -1]",44;74;-1;-1;-1,44;74,44,3D Rendering Techniques
Vis,2008,Generation of Accurate Integral Surfaces in Time-Dependent Vector fields,10.1109/tvcg.2008.133,http://dx.doi.org/10.1109/TVCG.2008.133,1404.0,1411.0,J,"We present a novel approach for the direct computation of integral surfaces in time-dependent vector fields. As opposed to previous work, which we analyze in detail, our approach is based on a separation of integral surface computation into two stages: surface approximation and generation of a graphical representation. This allows us to overcome several limitations of existing techniques. We first describe an algorithm for surface integration that approximates a series of time lines using iterative refinement and computes a skeleton of the integral surface. In a second step, we generate a well-conditioned triangulation. Our approach allows a highly accurate treatment of very large time-varying vector fields in an efficient, streaming fashion. We examine the properties of the presented methods on several example datasets and perform a numerical study of its correctness and accuracy. Finally, we investigate some visualization aspects of integral surfaces.",Christoph Garth;Han Krishnan;Xavier Tricoche;Tom Tricoche;Kenneth I. Joy,Christoph Garth;Han Krishnan;Xavier Tricoche;Tom Tricoche;Kenneth I. Joy,"Institute of Data Analysis and Visualization, University of California, Davis, USA;Institute of Data Analysis and Visualization, University of California, Davis, USA;Computer Science Dept., Purdue University, USA;Geometric Algorithms Group, University of Kaiserslautern;Institute of Data Analysis and Visualization, University of California, Davis, USA",10.1109/visual.1993.398875;10.1109/visual.2001.964506;10.1109/visual.2004.28;10.1109/visual.1992.235211;10.1109/visual.1992.235226;10.1109/visual.1993.398875,"3D vector field visualization, flow visualization, time-varying and time-series visualization, surface extraction",103.0,51.0,18.0,376.0,,,integral surfaces time;triangulation;streaming fashion;fields opposed;approximates series,0.5838;0.3497;0.1337;0.1040;0.0339,"[np.int64(-1), -1, -1, -1, -1]",76;-1;-1;-1;-1,76,76,Surface Topology
Vis,2000,Two-level volume rendering - fusing MIP and DVR,10.1109/visual.2000.885697,http://dx.doi.org/10.1109/VISUAL.2000.885697,211.0,218.0,C,"Presents a two-level approach for fusing direct volume rendering (DVR) and maximum-intensity projection (MIP) within a joint rendering method. Different structures within the data set are rendered locally by either MIP or DVR on an object-by-object basis. Globally, all the results of subsequent object renderings are combined in a merging step (usually compositing in our case). This allows us to selectively choose the most suitable technique for depicting each object within the data, while keeping the amount of information contained in the image at a reasonable level. This is especially useful when inner structures should be visualized together with semi-transparent outer parts, similar to the focus-and-context approach known from information visualization. We also present an implementation of our approach which allows us to explore volumetric data using two-level rendering at interactive frame rates.",Helwig Hauser;Lukas Mroz;Gian Italo Bischi;M. Eduard Gröller,H. Hauser;L. Mroz;G.-I. Bischi;M.E. Groller,"VRVis Center Vienna, Austria;University of Technology, Vienna, Austria;University of Urbino, Italy;University of Technology, Vienna, Austria",10.1109/visual.1998.745311;10.1109/visual.1999.809887;10.1109/visual.1996.568113;10.1109/visual.2000.885697;10.1109/visual.1998.745311,"visualization, volume rendering, dynamical systems,medical applications",81.0,12.0,20.0,173.0,,,direct volume rendering;object basis globally;explore;combined;keeping information,0.7287;0.2026;0.1436;0.1119;0.1087,"[np.int64(0), -1, -1, -1, -1]",0;-1;-1;-1;-1,0,0,Volume Rendering Techniques
Vis,2023,VISPUR: Visual Aids for Identifying and Interpreting Spurious Associations in Data-Driven Decisions,10.1109/tvcg.2023.3326587,http://dx.doi.org/10.1109/TVCG.2023.3326587,219.0,229.0,J,"Big data and machine learning tools have jointly empowered humans in making data-driven decisions. However, many of them capture empirical associations that might be spurious due to confounding factors and subgroup heterogeneity. The famous Simpson's paradox is such a phenomenon where aggregated and subgroup-level associations contradict with each other, causing cognitive confusions and difficulty in making adequate interpretations and decisions. Existing tools provide little insights for humans to locate, reason about, and prevent pitfalls of spurious association in practice. We propose VISPUR, a visual analytic system that provides a causal analysis framework and a human-centric workflow for tackling spurious associations. These include a CONFOUNDER DASHBOARD, which can automatically identify possible confounding factors, and a SUBGROUP VIEWER, which allows for the visualization and comparison of diverse subgroup patterns that likely or potentially result in a misinterpretation of causality. Additionally, we propose a REASONING STORYBOARD, which uses a flow-based approach to illustrate paradoxical phenomena, as well as an interactive DECISION DIAGNOSIS panel that helps ensure accountable decision-making. Through an expert interview and a controlled user experiment, our qualitative and quantitative results demonstrate that the proposed “de-paradox” workflow and the designed visual analytic system are effective in helping human users to identify and understand spurious associations, as well as to make accountable causal decisions.",Xian Teng;Yongsu Ahn;Yu-Ru Lin,Xian Teng;Yongsu Ahn;Yu-Ru Lin,"University of Pittsburgh, USA;University of Pittsburgh, USA;University of Pittsburgh, USA",0.1109/tvcg.2019.2934262;10.1109/tvcg.2014.2346297;10.1109/vast.2018.8802486;10.1109/vast47406.2019.8986948;10.1109/tvcg.2020.3030342;10.1109/tvcg.2018.2865043;10.1109/tvcg.2020.3030465;10.1109/tvcg.2021.3114824;10.1109/tvcg.2017.2745085;10.1109/infvis.2005.1532152;10.1109/tvcg.2015.2467931;10.1109/vast.2017.8585647;10.1109/tvcg.2019.2934619;10.1109/tvcg.2020.3028957,"Causal Analysis,Simpson's Paradox,Spurious Associations,Machine Learning,Decision Making",,0.0,76.0,426.0,,,associations spurious confounding;visualization comparison diverse;factors subgroup;dashboard automatically;uses,0.5565;0.3643;0.1866;0.1326;0.1200,"[np.int64(-1), np.int64(1), -1, -1, -1]",-1;68;-1;-1;-1,68,68,Visualization Techniques Comparison
Vis,2005,Multimodal exploration of the fourth dimension,10.1109/visual.2005.1532804,http://dx.doi.org/10.1109/VISUAL.2005.1532804,263.0,270.0,C,"We present a multimodal paradigm for exploring topological surfaces embedded in four dimensions; we exploit haptic methods in particular to overcome the intrinsic limitations of 3D graphics images and 3D physical models. The basic problem is that, just as 2D shadows of 3D curves lose structure where lines cross, 3D graphics projections of smooth 4D topological surfaces are interrupted where one surface intersects another. Furthermore, if one attempts to trace real knotted ropes or a plastic models of self-intersecting surfaces with a fingertip, one inevitably collides with parts of the physical artifact. In this work, we exploit the free motion of a computer-based haptic probe to support a continuous motion that follows the local continuity of the object being explored. For our principal test case of 4D-embedded surfaces projected to 3D, this permits us to follow the full local continuity of the surface as though in fact we were touching an actual 4D object. We exploit additional sensory cues to provide supplementary or redundant information. For example, we can use audio tags to note the relative 4D depth of illusory 3D surface intersections produced by projection from 4D, as well as providing automated refinement of the tactile exploration path to eliminate jitter and snagging, resulting in a much cleaner exploratory motion than a bare uncorrected motion. Visual enhancements provide still further improvement to the feedback: by opening a view-direction-defined cutaway into the interior of the 3D surface projection, we allow the viewer to keep the haptic probe continuously in view as it traverses any touchable part of the object. Finally, we extend the static tactile exploration framework using a dynamic mode that links each stylus motion to a change in orientation that creates at each instant a maximal-area screen projection of a neighborhood of the current point of interest. This minimizes 4D distortion and permits true metric sizes to be deduced locally at any point. All these methods combine to reveal the full richness of the complex spatial relationships of the target shapes, and to overcome many expected perceptual limitations in 4D visualization.",Andrew J. Hanson;Hui Zhang 0006,A.J. Hanson;H. Zhang,"Computer Science Department, Indiana University, USA;Computer Science Department, Indiana University, USA",10.1109/visual.1995.480804;10.1109/visual.1995.480804," multimodal, haptics, visualization",21.0,5.0,31.0,170.0,,,touching actual 4d;paradigm exploring topological;eliminate jitter snagging;attempts trace;provide supplementary redundant,0.6277;0.3054;0.0972;0.0809;-0.0137,"[np.int64(-1), -1, -1, -1, -1]",18;-1;-1;-1;-1,18,18,4D/3D Visualization
Vis,2001,"Semi-immersive space mission design and visualization: case study of the ""Terrestrial Planet Finder"" mission",10.1109/visual.2001.964562,http://dx.doi.org/10.1109/VISUAL.2001.964562,501.0,504.0,C,"The paper addresses visualization issues of the Terrestrial Planet Finder Mission (C.A. Beichman et al., 1999). The goal of this mission is to search for chemical signatures of life in distant solar systems using five satellites flying in formation to simulate a large telescope. To design and visually verify such a delicate mission, one has to analyze and interact with many different 3D spacecraft trajectories, which is often difficult in 2D. We employ a novel trajectory design approach using invariant manifold theory, which is best understood and utilized in an immersive setting. The visualization also addresses multi-scale issues related to the vast differences in distance, velocity, and time at different phases of the mission. Additionally, the parameterization and coordinate frames used for numerical simulations may not be suitable for direct visualization. Relative motion presents a more serious problem where the patterns of the trajectories can only be viewed in particular rotating frames. Some of these problems are greatly relieved by using interactive, animated stereo 3D visualization in a semi-immersive environment such as a Responsive Workbench. Others were solved using standard techniques such as a stratify approach with multiple windows to address the multiscale issues, re-parameterizations of trajectories and associated 2D manifolds and relative motion of the camera to ""evoke"" the desired patterns.",Ken Museth;Alan H. Barr;Martin W. Lo,K. Museth;A. Barr;M.W. Lo,"Computer Science Department, California Institute of Technology, Pasadena, CA, USA;Computer Science Department, California Institute of Technology, Pasadena, CA, USA;Jet Propulsion Laboratory and Computer Science Department, California Institute of Technology, Pasadena, CA",,,13.0,3.0,7.0,122.0,,,3d spacecraft trajectories;chemical signatures life;camera evoke desired;responsive workbench;stratify,0.6054;0.2041;0.1688;0.1521;0.0789,"[np.int64(-1), -1, -1, -1, -1]",28;-1;-1;-1;-1,28,28,3D Space Navigation
InfoVis,2020,Table Scraps: An Actionable Framework for Multi-Table Data Wrangling From An Artifact Study of Computational Journalism,10.1109/tvcg.2020.3030462,http://dx.doi.org/10.1109/TVCG.2020.3030462,957.0,966.0,J,"For the many journalists who use data and computation to report the news, data wrangling is an integral part of their work. Despite an abundance of literature on data wrangling in the context of enterprise data analysis, little is known about the specific operations, processes, and pain points journalists encounter while performing this tedious, time-consuming task. To better understand the needs of this user group, we conduct a technical observation study of 50 public repositories of data and analysis code authored by 33 professional journalists at 26 news organizations. We develop two detailed and cross-cutting taxonomies of data wrangling in computational journalism, for actions and for processes. We observe the extensive use of multiple tables, a notable gap in previous wrangling analyses. We develop a concise, actionable framework for general multi-table data wrangling that includes wrangling operations documented in our taxonomy that are without clear parallels in other work. This framework, the first to incorporate tables as first-class objects, will support future interactive wrangling tools for both computational journalism and general-purpose use. We assess the generative and descriptive power of our framework through discussion of its relationship to our set of taxonomies.",Stephen Kasica;Charles Berret;Tamara Munzner,Stephen Kasica;Charles Berret;Tamara Munzner,"Department of Computer Science, University of British Columbia;University of British Columbia, School of Journalism, Writing, and Media;Department of Computer Science, University of British Columbia",10.1109/vast47406.2019.8986909;10.1109/vast.2011.6102441;10.1109/tvcg.2012.219;10.1109/tvcg.2019.2934593;10.1109/vast.2011.6102440;10.1109/tvcg.2019.2934539;10.1109/tvcg.2015.2467551;10.1109/infvis.2000.885086;10.1109/vast47406.2019.8986909,"Computational journalism,Data journalism,Data wrangling",20.0,17.0,55.0,800.0,,,journalists use data;framework incorporate tables;operations processes pain;taxonomy clear parallels;26,0.6592;0.2414;0.1863;0.0989;0.0118,"[np.int64(-1), -1, -1, -1, -1]",75;-1;-1;-1;-1,75,75,Collaborative Data Analysis
Vis,1994,Nonpolygonal isosurface rendering for large volume datasets,10.1109/visual.1994.346306,http://dx.doi.org/10.1109/VISUAL.1994.346306,293.0,,C,"Surface-based rendering techniques, particularly those that extract a polygonal approximation of an isosurface, are widely used in volume visualization. As dataset size increases though, the computational demands of these methods can overwhelm typically available computing resources. Recent work on accelerating such techniques has focused on preprocessing the volume data or postprocessing the extracted polygonization. The algorithm presented, concentrates instead on streamlining the surface extraction process itself so as to accelerate the rendering of large volumes. The technique shortens the conventional isosurface visualization pipeline by eliminating the intermediate polygonization. We compute the contribution of the isosurface within a volume cell to the resulting image directly from a simplified numerical description of the cell/surface intersection. The approach also reduces the work in the remaining stages of the visualization process. By quantizing the volume data, we exploit precomputed and cached data at key processing steps to improve rendering efficiency. The resulting implementation provides comparatively fast renderings with reasonable image quality.&lt;&lt;ETX&gt;&gt;",James W. Durkin;John F. Hughes,J.W. Durkin;J.F. Hughes,"Cornell University, Ithaca, NY, USA;Computer Science Department, Brown University, Providence, RI, USA",,,27.0,2.0,12.0,53.0,,,volume visualization;comparatively fast renderings;conventional isosurface;postprocessing extracted polygonization;exploit precomputed cached,0.6695;0.4283;0.4127;0.4008;0.0458,"[np.int64(0), np.int64(-1), np.int64(-1), np.int64(-1), -1]",0;20;58;77;-1,0;20;58;77,0,Volume Rendering Techniques
Vis,2023,Interactive Design and Optics-Based Visualization of Arbitrary Non-Euclidean Kaleidoscopic Orbifolds,10.1109/tvcg.2023.3326927,http://dx.doi.org/10.1109/TVCG.2023.3326927,1292.0,1301.0,J,"Orbifolds are a modern mathematical concept that arises in the research of hyperbolic geometry with applications in computer graphics and visualization. In this paper, we make use of rooms with mirrors as the visual metaphor for orbifolds. Given any arbitrary two-dimensional kaleidoscopic orbifold, we provide an algorithm to construct a Euclidean, spherical, or hyperbolic polygon to match the orbifold. This polygon is then used to create a room for which the polygon serves as the floor and the ceiling. With our system that implements Möbius transformations, the user can interactively edit the scene and see the reflections of the edited objects. To correctly visualize non-Euclidean orbifolds, we adapt the rendering algorithms to account for the geodesics in these spaces, which light rays follow. Our interactive orbifold design system allows the user to create arbitrary two-dimensional kaleidoscopic orbifolds. In addition, our mirror-based orbifold visualization approach has the potential of helping our users gain insight on the orbifold, including its orbifold notation as well as its universal cover, which can also be the spherical space and the hyperbolic space.",Jinta Zheng;Eugene Zhang;Yue Zhang 0009,Jinta Zheng;Eugene Zhang;Yue Zhang,"Oregon State University, USA;Oregon State University, USA;Oregon State University, USA",0.1109/tvcg.2020.3030431;10.1109/tvcg.2017.2744038;10.1109/tvcg.2018.2864768,"Kaleidoscopic Orbifolds,Orbifold Visualization,Math Visualization,Orbifold Construction,Spherical Geometry,Hyperbolic Geometry",,0.0,36.0,214.0,,,based orbifold visualization;hyperbolic space;polygon serves floor;scene reflections edited;given arbitrary,0.7131;0.4431;0.3597;0.3065;0.0703,"[np.int64(-1), np.int64(-1), np.int64(-1), -1, -1]",84;17;77;-1;-1,17;77;84,84,Geospatial Visualization Techniques
InfoVis,1999,Evaluating a visualisation of image similarity as a tool for image browsing,10.1109/infvis.1999.801855,http://dx.doi.org/10.1109/INFVIS.1999.801855,36.0,,C,"A similarity metric based on the low-level content of images can be used to create a visualisation in which visually similar images are displayed close to each other. We are carrying out a series of experiments to evaluate the usefulness of this type of visualisation as an image browsing aid. The initial experiment, described, considered whether people would find a given photograph more quickly in a visualisation than in a randomly arranged grid of images. The results show that the subjects were faster with the visualisation, although in post-experiment interviews many of them said that they preferred the clarity and regularity of the grid. We describe an algorithm with which the best aspects of the two layout types can be combined.",Kerry Rodden;Wojciech Basalaj;David Sinclair;Kenneth R. Wood,K. Rodden;W. Basalaj;D. Sinclair;K. Wood,"Computer Laboratory, University of Cambridge, Cambridge, UK;Computer Laboratory, University of Cambridge, Cambridge, UK;AT and T Laboratories, Cambridge, UK;AT and T Laboratories, Cambridge, UK",0.1109/infvis.1999.801855,,113.0,25.0,17.0,236.0,,,visually similar images;best aspects layout;regularity grid algorithm;low level;carrying series,0.6448;0.3190;0.2895;0.0338;0.0122,"[np.int64(-1), -1, -1, -1, -1]",78;-1;-1;-1;-1,78,78,Cognitive Visual Analysis
InfoVis,2008,Particle-based labeling: Fast point-feature labeling without obscuring other visual features,10.1109/tvcg.2008.152,http://dx.doi.org/10.1109/TVCG.2008.152,1237.0,1244.0,J,"In many information visualization techniques, labels are an essential part to communicate the visualized data. To preserve the expressiveness of the visual representation, a placed label should neither occlude other labels nor visual representatives (e.g., icons, lines) that communicate crucial information. Optimal, non-overlapping labeling is an NP-hard problem. Thus, only a few approaches achieve a fast non-overlapping labeling in highly interactive scenarios like information visualization. These approaches generally target the point-feature label placement (PFLP) problem, solving only label-label conflicts. This paper presents a new, fast, solid and flexible 2D labeling approach for the PFLP problem that additionally respects other visual elements and the visual extent of labeled features. The results (number of placed labels, processing time) of our particle-based method compare favorably to those of existing techniques. Although the esthetic quality of non-real-time approaches may not be achieved with our method, it complies with practical demands and thus supports the interactive exploration of information spaces. In contrast to the known adjacent techniques, the flexibility of our technique enables labeling of dense point clouds by the use of non-occluding distant labels. Our approach is independent of the underlying visualization technique, which enables us to demonstrate the application of our labeling method within different information visualization scenarios.",Martin Luboschik;Heidrun Schumann;Hilko Cords,Martin Luboschik;Heidrun Schumann;Hilko Cords,"University of Rostock, Germany;University of Rostock, Germany;University of Rostock, Germany",10.1109/tvcg.2006.136;10.1109/tvcg.2006.136;10.1109/visual.2005.1532856,"Interactive labeling, dynamic labeling, automatic label placement, occlusion-free, information visualization",88.0,50.0,23.0,786.0,,,information visualization;labeling dense point;particle;placement pflp problem;hard,0.5756;0.4783;0.2606;0.2045;0.0631,"[np.int64(1), np.int64(-1), -1, -1, -1]",13;74;-1;-1;-1,13;74,13,Information Visualization
Vis,1997,Isosurface extraction using particle systems,10.1109/visual.1997.663930,http://dx.doi.org/10.1109/VISUAL.1997.663930,495.0,498.0,C,"Presents a new approach to isosurface extraction from volume data using particle systems. Particle behavior is dynamic and can be based on laws of physics or artificial rules. For isosurface extraction, we program particles to be attracted towards a specific surface value while simultaneously repelling adjacent particles. The repulsive forces are based on the curvature of the surface at that location. A birth-death process results in a denser concentration of particles in areas of high curvature and sparser populations in areas of lower curvature. The overall level of detail is controlled through a scaling factor that increases or decreases the repulsive forces of the particles. Once particles reach equilibrium, their locations are used as vertices in generating a triangular mesh of the surface. The advantages of our approach include: vertex densities are based on surface features rather than on the sampling rate of the volume; a single scaling factor simplifies level-of-detail control; and meshing is efficient because it uses neighbor information that has already been generated during the force calculations.",Patricia Crossno;Edward Angel,P. Crossno;E. Angel,"Department of Computer Science, University of New Mexico, USA;Department of Computer Science, University of New Mexico, USA",10.1109/visual.1993.398880;10.1109/visual.1993.398880,,101.0,24.0,9.0,136.0,,,densities based surface;repulsive forces particles;extraction program;vertices generating triangular;simultaneously,0.6053;0.2874;0.2475;0.1584;-0.0444,"[np.int64(-1), -1, -1, -1, -1]",-1;-1;-1;-1;-1,,-1,Complex Data Analysis
VAST,2015,VA2: A Visual Analytics Approach for Evaluating Visual Analytics Applications,10.1109/tvcg.2015.2467871,http://dx.doi.org/10.1109/TVCG.2015.2467871,61.0,70.0,J,"Evaluation has become a fundamental part of visualization research and researchers have employed many approaches from the field of human-computer interaction like measures of task performance, thinking aloud protocols, and analysis of interaction logs. Recently, eye tracking has also become popular to analyze visual strategies of users in this context. This has added another modality and more data, which requires special visualization techniques to analyze this data. However, only few approaches exist that aim at an integrated analysis of multiple concurrent evaluation procedures. The variety, complexity, and sheer amount of such coupled multi-source data streams require a visual analytics approach. Our approach provides a highly interactive visualization environment to display and analyze thinking aloud, interaction, and eye movement data in close relation. Automatic pattern finding algorithms allow an efficient exploratory search and support the reasoning process to derive common eye-interaction-thinking patterns between participants. In addition, our tool equips researchers with mechanisms for searching and verifying expected usage patterns. We apply our approach to a user study involving a visual analytics application and we discuss insights gained from this joint analysis. We anticipate our approach to be applicable to other combinations of evaluation techniques and a broad class of visualization applications.",Tanja Blascheck;Markus John;Kuno Kurzhals;Steffen Koch 0001;Thomas Ertl,Tanja Blascheck;Markus John;Kuno Kurzhals;Steffen Koch;Thomas Ertl,"Institute for Visualization and Interactive Systems (VIS), University of Stuttgart, Germany;Institute for Visualization and Interactive Systems (VIS), University of Stuttgart, Germany;Visualization Research Center, University of Stuttgart, Germany;Institute for Visualization and Interactive Systems (VIS), University of Stuttgart, Germany;Institute for Visualization and Interactive Systems (VIS), University of Stuttgart, Germany",10.1109/tvcg.2012.276;10.1109/tvcg.2013.124;10.1109/vast.2008.4677361;10.1109/vast.2009.5333878;10.1109/tvcg.2014.2346677;10.1109/vast.2010.5653598;10.1109/tvcg.2012.273;10.1109/visual.2005.1532837;10.1109/tvcg.2012.276,"visual analytics, qualitative evaluation, thinking aloud, interaction logs, eye tracking, time series data",,69.0,53.0,2679.0,HM,,visual analytics;thinking aloud protocols;recently eye;research researchers employed;derive common,0.6403;0.3537;0.2193;0.0892;0.0679,"[np.int64(1), np.int64(-1), -1, -1, -1]",14;45;-1;-1;-1,14;45,14,Visual Analytics Systems
VAST,2020,Diagnosing Concept Drift with Visual Analytics,10.1109/vast50239.2020.00007,http://dx.doi.org/10.1109/VAST50239.2020.00007,12.0,23.0,C,"Concept drift is a phenomenon in which the distribution of a data stream changes over time in unforeseen ways, causing prediction models built on historical data to become inaccurate. While a variety of automated methods have been developed to identify when concept drift occurs, there is limited support for analysts who need to understand and correct their models when drift is detected. In this paper, we present a visual analytics method, DriftVis, to support model builders and analysts in the identification and correction of concept drift in streaming data. DriftVis combines a distribution-based drift detection method with a streaming scatterplot to support the analysis of drift caused by the distribution changes of data streams and to explore the impact of these changes on the model’s accuracy. A quantitative experiment and two case studies on weather prediction and text classification have been conducted to demonstrate our proposed tool and illustrate how visual analytics can be used to support the detection, examination, and correction of concept drift.",Weikai Yang;Zhen Li 0044;Mengchen Liu;Yafeng Lu;Kelei Cao;Ross Maciejewski;Shixia Liu,Weikai Yang;Zhen Li;Mengchen Liu;Yafeng Lu;Kelei Cao;Ross Maciejewski;Shixia Liu,"School of Software, BNRist, Tsinghua University;School of Software, BNRist, Tsinghua University;Microsoft;Bloomberg L.P.;School of Software, BNRist, Tsinghua University;Computer Science, Arizona State University;School of Software, BNRist, Tsinghua University",10.1109/tvcg.2018.2864499;10.1109/tvcg.2017.2744878;10.1109/tvcg.2019.2934619;10.1109/vast50239.2020.00006;10.1109/tvcg.2018.2864504;10.1109/visual.2005.1532820;10.1109/tvcg.2017.2744158;10.1109/tvcg.2018.2865044;10.1109/tvcg.2018.2864838;10.1109/tvcg.2016.2598828;10.1109/tvcg.2016.2598838;10.1109/tvcg.2017.2744358;10.1109/tvcg.2019.2934267;10.1109/tvcg.2018.2864812;10.1109/vast.2017.8585721;10.1109/tvcg.2019.2934631;10.1109/tvcg.2016.2598831;10.1109/tvcg.2017.2744938;10.1109/vast.2018.8802509;10.1109/tvcg.2018.2865027;10.1109/tvcg.2018.2864500;10.1109/tvcg.2019.2934659;10.1109/tvcg.2018.2865043;10.1109/tvcg.2013.212;10.1109/tvcg.2017.2744683;10.1109/tvcg.2018.2864499,"Concept drift,streaming data,change detection,scatterplot,t-SNE.",16.0,21.0,76.0,1097.0,,,identify concept drift;weather prediction text;scatterplot support;model builders;correction,0.7139;0.3175;0.3137;0.1109;0.0434,"[np.int64(-1), -1, -1, -1, -1]",30;-1;-1;-1;-1,30,30,Concept Drift Detection
Vis,1996,The Design and Implementation of an Object-Oriented Toolkit for 3D Graphics and Visualization,10.1109/visual.1996.567752,http://doi.ieeecomputersociety.org/10.1109/VISUAL.1996.567752,93.0,100.0,C,"The Visualization Toolkit (vtk) is a freely available C++ class library for 3D graphics and visualization. We describe core characteristics of the toolkit. This includes a description of object oriented models for graphics and visualization; methods for synchronizing system execution; a summary of data representation schemes; the role of C++; issues in portability across PC and Unix systems; and how we automatically wrap the C++ class library with interpreted languages such as Java and Tcl. We also demonstrate the capabilities of the system for scalar, vector, tensor, and other visualization techniques.",William J. Schroeder;Ken Martin;William E. Lorensen,W.J. Schroeder;K.M. Martin;W.E. Lorensen,"GE Corp. Res. & Dev., USA;;",10.1109/visual.1993.398878;10.1109/visual.1994.346303;10.1109/visual.1992.235205;10.1109/visual.1995.480821,,402.0,95.0,0.0,150.0,TT,,3d graphics visualization;toolkit includes description;scalar;issues portability pc;methods synchronizing execution,0.6884;0.2728;0.1634;0.0733;0.0722,"[np.int64(1), -1, -1, -1, -1]",2;-1;-1;-1;-1,2,2,Advanced Visualization Techniques
Vis,2001,Wavelet representation of contour sets,10.1109/visual.2001.964525,http://dx.doi.org/10.1109/VISUAL.2001.964525,303.0,310.0,C,"We present a new wavelet compression and multiresolution modeling approach for sets of contours (level sets). In contrast to previous wavelet schemes, our algorithm creates a parametrization of a scalar field induced by its contours and compactly stores this parametrization rather than function values sampled on a regular grid. Our representation is based on hierarchical polygon meshes with subdivision connectivity whose vertices are transformed into wavelet coefficients. From this sparse set of coefficients, every set of contours can be efficiently reconstructed at multiple levels of resolution. When applying lossy compression, introducing high quantization errors, our method preserves contour topology, in contrast to compression methods applied to the corresponding field function. We provide numerical results for scalar fields defined on planar domains. Our approach generalizes to volumetric domains, time-varying contours, and level sets of vector fields.",Martin Bertram 0001;Daniel E. Laney;Mark A. Duchaineau;Charles D. Hansen;Bernd Hamann;Kenneth I. Joy,M. Bertram;D.E. Laney;M.A. Duchaineau;C.D. Hansen;B. Hamann;K.I. Joy,"Department of Computer Science, University of Kaiserslautern, Kaiserslautern, Germany and SCI Institute, University of Utah, Salt Lake, UT, USA;Center for Applied Scientific Computing CASC, Lawrence Livemore National Laboratory, Livermore, CA, USA;Center for Applied Scientific Computing CASC, Lawrence Livemore National Laboratory, Livermore, CA, USA;Center for Image Processing and Integrated Computing CIPIC Department of Computer Science, University of California, Davis, CA, USA;SCI Institute, University of Utah, Salt Lake, UT, USA;Center for Image Processing and Integrated Computing CIPIC Department of Computer Science, University of California, Davis, CA, USA",10.1109/visual.1994.346332;10.1109/visual.2000.885720;10.1109/visual.2000.885716;10.1109/visual.2000.885705;10.1109/visual.1994.346332,"Contours, Geometry Compression, Iso-surfaces, Level Sets, Multiresolution Methods, Wavelets",14.0,3.0,21.0,90.0,,,wavelet compression multiresolution;contours efficiently;fields defined planar;lossy;sets,0.5814;0.5136;0.1971;0.0804;0.0121,"[np.int64(-1), np.int64(-1), -1, -1, -1]",81;53;-1;-1;-1,53;81,81,Multiresolution Techniques
Vis,2001,Case study: medical Web service for the automatic 3D documentation for neuroradiological diagnosis,10.1109/visual.2001.964542,http://dx.doi.org/10.1109/VISUAL.2001.964542,425.0,428.0,C,"The case study presents a medical Web service for the automatic analysis of CTA (computer tomography angiography) datasets. It aims at the detection and evaluation of intracranial aneurysms which are malformations of cerebral blood vessels. To obtain a standardized 3D visualization, digital videos are automatically generated. The time-consuming video production caused by the manual delineation of structures, software based volume rendering, and the interactive definition of an optimized camera path is considerably improved with a fully automatic strategy. Therefore, a previously suggested approach (C. Rezk-Salama, 2000) is applied which uses an optimized transfer function as a template and automatically adapts it to an individual dataset. Furthermore, we introduce hardware-accelerated morphologic filtering in order to detect the location of mid-size and giant aneurysms. The actual generation of the video is finally integrated into a hardware accelerated off-screen rendering process based on 3D texture mapping, ensuring fast visualization of high quality. Overall, clinical routine can be considerably assisted by providing a Web based service combining automatic detection and standardized visualization.",Sabine Iserhardt-Bauer;Peter Hastreiter;Thomas Ertl;K. Eberhardt;Bernd Tomandl,S. Iserhardt-Bauer;P. Hastreiter;T. Ertl;K. Eberhardt;B. Tomandl,"Visualization and Interactive Systems Group, University of Stuttgart, Germany;Neurocenter, University of Erlangen Nuremberg, Germany;Visualization and Interactive Systems Group, University of Stuttgart, Germany;Division of Neuroradiology, University of Erlangen Nuremberg, Germany;Division of Neuroradiology, University of Erlangen Nuremberg, Germany",10.1109/visual.2000.885729;10.1109/visual.2000.885729,"Medical visualization, segmentation, automatic web service, video generation",15.0,2.0,11.0,128.0,,,computer tomography angiography;based 3d texture;video production caused;based service combining;definition,0.5708;0.4086;0.1848;0.0836;0.0123,"[np.int64(-1), np.int64(-1), -1, -1, -1]",49;44;-1;-1;-1,44;49,49,Computed Tomography
VAST,2014,Transforming Scagnostics to Reveal Hidden Features,10.1109/tvcg.2014.2346572,http://dx.doi.org/10.1109/TVCG.2014.2346572,1624.0,1632.0,J,"Scagnostics (Scatterplot Diagnostics) were developed by Wilkinson et al. based on an idea of Paul and John Tukey, in order to discern meaningful patterns in large collections of scatterplots. The Tukeys' original idea was intended to overcome the impediments involved in examining large scatterplot matrices (multiplicity of plots and lack of detail). Wilkinson's implementation enabled for the first time scagnostics computations on many points as well as many plots. Unfortunately, scagnostics are sensitive to scale transformations. We illustrate the extent of this sensitivity and show how it is possible to pair statistical transformations with scagnostics to enable discovery of hidden structures in data that are not discernible in untransformed visualizations.",Dang Tuan Nhon;Leland Wilkinson,Tuan Nhon Dang;Leland Wilkinson,"Department of Computer Science, University of Illinois at Chicago;Department of Computer Science, University of Illinois at Chicago",10.1109/tvcg.2006.163;10.1109/infvis.2005.1532142;10.1109/tvcg.2013.187;10.1109/tvcg.2011.167;10.1109/vast.2006.261423;10.1109/tvcg.2010.184;10.1109/vast.2011.6102437;10.1109/vast.2007.4389006;10.1109/tvcg.2006.163,"Scagnostics, Scatterplot matrix, Transformation, High-Dimensional Visual Analytics",46.0,26.0,44.0,783.0,,,scatterplot diagnostics developed;sensitive scale transformations;patterns large collections;multiplicity;al,0.6910;0.4130;0.2866;0.1130;0.0049,"[np.int64(-1), np.int64(-1), -1, -1, -1]",-1;54;-1;-1;-1,54,54,Image Transformation Techniques
Vis,1995,"Defining, computing, and visualizing molecular interfaces",10.1109/visual.1995.480793,http://dx.doi.org/10.1109/VISUAL.1995.480793,36.0,,C,"A parallel, analytic approach for defining and computing the inter and intra molecular interfaces in three dimensions is described. The molecular interface surfaces are derived from approximations to the power diagrams over the participating molecular units. For a given molecular interface our approach can generate a family of interface surfaces parametrized by /spl alpha/ and /spl beta/, where /spl alpha/ is the radius of the solvent molecule (also known as the probe radius) and /spl beta/ is the interface radius that defines the size of the molecular interface. Molecular interface surfaces provide biochemists with a powerful tool to study surface complementarity and to efficiently characterize the interactions during a protein substrate docking. The complexity of our algorithm for molecular environments is O(nk log/sup 2/ k), where n is the number of atoms in the participating molecular units and k is the average number of neighboring atoms-a constant, given /spl alpha/ and /spl beta/.",Amitabh Varshney;Frederick P. Brooks Jr.;David C. Richardson;William V. Wright;Dinesh Manocha,A. Varshney;F.P. Brooks;D.C. Richardson;W.V. Wright;D. Manocha,"Department of Computer Science, State University of New York, Stony Brook, Stony Brook, NY, USA;Department of Computer Science, University of North Carolina, Chapel Hill, Chapel Hill, NC, USA;Department of Biochemistry, Duke University Medical Center, Durham, NC, USA;Department of Computer Science, University of North Carolina, Chapel Hill, Chapel Hill, NC, USA;Department of Computer Science, University of North Carolina, Chapel Hill, Chapel Hill, NC, USA",10.1109/visual.1993.398878;10.1109/visual.1993.398878,,45.0,7.0,19.0,91.0,,,molecular interface approach;docking complexity algorithm;parallel;environments nk;log sup number,0.7336;0.3866;0.0905;0.0317;-0.0299,"[np.int64(-1), np.int64(-1), -1, -1, -1]",27;-1;-1;-1;-1,27,27,Molecular Design Techniques
Vis,1997,The multilevel finite element method for adaptive mesh optimization and visualization of volume data,10.1109/visual.1997.663907,http://dx.doi.org/10.1109/VISUAL.1997.663907,387.0,394.0,C,"Multilevel representations and mesh reduction techniques have been used for accelerating the processing and the rendering of large datasets representing scalar- or vector-valued functions defined on complex 2D or 3D meshes. We present a method based on finite element approximations which combines these two approaches in a new and unique way that is conceptually simple and theoretically sound. The main idea is to consider mesh reduction as an approximation problem in appropriate finite element spaces. Starting with a very coarse triangulation of the functional domain, a hierarchy of highly non-uniform tetrahedral (or triangular in 2D) meshes is generated adaptively by local refinement. This process is driven by controlling the local error of the piecewise linear finite element approximation of the function on each mesh element. A reliable and efficient computation of the global approximation error and a multilevel preconditioned conjugate gradient solver are the key components of the implementation. In order to analyze the properties and advantages of the adaptively generated tetrahedral meshes, we implemented two volume visualization algorithms: an iso-surface extractor and a ray-caster. Both algorithms, while conceptually simple, show significant speedups over conventional methods delivering comparable rendering quality from adaptively compressed datasets.",Roberto Grosso;Christoph Lürig;Thomas Ertl,R. Grosso;C. Lurig;T. Ertl,"Computer Graphics Group, Universität Erlangen Nürnberg, Germany;Computer Graphics Group, Universität Erlangen Nürnberg, Germany;Computer Graphics Group, Universität Erlangen Nürnberg, Germany",10.1109/visual.1996.568127;10.1109/visual.1996.568124;10.1109/visual.1995.480805;10.1109/visual.1996.568121;10.1109/visual.1993.398852;10.1109/visual.1995.480806;10.1109/visual.1996.567606;10.1109/visual.1996.568127,,133.0,38.0,32.0,281.0,,,mesh reduction techniques;multilevel representations;tetrahedral triangular 2d;scalar vector valued;approximation error,0.6374;0.3242;0.3191;0.1507;0.1277,"[np.int64(-1), -1, -1, -1, -1]",64;-1;-1;-1;-1,64,64,Mesh Optimization Techniques
Vis,2009,Multimodal Vessel Visualization of Mouse Aorta PET/CT Scans,10.1109/tvcg.2009.169,http://dx.doi.org/10.1109/TVCG.2009.169,1515.0,1522.0,J,"In this paper, we present a visualization system for the visual analysis of PET/CT scans of aortic arches of mice. The system has been designed in close collaboration between researchers from the areas of visualization and molecular imaging with the objective to get deeper insights into the structural and molecular processes which take place during plaque development. Understanding the development of plaques might lead to a better and earlier diagnosis of cardiovascular diseases, which are still the main cause of death in the western world. After motivating our approach, we will briefly describe the multimodal data acquisition process before explaining the visualization techniques used. The main goal is to develop a system which supports visual comparison of the data of different species. Therefore, we have chosen a linked multi-view approach, which amongst others integrates a specialized straightened multipath curved planar reformation and a multimodal vessel flattening technique. We have applied the visualization concepts to multiple data sets, and we will present the results of this investigation.",Timo Ropinski;Sven Hermann;Rainer Reich;Michael Schäfers 0001;Klaus H. Hinrichs,Timo Ropinski;Sven Hermann;Rainer Reich;Michael Schafers;Klaus Hinrichs,"Visualization and Computer Graphics Research Group (VisCG), University of Münster, Germany;University of Münster, Germany;Visualization and Computer Graphics Research Group (VisCG), University of Münster, Germany;European Institute of Molecular Imaging, Germany;Visualization and Computer Graphics Research Group (VisCG), University of Münster, Germany",10.1109/visual.2003.1250353;10.1109/visual.1992.235203;10.1109/tvcg.2007.70576;10.1109/visual.2004.104;10.1109/visual.2003.1250384;10.1109/visual.2001.964538;10.1109/tvcg.2007.70560;10.1109/visual.2002.1183754;10.1109/visual.2003.1250396;10.1109/visual.2003.1250353,"Vessel visualization, plaque growth, multipath CPR, vessel flattening",42.0,22.0,36.0,501.0,,,multimodal vessel flattening;visual comparison data;plaques lead better;arches mice;development understanding development,0.6502;0.3413;0.2385;0.2274;0.0214,"[np.int64(-1), -1, -1, -1, -1]",48;-1;-1;-1;-1,48,48,Medical Imaging Techniques
Vis,2007,Topological Visualization of Brain Diffusion MRI Data,10.1109/tvcg.2007.70602,http://dx.doi.org/10.1109/TVCG.2007.70602,1496.0,1503.0,J,"Topological methods give concise and expressive visual representations of flow fields. The present work suggests a comparable method for the visualization of human brain diffusion MRI data. We explore existing techniques for the topological analysis of generic tensor fields, but find them inappropriate for diffusion MRI data. Thus, we propose a novel approach that considers the asymptotic behavior of a probabilistic fiber tracking method and define analogs of the basic concepts of flow topology, like critical points, basins, and faces, with interpretations in terms of brain anatomy. The resulting features are fuzzy, reflecting the uncertainty inherent in any connectivity estimate from diffusion imaging. We describe an algorithm to extract the new type of features, demonstrate its robustness under noise, and present results for two regions in a diffusion MRI dataset to illustrate that the method allows a meaningful visual analysis of probabilistic fiber tracking results.",Thomas Schultz 0001;Holger Theisel;Hans-Peter Seidel,Thomas Schultz;Holger Theisel;Hans-Peter Seidel,"MPI Informatik Saarbrücken, Saarbruecken, Germany;BieGraph Group, Bielefeld University, Germany;MPI Informatik Saarbrücken, Saarbruecken, Germany",10.1109/visual.1999.809894;10.1109/visual.2005.1532777;10.1109/visual.2005.1532841;10.1109/visual.1994.346326;10.1109/visual.2005.1532778;10.1109/visual.1994.346326;10.1109/visual.1999.809894,"Diffusion tensor, probabilistic fiber tracking, tensor topology, uncertainty visualization",64.0,42.0,32.0,477.0,,,brain diffusion mri;existing techniques topological;tensor fields;probabilistic fiber;define analogs,0.6290;0.4574;0.4072;0.3331;0.0629,"[np.int64(-1), np.int64(-1), np.int64(-1), -1, -1]",47;-1;35;-1;-1,35;47,47,Diffusion MRI Analysis
InfoVis,2020,Rainbows Revisited: Modeling Effective Colormap Design for Graphical Inference,10.1109/tvcg.2020.3030439,http://dx.doi.org/10.1109/TVCG.2020.3030439,1032.0,1042.0,J,"Color mapping is a foundational technique for visualizing scalar data. Prior literature offers guidelines for effective colormap design, such as emphasizing luminance variation while limiting changes in hue. However, empirical studies of color are largely focused on perceptual tasks. This narrow focus inhibits our understanding of how generalizable these guidelines are, particularly to tasks like visual inference that require synthesis and judgement across multiple percepts. Furthermore, the emphasis on traditional ramp designs (e.g., sequential or diverging) may sideline other key metrics or design strategies. We study how a cognitive metric-color name variation-impacts people's ability to make model-based judgments. In two graphical inference experiments, participants saw a series of color-coded scalar fields sampled from different models and assessed the relationships between these models. Contrary to conventional guidelines, participants were more accurate when viewing colormaps that cross a variety of uniquely nameable colors. We modeled participants' performance using this metric and found that it provides a better fit to the experimental data than do existing design principles. Our findings indicate cognitive advantages for colorful maps like rainbow, which exhibit high color categorization, despite their traditionally undesirable perceptual properties. We also found no evidence that color categorization would lead observers to infer false data features. Our results provide empirically grounded metrics for predicting a colormap's performance and suggest alternative guidelines for designing new quantitative colormaps to support inference. The data and materials for this paper are available at: https://osf.io/tck2r/",Khairi Reda;Danielle Albers Szafir,Khairi Reda;Danielle Albers Szafir,"University of Colorado, Boulder;University-Purdue University, Indianapolis",10.1109/visual.1995.480803;10.1109/tvcg.2011.192;10.1109/tvcg.2017.2743978;10.1109/tvcg.2016.2598918;10.1109/tvcg.2012.230;10.1109/tvcg.2014.2346325;10.1109/tvcg.2016.2599106;10.1109/visual.2001.964510;10.1109/tvcg.2015.2467471;10.1109/tvcg.2019.2934284;10.1109/tvcg.2017.2744359;10.1109/tvcg.2010.161;10.1109/visual.1995.480803,"Color,perception,graphical inference,scalar data",18.0,29.0,68.0,1151.0,,,cognitive metric color;variety uniquely nameable;traditional ramp designs;scalar fields sampled;series,0.6480;0.2149;0.1770;0.0889;0.0410,"[np.int64(-1), -1, -1, -1, -1]",78;-1;-1;-1;-1,78,78,Cognitive Visual Analysis
Vis,1994,"Visualization and geographic information system integration: what are the needs and the requirements, if any?",10.1109/visual.1994.346284,http://dx.doi.org/10.1109/VISUAL.1994.346284,400.0,403.0,M,"Addresses the needs and requirements of integrating visualization and geographic information system technologies. There are three levels of integration methods: rudimentary, operational and functional. The rudimentary approach uses the minimum amount of data sharing and exchange between these two technologies. The operational level attempts to provide consistency of the data while removing redundancies between the two technologies. The functional form attempts to provide transparent communication between these respective software environments. At this level, the user only needs to request information and the integrated system retrieves or generates the information depending upon the request. This paper examines the role and impact of these three levels of integration. Stepping further into the future, the paper also questions the long-term survival of these separate disciplines.&lt;&lt;ETX&gt;&gt;",Theresa-Marie Rhyne;William Ivey;Loey Knapp;Peter Kochevar;Tom Mace,T.M. Rhyne;W. Ivey;L. Knapp;P. Kochevar;T. Mace,"Martin Marietta, U. S. EPA Visualization Center;SAS Institute, Inc.;IBM and University of Colorado, USA;DEC, San Diego Supercomputing Center;Scientific Computing Branch, U.S. EPA",,,29.0,2.0,3.0,112.0,,,integrating visualization geographic;technologies levels;minimum data sharing;retrieves generates;paper questions long,0.8077;0.2526;0.1851;-0.0067;-0.0702,"[np.int64(-1), -1, -1, -1, -1]",60;-1;-1;-1;-1,60,60,Geographic Visual Analytics
InfoVis,2011,"Angular Histograms: Frequency-Based Visualizations for Large, High Dimensional Data",10.1109/tvcg.2011.166,http://dx.doi.org/10.1109/TVCG.2011.166,2572.0,2580.0,J,"Parallel coordinates is a popular and well-known multivariate data visualization technique. However, one of their inherent limitations has to do with the rendering of very large data sets. This often causes an overplotting problem and the goal of the visual information seeking mantra is hampered because of a cluttered overview and non-interactive update rates. In this paper, we propose two novel solutions, namely, angular histograms and attribute curves. These techniques are frequency-based approaches to large, high-dimensional data visualization. They are able to convey both the density of underlying polylines and their slopes. Angular histogram and attribute curves offer an intuitive way for the user to explore the clustering, linear correlations and outliers in large data sets without the over-plotting and clutter problems associated with traditional parallel coordinates. We demonstrate the results on a wide variety of data sets including real-world, high-dimensional biological data. Finally, we compare our methods with the other popular frequency-based algorithms.",Zhao Geng;Zhenmin Peng;Robert S. Laramee;Jonathan C. Roberts;Rick Walker,Zhao Geng;ZhenMin Peng;Robert S.Laramee;Jonathan C. Roberts;Rick Walker,"Visual Computing Group, Swansea University, UK;Visual Computing Group, Swansea University, UK;Swansea University, UK;Bangor University, UK;Visual Computing Group, Swansea University, UK",10.1109/infvis.2002.1173157;10.1109/infvis.2004.68;10.1109/tvcg.2006.138;10.1109/tvcg.2007.70535;10.1109/visual.1999.809866;10.1109/infvis.1996.559216;10.1109/visual.1990.146402;10.1109/tvcg.2010.184;10.1109/infvis.2005.1532138;10.1109/tvcg.2006.170;10.1109/tvcg.2008.131;10.1109/infvis.2002.1173157,"Parallel Coordinates, Angular Histogram, Attribute Curves",77.0,33.0,28.0,1702.0,,,multivariate data visualization;polylines slopes angular;frequency;causes overplotting;non interactive update,0.6891;0.3585;0.1235;0.0522;0.0134,"[np.int64(1), np.int64(-1), -1, -1, -1]",11;72;-1;-1;-1,11;72,11,Multivariate Data Visualization
Vis,2010,VDVR: Verifiable Volume Visualization of Projection-Based Data,10.1109/tvcg.2010.211,http://dx.doi.org/10.1109/TVCG.2010.211,1515.0,1524.0,J,"Practical volume visualization pipelines are never without compromises and errors. A delicate and often-studied component is the interpolation of off-grid samples, where aliasing can lead to misleading artifacts and blurring, potentially hiding fine details of critical importance. The verifiable visualization framework we describe aims to account for these errors directly in the volume generation stage, and we specifically target volumetric data obtained via computed tomography (CT) reconstruction. In this case the raw data are the X-ray projections obtained from the scanner and the volume data generation process is the CT algorithm. Our framework informs the CT reconstruction process of the specific filter intended for interpolation in the subsequent visualization process, and this in turn ensures an accurate interpolation there at a set tolerance. Here, we focus on fast trilinear interpolation in conjunction with an octree-type mixed resolution volume representation without T-junctions. Efficient rendering is achieved by a space-efficient and locality-optimized representation, which can straightforwardly exploit fast fixed-function pipelines on GPUs.",Ziyi Zheng;Wei Xu 0020;Klaus Mueller 0001,Ziyi Zheng;Wei Xu;Klaus Mueller,"Center of Visual Computing, Stony Brook University, USA;Center of Visual Computing, Stony Brook University, USA;Center of Visual Computing, Stony Brook University, USA",10.1109/visual.1999.809908;10.1109/visual.1991.175805;10.1109/tvcg.2009.194;10.1109/tvcg.2006.141;10.1109/visual.1994.346331;10.1109/visual.2004.70;10.1109/tvcg.2009.149;10.1109/visual.1999.809908,"Direct volume rendering, computed tomography, filtered back-projection, verifiable visualization ",13.0,5.0,36.0,338.0,,,practical volume visualization;tomography ct reconstruction;filter intended interpolation;function pipelines gpus;exploit fast fixed,0.6427;0.4924;0.2875;0.2786;-0.0133,"[np.int64(0), np.int64(-1), -1, -1, -1]",0;49;-1;-1;-1,0;49,0,Volume Rendering Techniques
Vis,1991,Designing a distributed scientific visualization tool,10.1109/visual.1991.175835,http://dx.doi.org/10.1109/VISUAL.1991.175835,383.0,386.0,C,"The benefits of using a distributed scientific visualization tool in the field of acoustic modeling are demonstrated. A user-friendly interface was developed under SunView. A Remote Procedure Call was used for transparent data transfer between a CRAY X-MP/28 and Sun 4 workstation. PV-WAVE, a high-level graphics package, was used to visualize the results.&lt;&lt;ETX&gt;&gt;",L. van der Sluis,L.V. Sluis,"Technology Applications, Inc.",,,1.0,0.0,4.0,42.0,,,acoustic modeling demonstrated;scientific visualization tool;sunview remote procedure;benefits using distributed;28 sun,0.6136;0.5654;0.2888;0.1511;-0.0143,"[np.int64(-1), np.int64(1), -1, -1, -1]",39;9;-1;-1;-1,9;39,39,Sound Propagation Modeling
InfoVis,2004,Building Highly-Coordinated Visualizations in Improvise,10.1109/infvis.2004.12,http://dx.doi.org/10.1109/INFVIS.2004.12,159.0,166.0,C,"Improvise is a fully-implemented system in which users build and browse multiview visualizations interactively using a simple shared-object coordination mechanism coupled with a flexible, expression-based visual abstraction language. By coupling visual abstraction with coordination, users gain precise control over how navigation and selection in the visualization affects the appearance of data in individual views. As a result, it is practical to build visualizations with more views and richer coordination in Improvise than in other visualization systems. Building and browsing activities are integrated in a single, live user interface that lets users alter visualizations quickly and incrementally during data exploration",Chris E. Weaver,C. Weaver,"Computer Science Department, University of Wisconsin, Madison, USA",10.1109/infvis.2002.1173141;10.1109/infvis.2000.885086;10.1109/infvis.2002.1173141,"coordinated queries, coordination, exploratory visualization, multiple views, visual abstraction language",320.0,101.0,23.0,1026.0,,,visualizations interactively;build browse multiview;coordination mechanism coupled;expression;single live user,0.7397;0.4057;0.1154;0.0917;-0.0153,"[np.int64(1), np.int64(-1), -1, -1, -1]",16;74;-1;-1;-1,16;74,16,Interactive Visualization Systems
Vis,2008,Visualizing Particle/Flow Structure Interactions in the Small Bronchial Tubes,10.1109/tvcg.2008.183,http://dx.doi.org/10.1109/TVCG.2008.183,1412.0,1427.0,J,"Particle deposition in the small bronchial tubes (generations six through twelve) is strongly influenced by the vortex-dominated secondary flows that are induced by axial curvature of the tubes. In this paper, we employ particle destination maps in conjunction with two-dimensional, finite-time Lyapunov exponent maps to illustrate how the trajectories of finite-mass particles are influenced by the presence of vortices. We consider two three-generation bronchial tube models: a planar, asymmetric geometry and a non-planar, asymmetric geometry. Our visualizations demonstrate that these techniques, coupled with judiciously seeded particle trajectories, are effective tools for studying particle/flow structure interactions.",Bela Soni;David S. Thompson;Raghu Machiraju,Bela Soni;David Thompson;Raghu Machiraju,"Graduate Research Assistant at the Computational Simulation and Design Center, Mississippi State University, USA;Department of Aerospace Engineering, Mississippi State University, USA;Department of Computer Science and Engineering, Ohio State Uinversity, USA",10.1109/tvcg.2007.70551;10.1109/tvcg.2007.70554;10.1109/tvcg.2007.70551,"FTLE, particle trajectory, visualization, bronchial tube",27.0,17.0,30.0,335.0,,,studying particle flow;generation bronchial tube;lyapunov exponent maps;geometry non planar;judiciously,0.5979;0.4257;0.2888;0.0252;0.0074,"[np.int64(-1), np.int64(-1), -1, -1, -1]",24;40;-1;-1;-1,24;40,24,Particle Dynamics Analysis
VAST,2015,"The Role of Uncertainty, Awareness, and Trust in Visual Analytics",10.1109/tvcg.2015.2467591,http://dx.doi.org/10.1109/TVCG.2015.2467591,240.0,249.0,J,"Visual analytics supports humans in generating knowledge from large and often complex datasets. Evidence is collected, collated and cross-linked with our existing knowledge. In the process, a myriad of analytical and visualisation techniques are employed to generate a visual representation of the data. These often introduce their own uncertainties, in addition to the ones inherent in the data, and these propagated and compounded uncertainties can result in impaired decision making. The user's confidence or trust in the results depends on the extent of user's awareness of the underlying uncertainties generated on the system side. This paper unpacks the uncertainties that propagate through visual analytics systems, illustrates how human's perceptual and cognitive biases influence the user's awareness of such uncertainties, and how this affects the user's trust building. The knowledge generation model for visual analytics is used to provide a terminology and framework to discuss the consequences of these aspects in knowledge construction and though examples, machine uncertainty is compared to human trust measures with provenance. Furthermore, guidelines for the design of uncertainty-aware systems are presented that can aid the user in better decision making.",Dominik Sacha;Hansi Senaratne;Bum Chul Kwon;Geoffrey P. Ellis;Daniel A. Keim,Dominik Sacha;Hansi Senaratne;Bum Chul Kwon;Geoffrey Ellis;Daniel A. Keim,"Data Analysis and Visualisation Group, University of Konstanz;Data Analysis and Visualisation Group, University of Konstanz;Data Analysis and Visualisation Group, University of Konstanz;Data Analysis and Visualisation Group, University of Konstanz;Data Analysis and Visualisation Group, University of Konstanz",10.1109/tvcg.2014.2346575;10.1109/visual.2000.885679;10.1109/vast.2008.4677385;10.1109/vast.2009.5332611;10.1109/tvcg.2012.260;10.1109/vast.2011.6102473;10.1109/vast.2009.5333020;10.1109/vast.2011.6102435;10.1109/tvcg.2012.279;10.1109/tvcg.2014.2346481;10.1109/vast.2006.261416;10.1109/tvcg.2014.2346575,"Visual Analytics, Knowledge Generation, Uncertainty Measures and Propagation, Trust Building, Human Factors",261.0,180.0,83.0,4217.0,,,visual analytics systems;trust building knowledge;uncertainties result impaired;employed generate;terminology,0.5819;0.3769;0.3494;0.1029;0.0850,"[np.int64(1), np.int64(-1), -1, -1, -1]",14;42;-1;-1;-1,14;42,14,Visual Analytics Systems
InfoVis,2020,Responsive Matrix Cells: A Focus+Context Approach for Exploring and Editing Multivariate Graphs,10.1109/tvcg.2020.3030371,http://dx.doi.org/10.1109/TVCG.2020.3030371,1644.0,1654.0,J,"Matrix visualizations are a useful tool to provide a general overview of a graph's structure. For multivariate graphs, a remaining challenge is to cope with the attributes that are associated with nodes and edges. Addressing this challenge, we propose responsive matrix cells as a focus+context approach for embedding additional interactive views into a matrix. Responsive matrix cells are local zoomable regions of interest that provide auxiliary data exploration and editing facilities for multivariate graphs. They behave responsively by adapting their visual contents to the cell location, the available display space, and the user task. Responsive matrix cells enable users to reveal details about the graph, compare node and edge attributes, and edit data values directly in a matrix without resorting to external views or tools. We report the general design considerations for responsive matrix cells covering the visual and interactive means necessary to support a seamless data exploration and editing. Responsive matrix cells have been implemented in a web-based prototype based on which we demonstrate the utility of our approach. We describe a walk-through for the use case of analyzing a graph of soccer players and report on insights from a preliminary user feedback session.",Tom Horak;Philip Berger;Heidrun Schumann;Raimund Dachselt;Christian Tominski,Tom Horak;Philip Berger;Heidrun Schumann;Raimund Dachselt;Christian Tominski,"Interactive Media Lab, Technische Universitat Dresden;Inst. for Visual & Analytic Computing, University of Rostock;Inst. for Visual & Analytic Computing, University of Rostock;Interactive Media Lab, Technische Universitat Dresden;Inst. for Visual & Analytic Computing, University of Rostock",10.1109/tvcg.2006.120;10.1109/tvcg.2017.2743990;10.1109/tvcg.2014.2346575;10.1109/tvcg.2011.213;10.1109/tvcg.2007.70582;10.1109/infvis.2004.2;10.1109/tvcg.2008.109;10.1109/tvcg.2018.2865151;10.1109/infvis.2002.1173149;10.1109/tvcg.2009.151;10.1109/tvcg.2018.2865149;10.1109/tvcg.2014.2346279;10.1109/tvcg.2017.2745219;10.1109/tvcg.2014.2346441;10.1109/tvcg.2015.2467202;10.1109/tvcg.2006.120,"Multivariate graph visualization,matrix visualization,focus+context,embedded visualizations,responsive visualization,graph editing",7.0,14.0,83.0,1479.0,,,matrix visualizations;node edge attributes;editing responsive;soccer players report;contents cell,0.6361;0.3167;0.2746;0.1788;0.1482,"[np.int64(1), -1, -1, -1, -1]",12;-1;-1;-1;-1,12,12,Table-Based Visualizations
Vis,1990,Personal visualization system: applications in research and engineering,10.1109/visual.1990.146418,http://dx.doi.org/10.1109/VISUAL.1990.146418,443.0,,C,"The authors describe an innovative personal visualization system and its application to several research and engineering problems. The system bridges both hardware and software components to permit a user to graphically describe a visualization problem to the computer; thereby reducing program development time to a few hours. Low-cost visualization is achieved using PC-based software that can either be executed on a PC or drive graphic workstations for high-resolution displays. In either case, supercomputer computation rates are available for the visualization process. On PCs this is done with one or more PiP plug in cards, each of which is capable of 100 million floating point operations per second. On workstations this is done with the QUEN array processor. Applications mentioned include: ocean wave imaging; characterizing superconductors; and solar sail visualization.&lt;&lt;ETX&gt;&gt;",Quentin E. Dolecek;K. Moorjani;B. F. Kim;D. G. Tilley;Thomas S. Denney Jr.,Q.E. Dolecek;K. Moorjani;B.F. Kim;D.G. Tilley;T.S. Denney,"Applied Physics Laboratory, Johns Hopkins University, Laurel, MD, USA;Applied Physics Laboratory, Johns Hopkins University, Laurel, MD, USA;Applied Physics Laboratory, Johns Hopkins University, Laurel, MD, USA;Applied Physics Laboratory, Johns Hopkins University, Laurel, MD, USA;Applied Physics Laboratory, Johns Hopkins University, Laurel, MD, USA",,,0.0,0.0,9.0,54.0,,,solar sail visualization;resolution displays;characterizing superconductors;software executed pc;authors innovative personal,0.6115;0.2156;0.1910;0.1628;0.0885,"[np.int64(1), -1, -1, -1, -1]",3;-1;-1;-1;-1,3,3,Aerospace Visualizations
Vis,2000,New techniques for topologically correct surface reconstruction,10.1109/visual.2000.885718,http://dx.doi.org/10.1109/VISUAL.2000.885718,373.0,380.0,C,"We present a novel approach to surface reconstruction based on the Delaunay complex. First we give a simple and fast algorithm that picks locally a surface at each vertex. For that, we introduce the concept of /spl lambda/-intervals. It turns out that for smooth regions of the surface this method works very well and at difficult parts of the surface yields an output well-suited for postprocessing. As a postprocessing step we propose a topological clean up and a new technique based on linear programming in order to establish a topologically correct surface. These techniques should be useful also for many other reconstruction schemes.",Udo Adamy;Joachim Giesen;Matthias John 0003,U. Adamy;J. Giesen;M. John,"Institute of Theoretical Computer Science, Zurich, Switzerland;Institute of Theoretical Computer Science, Switzerland;Institute of Theoretical Computer Science, Switzerland",10.1109/visual.1998.745286;10.1109/visual.1998.745286,"surface reconstruction, gabriel graph, linear programming, topology",65.0,12.0,18.0,85.0,,,reconstruction based delaunay;topologically correct surface;complex simple;postprocessing postprocessing step;picks,0.7101;0.4721;0.1995;0.0687;0.0191,"[np.int64(-1), np.int64(-1), -1, -1, -1]",65;76;-1;-1;-1,65;76,65,Surface Reconstruction Techniques
Vis,2011,Interactive Multiscale Tensor Reconstruction for Multiresolution Volume Visualization,10.1109/tvcg.2011.214,http://dx.doi.org/10.1109/TVCG.2011.214,2135.0,2143.0,J,"Large scale and structurally complex volume datasets from high-resolution 3D imaging devices or computational simulations pose a number of technical challenges for interactive visual analysis. In this paper, we present the first integration of a multiscale volume representation based on tensor approximation within a GPU-accelerated out-of-core multiresolution rendering framework. Specific contributions include (a) a hierarchical brick-tensor decomposition approach for pre-processing large volume data, (b) a GPU accelerated tensor reconstruction implementation exploiting CUDA capabilities, and (c) an effective tensor-specific quantization strategy for reducing data transfer bandwidth and out-of-core memory footprint. Our multiscale representation allows for the extraction, analysis and display of structural features at variable spatial scales, while adaptive level-of-detail rendering methods make it possible to interactively explore large datasets within a constrained memory footprint. The quality and performance of our prototype system is evaluated on large structurally complex datasets, including gigabyte-sized micro-tomographic volumes.",Susanne K. Suter;José Antonio Iglesias Guitián;Fabio Marton;Marco Agus;Andreas Elsener;Christoph P. E. Zollikofer;Meenakshisundaram Gopi;Enrico Gobbetti;Renato Pajarola,Susanne K. Suter;Jose A. Iglesias Guitian;Fabio Marton;Marco Agus;Andreas Elsener;Christoph P.E. Zollikofer;M. Gopi;Enrico Gobbetti;Renato Pajarola,"University of Zurich, Switzerland;CRS4, Italy;CRS4, Italy;CRS4, Italy;University of Zurich, Switzerland;University of Zurich, Switzerland;University of California, Irvine, USA;CRS4, Italy;University of Zurich, Switzerland",10.1109/visual.2002.1183757;10.1109/visual.1997.663900;10.1109/tvcg.2007.70516;10.1109/visual.1998.745311;10.1109/tvcg.2006.146;10.1109/visual.2003.1250385;10.1109/visual.2002.1183757,"GPU/CUDA, multiscale, tensor reconstruction, interactive volume visualization, multiresolution rendering",63.0,39.0,28.0,838.0,,,volume data gpu;scale structurally complex;specific quantization strategy;including;prototype evaluated,0.6273;0.3216;0.1969;-0.0108;-0.0184,"[np.int64(0), -1, -1, -1, -1]",0;-1;-1;-1;-1,0,0,Volume Rendering Techniques
InfoVis,2004,Value and Relation Display for Interactive Exploration of High Dimensional Datasets,10.1109/infvis.2004.71,http://dx.doi.org/10.1109/INFVIS.2004.71,73.0,80.0,C,"Traditional multidimensional visualization techniques, such as glyphs, parallel coordinates and scatterplot matrices, suffer from clutter at the display level and difficult user navigation among dimensions when visualizing high dimensional datasets. In this paper, we propose a new multidimensional visualization technique named a value and relation (VaR) display, together with a rich set of navigation and selection tools, for interactive exploration of datasets with up to hundreds of dimensions. By explicitly conveying the relationships among the dimensions of a high dimensional dataset, the VaR display helps users grasp the associations among dimensions. By using pixel-oriented techniques to present values of the data items in a condensed manner, the VaR display reveals data patterns in the dataset using as little screen space as possible. The navigation and selection tools enable users to interactively reduce clutter, navigate within the dimension space, and examine data value details within context effectively and efficiently. The VaR display scales well to datasets with large numbers of data items by employing sampling and texture mapping. A case study on a real dataset, as well as the VaR displays of multiple real datasets throughout the paper, reveals how our proposed approach helps users interactively explore high dimensional datasets with large numbers of data items",Jing Yang 0001;Anilkumar Patro;Shiping Huang;Nishant K. Mehta;Matthew O. Ward;Elke A. Rundensteiner,Jing Yang;A. Patro;Shiping Huang;N. Mehta;M.O. Ward;E.A. Rundensteiner,"Computer Science Department, Worcester Polytechnic Institute, Worcester, MA, USA;Computer Science Department, Worcester Polytechnic Institute, Worcester, MA, USA;Computer Science Department, Worcester Polytechnic Institute, Worcester, MA, USA;Computer Science Department, Worcester Polytechnic Institute, Worcester, MA, USA;Computer Science Department, Worcester Polytechnic Institute, Worcester, MA, USA;Computer Science Department, Worcester Polytechnic Institute, Worcester, MA, USA",10.1109/infvis.1998.729559;10.1109/infvis.2003.1249015;10.1109/visual.1994.346302;10.1109/infvis.2003.1249014;10.1109/infvis.1995.528686;10.1109/visual.1995.485140;10.1109/infvis.1998.729559,"Multi-dimensional visualization, pixel-oriented, multi-dimensional scaling, high dimensional datasets",85.0,18.0,24.0,517.0,,,traditional multidimensional visualization;display reveals data;named value relation;helps users;set,0.7105;0.3073;0.2377;0.2026;0.0241,"[np.int64(1), -1, -1, -1, -1]",11;-1;-1;-1;-1,11,11,Multivariate Data Visualization
Vis,2002,Case study: Visualizing ocean flow vertical motions using Lagrangian-Eulerian time surfaces,10.1109/visual.2002.1183822,http://dx.doi.org/10.1109/VISUAL.2002.1183822,529.0,532.0,C,"Ocean model simulations commonly assume the ocean is hydrostatic, resulting in near zero vertical motion. The vertical motion found is typically associated with the variations of the thermocline depth over time, which are mainly a result of the development and movement of ocean fronts, eddies, and internal waves. A new technique, extended from Lagrangian-Eulerian Advection, is presented to help understand the variation of vertical motion associated with the change in thermocline depth over time. A time surface is correctly deformed in a single direction according to the flow. The evolution of the time surface is computed via a mixture of Eulerian and Lagrangian techniques. The dominant horizontal motion is textured onto the surface using texture advection, while both the horizontal and vertical motions are used to displace the surface. The resulting surface is shaded for enhanced contrast. Timings indicate that the overhead over standard 2D texture advection is no more than 12%.",Josh Grant;Gordon Erlebacher;James F. O'Brien,J. Grant;G. Erlebacher;J. O'Brien,"Center for Ocean-Atmospheric Prediction Studies, Florida State University, USA;School of Computational Science and Information Technology, Florida State University, USA;Center for Ocean-Atmospheric Prediction Studies, Florida State University, USA",10.1109/visual.1999.809895;10.1109/visual.2001.964493;10.1109/visual.2000.885688;10.1109/visual.1996.568149;10.1109/visual.1999.809895,"unsteady vector fields, time surfaces, ocean currents, vertical velocity",18.0,5.0,16.0,122.0,,,ocean model simulations;horizontal motion textured;associated change thermocline;eulerian lagrangian techniques;evolution time,0.5942;0.5057;0.3400;0.2878;0.1801,"[np.int64(-1), np.int64(-1), -1, -1, -1]",80;72;-1;-1;-1,72;80,80,Environmental Simulation Tools
InfoVis,2014,Activity Sculptures: Exploring the Impact of Physical Visualizations on Running Activity,10.1109/tvcg.2014.2352953,http://dx.doi.org/10.1109/TVCG.2014.2352953,2201.0,2210.0,J,"Data sculptures are a promising type of visualizations in which data is given a physical form. In the past, they have mostly been used for artistic, communicative or educational purposes, and designers of data sculptures argue that in such situations, physical visualizations can be more enriching than pixel-based visualizations. We present the design of Activity Sculptures: data sculptures of running activity. In a three-week field study we investigated the impact of the sculptures on 14 participants' running activity, the personal and social behaviors generated by the sculptures, as well as participants' experiences when receiving these individual physical tokens generated from the specific data of their runs. The physical rewards generated curiosity and personal experimentation but also social dynamics such as discussion on runs or envy/competition. We argue that such passive (or calm) visualizations can complement nudging and other mechanisms of persuasion with a more playful and reflective look at ones' activity.",Simon Stusak;Aurélien Tabard;Franziska Sauka;Rohit Ashok Khot;Andreas Butz,Simon Stusak;Aurélien Tabard;Franziska Sauka;Rohit Ashok Khot;Andreas Butz,"University of Munich (LMU);Université de Lyon & CNRS, Université Lyon 1, LIRIS, UMR5205, France;University of Munich (LMU);Exertion Games Lab, RMIT University;University of Munich (LMU)",10.1109/tvcg.2007.70541;10.1109/infvis.2003.1249031;10.1109/tvcg.2013.134;10.1109/tvcg.2007.70541,"Physical Visualizations, Activity Sculptures, Physical Activity, Data Sculptures, Behavioral Change",122.0,67.0,41.0,1566.0,,,activity sculptures;individual physical tokens;specific data runs;argue;past used,0.6085;0.1899;0.1848;0.1780;0.1123,"[np.int64(-1), -1, -1, -1, -1]",36;-1;-1;-1;-1,36,36,Artistic Expression
Vis,2000,Geometric compression for interactive transmission,10.1109/visual.2000.885711,http://dx.doi.org/10.1109/VISUAL.2000.885711,319.0,326.0,C,"The compression of geometric structures is a relatively new field of data compression. Since about 1995, several articles have dealt with the coding of meshes, using for most of them the following approach: the vertices of the mesh are coded in an order that partially contains the topology of the mesh. In the same time, some simple rules attempt to predict the position of each vertex from the positions of its neighbors that have been previously coded. We describe a compression algorithm whose principle is completely different: the coding order of the vertices is used to compress their coordinates, and then the topology of the mesh is reconstructed from the vertices. This algorithm achieves compression ratios that are slightly better than those of the currently available algorithms, and moreover, it allows progressive and interactive transmission of the meshes.",Olivier Devillers;Pierre-Marie Gandoin,O. Devillers;P.-M. Gandoin,"INRIA, Sophia-Antipolis, France;INRIA, Sophia-Antipolis, France",10.1109/visual.1997.663902;10.1109/visual.1999.809902;10.1109/vis.1999.10000;10.1109/visual.1997.663902,"geometry, compression, coding, interactivity, mesh, reconstruction, terrain models",187.0,76.0,18.0,339.0,,,compression geometric structures;mesh coded order;articles dealt coding;attempt predict position;completely different,0.6875;0.5249;0.1711;0.0919;-0.0491,"[np.int64(-1), np.int64(-1), -1, -1, -1]",56;56;-1;-1;-1,56,56,Geometric Compression
Vis,2024,Sportify: Question Answering with Embedded Visualizations and Personified Narratives for Sports Video,10.1109/tvcg.2024.3456332,http://dx.doi.org/10.1109/TVCG.2024.3456332,12.0,22.0,J,"As basketball's popularity surges, fans often find themselves confused and overwhelmed by the rapid game pace and complexity. Basketball tactics, involving a complex series of actions, require substantial knowledge to be fully understood. This complexity leads to a need for additional information and explanation, which can distract fans from the game. To tackle these challenges, we present Sportify, a Visual Question Answering system that integrates narratives and embedded visualization for demystifying basketball tactical questions, aiding fans in understanding various game aspects. We propose three novel action visualizations (i.e., Pass, Cut, and Screen) to demonstrate critical action sequences. To explain the reasoning and logic behind players' actions, we leverage a large-language model (LLM) to generate narratives. We adopt a storytelling approach for complex scenarios from both first and third-person perspectives, integrating action visualizations. We evaluated Sportify with basketball fans to investigate its impact on understanding of tactics, and how different personal perspectives of narratives impact the understanding of complex tactic with action visualizations. Our evaluation with basketball fans demonstrates Sportify's capability to deepen tactical insights and amplify the viewing experience. Furthermore, third-person narration assists people in getting in-depth game explanations while first-person narration enhances fans' game engagement.",Chunggi Lee;Tica Lin;Hanspeter Pfister;Zhu-Tian Chen,Chunggi Lee;Tica Lin;Hanspeter Pfister;Chen Zhu-Tian,"John A. Paulson School of Engineering and Applied Sciences, Harvard University, Cambridge, MA, USA;John A. Paulson School of Engineering and Applied Sciences, Harvard University, Cambridge, MA, USA;John A. Paulson School of Engineering and Applied Sciences, Harvard University, Cambridge, MA, USA;CSE department, University of Minnesota, Minneapolis, MN, USA",10.1109/tvcg.2020.3030358;10.1109/tvcg.2021.3114861;10.1109/vast.2014.7042478;10.1109/tvcg.2023.3326910;10.1109/tvcg.2023.3327161;10.1109/tvcg.2022.3209353;10.1109/tvcg.2013.192;10.1109/tvcg.2010.179;10.1109/tvcg.2023.3327197;10.1109/tvcg.2017.2745181;10.1109/tvcg.2019.2934630;10.1109/tvcg.2016.2598608;10.1109/tvcg.2022.3209373;10.1109/tvcg.2021.3114806,"Embedded Visualization,Narrative and storytelling,,,Basketball tactic,Question-answering (QA) system",,0.0,67.0,387.0,,,visualization demystifying basketball;answering integrates narratives;large language model;sportify capability;complex series actions,0.6367;0.4268;0.3013;0.1476;0.0899,"[np.int64(-1), np.int64(-1), -1, -1, -1]",57;45;-1;-1;-1,45;57,57,Sports Data Visualization
Vis,2001,Nonmanifold subdivision,10.1109/visual.2001.964528,http://dx.doi.org/10.1109/VISUAL.2001.964528,325.0,332.0,C,"Commonly-used subdivision schemes require manifold control meshes and produce manifold surfaces. However, it is often necessary to model nonmanifold surfaces, such as several surface patches meeting at a common boundary. In this paper, we describe a subdivision algorithm that makes it possible to model nonmanifold surfaces. Any triangle mesh, subject only to the restriction that no two vertices of any triangle coincide, can serve as an input to the algorithm. Resulting surfaces consist of collections of manifold patches joined along nonmanifold curves and vertices. If desired, constraints may be imposed on the tangent planes of manifold patches sharing a curve or a vertex. The algorithm is an extension of a well-known Loop subdivision scheme, and uses techniques developed for piecewise smooth surfaces.",Lexing Ying;Denis Zorin,Lexing Ying;D. Zorin,"New York University, USA;New York University, USA",10.1109/visual.1999.809870,"Subdivision surfaces, Nonmanifold surfaces, Geometric modeling",,3.0,17.0,88.0,,,manifold control meshes;subdivision scheme uses;surfaces triangle;piecewise;common,0.6513;0.4492;0.3928;0.2378;-0.0296,"[np.int64(-1), np.int64(-1), np.int64(-1), -1, -1]",73;34;77;-1;-1,34;73;77,73,Mesh Representation Techniques
VAST,2015,MobilityGraphs: Visual Analysis of Mass Mobility Dynamics via Spatio-Temporal Graphs and Clustering,10.1109/tvcg.2015.2468111,http://dx.doi.org/10.1109/TVCG.2015.2468111,11.0,20.0,J,"Learning more about people mobility is an important task for official decision makers and urban planners. Mobility data sets characterize the variation of the presence of people in different places over time as well as movements (or flows) of people between the places. The analysis of mobility data is challenging due to the need to analyze and compare spatial situations (i.e., presence and flows of people at certain time moments) and to gain an understanding of the spatio-temporal changes (variations of situations over time). Traditional flow visualizations usually fail due to massive clutter. Modern approaches offer limited support for investigating the complex variation of the movements over longer time periods. We propose a visual analytics methodology that solves these issues by combined spatial and temporal simplifications. We have developed a graph-based method, called MobilityGraphs, which reveals movement patterns that were occluded in flow maps. Our method enables the visual representation of the spatio-temporal variation of movements for long time series of spatial situations originally containing a large number of intersecting flows. The interactive system supports data exploration from various perspectives and at various levels of detail by interactive setting of clustering parameters. The feasibility our approach was tested on aggregated mobility data derived from a set of geolocated Twitter posts within the Greater London city area and mobile phone call data records in Abidjan, Ivory Coast. We could show that MobilityGraphs support the identification of regular daily and weekly movement patterns of resident population.",Tatiana von Landesberger;Felix Brodkorb;Philipp Roskosch;Natalia V. Andrienko;Gennady L. Andrienko;Andreas Kerren,Tatiana von Landesberger;Felix Brodkorb;Philipp Roskosch;Natalia Andrienko;Gennady Andrienko;Andreas Kerren,"Technical University of Darmstadt, Germany;Technical University of Darmstadt, Germany;Technical University of Darmstadt, Germany;Fraunhofer IAIS, City University, London, UK;Fraunhofer IAIS, City University, London, UK;Fraunhofer IAIS, City University, London, UK",10.1109/tvcg.2011.202;10.1109/tvcg.2011.226;10.1109/tvcg.2011.233;10.1109/infvis.2004.18;10.1109/tvcg.2009.143;10.1109/tvcg.2014.2346271;10.1109/tvcg.2008.125;10.1109/tvcg.2014.2346441;10.1109/infvis.1999.801851;10.1109/vast.2012.6400553;10.1109/vast.2009.5333893;10.1109/infvis.2005.1532150;10.1109/tvcg.2011.202,"Visual analytics, movement data, networks, graphs, temporal aggregation, spatial aggregation, flows, clustering",211.0,159.0,56.0,4670.0,,,analysis mobility data;traditional flow visualizations;simplifications;method enables visual;different,0.6385;0.4922;0.1218;0.0676;0.0297,"[np.int64(-1), np.int64(-1), -1, -1, -1]",31;66;-1;-1;-1,31;66,31,Trajectory Data Analysis
InfoVis,2001,"2D vs 3D, implications on spatial memory",10.1109/infvis.2001.963291,http://dx.doi.org/10.1109/INFVIS.2001.963291,139.0,145.0,C,"Since the introduction of graphical user interfaces (GUI) and two-dimensional (2D) displays, the concept of space has entered the information technology (IT) domain. Interactions with computers were re-encoded in terms of fidelity to the interactions with real environment and consequently in terms of fitness to cognitive and spatial abilities. A further step in this direction was the creation of three-dimensional (3D) displays which have amplified the fidelity of digital representations. However, there are no systematic results evaluating the extent to which 3D displays better support cognitive spatial abilities. The aim of this research is to empirically investigate spatial memory performance across different instances of 2D and 3D displays. Two experiments were performed. The displays used in the experimental situation represented hierarchical information structures. The results of the test show that the 3D display does improve performances in the designed spatial memory task.",Monica Tavanti;Mats Lind,M. Tavanti;M. Lind,"Department of Information Science, University of Uppsala, Sweden;Department of Information Science, University of Uppsala, Sweden",,,203.0,64.0,11.0,1036.0,,,support cognitive spatial;3d displays experiments;information technology domain;performance different;consequently terms,0.6517;0.5365;0.2360;0.1848;0.0253,"[np.int64(-1), np.int64(-1), -1, -1, -1]",78;18;-1;-1;-1,18;78,78,Cognitive Visual Analysis
VAST,2009,Combining automated analysis and visualization techniques for effective exploration of high-dimensional data,10.1109/vast.2009.5332628,http://dx.doi.org/10.1109/VAST.2009.5332628,59.0,66.0,C,"Visual exploration of multivariate data typically requires projection onto lower-dimensional representations. The number of possible representations grows rapidly with the number of dimensions, and manual exploration quickly becomes ineffective or even unfeasible. This paper proposes automatic analysis methods to extract potentially relevant visual structures from a set of candidate visualizations. Based on features, the visualizations are ranked in accordance with a specified user task. The user is provided with a manageable number of potentially useful candidate visualizations, which can be used as a starting point for interactive data analysis. This can effectively ease the task of finding truly useful visualizations and potentially speed up the data exploration task. In this paper, we present ranking measures for class-based as well as non class-based Scatterplots and Parallel Coordinates visualizations. The proposed analysis methods are evaluated on different datasets.",Andrada Tatu;Georgia Albuquerque;Martin Eisemann;Jörn Schneidewind;Holger Theisel;Marcus A. Magnor;Daniel A. Keim,Andrada Tatu;Georgia Albuquerque;Martin Eisemann;Jorn Schneidewind;Holger Theisel;Marcus Magnork;Daniel Keim,"University of Konstanz, Germany;TU Braunschweig, Germany;TU Braunschweig, Germany;Telefonica o2 Business Intelligence Center, Germany;University of Magdeburg, Germany;Technische Universitat Braunschweig, Braunschweig, Niedersachsen, DE;University of Konstanz, Germany",10.1109/infvis.2005.1532142;10.1109/infvis.1998.729559;10.1109/infvis.2003.1249017;10.1109/visual.1994.346302;10.1109/vast.2006.261423;10.1109/infvis.2005.1532142,,119.0,98.0,25.0,1325.0,,,visual exploration multivariate;class based;number dimensions manual;lower;ineffective unfeasible paper,0.7083;0.1922;0.1920;0.0384;0.0343,"[np.int64(1), -1, -1, -1, -1]",11;-1;-1;-1;-1,11,11,Multivariate Data Visualization
VAST,2014,Visual Analytics for Complex Engineering Systems: Hybrid Visual Steering of Simulation Ensembles,10.1109/tvcg.2014.2346744,http://dx.doi.org/10.1109/TVCG.2014.2346744,1803.0,1812.0,J,"In this paper we propose a novel approach to hybrid visual steering of simulation ensembles. A simulation ensemble is a collection of simulation runs of the same simulation model using different sets of control parameters. Complex engineering systems have very large parameter spaces so a naïve sampling can result in prohibitively large simulation ensembles. Interactive steering of simulation ensembles provides the means to select relevant points in a multi-dimensional parameter space (design of experiment). Interactive steering efficiently reduces the number of simulation runs needed by coupling simulation and visualization and allowing a user to request new simulations on the fly. As system complexity grows, a pure interactive solution is not always sufficient. The new approach of hybrid steering combines interactive visual steering with automatic optimization. Hybrid steering allows a domain expert to interactively (in a visualization) select data points in an iterative manner, approximate the values in a continuous region of the simulation space (by regression) and automatically find the “best” points in this continuous region based on the specified constraints and objectives (by optimization). We argue that with the full spectrum of optimization options, the steering process can be improved substantially. We describe an integrated system consisting of a simulation, a visualization, and an optimization component. We also describe typical tasks and propose an interactive analysis workflow for complex engineering systems. We demonstrate our approach on a case study from automotive industry, the optimization of a hydraulic circuit in a high pressure common rail Diesel injection system.",Kresimir Matkovic;Denis Gracanin;Rainer Splechtna;Mario Jelovic;Benedikt Stehno;Helwig Hauser;Werner Purgathofer,Kreŝimir Matković;Denis Gračanin;Rainer Splechtna;Mario Jelović;Benedikt Stehno;Helwig Hauser;Werner Purgathofer,"VRVis Research Center, Vienna, Austria;Virginia Tech, Blacksburg, VA, USA;VRVis Research Center, Vienna, Austria;AVL-AST Zagreb, Croatia;VRVis Research Center, Vienna, Austria;University of Bergen, Norway;Vienna University of Technology, Austria",10.1109/tvcg.2010.223;10.1109/tvcg.2012.280;10.1109/tvcg.2008.145;10.1109/tvcg.2009.110;10.1109/tvcg.2010.171;10.1109/vast.2009.5333081;10.1109/vast.2010.5651694;10.1109/tvcg.2010.223,"Interactive Visual Analysis, Integrated Design Environment, Simulation, Visual Steering, Automatic Optimization",31.0,25.0,42.0,946.0,,,simulation visualization optimization;steering automatic;domain expert;pressure common rail;argue spectrum,0.6506;0.2198;0.1953;0.1457;-0.0060,"[np.int64(-1), -1, -1, -1, -1]",83;-1;-1;-1;-1,83,83,Interactive Optimization Visualization
Vis,2023,A Local Iterative Approach for the Extraction of 2D Manifolds from Strongly Curved and Folded Thin-Layer Structures,10.1109/tvcg.2023.3327403,http://dx.doi.org/10.1109/TVCG.2023.3327403,1260.0,1270.0,J,"Ridge surfaces represent important features for the analysis of 3-dimensional (3D) datasets in diverse applications and are often derived from varying underlying data including flow fields, geological fault data, and point data, but they can also be present in the original scalar images acquired using a plethora of imaging techniques. Our work is motivated by the analysis of image data acquired using micro-computed tomography ($\mu\text{CT}$) of ancient, rolled and folded thin-layer structures such as papyrus, parchment, and paper as well as silver and lead sheets. From these documents we know that they are 2-dimensional (2D) in nature. Hence, we are particularly interested in reconstructing 2D manifolds that approximate the document's structure. The image data from which we want to reconstruct the 2D manifolds are often very noisy and represent folded, densely-layered structures with many artifacts, such as ruptures or layer splitting and merging. Previous ridge-surface extraction methods fail to extract the desired 2D manifold for such challenging data. We have therefore developed a novel method to extract 2D manifolds. The proposed method uses a local fast marching scheme in combination with a separation of the region covered by fast marching into two sub-regions. The 2D manifold of interest is then extracted as the surface separating the two sub-regions. The local scheme can be applied for both automatic propagation as well as interactive analysis. We demonstrate the applicability and robustness of our method on both artificial data as well as real-world data including folded silver and papyrus sheets.",Nicolas Klenert;Verena Lepper;Daniel Baum,Nicolas Klenert;Verena Lepper;Daniel Baum,"Zuse Institute Berlin, Germany;Agyptisches Museum und Papyrussammlung, Germany;Zuse Institute Berlin, Germany",0.1109/tvcg.2009.177;10.1109/tvcg.2007.70554,"Ridge surface,crease surface,2D manifold extraction,fast marching,virtual unfolding,historical documents",,0.0,42.0,226.0,,,ridge surface extraction;ruptures layer;fast marching sub;ancient;sheets documents,0.6400;0.2615;0.1886;0.1355;0.1352,"[np.int64(-1), -1, -1, -1, -1]",58;-1;-1;-1;-1,58,58,Isosurface Extraction
Vis,2002,Computing singularities of 3D vector fields with geometric algebra,10.1109/visual.2002.1183786,http://dx.doi.org/10.1109/VISUAL.2002.1183786,283.0,289.0,C,"Critical points of a vector field are key to their characterization. Their positions as well as their indexes are crucial for understanding vector fields. Considerable work exists in 2D, but less is available for 3D or higher dimensions. Geometric algebra is a derivative of Clifford algebra that not only enables a succinct definition of the index of a critical point in higher dimension; it also provides insight and computational pathways for calculating the index. We describe the problems in terms of geometric algebra and present an octree based solution using the algebra for finding critical points and their index in a 3D vector field.",Stephen Mann;Alyn P. Rockwood,S. Mann;A. Rockwood,"School of Computer Science, University of Waterloo, Waterloo, ONT, Canada;Department of Math and Computer Science, Colorado Schml of Mines, Golden, CO, USA",10.1109/visual.1997.663858;10.1109/visual.1997.663871,"Geometric Algebra, 3D Vector Fields, Singularities",59.0,18.0,20.0,232.0,,,vector fields;algebra present octree;definition index critical;clifford;insight computational pathways,0.5804;0.4378;0.2139;0.1653;0.1156,"[np.int64(-1), np.int64(-1), -1, -1, -1]",35;77;-1;-1;-1,35;77,35,Vector and Tensor Visualization
VAST,2010,Interactive visual analysis of multiobjective optimizations,10.1109/vast.2010.5651694,http://dx.doi.org/10.1109/VAST.2010.5651694,215.0,216.0,M,"Optimization problems are typically addressed by purely automatic approaches. For multi-objective problems, however, a single best solution often does not exist. In this case, it is necessary to analyze trade-offs between many conflicting goals within a given application context. This poster describes an approach that tightly integrates automatic algorithms for multi-objective optimization and interactive multivariate visualizations. Ad-hoc selections support a flexible definition of input data for subsequent algorithms. These algorithms in turn represent their result as derived data attributes that can be assigned to visualizations or be used as a basis for further selections (e.g., to constrain the result set). This enables a guided search that still involves the knowledge of domain experts. We describe our approach in the context of multi-run simulation data from the application domain of car engine design.",Wolfgang Berger;Harald Piringer,Wolfgang Berger;Harald Piringer,"VRVis Research Center, Vienna, Austria;VRVis Research Center, Vienna, Austria",0.1109/vast.2009.5333081;10.1109/tvcg.2009.110,,8.0,9.0,7.0,309.0,,,objective optimization interactive;multivariate visualizations;car engine;offs conflicting;represent,0.5803;0.4629;0.2608;0.0555;0.0079,"[np.int64(-1), np.int64(1), -1, -1, -1]",83;11;-1;-1;-1,11;83,83,Interactive Optimization Visualization
Vis,1999,Time-critical Multiresolution Scene Rendering,10.1109/visual.1999.809876,http://doi.ieeecomputersociety.org/10.1109/VISUAL.1999.809876,123.0,130.0,C,"We describe a framework for time-critical rendering of graphics scenes composed of a large number of objects having complex geometric descriptions. Our technique relies upon a scene description in which objects are represented as multiresolution meshes. We perform a constrained optimization at each frame to choose the resolution of each potentially visible object that generates the best quality image while meeting timing constraints. The technique provides smooth level-of-detail control and aims at guaranteeing a uniform, bounded frame rate even for widely changing viewing conditions. The optimization algorithm is independent from the particular data structure used to represent multiresolution meshes. The only requirements are the ability to represent a mesh with an arbitrary number of triangles and to traverse a mesh structure at an arbitrary resolution in a short predictable time. A data structure satisfying these criteria is described and experimental results are discussed.",Enrico Gobbetti;Eric Bouvier,E. Gobbetti;E. Bouvier,"Center for Adv. Studies, Cagliari, Italy;Center for Adv. Studies, Cagliari, Italy",10.1109/visual.1996.568126;10.1109/visual.1998.745282,"multiresolution modeling,level of detail,adaptive rendering, time-critical graphics",77.0,15.0,0.0,26.0,,,represented multiresolution meshes;meeting timing constraints;visible object generates;traverse;large number,0.6247;0.2184;0.2034;0.1737;0.1172,"[np.int64(-1), -1, -1, -1, -1]",73;-1;-1;-1;-1,73,73,Mesh Representation Techniques
VAST,2006,Visual Analysis of Conflicting Opinions,10.1109/vast.2006.261431,http://dx.doi.org/10.1109/VAST.2006.261431,59.0,66.0,C,"Understanding the nature and dynamics of conflicting opinions is a profound and challenging issue. In this paper we address several aspects of the issue through a study of more than 3,000 Amazon customer reviews of the controversial bestseller The Da Vinci Code, including 1,738 positive and 918 negative reviews. The study is motivated by critical questions such as: what are the differences between positive and negative reviews? What is the origin of a particular opinion? How do these opinions change over time? To what extent can differentiating features be identified from unstructured text? How accurately can these features predict the category of a review? We first analyze terminology variations in these reviews in terms of syntactic, semantic, and statistic associations identified by TermWatch and use term variation patterns to depict underlying topics. We then select the most predictive terms based on log likelihood tests and demonstrate that this small set of terms classifies over 70% of the conflicting reviews correctly. This feature selection process reduces the dimensionality of the feature space from more than 20,000 dimensions to a couple of hundreds. We utilize automatically generated decision trees to facilitate the understanding of conflicting opinions in terms of these highly predictive terms. This study also uses a number of visualization and modeling tools to identify not only what positive and negative reviews have in common, but also they differ and evolve over time",Chaomei Chen;Fidelia Ibekwe-Sanjuan;Eric SanJuan;Chris E. Weaver,Chaomei Chen;Fidelia Ibekwe-SanJuan;Eric SanJuan;Chris Weaver,"Drexel University, USA;Universite de Lyon, France;Universite d''Avignon, France;Pennsylvania State University, USA",10.1109/infvis.2002.1173155,"Visual Analytics, Intelligence analysis, Problemsolving environments, Visual Knowledge Discovery",105.0,53.0,21.0,732.0,,,customer reviews controversial;associations identified termwatch;vinci code including;number visualization;change time,0.5519;0.3176;0.2654;0.1870;0.0368,"[np.int64(-1), -1, -1, -1, -1]",42;-1;-1;-1;-1,42,42,Consumer Trust Dynamics
VAST,2018,ForVizor: Visualizing Spatio-Temporal Team Formations in Soccer,10.1109/tvcg.2018.2865041,http://dx.doi.org/10.1109/TVCG.2018.2865041,65.0,75.0,J,"Regarded as a high-level tactic in soccer, a team formation assigns players different tasks and indicates their active regions on the pitch, thereby influencing the team performance significantly. Analysis of formations in soccer has become particularly indispensable for soccer analysts. However, formations of a team are intrinsically time-varying and contain inherent spatial information. The spatio-temporal nature of formations and other characteristics of soccer data, such as multivariate features, make analysis of formations in soccer a challenging problem. In this study, we closely worked with domain experts to characterize domain problems of formation analysis in soccer and formulated several design goals. We design a novel spatio-temporal visual representation of changes in team formation, allowing analysts to visually analyze the evolution of formations and track the spatial flow of players within formations over time. Based on the new design, we further design and develop ForVizor, a visual analytics system, which empowers users to track the spatio-temporal changes in formation and understand how and why such changes occur. With ForVizor, domain experts conduct formation analysis of two games. Analysis results with insights and useful feedback are summarized in two case studies.",Yingcai Wu;Xiao Xie;Jiachen Wang;Dazhen Deng;Hongye Liang;Hui Zhang 0051;Shoubin Cheng;Wei Chen 0001,Yingcai Wu;Xiao Xie;Jiachen Wang;Dazhen Deng;Hongye Liang;Hui Zhang;Shoubin Cheng;Wei Chen,"State Key Lab of CAD&CG, Zhejiang University;State Key Lab of CAD&CG, Zhejiang University;State Key Lab of CAD&CG, Zhejiang University;State Key Lab of CAD&CG, Zhejiang University;State Key Lab of CAD&CG, Zhejiang University;Department of Sport Science, Zhejiang University;Department of Sport Science, Zhejiang University;State Key Lab of CAD&CG, Zhejiang University",10.1109/vast.2008.4677356;10.1109/tvcg.2011.239;10.1109/tvcg.2014.2346433;10.1109/vast.2014.7042477;10.1109/tvcg.2018.2865018;10.1109/tvcg.2016.2598831;10.1109/tvcg.2013.192;10.1109/tvcg.2014.2346445;10.1109/tvcg.2017.2745181;10.1109/tvcg.2017.2744218;10.1109/vast.2008.4677356,"Soccer data,formation analysis,spatio-temporal visualization",79.0,82.0,48.0,2778.0,,,formation analysis soccer;temporal visual representation;analytics empowers users;forvizor domain;regions pitch influencing,0.6550;0.3629;0.3330;0.1266;0.1250,"[np.int64(-1), np.int64(-1), -1, -1, -1]",-1;26;-1;-1;-1,26,26,Temporal Animation Techniques
VAST,2016,Visualizing Dimension Coverage to Support Exploratory Analysis,10.1109/tvcg.2016.2598466,http://dx.doi.org/10.1109/TVCG.2016.2598466,21.0,30.0,J,"Data analysis involves constantly formulating and testing new hypotheses and questions about data. When dealing with a new dataset, especially one with many dimensions, it can be cumbersome for the analyst to clearly remember which aspects of the data have been investigated (i.e., visually examined for patterns, trends, outliers etc.) and which combinations have not. Yet this information is critical to help the analyst formulate new questions that they have not already answered. We observe that for tabular data, questions are typically comprised of varying combinations of data dimensions (e.g., what are the trends of Sales and Profit for different Regions?). We propose representing analysis history from the angle of dimension coverage (i.e., which data dimensions have been investigated and in which combinations). We use scented widgets to incorporate dimension coverage of the analysts' past work into interaction widgets of a visualization tool. We demonstrate how this approach can assist analysts with the question formation process. Our approach extends the concept of scented widgets to reveal aspects of one's own analysis history, and offers a different perspective on one's past work than typical visualization history tools. Results of our empirical study showed that participants with access to embedded dimension coverage information relied on this information when formulating questions, asked more questions about the data, generated more top-level findings, and showed greater breadth of their analysis without sacrificing depth.",Ali Sarvghad;Melanie Tory;Narges Mahyar,Ali Sarvghad;Melanie Tory;Narges Mahyar,University of Victoria;Tableau Research;University of British Columbia,10.1109/tvcg.2015.2467191;10.1109/tvcg.2006.120;10.1109/infvis.1999.801862;10.1109/infvis.2000.885086;10.1109/visual.2005.1532788;10.1109/tvcg.2014.2346452;10.1109/vast.2009.5333020;10.1109/infvis.2001.963289;10.1109/tvcg.2008.137;10.1109/tvcg.2015.2467611;10.1109/visual.1993.398857;10.1109/tvcg.2007.70589;10.1109/tvcg.2013.167;10.1109/tvcg.2008.109;10.1109/tvcg.2015.2467191,Dimension coverage;Tabular data;History;Empirical laboratory study;Exploratory data analysis;Scented widgets,35.0,27.0,33.0,1201.0,,,visualization history tools;dimension coverage analysts;formulating questions asked;extends concept scented;typical,0.5611;0.3797;0.3108;0.2549;0.0647,"[np.int64(1), np.int64(-1), -1, -1, -1]",52;22;-1;-1;-1,22;52,52,Visualization Tools
SciVis,2018,Dynamic Volume Lines: Visual Comparison of 3D Volumes through Space-filling Curves,10.1109/tvcg.2018.2864510,http://dx.doi.org/10.1109/TVCG.2018.2864510,1040.0,1049.0,J,"The comparison of many members of an ensemble is difficult, tedious, and error-prone, which is aggravated by often just subtle differences. In this paper, we introduce Dynamic Volume Lines for the interactive visual analysis and comparison of sets of 3D volumes. Each volume is linearized along a Hilbert space-filling curve into a 1D Hilbert line plot, which depicts the intensities over the Hilbert indices. We present a nonlinear scaling of these 1D Hilbert line plots based on the intensity variations in the ensemble of 3D volumes, which enables a more effective use of the available screen space. The nonlinear scaling builds the basis for our interactive visualization techniques. An interactive histogram heatmap of the intensity frequencies serves as overview visualization. When zooming in, the frequencies are replaced by detailed 1D Hilbert line plots and optional functional boxplots. To focus on important regions of the volume ensemble, nonlinear scaling is incorporated into the plots. An interactive scaling widget depicts the local ensemble variations. Our brushing and linking interface reveals, for example, regions with a high ensemble variation by showing the affected voxels in a 3D spatial view. We show the applicability of our concepts using two case studies on ensembles of 3D volumes resulting from tomographic reconstruction. In the first case study, we evaluate an artificial specimen from simulated industrial 3D X-ray computed tomography (XCT). In the second case study, a real-world XCT foam specimen is investigated. Our results show that Dynamic Volume Lines can identify regions with high local intensity variations, allowing the user to draw conclusions, for example, about the choice of reconstruction parameters. Furthermore, it is possible to detect ring artifacts in reconstructions volumes.",Johannes Weissenbock;Bernhard Fröhler;M. Eduard Gröller;Johann Kastner;Christoph Heinzl,Johannes Weissenböck;Bernhard Fröhler;Eduard Gröller;Johann Kastner;Christoph Heinzl,"University of Applied Sciences Upper Austria, Wels, Austria;University of Applied Sciences Upper Austria, Wels, Austria;Technische Universitat Wien, Wien, Wien, AT;University of Applied Sciences Upper Austria, Wels, Austria;University of Applied Sciences Upper Austria, Wels, Austria",10.1109/tvcg.2014.2346448;10.1109/vast.2015.7347634;10.1109/tvcg.2009.155;10.1109/tvcg.2014.2346455;10.1109/visual.2005.1532847;10.1109/tvcg.2013.213;10.1109/vast.2014.7042491;10.1109/tvcg.2014.2346321;10.1109/vast.2016.7883516;10.1109/tvcg.2013.143;10.1109/tvcg.2014.2346448,"Ensemble data,comparative visualization,visual analysis,Hilbert curve,nonlinear scaling,X-ray computed tomography",29.0,20.0,43.0,955.0,,,volume lines interactive;linearized hilbert space;scaling builds;just subtle differences;choice reconstruction,0.6298;0.1895;0.1475;0.0962;0.0952,"[np.int64(-1), -1, -1, -1, -1]",70;-1;-1;-1;-1,70,70,Interactive Volume Rendering
VAST,2013,Visual Analysis of Topic Competition on Social Media,10.1109/tvcg.2013.221,http://dx.doi.org/10.1109/TVCG.2013.221,2012.0,2021.0,J,"How do various topics compete for public attention when they are spreading on social media? What roles do opinion leaders play in the rise and fall of competitiveness of various topics? In this study, we propose an expanded topic competition model to characterize the competition for public attention on multiple topics promoted by various opinion leaders on social media. To allow an intuitive understanding of the estimated measures, we present a timeline visualization through a metaphoric interpretation of the results. The visual design features both topical and social aspects of the information diffusion process by compositing ThemeRiver with storyline style visualization. ThemeRiver shows the increase and decrease of competitiveness of each topic. Opinion leaders are drawn as threads that converge or diverge with regard to their roles in influencing the public agenda change over time. To validate the effectiveness of the visual analysis techniques, we report the insights gained on two collections of Tweets: the 2012 United States presidential election and the Occupy Wall Street movement.",Panpan Xu;Yingcai Wu;Enxun Wei;Tai-Quan Peng;Shixia Liu;Jonathan J. H. Zhu;Huamin Qu,Panpan Xu;Yingcai Wu;Enxun Wei;Tai-Quan Peng;Shixia Liu;Jonathan J.H. Zhu;Huamin Qu,"Hong Kong University of Science and Technology, Hong Kong, China;Microsoft Research, Asia, Russia;Shanghai Jiao Tong University, China;Nanyang Technological University, Singapore;Microsoft Research, Asia, Russia;City University of Hong Kong, Hong Kong, China;Hong Kong University of Science and Technology, Hong Kong, China",10.1109/tvcg.2008.166;10.1109/tvcg.2011.239;10.1109/tvcg.2012.253;10.1109/tvcg.2012.225;10.1109/vast.2009.5333437;10.1109/tvcg.2010.194;10.1109/tvcg.2012.291;10.1109/vast.2010.5652931;10.1109/tvcg.2013.196;10.1109/infvis.2001.963273;10.1109/tvcg.2012.212;10.1109/vast.2010.5652922;10.1109/tvcg.2010.129;10.1109/infvis.1999.801851;10.1109/tvcg.2008.166,"Social media visuaization, topic competition, information diffusion, information propagation, agenda-setting",153.0,90.0,50.0,4604.0,,,topic competition model;visualization metaphoric interpretation;wall street movement;drawn threads converge;united states presidential,0.5876;0.3672;0.3335;0.2520;0.1711,"[np.int64(-1), np.int64(1), -1, -1, -1]",79;10;-1;-1;-1,10;79,79,Social Media Analysis
Vis,1997,Building and traversing a surface at variable resolution,10.1109/visual.1997.663865,http://dx.doi.org/10.1109/VISUAL.1997.663865,103.0,110.0,C,"The authors consider the multi-triangulation, a general model for representing surfaces at variable resolution based on triangle meshes. They analyse characteristics of the model that make it effective for supporting basic operations such as extraction of a surface approximation, and point location. An interruptible algorithm for extracting a representation at a resolution variable over the surface is presented. Different heuristics for building the model are considered and compared. Results on both the construction and the extraction algorithm are presented.",Leila De Floriani;Paola Magillo;Enrico Puppo,L. De Fioriani;P. Magillo;E. Puppo,"Dipt. di Inf. e Sci. dell'Inf., Genoa Univ., Italy;Dipartimento di Informatica e Scienze dellInformazione, Universita di Genova, Genoa, Italy;Consiglio Nazionale delle Ricerche, Istituto per la Matematica Applicata del CNR, Genoa, Italy",,,163.0,26.0,21.0,79.0,,,based triangle meshes;representation resolution variable;location interruptible;building;compared,0.6977;0.2590;0.1870;0.0971;0.0333,"[np.int64(-1), -1, -1, -1, -1]",73;-1;-1;-1;-1,73,73,Mesh Representation Techniques
SciVis,2015,Real-time Uncertainty Visualization for B-Mode Ultrasound,10.1109/scivis.2015.7429489,http://dx.doi.org/10.1109/SciVis.2015.7429489,33.0,40.0,C,"B-mode ultrasound is a very well established imaging modality and is widely used in many of today's clinical routines. However, acquiring good images and interpreting them correctly is a challenging task due to the complex ultrasound image formation process depending on a large number of parameters. To facilitate ultrasound acquisitions, we introduce a novel framework for real-time uncertainty visualization in B-mode images. We compute real-time per-pixel ultrasound Confidence Maps, which we fuse with the original ultrasound image in order to provide the user with an interactive feedback on the quality and credibility of the image. In addition to a standard color overlay mode, primarily intended for educational purposes, we propose two perceptional visualization schemes to be used in clinical practice. Our mapping of uncertainty to chroma uses the perceptionally uniform L*a*b* color space to ensure that the perceived brightness of B-mode ultrasound remains the same. The alternative mapping of uncertainty to fuzziness keeps the B-mode image in its original grayscale domain and locally blurs or sharpens the image based on the uncertainty distribution. An elaborate evaluation of our system and user studies on both medical students and expert sonographers demonstrate the usefulness of our proposed technique. In particular for ultrasound novices, such as medical students, our technique yields powerful visual cues to evaluate the image quality and thereby learn the ultrasound image formation process. Furthermore, seeing the distribution of uncertainty adjust to the transducer positioning in real-time, provides also expert clinicians with a strong visual feedback on their actions. This helps them to optimize the acoustic window and can improve the general clinical value of ultrasound.",Christian Schulte zu Berge;Denis Declara;Christoph Hennersperger;Maximilian Baust;Nassir Navab,Christian Schulte Zu Berge;Denis Declara;Christoph Hennersperger;Maximilian Baust;Nassir Navab,;;;;,10.1109/visual.2001.964550;10.1109/tvcg.2006.134;10.1109/tvcg.2007.70518;10.1109/tvcg.2012.279;10.1109/tvcg.2009.114;10.1109/visual.2001.964550,"Ultrasound, Uncertainty Visualization, Confidence Maps, Real-time",2.0,3.0,23.0,436.0,,,ultrasound confidence maps;color overlay mode;blurs sharpens image;improve general clinical;task,0.6866;0.3184;0.2482;0.1806;0.0559,"[np.int64(-1), -1, -1, -1, -1]",37;-1;-1;-1;-1,37,37,Uncertainty Visualization
InfoVis,2013,Selecting the Aspect Ratio of a Scatter Plot Based on Its Delaunay Triangulation,10.1109/tvcg.2013.187,http://dx.doi.org/10.1109/TVCG.2013.187,2326.0,2335.0,J,"Scatter plots are diagrams that visualize two-dimensional data as sets of points in the plane. They allow users to detect correlations and clusters in the data. Whether or not a user can accomplish these tasks highly depends on the aspect ratio selected for the plot, i.e., the ratio between the horizontal and the vertical extent of the diagram. We argue that an aspect ratio is good if the Delaunay triangulation of the scatter plot at this aspect ratio has some nice geometric property, e.g., a large minimum angle or a small total edge length. More precisely, we consider the following optimization problem. Given a set Q of points in the plane, find a scale factor s such that scaling the x-coordinates of the points in Q by s and the y-coordinates by 1=s yields a point set P(s) that optimizes a property of the Delaunay triangulation of P(s), over all choices of s. We present an algorithm that solves this problem efficiently and demonstrate its usefulness on real-world instances. Moreover, we discuss an empirical test in which we asked 64 participants to choose the aspect ratios of 18 scatter plots. We tested six different quality measures that our algorithm can optimize. In conclusion, minimizing the total edge length and minimizing what we call the 'uncompactness' of the triangles of the Delaunay triangulation yielded the aspect ratios that were most similar to those chosen by the participants in the test.",Martin Fink 0001;Jan-Henrik Haunert;Joachim Spoerhase;Alexander Wolff 0001,Martin Fink;Jan-Henrik Haunert;Joachim Spoerhase;Alexander Wolff,"Lehrstuhl I, Institut für Informatik, Universität Würzburg, Germany;Lehrstuhl I, Institut für Informatik, Universität Würzburg, Germany;Lehrstuhl I, Institut für Informatik, Universität Würzburg, Germany;Lehrstuhl I, Institut für Informatik, Universität Würzburg, Germany",10.1109/tvcg.2006.163;10.1109/tvcg.2012.196;10.1109/tvcg.2011.167;10.1109/tvcg.2006.163,"Scatter plot, aspect ratio, Delaunay triangulation",35.0,24.0,28.0,727.0,,,delaunay triangulation scatter;choose aspect ratios;clusters data;efficiently demonstrate usefulness;allow,0.6072;0.3702;0.3686;0.1983;-0.0029,"[np.int64(-1), np.int64(-1), np.int64(-1), -1, -1]",59;-1;38;-1;-1,38;59,59,Triangulation Algorithms
VAST,2012,The spatiotemporal multivariate hypercube for discovery of patterns in event data,10.1109/vast.2012.6400536,http://dx.doi.org/10.1109/VAST.2012.6400536,235.0,236.0,M,"Event data can hold valuable decision making information, yet detecting interesting patterns in this type of data is not an easy task because the data is usually rich and contains spatial, temporal as well as multivariate dimensions. Research into visual analytics tools to support the discovery of patterns in event data often focuses on the spatiotemporal or spatiomultivariate dimension of the data only. Few research efforts focus on all three dimensions in one framework. An integral view on all three dimensions is, however, required to unlock the full potential of event datasets. In this poster, we present an event visualization, transition, and interaction framework that enables an integral view on all dimensions of spatiotemporal multivariate event data. The framework is built around the notion that the event data space can be considered a spatiotemporal multivariate hypercube. Results of a case study we performed suggest that a visual analytics tool based on the proposed framework is indeed capable to support users in the discovery of multidimensional spatiotemporal multivariate patterns in event data.",Fred Olislagers;Marcel Worring,Fred Olislagers;Marcel Worring,"Intelligent Systems Lab Amsterdam, University of Amsterdam, The Netherlands;Intelligent Systems Lab Amsterdam, University of Amsterdam, The Netherlands",,,3.0,1.0,3.0,206.0,,,event visualization;spatiomultivariate dimension data;framework built notion;study performed suggest;unlock,0.7077;0.4763;0.0467;0.0456;-0.0202,"[np.int64(1), np.int64(-1), -1, -1, -1]",85;29;-1;-1;-1,29;85,85,Dynamic Data Visualization
InfoVis,2010,Declarative Language Design for Interactive Visualization,10.1109/tvcg.2010.144,http://dx.doi.org/10.1109/TVCG.2010.144,1149.0,1156.0,J,"We investigate the design of declarative, domain-specific languages for constructing interactive visualizations. By separating specification from execution, declarative languages can simplify development, enable unobtrusive optimization, and support retargeting across platforms. We describe the design of the Protovis specification language and its implementation within an object-oriented, statically-typed programming language (Java). We demonstrate how to support rich visualizations without requiring a toolkit-specific data model and extend Protovis to enable declarative specification of animated transitions. To support cross-platform deployment, we introduce rendering and event-handling infrastructures decoupled from the runtime platform, letting designers retarget visualization specifications (e.g., from desktop to mobile phone) with reduced effort. We also explore optimizations such as runtime compilation of visualization specifications, parallelized execution, and hardware-accelerated rendering. We present benchmark studies measuring the performance gains provided by these optimizations and compare performance to existing Java-based visualization tools, demonstrating scalability improvements exceeding an order of magnitude.",Jeffrey Heer;Michael Bostock,Jeffrey Heer;Michael Bostock,"Computer Science Department, University of Stanford, Stanford, CA, USA;Computer Science Department, University of Stanford, Stanford, CA, USA",10.1109/tvcg.2009.174;10.1109/tvcg.2006.178;10.1109/infvis.2004.12;10.1109/tvcg.2007.70577;10.1109/tvcg.2009.128;10.1109/visual.1992.235219;10.1109/tvcg.2009.191;10.1109/tvcg.2009.110;10.1109/tvcg.2007.70539;10.1109/infvis.2004.64;10.1109/infvis.2000.885086;10.1109/tvcg.2009.174,"Information visualization, user interfaces, toolkits, domain specific languages, declarative languages, optimization",151.0,82.0,25.0,1485.0,HM,,visualization specifications;animated transitions;languages simplify development;decoupled runtime;retarget,0.6372;0.4034;0.3889;0.2261;0.0498,"[np.int64(1), np.int64(-1), np.int64(-1), -1, -1]",68;26;34;-1;-1,26;34;68,68,Visualization Techniques Comparison
Vis,2009,Interactive Visual Analysis of Complex Scientific Data as Families of Data Surfaces,10.1109/tvcg.2009.155,http://dx.doi.org/10.1109/TVCG.2009.155,1351.0,1358.0,J,"The widespread use of computational simulation in science and engineering provides challenging research opportunities. Multiple independent variables are considered and large and complex data are computed, especially in the case of multi-run simulation. Classical visualization techniques deal well with 2D or 3D data and also with time-dependent data. Additional independent dimensions, however, provide interesting new challenges. We present an advanced visual analysis approach that enables a thorough investigation of families of data surfaces, i.e., datasets, with respect to pairs of independent dimensions. While it is almost trivial to visualize one such data surface, the visual exploration and analysis of many such data surfaces is a grand challenge, stressing the users' perception and cognition. We propose an approach that integrates projections and aggregations of the data surfaces at different levels (one scalar aggregate per surface, a 1D profile per surface, or the surface as such). We demonstrate the necessity for a flexible visual analysis system that integrates many different (linked) views for making sense of this highly complex data. To demonstrate its usefulness, we exemplify our approach in the context of a meteorological multi-run simulation data case and in the context of the engineering domain, where our collaborators are working with the simulation of elastohydrodynamic (EHD) lubrication bearing in the automotive industry.",Kresimir Matkovic;Denis Gracanin;Borislav Klarin;Helwig Hauser,Kresimir Matkovic;Denis Gracanin;Borislav Klarin;Helwig Hauser,"VRVis Research Center Vienna, Austria;Virginia Technology, USA;AVL AST, Zagreb, Croatia;University of Bergen, Norway",10.1109/visual.1997.663867;10.1109/tvcg.2008.145;10.1109/infvis.2001.963273;10.1109/tvcg.2006.170;10.1109/visual.1997.663867,"Interactive visual analysis, family of surfaces, coordinated multiple views, multidimensional multivariate data",60.0,34.0,23.0,784.0,,,visualize data surface;lubrication bearing automotive;multi run simulation;engineering provides challenging;especially,0.6697;0.2883;0.2655;0.2253;0.0169,"[np.int64(1), -1, -1, -1, -1]",67;-1;-1;-1;-1,67,67,Data Visualization Techniques
InfoVis,2008,Effectiveness of Animation in Trend Visualization,10.1109/tvcg.2008.125,http://dx.doi.org/10.1109/TVCG.2008.125,1325.0,1332.0,J,"Animation has been used to show trends in multi-dimensional data. This technique has recently gained new prominence for presentations, most notably with Gapminder Trendalyzer. In Trendalyzer, animation together with interesting data and an engaging presenter helps the audience understand the results of an analysis of the data. It is less clear whether trend animation is effective for analysis. This paper proposes two alternative trend visualizations that use static depictions of trends: one which shows traces of all trends overlaid simultaneously in one display and a second that uses a small multiples display to show the trend traces side-by-side. The paper evaluates the three visualizations for both analysis and presentation. Results indicate that trend animation can be challenging to use even for presentations; while it is the fastest technique for presentation and participants find it enjoyable and exciting, it does lead to many participant errors. Animation is the least effective form for analysis; both static depictions of trends are significantly faster than animation, and the small multiples display is more accurate.",George G. Robertson;Roland Fernandez;Danyel Fisher;Bongshin Lee;John T. Stasko,George Robertson;Roland Fernandez;Danyel Fisher;Bongshin Lee;John Stasko,Microsoft Research;Microsoft Research;Microsoft Research;Microsoft Research;Georgia Institute of Technology,10.1109/infvis.1999.801854;10.1109/tvcg.2007.70539,"Information visualization, animation, trends, design, experiment",480.0,259.0,21.0,4273.0,TT,,trend visualizations;faster animation small;overlaid simultaneously display;presenter helps audience;paper proposes alternative,0.7835;0.3073;0.2422;0.1804;0.0312,"[np.int64(1), -1, -1, -1, -1]",6;-1;-1;-1;-1,6,6,Dynamic Data Visualization
Vis,2005,Understanding visualization through spatial ability differences,10.1109/visual.2005.1532836,http://dx.doi.org/10.1109/VISUAL.2005.1532836,511.0,518.0,C,"Little is known about the cognitive abilities which influence the comprehension of scientific and information visualizations and what properties of the visualization affect comprehension. Our goal in this paper is to understand what makes visualizations difficult. We address this goal by examining the spatial ability differences in a diverse population selected for spatial ability variance. For example, how is, spatial ability related to visualization comprehension? What makes a particular visualization difficult or time intensive for specific groups of subjects? In this paper, we present the results of an experiment designed to answer these questions. Fifty-six subjects were tested on a basic visualization task and given standard paper tests of spatial abilities. An equal number of males and females were recruited in this study in order to increase spatial ability variance. Our results show that high spatial ability is correlated with accuracy on our three-dimensional visualization test, but not with time. High spatial ability subjects also had less difficulty with object complexity and the hidden properties of an object.",Maria C. Velez;Deborah Silver;Marilyn Tremaine,M.C. Velez;D. Silver;M. Tremaine,"Center for Advanced Information Processing Rutgers, State University of New Jersey, USA;Center for Advanced Information Processing Rutgers, State University of New Jersey, USA;Center for Advanced Information Processing Rutgers, State University of New Jersey, USA",10.1109/infvis.2003.1249022;10.1109/visual.2003.1250396,"Gender differences, orthogonal projections, spatial ability, standardized testing",199.0,21.0,36.0,1041.0,,,visualization comprehension makes;ability correlated accuracy;population selected spatial;standard paper tests;difficult time,0.6827;0.2801;0.2793;0.1748;0.0938,"[np.int64(1), -1, -1, -1, -1]",10;-1;-1;-1;-1,10,10,Intuitive Visualization Comprehension
SciVis,2017,Multiscale Visualization and Scale-Adaptive Modification of DNA Nanostructures,10.1109/tvcg.2017.2743981,http://dx.doi.org/10.1109/TVCG.2017.2743981,1014.0,1024.0,J,"We present an approach to represent DNA nanostructures in varying forms of semantic abstraction, describe ways to smoothly transition between them, and thus create a continuous multiscale visualization and interaction space for applications in DNA nanotechnology. This new way of observing, interacting with, and creating DNA nanostructures enables domain experts to approach their work in any of the semantic abstraction levels, supporting both low-level manipulations and high-level visualization and modifications. Our approach allows them to deal with the increasingly complex DNA objects that they are designing, to improve their features, and to add novel functions in a way that no existing single-scale approach offers today. For this purpose we collaborated with DNA nanotechnology experts to design a set of ten semantic scales. These scales take the DNA's chemical and structural behavior into account and depict it from atoms to the targeted architecture with increasing levels of abstraction. To create coherence between the discrete scales, we seamlessly transition between them in a well-defined manner. We use special encodings to allow experts to estimate the nanoscale object's stability. We also add scale-adaptive interactions that facilitate the intuitive modification of complex structures at multiple scales. We demonstrate the applicability of our approach on an experimental use case. Moreover, feedback from our collaborating domain experts confirmed an increased time efficiency and certainty for analysis and modification tasks on complex DNA structures. Our method thus offers exciting new opportunities with promising applications in medicine and biotechnology.",Haichao Miao;Elisa De Llano;Johannes Sorger;Yasaman Ahmadi;Tadija Kekic;Tobias Isenberg 0001;M. Eduard Gröller;Ivan Barisic;Ivan Viola,Haichao Miao;Elisa De Llano;Johannes Sorger;Yasaman Ahmadi;Tadija Kekic;Tobias Isenberg;M. Eduard Gröller;Ivan Barišić;Ivan Viola,"Austrian Institute of Technology and TU Wien, Austria;Austrian Institute of Technology;TU Wien, Austria;Austrian Institute of Technology;Austrian Institute of Technology;Université Paris-Saclay, France;VRVis Research Center, Austria and TU Wien, Austria;Austrian Institute of Technology;Austrian Institute of Technology and TU Wien, Austria",10.1109/visual.2004.103;10.1109/tvcg.2007.70578;10.1109/tvcg.2009.168;10.1109/tvcg.2013.126;10.1109/tvcg.2009.111,"Nano,nanotechnology,assembly,multiscale,abstraction,DNA,origami,scale-adaptive modification",23.0,21.0,54.0,1015.0,,,represent dna nanostructures;work semantic abstraction;scales seamlessly transition;experimental use;single,0.7316;0.2776;0.2300;0.0832;-0.0213,"[np.int64(-1), -1, -1, -1, -1]",27;-1;-1;-1;-1,27,27,Molecular Design Techniques
Vis,2002,A radial focus+context visualization for multi-dimensional functions,10.1109/visual.2002.1183806,http://dx.doi.org/10.1109/VISUAL.2002.1183806,443.0,450.0,C,"The analysis of multidimensional functions is important in many engineering disciplines, and poses a major problem as the number of dimensions increases. Previous visualization approaches focus on representing three or fewer dimensions at a time. This paper presents a new focus+context visualization that provides an integrated overview of an entire multidimensional function space, with uniform treatment of all dimensions. The overview is displayed with respect to a user-controlled polar focal point in the function's parameter space. Function value patterns are viewed along rays that emanate from the focal point in all directions in the parameter space, and represented radially around the focal point in the visualization. Data near the focal point receives proportionally more screen space than distant data. This approach scales smoothly from two dimensions to 10-20, with a 1000 pixel range on each dimension.",Sanjini Jayaraman;Chris North 0001,S. Jayaraman;C. North,"Center for Human Computer Interaction, Department of Computer Science, Virginia Polytechnic Institute and State University, Blacksburg, VA, USA;Center for Human Computer Interaction, Department of Computer Science, Virginia Polytechnic Institute and State University, Blacksburg, VA, USA",10.1109/infvis.1997.636793;10.1109/infvis.1995.528688;10.1109/visual.1993.398859;10.1109/infvis.1998.729558;10.1109/infvis.1997.636793,"visualization, multidimensional functions",27.0,8.0,11.0,146.0,,,focus context visualization;entire multidimensional function;user controlled polar;proportionally;10 20 1000,0.6944;0.3623;0.2096;0.1233;0.0720,"[np.int64(1), np.int64(-1), -1, -1, -1]",85;33;-1;-1;-1,33;85,85,Dynamic Data Visualization
VAST,2017,Supporting Handoff in Asynchronous Collaborative Sensemaking Using Knowledge-Transfer Graphs,10.1109/tvcg.2017.2745279,http://dx.doi.org/10.1109/TVCG.2017.2745279,340.0,350.0,J,"During asynchronous collaborative analysis, handoff of partial findings is challenging because externalizations produced by analysts may not adequately communicate their investigative process. To address this challenge, we developed techniques to automatically capture and help encode tacit aspects of the investigative process based on an analyst's interactions, and streamline explicit authoring of handoff annotations. We designed our techniques to mediate awareness of analysis coverage, support explicit communication of progress and uncertainty with annotation, and implicit communication through playback of investigation histories. To evaluate our techniques, we developed an interactive visual analysis system, KTGraph, that supports an asynchronous investigative document analysis task. We conducted a two-phase user study to characterize a set of handoff strategies and to compare investigative performance with and without our techniques. The results suggest that our techniques promote the use of more effective handoff strategies, help increase an awareness of prior investigative process and insights, as well as improve final investigative outcomes.",Jian Zhao 0010;Michael Glueck;Petra Isenberg;Fanny Chevalier;Azam Khan,Jian Zhao;Michael Glueck;Petra Isenberg;Fanny Chevalier;Azam Khan,FX Palo Alto Laboratory;Autodesk Research;Inria;Inria;Autodesk Research,10.1109/vast.2007.4389009;10.1109/vast.2011.6102447;10.1109/vast.2010.5652932;10.1109/vast.2006.261420;10.1109/vast.2007.4389011;10.1109/tvcg.2008.137;10.1109/tvcg.2007.70568;10.1109/vast.2009.5333020;10.1109/vast.2009.5333878;10.1109/vast.2011.6102438;10.1109/vast.2006.261415;10.1109/tvcg.2014.2346573;10.1109/tvcg.2015.2467551;10.1109/vast.2008.4677358;10.1109/tvcg.2016.2598466;10.1109/vast.2007.4389006;10.1109/tvcg.2007.70577;10.1109/tvcg.2007.70589;10.1109/tvcg.2016.2598543;10.1109/vast.2007.4389009,"Collaboration,sensemaking,handoff,handover,structured externalizations,interactive visual analysis",63.0,41.0,55.0,1372.0,HM,,asynchronous collaborative analysis;investigative process address;handoff strategies help;visual;capture help encode,0.6236;0.4040;0.2333;0.2283;0.1042,"[np.int64(-1), np.int64(-1), -1, -1, -1]",75;23;-1;-1;-1,23;75,75,Collaborative Data Analysis
Vis,2002,Evaluation of a multimodal interface for 3D terrain visualization,10.1109/visual.2002.1183802,http://dx.doi.org/10.1109/VISUAL.2002.1183802,411.0,418.0,C,"Novel speech and/or gesture interfaces are candidates for use in future mobile or ubiquitous applications. This paper describes an evaluation of various interfaces for visual navigation of a whole Earth 3D terrain model. A mouse driven interface, a speech interface, a gesture interface, and a multimodal speech and gesture interface were used to navigate to targets placed at various points on the Earth. This study measured each participant's recall of target identity, order, and location as a measure of cognitive load. Timing information as well as a variety of subjective measures including discomfort and user preference were taken. While the familiar and mature mouse interface scored best by most measures, the speech interface also performed well. The gesture and multimodal interface suffered from weaknesses in the gesture modality. Weaknesses in the speech and multimodal modalities are identified and areas for improvement are discussed.",David M. Krum;Olugbenga Omoteso;William Ribarsky;Thad Starner;Larry F. Hodges,D.M. Krum;O. Omoteso;W. Ribarsky;T. Starner;L.F. Hodges,"College of Computing, Georgia Institute of Technology, GVU Center, Atlanta, GA, USA;College of Computing, Georgia Institute of Technology, GVU Center, Atlanta, GA, USA;College of Computing, Georgia Institute of Technology, GVU Center, Atlanta, GA, USA;College of Computing, Georgia Institute of Technology, GVU Center, Atlanta, GA, USA;College of Computing, Georgia Institute of Technology, GVU Center, Atlanta, GA, USA",,"multimodal interaction, evaluation, navigation, speech recognition, gesture recognition, virtual reality, mobile visualization, GIS",32.0,5.0,15.0,175.0,,,gesture interfaces;used navigate;earth 3d terrain;participant recall target;load timing,0.5964;0.3681;0.3312;0.1355;0.0647,"[np.int64(-1), np.int64(-1), -1, -1, -1]",43;-1;-1;-1;-1,43,43,Augmented Reality Interfaces
InfoVis,2018,Looks Good To Me: Visualizations As Sanity Checks,10.1109/tvcg.2018.2864907,http://dx.doi.org/10.1109/TVCG.2018.2864907,830.0,839.0,J,"Famous examples such as Anscombe's Quartet highlight that one of the core benefits of visualizations is allowing people to discover visual patterns that might otherwise be hidden by summary statistics. This visual inspection is particularly important in exploratory data analysis, where analysts can use visualizations such as histograms and dot plots to identify data quality issues. Yet, these visualizations are driven by parameters such as histogram bin size or mark opacity that have a great deal of impact on the final visual appearance of the chart, but are rarely optimized to make important features visible. In this paper, we show that data flaws have varying impact on the visual features of visualizations, and that the adversarial or merely uncritical setting of design parameters of visualizations can obscure the visual signatures of these flaws. Drawing on the framework of Algebraic Visualization Design, we present the results of a crowdsourced study showing that common visualization types can appear to reasonably summarize distributional data while hiding large and important flaws such as missing data and extraneous modes. We make use of these results to propose additional best practices for visualizations of distributions for data quality tasks.",Michael Correll;Mingwei Li;Gordon L. Kindlmann;Carlos Scheidegger,Michael Correll;Mingwei Li;Gordon Kindlmann;Carlos Scheidegger,Tableau Research;University of Arizona;University of Chicago;University of Arizona,10.1109/tvcg.2016.2598862;10.1109/tvcg.2011.185;10.1109/tvcg.2014.2346298;10.1109/vast.2016.7883519;10.1109/tvcg.2016.2598618;10.1109/tvcg.2014.2346978;10.1109/tvcg.2014.2346979;10.1109/tvcg.2012.230;10.1109/tvcg.2014.2346325;10.1109/tvcg.2016.2599030;10.1109/tvcg.2017.2744359;10.1109/tvcg.2015.2469125;10.1109/tvcg.2010.161;10.1109/tvcg.2015.2467191;10.1109/tvcg.2016.2598862,"Graphical perception,data quality,univariate visualizations",52.0,47.0,51.0,1426.0,,,quality issues visualizations;adversarial merely uncritical;histogram bin;make use results;deal,0.6983;0.2991;0.2753;0.0362;-0.0260,"[np.int64(1), -1, -1, -1, -1]",7;-1;-1;-1;-1,7,7,Uncertainty Visualization
VAST,2014,DIA2: Web-based Cyberinfrastructure for Visual Analysis of Funding Portfolios,10.1109/tvcg.2014.2346747,http://dx.doi.org/10.1109/TVCG.2014.2346747,1823.0,1832.0,J,"We present a design study of the Deep Insights Anywhere, Anytime (DIA2) platform, a web-based visual analytics system that allows program managers and academic staff at the U.S. National Science Foundation to search, view, and analyze their research funding portfolio. The goal of this system is to facilitate users' understanding of both past and currently active research awards in order to make more informed decisions of their future funding. This user group is characterized by high domain expertise yet not necessarily high literacy in visualization and visual analytics-they are essentially casual experts-and thus require careful visual and information design, including adhering to user experience standards, providing a self-instructive interface, and progressively refining visualizations to minimize complexity. We discuss the challenges of designing a system for casual experts and highlight how we addressed this issue by modeling the organizational structure and workflows of the NSF within our system. We discuss each stage of the design process, starting with formative interviews, prototypes, and finally live deployments and evaluation with stakeholders.",Krishna P. C. Madhavan;Niklas Elmqvist;Mihaela Vorvoreanu;Xin Chen;Yuet Ling Wong;Hanjun Xian;Zhihua Dong;Aditya Johri,Krishna Madhavan;Niklas Elmqvist;Mihaela Vorvoreanu;Xin Chen;Yuetling Wong;Hanjun Xian;Zhihua Dong;Aditya Johri,Purdue University;Purdue University;Purdue University;Purdue University;Purdue University;Microsoft Corporation;Microsoft Corporation;George Mason University,10.1109/tvcg.2007.70541;10.1109/tvcg.2011.174;10.1109/tvcg.2010.177;10.1109/tvcg.2012.255;10.1109/tvcg.2009.123;10.1109/tvcg.2013.223;10.1109/infvis.2001.963283;10.1109/tvcg.2012.213;10.1109/vast.2008.4677361;10.1109/tvcg.2007.70541,"visual analytics, portfolio mining, web-based visualization, casual visualization, design study",30.0,16.0,40.0,1540.0,,,visualization visual analytics;research funding portfolio;expertise necessarily high;workflows nsf discuss;national,0.5746;0.3450;0.3208;0.2833;0.0544,"[np.int64(1), -1, -1, -1, -1]",14;-1;-1;-1;-1,14,14,Visual Analytics Systems
Vis,2021,Augmenting Sports Videos with VisCommentator,10.1109/tvcg.2021.3114806,http://dx.doi.org/10.1109/TVCG.2021.3114806,824.0,834.0,J,"Visualizing data in sports videos is gaining traction in sports analytics, given its ability to communicate insights and explicate player strategies engagingly. However, augmenting sports videos with such data visualizations is challenging, especially for sports analysts, as it requires considerable expertise in video editing. To ease the creation process, we present a design space that characterizes augmented sports videos at an element-level <i>(what the constituents are)</i> and clip-level <i>(how those constituents are organized)</i>. We do so by systematically reviewing 233 examples of augmented sports videos collected from TV channels, teams, and leagues. The design space guides selection of data insights and visualizations for various purposes. Informed by the design space and close collaboration with domain experts, we design VisCommentator, a fast prototyping tool, to eases the creation of augmented table tennis videos by leveraging machine learning-based data extractors and design space-based visualization recommendations. With VisCommentator, sports analysts can create an augmented video by <i>selecting the data</i> to visualize instead of manually <i>drawing the graphical marks</i>. Our system can be generalized to other racket sports <i>(e.g</i>., tennis, badminton) once the underlying datasets and models are available. A user study with seven domain experts shows high satisfaction with our system, confirms that the participants can reproduce augmented sports videos in a short period, and provides insightful implications into future improvements and opportunities.",Zhutian Chen;Shuainan Ye;Xiangtong Chu;Haijun Xia;Hui Zhang 0051;Huamin Qu;Yingcai Wu,Zhutian Chen;Shuainan Ye;Xiangtong Chu;Haijun Xia;Hui Zhang;Huamin Qu;Yingcai Wu,"Department of Cognitive Science and Design Lab, State Key Lab of CAD & CG, Zhejiang University and Hong Kong University of Science and Technology, University of California, San Diego, United States;State Key Lab of CAD & CG, Zhejiang University, China;State Key Lab of CAD & CG, Zhejiang University, China;Department of Cognitive Science and Design Lab, University of California, San Diego, United States;Department of Sport Science, Zhejiang University, China;Hong Kong University of Science and Technology, Hong Kong;State Key Lab of CAD & CG, Zhejiang University, China",10.1109/tvcg.2016.2598647;10.1109/tvcg.2019.2934810;10.1109/tvcg.2014.2346250;10.1109/tvcg.2018.2865240;10.1109/tvcg.2010.179;10.1109/tvcg.2020.3030403;10.1109/tvcg.2017.2745181;10.1109/tvcg.2019.2934398;10.1109/tvcg.2015.2467191;10.1109/tvcg.2017.2744218;10.1109/tvcg.2020.3028957;10.1109/tvcg.2020.3030359;10.1109/tvcg.2020.3030392;10.1109/tvcg.2019.2934656;10.1109/tvcg.2020.3030458,"Augmented Sports Videos,Video-based Visualization,Sports visualization,Intelligent Design Tool,Storytelling",19.0,42.0,62.0,2151.0,HM,,visualizing data sports;video editing ease;insightful implications future;element;design space close,0.7605;0.3853;0.1952;0.1452;0.1355,"[np.int64(1), np.int64(-1), -1, -1, -1]",57;34;-1;-1;-1,34;57,57,Sports Data Visualization
Vis,1998,Visualizing diffusion tensor images of the mouse spinal cord,10.1109/visual.1998.745294,http://dx.doi.org/10.1109/VISUAL.1998.745294,127.0,134.0,C,"Within biological systems, water molecules undergo continuous stochastic Brownian motion. The diffusion rate can give clues to the structure of the underlying tissues. In some tissues, the rate is anisotropic. Diffusion-rate images can be calculated from diffusion-weighted MRI. A 2D diffusion tensor image (DTI) and an associated anatomical scalar field define seven values at each spatial location. We present two new methods for visually representing DTIs. The first method displays an array of ellipsoids, where the shape of each ellipsoid represents one tensor value. The ellipsoids are all normalized to approximately the same size so that they can be displayed simultaneously in context. The second method uses concepts from oil painting to represent the seven-valued data with multiple layers of varying brush strokes. Both methods successfully display most or all of the information in DTIs and provide exploratory methods for understanding them. The ellipsoid method has a simpler interpretation and explanation than the painting-motivated method; the painting-motivated method displays more of the information and is easier to read quantatively. We demonstrate the methods on images of the mouse spinal cord. The visualizations show significant differences between spinal cords from mice suffering from experimental allergic encephalomyelitis and spinal cords from wild-type mice. The differences are consistent with differences shown histologically and suggest that our new non-invasive imaging methodology and visualization of the results could have early diagnostic value for neurodegenerative diseases.",David H. Laidlaw;Eric T. Ahrens;David Kremers;Matthew J. Avalos;Russell E. Jacobs;Carol Readhead,D.H. Laidlaw;E.T. Ahrens;D. Kremers;M.J. Avalos;R.E. Jacobs;C. Readhead,"California Institute of Technology, Pasadena, CA, USA;California Institute of Technology, Pasadena, CA, USA;California Institute of Technology, Pasadena, CA, USA;California Institute of Technology, Pasadena, CA, USA;California Institute of Technology, Pasadena, CA, USA;Cedars Sinai Medical Center, Los Angeles, CA, USA",10.1109/visual.1992.235201;10.1109/visual.1992.235201,"multi-valued visualization, tensor field visualization,oil painting",223.0,63.0,26.0,287.0,,,diffusion tensor image;histologically suggest new;ellipsoids shape;simpler interpretation explanation;cords mice suffering,0.6835;0.2179;0.2178;0.1688;0.1257,"[np.int64(-1), -1, -1, -1, -1]",47;-1;-1;-1;-1,47,47,Diffusion MRI Analysis
Vis,2004,Surface reconstruction of noisy and defective data sets,10.1109/visual.2004.101,http://dx.doi.org/10.1109/VISUAL.2004.101,259.0,266.0,C,"We present a novel surface reconstruction algorithm that can recover high-quality surfaces from noisy and defective data sets without any normal or orientation information. A set of new techniques is introduced to afford extra noise tolerability, robust orientation alignment, reliable outlier removal, and satisfactory feature recovery. In our algorithm, sample points are first organized by an octree. The points are then clustered into a set of monolithically singly-oriented groups. The inside/outside orientation of each group is determined through a robust voting algorithm. We locally fit an implicit quadric surface in each octree cell. The locally fitted implicit surfaces are then blended to produce a signed distance field using the modified Shepard's method. We develop sophisticated iterative fitting algorithms to afford improved noise tolerance both in topology recognition and geometry accuracy. Furthermore, this iterative fitting algorithm, coupled with a local model selection scheme, provides a reliable sharp feature recovery mechanism even in the presence of bad input.",Hui Xie 0001;Kevin T. McDonnell;Hong Qin 0001,H. Xie;K.T. McDonnell;H. Qin,"Computer Science Department, State University of New York at Stony Brook, NY;Computer Science Department, State University of New York at Stony Brook, Stony Brook, NY, USA;Computer Science Department, State University of New York at Stony Brook, Stony Brook, NY, USA",10.1109/visual.2003.1250359;10.1109/visual.2003.1250359,"Computer Graphics, Surface Reconstruction, Surface Representation, MPU implicits, Modified Shepard's Method",106.0,39.0,27.0,475.0,,,surface reconstruction;octree cell locally;alignment reliable;outlier;using modified shepard,0.6800;0.2833;0.2343;0.2067;0.1219,"[np.int64(-1), -1, -1, -1, -1]",65;-1;-1;-1;-1,65,65,Surface Reconstruction Techniques
SciVis,2016,Topological Analysis of Inertial Dynamics,10.1109/tvcg.2016.2599018,http://dx.doi.org/10.1109/TVCG.2016.2599018,950.0,959.0,J,"Traditional vector field visualization has a close focus on velocity, and is typically constrained to the dynamics of massless particles. In this paper, we present a novel approach to the analysis of the force-induced dynamics of inertial particles. These forces can arise from acceleration fields such as gravitation, but also be dependent on the particle dynamics itself, as in the case of magnetism. Compared to massless particles, the velocity of an inertial particle is not determined solely by its position and time in a vector field. In contrast, its initial velocity can be arbitrary and impacts the dynamics over its entire lifetime. This leads to a four-dimensional problem for 2D setups, and a six-dimensional problem for the 3D case. Our approach avoids this increase in dimensionality and tackles the visualization by an integrated topological analysis approach. We demonstrate the utility of our approach using a synthetic time-dependent acceleration field, a system of magnetic dipoles, and N-body systems both in 2D and 3D.",Antoni Sagristà;Stefan Jordan;Andreas Just;Fabio Dias 0001;Luis Gustavo Nonato;Filip Sadlo,Antoni Sagristà;Stefan Jordan;Andreas Just;Fabio Dias;Luis Gustavo Nonato;Filip Sadlo,"Heidelberg University, Germany;Heidelberg University, Germany;ZAH, Heidelberg University, Germany;Universidade de Såo Paulo, Såo Carlos, Brazil;Universidade de Såo Paulo, Såo Carlos, Brazil;Heidelberg University, Germany",10.1109/visual.1993.398859;10.1109/tvcg.2014.2346415;10.1109/visual.1990.146386;10.1109/visual.1993.398859,Visualization of inertial dynamics;N-body systems;magnetism;acceleration,15.0,12.0,30.0,448.0,,,vector field visualization;induced dynamics inertial;massless particles;topological;entire lifetime,0.6084;0.4318;0.3073;0.2460;0.0203,"[np.int64(-1), np.int64(-1), -1, -1, -1]",35;-1;-1;-1;-1,35,35,Vector and Tensor Visualization
InfoVis,2019,Why Authors Don't Visualize Uncertainty,10.1109/tvcg.2019.2934287,http://dx.doi.org/10.1109/TVCG.2019.2934287,130.0,139.0,J,"Clear presentation of uncertainty is an exception rather than rule in media articles, data-driven reports, and consumer applications, despite proposed techniques for communicating sources of uncertainty in data. This work considers, Why do so many visualization authors choose not to visualize uncertainty? I contribute a detailed characterization of practices, associations, and attitudes related to uncertainty communication among visualization authors, derived from the results of surveying 90 authors who regularly create visualizations for others as part of their work, and interviewing thirteen influential visualization designers. My results highlight challenges that authors face and expose assumptions and inconsistencies in beliefs about the role of uncertainty in visualization. In particular, a clear contradiction arises between authors' acknowledgment of the value of depicting uncertainty and the norm of omitting direct depiction of uncertainty. To help explain this contradiction, I present a rhetorical model of uncertainty omission in visualization-based communication. I also adapt a formal statistical model of how viewers judge the strength of a signal in a visualization to visualization-based communication, to argue that uncertainty communication necessarily reduces degrees of freedom in viewers' statistical inferences. I conclude with recommendations for how visualization research on uncertainty communication could better serve practitioners' current needs and values while deepening understanding of assumptions that reinforce uncertainty omission.",Jessica Hullman,Jessica Hullman,Northwestern University,10.1109/tvcg.2016.2598862;10.1109/tvcg.2011.255;10.1109/tvcg.2018.2864889;10.1109/tvcg.2018.2864909;10.1109/tvcg.2010.161;10.1109/tvcg.2014.2346298;10.1109/tvcg.2016.2598862,"Uncertainty visualization,graphical statistical inference,visualization rhetoric",97.0,87.0,55.0,2598.0,,,visualization research uncertainty;rule media articles;better;serve practitioners;necessarily reduces degrees,0.7483;0.1476;0.1162;0.0599;0.0291,"[np.int64(1), -1, -1, -1, -1]",7;-1;-1;-1;-1,7,7,Uncertainty Visualization
InfoVis,2010,Pargnostics: Screen-Space Metrics for Parallel Coordinates,10.1109/tvcg.2010.184,http://dx.doi.org/10.1109/TVCG.2010.184,1017.0,1026.0,J,"Interactive visualization requires the translation of data into a screen space of limited resolution. While currently ignored by most visualization models, this translation entails a loss of information and the introduction of a number of artifacts that can be useful, (e.g., aggregation, structures) or distracting (e.g., over-plotting, clutter) for the analysis. This phenomenon is observed in parallel coordinates, where overlapping lines between adjacent axes form distinct patterns, representing the relation between variables they connect. However, even for a small number of dimensions, the challenge is to effectively convey the relationships for all combinations of dimensions. The size of the dataset and a large number of dimensions only add to the complexity of this problem. To address these issues, we propose Pargnostics, parallel coordinates diagnostics, a model based on screen-space metrics that quantify the different visual structures. Pargnostics metrics are calculated for pairs of axes and take into account the resolution of the display as well as potential axis inversions. Metrics include the number of line crossings, crossing angles, convergence, overplotting, etc. To construct a visualization view, the user can pick from a ranked display showing pairs of coordinate axes and the structures between them, or examine all possible combinations of axes at once in a matrix display. Picking the best axes layout is an NP-complete problem in general, but we provide a way of automatically optimizing the display according to the user's preferences based on our metrics and model.",Aritra Dasgupta;Robert Kosara,Aritra Dasgupta;Robert Kosara,"UNC-Charlotte, USA;UNC-Charlotte, USA",10.1109/infvis.2005.1532142;10.1109/tvcg.2006.138;10.1109/visual.1990.146402;10.1109/vast.2006.261423;10.1109/vast.2009.5332628;10.1109/infvis.2005.1532136;10.1109/infvis.1998.729559;10.1109/infvis.1997.636793;10.1109/infvis.2005.1532142,"Parallel coordinates, metrics, display optimization, visualization models",163.0,102.0,32.0,1207.0,,,interactive visualization requires;axes matrix;overlapping lines;inversions metrics;resolution currently ignored,0.6396;0.3388;0.3335;0.1644;0.1606,"[np.int64(1), -1, -1, -1, -1]",16;-1;-1;-1;-1,16,16,Interactive Visualization Systems
VAST,2017,Analyzing the Training Processes of Deep Generative Models,10.1109/tvcg.2017.2744938,http://dx.doi.org/10.1109/TVCG.2017.2744938,77.0,87.0,J,"Among the many types of deep models, deep generative models (DGMs) provide a solution to the important problem of unsupervised and semi-supervised learning. However, training DGMs requires more skill, experience, and know-how because their training is more complex than other types of deep models such as convolutional neural networks (CNNs). We develop a visual analytics approach for better understanding and diagnosing the training process of a DGM. To help experts understand the overall training process, we first extract a large amount of time series data that represents training dynamics (e.g., activation changes over time). A blue-noise polyline sampling scheme is then introduced to select time series samples, which can both preserve outliers and reduce visual clutter. To further investigate the root cause of a failed training process, we propose a credit assignment algorithm that indicates how other neurons contribute to the output of the neuron causing the training failure. Two case studies are conducted with machine learning experts to demonstrate how our approach helps understand and diagnose the training processes of DGMs. We also show how our approach can be directly used to analyze other types of deep models, such as CNNs.",Mengchen Liu;Jiaxin Shi;Kelei Cao;Jun Zhu 0001;Shixia Liu,Mengchen Liu;Jiaxin Shi;Kelei Cao;Jun Zhu;Shixia Liu,"Tsinghua University, National Engineering Lab for Big Data Software;Tsinghua University;Tsinghua University, National Engineering Lab for Big Data Software;Tsinghua University;Tsinghua University, National Engineering Lab for Big Data Software",10.1109/tvcg.2016.2598496;10.1109/tvcg.2014.2346594;10.1109/tvcg.2010.131;10.1109/tvcg.2011.239;10.1109/tvcg.2016.2598831;10.1109/tvcg.2016.2598797;10.1109/tvcg.2016.2598838;10.1109/tvcg.2016.2598829;10.1109/visual.2005.1532820;10.1109/vast.2016.7883511;10.1109/tvcg.2016.2598664;10.1109/tvcg.2010.132;10.1109/tvcg.2016.2598496,"deep learning,deep generative models,blue noise sampling,credit assignment",134.0,116.0,55.0,3126.0,,,deep generative;visual analytics;large time series;understanding diagnosing;blue noise polyline,0.6353;0.3519;0.2768;0.2458;0.2218,"[np.int64(-1), np.int64(1), -1, -1, -1]",41;14;-1;-1;-1,14;41,41,Deep Learning Models
VAST,2014,The Spinel Explorer - Interactive Visual Analysis of Spinel Group Minerals,10.1109/tvcg.2014.2346754,http://dx.doi.org/10.1109/TVCG.2014.2346754,1913.0,1922.0,J,"Geologists usually deal with rocks that are up to several thousand million years old. They try to reconstruct the tectonic settings where these rocks were formed and the history of events that affected them through the geological time. The spinel group minerals provide useful information regarding the geological environment in which the host rocks were formed. They constitute excellent indicators of geological environments (tectonic settings) and are of invaluable help in the search for mineral deposits of economic interest. The current workflow requires the scientists to work with different applications to analyze spine data. They do use specific diagrams, but these are usually not interactive. The current workflow hinders domain experts to fully exploit the potentials of tediously and expensively collected data. In this paper, we introduce the Spinel Explorer-an interactive visual analysis application for spinel group minerals. The design of the Spinel Explorer and of the newly introduced interactions is a result of a careful study of geologists' tasks. The Spinel Explorer includes most of the diagrams commonly used for analyzing spinel group minerals, including 2D binary plots, ternary plots, and 3D Spinel prism plots. Besides specific plots, conventional information visualization views are also integrated in the Spinel Explorer. All views are interactive and linked. The Spinel Explorer supports conventional statistics commonly used in spinel minerals exploration. The statistics views and different data derivation techniques are fully integrated in the system. Besides the Spinel Explorer as newly proposed interactive exploration system, we also describe the identified analysis tasks, and propose a new workflow. We evaluate the Spinel Explorer using real-life data from two locations in Argentina: the Frontal Cordillera in Central Andes and Patagonia. We describe the new findings of the geologists which would have been much more difficult to achieve using the current workflow only. Very positive feedback from geologists confirms the usefulness of the Spinel Explorer.",Maria Luján Ganuza;Gabriela Ferracutti;Maria Florencia Gargiulo;Silvia Mabel Castro;Ernesto A. Bjerg;M. Eduard Gröller;Kresimir Matkovic,María Luján Ganuza;Gabriela Ferracutti;María Florencia Gargiulo;Silvia Mabel Castro;Ernesto Bjerg;Eduard Gröller;Krešimir Matković,"VyGLab Research Laboratory at the Universidad Nacional del Sur, Bahía Blanca, Argentina;Departamento de Geología, Universidad Nacional del Sur, Bahía Blanca, Argentina;Departamento de Geología, Universidad Nacional del Sur, Bahía Blanca, Argentina;VyGLab Research Laboratory at the Universidad Nacional del Sur, Bahía Blanca, Argentina;Departamento de Geología, Universidad Nacional del Sur, Bahía Blanca, Argentina;Vienna University of Technology, Austria;VRVis Research Center, Vienna, Austria",10.1109/infvis.2000.885086;10.1109/tvcg.2009.155;10.1109/visual.1995.485139,"Interactive visual analysis, visualization in earth/space/ and environmental sciences, coordinated and multiple views, design studies",21.0,12.0,29.0,664.0,,,spinel minerals exploration;explorer supports;interactive current workflow;statistics views different;hinders domain,0.6622;0.1978;0.1891;0.1877;-0.0340,"[np.int64(-1), -1, -1, -1, -1]",21;-1;-1;-1;-1,21,21,Geological Data Analysis
InfoVis,2007,NodeTrix: a Hybrid Visualization of Social Networks,10.1109/tvcg.2007.70582,http://dx.doi.org/10.1109/TVCG.2007.70582,1302.0,1309.0,J,"The need to visualize large social networks is growing as hardware capabilities make analyzing large networks feasible and many new data sets become available. Unfortunately, the visualizations in existing systems do not satisfactorily resolve the basic dilemma of being readable both for the global structure of the network and also for detailed analysis of local communities. To address this problem, we present NodeTrix, a hybrid representation for networks that combines the advantages of two traditional representations: node-link diagrams are used to show the global structure of a network, while arbitrary portions of the network can be shown as adjacency matrices to better support the analysis of communities. A key contribution is a set of interaction techniques. These allow analysts to create a NodeTrix visualization by dragging selections to and from node-link and matrix forms, and to flexibly manipulate the NodeTrix representation to explore the dataset and create meaningful summary visualizations of their findings. Finally, we present a case study applying NodeTrix to the analysis of the InfoVis 2004 coauthorship dataset to illustrate the capabilities of NodeTrix as both an exploration tool and an effective means of communicating results.",Nathalie Henry;Jean-Daniel Fekete;Michael J. McGuffin,Nathalie Henry;Jean-Daniel Fekete;Michael J. McGuffin,"University of Sydney, Australia and INRIA Futurs, University of Paris-Sud 11, France;INRIA Futurs and Laboratory RI UMR CNRS 5800, France;Ontario Cancer Institute, University of Toronto, Canada",10.1109/tvcg.2006.160;10.1109/vast.2006.261426;10.1109/infvis.2005.1532126;10.1109/infvis.2004.46;10.1109/tvcg.2006.193;10.1109/infvis.2005.1532129;10.1109/tvcg.2006.166;10.1109/tvcg.2006.147;10.1109/infvis.2004.64;10.1109/infvis.2003.1249011;10.1109/tvcg.2006.160,"Network visualization, Matrix visualization, Hybrid visualization, Aggregation, Interaction",675.0,383.0,35.0,4341.0,,,visualize large social;capabilities nodetrix;matrix forms;unfortunately;dragging selections,0.6996;0.2556;0.1249;0.0841;0.0737,"[np.int64(1), -1, -1, -1, -1]",5;-1;-1;-1;-1,5,5,Social Network Visualization
InfoVis,2016,Gaussian Cubes: Real-Time Modeling for Visual Exploration of Large Multidimensional Datasets,10.1109/tvcg.2016.2598694,http://dx.doi.org/10.1109/TVCG.2016.2598694,681.0,690.0,J,"Recently proposed techniques have finally made it possible for analysts to interactively explore very large datasets in real time. However powerful, the class of analyses these systems enable is somewhat limited: specifically, one can only quickly obtain plots such as histograms and heatmaps. In this paper, we contribute Gaussian Cubes, which significantly improves on state-of-the-art systems by providing interactive modeling capabilities, which include but are not limited to linear least squares and principal components analysis (PCA). The fundamental insight in Gaussian Cubes is that instead of precomputing counts of many data subsets (as state-of-the-art systems do), Gaussian Cubes precomputes the best multivariate Gaussian for the respective data subsets. As an example, Gaussian Cubes can fit hundreds of models over millions of data points in well under a second, enabling novel types of visual exploration of such large datasets. We present three case studies that highlight the visualization and analysis capabilities in Gaussian Cubes, using earthquake safety simulations, astronomical catalogs, and transportation statistics. The dataset sizes range around one hundred million elements and 5 to 10 dimensions. We present extensive performance results, a discussion of the limitations in Gaussian Cubes, and future research directions.",Zhe Wang;Nivan Ferreira;Youhao Wei;Aarthy Sankari Bhaskar;Carlos Scheidegger,Zhe Wang;Nivan Ferreira;Youhao Wei;Aarthy Sankari Bhaskar;Carlos Scheidegger,University of Arizona;Universidade Federal de Pernambuco;University of Arizona;University of Arizona;University of Arizona,10.1109/vast.2008.4677357;10.1109/infvis.2000.885086;10.1109/tvcg.2013.179;10.1109/tvcg.2014.2346452;10.1109/tvcg.2009.129;10.1109/tvcg.2013.141;10.1109/tvcg.2014.2346325;10.1109/vast.2012.6400490,data cubes;Data modeling;dimensionality reduction;interactive visualization,61.0,37.0,45.0,1167.0,,,gaussian cubes precomputes;studies highlight visualization;astronomical catalogs transportation;earthquake;enable somewhat limited,0.5705;0.3616;0.2544;0.1783;-0.0009,"[np.int64(-1), np.int64(1), -1, -1, -1]",20;69;-1;-1;-1,20;69,20,GPU Rendering Techniques
InfoVis,2010,The FlowVizMenu and Parallel Scatterplot Matrix: Hybrid Multidimensional Visualizations for Network Exploration,10.1109/tvcg.2010.205,http://dx.doi.org/10.1109/TVCG.2010.205,1100.0,1108.0,J,"A standard approach for visualizing multivariate networks is to use one or more multidimensional views (for example, scatterplots) for selecting nodes by various metrics, possibly coordinated with a node-link view of the network. In this paper, we present three novel approaches for achieving a tighter integration of these views through hybrid techniques for multidimensional visualization, graph selection and layout. First, we present the FlowVizMenu, a radial menu containing a scatterplot that can be popped up transiently and manipulated with rapid, fluid gestures to select and modify the axes of its scatterplot. Second, the FlowVizMenu can be used to steer an attribute-driven layout of the network, causing certain nodes of a node-link diagram to move toward their corresponding positions in a scatterplot while others can be positioned manually or by force-directed layout. Third, we describe a novel hybrid approach that combines a scatterplot matrix (SPLOM) and parallel coordinates called the Parallel Scatterplot Matrix (P-SPLOM), which can be used to visualize and select features within the network. We also describe a novel arrangement of scatterplots called the Scatterplot Staircase (SPLOS) that requires less space than a traditional scatterplot matrix. Initial user feedback is reported.",Christophe Viau;Michael J. McGuffin;Yves Chiricota;Igor Jurisica,Christophe Viau;Michael J. McGuffin;Yves Chiricota;Igor Jurisica,"École de technologie supérieure, Montreal, Canada;École de technologie supérieure, Montreal, Canada;Université du Quàbec à Chicoutimi, Chicoutimi, Canada;Ontario Cancer Institute, PMH UHN, Toronto, Canada",10.1109/tvcg.2009.151;10.1109/infvis.2005.1532142;10.1109/tvcg.2007.70523;10.1109/tvcg.2009.179;10.1109/vast.2009.5332586;10.1109/infvis.2005.1532141;10.1109/tvcg.2006.187;10.1109/infvis.2004.47;10.1109/tvcg.2007.70521;10.1109/infvis.2003.1249011;10.1109/tvcg.2008.153;10.1109/tvcg.2009.151,"Interactive graph drawing, network layout, attribute-driven layout, parallel coordinates, scatterplot matrix, radial menu",104.0,67.0,39.0,1480.0,,,visualizing multivariate networks;driven layout;gestures select modify;certain nodes node;standard,0.7594;0.2834;0.2561;0.2016;-0.0079,"[np.int64(1), -1, -1, -1, -1]",11;-1;-1;-1;-1,11,11,Multivariate Data Visualization
VAST,2020,A Visual Analytics Approach for Ecosystem Dynamics based on Empirical Dynamic Modeling,10.1109/tvcg.2020.3028956,http://dx.doi.org/10.1109/TVCG.2020.3028956,506.0,516.0,J,"An important approach for scientific inquiry across many disciplines involves using observational time series data to understand the relationships between key variables to gain mechanistic insights into the underlying rules that govern the given system. In real systems, such as those found in ecology, the relationships between time series variables are generally not static; instead, these relationships are dynamical and change in a nonlinear or state-dependent manner. To further understand such systems, we investigate integrating methods that appropriately characterize these dynamics (i.e., methods that measure interactions as they change with time-varying system states) with visualization techniques that can help analyze the behavior of the system. Here, we focus on empirical dynamic modeling (EDM) as a state-of-the-art method that specifically identifies causal variables and measures changing state-dependent relationships between time series variables. Instead of using approaches centered on parametric equations, EDM is an equation-free approach that studies systems based on their dynamic attractors. We propose a visual analytics system to support the identification and mechanistic interpretation of system states using an EDM-constructed dynamic graph. This work, as detailed in four analysis tasks and demonstrated with a GUI, provides a novel synthesis of EDM and visualization techniques such as brush-link visualization and visual summarization to interpret dynamic graphs representing ecosystem dynamics. We applied our proposed system to ecological simulation data and real data from a marine mesocosm study as two key use cases. Our case studies show that our visual analytics tools support the identification and interpretation of the system state by the user, and enable us to discover both confirmatory and new findings in ecosystem dynamics. Overall, we demonstrated that our system can facilitate an understanding of how systems function beyond the intuitive analysis of high-dimensional information based on specific domain knowledge.",Hiroaki Natsukawa;Ethan R. Deyle;Gerald M. Pao;Koji Koyamada;George Sugihara,Hiroaki Natsukawa;Ethan R. Deyle;Gerald M. Pao;Koji Koyamada;George Sugihara,"Kyoto University;Boston University and Scripps Institution of Oceanography, University of California, San Diego;Salk Institution for Biological Sciences;Kyoto University;Scripps Institution of Oceanography, University of California, San Diego",10.1109/tvcg.2009.181;10.1109/tvcg.2019.2934251;10.1109/tvcg.2013.198;10.1109/tvcg.2006.192;10.1109/tvcg.2015.2468078;10.1109/tvcg.2017.2745258;10.1109/tvcg.2009.181,"Visual analytics,empirical dynamic modeling,dynamic network,exploratory data analysis",4.0,7.0,58.0,1153.0,,,representing ecosystem dynamics;mechanistic insights underlying;techniques brush;enable discover confirmatory;case,0.6974;0.3436;0.1183;0.0408;-0.0517,"[np.int64(-1), -1, -1, -1, -1]",82;-1;-1;-1;-1,82,82,Environmental Visualization
Vis,1996,Case Study: Visual access for landscape event based temporal data,10.1109/visual.1996.568148,http://dx.doi.org/10.1109/VISUAL.1996.568148,425.0,428.0,C,As ecological awareness increases there has been a shift towards more integrated forest management. Accurate modeling of future states of forested landscapes will allow better planning for safeguarding our forest resource for future generations. We present an initial exploration into providing visual access to information generated by SELES (Spatially Explicit Landscape Event Simulator). We explore the application of our visual access distortion technique to a block of temporal data created from a sequence of landscape event based information. This type of access extends the possibilities of visual exploration for temporal and spatial interrelations in a data set.,M. Sheelagh T. Carpendale;Andrew Fall;David J. Cowperthwaite;Joseph Fall;F. David Fracchia,M. Sheelagh T. Carpendale;A. Fall;D.J. Cowperthwaite;J. Fall;F.D. Fracchia,"Simon Fraser University, Burnaby, BC, CA;Simon Fraser University, Burnaby, BC, CA;Simon Fraser University, Burnaby, BC, CA;Simon Fraser University, Burnaby, BC, CA;Simon Fraser University, Burnaby, BC, CA",,"distortion viewing, 3D interaction, information visualization, temporal data",12.0,4.0,4.0,90.0,,,landscape event simulator;safeguarding forest resource;interrelations data;access extends possibilities;seles,0.5539;0.3467;0.2581;0.2084;0.0528,"[np.int64(-1), -1, -1, -1, -1]",80;-1;-1;-1;-1,80,80,Environmental Simulation Tools
VAST,2007,VAST 2007 Contest - Blue Iguanodon,10.1109/vast.2007.4389032,http://dx.doi.org/10.1109/VAST.2007.4389032,231.0,232.0,M,Visual analytics experts realize that one effective way to push the field forward and to develop metrics for measuring the performance of various visual analytics components is to hold an annual competition. The second visual analytics science and technology (VAST) contest was held in conjunction with the 2007 IEEE VAST symposium. In this contest participants were to use visual analytic tools to explore a large heterogeneous data collection to construct a scenario and find evidence buried in the data of illegal and terrorist activities that were occurring. A synthetic data set was made available as well as tasks. In this paper we describe some of the advances we have made from the first competition held in 2006.,Georges G. Grinstein;Catherine Plaisant;Sharon J. Laskowski;Theresa A. O'Connell;Jean Scholtz;Mark A. Whiting,Georges Grinstein;Catherine Plaisant;Sharon Laskowski;Theresa O'Connell;Jean Scholtz;Mark Whiting,"University of Massachusetts, Lowell, USA;National Institute for Standards and Technology, USA;National Institute for Standards and Technology, USA;Pacific Northwest National Laboratory, USA;Pacific Northwest National Laboratory, USA;University of Maryland, USA",,,17.0,10.0,6.0,121.0,,,visual analytics science;scenario evidence buried;illegal terrorist;hold annual competition;set available tasks,0.7134;0.2577;0.2463;0.1454;-0.0093,"[np.int64(1), -1, -1, -1, -1]",14;-1;-1;-1;-1,14,14,Visual Analytics Systems
SciVis,2020,ChemVA: Interactive Visual Analysis of Chemical Compound Similarity in Virtual Screening,10.1109/tvcg.2020.3030438,http://dx.doi.org/10.1109/TVCG.2020.3030438,891.0,901.0,J,"In the modern drug discovery process, medicinal chemists deal with the complexity of analysis of large ensembles of candidate molecules. Computational tools, such as dimensionality reduction (DR) and classification, are commonly used to efficiently process the multidimensional space of features. These underlying calculations often hinder interpretability of results and prevent experts from assessing the impact of individual molecular features on the resulting representations. To provide a solution for scrutinizing such complex data, we introduce ChemVA, an interactive application for the visual exploration of large molecular ensembles and their features. Our tool consists of multiple coordinated views: Hexagonal view, Detail view, 3D view, Table view, and a newly proposed Difference view designed for the comparison of DR projections. These views display DR projections combined with biological activity, selected molecular features, and confidence scores for each of these projections. This conjunction of views allows the user to drill down through the dataset and to efficiently select candidate compounds. Our approach was evaluated on two case studies of finding structurally similar ligands with similar binding affinity to a target protein, as well as on an external qualitative evaluation. The results suggest that our system allows effective visual inspection and comparison of different high-dimensional molecular representations. Furthermore, ChemVA assists in the identification of candidate compounds while providing information on the certainty behind different molecular representations.",María Virginia Sabando;Pavol Ulbrich;Matias Nicolás Selzer;Jan Byska;Jan Mican;Ignacio Ponzoni;Axel J. Soto;Maria Luján Ganuza;Barbora Kozlíková,María Virginia Sabando;Pavol Ulbrich;Matías Selzer;Jan Byška;Jan Mičan;Ignacio Ponzoni;Axel J. Soto;María Luján Ganuza;Barbora Kozlíková,"Department of Computer Science and Engineering, Universidad Nacional del Sur, Institute for Computer Science and Engineering (UNS-CONICET), Bahía, Blanca, Argentina and Department of Computer Science and Engineering, Universidad Nacional del Sur, VyGLab Research Laboratory (UNS-CICPBA), Institute for Computer Science and Engineering (UNS-CONICET), Bahía, Blanca, Argentina;Faculty of Informatics, Masaryk University, Brno, Czech Republic;Department of Computer Science and Engineering, Universidad Nacional del Sur, Institute for Computer Science and Engineering (UNS-CONICET), Bahía, Blanca, Argentina and Department of Computer Science and Engineering, Universidad Nacional del Sur, VyGLab Research Laboratory (UNS-CICPBA), Institute for Computer Science and Engineering (UNS-CONICET), Bahía, Blanca, Argentina;Faculty of Informatics, Masaryk University, Brno, Czech Republic;Department of Experimental Biology and RECETOX, Loschmidt Laboratories, Faculty of Medicine Masaryk University, Brno, Czech Republic;Department of Computer Science and Engineering, Universidad Nacional del Sur, Institute for Computer Science and Engineering (UNS-CONICET), Bahía, Blanca, Argentina and Department of Computer Science and Engineering, Universidad Nacional del Sur, VyGLab Research Laboratory (UNS-CICPBA), Institute for Computer Science and Engineering (UNS-CONICET), Bahía, Blanca, Argentina;Department of Computer Science and Engineering, Universidad Nacional del Sur, Institute for Computer Science and Engineering (UNS-CONICET), Bahía, Blanca, Argentina and Department of Computer Science and Engineering, Universidad Nacional del Sur, VyGLab Research Laboratory (UNS-CICPBA), Institute for Computer Science and Engineering (UNS-CONICET), Bahía, Blanca, Argentina;Department of Computer Science and Engineering, Universidad Nacional del Sur, Institute for Computer Science and Engineering (UNS-CONICET), Bahía, Blanca, Argentina and Department of Computer Science and Engineering, Universidad Nacional del Sur, VyGLab Research Laboratory (UNS-CICPBA), Institute for Computer Science and Engineering (UNS-CONICET), Bahía, Blanca, Argentina;Faculty of Informatics, Masaryk University, Brno, Czech Republic",10.1109/tvcg.2019.2934209;10.1109/tvcg.2011.185;10.1109/tvcg.2013.173;10.1109/tvcg.2016.2598495;10.1109/tvcg.2013.153;10.1109/tvcg.2019.2934209,"Virtual screening,visual analysis,dimensionality reduction,coordinated views,cheminformatics",4.0,9.0,79.0,665.0,,,candidate molecules computational;hinder interpretability results;projections views display;user drill dataset;qualitative,0.5921;0.2879;0.2414;0.1289;0.1061,"[np.int64(-1), -1, -1, -1, -1]",27;-1;-1;-1;-1,27,27,Molecular Design Techniques
Vis,2008,Interactive Visualization and Analysis of Transitional Flow,10.1109/tvcg.2008.146,http://dx.doi.org/10.1109/TVCG.2008.146,1420.0,1427.0,J,"A stand-alone visualization application has been developed by a multi-disciplinary, collaborative team with the sole purpose of creating an interactive exploration environment allowing turbulent flow researchers to experiment and validate hypotheses using visualization. This system has specific optimizations made in data management, caching computations, and visualization allowing for the interactive exploration of datasets on the order of 1TB in size. Using this application, the user (co-author Calo) is able to interactively visualize and analyze all regions of a transitional flow volume, including the laminar, transitional and fully turbulent regions. The underlying goal of the visualizations produced from these transitional flow simulations is to localize turbulent spots in the laminar region of the boundary layer, determine under which conditions they form, and follow their evolution. The initiation of turbulent spots, which ultimately lead to full turbulence, was located via a proposed feature detection condition and verified by experimental results. The conditions under which these turbulent spots form and coalesce are validated and presented.",Gregory P. Johnson;Victor M. Calo;Kelly P. Gaither,"Gregory P. Johnson,;Victor M. Calo;Kelly P. Gaither","Texas Advanced Computing Center, The University of Texas, Austin;Texas Advanced Computing Center, University of Technology, Austin, USA and Institute for Computational and Engineering Sciences, The University of Texas, Austin;Texas Advanced Computing Center, University of Technology, Austin, USA and Texas Advanced Computing Center, The University of Texas, Austin",10.1109/visual.2005.1532792;10.1109/visual.1993.398850;10.1109/visual.2005.1532794;10.1109/visual.1991.175818;10.1109/visual.2004.55;10.1109/visual.2004.54,"Applications of Visualization, Flow Visualization, Transitional Flow, Turbulence",11.0,8.0,31.0,323.0,,,turbulent flow researchers;interactively visualize;laminar region boundary;follow evolution initiation;localize,0.7199;0.2904;0.2775;0.0792;-0.1823,"[np.int64(-1), -1, -1, -1, -1]",25;-1;-1;-1;-1,25,25,Fluid Dynamics Research
Vis,2007,Querying and Creating Visualizations by Analogy,10.1109/tvcg.2007.70584,http://dx.doi.org/10.1109/TVCG.2007.70584,1560.0,1567.0,J,"While there have been advances in visualization systems, particularly in multi-view visualizations and visual exploration, the process of building visualizations remains a major bottleneck in data exploration. We show that provenance metadata collected during the creation of pipelines can be reused to suggest similar content in related visualizations and guide semi-automated changes. We introduce the idea of query-by-example in the context of an ensemble of visualizations, and the use of analogies as first-class operations in a system to guide scalable interactions. We describe an implementation of these techniques in VisTrails, a publicly-available, open-source system.",Carlos Eduardo Scheidegger;Huy T. Vo;David Koop;Juliana Freire;Cláudio T. Silva,Carlos Scheidegger;Huy Vo;David Koop;Juliana Freire;Claudio Silva,"Scientific Computing and Imaging (SCI) Institute, University of Utah, USA;Scientific Computing and Imaging (SCI) Institute, University of Utah, USA;Scientific Computing and Imaging (SCI) Institute, University of Utah, USA;School of Computing, University of Utah, USA;Scientific Computing and Imaging (SCI) Institute, University of Utah, USA",10.1109/visual.2005.1532781;10.1109/infvis.2004.2;10.1109/visual.2004.112;10.1109/visual.2005.1532788;10.1109/visual.2005.1532795;10.1109/visual.2005.1532781,"visualization systems, query-by-example, analogy",160.0,70.0,31.0,594.0,BP,,building visualizations;provenance metadata;pipelines reused;suggest similar content;particularly,0.6312;0.4755;0.2436;0.2272;0.0794,"[np.int64(1), np.int64(-1), -1, -1, -1]",15;21;-1;-1;-1,15;21,15,Visualization Design
VAST,2016,VisFlow - Web-based Visualization Framework for Tabular Data with a Subset Flow Model,10.1109/tvcg.2016.2598497,http://dx.doi.org/10.1109/TVCG.2016.2598497,251.0,260.0,J,"Data flow systems allow the user to design a flow diagram that specifies the relations between system components which process, filter or visually present the data. Visualization systems may benefit from user-defined data flows as an analysis typically consists of rendering multiple plots on demand and performing different types of interactive queries across coordinated views. In this paper, we propose VisFlow, a web-based visualization framework for tabular data that employs a specific type of data flow model called the subset flow model. VisFlow focuses on interactive queries within the data flow, overcoming the limitation of interactivity from past computational data flow systems. In particular, VisFlow applies embedded visualizations and supports interactive selections, brushing and linking within a visualization-oriented data flow. The model requires all data transmitted by the flow to be a data item subset (i.e. groups of table rows) of some original input table, so that rendering properties can be assigned to the subset unambiguously for tracking and comparison. VisFlow features the analysis flexibility of a flow diagram, and at the same time reduces the diagram complexity and improves usability. We demonstrate the capability of VisFlow on two case studies with domain experts on real-world datasets showing that VisFlow is capable of accomplishing a considerable set of visualization and analysis tasks. The VisFlow system is available as open source on GitHub.",Bowen Yu 0004;Cláudio T. Silva,Bowen Yu;Cláudio T. Silva,New York University;New York University,10.1109/tvcg.2009.195;10.1109/infvis.2004.12;10.1109/vast.2011.6102440;10.1109/infvis.1998.729560;10.1109/tvcg.2014.2346260;10.1109/infvis.2005.1532136;10.1109/tvcg.2011.225;10.1109/infvis.2003.1249013;10.1109/visual.2005.1532788;10.1109/tvcg.2014.2346753;10.1109/tvcg.2011.185;10.1109/tvcg.2014.2346291;10.1109/tvcg.2009.195,Visualization framework;data flow;subset flow model;tabular data,45.0,43.0,47.0,2370.0,,,data visualization;framework tabular;model visflow focuses;subset groups;limitation interactivity past,0.6549;0.2790;0.2140;0.1909;0.1538,"[np.int64(1), -1, -1, -1, -1]",67;-1;-1;-1;-1,67,67,Data Visualization Techniques
Vis,2002,NASA's great zooms: a case study,10.1109/visual.2002.1183825,http://dx.doi.org/10.1109/VISUAL.2002.1183825,541.0,544.0,C,"This paper examines a series of NASA outreach visualizations created using several layers of remote sensing satellite data ranging from 4-kilometers per pixel to I-meter per pixel. The viewer is taken on a seamless, cloud free journey from a global view of the Earth down to ground level where buildings, streets, and cars are visible. The visualizations were produced using a procedural shader that takes advantage of accurate georegistration and color matching between images. The shader accurately and efficiently maps the data sets to geometry allowing for animations with few perceptual transitions among data sets. We developed a pipeline to facilitate the production of over twenty zoom visualizations. Millions of people have seen these visualizations through national and international media coverage.",Gregory W. Shirah;Horace Mitchell,G.W. Shirah;H.G. Mitchell,"Scientific Visualization Studio, NASA Goddard Space Flight Center, USA;Scientific Visualization Studio, NASA Goddard Space Flight Center, USA",,"visualization, remote sensing, renderman, shader, georegistration, color matching",0.0,0.0,11.0,120.0,,,nasa outreach visualizations;animations perceptual transitions;images shader accurately;level buildings streets;takes advantage,0.6192;0.3521;0.3128;0.1819;0.0875,"[np.int64(1), np.int64(-1), -1, -1, -1]",86;26;-1;-1;-1,26;86,86,Scientific Visualization
InfoVis,2006,Visualization of Barrier Tree Sequences,10.1109/tvcg.2006.196,http://dx.doi.org/10.1109/TVCG.2006.196,781.0,788.0,J,"Dynamical models that explain the formation of spatial structures of RNA molecules have reached a complexity that requires novel visualization methods that help to analyze the validity of these models. We focus on the visualization of so-called folding landscapes of a growing RNA molecule. Folding landscapes describe the energy of a molecule as a function of its spatial configuration; thus they are huge and high dimensional. Their most salient features, however, are encapsulated by their so-called barrier tree that reflects the local minima and their connecting saddle points. For each length of the growing RNA chain there exists a folding landscape. We visualize the sequence of folding landscapes by an animation of the corresponding barrier trees. To generate the animation, we adapt the foresight layout with tolerance algorithm for general dynamic graph layout problems. Since it is very general, we give a detailed description of each phase: constructing a supergraph for the trees, layout of that supergraph using a modified DOT algorithm, and presentation techniques for the final animation",Christian Heine 0002;Gerik Scheuermann;Christoph Flamm;Ivo L. Hofacker;Peter F. Stadler,Christian Heine;Gerik Scheuermann;Christoph Flamm;Ivo L. Hofacker;Peter F. Stadler,"Image and Signal Processing Group, Department of Computer Science, University of Leipzig, Germany;Image and Signal Processing Group, Department of Computer Science, University of Leipzig, Germany;Bioinformatics Group, Department of Computer Science, University of Leipzig, Germany;Department of Theoretical Chemistry and Structural Biology, University of Vienna, Germany;Bioinformatics Group, Department of Computer Science, University of Leipzig, Germany",10.1109/infvis.2004.18;10.1109/infvis.2004.18,"Graph drawing, dynamic graph, RNA folding, energy landscape, fitness landscape, barrier tree",22.0,13.0,25.0,347.0,,,visualize sequence folding;spatial configuration huge;energy molecule function;tolerance algorithm general;tree,0.6288;0.3042;0.2203;0.1596;0.1468,"[np.int64(-1), -1, -1, -1, -1]",32;-1;-1;-1;-1,32,32,Chromatin Visualization
InfoVis,2020,A Bayesian cognition approach for belief updating of correlation judgement through uncertainty visualizations,10.1109/tvcg.2020.3029412,http://dx.doi.org/10.1109/TVCG.2020.3029412,978.0,988.0,J,"Understanding correlation judgement is important to designing effective visualizations of bivariate data. Prior work on correlation perception has not considered how factors including prior beliefs and uncertainty representation impact such judgements. The present work focuses on the impact of uncertainty communication when judging bivariate visualizations. Specifically, we model how users update their beliefs about variable relationships after seeing a scatterplot with and without uncertainty representation. To model and evaluate the belief updating, we present three studies. Study 1 focuses on a proposed “Line + Cone” visual elicitation method for capturing users' beliefs in an accurate and intuitive fashion. The findings reveal that our proposed method of belief solicitation reduces complexity and accurately captures the users' uncertainty about a range of bivariate relationships. Study 2 leverages the “Line + Cone” elicitation method to measure belief updating on the relationship between different sets of variables when seeing correlation visualization with and without uncertainty representation. We compare changes in users beliefs to the predictions of Bayesian cognitive models which provide normative benchmarks for how users should update their prior beliefs about a relationship in light of observed data. The findings from Study 2 revealed that one of the visualization conditions with uncertainty communication led to users being slightly more confident about their judgement compared to visualization without uncertainty information. Study 3 builds on findings from Study 2 and explores differences in belief update when the bivariate visualization is congruent or incongruent with users' prior belief. Our results highlight the effects of incorporating uncertainty representation, and the potential of measuring belief updating on correlation judgement with Bayesian cognitive models.",Alireza Karduni;Douglas Markant;Ryan Wesslen;Wenwen Dou,Alireza Karduni;Douglas Markant;Ryan Wesslen;Wenwen Dou,"University of North Carolina, Charlotte;University of North Carolina, Charlotte;University of North Carolina, Charlotte;University of North Carolina, Charlotte",10.1109/tvcg.2014.2346979;10.1109/tvcg.2019.2934287;10.1109/tvcg.2017.2743898;10.1109/tvcg.2018.2864889;10.1109/tvcg.2018.2864909;10.1109/tvcg.2015.2467671;10.1109/tvcg.2017.2745240;10.1109/tvcg.2010.177;10.1109/tvcg.2012.279;10.1109/tvcg.2012.199;10.1109/tvcg.2015.2467758;10.1109/tvcg.2013.153;10.1109/tvcg.2014.2346979,"Information visualization,Bayesian modeling,uncertainty visualizations,correlations,belief elicitation",22.0,14.0,59.0,911.0,,,correlation visualization uncertainty;models provide normative;different sets variables;incongruent;users update,0.6619;0.2804;0.1482;0.1320;0.0604,"[np.int64(-1), -1, -1, -1, -1]",37;-1;-1;-1;-1,37,37,Uncertainty Visualization
InfoVis,2007,VisLink: Revealing Relationships Amongst Visualizations,10.1109/tvcg.2007.70521,http://dx.doi.org/10.1109/TVCG.2007.70521,1192.0,1199.0,J,"We present VisLink, a method by which visualizations and the relationships between them can be interactively explored. VisLink readily generalizes to support multiple visualizations, empowers inter-representational queries, and enables the reuse of the spatial variables, thus supporting efficient information encoding and providing for powerful visualization bridging. Our approach uses multiple 2D layouts, drawing each one in its own plane. These planes can then be placed and re-positioned in 3D space: side by side, in parallel, or in chosen placements that provide favoured views. Relationships, connections, and patterns between visualizations can be revealed and explored using a variety of interaction techniques including spreading activation and search filters.",Christopher Collins 0001;Sheelagh Carpendale,Christopher Collins;Sheelagh Carpendale,"Computer Science Department, Univeristy of Toronto, Canada;Computer Science Department, University of Calgary, Canada",10.1109/visual.2003.1250400;10.1109/visual.1990.146402;10.1109/tvcg.2006.166;10.1109/visual.1991.175815;10.1109/infvis.2003.1249008;10.1109/infvis.2001.963279;10.1109/tvcg.2006.147;10.1109/visual.2003.1250400,"Graph visualization, node-link diagrams, structural comparison, hierarchies, 3D visualization, edge aggregation",275.0,139.0,22.0,1646.0,,,multiple visualizations empowers;vislink;positioned 3d space;search;including,0.7315;0.3305;0.2779;0.1259;0.0999,"[np.int64(1), -1, -1, -1, -1]",68;-1;-1;-1;-1,68,68,Visualization Techniques Comparison
VAST,2006,Exploring Large-Scale Video News via Interactive Visualization,10.1109/vast.2006.261433,http://dx.doi.org/10.1109/VAST.2006.261433,75.0,82.0,C,"In this paper, we have developed a novel visualization framework to enable more effective visual analysis of large-scale news videos, where keyframes and keywords are automatically extracted from news video clips and visually represented according to their interestingness measurement to help audiences rind news stories of interest at first glance. A computational approach is also developed to quantify the interestingness measurement of video clips. Our experimental results have shown that our techniques for intelligent news video analysis have the capacity to enable more effective visualization of large-scale news videos. Our news video visualization system is very useful for security applications and for general audiences to quickly find news topics of interest from among many channels",Hangzai Luo;Jianping Fan 0001;Jing Yang 0001;William Ribarsky;Shin'ichi Satoh 0001,Hangzai Luo;Jianping Fan;Jing Yang;William Ribarsky;Shin'ichi Satoh,"Department of Computer Science, UNC-Charlotte, Charlotte, NC, USA;Department of Computer Science, UNC-Charlotte, Charlotte, NC, USA;Department of Computer Science, UNC-Charlotte, Charlotte, NC, USA;Department of Computer Science, UNC-Charlotte, Charlotte, NC, USA;National Institute of Informatics (NII), Tokyo, Japan",10.1109/infvis.1998.729570;10.1109/infvis.2003.1249019;10.1109/visual.1991.175815;10.1109/infvis.1998.729570,"News Visualization, Semantic Video Classification",36.0,23.0,25.0,390.0,,,news video visualization;according interestingness;keywords automatically extracted;computational approach developed;capacity enable,0.7307;0.3640;0.2743;0.1352;-0.0199,"[np.int64(-1), np.int64(-1), -1, -1, -1]",85;55;-1;-1;-1,55;85,85,Dynamic Data Visualization
VAST,2015,Evolution inspector: Interactive visual analysis for evolutionary molecular design,10.1109/vast.2015.7347687,http://dx.doi.org/10.1109/VAST.2015.7347687,219.0,220.0,M,"De novo design is a computational-chemistry method, where a computer program utilizes an optimization method, in our case an evolutionary algorithm, to design compounds with desired chemical properties. The optimization is performed with respect to a quantity called fitness, defined by the chemists. We present a tool that connects interactive visual analysis and evolutionary algorithm-based molecular design. We employ linked views to communicate different aspects of the data: the statistical distribution of molecule fitness, connections between individual molecules during the evolution and 3D molecular structure. The application is already used by chemists to explore and analyze the results of their evolution experiments and has proved to be highly useful.",Veronika Soltészová;Marco Foscato;Sondre H. Eliasson;Vidar R. Jensen,Veronika Solteszova;Marco Foscato;Sondre H. Eliasson;Vidar R. Jensen,"Christian Michelsen Research, Bergen, Norway;Department of Chemistry, University of Bergen, Norway;Department of Chemistry, University of Bergen, Norway;Department of Chemistry, University of Bergen, Norway",0.1109/tvcg.2007.70535,,0.0,1.0,10.0,137.0,,,molecular design;evolution 3d;interactive visual analysis;called fitness defined;linked,0.6966;0.2911;0.2575;0.1502;0.0422,"[np.int64(-1), -1, -1, -1, -1]",27;-1;-1;-1;-1,27,27,Molecular Design Techniques
VAST,2014,Vismate: Interactive Visual Analysis of Station-Based Observation Data on Climate Changes,10.1109/vast.2014.7042489,http://dx.doi.org/10.1109/VAST.2014.7042489,133.0,142.0,C,"We present a new approach to visualizing the climate data of multi-dimensional, time-series, and geo-related characteristics. Our approach integrates three new highly interrelated visualization techniques, and uses the same input data types as in the traditional model-based analysis methods. As the main visualization view, Global Radial Map is used to identify the overall state of climate changes and provide users with a compact and intuitive view for analyzing spatial and temporal patterns at the same time. Other two visualization techniques, providing complementary views, are specialized in analysing time trend and detecting abnormal cases, which are two important analysis tasks in any climate change study. Case studies and expert reviews have been conducted, through which the effectiveness and scalability of the proposed approach has been confirmed.",Jie Li 0006;Kang Zhang 0001;Zhao-Peng Meng,Jie Li;Kang Zhang;Zhao-Peng Meng,"School of Computer Science and Technology, National Ocean Technology Center, Tianjin, China;Department of Computer Science, The University of Texas, Dallas, USA;School of Computer Software, Tianjin University, China",10.1109/vast.2012.6400491;10.1109/tvcg.2010.194;10.1109/infvis.2000.885098;10.1109/tvcg.2007.70523;10.1109/tvcg.2009.199;10.1109/tvcg.2010.183;10.1109/vast.2012.6400553;10.1109/tvcg.2010.180;10.1109/tvcg.2009.197;10.1109/tvcg.2008.187;10.1109/tvcg.2012.284;10.1109/vast.2012.6400491,"climate changes, spatiotemporal visualization, station-based observation data, radial layout, visual analytics",44.0,18.0,54.0,760.0,,,visualizing climate data;radial;compact intuitive;abnormal cases important;proposed approach confirmed,0.8036;0.1524;0.0719;0.0440;0.0041,"[np.int64(1), -1, -1, -1, -1]",82;-1;-1;-1;-1,82,82,Environmental Visualization
Vis,2023,Adaptive Assessment of Visualization Literacy,10.1109/tvcg.2023.3327165,http://dx.doi.org/10.1109/TVCG.2023.3327165,628.0,637.0,J,"Visualization literacy is an essential skill for accurately interpreting data to inform critical decisions. Consequently, it is vital to understand the evolution of this ability and devise targeted interventions to enhance it, requiring concise and repeatable assessments of visualization literacy for individuals. However, current assessments, such as the Visualization Literacy Assessment Test (vlat), are time-consuming due to their fixed, lengthy format. To address this limitation, we develop two streamlined computerized adaptive tests (cats) for visualization literacy, a-vlat and a-calvi, which measure the same set of skills as their original versions in half the number of questions. Specifically, we (1) employ item response theory (IRT) and non-psychometric constraints to construct adaptive versions of the assessments, (2) finalize the configurations of adaptation through simulation, (3) refine the composition of test items of a-calvi via a qualitative study, and (4) demonstrate the test-retest reliability (ICC: 0.98 and 0.98) and convergent validity (correlation: 0.81 and 0.66) of both CATS via four online studies. We discuss practical recommendations for using our CATS and opportunities for further customization to leverage the full potential of adaptive assessments. All supplemental materials are available at https://osf.io/a6258/.",Yuan Cui;Lily W. Ge;Yiren Ding;Fumeng Yang;Lane Harrison;Matthew Kay 0001,Yuan Cui;Lily W. Ge;Yiren Ding;Fumeng Yang;Lane Harrison;Matthew Kay,"Northwestern University, USA;Northwestern University, USA;Worcester Polytechnic Institute, USA;Northwestern University, USA;Worcester Polytechnic Institute, USA;Northwestern University, USA",0.1109/tvcg.2014.2346984;10.1109/tvcg.2016.2598920,"Visualization literacy,computerized adaptive testing,item response theory",,1.0,33.0,521.0,,,assessments visualization literacy;leverage potential adaptive;irt non;convergent validity;lengthy format address,0.7585;0.1419;0.1090;0.0266;-0.0747,"[np.int64(1), -1, -1, -1, -1]",69;-1;-1;-1;-1,69,69,Visualization User Studies
InfoVis,2020,Implicit Multidimensional Projection of Local Subspaces,10.1109/tvcg.2020.3030368,http://dx.doi.org/10.1109/TVCG.2020.3030368,1558.0,1568.0,J,"We propose a visualization method to understand the effect of multidimensional projection on local subspaces, using implicit function differentiation. Here, we understand the local subspace as the multidimensional local neighborhood of data points. Existing methods focus on the projection of multidimensional data points, and the neighborhood information is ignored. Our method is able to analyze the shape and directional information of the local subspace to gain more insights into the global structure of the data through the perception of local structures. Local subspaces are fitted by multidimensional ellipses that are spanned by basis vectors. An accurate and efficient vector transformation method is proposed based on analytical differentiation of multidimensional projections formulated as implicit functions. The results are visualized as glyphs and analyzed using a full set of specifically-designed interactions supported in our efficient web-based visualization tool. The usefulness of our method is demonstrated using various multi- and high-dimensional benchmark datasets. Our implicit differentiation vector transformation is evaluated through numerical comparisons; the overall method is evaluated through exploration examples and use cases.",Rongzheng Bian;Yumeng Xue;Liang Zhou 0001;Jian Zhang 0070;Baoquan Chen;Daniel Weiskopf;Yunhai Wang,Rongzheng Bian;Yumeng Xue;Liang Zhou;Jian Zhang;Baoquan Chen;Daniel Weiskopf;Yunhai Wang,"Shandong University, Qingdao;Shandong University, Qingdao;University of Utah;CNIC, CAS;Peking University;University of Stuttgart;Shandong University, Qingdao",10.1109/vast.2012.6400488;10.1109/tvcg.2015.2467717;10.1109/tvcg.2013.153;10.1109/tvcg.2016.2598495;10.1109/tvcg.2019.2934811;10.1109/tvcg.2011.220;10.1109/tvcg.2018.2865194;10.1109/tvcg.2007.70535;10.1109/vast.2010.5652460;10.1109/vast.2012.6400488,"High-dimensional data visualization,dimensionality reduction,local linear subspaces,user interaction",7.0,4.0,51.0,830.0,,,differentiation multidimensional projections;visualization tool usefulness;ellipses;understand local;ignored method able,0.6228;0.3539;0.2404;0.2315;-0.0581,"[np.int64(-1), np.int64(1), -1, -1, -1]",33;14;-1;-1;-1,14;33,33,Multidimensional Function Analysis
Vis,1999,DELTA's Virtual Physics Laboratory: a comprehensive learning platform on physics and astronomy,10.1109/visual.1999.809920,http://dx.doi.org/10.1109/VISUAL.1999.809920,421.0,423.0,C,"Perhaps the most effective instrument to simplify and to clarify the comprehension of any complex mathematical or scientific theory is through visualisation. Moreover using interactivity and 3D real time representations, one can easily explore and hence learn quickly in the virtual environments. The concept of virtual and safe laboratories has vast potentials in education. With the aid of computer simulations and 3D visualisations, many dangerous or cumbersome experiments may be implemented in the virtual environments, with rather small effort. Nonetheless visualisation alone is of little use if the respective simulation is not scientifically accurate. Hence a rigorous combination of precise computation as well as sophisticated visualisation, presented through some intuitive user interface is required to realise a virtual laboratory for education. We introduce Delta's Virtual Physics Laboratory, comprising a wide range of applications in the field of physics and astronomy, which can be implemented and used as an interactive learning tool on the World Wide Web.",Sepideh Chakaveh;Udo Zlender;Detlef Skaley;Konstantinos Fostiropoulos;Dieter Breitschwerdt,S. Chakaveh;U. Zlender;D. Skaley;K. Fostiropoulos;D. Breitschwerdt,"GMD Forschungszentrum Informationtechnik GmBH, German National Research Centre for Information Technology, IMK-DELTA, Saint Augustine, USA;GMD Forschungszentrum Informationtechnik GmBH, German National Research Centre for Information Technology, IMK-DELTA, Saint Augustine, USA;GMD Forschungszentrum Informationtechnik GmBH, German National Research Centre for Information Technology, IMK-DELTA, Saint Augustine, USA;;Max Planck Institut für Extraterrestrische Physik, Munich, Germany and Department of Physics & Astronomy, University of Heidelberg, Germany",,,,4.0,6.0,104.0,,,virtual physics laboratory;visualisation presented intuitive;astronomy;combination precise computation;nonetheless,0.7756;0.3729;0.3248;0.0794;0.0102,"[np.int64(-1), np.int64(1), -1, -1, -1]",25;10;-1;-1;-1,10;25,25,Fluid Dynamics Research
Vis,2024,DiffFit: Visually-Guided Differentiable Fitting of Molecule Structures to a Cryo-EM Map,10.1109/tvcg.2024.3456404,http://dx.doi.org/10.1109/TVCG.2024.3456404,558.0,568.0,J,"We introduce DiffFit, a differentiable algorithm for fitting protein atomistic structures into an experimental reconstructed Cryo-Electron Microscopy (cryo-EM) volume map. In structural biology, this process is necessary to semi-automatically composite large mesoscale models of complex protein assemblies and complete cellular structures that are based on measured cryo-EM data. The current approaches require manual fitting in three dimensions to start, resulting in approximately aligned structures followed by an automated fine-tuning of the alignment. The DiffFit approach enables domain scientists to fit new structures automatically and visualize the results for inspection and interactive revision. The fitting begins with differentiable three-dimensional (3D) rigid transformations of the protein atom coordinates followed by sampling the density values at the atom coordinates from the target cryo-EM volume. To ensure a meaningful correlation between the sampled densities and the protein structure, we proposed a novel loss function based on a multi-resolution volume-array approach and the exploitation of the negative space. This loss function serves as a critical metric for assessing the fitting quality, ensuring the fitting accuracy and an improved visualization of the results. We assessed the placement quality of DiffFit with several large, realistic datasets and found it to be superior to that of previous methods. We further evaluated our method in two use cases: automating the integration of known composite structures into larger protein complexes and facilitating the fitting of predicted protein domains into volume densities to aid researchers in identifying unknown proteins. We implemented our algorithm as an open-source plugin (github.com/nanovis/DiffFit) in ChimeraX, a leading visualization software in the field. All supplemental materials are available at osf. io/5tx4q.",Deng Luo;Zainab Alsuwaykit;Dawar Khan;Ondrej Strnad;Tobias Isenberg 0001;Ivan Viola,Deng Luo;Zainab Alsuwaykit;Dawar Khan;Ondřej Strnad;Tobias Isenberg;Ivan Viola,"Visual Computing Center at King Abdullah University of Science and Technology (KAUST), Saudi Arabia;Visual Computing Center at King Abdullah University of Science and Technology (KAUST), Saudi Arabia;Visual Computing Center at King Abdullah University of Science and Technology (KAUST), Saudi Arabia;Visual Computing Center at King Abdullah University of Science and Technology (KAUST), Saudi Arabia;Université Paris-Saclay, CNRS, Inria, LISN, France;Visual Computing Center at King Abdullah University of Science and Technology (KAUST), Saudi Arabia",10.1109/tvcg.2018.2864851;10.1109/tvcg.2020.3030415;10.1109/vast.2014.7042491;10.1109/tvcg.2015.2467293;10.1109/tvcg.2022.3209411,"Scalar field data,algorithms,genomics,cryo-EM,application-motivated visualization,process/workflow design,life sciences,health,medicine,biology,structural biology,bioinformatics",,0.0,52.0,308.0,,X,fitting protein atomistic;reconstructed cryo;leading visualization;necessary;differentiable dimensional,0.6115;0.3870;0.2166;0.0255;0.0219,"[np.int64(-1), np.int64(-1), -1, -1, -1]",27;-1;-1;-1;-1,27,27,Molecular Design Techniques
Vis,2002,Efficient simplification of point-sampled surfaces,10.1109/visual.2002.1183771,http://dx.doi.org/10.1109/VISUAL.2002.1183771,163.0,170.0,C,"We introduce, analyze and quantitatively compare a number of surface simplification methods for point-sampled geometry. We have implemented incremental and hierarchical clustering, iterative simplification, and particle simulation algorithms to create approximations of point-based models with lower sampling density. All these methods work directly on the point cloud, requiring no intermediate tesselation. We show how local variation estimation and quadric error metrics can be employed to diminish the approximation error and concentrate more samples in regions of high curvature. To compare the quality of the simplified surfaces, we have designed a new method for computing numerical and visual error estimates for point-sampled surfaces. Our algorithms are fast, easy to implement, and create high-quality surface approximations, clearly demonstrating the effectiveness of point-based surface simplification.",Mark Pauly;Markus H. Gross;Leif Kobbelt,M. Pauly;M. Gross;L.P. Kobbelt,"ETH Zurich, Switzerland;ETH Zurich, Switzerland;RWTH Aachen, Germany",10.1109/visual.2001.964503;10.1109/visual.1999.809896;10.1109/visual.2001.964502;10.1109/visual.2001.964489;10.1109/visual.2000.885722;10.1109/visual.2001.964503,,1370.0,340.0,32.0,4117.0,,,based surface simplification;particle simulation;error concentrate samples;point;local,0.6769;0.3500;0.1362;0.1139;0.0937,"[np.int64(-1), np.int64(-1), -1, -1, -1]",65;24;-1;-1;-1,24;65,65,Surface Reconstruction Techniques
Vis,1990,Applying space subdivision techniques to volume rendering,10.1109/visual.1990.146377,http://dx.doi.org/10.1109/VISUAL.1990.146377,150.0,,C,"The authors present a ray-tracing algorithm for volume rendering designed to work efficiently when the data of interest is distributed sparsely through the volume. A simple preprocessing step identifies the voxels representing features of interest. Frequently this set of voxels, arbitrarily distributed in three-dimensional space, is a small fraction of the original voxel grid. A median-cut space partitioning scheme, combined with bounding volumes to prune void spaces in the resulting search structure, is used to store the voxels of interest in a k-d tree. The k-d tree is used as a data structure. The tree is then efficiently ray-traced to render the voxel data. The k-d tree is view independent, and can be used for animation sequences involving changes in positions of the viewer or positions of lights. This search structure has been applied to render voxel data from MRI, CAT scan, and electron density distributions.&lt;&lt;ETX&gt;&gt;",Kalpathi R. Subramanian;Donald S. Fussell,K.R. Subramanian;D.S. Fussell,"Department of Computer Sciences, University of Texas, Austin, Austin, TX, USA;Department of Computer Sciences, University of Texas, Austin, Austin, TX, USA",,,139.0,20.0,21.0,163.0,,,volume rendering designed;tree used data;scan electron;independent used animation;authors,0.6821;0.2581;0.1895;0.1199;0.0323,"[np.int64(0), -1, -1, -1, -1]",0;-1;-1;-1;-1,0,0,Volume Rendering Techniques
SciVis,2017,Instant Construction and Visualization of Crowded Biological Environments,10.1109/tvcg.2017.2744258,http://dx.doi.org/10.1109/TVCG.2017.2744258,862.0,872.0,J,"We present the first approach to integrative structural modeling of the biological mesoscale within an interactive visual environment. These complex models can comprise up to millions of molecules with defined atomic structures, locations, and interactions. Their construction has previously been attempted only within a non-visual and non-interactive environment. Our solution unites the modeling and visualization aspect, enabling interactive construction of atomic resolution mesoscale models of large portions of a cell. We present a novel set of GPU algorithms that build the basis for the rapid construction of complex biological structures. These structures consist of multiple membrane-enclosed compartments including both soluble molecules and fibrous structures. The compartments are defined using volume voxelization of triangulated meshes. For membranes, we present an extension of the Wang Tile concept that populates the bilayer with individual lipids. Soluble molecules are populated within compartments distributed according to a Halton sequence. Fibrous structures, such as RNA or actin filaments, are created by self-avoiding random walks. Resulting overlaps of molecules are resolved by a forced-based system. Our approach opens new possibilities to the world of interactive construction of cellular compartments. We demonstrate its effectiveness by showcasing scenes of different scale and complexity that comprise blood plasma, mycoplasma, and HIV.",Tobias Klein;Ludovic Autin;Barbora Kozlíková;David S. Goodsell;Arthur J. Olson;M. Eduard Gröller;Ivan Viola,Tobias Klein;Ludovic Autin;Barbora Kozlíková;David S. Goodsell;Arthur Olson;M. Eduard Gröller;Ivan Viola,"TU Wien, Austria;The Scripps Research Institute, California, USA;Masaryk University, Brno, Czech Republic;The Scripps Research Institute, California, USA;The Scripps Research Institute, California, USA;TU Wien, VRVis Research Center, Austria;TU Wien, Austria",,"Interactive modeling,population,biological data,interactive visualization",37.0,35.0,49.0,1043.0,HM,,biological mesoscale interactive;gpu algorithms;plasma mycoplasma hiv;effectiveness showcasing scenes;build,0.6177;0.4216;0.1083;0.1040;0.0590,"[np.int64(-1), np.int64(-1), -1, -1, -1]",80;20;-1;-1;-1,20;80,80,Environmental Simulation Tools
InfoVis,2020,Modeling the Influence of Visual Density on Cluster Perception in Scatterplots Using Topology,10.1109/tvcg.2020.3030365,http://dx.doi.org/10.1109/TVCG.2020.3030365,1829.0,1839.0,J,"Scatterplots are used for a variety of visual analytics tasks, including cluster identification, and the visual encodings used on a scatterplot play a deciding role on the level of visual separation of clusters. For visualization designers, optimizing the visual encodings is crucial to maximizing the clarity of data. This requires accurately modeling human perception of cluster separation, which remains challenging. We present a multi-stage user study focusing on four factors-distribution size of clusters, number of points, size of points, and opacity of points-that influence cluster identification in scatterplots. From these parameters, we have constructed two models, a distance-based model, and a density-based model, using the merge tree data structure from Topological Data Analysis. Our analysis demonstrates that these factors play an important role in the number of clusters perceived, and it verifies that the distance-based and density-based models can reasonably estimate the number of clusters a user observes. Finally, we demonstrate how these models can be used to optimize visual encodings on real-world data.",Ghulam Jilani Quadri;Paul Rosen 0001,Ghulam Jilani Quadri;Paul Rosen,University of South Florida;University of South Florida,10.1109/vast.2014.7042493;10.1109/infvis.2005.1532136;10.1109/tvcg.2014.2346594;10.1109/tvcg.2019.2934541;10.1109/tvcg.2018.2864907;10.1109/tvcg.2014.2346572;10.1109/tvcg.2007.70535;10.1109/tvcg.2013.183;10.1109/tvcg.2014.2346983;10.1109/tvcg.2014.2346979;10.1109/tvcg.2019.2934799;10.1109/tvcg.2017.2744339;10.1109/tvcg.2017.2744184;10.1109/tvcg.2017.2744359;10.1109/infvis.2005.1532142;10.1109/vast.2014.7042493,"Scatterplot,clustering,perception,empirical evaluation,visual encoding,crowdsourcing,topological data analysis",5.0,16.0,88.0,737.0,,,clusters visualization;opacity points influence;encodings;models reasonably estimate;play important,0.7490;0.1676;0.1076;0.0878;0.0398,"[np.int64(-1), -1, -1, -1, -1]",46;-1;-1;-1;-1,46,46,Cluster Visualization
Vis,1990,A procedural interface for volume rendering,10.1109/visual.1990.146362,http://dx.doi.org/10.1109/VISUAL.1990.146362,36.0,,C,"The author presents a simple, procedural interface for volume rendering. The interface is built on three types of objects: volumes, which contain the data to be visualized, environments, which set up viewing and lighting, and image objects, which convert results to a user-definable format. A volume is rendered against a particular environment with the results sent to an image object for conversion. By defining volume qualities such as color, opacity, and gradient in terms of user-definable transfer functions, the rendering process is made independent of the data set's underlying representation.&lt;&lt;ETX&gt;&gt;",James L. Montine,J.L. Montine,"Alliant Computer Systems Corporation, Littleton, MA, USA",,,18.0,3.0,9.0,71.0,,,volume rendering interface;lighting image objects;procedural;defining;convert results user,0.8052;0.3039;0.2655;0.0681;0.0542,"[np.int64(0), -1, -1, -1, -1]",0;-1;-1;-1;-1,0,0,Volume Rendering Techniques
Vis,2022,FlowNL: Asking the Flow Data in Natural Languages,10.1109/tvcg.2022.3209453,http://dx.doi.org/10.1109/TVCG.2022.3209453,1200.0,1210.0,J,"Flow visualization is essentially a tool to answer domain experts' questions about flow fields using rendered images. Static flow visualization approaches require domain experts to raise their questions to visualization experts, who develop specific techniques to extract and visualize the flow structures of interest. Interactive visualization approaches allow domain experts to ask the system directly through the visual analytic interface, which provides flexibility to support various tasks. However, in practice, the visual analytic interface may require extra learning effort, which often discourages domain experts and limits its usage in real-world scenarios. In this paper, we propose FlowNL, a novel interactive system with a natural language interface. FlowNL allows users to manipulate the flow visualization system using plain English, which greatly reduces the learning effort. We develop a natural language parser to interpret user intention and translate textual input into a declarative language. We design the declarative language as an intermediate layer between the natural language and the programming language specifically for flow visualization. The declarative language provides selection and composition rules to derive relatively complicated flow structures from primitive objects that encode various kinds of information about scalar fields, flow patterns, regions of interest, connectivities, etc. We demonstrate the effectiveness of FlowNL using multiple usage scenarios and an empirical evaluation.",Jieying Huang;Yang Xi;Junnan Hu;Jun Tao 0002,Jieying Huang;Yang Xi;Junnan Hu;Jun Tao,"School of Computer Science and Engineering, Sun Yat-sen University, China;School of Computer Science and Engineering, Sun Yat-sen University, China;School of Computer Science and Engineering, Sun Yat-sen University, China;Southern Marine Science and Engineering Guangdong Laboratory (Zhuhai), School of Computer Science and Engineering, Sun Yat-sen University, National Supercomputer Center in Guangzhou, China",10.1109/tvcg.2019.2934310;10.1109/tvcg.2011.185;10.1109/visual.2005.1532856;10.1109/tvcg.2014.2346322;10.1109/tvcg.2019.2934785;10.1109/tvcg.2017.2744684;10.1109/tvcg.2013.121;10.1109/tvcg.2018.2864806;10.1109/tvcg.2013.189;10.1109/tvcg.2019.2934537;10.1109/tvcg.2020.3030453;10.1109/tvcg.2021.3114848;10.1109/tvcg.2020.3030378;10.1109/tvcg.2020.3030378;10.1109/tvcg.2019.2934367;10.1109/tvcg.2014.2346318;10.1109/visual.2004.128;10.1109/tvcg.2016.2599030;10.1109/tvcg.2015.2467091;10.1109/tvcg.2017.2745219;10.1109/visual.2003.1250376;10.1109/vast47406.2019.8986918;10.1109/tvcg.2018.2864841;10.1109/tvcg.2010.131;10.1109/visual.2005.1532831;10.1109/tvcg.2019.2934668;10.1109/tvcg.2019.2934310,"Flow visualization,natural language interface,interactive exploration,declarative grammar",,7.0,59.0,956.0,,,flow visualization declarative;translate textual input;using rendered images;experts raise;require domain,0.7705;0.2371;0.1520;0.1073;0.0361,"[np.int64(-1), -1, -1, -1, -1]",66;-1;-1;-1;-1,66,66,Flow Visualization Techniques
Vis,2008,AD-Frustum: Adaptive Frustum Tracing for Interactive Sound Propagation,10.1109/tvcg.2008.111,http://dx.doi.org/10.1109/TVCG.2008.111,1707.0,1722.0,J,"We present an interactive algorithm to compute sound propagation paths for transmission, specular reflection and edge diffraction in complex scenes. Our formulation uses an adaptive frustum representation that is automatically sub-divided to accurately compute intersections with the scene primitives. We describe a simple and fast algorithm to approximate the visible surface for each frustum and generate new frusta based on specular reflection and edge diffraction. Our approach is applicable to all triangulated models and we demonstrate its performance on architectural and outdoor models with tens or hundreds of thousands of triangles and moving objects. In practice, our algorithm can perform geometric sound propagation in complex scenes at 4-20 frames per second on a multi-core PC.",Anish Chandak;Christian Lauterbach;Micah T. Taylor;Zhimin Ren;Dinesh Manocha,Anish Chandak;Christian Lauterbach;Micah Taylor;Zhimin Ren;Dinesh Manocha,"University of North Carolina at Chapel Hill, Chapel Hill, NC, US;University of North Carolina at Chapel Hill, Chapel Hill, NC, US;University of North Carolina at Chapel Hill, Chapel Hill, NC, US;University of North Carolina at Chapel Hill, Chapel Hill, NC, US;University of North Carolina at Chapel Hill, Chapel Hill, NC, US",10.1109/tvcg.2007.70575;10.1109/tvcg.2006.125;10.1109/visual.2005.1532790;10.1109/tvcg.2008.111;10.1109/tvcg.2007.70567;10.1109/tvcg.2007.70575,"Sound propagation, interactive system, auralization",122.0,58.0,43.0,465.0,,,geometric sound propagation;intersections scene primitives;demonstrate performance architectural;frusta;tens hundreds thousands,0.6170;0.3631;0.2319;0.2022;0.0274,"[np.int64(-1), np.int64(-1), -1, -1, -1]",39;77;-1;-1;-1,39;77,39,Sound Propagation Modeling
Vis,2023,Perception of Line Attributes for Visualization,10.1109/tvcg.2023.3326523,http://dx.doi.org/10.1109/TVCG.2023.3326523,1041.0,1051.0,J,"Line attributes such as width and dashing are commonly used to encode information. However, many questions on the perception of line attributes remain, such as how many levels of attribute variation can be distinguished or which line attributes are the preferred choices for which tasks. We conducted three studies to develop guidelines for using stylized lines to encode scalar data. In our first study, participants drew stylized lines to encode uncertainty information. Uncertainty is usually visualized alongside other data. Therefore, alternative visual channels are important for the visualization of uncertainty. Additionally, uncertainty—e.g., in weather forecasts—is a familiar topic to most people. Thus, we picked it for our visualization scenarios in study 1. We used the results of our study to determine the most common line attributes for drawing uncertainty: Dashing, luminance, wave amplitude, and width. While those line attributes were especially common for drawing uncertainty, they are also commonly used in other areas. In studies 2 and 3, we investigated the discriminability of the line attributes determined in study 1. Studies 2 and 3 did not require specific application areas; thus, their results apply to visualizing any scalar data in line attributes. We evaluated the just-noticeable differences (JND) and derived recommendations for perceptually distinct line levels. We found that participants could discriminate considerably more levels for the line attribute width than for wave amplitude, dashing, or luminance.",Anna Sterzik;Nils Lichtenberg;Jana Wilms;Michael Krone;Douglas W. Cunningham;Kai Lawonn,Anna Sterzik;Nils Lichtenberg;Jana Wilms;Michael Krone;Douglas W. Cunningham;Kai Lawonn,"University of Jena, Germany;University of Tübingen, Germany;University of Jena, Germany;University of Tübingen, Germany;Brandenburg University of Technology, Germany;University of Jena, Germany",0.1109/tvcg.2012.220;10.1109/tvcg.2017.2743959;10.1109/tvcg.2015.2467671;10.1109/tvcg.2012.279;10.1109/tvcg.2015.2467591;10.1109/tvcg.2016.2598826;10.1109/tvcg.2023.3326574,"Line Drawings,Line Stylization,Perceptual Evaluation,Uncertainty Visualization",,1.0,48.0,326.0,,,lines encode uncertainty;visualization scenarios study;drew stylized;attributes preferred choices;require specific application,0.6815;0.4231;0.3610;0.2596;-0.0785,"[np.int64(-1), np.int64(1), np.int64(-1), -1, -1]",37;68;36;-1;-1,36;37;68,37,Uncertainty Visualization
InfoVis,2000,A scalable framework for information visualization,10.1109/infvis.2000.885088,http://dx.doi.org/10.1109/INFVIS.2000.885088,27.0,36.0,C,"The paper describes major concepts of a scalable information visualization framework. We assume that the exploration of heterogeneous information spaces at arbitrary levels of detail requires a suitable preprocessing of information quantities, the combination of different graphical interfaces and the illustration of the frame of reference of given information sets. The innovative features of our system include: dynamic hierarchy computation and user controlled refinement of those hierarchies for preprocessing unstructured information spaces; a new Focus+Context technique for visualizing complex hierarchy graphs; a new paradigm for visualizing information structures within their frame of reference; and a new graphical interface that utilizes textual similarities to arrange objects of high dimensional information space in 3-dimensional visualization space.",Matthias Kreuseler;Norma López;Heidrun Schumann,M. Kreuseler;N. Lopez;H. Schumann,"Department of Computer Science, University of Rostock, Rostock, Germany;Department of Computer Science, University of Rostock, Rostock, Germany;Department of Computer Science, University of Rostock, Rostock, Germany",10.1109/visual.1990.146402;10.1109/infvis.1997.636759;10.1109/visual.1996.567745;10.1109/visual.1997.663916;10.1109/infvis.1995.528686;10.1109/infvis.1995.528691;10.1109/infvis.1998.729555;10.1109/visual.1991.175815;10.1109/infvis.1998.729559,,114.0,23.0,25.0,534.0,,,visualizing information structures;new focus context;user controlled;suitable preprocessing information;assume,0.7851;0.2440;0.1524;0.1400;-0.0171,"[np.int64(1), -1, -1, -1, -1]",13;-1;-1;-1;-1,13,13,Information Visualization
Vis,2001,User-centric viewpoint computation for haptic exploration and manipulation,10.1109/visual.2001.964526,http://dx.doi.org/10.1109/VISUAL.2001.964526,311.0,318.0,C,"We present several techniques for user-centric viewing of the virtual objects or datasets under haptic exploration and manipulation. Depending on the type of tasks performed by the user, our algorithms compute automatic placement of the user viewpoint to navigate through the scene, to display the near-optimal views, and to reposition the viewpoint for haptic visualization. This is accomplished by conjecturing the user's intent based on the user's actions, the object geometry, and intra- and inter-object occlusion relationships. These algorithms have been implemented and interfaced with both a 3-DOF and a 6-DOF PHANToM arms. We demonstrate their application on haptic exploration and visualization of a complex structure, as well as multiresolution modeling and 3D painting with a haptic interface.",Miguel A. Otaduy;Ming C. Lin,M.A. Otaduy;M.C. Lin,"Department of Computer Science, University of North Carolina, Chapel Hill, USA;Department of Computer Science, University of North Carolina, Chapel Hill, USA",10.1109/visual.2000.885686;10.1109/visual.1996.568108;10.1109/visual.2000.885686,,22.0,10.0,33.0,102.0,,,viewpoint haptic visualization;user actions object;dof dof phantom;multiresolution;algorithms compute automatic,0.7477;0.2361;0.1876;0.1765;0.1116,"[np.int64(1), -1, -1, -1, -1]",2;-1;-1;-1;-1,2,2,Advanced Visualization Techniques
Vis,2021,STNet: An End-to-End Generative Framework for Synthesizing Spatiotemporal Super-Resolution Volumes,10.1109/tvcg.2021.3114815,http://dx.doi.org/10.1109/TVCG.2021.3114815,270.0,280.0,J,"We present STNet, an end-to-end generative framework that synthesizes spatiotemporal super-resolution volumes with high fidelity for time-varying data. STNet includes two modules: a generator and a spatiotemporal discriminator. The input to the generator is two low-resolution volumes at both ends, and the output is the intermediate and the two-ending spatiotemporal super-resolution volumes. The spatiotemporal discriminator, leveraging convolutional long short-term memory, accepts a spatiotemporal super-resolution sequence as input and predicts a conditional score for each volume based on its spatial (the volume itself) and temporal (the previous volumes) information. We propose an unsupervised pre-training stage using cycle loss to improve the generalization of STNet. Once trained, STNet can generate spatiotemporal super-resolution volumes from low-resolution ones, offering scientists an option to save data storage (i.e., sparsely sampling the simulation output in both spatial and temporal dimensions). We compare STNet with the baseline bicubic+linear interpolation, two deep learning solutions (<inline-formula><tex-math notation=""LaTeX"">$\mathsf{SSR}+\mathsf{TSF}$</tex-math><alternatives><graphic orientation=""portrait"" position=""float"" xlink:href=""28tvcg01-han-3114815-eqinline-1-small.tif"" xmlns:xlink=""http://www.w3.org/1999/xlink""/></alternatives></inline-formula>, STD), and a state-of-the-art tensor compression solution (TTHRESH) to show the effectiveness of STNet.",Jun Han 0010;Hao Zheng 0006;Danny Z. Chen;Chaoli Wang 0001,Jun Han;Hao Zheng;Danny Z. Chen;Chaoli Wang,"Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, USA;Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, USA;Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, USA;Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, USA",10.1109/tvcg.2019.2934332;10.1109/tvcg.2020.3030344;10.1109/tvcg.2019.2934255;10.1109/tvcg.2020.3030346;10.1109/tvcg.2019.2934312;10.1109/tvcg.2006.143;10.1109/tvcg.2019.2934375;10.1109/tvcg.2019.2934332,"Time-varying data,generative adversarial network,spatiotemporal super-resolution",15.0,30.0,65.0,1183.0,,,spatiotemporal super resolution;stnet generate;volumes information;cycle loss;input predicts conditional,0.5764;0.2813;0.2548;0.2193;0.1659,"[np.int64(-1), -1, -1, -1, -1]",81;-1;-1;-1;-1,81,81,Multiresolution Techniques
VAST,2013,Interactive Exploration of Implicit and Explicit Relations in Faceted Datasets,10.1109/tvcg.2013.167,http://dx.doi.org/10.1109/TVCG.2013.167,2080.0,2089.0,J,"Many datasets, such as scientific literature collections, contain multiple heterogeneous facets which derive implicit relations, as well as explicit relational references between data items. The exploration of this data is challenging not only because of large data scales but also the complexity of resource structures and semantics. In this paper, we present PivotSlice, an interactive visualization technique which provides efficient faceted browsing as well as flexible capabilities to discover data relationships. With the metaphor of direct manipulation, PivotSlice allows the user to visually and logically construct a series of dynamic queries over the data, based on a multi-focus and multi-scale tabular view that subdivides the entire dataset into several meaningful parts with customized semantics. PivotSlice further facilitates the visual exploration and sensemaking process through features including live search and integration of online data, graphical interaction histories and smoothly animated visual state transitions. We evaluated PivotSlice through a qualitative lab study with university researchers and report the findings from our observations and interviews. We also demonstrate the effectiveness of PivotSlice using a scenario of exploring a repository of information visualization literature.",Jian Zhao 0010;Christopher Collins 0001;Fanny Chevalier;Ravin Balakrishnan,Jian Zhao;Christopher Collins;Fanny Chevalier;Ravin Balakrishnan,"University of Toronto, Canada;Institute of Technology, University of Ontario, Canada;University of Toronto, Toronto, ON, CA;University of Toronto, Canada",10.1109/tvcg.2008.137;10.1109/vast.2011.6102440;10.1109/tvcg.2011.213;10.1109/tvcg.2010.154;10.1109/vast.2006.261426;10.1109/infvis.2005.1532136;10.1109/tvcg.2010.205;10.1109/tvcg.2012.252;10.1109/tvcg.2006.166;10.1109/infvis.2000.885086;10.1109/tvcg.2009.108;10.1109/infvis.2004.64;10.1109/tvcg.2008.137,"Faceted browsing, network exploration, dynamic query, interaction, information visualization, visual analytics",120.0,76.0,39.0,1487.0,,,information visualization literature;evaluated pivotslice;implicit relations;study university;allows,0.6158;0.2549;0.2241;0.1012;0.0227,"[np.int64(1), -1, -1, -1, -1]",13;-1;-1;-1;-1,13,13,Information Visualization
InfoVis,2004,Information Visualization Research: Citation and Co-Citation Highlights,10.1109/infvis.2004.38,http://dx.doi.org/10.1109/INFVIS.2004.38,,,M,An overview of the entry is given. The techniques used to prepare the InfoVis contest entry are outlined. The strengths and weaknesses are briefly discussed.,Chaomei Chen,Chaomei Chen,"Drexel University, USA",,,5.0,0.0,4.0,146.0,,,prepare infovis contest;entry outlined;overview;weaknesses briefly discussed;used,0.8292;0.3665;0.2941;0.2512;0.1218,"[np.int64(-1), np.int64(-1), -1, -1, -1]",55;23;-1;-1;-1,23;55,55,Information Visualization Preparation
Vis,2002,Geometric verification of swirling features in flow fields,10.1109/visual.2002.1183789,http://dx.doi.org/10.1109/VISUAL.2002.1183789,307.0,314.0,C,"In this paper, we present a verification algorithm for swirling features in flow fields, based on the geometry of streamlines. The features of interest in this case are vortices. Without a formal definition, existing detection algorithms lack the ability to accurately identify these features, and the current method for verifying the accuracy of their results is by human visual inspection. Our verification algorithm addresses this issue by automating the visual inspection process. It is based on identifying the swirling streamlines that surround the candidate vortex cores. We apply our algorithm to both numerically simulated and procedurally generated datasets to illustrate the efficacy of our approach.",Ming Jiang 0005;Raghu Machiraju;David S. Thompson,Ming Jiang;R. Machiraju;D. Thompson,"Ohio State Uinversity, USA;Ohio State Uinversity, USA;Mississippi State University, USA",10.1109/visual.1999.809896;10.1109/visual.1998.745333;10.1109/visual.1998.745296;10.1109/visual.1993.398877;10.1109/visual.1999.809896,"feature verification, vortex detection, flow field visualization",76.0,22.0,19.0,190.0,,,based identifying swirling;inspection verification;features case;definition;addresses issue automating,0.6849;0.3272;0.0763;0.0204;-0.0038,"[np.int64(-1), -1, -1, -1, -1]",30;-1;-1;-1;-1,30,30,Concept Drift Detection
VAST,2007,Visual Analysis of Dynamic Networks with Geological Clustering,10.1109/vast.2007.4389027,http://dx.doi.org/10.1109/VAST.2007.4389027,221.0,222.0,M,"Many dynamic networks have associated geological information. Here we present two complementing visual analysis methods for such networks. The first one provides an overview with summerized information while the second one presents a more detailed view. The geological information is encoded in the network layout, which is designed to help maintain user's mental map. We also combined visualization with social network analysis to facilitate knowledge discovery, especially to understand network changes in the context overall evolution. Both methods are applied to the ""History of the FIFA World Cup Competition"" data set.",Adel Ahmed;Xiaoyan Fu;Seok-Hee Hong 0001;Quan Hoang Nguyen 0001;Kai Xu 0003,Adel Ahmed;Xiaoyan Fu;Seok-Hee Hong;Quan Hoang Nguyen;Kai Xu,"School of Information Technologies, University of Sydney, Australia and NICTA, Australia;NICTA, Australia;School of Information Technologies, University of Sydney, Australia;School of Computer Sciences and Engineering, University of New South Wales, Australia;NICTA, Australia",0.1109/tvcg.2006.166;10.1109/tvcg.2006.122,,3.0,1.0,7.0,194.0,,,visualization social network;geological information;fifa;evolution methods applied;changes context overall,0.6821;0.4418;0.1423;0.1017;0.0929,"[np.int64(1), np.int64(-1), -1, -1, -1]",5;21;-1;-1;-1,5;21,5,Social Network Visualization
InfoVis,2011,DICON: Interactive Visual Analysis of Multidimensional Clusters,10.1109/tvcg.2011.188,http://dx.doi.org/10.1109/TVCG.2011.188,2581.0,2590.0,J,"Clustering as a fundamental data analysis technique has been widely used in many analytic applications. However, it is often difficult for users to understand and evaluate multidimensional clustering results, especially the quality of clusters and their semantics. For large and complex data, high-level statistical information about the clusters is often needed for users to evaluate cluster quality while a detailed display of multidimensional attributes of the data is necessary to understand the meaning of clusters. In this paper, we introduce DICON, an icon-based cluster visualization that embeds statistical information into a multi-attribute display to facilitate cluster interpretation, evaluation, and comparison. We design a treemap-like icon to represent a multidimensional cluster, and the quality of the cluster can be conveniently evaluated with the embedded statistical information. We further develop a novel layout algorithm which can generate similar icons for similar clusters, making comparisons of clusters easier. User interaction and clutter reduction are integrated into the system to help users more effectively analyze and refine clustering results for large datasets. We demonstrate the power of DICON through a user study and a case study in the healthcare domain. Our evaluation shows the benefits of the technique, especially in support of complex multidimensional cluster analysis.",Nan Cao 0001;David Gotz;Jimeng Sun 0001;Huamin Qu,Nan Cao;David Gotz;Jimeng Sun;Huamin Qu,"Department of Computer Science and Engineering, Hong Kong University of Science and Technology, Hong Kong, China;IBM Thomas J. Watson Research Center, USA;IBM Thomas J. Watson Research Center, USA;Department of Computer Science and Engineering, Hong Kong University of Science and Technology, Hong Kong, China",10.1109/infvis.2005.1532128;10.1109/tvcg.2006.147;10.1109/tvcg.2009.179;10.1109/visual.1995.485141;10.1109/tvcg.2007.70582;10.1109/visual.1990.146402;10.1109/vast.2009.5332628;10.1109/infvis.2001.963283;10.1109/infvis.1998.729559;10.1109/tvcg.2010.216;10.1109/visual.1999.809866;10.1109/tvcg.2008.153;10.1109/tvcg.2008.165;10.1109/tvcg.2009.153;10.1109/infvis.2005.1532128,"Visual Analysis, Clustering, Information Visualization",155.0,93.0,40.0,2696.0,,,cluster visualization;introduce dicon icon;applications difficult users;conveniently evaluated embedded;healthcare domain,0.7219;0.2777;0.1504;0.1362;0.1267,"[np.int64(-1), -1, -1, -1, -1]",46;-1;-1;-1;-1,46,46,Cluster Visualization
SciVis,2020,A Fluid Flow Data Set for Machine Learning and its Application to Neural Flow Map Interpolation,10.1109/tvcg.2020.3028947,http://dx.doi.org/10.1109/TVCG.2020.3028947,1279.0,1289.0,J,"In recent years, deep learning has opened countless research opportunities across many different disciplines. At present, visualization is mainly applied to explore and explain neural networks. Its counterpart-the application of deep learning to visualization problems-requires us to share data more openly in order to enable more scientists to engage in data-driven research. In this paper, we construct a large fluid flow data set and apply it to a deep learning problem in scientific visualization. Parameterized by the Reynolds number, the data set contains a wide spectrum of laminar and turbulent fluid flow regimes. The full data set was simulated on a high-performance compute cluster and contains 8000 time-dependent 2D vector fields, accumulating to more than 16 TB in size. Using our public fluid data set, we trained deep convolutional neural networks in order to set a benchmark for an improved post-hoc Lagrangian fluid flow analysis. In in-situ settings, flow maps are exported and interpolated in order to assess the transport characteristics of time-dependent fluids. Using deep learning, we improve the accuracy of flow map interpolations, allowing a more precise flow analysis at a reduced memory IO footprint.",Jakob Jakob;Markus Gross 0001;Tobias Günther,Jakob Jakob;Markus Gross;Tobias Günther,"ETH Zurich, Switzerland;ETH Zurich, Switzerland;ETH Zurich, Switzerland",10.1109/tvcg.2013.128;10.1109/tvcg.2019.2934332;10.1109/tvcg.2007.70551;10.1109/tvcg.2019.2934255;10.1109/tvcg.2019.2934312;10.1109/tvcg.2019.2934335;10.1109/tvcg.2007.70554;10.1109/tvcg.2013.128,"Scientific visualization,deep learning,flow maps",24.0,24.0,73.0,1932.0,,,deep learning visualization;fluid flow regimes;8000 time dependent;public;set contains,0.5911;0.4421;0.1663;0.0506;-0.0378,"[np.int64(-1), np.int64(-1), -1, -1, -1]",41;25;-1;-1;-1,25;41,41,Deep Learning Models
Vis,2002,Probabilistic surfaces: point based primitives to show surface uncertainty,10.1109/visual.2002.1183769,http://dx.doi.org/10.1109/VISUAL.2002.1183769,147.0,153.0,C,"Efficient and informative visualization of surfaces with uncertainties is an important topic with many applications in science and engineering. Examples include environmental pollution borderline identification, identification of the limits of an oil basin, or discrimination between contaminated and healthy tissue in medicine. This paper presents an approach for such visualization using points as display primitives. The approach is to render each polygon as a collection of points and to displace each point from the surface in the direction of the surface normal by an amount proportional to some random number multiplied by the uncertainty level at that point. This approach can be used in combination with other techniques such as pseudo-coloring and shading to give rise to efficient and revealing visualizations. The method is used to visualize real and simulated tumor formations with uncertainty of tumor boundaries.",Gevorg Grigoryan;Penny Rheingans,G. Grigoryan;P. Rheingans,"University of Maryland, Baltimore, USA;University of Maryland, Baltimore, USA",10.1109/visual.1996.568105;10.1109/visual.2000.885679;10.1109/visual.2001.964492;10.1109/visual.1995.480802;10.1109/visual.1995.480798;10.1109/visual.1996.568105,"uncertainty, visualizing surface uncertainty, points as display primitives",65.0,17.0,18.0,197.0,,,visualization surfaces uncertainties;techniques pseudo coloring;polygon collection;tumor;important topic applications,0.6172;0.3416;0.3234;0.2040;0.0817,"[np.int64(-1), -1, -1, -1, -1]",37;-1;-1;-1;-1,37,37,Uncertainty Visualization
VAST,2016,GazeDx: Interactive Visual Analytics Framework for Comparative Gaze Analysis with Volumetric Medical Images,10.1109/tvcg.2016.2598796,http://dx.doi.org/10.1109/TVCG.2016.2598796,311.0,320.0,J,"We present an interactive visual analytics framework, GazeDx (abbr. of GazeDiagnosis), for the comparative analysis of gaze data from multiple readers examining volumetric images while integrating important contextual information with the gaze data. Gaze pattern comparison is essential to understanding how radiologists examine medical images, and to identifying factors influencing the examination. Most prior work depended upon comparisons with manually juxtaposed static images of gaze tracking results. Comparative gaze analysis with volumetric images is more challenging due to the additional cognitive load on 3D perception. A recent study proposed a visualization design based on direct volume rendering (DVR) for visualizing gaze patterns in volumetric images; however, effective and comprehensive gaze pattern comparison is still challenging due to a lack of interactive visualization tools for comparative gaze analysis. We take the challenge with GazeDx while integrating crucial contextual information such as pupil size and windowing into the analysis process for more in-depth and ecologically valid findings. Among the interactive visualization components in GazeDx, a context-embedded interactive scatterplot is especially designed to help users examine abstract gaze data in diverse contexts by embedding medical imaging representations well known to radiologists in it. We present the results from two case studies with two experienced radiologists, where they compared the gaze patterns of 14 radiologists reading two patients' volumetric CT images.",Hyunjoo Song;Jeongjin Lee;Tae Jung Kim;Kyoung Ho Lee;Bo Hyoung Kim;Jinwook Seo,Hyunjoo Song;Jeongjin Lee;Tae Jung Kim;Kyoung Ho Lee;Bohyoung Kim;Jinwook Seo,"Seoul National University;Soongsil University;Samsung Medical Center;Bundang Hospital, Seoul National University;Hankuk University of Foreign Studies;Seoul National University",10.1109/vast.2011.6102435;10.1109/tvcg.2010.149;10.1109/vast.2011.6102435,Eye tracking;gaze visualization;gaze pattern comparison;volumetric medical images;context-embedded interactive scatterplot;interactive temporal chart,17.0,21.0,32.0,1122.0,,,visualizing gaze patterns;patients volumetric ct;context embedded interactive;compared;ecologically valid,0.7186;0.4710;0.2223;0.1715;0.0198,"[np.int64(1), np.int64(-1), -1, -1, -1]",62;49;-1;-1;-1,49;62,62,Visual Perception Analysis
InfoVis,2016,Iterating between Tools to Create and Edit Visualizations,10.1109/tvcg.2016.2598609,http://dx.doi.org/10.1109/TVCG.2016.2598609,481.0,490.0,J,"A common workflow for visualization designers begins with a generative tool, like D3 or Processing, to create the initial visualization; and proceeds to a drawing tool, like Adobe Illustrator or Inkscape, for editing and cleaning. Unfortunately, this is typically a one-way process: once a visualization is exported from the generative tool into a drawing tool, it is difficult to make further, data-driven changes. In this paper, we propose a bridge model to allow designers to bring their work back from the drawing tool to re-edit in the generative tool. Our key insight is to recast this iteration challenge as a merge problem - similar to when two people are editing a document and changes between them need to reconciled. We also present a specific instantiation of this model, a tool called Hanpuku, which bridges between D3 scripts and Illustrator. We show several examples of visualizations that are iteratively created using Hanpuku in order to illustrate the flexibility of the approach. We further describe several hypothetical tools that bridge between other visualization tools to emphasize the generality of the model.",Alex Bigelow;Steven Mark Drucker;Danyel Fisher;Miriah D. Meyer,Alex Bigelow;Steven Drucker;Danyel Fisher;Miriah Meyer,University of Utah;Microsoft Research;Microsoft Research;University of Utah,10.1109/tvcg.2014.2346292;10.1109/tvcg.2015.2467191;10.1109/tvcg.2014.2346291;10.1109/tvcg.2015.2467091;10.1109/infvis.2004.12;10.1109/tvcg.2011.209;10.1109/tvcg.2007.70584;10.1109/tvcg.2011.185;10.1109/tvcg.2014.2346292,illustration;Visualization;iteration,49.0,39.0,32.0,1225.0,,,visualization designers;bridges d3 scripts;merge;editing document changes;using hanpuku order,0.6331;0.2923;0.2921;0.2049;0.1487,"[np.int64(1), -1, -1, -1, -1]",15;-1;-1;-1;-1,15,15,Visualization Design
VAST,2009,Interactive visual clustering of large collections of trajectories,10.1109/vast.2009.5332584,http://dx.doi.org/10.1109/VAST.2009.5332584,3.0,10.0,C,"One of the most common operations in exploration and analysis of various kinds of data is clustering, i.e. discovery and interpretation of groups of objects having similar properties and/or behaviors. In clustering, objects are often treated as points in multi-dimensional space of properties. However, structurally complex objects, such as trajectories of moving entities and other kinds of spatio-temporal data, cannot be adequately represented in this manner. Such data require sophisticated and computationally intensive clustering algorithms, which are very hard to scale effectively to large datasets not fitting in the computer main memory. We propose an approach to extracting meaningful clusters from large databases by combining clustering and classification, which are driven by a human analyst through an interactive visual interface.",Gennady L. Andrienko;Natalia V. Andrienko;Salvatore Rinzivillo;Mirco Nanni;Dino Pedreschi;Fosca Giannotti,Gennady Andrienko;Natalia Andrienko;Salvatore Rinzivillo;Mirco Nanni;Dino Pedreschi;Fosca Giannotti,"Fraunhofer Institute of Intelligent Analysis and Information Systems (IAIS), Sankt Augustin, Germany;Fraunhofer Institute of Intelligent Analysis and Information Systems (IAIS), Sankt Augustin, Germany;KDD Lab-ISTI-CNR, Pisa, Italy;KDD Lab-ISTI-CNR, Pisa, Italy;University of Pisa, Pisa, Italy;KDD Lab-ISTI-CNR, Pisa, Italy",10.1109/vast.2008.4677356;10.1109/vast.2007.4388999;10.1109/vast.2008.4677356,"Spatio-temporal data, movement data, trajectories, clustering, classification, scalable visualization, geovisualization",291.0,144.0,26.0,1630.0,,,extracting meaningful clusters;objects trajectories moving;analyst interactive visual;memory propose approach;human,0.6338;0.3544;0.3121;0.1695;0.1557,"[np.int64(-1), np.int64(-1), -1, -1, -1]",38;31;-1;-1;-1,31;38,38,Cluster Analysis
SciVis,2013,MObjects--A Novel Method for the Visualization and Interactive Exploration of Defects in Industrial XCT Data,10.1109/tvcg.2013.177,http://dx.doi.org/10.1109/TVCG.2013.177,2906.0,2915.0,J,"This paper describes an advanced visualization method for the analysis of defects in industrial 3D X-Ray Computed Tomography (XCT) data. We present a novel way to explore a high number of individual objects in a dataset, e.g., pores, inclusions, particles, fibers, and cracks demonstrated on the special application area of pore extraction in carbon fiber reinforced polymers (CFRP). After calculating the individual object properties volume, dimensions and shape factors, all objects are clustered into a mean object (MObject). The resulting MObject parameter space can be explored interactively. To do so, we introduce the visualization of mean object sets (MObject Sets) in a radial and a parallel arrangement. Each MObject may be split up into sub-classes by selecting a specific property, e.g., volume or shape factor, and the desired number of classes. Applying this interactive selection iteratively leads to the intended classifications and visualizations of MObjects along the selected analysis path. Hereby the given different scaling factors of the MObjects down the analysis path are visualized through a visual linking approach. Furthermore the representative MObjects are exported as volumetric datasets to serve as input for successive calculations and simulations. In the field of porosity determination in CFRP non-destructive testing practitioners use representative MObjects to improve ultrasonic calibration curves. Representative pores also serve as input for heat conduction simulations in active thermography. For a fast overview of the pore properties in a dataset we propose a local MObjects visualization in combination with a color-coded homogeneity visualization of cells. The advantages of our novel approach are demonstrated using real world CFRP specimens. The results were evaluated through a questionnaire in order to determine the practicality of the MObjects visualization as a supportive tool for domain specialists.",Andreas Reh;Christian Gusenbauer;Johann Kastner;M. Eduard Gröller;Christoph Heinzl,Andreas Reh;Christian Gusenbauer;Johann Kastner;M. Eduard Gröller;Christoph Heinzl,"University of Applied Sciences Upper Austria, Austria;University of Applied Sciences Upper Austria, Austria;University of Applied Sciences Upper Austria, Austria;Institute of Computer Graphics and Algorithms, Vienna University of Technology, Austria;University of Applied Sciences Upper Austria, Austria",10.1109/tvcg.2012.231;10.1109/visual.1999.809871;10.1109/tvcg.2009.121;10.1109/tvcg.2012.227;10.1109/tvcg.2011.248;10.1109/visual.2005.1532807;10.1109/tvcg.2010.190;10.1109/tvcg.2010.214;10.1109/visual.1993.398859;10.1109/visual.1997.663875,"3D X-ray computed tomography, carbon fiber reinforced polymers, porosity, parameter space analysis, MObjects",37.0,21.0,29.0,834.0,,,advanced visualization;computed tomography xct;pores inclusions;reinforced polymers cfrp;representative mobjects exported,0.5185;0.4427;0.3050;0.2771;0.1662,"[np.int64(1), np.int64(-1), -1, -1, -1]",67;49;-1;-1;-1,49;67,67,Data Visualization Techniques
Vis,1998,Efficient warping for architectural walkthroughs using layered depth images,10.1109/visual.1998.745305,http://dx.doi.org/10.1109/VISUAL.1998.745305,211.0,215.0,C,"This paper presents efficient image-based rendering techniques used in the context of an architectural walkthrough system. Portals (doors and windows) are rendered by warping layered depth images (LDIs). In a preprocessing phase, for every portal, a number of pre-rendered images are combined into an LDI. The resulting LDI stores, exactly once, all surfaces visible in at least one of the images used in the construction, so most of the exposure errors are efficiently eliminated. The LDI can be warped in the McMillan occlusion compatible ordering. A substantial increase in performance is obtained by warping in parallel. Our parallelization scheme achieves good load balancing, scales with the number of processors, and preserves the occlusion compatible ordering. A fast, conservative reference-image-space clipping algorithm also reduces the warping effort.",Voicu Popescu;Anselmo Lastra;Daniel G. Aliaga;Manuel Menezes de Oliveira Neto,V. Popescu;A. Lastra;D. Aliaga;M. de Oliveira Neto,"University of North Carolina, Chapel Hill, USA;University of North Carolina, Chapel Hill, USA;University of North Carolina, Chapel Hill, USA;University of North Carolina, Chapel Hill, USA",10.1109/visual.1997.663903,"image-based rendering, parallel warping, occlusion compatible ordering for discrete images, portal, cell, exposure error, layered depth image, clipping, architectural walkthrough",69.0,16.0,8.0,75.0,,,layered depth images;windows rendered warping;context architectural walkthrough;achieves good load;number pre,0.6225;0.2458;0.2125;0.1130;0.0853,"[np.int64(-1), -1, -1, -1, -1]",44;-1;-1;-1;-1,44,44,3D Rendering Techniques
InfoVis,1995,Case study: 3D displays of Internet traffic,10.1109/infvis.1995.528697,http://dx.doi.org/10.1109/INFVIS.1995.528697,129.0,131.0,C,"The explosive growth in world-wide communications, especially the Internet, has highlighted the need for techniques to visualize network traffic. The traditional node and link network displays work well for small datasets but become visually cluttered and uninterpretable for large datasets. A natural 3D metaphor for displaying world-wide network data is to position the nodes on a globe and draw arcs between them coding the traffic. This technique has several advantages of over the traditional 2D displays, it naturally reduces line crossing clutter, provides an intuitive model for navigation and indication of time, and retains the geographic context. Coupling these strengths with some novel interaction techniques involving the globe surface translucency and arc heights illustrates the usefulness for this class of displays.",Kenneth C. Cox;Stephen G. Eick,K.C. Cox;S.G. Eick,"AT and T Bell Laboratories, USA;AT and T Bell Laboratories, Naperville, IL, USA",10.1109/visual.1993.398870;10.1109/visual.1993.398870,,52.0,14.0,8.0,201.0,,,visualize network traffic;globe draw arcs;advantages traditional 2d;retains geographic context;especially,0.6573;0.5260;0.2500;0.2269;0.1046,"[np.int64(1), np.int64(-1), -1, -1, -1]",6;84;-1;-1;-1,6;84,6,Dynamic Data Visualization
Vis,2022,Uncertainty-Aware Multidimensional Scaling,10.1109/tvcg.2022.3209420,http://dx.doi.org/10.1109/TVCG.2022.3209420,23.0,32.0,J,"We present an extension of multidimensional scaling (MDS) to uncertain data, facilitating uncertainty visualization of multidimensional data. Our approach uses local projection operators that map high-dimensional random vectors to low-dimensional space to formulate a generalized stress. In this way, our generic model supports arbitrary distributions and various stress types. We use our uncertainty-aware multidimensional scaling (UAMDS) concept to derive a formulation for the case of normally distributed random vectors and a squared stress. The resulting minimization problem is numerically solved via gradient descent. We complement UAMDS by additional visualization techniques that address the sensitivity and trustworthiness of dimensionality reduction under uncertainty. With several examples, we demonstrate the usefulness of our approach and the importance of uncertainty-aware techniques.",David Hägele;Tim Krake;Daniel Weiskopf,David Hägele;Tim Krake;Daniel Weiskopf,"University of Stuttgart, Germany;University of Stuttgart, Germany;University of Stuttgart, Germany",10.1109/infvis.1998.729560;10.1109/vast.2009.5332611;10.1109/tvcg.2019.2934812;10.1109/tvcg.2018.2864889;10.1109/tvcg.2016.2599106;10.1109/tvcg.2015.2467591;10.1109/tvcg.2016.2598919;10.1109/infvis.1998.729560,"Uncertainty visualization,dimensionality reduction,multidimensional scaling,non-linear projection",,2.0,37.0,2801.0,BP,X,uncertainty visualization multidimensional;generalized stress way;scaling uamds;local projection;normally,0.7401;0.4089;0.2399;0.2091;0.0181,"[np.int64(-1), np.int64(-1), -1, -1, -1]",37;81;-1;-1;-1,37;81,37,Uncertainty Visualization
VAST,2011,Visual sentiment analysis on twitter data streams,10.1109/vast.2011.6102472,http://dx.doi.org/10.1109/VAST.2011.6102472,277.0,278.0,M,"Twitter currently receives about 190 million tweets (small text-based Web posts) a day, in which people share their comments regarding a wide range of topics. A large number of tweets include opinions about products and services. However, with Twitter being a relatively new phenomenon, these tweets are underutilized as a source for evaluating customer sentiment. To explore high-volume twitter data, we introduce three novel time-based visual sentiment analysis techniques: (1) topic-based sentiment analysis that extracts, maps, and measures customer opinions; (2) stream analysis that identifies interesting tweets based on their density, negativity, and influence characteristics; and (3) pixel cell-based sentiment calendars and high density geo maps that visualize large volumes of data in a single view. We applied these techniques to a variety of twitter data, (e.g., movies, amusement parks, and hotels) to show their distribution and patterns, and to identify influential opinions.",Ming C. Hao;Christian Rohrdantz;Halldor Janetzko;Umeshwar Dayal;Daniel A. Keim;Lars-Erik Haug;Meichun Hsu,Ming Hao;Christian Rohrdantz;Halldór Janetzko;Umeshwar Dayal;Daniel A. Keim;Lars-Erik Haug;Mei-Chun Hsu,"Hewlett Packard Laboratory, USA;Hewlett-Packard Laboratories, University of Konstanz, Germany;Hewlett-Packard Laboratories, University of Konstanz, Germany;Hewlett Packard Laboratory, USA;Hewlett-Packard Laboratories, University of Konstanz, Germany;Hewlett Packard Laboratory, USA;Hewlett Packard Laboratory, USA",0.1109/vast.2009.5333919,,94.0,38.0,3.0,3669.0,,,visual sentiment analysis;190 million tweets;hotels distribution patterns;geo;introduce novel time,0.6370;0.4394;0.1451;0.1425;0.1135,"[np.int64(1), np.int64(-1), -1, -1, -1]",4;79;-1;-1;-1,4;79,4,Visualization Bias Analysis
InfoVis,2008,"The Word Tree, an Interactive Visual Concordance",10.1109/tvcg.2008.172,http://dx.doi.org/10.1109/TVCG.2008.172,1221.0,1228.0,J,"We introduce the Word Tree, a new visualization and information-retrieval technique aimed at text documents. A Word Tree is a graphical version of the traditional ""keyword-in-context"" method, and enables rapid querying and exploration of bodies of text. In this paper we describe the design of the technique, along with some of the technical issues that arise in its implementation. In addition, we discuss the results of several months of public deployment of word trees on Many Eyes, which provides a window onto the ways in which users obtain value from the visualization.",Martin Wattenberg;Fernanda B. Viégas,Martin Wattenberg;Fernanda B. Viégas,IBM Research;IBM Research,10.1109/infvis.2002.1173155;10.1109/vast.2007.4389006;10.1109/tvcg.2007.70577;10.1109/infvis.2002.1173148,"Text visualization, document visualization, Many Eyes, case study, concordance, information retrieval, search",449.0,206.0,15.0,3020.0,,,word tree graphical;rapid querying;bodies text paper;users obtain value;months public deployment,0.6574;0.3934;0.1986;0.1609;0.0528,"[np.int64(-1), np.int64(-1), -1, -1, -1]",50;75;-1;-1;-1,50;75,50,Hierarchical Visualization
InfoVis,2013,"Interactive Visualizations on Large and Small Displays: The Interrelation of Display Size, Information Space, and Scale",10.1109/tvcg.2013.170,http://dx.doi.org/10.1109/TVCG.2013.170,2336.0,2345.0,J,"In controlled experiments on the relation of display size (i.e., the number of pixels) and the usability of visualizations, the size of the information space can either be kept constant or varied relative to display size. Both experimental approaches have limitations. If the information space is kept constant then the scale ratio between an overview of the entire information space and the lowest zoom level varies, which can impact performance; if the information space is varied then the scale ratio is kept constant, but performance cannot be directly compared. In other words, display size, information space, and scale ratio are interrelated variables. We investigate this relation in two experiments with interfaces that implement classic information visualization techniques-focus+context, overview+detail, and zooming-for multi-scale navigation in maps. Display size varied between 0.17, 1.5, and 13.8 megapixels. Information space varied relative to display size in one experiment and was constant in the other. Results suggest that for tasks where users navigate targets that are visible at all map scales the interfaces do not benefit from a large display: With a constant map size, a larger display does not improve performance with the interfaces; with map size varied relative to display size, participants found interfaces harder to use with a larger display and task completion times decrease only when they are normalized to compensate for the increase in map size. The two experimental approaches show different interaction effects between display size and interface. In particular, focus+context performs relatively worse at a large display size with variable map size, and relatively worse at a small display size with a fixed map size. Based on a theoretical analysis of the interaction with the visualization techniques, we examine individual task actions empirically so as to understand the relative impact of display size and scale ratio on the visualization techniques' performance and to discuss differences between the two experimental approaches.",Mikkel R. Jakobsen;Kasper Hornbæk,Mikkel R. Jakobsen;Kasper Hornbæk,"University of Copenhagen, Denmark;University of Copenhagen, Denmark",10.1109/tvcg.2006.184;10.1109/tvcg.2006.187;10.1109/tvcg.2006.184,"Information visualization, multi-scale navigation, interaction techniques, experimental method, user studies",42.0,25.0,32.0,1625.0,,,usability visualizations size;users navigate;focus context performs;interrelated variables;directly,0.6446;0.3474;0.2870;0.1075;-0.0122,"[np.int64(1), -1, -1, -1, -1]",87;-1;-1;-1;-1,87,87,Mobile Usability Visualizations
InfoVis,2006,Visualization of Geo-spatial Point Sets via Global Shape Transformation and Local Pixel Placement,10.1109/tvcg.2006.198,http://dx.doi.org/10.1109/TVCG.2006.198,749.0,756.0,J,"In many applications, data is collected and indexed by geo-spatial location. Discovering interesting patterns through visualization is an important way of gaining insight about such data. A previously proposed approach is to apply local placement functions such as PixelMaps that transform the input data set into a solution set that preserves certain constraints while making interesting patterns more obvious and avoid data loss from overplotting. In experience, this family of spatial transformations can reveal fine structures in large point sets, but it is sometimes difficult to relate those structures to basic geographic features such as cities and regional boundaries. Recent information visualization research has addressed other types of transformation functions that make spatially-transformed maps with recognizable shapes. These types of spatial-transformation are called global shape functions. In particular, cartogram-based map distortion has been studied. On the other hand, cartogram-based distortion does not handle point sets readily. In this study, we present a framework that allows the user to specify a global shape function and a local placement function. We combine cartogram-based layout (global shape) with PixelMaps (local placement), obtaining some of the benefits of each toward improved exploration of dense geo-spatial data sets",Christian Panse;Mike Sips;Daniel A. Keim;Stephen C. North,Christian Panse;Mike Sips;Daniel Keim;Stephen North,"University ETH Zurich, Switzerland;Max Planck Center for Visual Computing and Communication, University of Stanford, USA;University of Konstanz, Germany;AT and T Research Laboratories, NJ, USA",10.1109/visual.1998.745303;10.1109/infvis.2004.57;10.1109/visual.2003.1250410;10.1109/visual.1998.745303,"Geo-spatial Data, Shape Transformation, Cartogram, Pixel Visualization",48.0,22.0,12.0,508.0,,,cartogram based map;interesting patterns;apply local placement;transformations reveal fine;avoid,0.6521;0.2843;0.2154;0.1282;0.0954,"[np.int64(-1), -1, -1, -1, -1]",61;-1;-1;-1;-1,61,61,Thematic Mapping
Vis,2004,Interactive terascale particle visualization,10.1109/visual.2004.55,http://dx.doi.org/10.1109/VISUAL.2004.55,353.0,360.0,C,"This work describes the methods used to produce an interactive visualization of a 2 TB computational fluid dynamics (CFD) data set using particle tracing (streaklines). We use the method introduced by Bruckschen el al. (2001) that precomputes a large number of particles, stores them on disk using a space-filling curve ordering that minimizes seeks, then retrieves and displays the particles according to the user's command. We describe how the particle computation can be performed using a PC cluster, how the algorithm can be adapted to work with a multiblock curvilinear mesh, how scalars can be extracted and used to color the particles, and how the out-of-core visualization can be scaled to 293 billion particles while still achieving interactive performance on PC hardware. Compared to the earlier work, our data set size and total number of particles are an order of magnitude larger. We also describe a new compression technique that losslessly reduces the amount of particle storage by 41% and speeds the particle retrieval by about 20%.",David A. Ellsworth;Bryan Green;Patrick J. Moran,D. Ellsworth;B. Green;P. Moran,"Advanced Management Technology Incorporataed, NASA Ames Research Center, USA;Advanced Management Technology Incorporataed, NASA Ames Research Center, USA;NASA Ames Research Center, USA",10.1109/visual.2003.1250375;10.1109/visual.1998.745299;10.1109/visual.1997.663888;10.1109/visual.2003.1250420;10.1109/visual.1994.346311;10.1109/visual.1998.745343;10.1109/visual.1995.480821;10.1109/visual.2003.1250375,"visualization, particle tracing, large data, out-of-core, PC hardware, clusters, computational fluid dynamics",56.0,19.0,14.0,171.0,,,using particle tracing;storage 41 speeds;ordering minimizes;core;retrieves displays,0.6219;0.1596;0.0700;0.0332;0.0240,"[np.int64(-1), -1, -1, -1, -1]",24;-1;-1;-1;-1,24,24,Particle Dynamics Analysis
SciVis,2016,Physics-Based Visual Characterization of Molecular Interaction Forces,10.1109/tvcg.2016.2598825,http://dx.doi.org/10.1109/TVCG.2016.2598825,731.0,740.0,J,"Molecular simulations are used in many areas of biotechnology, such as drug design and enzyme engineering. Despite the development of automatic computational protocols, analysis of molecular interactions is still a major aspect where human comprehension and intuition are key to accelerate, analyze, and propose modifications to the molecule of interest. Most visualization algorithms help the users by providing an accurate depiction of the spatial arrangement: the atoms involved in inter-molecular contacts. There are few tools that provide visual information on the forces governing molecular docking. However, these tools, commonly restricted to close interaction between atoms, do not consider whole simulation paths, long-range distances and, importantly, do not provide visual cues for a quick and intuitive comprehension of the energy functions (modeling intermolecular interactions) involved. In this paper, we propose visualizations designed to enable the characterization of interaction forces by taking into account several relevant variables such as molecule-ligand distance and the energy function, which is essential to understand binding affinities. We put emphasis on mapping molecular docking paths obtained from Molecular Dynamics or Monte Carlo simulations, and provide time-dependent visualizations for different energy components and particle resolutions: atoms, groups or residues. The presented visualizations have the potential to support domain experts in a more efficient drug or enzyme design process.",Pedro Hermosilla;Jorge Estrada;Victor Guallar;Timo Ropinski;Àlvar Vinacua;Pere-Pau Vázquez,Pedro Hermosilla;Jorge Estrada;Victor Guallar;Timo Ropinski;Àlvar Vinacua;Pere-Pau Vázquez,"ViRVIG Group, Barcelona Supercomputing Center;Barcelona Supercomputing Center;Barcelona Supercomputing Center;Visual Computing Group, Ulm University;ViRVIG Group, UPC, Barcelona;ViRVIG Group, UPC, Barcelona",10.1109/tvcg.2009.168;10.1109/tvcg.2012.282;10.1109/tvcg.2015.2467293;10.1109/tvcg.2007.70578;10.1109/tvcg.2006.115;10.1109/tvcg.2007.70517;10.1109/tvcg.2014.2346403;10.1109/tvcg.2009.157;10.1109/tvcg.2009.168,Molecular visualization;binding analysis,21.0,17.0,52.0,708.0,,,molecule visualization;efficient drug enzyme;simulations used;docking tools commonly;taking account relevant,0.6606;0.3545;0.2855;0.2583;0.0086,"[np.int64(-1), np.int64(-1), -1, -1, -1]",27;27;-1;-1;-1,27,27,Molecular Design Techniques
Vis,1992,Visualization for the document space,10.1109/visual.1992.235198,http://dx.doi.org/10.1109/VISUAL.1992.235198,274.0,281.0,C,"An information retrieval frame work that promotes graphical displays, and that will make documents in the computer visualizable to the searcher, is described. As examples of such graphical displays, two simulation results of using a Kohonen feature map to generate map displays for information retrieval are presented and discussed. The map displays are a mapping from a high-dimensional document space to a two-dimensional space. They show document relationships by various visual cues, such as dots, links, clusters, and areas, as well as their measurement and spatial arrangement. Using the map displays as an interface for document retrieval systems, the user is provided with richer visual information to support browsing and searching.&lt;&lt;ETX&gt;&gt;",X. Lin,X. Lin,"Center for Computerized Legal Research, Pace University, White Plains, NY, USA",,,110.0,16.0,17.0,186.0,,,displays information retrieval;using kohonen;dimensional space;map generate map;discussed,0.6679;0.3023;0.2868;0.2539;0.0188,"[np.int64(-1), -1, -1, -1, -1]",-1;-1;-1;-1;-1,,-1,Complex Data Analysis
InfoVis,2020,ShuttleSpace: Exploring and Analyzing Movement Trajectory in Immersive Visualization,10.1109/tvcg.2020.3030392,http://dx.doi.org/10.1109/TVCG.2020.3030392,860.0,869.0,J,"We present ShuttleSpace, an immersive analytics system to assist experts in analyzing trajectory data in badminton. Trajectories in sports, such as the movement of players and balls, contain rich information on player behavior and thus have been widely analyzed by coaches and analysts to improve the players' performance. However, existing visual analytics systems often present the trajectories in court diagrams that are abstractions of reality, thereby causing difficulty for the experts to imagine the situation on the court and understand why the player acted in a certain way. With recent developments in immersive technologies, such as virtual reality (VR), experts gradually have the opportunity to see, feel, explore, and understand these 3D trajectories from the player's perspective. Yet, few research has studied how to support immersive analysis of sports data from such a perspective. Specific challenges are rooted in data presentation (e.g., how to seamlessly combine 2D and 3D visualizations) and interaction (e.g., how to naturally interact with data without keyboard and mouse) in VR. To address these challenges, we have worked closely with domain experts who have worked for a top national badminton team to design ShuttleSpace. Our system leverages 1) the peripheral vision to combine the 2D and 3D visualizations and 2) the VR controller to support natural interactions via a stroke metaphor. We demonstrate the effectiveness of ShuttleSpace through three case studies conducted by the experts with useful insights. We further conduct interviews with the experts whose feedback confirms that our first-person immersive analytics system is suitable and useful for analyzing badminton data.",Shuainan Ye;Zhutian Chen;Xiangtong Chu;Yifan Wang;Siwei Fu;Lejun Shen;Kun Zhou 0001;Yingcai Wu,Shuainan Ye;Zhutian Chen;Xiangtong Chu;Yifan Wang;Siwei Fu;Lejun Shen;Kun Zhou;Yingcai Wu,"State Key Lab of CAD CG, Zhejiang University;Hong Kong University of Science and Technology;State Key Lab of CAD CG, Zhejiang University;State Key Lab of CAD CG, Zhejiang University;Zhejiang Lab;Chengdu Sports University;State Key Lab of CAD CG, Zhejiang University;State Key Lab of CAD CG, Zhejiang University",10.1109/tvcg.2019.2934332;10.1109/vast.2014.7042478;10.1109/tvcg.2018.2865191;10.1109/tvcg.2016.2598831;10.1109/tvcg.2013.192;10.1109/visual.2001.964496;10.1109/tvcg.2019.2934243;10.1109/tvcg.2014.2346445;10.1109/vast.2014.7042477;10.1109/tvcg.2017.2745181;10.1109/tvcg.2017.2744218;10.1109/tvcg.2018.2865041;10.1109/tvcg.2018.2865192,"Movement trajectory,badminton analytics,virtual reality",43.0,61.0,49.0,2444.0,,,immersive analysis sports;stroke metaphor;data keyboard mouse;court understand;design shuttlespace leverages,0.7198;0.2911;0.2708;0.2008;0.1371,"[np.int64(-1), -1, -1, -1, -1]",57;-1;-1;-1;-1,57,57,Sports Data Visualization
InfoVis,2009,Constructing Overview + Detail Dendrogram-Matrix Views,10.1109/tvcg.2009.130,http://dx.doi.org/10.1109/TVCG.2009.130,889.0,896.0,J,"A dendrogram that visualizes a clustering hierarchy is often integrated with a re-orderable matrix for pattern identification. The method is widely used in many research fields including biology, geography, statistics, and data mining. However, most dendrograms do not scale up well, particularly with respect to problems of graphical and cognitive information overload. This research proposes a strategy that links an overview dendrogram and a detail-view dendrogram, each integrated with a re-orderable matrix. The overview displays only a user-controlled, limited number of nodes that represent the ldquoskeletonrdquo of a hierarchy. The detail view displays the sub-tree represented by a selected meta-node in the overview. The research presented here focuses on constructing a concise overview dendrogram and its coordination with a detail view. The proposed method has the following benefits: dramatic alleviation of information overload, enhanced scalability and data abstraction quality on the dendrogram, and the support of data exploration at arbitrary levels of detail. The contribution of the paper includes a new metric to measure the ldquoimportancerdquo of nodes in a dendrogram; the method to construct the concise overview dendrogram from the dynamically-identified, important nodes; and measure for evaluating the data abstraction quality for dendrograms. We evaluate and compare the proposed method to some related existing methods, and demonstrating how the proposed method can help users find interesting patterns through a case study on county-level U.S. cervical cancer mortality and demographic data.",Jin Chen;Alan M. MacEachren;Donna J. Peuquet,Jin Chen;Alan M. MacEachren;Donna J. Peuquet,"GeoVISTA Center, Department of Geography, Pennsylvania State University, USA;GeoVISTA Center, Department of Geography, Pennsylvania State University, USA;GeoVISTA Center, Department of Geography, Pennsylvania State University, USA",10.1109/tvcg.2006.161;10.1109/tvcg.2007.70535;10.1109/infvis.2004.46;10.1109/tvcg.2006.161,"Dendrogram, reorderable matrix, compound graphs, data abstraction quality metrics, hierarchical clusters",40.0,14.0,28.0,632.0,,,dendrogram visualizes clustering;evaluating data abstraction;orderable matrix pattern;cervical cancer mortality;user controlled limited,0.7383;0.3068;0.2252;0.1697;0.0281,"[np.int64(-1), -1, -1, -1, -1]",46;-1;-1;-1;-1,46,46,Cluster Visualization
Vis,2023,ARGUS: Visualization of AI-Assisted Task Guidance in AR,10.1109/tvcg.2023.3327396,http://dx.doi.org/10.1109/TVCG.2023.3327396,1313.0,1323.0,J,"The concept of augmented reality (AR) assistants has captured the human imagination for decades, becoming a staple of modern science fiction. To pursue this goal, it is necessary to develop artificial intelligence (AI)-based methods that simultaneously perceive the 3D environment, reason about physical tasks, and model the performer, all in real-time. Within this framework, a wide variety of sensors are needed to generate data across different modalities, such as audio, video, depth, speech, and time-of-flight. The required sensors are typically part of the AR headset, providing performer sensing and interaction through visual, audio, and haptic feedback. AI assistants not only record the performer as they perform activities, but also require machine learning (ML) models to understand and assist the performer as they interact with the physical world. Therefore, developing such assistants is a challenging task. We propose ARGUS, a visual analytics system to support the development of intelligent AR assistants. Our system was designed as part of a multi-year-long collaboration between visualization researchers and ML and AR experts. This co-design process has led to advances in the visualization of ML in AR. Our system allows for online visualization of object, action, and step detection as well as offline analysis of previously recorded AR sessions. It visualizes not only the multimodal sensor data streams but also the output of the ML models. This allows developers to gain insights into the performer activities as well as the ML models, helping them troubleshoot, improve, and fine-tune the components of the AR assistant.",Sonia Castelo;João Rulff;Erin McGowan;Bea Steers;Guande Wu;Shaoyu Chen;Irán R. Román;Roque Lopez;Ethan Brewer;Chen Zhao;Jing Qian;Kyunghyun Cho;He He 0001;Qi Sun 0003;Huy T. Vo;Juan Pablo Bello;Michael Krone;Cláudio T. Silva,Sonia Castelo;Joao Rulff;Erin McGowan;Bea Steers;Guande Wu;Shaoyu Chen;Iran Roman;Roque Lopez;Ethan Brewer;Chen Zhao;Jing Qian;Kyunghyun Cho;He He;Qi Sun;Huy Vo;Juan Bello;Michael Krone;Claudio Silva,"New York University, New York;New York University, New York;New York University, New York;New York University, New York;New York University, New York;New York University, New York;New York University, New York;New York University, New York;New York University, New York;New York University, New York;New York University, New York;New York University, New York;New York University, New York;New York University, New York;New York University, New York;New York University, New York;New York University, New York;New York University, New York",0.1109/tvcg.2017.2746018;10.1109/tvcg.2018.2865152;10.1109/tvcg.2018.2864499,"Data Models,Image and Video Data,Temporal Data,Application Motivated Visualization,AR/VR/Immersive",,10.0,58.0,1124.0,HM,,reality ar assistants;performer perform activities;data streams output;modern science;necessary,0.6510;0.2641;0.1268;0.1133;0.0723,"[np.int64(-1), -1, -1, -1, -1]",43;-1;-1;-1;-1,43,43,Augmented Reality Interfaces
InfoVis,2002,Case study: visualizing sets of evolutionary trees,10.1109/infvis.2002.1173150,http://dx.doi.org/10.1109/INFVIS.2002.1173150,71.0,74.0,C,"We describe a visualization tool which allows a biologist to explore a large set of hypothetical evolutionary trees. Interacting with such a dataset allows the biologist to identify distinct hypotheses about how different species or organisms evolved, which would not have been clear from traditional analyses. Our system integrates a point-set visualization of the distribution of hypothetical trees with detail views of an individual tree, or of a consensus tree summarizing a subset of trees. Efficient algorithms were required for the key tasks of computing distances between trees, finding consensus trees, and laying out the point-set visualization.",Nina Amenta;Jeff Klingner,N. Amenta;J. Klingner,"University of Texas, Austin, Austin, TX, USA;Computer Sciences Department, University of Texas, Austin, Austin, TX, USA",10.1109/visual.1996.567787;10.1109/visual.1993.398870;10.1109/visual.1996.567787,,119.0,27.0,15.0,395.0,,,evolutionary trees;point set visualization;finding consensus;traditional analyses integrates;different,0.6739;0.4496;0.2237;0.0359;0.0049,"[np.int64(-1), np.int64(-1), -1, -1, -1]",19;63;-1;-1;-1,19;63,19,Tree Structures
Vis,2004,Light weight space leaping using ray coherence,10.1109/visual.2004.63,http://dx.doi.org/10.1109/VISUAL.2004.63,19.0,26.0,C,"We present a space leaping technique for accelerating volume rendering with very low space and run-time complexity. Our technique exploits the ray coherence during ray casting by using the distance a ray traverses in empty space to leap its neighboring rays. Our technique works with parallel as well as perspective volume rendering, does not require any preprocessing or 3D data structures, and is independent of the transfer function. Being an image-space technique, it is independent of the complexity of the data being rendered. It can be used to accelerate both time-coherent and noncoherent animation sequences.",Sarang Lakare;Arie E. Kaufman,S. Lakare;A. Kaufman,"Center for Visual Computing (CVC) and Department of Computer Science, Stony Brook University, Stony Brook, NY, USA;Center for Visual Computing (CVC) and Department of Computer Science, Stony Brook University, Stony Brook, NY, USA",10.1109/visual.1993.398852;10.1109/visual.1999.809914;10.1109/visual.1990.146377;10.1109/visual.1998.745713;10.1109/visual.2002.1183775;10.1109/visual.1993.398852,"Direct Volume Rendering, Space Leaping, Empty Space Skipping, Ray Coherence, Volume Rendering Acceleration",34.0,6.0,13.0,114.0,,,accelerating volume rendering;space leap neighboring;casting using;does require preprocessing;coherent noncoherent,0.6881;0.3528;0.1305;0.1218;0.0724,"[np.int64(-1), np.int64(-1), -1, -1, -1]",70;-1;-1;-1;-1,70,70,Interactive Volume Rendering
Vis,1990,A problem-oriented classification of visualization techniques,10.1109/visual.1990.146375,http://dx.doi.org/10.1109/VISUAL.1990.146375,139.0,,C,"Progress in scientific visualization could be accelerated if workers could more readily find visualization techniques relevant to a given problem. The authors describe an approach to this problem, based on a classification of visualization techniques, that is independent of particular application domains. A user breaks up a problem into subproblems, describes these subproblems in terms of the objects to be represented and the operations to be supported by a representation, locates applicable visualization techniques in a catalog, and combines these representations into a composite representation for the original problem. The catalog and its underlying classification provide a way for workers in different application disciplines to share methods.&lt;&lt;ETX&gt;&gt;",Stephen Wehrend;Clayton Lewis,S. Wehrend;C. Lewis,"Center for Advanced Decision Support in Water and Environmental, Systems and Department of Computer Science, University of Colorado, Boulder, CO, USA;Center for Advanced Decision Support in Water and Environmental, Systems and Department of Computer Science, University of Colorado, Boulder, CO, USA",,,483.0,112.0,6.0,1214.0,,,scientific visualization;representations composite representation;particular application domains;readily;user breaks problem,0.7366;0.1735;0.1011;0.0638;0.0245,"[np.int64(1), -1, -1, -1, -1]",9;-1;-1;-1;-1,9,9,Scientific Visualization
SciVis,2016,Progressive Direct Volume-to-Volume Transformation,10.1109/tvcg.2016.2599042,http://dx.doi.org/10.1109/TVCG.2016.2599042,921.0,930.0,J,"We present a novel technique to generate transformations between arbitrary volumes, providing both expressive distances and smooth interpolates. In contrast to conventional morphing or warping approaches, our technique requires no user guidance, intermediate representations (like extracted features), or blending, and imposes no restrictions regarding shape or structure. Our technique operates directly on the volumetric data representation, and while linear programming approaches could solve the underlying problem optimally, their polynomial complexity makes them infeasible for high-resolution volumes. We therefore propose a progressive refinement approach designed for parallel execution that is able to quickly deliver approximate results that are iteratively improved toward the optimum. On this basis, we further present a new approach for the streaming selection of time steps in temporal data that allows for the reconstruction of the full sequence with a user-specified error bound. We finally demonstrate the utility of our technique for different applications, compare our approach against alternatives, and evaluate its characteristics with a variety of different data sets.",Steffen Frey;Thomas Ertl,Steffen Frey;Thomas Ertl,University of Stuttgart;University of Stuttgart,10.1109/tvcg.2008.140;10.1109/tvcg.2012.284;10.1109/visual.1994.346333;10.1109/tvcg.2008.143;10.1109/tvcg.2009.200;10.1109/visual.2002.1183809;10.1109/tvcg.2008.140,Volume transformation;Volume visualization;progressive;automatic;parallel;time-varying data;streaming data,14.0,12.0,47.0,679.0,,,morphing warping approaches;steps temporal data;arbitrary volumes providing;smooth;specified error,0.5367;0.3656;0.2639;0.2014;-0.0761,"[np.int64(-1), np.int64(-1), -1, -1, -1]",54;71;-1;-1;-1,54;71,54,Image Transformation Techniques
Vis,2009,Visual Exploration of Nasal Airflow,10.1109/tvcg.2009.198,http://dx.doi.org/10.1109/TVCG.2009.198,1407.0,1414.0,J,"Rhinologists are often faced with the challenge of assessing nasal breathing from a functional point of view to derive effective therapeutic interventions. While the complex nasal anatomy can be revealed by visual inspection and medical imaging, only vague information is available regarding the nasal airflow itself: Rhinomanometry delivers rather unspecific integral information on the pressure gradient as well as on total flow and nasal flow resistance. In this article we demonstrate how the understanding of physiological nasal breathing can be improved by simulating and visually analyzing nasal airflow, based on an anatomically correct model of the upper human respiratory tract. In particular we demonstrate how various information visualization (InfoVis) techniques, such as a highly scalable implementation of parallel coordinates, time series visualizations, as well as unstructured grid multi-volume rendering, all integrated within a multiple linked views framework, can be utilized to gain a deeper understanding of nasal breathing. Evaluation is accomplished by visual exploration of spatio-temporal airflow characteristics that include not only information on flow features but also on accompanying quantities such as temperature and humidity. To our knowledge, this is the first in-depth visual exploration of the physiological function of the nose over several simulated breathing cycles under consideration of a complete model of the nasal airways, realistic boundary conditions, and all physically relevant time-varying quantities.",Stefan Zachow;Philipp Muigg;Thomas Hildebrandt;Helmut Doleisch;Hans-Christian Hege,Stefan Zachow;Philipp Muigg;Thomas Hildebrandt;Helmut Doleisch;Hans-Christian Hege,"Zuse Institute Berlin, Germany;Institute of Computer Graphics and Algorithms, University of Technology, Vienna, Austria;Section Brain Surgery, Asklepios Clinic Birkenwerder, Germany;SimVis GmbH, Austria;Zuse Institute Berlin, Germany",10.1109/tvcg.2008.139;10.1109/tvcg.2007.70588;10.1109/visual.2003.1250390;10.1109/visual.2000.885739;10.1109/visual.1990.146402;10.1109/visual.2005.1532788;10.1109/tvcg.2006.170;10.1109/tvcg.2008.139,"Flow visualization, exploratory data analysis, interactive visual analysis of scientific data, time-dependent data",55.0,31.0,44.0,730.0,,,nasal airflow rhinomanometry;visualization infovis techniques;simulating;physically relevant time;deeper,0.6935;0.3798;0.1797;0.0991;0.0838,"[np.int64(-1), np.int64(1), -1, -1, -1]",40;13;-1;-1;-1,13;40,40,Respiratory Function Analysis
Vis,2010,An Information-theoretic Framework for Visualization,10.1109/tvcg.2010.132,http://dx.doi.org/10.1109/TVCG.2010.132,1206.0,1215.0,J,"In this paper, we examine whether or not information theory can be one of the theoretic frameworks for visualization. We formulate concepts and measurements for qualifying visual information. We illustrate these concepts with examples that manifest the intrinsic and implicit use of information theory in many existing visualization techniques. We outline the broad correlation between visualization and the major applications of information theory, while pointing out the difference in emphasis and some technical gaps. Our study provides compelling evidence that information theory can explain a significant number of phenomena or events in visualization, while no example has been found which is fundamentally in conflict with information theory. We also notice that the emphasis of some traditional applications of information theory, such as data compression or data communication, may not always suit visualization, as the former typically focuses on the efficient throughput of a communication channel, whilst the latter focuses on the effectiveness in aiding the perceptual and cognitive process for data understanding and knowledge discovery. These findings suggest that further theoretic developments are necessary for adopting and adapting information theory for visualization.",Min Chen 0001;Heike Jänicke,Min Chen;Heike Jaenicke,"Swansea University, UK;Ruprecht-Karls-University Heidelberg",10.1109/tvcg.2007.70615;10.1109/visual.2005.1532781;10.1109/tvcg.2006.152;10.1109/infvis.1996.559213;10.1109/visual.2005.1532834;10.1109/infvis.2000.885096;10.1109/tvcg.2007.70515;10.1109/tvcg.2006.159;10.1109/infvis.2004.59;10.1109/tvcg.2007.70535;10.1109/tvcg.2008.140;10.1109/tvcg.2008.121;10.1109/infvis.1997.636792;10.1109/visual.2005.1532833;10.1109/infvis.2000.885092;10.1109/visual.1990.146375;10.1109/visual.2002.1183785,"Information theory, theory of visualization, quantitative evaluation",192.0,108.0,56.0,2654.0,TT,,information theory visualization;findings suggest theoretic;explain;manifest intrinsic implicit;necessary adopting,0.7910;0.2025;0.1634;0.0004;-0.0284,"[np.int64(1), -1, -1, -1, -1]",-1;-1;-1;-1;-1,,-1,Complex Data Analysis
InfoVis,2017,MyBrush: Brushing and Linking with Personal Agency,10.1109/tvcg.2017.2743859,http://dx.doi.org/10.1109/TVCG.2017.2743859,605.0,615.0,J,"We extend the popular brushing and linking technique by incorporating personal agency in the interaction. We map existing research related to brushing and linking into a design space that deconstructs the interaction technique into three components: source (what is being brushed), link (the expression of relationship between source and target), and target (what is revealed as related to the source). Using this design space, we created MyBrush, a unified interface that offers personal agency over brushing and linking by giving people the flexibility to configure the source, link, and target of multiple brushes. The results of three focus groups demonstrate that people with different backgrounds leveraged personal agency in different ways, including performing complex tasks and showing links explicitly. We reflect on these results, paving the way for future research on the role of personal agency in information visualization.",Philipp Koytek;Charles Perin;Jo Vermeulen;Elisabeth André;Sheelagh Carpendale,Philipp Koytek;Charles Perin;Jo Vermeulen;Elisabeth André;Sheelagh Carpendale,"University of Calgary, Augsburg University;City, University of London, University of Calgary;University of Calgary;Augsburg University;University of Calgary",10.1109/tvcg.2011.185;10.1109/visual.1991.175794;10.1109/infvis.2003.1249024;10.1109/tvcg.2011.201;10.1109/tvcg.2007.70521;10.1109/vast.2009.5333443;10.1109/tvcg.2008.153;10.1109/infvis.2004.64;10.1109/infvis.1999.801858;10.1109/tvcg.2014.2346260;10.1109/visual.2000.885739;10.1109/infvis.2002.1173157;10.1109/vast.2007.4389011;10.1109/tvcg.2006.147;10.1109/tvcg.2008.116;10.1109/tvcg.2013.154;10.1109/tvcg.2010.138;10.1109/visual.1995.485139;10.1109/tvcg.2011.183;10.1109/tvcg.2009.162;10.1109/visual.1994.346302;10.1109/infvis.2004.12;10.1109/visual.1996.567800;10.1109/tvcg.2014.2346279;10.1109/infvis.1996.559216;10.1109/tvcg.2011.185,"Brushing,linking,personal agency,coordinated multiple views,interaction,design space,information visualization",36.0,27.0,82.0,1037.0,,,personal agency interaction;information visualization;popular brushing linking;source target target;different,0.5412;0.4387;0.4358;0.1131;0.0435,"[np.int64(-1), np.int64(1), np.int64(-1), -1, -1]",45;13;34;-1;-1,13;34;45,45,Cognitive Interaction Analysis
VAST,2012,Visualizing flows of images in social media,10.1109/vast.2012.6400539,http://dx.doi.org/10.1109/VAST.2012.6400539,229.0,230.0,M,"Mass and social media provide flows of images for real world events. It is sometimes difficult to represent realities and impressions of events using only text. However, even a single photo might remind us complex events. Along with events in the real world, there are representative images, such as design of products and commercial pictures. We can therefore recognize changes in trends of people's ideas, experiences, and interests through observing the flows of such representative images. This paper presents a novel 3D visualization system to explore temporal changes in trends using images associating with different topics, called Image Bricks. We show case studies using images extracted from our six-year blog archive. We first extract clusters of images as topics related to given keywords. We then visualize them on multiple timelines in a 3D space. Users can visually read stories of topics through exploring visualized images.",Masahiko Itoh;Masashi Toyoda;Tetsuya Kamijo;Masaru Kitsuregawa,Masahiko Itoh;Masashi Toyoda;Tetsuya Kamijo;Masaru Kitsuregawa,"Institute of Industrial Science, University of Tokyo;Institute of Industrial Science, University of Tokyo;Rakuten, Inc.;Institute of Industrial Science, University of Tokyo",,,1.0,2.0,6.0,345.0,,,trends using images;multiple timelines 3d;blog archive extract;read stories;bricks case,0.6963;0.3811;0.2628;0.2496;0.2086,"[np.int64(-1), np.int64(-1), -1, -1, -1]",85;71;-1;-1;-1,71;85,85,Dynamic Data Visualization
Vis,1997,Constrained 3D navigation with 2D controllers,10.1109/visual.1997.663876,http://dx.doi.org/10.1109/VISUAL.1997.663876,175.0,182.0,C,"Navigation through 3D spaces is required in many interactive graphics and virtual reality applications. The authors consider the subclass of situations in which a 2D device such as a mouse controls smooth movements among viewpoints for a ""through the screen"" display of a 3D world. Frequently, there is a poor match between the goal of such a navigation activity, the control device, and the skills of the average user. They propose a unified mathematical framework for incorporating context-dependent constraints into the generalized viewpoint generation problem. These designer-supplied constraint modes provide a middle ground between the triviality of a single camera animation path and the confusing excess freedom of common unconstrained control paradigms. They illustrate the approach with a variety of examples, including terrain models, interior architectural spaces, and complex molecules.",Andrew J. Hanson;Eric A. Wernert,A.J. Hanson;E.A. Wernert,"Computer Science Department, Indiana University, Bloomington, IN, USA;Computer Science Department, Indiana University, Bloomington, IN, USA",10.1109/visual.1995.480804;10.1109/visual.1995.480804,"Navigation, Constrained Navigation, Viewing Control, Camera Control",189.0,32.0,25.0,250.0,,,navigation 3d spaces;framework incorporating context;screen display;common unconstrained;authors,0.6532;0.2401;0.2057;0.1998;0.0396,"[np.int64(-1), -1, -1, -1, -1]",28;-1;-1;-1;-1,28,28,3D Space Navigation
Vis,1994,Piecewise-linear surface approximation from noisy scattered samples,10.1109/visual.1994.346336,http://dx.doi.org/10.1109/VISUAL.1994.346336,61.0,68.0,C,"We consider the problem of approximating a smooth surface f(x, y), based on n scattered samples {(x/sub i/, y/sub i/, z/sub i/)/sub i=1//sup n/} where the sample values {z/sub i/} are contaminated with noise: z/sub i/=f(x/sub i/, y/sub i/)=/spl epsiv//sub i/. We present an algorithm that generates a PLS (piecewise linear surface) f', defined on a triangulation of the sample locations V={(x/sub i/, y/sub i/)/sub i=1//sup n/}, approximating f well. Constructing the PLS involves specifying both the triangulation of V and the values of f' at the points of V. We demonstrate that even when the sampling process is not noisy, a better approximation for f is obtained using our algorithm, compared to existing methods. This algorithm is useful for DTM (digital terrain map) manipulation by polygon-based graphics engines for visualization applications.&lt;&lt;ETX&gt;&gt;",Michael Margaliot;Craig Gotsman,M. Margaliot;C. Gotsman,"Department of Electrical Engineering, Technion-Israel Institute of Technology, Haifa, Israel;Department of Computer Science, Technion-Israel Institute of Technology, Haifa, Israel",,,19.0,3.0,16.0,72.0,,,approximating smooth surface;defined triangulation;visualization applications lt;generates pls piecewise;contaminated,0.6507;0.4176;0.3435;0.2145;0.0497,"[np.int64(-1), np.int64(-1), -1, -1, -1]",65;59;-1;-1;-1,59;65,65,Surface Reconstruction Techniques
InfoVis,2005,Low-level components of analytic activity in information visualization,10.1109/infvis.2005.1532136,http://dx.doi.org/10.1109/INFVIS.2005.1532136,111.0,117.0,C,"Existing system level taxonomies of visualization tasks are geared more towards the design of particular representations than the facilitation of user analytic activity. We present a set of ten low level analysis tasks that largely capture people's activities while employing information visualization tools for understanding data. To help develop these tasks, we collected nearly 200 sample questions from students about how they would analyze five particular data sets from different domains. The questions, while not being totally comprehensive, illustrated the sheer variety of analytic questions typically posed by users when employing information visualization systems. We hope that the presented set of tasks is useful for information visualization system designers as a kind of common substrate to discuss the relative analytic capabilities of the systems. Further, the tasks may provide a form of checklist for system designers.",Robert A. Amar;James Eagan;John T. Stasko,R. Amar;J. Eagan;J. Stasko,"Georgia Institute of Technology,College of Computing, GVU Center;Georgia Institute of Technology,College of Computing, GVU Center;Georgia Institute of Technology,College of Computing, GVU Center",10.1109/visual.1990.146375;10.1109/infvis.1998.729560;10.1109/infvis.2000.885092;10.1109/infvis.2004.5;10.1109/infvis.2001.963289;10.1109/visual.1990.146375,"Analytic activity, taxonomy, knowledge discovery, design, evaluation",844.0,205.0,15.0,4315.0,,,information visualization designers;analytic questions typically;tasks collected nearly;kind common substrate;set low,0.7335;0.4007;0.1592;0.0402;-0.0959,"[np.int64(1), np.int64(-1), -1, -1, -1]",15;22;-1;-1;-1,15;22,15,Visualization Design
Vis,1998,Rear-projecting virtual data onto physical terrain: an exercise in two senses being better than one,10.1109/visual.1998.745341,http://dx.doi.org/10.1109/VISUAL.1998.745341,451.0,454.0,C,"This paper describes a project that combined physical model fabrication and virtual computer-based data display to create a unique visualization presentation. USGS terrain information on Prince of Wales Island, Alaska was used to create a physical prototype in SDSC's TeleManufacturing Facility. This model was then used as a mold to create a translucent plate of the terrain. Finally, deforestation data from the island was color mapped and rear-projected onto the translucent plate within a light box. The result is a very compelling display in which both the senses of sight and touch are used to make relationships between terrain features and the data more readily apparent.",Dru Clark;Richard Marciano;Rosemarie McKeon;Michael J. Bailey,D. Clark;R. Marciano;R. McKeon;M. Bailey,"San Diego Supercomputer Center, University of California, San Diego, USA;San Diego Supercomputer Center, University of California, San Diego, USA;San Diego Supercomputer Center, University of California, San Diego, USA;San Diego Supercomputer Center, University of California, San Diego, San Diego, CA, USA",10.1109/visual.1997.663862;10.1109/visual.1997.663862,,3.0,1.0,5.0,42.0,,,visualization presentation usgs;virtual computer based;used mold create;senses sight touch;island alaska used,0.6176;0.3057;0.2409;0.2146;0.1847,"[np.int64(1), -1, -1, -1, -1]",86;-1;-1;-1;-1,86,86,Scientific Visualization
VAST,2012,Enterprise Data Analysis and Visualization: An Interview Study,10.1109/tvcg.2012.219,http://dx.doi.org/10.1109/TVCG.2012.219,2917.0,2926.0,J,"Organizations rely on data analysts to model customer engagement, streamline operations, improve production, inform business decisions, and combat fraud. Though numerous analysis and visualization tools have been built to improve the scale and efficiency at which analysts can work, there has been little research on how analysis takes place within the social and organizational context of companies. To better understand the enterprise analysts' ecosystem, we conducted semi-structured interviews with 35 data analysts from 25 organizations across a variety of sectors, including healthcare, retail, marketing and finance. Based on our interview data, we characterize the process of industrial data analysis and document how organizational features of an enterprise impact it. We describe recurring pain points, outstanding challenges, and barriers to adoption for visual analytic tools. Finally, we discuss design implications and opportunities for visual analysis research.",Sean Kandel;Andreas Paepcke;Joseph M. Hellerstein;Jeffrey Heer,Sean Kandel;Andreas Paepcke;Joseph M. Hellerstein;Jeffrey Heer,"University of Stanford, USA;University of Stanford, USA;University of California, Berkeley, USA;University of Stanford, USA",10.1109/tvcg.2008.137;10.1109/vast.2008.4677365;10.1109/vast.2011.6102438;10.1109/infvis.2005.1532136;10.1109/vast.2010.5652880;10.1109/vast.2009.5333878;10.1109/vast.2007.4389011;10.1109/vast.2011.6102435;10.1109/tvcg.2008.137,"Data, analysis, visualization, enterprise",500.0,274.0,37.0,7112.0,HM,,visual analytic tools;companies better understand;35 data;takes place social;impact recurring pain,0.6462;0.3684;0.1937;0.1162;0.0162,"[np.int64(1), np.int64(-1), -1, -1, -1]",14;42;-1;-1;-1,14;42,14,Visual Analytics Systems
Vis,2010,Direct Interval Volume Visualization,10.1109/tvcg.2010.145,http://dx.doi.org/10.1109/TVCG.2010.145,1505.0,1514.0,J,"We extend direct volume rendering with a unified model for generalized isosurfaces, also called interval volumes, allowing a wider spectrum of visual classification. We generalize the concept of scale-invariant opacity-typical for isosurface rendering-to semi-transparent interval volumes. Scale-invariant rendering is independent of physical space dimensions and therefore directly facilitates the analysis of data characteristics. Our model represents sharp isosurfaces as limits of interval volumes and combines them with features of direct volume rendering. Our objective is accurate rendering, guaranteeing that all isosurfaces and interval volumes are visualized in a crack-free way with correct spatial ordering. We achieve simultaneous direct and interval volume rendering by extending preintegration and explicit peak finding with data-driven splitting of ray integration and hybrid computation in physical and data domains. Our algorithm is suitable for efficient parallel processing for interactive applications as demonstrated by our CUDA implementation.",Marco Ament;Daniel Weiskopf;Hamish A. Carr,Marco Ament;Daniel Weiskopf;Hamish Carr,"VISUS Visualization Research Center, Universität Stuttgart, Stuttgart, Germany;VISUS Visualization Research Center, Universität Stuttgart, Stuttgart, Germany;School of Computing, University of Leeds, Leeds, UK",10.1109/visual.1998.745713;10.1109/visual.1997.663886;10.1109/visual.2004.85;10.1109/visual.1995.480789;10.1109/visual.2002.1183762;10.1109/tvcg.2009.149;10.1109/tvcg.2006.113;10.1109/tvcg.2008.186;10.1109/visual.2000.885683;10.1109/visual.2005.1532808;10.1109/tvcg.2008.160;10.1109/visual.2003.1250384;10.1109/tvcg.2009.204;10.1109/visual.1995.480807;10.1109/visual.1998.745713,"Direct volume rendering, interval volume, isosurface, ray casting, preintegration, scale-invariant opacity",28.0,16.0,41.0,654.0,,,direct volume rendering;peak finding data;called interval;crack free way;unified model generalized,0.6920;0.2725;0.1662;0.1025;0.0943,"[np.int64(0), -1, -1, -1, -1]",0;-1;-1;-1;-1,0,0,Volume Rendering Techniques
InfoVis,2014,Combing the Communication Hairball: Visualizing Parallel Execution Traces using Logical Time,10.1109/tvcg.2014.2346456,http://dx.doi.org/10.1109/TVCG.2014.2346456,2349.0,2358.0,J,"With the continuous rise in complexity of modern supercomputers, optimizing the performance of large-scale parallel programs is becoming increasingly challenging. Simultaneously, the growth in scale magnifies the impact of even minor inefficiencies - potentially millions of compute hours and megawatts in power consumption can be wasted on avoidable mistakes or sub-optimal algorithms. This makes performance analysis and optimization critical elements in the software development process. One of the most common forms of performance analysis is to study execution traces, which record a history of per-process events and interprocess messages in a parallel application. Trace visualizations allow users to browse this event history and search for insights into the observed performance behavior. However, current visualizations are difficult to understand even for small process counts and do not scale gracefully beyond a few hundred processes. Organizing events in time leads to a virtually unintelligible conglomerate of interleaved events and moderately high process counts overtax even the largest display. As an alternative, we present a new trace visualization approach based on transforming the event history into logical time inferred directly from happened-before relationships. This emphasizes the code's structural behavior, which is much more familiar to the application developer. The original timing data, or other information, is then encoded through color, leading to a more intuitive visualization. Furthermore, we use the discrete nature of logical timelines to cluster processes according to their local behavior leading to a scalable visualization of even long traces on large process counts. We demonstrate our system using two case studies on large-scale parallel codes.",Katherine E. Isaacs;Peer-Timo Bremer;Ilir Jusufi;Todd Gamblin;Abhinav Bhatele;Martin Schulz 0001;Bernd Hamann,Katherine E. Isaacs;Peer-Timo Bremer;Ilir Jusufi;Todd Gamblin;Abhinav Bhatele;Martin Schulz;Bernd Hamann,"University of California, Davis;Lawrence Livermore National Laboratory;University of California, Davis;Lawrence Livermore National Laboratory;Lawrence Livermore National Laboratory;Lawrence Livermore National Laboratory;University of California, Davis",10.1109/tvcg.2012.286;10.1109/tvcg.2009.196;10.1109/tvcg.2011.199;10.1109/tvcg.2013.200;10.1109/tvcg.2012.286,"Information visualization, software visualization, timelines, traces, performance analysis",64.0,35.0,44.0,853.0,,,application trace visualizations;parallel codes;time leads;power consumption;moderately,0.6666;0.3318;0.2515;0.1157;0.0285,"[np.int64(1), -1, -1, -1, -1]",52;-1;-1;-1;-1,52,52,Visualization Tools
SciVis,2018,Tensor Field Visualization using Fiber Surfaces of Invariant Space,10.1109/tvcg.2018.2864846,http://dx.doi.org/10.1109/TVCG.2018.2864846,1122.0,1131.0,J,"Scientific visualization developed successful methods for scalar and vector fields. For tensor fields, however, effective, interactive visualizations are still missing despite progress over the last decades. We present a general approach for the generation of separating surfaces in symmetric, second-order, three-dimensional tensor fields. These surfaces are defined as fiber surfaces of the invariant space, i.e. as pre-images of surfaces in the range of a complete set of invariants. This approach leads to a generalization of the fiber surface algorithm by Klacansky et al. [16] to three dimensions in the range. This is due to the fact that the invariant space is three-dimensional for symmetric second-order tensors over a spatial domain. We present an algorithm for surface construction for simplicial grids in the domain and simplicial surfaces in the invariant space. We demonstrate our approach by applying it to stress fields from component design in mechanical engineering.",Felix Raith;Christian Blecha;Thomas Nagel;Francesco Parisio;Olaf Kolditz;Fabian Günther;Markus Stommel;Gerik Scheuermann,Felix Raith;Christian Blecha;Thomas Nagel;Francesco Parisio;Olaf Kolditz;Fabian Günther;Markus Stommel;Gerik Scheuermann,"Institute of Computer Science, Leipzig University, Leipzig, Germany;Institute of Computer Science, Leipzig University, Leipzig, Germany;Department of Environmental Informatics, Helmholtz Center for Environmental Research, Leipzig, Germany;Department of Environmental Informatics, Helmholtz Center for Environmental Research, Leipzig, Germany;Department of Environmental Informatics, Helmholtz Center for Environmental Research, Leipzig, Germany;Faculty for Mechanical Engineering, TU Dortmund University, Dortmund;Faculty for Mechanical Engineering, TU Dortmund University, Dortmund;Institute of Computer Science, Leipzig University, Leipzig, Germany",10.1109/visual.1994.346326;10.1109/visual.2003.1250379;10.1109/visual.1994.346326,"visualization,tensor field,invariants,fiber surface,interaction",18.0,21.0,36.0,622.0,,,tensor fields surfaces;interactive visualizations;grids domain simplicial;approach applying stress;range fact invariant,0.6828;0.3660;0.3006;0.2202;-0.0187,"[np.int64(-1), np.int64(1), -1, -1, -1]",35;16;-1;-1;-1,16;35,35,Vector and Tensor Visualization
InfoVis,2014,Revisiting Bertin Matrices: New Interactions for Crafting Tabular Visualizations,10.1109/tvcg.2014.2346279,http://dx.doi.org/10.1109/TVCG.2014.2346279,2082.0,2091.0,J,"We present Bertifier, a web app for rapidly creating tabular visualizations from spreadsheets. Bertifier draws from Jacques Bertin's matrix analysis method, whose goal was to “simplify without destroying” by encoding cell values visually and grouping similar rows and columns. Although there were several attempts to bring this method to computers, no implementation exists today that is both exhaustive and accessible to a large audience. Bertifier remains faithful to Bertin's method while leveraging the power of today's interactive computers. Tables are formatted and manipulated through crossets, a new interaction technique for rapidly applying operations on rows and columns. We also introduce visual reordering, a semi-interactive reordering approach that lets users apply and tune automatic reordering algorithms in a WYSIWYG manner. Sessions with eight users from different backgrounds suggest that Bertifier has the potential to bring Bertin's method to a wider audience of both technical and non-technical users, and empower them with data analysis and communication tools that were so far only accessible to a handful of specialists.COMPUTER",Charles Perin;Pierre Dragicevic;Jean-Daniel Fekete,Charles Perin;Pierre Dragicevic;Jean-Daniel Fekete,"INRIA, CNRS-LIMSI;INRIA;INRIA",10.1109/tvcg.2006.160;10.1109/tvcg.2014.2346292;10.1109/tvcg.2014.2346426;10.1109/tvcg.2006.160,"Visualization, Interaction, Tabular Data, Bertin, Crossing, Crossets",105.0,61.0,60.0,1031.0,,,tabular visualizations;reordering algorithms;web app rapidly;leveraging power today;bertifier remains faithful,0.6844;0.2624;0.2355;0.1610;0.1270,"[np.int64(1), -1, -1, -1, -1]",12;-1;-1;-1;-1,12,12,Table-Based Visualizations
Vis,1990,Case study in scientific visualization: factors inducing periodic breathing in humans with blunted hypoxic sensitivity,10.1109/visual.1990.146415,http://dx.doi.org/10.1109/VISUAL.1990.146415,430.0,434.0,C,"The problem of presenting and gaining deeper understanding of a multidimensional system, a mathematical model Predicting 20-90 s oscillations in breathing, is presented. The authors utilized custom software for interactive analysis of a three-dimensional model, plus Wavefront software to render translucent images of the 3D surfaces. The results show that under conditions of no peripheral chemosensor sensitivity, periodic breathing is predicted to occur with (1) an increase in circulatory transit time between the lungs and brain, (2) the presence of marked steady state hypoventilation, and/or (3) an increase in brain blood flow rate. It is concluded that the peripheral chemosensors (carotid bodies) are not essential for the development of periodic breathing.&lt;&lt;ETX&gt;&gt;",Wayne E. Fordyce;Jeffrey Ventrella,W.E. Fordyce;J.J. Ventrella,"Research Computing Services, Syracuse University, Syracuse, NY, USA;Research Computing Services, Syracuse University, Syracuse, NY, USA",0.1109/visual.1990.146415,,1.0,1.0,10.0,46.0,,,periodic breathing predicted;peripheral chemosensors;software interactive analysis;images 3d surfaces;state,0.7084;0.3371;0.0867;0.0782;-0.0205,"[np.int64(-1), -1, -1, -1, -1]",40;-1;-1;-1;-1,40,40,Respiratory Function Analysis
InfoVis,2016,Colorgorical: Creating discriminable and preferable color palettes for information visualization,10.1109/tvcg.2016.2598918,http://dx.doi.org/10.1109/TVCG.2016.2598918,521.0,530.0,J,"We present an evaluation of Colorgorical, a web-based tool for creating discriminable and aesthetically preferable categorical color palettes. Colorgorical uses iterative semi-random sampling to pick colors from CIELAB space based on user-defined discriminability and preference importances. Colors are selected by assigning each a weighted sum score that applies the user-defined importances to Perceptual Distance, Name Difference, Name Uniqueness, and Pair Preference scoring functions, which compare a potential sample to already-picked palette colors. After, a color is added to the palette by randomly sampling from the highest scoring palettes. Users can also specify hue ranges or build off their own starting palettes. This procedure differs from previous approaches that do not allow customization (e.g., pre-made ColorBrewer palettes) or do not consider visualization design constraints (e.g., Adobe Color and ACE). In a Palette Score Evaluation, we verified that each scoring function measured different color information. Experiment 1 demonstrated that slider manipulation generates palettes that are consistent with the expected balance of discriminability and aesthetic preference for 3-, 5-, and 8-color palettes, and also shows that the number of colors may change the effectiveness of pair-based discriminability and preference scores. For instance, if the Pair Preference slider were upweighted, users would judge the palettes as more preferable on average. Experiment 2 compared Colorgorical palettes to benchmark palettes (ColorBrewer, Microsoft, Tableau, Random). Colorgorical palettes are as discriminable and are at least as preferable or more preferable than the alternative palette sets. In sum, Colorgorical allows users to make customized color palettes that are, on average, as effective as current industry standards by balancing the importance of discriminability and aesthetic preference.",Connor Gramazio;David H. Laidlaw;Karen B. Schloss,Connor C. Gramazio;David H. Laidlaw;Karen B. Schloss,"Dept. of Computer Science at Brown University;Dept. of Computer Science at Brown University;Dept. of Cognitive, Linguistic, and Psychological Sciences at Brown University",10.1109/visual.1996.568118;10.1109/tvcg.2014.2346978;10.1109/tvcg.2015.2467471;10.1109/tvcg.2014.2346983;10.1109/tvcg.2012.233;10.1109/visual.1996.568118,Aesthetics in Visualization;Color Perception;Metrics & Benchmarks;Visual Design;Visualization,119.0,101.0,37.0,3136.0,,,preference color palettes;balancing importance discriminability;demonstrated slider manipulation;generates;function measured different,0.7348;0.2763;0.1581;0.0475;-0.0502,"[np.int64(-1), -1, -1, -1, -1]",-1;-1;-1;-1;-1,,-1,Complex Data Analysis
Vis,1997,exVis: developing a wind tunnel data visualization tool,10.1109/visual.1997.663911,http://dx.doi.org/10.1109/VISUAL.1997.663911,417.0,420.0,C,"Software has been developed to apply visualization techniques to aeronautics data collected during wind tunnel experiments. Interaction between the software developers and the aeroscientists has been crucial in making the software. The interaction has also been important in building the scientists' confidence in the use of interactive, computer-mediated analysis tools.",Samuel P. Uselton,S.P. Uselton,"Ames Research Center, NASA, Moffett Field, CA, USA",,,22.0,6.0,0.0,95.0,,,wind tunnel experiments;software developers aeroscientists;apply visualization;use interactive computer;scientists confidence use,0.6379;0.4952;0.4543;0.2616;0.2133,"[np.int64(-1), np.int64(-1), np.int64(1), -1, -1]",25;34;67;-1;-1,25;34;67,25,Fluid Dynamics Research
Vis,2008,Visualization of Cellular and Microvascular Relationships,10.1109/tvcg.2008.179,http://dx.doi.org/10.1109/TVCG.2008.179,1611.0,1618.0,J,"Understanding the structure of microvasculature structures and their relationship to cells in biological tissue is an important and complex problem. Brain microvasculature in particular is known to play an important role in chronic diseases. However, these networks are only visible at the microscopic level and can span large volumes of tissue. Due to recent advances in microscopy, large volumes of data can be imaged at the resolution necessary to reconstruct these structures. Due to the dense and complex nature of microscopy data sets, it is important to limit the amount of information displayed. In this paper, we describe methods for encoding the unique structure of microvascular data, allowing researchers to selectively explore microvascular anatomy. We also identify the queries most useful to researchers studying microvascular and cellular relationships. By associating cellular structures with our microvascular framework, we allow researchers to explore interesting anatomical relationships in dense and complex data sets.",David Mayerich;Louise C. Abbott;John Keyser,David Mayerich;Louise Abbott;John Keyser,"Department of Computer Science, Texas A and M University, USA;Department of Veterinary Integrative Biosciences, Texas A and M University, USA;Department of Computer Science, Texas A and M University, USA",10.1109/visual.2005.1532859;10.1109/visual.1997.663917;10.1109/tvcg.2006.197;10.1109/tvcg.2007.70532;10.1109/visual.2004.16;10.1109/visual.2005.1532859,"microscopy, biomedical, medical, blood vessels, cells",26.0,14.0,35.0,370.0,,,structure microvascular data;problem brain;limit information displayed;methods encoding unique;advances,0.7228;0.2447;0.1752;0.1447;0.0935,"[np.int64(-1), -1, -1, -1, -1]",48;-1;-1;-1;-1,48,48,Medical Imaging Techniques
InfoVis,2020,MobileVisFixer: Tailoring Web Visualizations for Mobile Phones Leveraging an Explainable Reinforcement Learning Framework,10.1109/tvcg.2020.3030423,http://dx.doi.org/10.1109/TVCG.2020.3030423,464.0,474.0,J,"We contribute MobileVisFixer, a new method to make visualizations more mobile-friendly. Although mobile devices have become the primary means of accessing information on the web, many existing visualizations are not optimized for small screens and can lead to a frustrating user experience. Currently, practitioners and researchers have to engage in a tedious and time-consuming process to ensure that their designs scale to screens of different sizes, and existing toolkits and libraries provide little support in diagnosing and repairing issues. To address this challenge, MobileVisFixer automates a mobile-friendly visualization re-design process with a novel reinforcement learning framework. To inform the design of MobileVisFixer, we first collected and analyzed SVG-based visualizations on the web, and identified five common mobile-friendly issues. MobileVisFixer addresses four of these issues on single-view Cartesian visualizations with linear or discrete scales by a Markov Decision Process model that is both generalizable across various visualizations and fully explainable. MobileVisFixer deconstructs charts into declarative formats, and uses a greedy heuristic based on Policy Gradient methods to find solutions to this difficult, multi-criteria optimization problem in reasonable time. In addition, MobileVisFixer can be easily extended with the incorporation of optimization algorithms for data visualizations. Quantitative evaluation on two real-world datasets demonstrates the effectiveness and generalizability of our method.",Aoyu Wu;Wai Tong;Tim Dwyer;Bongshin Lee;Petra Isenberg;Huamin Qu,Aoyu Wu;Wai Tong;Tim Dwyer;Bongshin Lee;Petra Isenberg;Huamin Qu,Hong Kong University of Science and Technology;Hong Kong University of Science and Technology;Monash University;Microsoft Research;Inria;Hong Kong University of Science and Technology,10.1109/tvcg.2018.2865234;10.1109/tvcg.2019.2934397;10.1109/tvcg.2018.2865138;10.1109/tvcg.2019.2934431;10.1109/vast.2007.4388994;10.1109/tvcg.2007.70594;10.1109/tvcg.2018.2865240;10.1109/tvcg.2017.2744320;10.1109/tvcg.2018.2865158;10.1109/tvcg.2016.2599030;10.1109/tvcg.2015.2467091;10.1109/tvcg.2012.196;10.1109/tvcg.2019.2934538;10.1109/tvcg.2018.2865234,"Mobile visualization,Responsive visualization,Machine learning for visualizations,Reinforcement learning",30.0,27.0,78.0,1404.0,,,visualizations mobile friendly;heuristic based policy;different sizes;screens lead frustrating;contribute,0.6404;0.2778;0.1615;0.1557;0.0637,"[np.int64(1), -1, -1, -1, -1]",87;-1;-1;-1;-1,87,87,Mobile Usability Visualizations
InfoVis,2002,InterRing: an interactive tool for visually navigating and manipulating hierarchical structures,10.1109/infvis.2002.1173151,http://dx.doi.org/10.1109/INFVIS.2002.1173151,77.0,84.0,C,"Radial, space-filling (RSF) techniques for hierarchy visualization have several advantages over traditional node-link diagrams, including the ability to efficiently use the display space while effectively conveying the hierarchy structure. Several RSF systems and tools have been developed to date, each with varying degrees of support for interactive operations such as selection and navigation. We describe what we believe to be a complete set of desirable operations on hierarchical structures. We then present InterRing, an RSF hierarchy visualization system that supports a significantly more extensive set of these operations than prior systems. In particular, InterRing supports multi-focus distortions, interactive hierarchy reconfiguration, and both semi-automated and manual selection. We show the power and utility of these and other operations, and describe our on-going efforts to evaluate their effectiveness and usability.",Jing Yang 0001;Matthew O. Ward;Elke A. Rundensteiner,Jing Yang;M.O. Ward;E.A. Rundensteiner,"Computer Science Department, Worcester Polytechnic Institute, Worcester, MA, USA;Computer Science Department, Worcester Polytechnic Institute, Worcester, MA, USA;Computer Science Department, Worcester Polytechnic Institute, Worcester, MA, USA",10.1109/infvis.2001.963290;10.1109/infvis.2001.963285;10.1109/infvis.1997.636718;10.1109/infvis.1999.801858;10.1109/infvis.1995.528689;10.1109/infvis.2001.963283;10.1109/visual.1991.175815;10.1109/infvis.2000.885091;10.1109/infvis.1999.801860;10.1109/infvis.2001.963284;10.1109/visual.1999.809866;10.1109/infvis.2001.963281;10.1109/infvis.1998.729557;10.1109/infvis.2001.963290,"radial space-filling hierarchy visualizations, multi-focus distortion, structure-based brushing",192.0,21.0,32.0,1028.0,,,hierarchy visualization supports;space filling rsf;reconfiguration semi automated;focus;date varying,0.7759;0.2713;0.1349;0.0963;-0.0968,"[np.int64(1), -1, -1, -1, -1]",50;-1;-1;-1;-1,50,50,Hierarchical Visualization
Vis,2021,A Critical Reflection on Visualization Research: Where Do Decision Making Tasks Hide?,10.1109/tvcg.2021.3114813,http://dx.doi.org/10.1109/TVCG.2021.3114813,1128.0,1138.0,J,"It has been widely suggested that a key goal of visualization systems is to assist decision making, but is this true? We conduct a critical investigation on whether the activity of decision making is indeed central to the visualization domain. By approaching decision making as a user <i>task</i>, we explore the degree to which decision tasks are evident in visualization research and user studies. Our analysis suggests that decision tasks are not commonly found in current visualization task taxonomies and that the visualization field has yet to leverage guidance from decision theory domains on how to study such tasks. We further found that the majority of visualizations addressing decision making were not evaluated based on their ability to assist decision tasks. Finally, to help expand the impact of visual analytics in organizational as well as casual decision making activities, we initiate a research agenda on how decision making assistance could be elevated throughout visualization research.",Evanthia Dimara;John T. Stasko,Evanthia Dimara;John Stasko,"Utrecht University, Netherlands and University of Konstanz, Germany;Georgia Tech, US",10.1109/vast.2011.6102457;10.1109/tvcg.2019.2934262;10.1109/infvis.2005.1532136;10.1109/infvis.2004.10;10.1109/vast.2007.4388995;10.1109/tvcg.2020.3028891;10.1109/tvcg.2016.2598869;10.1109/tvcg.2020.3030455;10.1109/tvcg.2013.186;10.1109/tvcg.2013.124;10.1109/tvcg.2013.146;10.1109/vast.2006.261431;10.1109/tvcg.2020.3030342;10.1109/infvis.1998.729560;10.1109/vast.2017.8585665;10.1109/infvis.1996.559213;10.1109/tvcg.2016.2598544;10.1109/tvcg.2018.2865233;10.1109/tvcg.2016.2598594;10.1109/tvcg.2017.2745138;10.1109/tvcg.2019.2934283;10.1109/tvcg.2020.3030469;10.1109/vast.2015.7347636;10.1109/tvcg.2013.226;10.1109/tvcg.2013.138;10.1109/vast.2008.4677365;10.1109/tvcg.2013.173;10.1109/vast.2010.5650815;10.1109/tvcg.2016.2598588;10.1109/tvcg.2019.2934659;10.1109/tvcg.2011.255;10.1109/tvcg.2018.2864889;10.1109/infvis.1997.636793;10.1109/tvcg.2020.3030335;10.1109/tvcg.2018.2864909;10.1109/tvcg.2012.215;10.1109/vast.2007.4388994;10.1109/tvcg.2014.2346930;10.1109/tvcg.2017.2744299;10.1109/tvcg.2018.2865159;10.1109/tvcg.2020.3028985;10.1109/tvcg.2010.177;10.1109/tvcg.2014.2346926;10.1109/tvcg.2012.278;10.1109/vast.2011.6102451;10.1109/tvcg.2016.2599106;10.1109/tvcg.2016.2598589;10.1109/vast.2006.261434;10.1109/tvcg.2015.2467754;10.1109/tvcg.2012.261;10.1109/tvcg.2011.196;10.1109/tvcg.2013.130;10.1109/vast.2009.5333920;10.1109/tvcg.2015.2467591;10.1109/tvcg.2014.2346481;10.1109/vast.2008.4677363;10.1109/tvcg.2013.120;10.1109/tvcg.2012.213;10.1109/tvcg.2015.2468011;10.1109/visual.1992.235203;10.1109/vast.2011.6102453;10.1109/visual.2005.1532781;10.1109/tvcg.2015.2468111;10.1109/tvcg.2017.2745078;10.1109/visual.1990.146375;10.1109/tvcg.2018.2865126;10.1109/infvis.1995.528682;10.1109/tvcg.2020.3028957;10.1109/tvcg.2016.2598664;10.1109/tvcg.2007.70515;10.1109/tvcg.2014.2346898;10.1109/tvcg.2018.2865076;10.1109/tvcg.2017.2744738;10.1109/tvcg.2020.3030458;10.1109/tvcg.2010.223;10.1109/tvcg.2014.2346922;10.1109/infvis.1995.528694;10.1109/vast.2011.6102457,"decision making,data,visualization,visual analytics,taxonomies,task",13.0,23.0,190.0,1955.0,,,visualizations addressing decision;making user task;study;theory domains;elevated,0.7813;0.1540;0.1104;0.0515;0.0102,"[np.int64(1), -1, -1, -1, -1]",69;-1;-1;-1;-1,69,69,Visualization User Studies
VAST,2017,SOMFlow: Guided Exploratory Cluster Analysis with Self-Organizing Maps and Analytic Provenance,10.1109/tvcg.2017.2744805,http://dx.doi.org/10.1109/TVCG.2017.2744805,120.0,130.0,J,"Clustering is a core building block for data analysis, aiming to extract otherwise hidden structures and relations from raw datasets, such as particular groups that can be effectively related, compared, and interpreted. A plethora of visual-interactive cluster analysis techniques has been proposed to date, however, arriving at useful clusterings often requires several rounds of user interactions to fine-tune the data preprocessing and algorithms. We present a multi-stage Visual Analytics (VA) approach for iterative cluster refinement together with an implementation (SOMFlow) that uses Self-Organizing Maps (SOM) to analyze time series data. It supports exploration by offering the analyst a visual platform to analyze intermediate results, adapt the underlying computations, iteratively partition the data, and to reflect previous analytical activities. The history of previous decisions is explicitly visualized within a flow graph, allowing to compare earlier cluster refinements and to explore relations. We further leverage quality and interestingness measures to guide the analyst in the discovery of useful patterns, relations, and data partitions. We conducted two pair analytics experiments together with a subject matter expert in speech intonation research to demonstrate that the approach is effective for interactive data analysis, supporting enhanced understanding of clustering results as well as the interactive process itself.",Dominik Sacha;Matthias Kraus 0002;Jürgen Bernard;Michael Behrisch 0001;Tobias Schreck;Yuki Asano 0003;Daniel A. Keim,Dominik Sacha;Matthias Kraus;Jürgen Bernard;Michael Behrisch;Tobias Schreck;Yuki Asano;Daniel A. Keim,"University of Konstanz, Germany;University of Konstanz, Germany;TU Darmstadt, Germany;University of Konstanz, Germany;Graz University of Technology;University of Tübingen;University of Konstanz, Germany",10.1109/vast.2009.5332584;10.1109/vast.2014.7042480;10.1109/tvcg.2013.178;10.1109/tvcg.2011.229;10.1109/tvcg.2011.188;10.1109/tvcg.2016.2598468;10.1109/vast.2010.5652443;10.1109/vast.2015.7347625;10.1109/vast.2007.4389013;10.1109/tvcg.2014.2346260;10.1109/tvcg.2007.70582;10.1109/vast.2007.4388999;10.1109/tvcg.2014.2346481;10.1109/tvcg.2016.2598495;10.1109/vast.2011.6102453;10.1109/vast.2009.5332584,"Visual Analytics,Interaction,Visual Cluster Analysis,Quality Metrics,Guidance,Self-Organizing Maps,Time Series",72.0,57.0,58.0,1887.0,,,interactive cluster analysis;data reflect previous;somflow uses self;intonation research;time,0.7032;0.2200;0.1985;0.1765;0.0697,"[np.int64(1), -1, -1, -1, -1]",8;-1;-1;-1;-1,8,8,Cluster Analysis Tools
InfoVis,2015,Off the Radar: Comparative Evaluation of Radial Visualization Solutions for Composite Indicators,10.1109/tvcg.2015.2467322,http://dx.doi.org/10.1109/TVCG.2015.2467322,569.0,578.0,J,"A composite indicator (CI) is a measuring and benchmark tool used to capture multi-dimensional concepts, such as Information and Communication Technology (ICT) usage. Individual indicators are selected and combined to reflect a phenomena being measured. Visualization of a composite indicator is recommended as a tool to enable interested stakeholders, as well as the public audience, to better understand the indicator components and evolution overtime. However, existing CI visualizations introduce a variety of solutions and there is a lack in CI's visualization guidelines. Radial visualizations are popular among these solutions because of CI's inherent multi-dimensionality. Although in dispute, Radar-charts are often used for CI presentation. However, no empirical evidence on Radar's effectiveness and efficiency for common CI tasks is available. In this paper, we aim to fill this gap by reporting on a controlled experiment that compares the Radar chart technique with two other radial visualization methods: Flowercharts as used in the well-known OECD Betterlife index, and Circle-charts which could be adopted for this purpose. Examples of these charts in the current context are shown in Figure 1. We evaluated these charts, showing the same data with each of the mentioned techniques applying small multiple views for different dimensions of the data. We compared users' performance and preference empirically under a formal task-taxonomy. Results indicate that the Radar chart was the least effective and least liked, while performance of the two other options were mixed and dependent on the task. Results also showed strong preference of participants toward the Flower chart. Summarizing our results, we provide specific design guidelines for composite indicator visualization.",Yael Albo;Joel Lanir;Peter Bak;Sheizaf Rafaeli,Yael Albo;Joel Lanir;Peter Bak;Sheizaf Rafaeli,"University of Haifa, Israel;University of Haifa, Israel;IBM Research Haifa Lab, Haifa, Israel;Sheizaf Rafaeli is with University of Haifa, Israel",10.1109/tvcg.2010.209;10.1109/tvcg.2008.125;10.1109/tvcg.2010.209,"Visualization evaluation, radial layout design, composite indicator visualization, experiment",60.0,46.0,35.0,1415.0,,,composite indicator visualization;communication technology ict;compared users;radar effectiveness efficiency;adopted purpose,0.6964;0.2733;0.2726;0.1764;-0.0205,"[np.int64(1), -1, -1, -1, -1]",6;-1;-1;-1;-1,6,6,Dynamic Data Visualization
